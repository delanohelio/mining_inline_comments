{"pr_number": 6375, "pr_title": "feat: Implement a physical plan builder and physical plan for pull queries", "pr_createdAt": "2020-10-07T20:43:22Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6375", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNDAzOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502704038", "bodyText": "Can you genericize this so that you don't have to return Object?", "author": "AlanConfluent", "createdAt": "2020-10-09T22:54:24Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {\n+\n+  public abstract void open();\n+\n+  // Scan returns TableRow, Project returns List<List<?>>", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjE2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722169", "bodyText": "Unfortunately, I haven't found a better way since two different operators need to return each TableRow and the other List<List<?>>", "author": "vpapavas", "createdAt": "2020-10-10T00:35:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNDAzOA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\nindex 89a771986f..fcc0bf05b7 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n\n@@ -15,6 +15,11 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import java.util.List;\n+\n+/**\n+ * Represents a pipelined physical operator of the physical plan.\n+ */\n public abstract class AbstractPhysicalOperator {\n \n   public abstract void open();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzA3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502707074", "bodyText": "So we're just using the existing, unchanged LogicalPlanner to begin with?  Looking through it, it probably handles the basic logical nodes we would want.  I can see us doing more of our analysis and error checking there (e.g. not more than one key comparison for pull queries, etc. rather than doing it in the physical planner since that seems too far downstream).   If we handle more complex operations in the future, we'd obviously want to have a logical component.", "author": "AlanConfluent", "createdAt": "2020-10-09T23:08:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -221,6 +314,41 @@ private ExecutorPlans planQuery(\n     return new ExecutorPlans(logicalPlan, physicalPlan);\n   }\n \n+  private LogicalPlanNode buildAndValidateLogicalPlan(\n+      final ConfiguredStatement<?> statement,\n+      final ImmutableAnalysis analysis,\n+      final KsqlConfig config\n+  ) {\n+    final OutputNode outputNode = new LogicalPlanner(config, analysis, engineContext.getMetaStore())", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjQwMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722401", "bodyText": "Yes. The logical plan nodes are there but they all have AST expressions and miss the analysis that is done for instance in the PhysicalPlanBuilder. A lot of that code in there should be moved to the logical plan", "author": "vpapavas", "createdAt": "2020-10-10T00:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzA3NA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..eb9b486593 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -328,28 +309,25 @@ final class EngineExecutor {\n   }\n \n   private PullPhysicalPlan buildPullPhysicalPlan(\n-      final KsqlExecutionContext ksqlEngine,\n       final LogicalPlanNode logicalPlan,\n       final KsqlConfig config,\n       final ImmutableAnalysis analysis,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final RoutingOptions routingOptions,\n       final ConfiguredStatement<Query> statement\n   ) {\n+\n     final PullPhysicalPlanBuilder builder = new PullPhysicalPlanBuilder(\n         engineContext.getMetaStore(),\n+        engineContext.getProcessingLogContext(),\n+        PullQueryExecutionUtil.findMaterializingQuery(engineContext, analysis),\n         config,\n-        serviceContext,\n-        ksqlEngine,\n         analysis,\n-        routingFilterFactory,\n-        routingOptions,\n         statement\n     );\n     return builder.buildPullPhysicalPlan(logicalPlan);\n   }\n \n   private static final class ExecutorPlans {\n+\n     private final LogicalPlanNode logicalPlan;\n     private final PhysicalPlan physicalPlan;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzQ5OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502707499", "bodyText": "Maybe pull this out to its own class?", "author": "AlanConfluent", "createdAt": "2020-10-09T23:10:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -403,4 +531,66 @@ private String buildPlanSummary(final QueryId queryId, final ExecutionStep<?> pl\n     return new PlanSummary(queryId, config.getConfig(false), engineContext.getMetaStore())\n         .summarize(plan);\n   }\n+\n+  private static final class ColumnReferenceRewriter\n+      extends VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n+\n+    private ColumnReferenceRewriter() {\n+      super(Optional.empty());\n+    }\n+\n+    @Override\n+    public Optional<Expression> visitQualifiedColumnReference(\n+        final QualifiedColumnReferenceExp node,\n+        final Context<Void> ctx\n+    ) {\n+      return Optional.of(new UnqualifiedColumnReferenceExp(node.getColumnName()));\n+    }\n+  }\n+\n+  private static final class ConfigRoutingOptions implements RoutingOptions {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2MDgyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505760826", "bodyText": "+1", "author": "guozhangwang", "createdAt": "2020-10-15T18:39:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzQ5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..122fbc98fa 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -548,44 +549,6 @@ final class EngineExecutor {\n     }\n   }\n \n-  private static final class ConfigRoutingOptions implements RoutingOptions {\n-\n-    private final KsqlConfig ksqlConfig;\n-    private final Map<String, ?> requestProperties;\n-\n-    ConfigRoutingOptions(\n-        final KsqlConfig ksqlConfig,\n-        final Map<String, ?> requestProperties\n-    ) {\n-      this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n-      this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n-    }\n-\n-    private boolean getForwardedFlag(final String key) {\n-      if (requestProperties.containsKey(key)) {\n-        return (Boolean) requestProperties.get(key);\n-      }\n-      return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n-    }\n-\n-    public boolean isDebugRequest() {\n-      if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n-        return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n-      }\n-      return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n-    }\n-\n-    @Override\n-    public long getOffsetLagAllowed() {\n-      return ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG);\n-    }\n-\n-    @Override\n-    public boolean skipForwardRequest() {\n-      return getForwardedFlag(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING);\n-    }\n-  }\n-\n   @VisibleForTesting\n   void checkRateLimit(final RateLimiter rateLimiter) {\n     if (!rateLimiter.tryAcquire()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502709007", "bodyText": "Is this not the type of logic that would live in the logical planner? Or at least in buildAndValidateLogicalPlan", "author": "AlanConfluent", "createdAt": "2020-10-09T23:17:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new ConfigRoutingOptions(\n+        sessionConfig.getConfig(true),\n+        requestProperties\n+    );\n+    final RateLimiter rateLimiter = RateLimiter.create(sessionConfig.getConfig(true).getInt(\n+        KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      checkRateLimit(rateLimiter);\n+    }\n+\n+\n+    try {\n+      final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n+      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n+          queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n+          new ColumnReferenceRewriter()::process\n+      );", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMzE3Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502723176", "bodyText": "The analyzer is a different step from the logical plan.", "author": "vpapavas", "createdAt": "2020-10-10T00:44:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc1OTgwNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505759805", "bodyText": "I thought the plan is to have a single code path for logical plans across all queries. But this new function is only for pull queries, whereas for other queries we are still using QueryEngine#buildQueryLogicalPlan.", "author": "guozhangwang", "createdAt": "2020-10-15T18:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2ODI2NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509768265", "bodyText": "Yes but they are doing the same thing with respect to the logical planner i.e. calling the same methods to build the logical plan. The difference is in the Analyzer where for pull queries there is something different done, that's why I had to create a new method. The analyzer part will be cleaned up in a later PR once we get more clarity about what we need from push queries as well.", "author": "vpapavas", "createdAt": "2020-10-21T22:37:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}], "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..122fbc98fa 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -145,7 +144,8 @@ final class EngineExecutor {\n       final RoutingFilterFactory routingFilterFactory,\n       final Map<String, Object> requestProperties,\n       final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTcwOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502709708", "bodyText": "This analysis exposes all of the parser expressions.  Isn't that something that should be at the logical planner layer?  I would assume that the physical planner would take some logical nodes which have all of the relevant data extracted from the expressions.\nMaybe this is just a first step, and there's still some intermixing of layers, but I just thought I would ask.", "author": "AlanConfluent", "createdAt": "2020-10-09T23:20:43Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -221,6 +314,41 @@ private ExecutorPlans planQuery(\n     return new ExecutorPlans(logicalPlan, physicalPlan);\n   }\n \n+  private LogicalPlanNode buildAndValidateLogicalPlan(\n+      final ConfiguredStatement<?> statement,\n+      final ImmutableAnalysis analysis,\n+      final KsqlConfig config\n+  ) {\n+    final OutputNode outputNode = new LogicalPlanner(config, analysis, engineContext.getMetaStore())\n+        .buildPlan();\n+    return new LogicalPlanNode(\n+        statement.getStatementText(),\n+        Optional.of(outputNode)\n+    );\n+  }\n+\n+  private PullPhysicalPlan buildPullPhysicalPlan(\n+      final KsqlExecutionContext ksqlEngine,\n+      final LogicalPlanNode logicalPlan,\n+      final KsqlConfig config,\n+      final ImmutableAnalysis analysis,", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjgxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722818", "bodyText": "The analyzer performs some initial validation and categorization and is a different step happening before the logical plan. The logical planner exposes as well parser expressions but inside logical nodes. That's what I want to change. So that at the physical planner we don't deal with any AST expressions anymore, only logical entities.", "author": "vpapavas", "createdAt": "2020-10-10T00:41:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTcwOA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..eb9b486593 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -328,28 +309,25 @@ final class EngineExecutor {\n   }\n \n   private PullPhysicalPlan buildPullPhysicalPlan(\n-      final KsqlExecutionContext ksqlEngine,\n       final LogicalPlanNode logicalPlan,\n       final KsqlConfig config,\n       final ImmutableAnalysis analysis,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final RoutingOptions routingOptions,\n       final ConfiguredStatement<Query> statement\n   ) {\n+\n     final PullPhysicalPlanBuilder builder = new PullPhysicalPlanBuilder(\n         engineContext.getMetaStore(),\n+        engineContext.getProcessingLogContext(),\n+        PullQueryExecutionUtil.findMaterializingQuery(engineContext, analysis),\n         config,\n-        serviceContext,\n-        ksqlEngine,\n         analysis,\n-        routingFilterFactory,\n-        routingOptions,\n         statement\n     );\n     return builder.buildPullPhysicalPlan(logicalPlan);\n   }\n \n   private static final class ExecutorPlans {\n+\n     private final LogicalPlanNode logicalPlan;\n     private final PhysicalPlan physicalPlan;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMTY1Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502711656", "bodyText": "Is there anything that sanity checks the order in which these methods will be called?  For example, will whereInfo be set at this point?\nI guess we know this will be processed last because it's the source node, but it might make sense to assert some of the invariants you're assuming to begin with (e.g. whereInfo != null)", "author": "AlanConfluent", "createdAt": "2020-10-09T23:30:28Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.SingleKeyTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.SingleKeyWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private Struct key;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        key,\n+        mat,\n+        routingFilterFactory,\n+        routingOptions,\n+        statement,\n+        serviceContext);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(logicalNode, analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+\n+    key = asKeyStruct(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjg5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722896", "bodyText": "I can add some sanity checks", "author": "vpapavas", "createdAt": "2020-10-10T00:41:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMTY1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex a66dd785dd..33f3c560e7 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -211,7 +211,9 @@ public class PullPhysicalPlanBuilder {\n       final DataSourceNode logicalNode,\n       final PersistentQueryMetadata persistentQueryMetadata\n   ) {\n-\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n     key = asKeyStruct(\n         whereInfo.getKeyBound(), persistentQueryMetadata.getPhysicalSchema());\n     if (!whereInfo.getWindowBounds().isPresent()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMzI5NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502713295", "bodyText": "I assume this doesn't currently do anything because this is done at the rocksdb layer?", "author": "AlanConfluent", "createdAt": "2020-10-09T23:38:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import java.util.Objects;\n+\n+public class SelectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final FilterNode logicalNode;\n+  private AbstractPhysicalOperator child;\n+\n+  public SelectOperator(final FilterNode logicalNode) {\n+    this.logicalNode = Objects.requireNonNull(logicalNode);\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    return child.next();", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMzA0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502723041", "bodyText": "This doesn't do anything because currently we only support single key equality and nothing else in the WHERE clause. When we make it more general and allow others stuff as well, (like functions) we will need to add logic here.", "author": "vpapavas", "createdAt": "2020-10-10T00:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMzI5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java\nindex b0568ded2a..9282393ad8 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java\n\n@@ -16,6 +16,7 @@\n package io.confluent.ksql.physical.pull.operators;\n \n import io.confluent.ksql.planner.plan.FilterNode;\n+import java.util.List;\n import java.util.Objects;\n \n public class SelectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyNjkxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505726918", "bodyText": "Just curious is it intentional to use different terms for types of queries? It seems:\n\nExecuteResult execute is for persistent push query\nTransientQueryMetadata executeQuery is for transient push query\nPullQueryResult executePullQuery is for pull query\n\nThe return class name, and the function names are all very different.", "author": "guozhangwang", "createdAt": "2020-10-15T17:45:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -114,6 +118,15 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3NzgyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509777825", "bodyText": "Yeah, I don't know what to tell you :)", "author": "vpapavas", "createdAt": "2020-10-21T22:50:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyNjkxOA=="}], "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 6e855e2e07..c67b014e45 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -124,7 +125,8 @@ public interface KsqlExecutionContext {\n       ConfiguredStatement<Query> statement,\n       Map<String, Object> requestProperties,\n       Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      RateLimiter rateLimiter\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMDIxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505730211", "bodyText": "nit: is there a line breaker or space needed before the statement text?", "author": "guozhangwang", "createdAt": "2020-10-15T17:51:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..122fbc98fa 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -145,7 +144,8 @@ final class EngineExecutor {\n       final RoutingFilterFactory routingFilterFactory,\n       final Map<String, Object> requestProperties,\n       final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMzQzOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505733439", "bodyText": "Is it okay to create a new rate limiter per query execution? It seems it does not use a global shared counter, so an individual rate limiter would only act for that single query and may never fail.", "author": "guozhangwang", "createdAt": "2020-10-15T17:56:41Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new ConfigRoutingOptions(\n+        sessionConfig.getConfig(true),\n+        requestProperties\n+    );\n+    final RateLimiter rateLimiter = RateLimiter.create(sessionConfig.getConfig(true).getInt(\n+        KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc4NTI4OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509785289", "bodyText": "You are right, I fixed it to be created only once.", "author": "vpapavas", "createdAt": "2020-10-21T23:06:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMzQzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 3ffabf0517..122fbc98fa 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -145,7 +144,8 @@ final class EngineExecutor {\n       final RoutingFilterFactory routingFilterFactory,\n       final Map<String, Object> requestProperties,\n       final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NDgyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505764825", "bodyText": "Another question for my own education: what's the difference between this class and QueryEngine? It seems the latter is only for persistent and transient push queries?", "author": "guozhangwang", "createdAt": "2020-10-15T18:46:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -246,6 +250,30 @@ public TransientQueryMetadata executeQuery(\n     }\n   }\n \n+  @Override\n+  public PullQueryResult executePullQuery(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "976bb4de2b89a498903d1931d9f182608846f0e5", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\nindex 28a93412e7..933d7b440f 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\n\n@@ -257,7 +258,8 @@ public class KsqlEngine implements KsqlExecutionContext, Closeable {\n       final ConfiguredStatement<Query> statement,\n       final Map<String, Object> requestProperties,\n       final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n   ) {\n     return EngineExecutor\n         .create(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NzM1NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505767354", "bodyText": "Is this going to be used beyond pull queries in the future?", "author": "guozhangwang", "createdAt": "2020-10-15T18:50:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MTIzNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509771235", "bodyText": "Yes, for push queries if the use the same physical plan builder", "author": "vpapavas", "createdAt": "2020-10-21T22:41:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NzM1NA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\nindex 89a771986f..fcc0bf05b7 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n\n@@ -15,6 +15,11 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import java.util.List;\n+\n+/**\n+ * Represents a pipelined physical operator of the physical plan.\n+ */\n public abstract class AbstractPhysicalOperator {\n \n   public abstract void open();\n"}}, {"oid": "976bb4de2b89a498903d1931d9f182608846f0e5", "url": "https://github.com/confluentinc/ksql/commit/976bb4de2b89a498903d1931d9f182608846f0e5", "message": "Address comments", "committedDate": "2020-10-26T19:00:50Z", "type": "forcePushed"}, {"oid": "be69d38620a9d72a17eab4913083890652b3684b", "url": "https://github.com/confluentinc/ksql/commit/be69d38620a9d72a17eab4913083890652b3684b", "message": "trying to fix rqt test", "committedDate": "2020-10-28T22:26:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTA2MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516205060", "bodyText": "Aren't these only used in tests?  I think they can still be package private.", "author": "AlanConfluent", "createdAt": "2020-11-02T19:28:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/internal/PullQueryExecutorMetrics.java", "diffHunk": "@@ -108,11 +108,11 @@ public void recordResponseSize(final double value) {\n     this.responseSizeSensor.record(value);\n   }\n \n-  List<Sensor> getSensors() {\n+  public List<Sensor> getSensors() {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjMwMjI2MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516302261", "bodyText": "No, they actually need to be public.", "author": "vpapavas", "createdAt": "2020-11-02T22:43:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTA2MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTEyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516205129", "bodyText": "Same here", "author": "AlanConfluent", "createdAt": "2020-11-02T19:28:19Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/internal/PullQueryExecutorMetrics.java", "diffHunk": "@@ -108,11 +108,11 @@ public void recordResponseSize(final double value) {\n     this.responseSizeSensor.record(value);\n   }\n \n-  List<Sensor> getSensors() {\n+  public List<Sensor> getSensors() {\n     return sensors;\n   }\n \n-  Metrics getMetrics() {\n+  public Metrics getMetrics() {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516208359", "bodyText": "You've created multiple RateLimiters, effectively allowing the rate limit only over each particular endpoint.  Can this be pushed down to a common place, such as the EngineExecutor?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:34:40Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -153,6 +163,7 @@ public void configure(final KsqlConfig config) {\n     }\n \n     ksqlConfig = config;\n+    rateLimiter = RateLimiter.create(ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3ODYwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516378609", "bodyText": "If I put in the EngineExecutor it will be per pull query (that's where I had it initially). I moved it to the KsqlRestApplication", "author": "vpapavas", "createdAt": "2020-11-03T01:09:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODU0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516418541", "bodyText": "@vpapavas did you mean to push a more recent udpate? some of your comments, like this one, don't seem to be resolved", "author": "agavra", "createdAt": "2020-11-03T04:08:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\nindex 9460ce0045..a8c7d24776 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n\n@@ -163,14 +165,14 @@ public class StreamedQueryResource implements KsqlConfigurable {\n     }\n \n     ksqlConfig = config;\n-    rateLimiter = RateLimiter.create(ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));\n   }\n \n   public EndpointResponse streamQuery(\n       final KsqlSecurityContext securityContext,\n       final KsqlRequest request,\n       final CompletableFuture<Void> connectionClosedFuture,\n-      final Optional<Boolean> isInternalRequest\n+      final Optional<Boolean> isInternalRequest,\n+      final KsqlMediaType mediaType\n   ) {\n     throwIfNotConfigured();\n     activenessRegistrar.updateLastRequestTime();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODU1MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516208550", "bodyText": "Remove commented code?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:34:57Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -266,9 +277,24 @@ private EndpointResponse handlePullQuery(\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n-    final PullQueryResult result = pullQueryExecutor.execute(\n+    final PullQueryResult result = ksqlEngine.executePullQuery(\n+        serviceContext,\n+        routingFilterFactory,\n+        configured,\n+        requestProperties,\n+        isInternalRequest,\n+        pullQueryMetrics,\n+        rateLimiter);\n+    final TableRows tableRows = new TableRows(\n+        statement.getStatementText(),\n+        result.getQueryId(),\n+        result.getSchema(),\n+        result.getTableRows());\n+\n+\n+    /*final PullQueryResult result = pullQueryExecutor.execute(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\nindex 9460ce0045..a8c7d24776 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n\n@@ -277,43 +278,71 @@ public class StreamedQueryResource implements KsqlConfigurable {\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n+    final SessionConfig sessionConfig = configured.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        configured.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // A request is considered forwarded if the request has the forwarded flag or if the request\n+    // is from an internal listener.\n+    final boolean isAlreadyForwarded = routingOptions.getIsSkipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      PullQueryExecutionUtil.checkRateLimit(rateLimiter);\n+    }\n+\n     final PullQueryResult result = ksqlEngine.executePullQuery(\n         serviceContext,\n-        routingFilterFactory,\n         configured,\n-        requestProperties,\n-        isInternalRequest,\n-        pullQueryMetrics,\n-        rateLimiter);\n+        routingFilterFactory,\n+        routingOptions,\n+        pullQueryMetrics\n+    );\n     final TableRows tableRows = new TableRows(\n         statement.getStatementText(),\n         result.getQueryId(),\n         result.getSchema(),\n         result.getTableRows());\n \n-\n-    /*final PullQueryResult result = pullQueryExecutor.execute(\n-        configured, requestProperties, serviceContext, isInternalRequest, pullQueryMetrics);\n-    final TableRows tableRows = result.getTableRows();*/\n     final Optional<List<KsqlHostInfoEntity>> hosts = result.getSourceNodes()\n         .map(list -> list.stream().map(KsqlNode::location)\n             .map(location -> new KsqlHostInfoEntity(location.getHost(), location.getPort()))\n             .collect(Collectors.toList()));\n \n-    final StreamedRow header = StreamedRow.header(tableRows.getQueryId(), tableRows.getSchema());\n+    final StreamedRow header = StreamedRow.header(\n+        tableRows.getQueryId(),\n+        tableRows.getSchema()\n+    );\n \n     hosts.ifPresent(h -> Preconditions.checkState(h.size() == tableRows.getRows().size()));\n     final List<StreamedRow> rows = IntStream.range(0, tableRows.getRows().size())\n         .mapToObj(i -> Pair.of(\n             StreamedQueryResource.toGenericRow(tableRows.getRows().get(i)),\n             hosts.map(h -> h.get(i))))\n-        .map(pair -> StreamedRow.row(pair.getLeft(), pair.getRight()))\n+        .map(pair -> StreamedRow.pullRow(pair.getLeft(), pair.getRight()))\n         .collect(Collectors.toList());\n \n     rows.add(0, header);\n \n     final String data = rows.stream()\n-        .map(this::writeValueAsString)\n+        .map(StreamedQueryResource::writeValueAsString)\n         .collect(Collectors.joining(\",\" + System.lineSeparator(), \"[\", \"]\"));\n \n     return EndpointResponse.ok(data);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMDMyOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516210328", "bodyText": "Is there any reason this can't be:\nfinal TableRows tableRows = result.getTableRows();", "author": "AlanConfluent", "createdAt": "2020-11-02T19:38:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -266,9 +277,24 @@ private EndpointResponse handlePullQuery(\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n-    final PullQueryResult result = pullQueryExecutor.execute(\n+    final PullQueryResult result = ksqlEngine.executePullQuery(\n+        serviceContext,\n+        routingFilterFactory,\n+        configured,\n+        requestProperties,\n+        isInternalRequest,\n+        pullQueryMetrics,\n+        rateLimiter);\n+    final TableRows tableRows = new TableRows(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3OTM4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516379383", "bodyText": "The PullQueryResult of the pull physical plan is a different class than the PullQueryResult of PullQueryExecutor. The first doesn't have visibility to TableRows that's why I have to create them in StreamedQueryResource", "author": "vpapavas", "createdAt": "2020-11-03T01:12:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMDMyOA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\nindex 9460ce0045..a8c7d24776 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java\n\n@@ -277,43 +278,71 @@ public class StreamedQueryResource implements KsqlConfigurable {\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n+    final SessionConfig sessionConfig = configured.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        configured.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // A request is considered forwarded if the request has the forwarded flag or if the request\n+    // is from an internal listener.\n+    final boolean isAlreadyForwarded = routingOptions.getIsSkipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      PullQueryExecutionUtil.checkRateLimit(rateLimiter);\n+    }\n+\n     final PullQueryResult result = ksqlEngine.executePullQuery(\n         serviceContext,\n-        routingFilterFactory,\n         configured,\n-        requestProperties,\n-        isInternalRequest,\n-        pullQueryMetrics,\n-        rateLimiter);\n+        routingFilterFactory,\n+        routingOptions,\n+        pullQueryMetrics\n+    );\n     final TableRows tableRows = new TableRows(\n         statement.getStatementText(),\n         result.getQueryId(),\n         result.getSchema(),\n         result.getTableRows());\n \n-\n-    /*final PullQueryResult result = pullQueryExecutor.execute(\n-        configured, requestProperties, serviceContext, isInternalRequest, pullQueryMetrics);\n-    final TableRows tableRows = result.getTableRows();*/\n     final Optional<List<KsqlHostInfoEntity>> hosts = result.getSourceNodes()\n         .map(list -> list.stream().map(KsqlNode::location)\n             .map(location -> new KsqlHostInfoEntity(location.getHost(), location.getPort()))\n             .collect(Collectors.toList()));\n \n-    final StreamedRow header = StreamedRow.header(tableRows.getQueryId(), tableRows.getSchema());\n+    final StreamedRow header = StreamedRow.header(\n+        tableRows.getQueryId(),\n+        tableRows.getSchema()\n+    );\n \n     hosts.ifPresent(h -> Preconditions.checkState(h.size() == tableRows.getRows().size()));\n     final List<StreamedRow> rows = IntStream.range(0, tableRows.getRows().size())\n         .mapToObj(i -> Pair.of(\n             StreamedQueryResource.toGenericRow(tableRows.getRows().get(i)),\n             hosts.map(h -> h.get(i))))\n-        .map(pair -> StreamedRow.row(pair.getLeft(), pair.getRight()))\n+        .map(pair -> StreamedRow.pullRow(pair.getLeft(), pair.getRight()))\n         .collect(Collectors.toList());\n \n     rows.add(0, header);\n \n     final String data = rows.stream()\n-        .map(this::writeValueAsString)\n+        .map(StreamedQueryResource::writeValueAsString)\n         .collect(Collectors.joining(\",\" + System.lineSeparator(), \"[\", \"]\"));\n \n     return EndpointResponse.ok(data);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516213005", "bodyText": "Is this a programming error if this hits?  If so, might want to throw an IllegalStateException or at least log a warning if this can reasonably be ignored?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:43:48Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3MDAwMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516370002", "bodyText": "No, it's not an error. This is just to check that we have reached the leaf of the LogicalPlan and we can stop the translation to physical", "author": "vpapavas", "createdAt": "2020-11-03T00:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzczMTExNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517731117", "bodyText": "I see.  Will the logic while (currentLogicalNode.getSources() != null) { ever be false?  Walking through the code, it looks like it wouldn't be and this is the main exit from the loop.  If so, maybe it makes sense to either make it while (true) so it's obvious this is the way the iteration ends.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxODE2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516218169", "bodyText": "Do we want to assert that dataSourceOperator isn't null before passing it off to the PullPhysicalPlan?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:53:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxOTA5Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516219097", "bodyText": "Can you add some comments to new interfaces just to make it easy to understand for people new to the code?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:55:16Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import java.util.List;\n+\n+public interface DataSourceOperator {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\nindex f130220a70..c463c71bd2 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\n\n@@ -18,6 +18,11 @@ package io.confluent.ksql.physical.pull.operators;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import java.util.List;\n \n+/**\n+ * Represents the leaf operators of physical plans that scan the data sources\n+ * (for example data stores).  The methods allow for dynamically getting/setting the partition\n+ * information that is only available at runtime.\n+ */\n public interface DataSourceOperator {\n \n   List<KsqlPartitionLocation> getPartitionLocations();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516223547", "bodyText": "getWindowBounds is always present if it's windowed, regardless of what the bounds on the window are, right?  This is effectively an isWindowed check.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:04:07Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM2OTE5MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516369191", "bodyText": "If there are no window-bounds in the query, the query is not windowed. So, yes this is a isWindowed check", "author": "vpapavas", "createdAt": "2020-11-03T00:48:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzc3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403774", "bodyText": "in that case, can we create a method in WhereInfo called isWindowed?", "author": "agavra", "createdAt": "2020-11-03T02:57:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNTMzNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516225335", "bodyText": "This wrapping looks a little funny", "author": "AlanConfluent", "createdAt": "2020-11-02T20:07:33Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNTYxNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516225617", "bodyText": "Unnecessary return?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:08:06Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNjYyMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516226621", "bodyText": "Remove comment?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:10:13Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNjkyMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516226921", "bodyText": "Extra line", "author": "AlanConfluent", "createdAt": "2020-11-02T20:10:53Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>\n+    return mapped.values();\n+  }\n+\n+  @Override\n+  public void close() {\n+    child.close();\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {\n+    this.child = child;\n+  }\n+\n+\n+  @Override\n+  public AbstractPhysicalOperator getChild() {\n+    return child;\n+  }\n+\n+  public LogicalSchema getOutputSchema() {\n+    return outputSchema;\n+  }\n+\n+  private void validateProjection(\n+      final GenericRow fullRow,\n+      final LogicalSchema schema\n+  ) {\n+    final int actual = fullRow.size();\n+    final int expected = schema.columns().size();\n+    if (actual != expected) {\n+      throw new IllegalStateException(\"Row column count mismatch.\"\n+                                          + \" expected:\" + expected\n+                                          + \", got:\" + actual\n+      );\n+    }\n+  }\n+\n+  private List<?> createRow(final TableRow row) {\n+    final List<Object> rowList = new ArrayList<>();\n+\n+    keyFields(row.key()).forEach(rowList::add);\n+\n+    row.window().ifPresent(window -> {\n+      rowList.add(window.start().toEpochMilli());\n+      rowList.add(window.end().toEpochMilli());\n+    });\n+\n+    rowList.addAll(row.value().values());\n+\n+    return rowList;\n+  }\n+\n+  private Stream<?> keyFields(final Struct key) {\n+    return key.schema().fields().stream().map(key::get);\n+  }\n+", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516230490", "bodyText": "It's slightly funny to do the real work in open and then just dish out the cached rows on each next.  Since the interface is row oriented, we could also keep track of the key we're on and then do the actual single key lookup on each call to next.  In theory, this allows for \"back pressure\" and avoiding a burst a work since we could do it incrementally and on demand.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:18:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM2NzQyMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516367423", "bodyText": "There are multiple locations and keys, so we need to keep track of both in next and exhaust both iterators. I made the change, lmk how it looks", "author": "vpapavas", "createdAt": "2020-11-03T00:44:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTg2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415866", "bodyText": "+1 to what @AlanConfluent said - it doesn't look like the code has updated to do what Alan is saying?", "author": "agavra", "createdAt": "2020-11-03T03:55:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNTM4Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516425386", "bodyText": "I first commented and then waited for the tests to pass before pushing. Unfortunately, it took longer than expected :(", "author": "vpapavas", "createdAt": "2020-11-03T04:42:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\nindex fb70b0c3b4..cf8fc96495 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n\n@@ -20,7 +20,6 @@ import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartition\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.Row;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n-import java.util.ArrayList;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDg3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516230877", "bodyText": "Throw an exception since this should be a leaf?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:09Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {\n+        final List<Row> rows = mat.nonWindowed()\n+            .get(key, location.getPartition())\n+            .map(ImmutableList::of)\n+            .orElse(ImmutableList.of());\n+        result.addAll(rows);\n+      }\n+    }\n+\n+    resultIterator = result.iterator();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public void close() {\n+\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\nindex fb70b0c3b4..cf8fc96495 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n\n@@ -20,7 +20,6 @@ import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartition\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.Row;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n-import java.util.ArrayList;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMTA3MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516231071", "bodyText": "Similar question as for non windowed.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private List<? extends TableRow> result;\n+  private Iterator<? extends TableRow> resultIterator;\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<WindowedRow> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Window queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\nindex 424f001558..11277a2d9f 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n\n@@ -17,11 +17,9 @@ package io.confluent.ksql.physical.pull.operators;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n-import java.util.ArrayList;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMTE4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516231182", "bodyText": "Throw an exception if this is meant to be a leaf?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:45Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private List<? extends TableRow> result;\n+  private Iterator<? extends TableRow> resultIterator;\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<WindowedRow> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Window queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {\n+        final List<WindowedRow> rows = mat.windowed()\n+            .get(key, location.getPartition(), windowBounds.getStart(), windowBounds.getEnd());\n+        result.addAll(rows);\n+      }\n+    }\n+    resultIterator = result.iterator();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public void close() {\n+\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\nindex 424f001558..11277a2d9f 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n\n@@ -17,11 +17,9 @@ package io.confluent.ksql.physical.pull.operators;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n-import java.util.ArrayList;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDQzMA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516394430", "bodyText": "as discussed with @guozhangwang offline, it would be good if we improved our javadoc around these classes! (same applies to the rest of the PR)", "author": "agavra", "createdAt": "2020-11-03T02:15:38Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516394911", "bodyText": "Optional<Boolean> feels very clunky, and makes me thing that we're mixing together multiple APIs in one. At a minimum, since the values are either true or false, we should require that all callers of this method explicitly handle the optional (either passing true or false) - otherwise we allow callers to be undecided and default to one or the other, which doesn't seem right.\nAlternatively, we might want to consider to methods executePullQuery and executedInternallPullQuery or executedForwardedPullQuery to make the distinction clear", "author": "agavra", "createdAt": "2020-11-03T02:17:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMjQ2OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516432468", "bodyText": "I am not sure I understand why it is clunky but @AlanConfluent wrote this code: Alan do you have any background information here of why this needs to be Optional? Can it be replaced with boolean? I see in ServerVerticle:isInternalRequest that it could just as easily return boolean (true if is internal, false otherwise), right?\n  private static Optional<Boolean> isInternalRequest(final RoutingContext routingContext) {\n    return Optional.ofNullable(routingContext.get(CONTEXT_DATA_IS_INTERNAL));\n  }", "author": "vpapavas", "createdAt": "2020-11-03T05:18:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwNjg3Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517006876", "bodyText": "+1. From the code it seems we can always determine whether the flag is set or not, and there's no scenarios where it is \"undecided\" or \"unknown\".", "author": "guozhangwang", "createdAt": "2020-11-03T23:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcxNjM3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517716379", "bodyText": "In some areas of code, it was necessary to see whether the internal interface was enabled at all.  Effectively, it's a 3 state flag: Internal interface not in use at all, internal interface in use and this request is internal, and internal interface in use and this request is not internal.  If you look at how it's being used in the code it's this:\nfinal boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n          // Trust the forward request option if isInternalRequest isn't available.\n          && isInternalRequest.orElse(true);\n\nSo, if the interface isn't in use, the value defaults to true, not false.  If you want to do this at the calling layer, that's fine.  Also, if this three state thing isn's clear, it could be wrapped in a class that makes it clearer.", "author": "AlanConfluent", "createdAt": "2020-11-05T00:47:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMzEzMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517723132", "bodyText": "that makes sense @AlanConfluent  thanks for the clarification, I think it would be nice to wrap it in an enum representing these three states (or in a class like you suggest) but this can be done in a follow-up (or now, if you're eager!)", "author": "agavra", "createdAt": "2020-11-05T01:10:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516395514", "bodyText": "why are passing in both a ConfiguredStatement and requestProperties? The ConfiguredStatement should contain the requestProperties within it (indirectly via the SessionConfig)", "author": "agavra", "createdAt": "2020-11-03T02:20:31Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMDM3OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516430378", "bodyText": "The SessionConfig contains the overrides not the request properties, right?", "author": "vpapavas", "createdAt": "2020-11-03T05:07:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwMzQxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517703414", "bodyText": "ah yes, you are right.", "author": "agavra", "createdAt": "2020-11-05T00:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516396553", "bodyText": "it seems odd that whomever is calling this method passes in the rateLimiter, it should be up to the engine to decide whether or not a query is rate limited, no? That way, we need to make sure that the same rate limiter is always being passed. If the engine (or whatever the leaf that executes this method call) \"owns\" the rate limiter, we can make sure we don't accidentally bypass this.\nEDIT: I see that @AlanConfluent pointed out something similar here https://github.com/confluentinc/ksql/pull/6375/files#r516208359 - which I think \"proves\" my point that this design isn't safe! If we want to \"bypass\" the rate limiter, then we should be creating a sandbox of the engine context with a new rate limiter.", "author": "agavra", "createdAt": "2020-11-03T02:25:13Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      RateLimiter rateLimiter", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyODU4MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516428581", "bodyText": "I am not sure I am following what you mean.\nThe rateLimiter (after my last changes) is created once in the KsqlRestApplication and then used in StreamedQueryResource and WsQueryEndpoint.  After that, the logic of how it is applied hasn't changed from the PullQueryExecutor: it is used for every pull query. The same rateLimiter is being used for every pull query since it is created once.\nI don't understand what you are saying that the design isn't safe. Alan's comment was about the StreamedQueryResource and WsQueryEndpoint having a different rateLimiter whereas we wanted to limit on their combined pull queries.", "author": "vpapavas", "createdAt": "2020-11-03T04:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwODE2Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517008162", "bodyText": "I also found that maintaining this object at one class while only \"executing\" its logic in another class a bit weird. Generally speaking, if the rate limiter is maintained at the KsqlRestApplication (which indicates we think the rate limiter is per Rest application not per engine) then it can just be applied at that layer rather than passing it through to KsqlEngine and applied at this lower level, unless there's any blockers prevent us from doing so.", "author": "guozhangwang", "createdAt": "2020-11-03T23:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3MDA0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523370044", "bodyText": "I don't think it can be applied at the KsqlRestApplication as we don't know there whether a request is a pull query or not.", "author": "vpapavas", "createdAt": "2020-11-14T03:44:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516397357", "bodyText": "this comment is saying what the code below does, but as someone unfamiliar with the context here I still have no idea why! would be good to rephrase this giving some more context. It's also contradicted with the line below (we don't actually require this?)", "author": "agavra", "createdAt": "2020-11-03T02:29:01Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        statement.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyNDg2Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517024862", "bodyText": "nit: I think maybe renaming the variable as \"doNotForward\" could help readers to understand :) Myself spent some time to realize that we only do forwarding ONCE, so isAlreadyForwarded == WillNotForwardAgain. But the name isAlreadyForwarded does not necessarily indicate so.", "author": "guozhangwang", "createdAt": "2020-11-04T00:01:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM2OTk0NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523369945", "bodyText": "It true that we forward only once but this variable is not used to achieve this. It only checks if the request is a forwarded one or not to apply the rate limiting. So, isAlreadyForwarded == don't apply rate limiting", "author": "vpapavas", "createdAt": "2020-11-14T03:42:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 7b741f27e6..eb9b486593 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -133,70 +120,49 @@ final class EngineExecutor {\n     }\n \n     final QueryPlan queryPlan = plan.getQueryPlan().get();\n-    plan.getDdlCommand().map(ddl -> executeDdl(ddl, plan.getStatementText(), true));\n-    return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n+    plan.getDdlCommand().map(ddl ->\n+        executeDdl(ddl, plan.getStatementText(), true, queryPlan.getSources()));\n+    return ExecuteResult.of(executePersistentQuery(\n+        queryPlan,\n+        plan.getStatementText(),\n+        plan.getDdlCommand().isPresent())\n+    );\n   }\n \n+  /**\n+   * Evaluates a pull query by first analyzing it, then building the logical plan and finally\n+   * the physical plan. The execution is then done using the physical plan in a pipelined manner.\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used for HA routing\n+   * @param routingOptions Configuration parameters used for HA routing\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of evaluating the pull query\n+   */\n   PullQueryResult executePullQuery(\n-      final KsqlExecutionContext ksqlEngine,\n       final ConfiguredStatement<Query> statement,\n       final RoutingFilterFactory routingFilterFactory,\n-      final Map<String, Object> requestProperties,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final RateLimiter rateLimiter\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n       throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n     }\n     final SessionConfig sessionConfig = statement.getSessionConfig();\n-    if (!sessionConfig.getConfig(false)\n-        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n-      throw new KsqlStatementException(\n-          \"Pull queries are disabled.\"\n-              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-              + System.lineSeparator()\n-              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n-              + \"this feature.\"\n-              + System.lineSeparator(),\n-          statement.getStatementText());\n-    }\n-\n-    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n-        sessionConfig.getConfig(false),\n-        statement.getSessionConfig().getOverrides(),\n-        requestProperties\n-    );\n-\n-    // If internal listeners are in use, we require the request to come from that listener to\n-    // treat it as having been forwarded.\n-    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n-        // Trust the forward request option if isInternalRequest isn't available.\n-        && isInternalRequest.orElse(true);\n-\n-    // Only check the rate limit at the forwarding host\n-    if (!isAlreadyForwarded) {\n-      checkRateLimit(rateLimiter);\n-    }\n-\n \n     try {\n       final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n       final ImmutableAnalysis analysis = new RewrittenAnalysis(\n           queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n-          new ColumnReferenceRewriter()::process\n+          new PullQueryExecutionUtil.ColumnReferenceRewriter()::process\n       );\n       final KsqlConfig ksqlConfig = sessionConfig.getConfig(false);\n       final LogicalPlanNode logicalPlan = buildAndValidateLogicalPlan(\n           statement, analysis, ksqlConfig);\n       final PullPhysicalPlan physicalPlan = buildPullPhysicalPlan(\n-          ksqlEngine,\n           logicalPlan,\n           ksqlConfig,\n           analysis,\n-          routingFilterFactory,\n-          routingOptions,\n           statement);\n       final HARouting routing = new HARouting(\n           ksqlConfig, physicalPlan, routingFilterFactory, routingOptions, statement, serviceContext,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTUyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516399529", "bodyText": "passing this into another class is often the sign that we're breaking abstraction barriers. Is there anything inside this class we need that we can just pass in directly?", "author": "agavra", "createdAt": "2020-11-03T02:38:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -250,6 +254,32 @@ public TransientQueryMetadata executeQuery(\n     }\n   }\n \n+  @Override\n+  public PullQueryResult executePullQuery(\n+      final ServiceContext serviceContext,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final ConfiguredStatement<Query> statement,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+    return EngineExecutor\n+        .create(\n+            primaryContext,\n+            serviceContext,\n+            statement.getSessionConfig()\n+        )\n+        .executePullQuery(\n+            this,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg3NzY0MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516877640", "bodyText": "Refactored to not pass this", "author": "vpapavas", "createdAt": "2020-11-03T18:37:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTUyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\nindex dc8ec7bf16..867ca55fa0 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java\n\n@@ -257,12 +265,10 @@ public class KsqlEngine implements KsqlExecutionContext, Closeable {\n   @Override\n   public PullQueryResult executePullQuery(\n       final ServiceContext serviceContext,\n-      final RoutingFilterFactory routingFilterFactory,\n       final ConfiguredStatement<Query> statement,\n-      final Map<String, Object> requestProperties,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final RateLimiter rateLimiter\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   ) {\n     return EngineExecutor\n         .create(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTk5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516399996", "bodyText": "why do we bother passing in the key here? the key is only ever KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING", "author": "agavra", "createdAt": "2020-11-03T02:40:27Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4MjE2NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516882165", "bodyText": "Fixed", "author": "vpapavas", "createdAt": "2020-11-03T18:45:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTk5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nsimilarity index 75%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\nrename to ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nindex 202ba15124..3090395466 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\n\n@@ -13,7 +13,7 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.engine;\n+package io.confluent.ksql.rest.server.resources.streaming;\n \n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.util.KsqlConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDI2MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516400260", "bodyText": "might make sense to javadoc this (especially how it plays together with all the other \"plans\" in ksql)", "author": "agavra", "createdAt": "2020-11-03T02:41:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\nindex af191509bc..fb4b07cc4e 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n\n@@ -17,7 +17,6 @@ package io.confluent.ksql.physical.pull;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n import io.confluent.ksql.query.QueryId;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDk3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516400979", "bodyText": "nit: instead of having mutable state, it's usually easier to reason about code that just passes down the variables (i.e. make these local final and just pass them down into methods that need them). that way we don't need to think about \"what if one of these changes?\"", "author": "agavra", "createdAt": "2020-11-03T02:44:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5MjY2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516892669", "bodyText": "Fixed", "author": "vpapavas", "createdAt": "2020-11-03T19:04:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDk3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMTY0OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516401649", "bodyText": "let's handle this explicitly instead of just a comment :) (e.g. check that the root node is indeed a KsqlBareOutputNode and throw an exception if it's a KsqlStructuredDataOutputNode, which should only be created for C*AS statemetns)", "author": "agavra", "createdAt": "2020-11-03T02:47:58Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjI5NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402294", "bodyText": "going forward, it would be really cool if we could have a PlanNode#getType so that you can implement this as a switch statement. That makes sure that if anyone adds a new type of node it would automatically be covered here", "author": "agavra", "createdAt": "2020-11-03T02:50:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTM0Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039346", "bodyText": "+1 :)", "author": "guozhangwang", "createdAt": "2020-11-04T00:54:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjI5NA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjM4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402383", "bodyText": "let's make this a better exception! What if the user saw this \ud83d\ude40", "author": "agavra", "createdAt": "2020-11-03T02:51:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjY2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402666", "bodyText": "as with above, we should codify this in code. if it has more than one source, let's throw an explicit error instead of failing soft. then we can remove the comment as the code is self-documenting. Imagine we supported join pull queries going forward, it would be much easier to write a test and then just see where it explicitly throws an exception instead of trying to figure out where it silently failed \ud83e\udd2d", "author": "agavra", "createdAt": "2020-11-03T02:52:38Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzA2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403063", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private LogicalSchema buildSchema(\n          \n          \n            \n              private LogicalSchema buildSelectStarSchema(", "author": "agavra", "createdAt": "2020-11-03T02:54:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {\n+      return new KeyedTableLookupOperator(mat, logicalNode);\n+    } else {\n+      return new KeyedWindowedTableLookupOperator(\n+          mat, logicalNode, whereInfo.getWindowBounds().get());\n+    }\n+  }\n+\n+  private PersistentQueryMetadata findMaterializingQuery(\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis\n+  ) {\n+    final MetaStore metaStore = executionContext.getMetaStore();\n+\n+    final SourceName sourceName = getSourceName(analysis);\n+\n+    final Set<String> queries = metaStore.getQueriesWithSink(sourceName);\n+    if (queries.isEmpty()) {\n+      throw notMaterializedException(sourceName);\n+    }\n+    if (queries.size() > 1) {\n+      throw new KsqlException(\n+        \"Multiple queries currently materialize '\" + sourceName + \"'.\"\n+        + \" KSQL currently only supports pull queries when the table has only been\"\n+        + \" materialized once.\");\n+    }\n+\n+    final QueryId queryId = new QueryId(Iterables.get(queries, 0));\n+\n+    final PersistentQueryMetadata query = executionContext\n+        .getPersistentQuery(queryId)\n+        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n+\n+    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n+      throw new KsqlException(\"Pull queries are not supported on streams.\");\n+    }\n+\n+    return query;\n+  }\n+\n+  private SourceName getSourceName(final ImmutableAnalysis analysis) {\n+    final DataSource source = analysis.getFrom().getDataSource();\n+    return source.getName();\n+  }\n+\n+  private KsqlException notMaterializedException(final SourceName sourceTable) {\n+    return new KsqlException(\n+        \"Can't pull from \" + sourceTable + \" as it's not a materialized table.\"\n+            + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+    );\n+  }\n+\n+  private Struct asKeyStruct(final Object keyValue, final PhysicalSchema physicalSchema) {\n+    final ConnectSchema keySchema = ConnectSchemas\n+        .columnsToConnectSchema(physicalSchema.keySchema().columns());\n+\n+    final Field keyField = Iterables.getOnlyElement(keySchema.fields());\n+\n+    final Struct key = new Struct(keySchema);\n+    key.put(keyField, keyValue);\n+    return key;\n+  }\n+\n+  private LogicalSchema selectOutputSchema(\n+      final KsqlExecutionContext executionContext,\n+      final List<SelectExpression> selectExpressions,\n+      final Optional<WindowType> windowType\n+  ) {\n+    final Builder schemaBuilder = LogicalSchema.builder();\n+\n+    // Copy meta & key columns into the value schema as SelectValueMapper expects it:\n+    final LogicalSchema schema = mat.schema()\n+        .withPseudoAndKeyColsInValue(windowType.isPresent());\n+\n+    final ExpressionTypeManager expressionTypeManager =\n+        new ExpressionTypeManager(schema, executionContext.getMetaStore());\n+\n+    for (final SelectExpression select : selectExpressions) {\n+      final SqlType type = expressionTypeManager.getExpressionSqlType(select.getExpression());\n+\n+      if (mat.schema().isKeyColumn(select.getAlias())\n+          || select.getAlias().equals(SystemColumns.WINDOWSTART_NAME)\n+          || select.getAlias().equals(SystemColumns.WINDOWEND_NAME)\n+      ) {\n+        schemaBuilder.keyColumn(select.getAlias(), type);\n+      } else {\n+        schemaBuilder.valueColumn(select.getAlias(), type);\n+      }\n+    }\n+    return schemaBuilder.build();\n+  }\n+\n+  private boolean isSelectStar(final Select select) {\n+    final boolean someStars = select.getSelectItems().stream()\n+        .anyMatch(s -> s instanceof AllColumns);\n+\n+    if (someStars && select.getSelectItems().size() != 1) {\n+      throw new KsqlException(\"Pull queries only support wildcards in the projects \"\n+                                  + \"if they are the only expression\");\n+    }\n+\n+    return someStars;\n+  }\n+\n+  private QueryId uniqueQueryId() {\n+    return new QueryId(\"query_\" + System.currentTimeMillis());\n+  }\n+\n+  private LogicalSchema buildSchema(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403309", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                LogicalSchema outputSchema = null;\n          \n          \n            \n                final LogicalSchema outputSchema = null;", "author": "agavra", "createdAt": "2020-11-03T02:55:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5Nzk4NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516897984", "bodyText": "It can't be final", "author": "vpapavas", "createdAt": "2020-11-03T19:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MDA4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517040083", "bodyText": "I think you can actually: https://stackoverflow.com/questions/46574275/declare-a-final-variable-based-on-a-condition-and-use-it-in-lambda-in-java", "author": "guozhangwang", "createdAt": "2020-11-04T00:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzQ1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403452", "bodyText": "shouldn't building the output schema be part of the logical nodes, not the physical?", "author": "agavra", "createdAt": "2020-11-03T02:55:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5NzQ1Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516897453", "bodyText": "Yes! All this code is going to move to the logical plan with the refactoring I will do after this PR is merged", "author": "vpapavas", "createdAt": "2020-11-03T19:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzQ1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 83f1b21bb5..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMDY3Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516410673", "bodyText": "would be good to have a javadoc for this", "author": "agavra", "createdAt": "2020-11-03T03:30:00Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0Mzc5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043790", "bodyText": "BTW Why declare it as abstract class not interface??", "author": "guozhangwang", "createdAt": "2020-11-04T01:12:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMDY3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\nindex 89a771986f..fcc0bf05b7 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java\n\n@@ -15,6 +15,11 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import java.util.List;\n+\n+/**\n+ * Represents a pipelined physical operator of the physical plan.\n+ */\n public abstract class AbstractPhysicalOperator {\n \n   public abstract void open();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMzY1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516413655", "bodyText": "how are we going to debug this if it happens? should we include information on which node we sent it to? the request? etc...", "author": "agavra", "createdAt": "2020-11-03T03:44:46Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMzcyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516413729", "bodyText": "what could cause this? similarly to the above error, we should include information on the node that we sent to, the request etc... at a minimum, we should log it at the error level if we believe this is 100% our fault (can't be a user error)\nalso, we should probably have something like \"Invalid empty response from forwarding call to {}: Expected a header row\" (reading this code, I wasn't sure why an empty response is invalid - i assumed it meant no response)", "author": "agavra", "createdAt": "2020-11-03T03:45:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNDY4MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516414681", "bodyText": "same as above, let's explain a little more in this error message so that we can debug it if it happens", "author": "agavra", "createdAt": "2020-11-03T03:49:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n+    }\n+\n+    final List<List<?>> rows = new ArrayList<>();\n+\n+    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n+      if (row.getErrorMessage().isPresent()) {\n+        throw new KsqlStatementException(\n+            row.getErrorMessage().get().getMessage(),\n+            statement.getStatementText()\n+        );\n+      }\n+\n+      if (!row.getRow().isPresent()) {\n+        throw new KsqlServerException(\"Unexpected forwarding response\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTEzMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415132", "bodyText": "we should include information on which host each conflicting schema was on so that we can debug it, and it probably makes sense to also print the schemas that differed.\nAlso, what happens if a pull query is issued in the middle of a query upgrade? It's possible that some nodes have the old schema and some have the new schema - the new schema should be backwards compatible with the old one. Out of scope for this PR, but can you create a ticket to track this?", "author": "agavra", "createdAt": "2020-11-03T03:51:33Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n+    }\n+\n+    final List<List<?>> rows = new ArrayList<>();\n+\n+    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n+      if (row.getErrorMessage().isPresent()) {\n+        throw new KsqlStatementException(\n+            row.getErrorMessage().get().getMessage(),\n+            statement.getStatementText()\n+        );\n+      }\n+\n+      if (!row.getRow().isPresent()) {\n+        throw new KsqlServerException(\"Unexpected forwarding response\");\n+      }\n+\n+      rows.add(row.getRow().get().values());\n+    }\n+\n+    return rows;\n+  }\n+\n+  private void validateSchemas(final List<LogicalSchema> schemas) {\n+    final LogicalSchema schema = Iterables.getLast(schemas);\n+    for (LogicalSchema s : schemas) {\n+      if (!schema.equals(s)) {\n+        throw new KsqlException(\"Schemas from different hosts should be identical\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxOTMyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517019326", "bodyText": "Tracked in #6571", "author": "vpapavas", "createdAt": "2020-11-03T23:42:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTEzMg=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTYyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415626", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  for (Struct key : location.getKeys().get()) {\n          \n          \n            \n                  for (final Struct key : location.getKeys().get()) {\n          \n      \n    \n    \n  \n\nDo we have checkstyle off for these classes? this should be failing I think", "author": "agavra", "createdAt": "2020-11-03T03:54:09Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\nindex fb70b0c3b4..cf8fc96495 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n\n@@ -20,7 +20,6 @@ import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartition\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.Row;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n-import java.util.ArrayList;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Objects;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjA5OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416098", "bodyText": "would be nice to javadoc this - especially since it's mutable state. Why can't the locations be passed to the methods that need them?", "author": "agavra", "createdAt": "2020-11-03T03:56:26Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import java.util.List;\n+\n+public interface DataSourceOperator {\n+\n+  List<KsqlPartitionLocation> getPartitionLocations();\n+\n+  void setPartitionLocations(List<KsqlPartitionLocation> partitionLocations);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\nindex f130220a70..c463c71bd2 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java\n\n@@ -18,6 +18,11 @@ package io.confluent.ksql.physical.pull.operators;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import java.util.List;\n \n+/**\n+ * Represents the leaf operators of physical plans that scan the data sources\n+ * (for example data stores).  The methods allow for dynamically getting/setting the partition\n+ * information that is only available at runtime.\n+ */\n public interface DataSourceOperator {\n \n   List<KsqlPartitionLocation> getPartitionLocations();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjcxOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416719", "bodyText": "nit: these comments aren't really helpful", "author": "agavra", "createdAt": "2020-11-03T03:59:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjg0OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416849", "bodyText": "if child is already non-null, should we throw?", "author": "agavra", "createdAt": "2020-11-03T03:59:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>\n+    return mapped.values();\n+  }\n+\n+  @Override\n+  public void close() {\n+    child.close();\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {\n+    this.child = child;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex 8321d0313e..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNzQ0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516417443", "bodyText": "why are we using getLast here? did we intend to use getOnlyElement?", "author": "agavra", "createdAt": "2020-11-03T04:02:42Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java", "diffHunk": "@@ -0,0 +1,542 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.BoundType;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n+import com.google.common.collect.Range;\n+import com.google.common.collect.Sets;\n+import com.google.common.collect.Sets.SetView;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.Literal;\n+import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.NullLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.schema.ksql.Column;\n+import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.utils.FormatOptions;\n+import io.confluent.ksql.util.GrammaticalJoiner;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public final class WhereInfo {\n+\n+  private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n+      Type.EQUAL,\n+      Type.GREATER_THAN,\n+      Type.GREATER_THAN_OR_EQUAL,\n+      Type.LESS_THAN,\n+      Type.LESS_THAN_OR_EQUAL\n+  );\n+\n+  private static final String VALID_WINDOW_BOUNDS_COLUMNS =\n+      GrammaticalJoiner.and().join(SystemColumns.windowBoundsColumnNames());\n+\n+  private static final String VALID_WINDOW_BOUNDS_TYPES_STRING =\n+      GrammaticalJoiner.and().join(VALID_WINDOW_BOUNDS_TYPES);\n+\n+\n+  private final List<Object> keysBound;\n+  private final Optional<WindowBounds> windowBounds;\n+\n+  private WhereInfo(\n+      final List<Object> keysBound,\n+      final Optional<WindowBounds> windowBounds\n+  ) {\n+    this.keysBound = keysBound;\n+    this.windowBounds = Objects.requireNonNull(windowBounds);\n+  }\n+\n+  public static WhereInfo extractWhereInfo(\n+      final ImmutableAnalysis analysis,\n+      final PersistentQueryMetadata query\n+  ) {\n+    final boolean windowed = query.getResultTopic().getKeyFormat().isWindowed();\n+\n+    final Expression where = analysis.getWhereExpression()\n+        .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n+    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n+    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n+    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n+      throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n+    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n+      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n+    }\n+\n+    final List<Object> keys;\n+    if (keyComparison.size() > 0) {\n+      keys = ImmutableList.of(\n+          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n+    } else {\n+      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n+    }\n+\n+    if (!windowed) {\n+      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n+          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n+        throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n+      }\n+\n+      return new WhereInfo(keys, Optional.empty());\n+    }\n+\n+    final WindowBounds windowBounds =\n+        extractWhereClauseWindowBounds(keyAndWindowBounds);\n+\n+    return new WhereInfo(keys, Optional.of(windowBounds));\n+  }\n+\n+  public List<Object> getKeysBound() {\n+    return keysBound;\n+  }\n+\n+  private static List<Object> extractKeysFromInPredicate(\n+      final List<InPredicate> inPredicates,\n+      final boolean windowed,\n+      final LogicalSchema schema\n+  ) {\n+    final InPredicate inPredicate = Iterables.getLast(inPredicates);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\nindex 8725f553a0..4823a3675d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\n\n@@ -55,6 +55,12 @@ import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n \n+/**\n+ * Extracts and validates the conditions in the WHERE clause of a pull query.\n+ * The assumptions are that the conditions must be either a single equality on a key or the IN\n+ * predicate on a list of keys. If the table is windowed, the WHERE clause can have addtionally\n+ * conditions on the window bounds, windowstart and windowend.\n+ */\n public final class WhereInfo {\n \n   private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODI5NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516418294", "bodyText": "uh - shouldn't we be using the result of this? otherwise we're just executing the pull query twice, right? once here and once on line 92?\nalso now that this refactor is done, can we get rid of PullQueryExecutor?", "author": "agavra", "createdAt": "2020-11-03T04:06:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java", "diffHunk": "@@ -42,32 +45,50 @@\n \n class PullQueryPublisher implements Flow.Publisher<Collection<StreamedRow>> {\n \n+  private final KsqlEngine ksqlEngine;\n   private final ServiceContext serviceContext;\n   private final ConfiguredStatement<Query> query;\n   private final PullQueryExecutor pullQueryExecutor;\n   private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n   private final long startTimeNanos;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RateLimiter rateLimiter;\n \n   @VisibleForTesting\n   PullQueryPublisher(\n+      final KsqlEngine ksqlEngine,\n       final ServiceContext serviceContext,\n       final ConfiguredStatement<Query> query,\n       final PullQueryExecutor pullQueryExecutor,\n       final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final long startTimeNanos\n+      final long startTimeNanos,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RateLimiter rateLimiter\n   ) {\n+    this.ksqlEngine = requireNonNull(ksqlEngine, \"ksqlEngine\");\n     this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n     this.query = requireNonNull(query, \"query\");\n     this.pullQueryExecutor = requireNonNull(pullQueryExecutor, \"pullQueryExecutor\");\n     this.pullQueryMetrics = pullQueryMetrics;\n     this.startTimeNanos = startTimeNanos;\n+    this.routingFilterFactory = requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.rateLimiter = requireNonNull(rateLimiter, \"rateLimiter\");\n   }\n \n   @Override\n   public synchronized void subscribe(final Subscriber<Collection<StreamedRow>> subscriber) {\n     final PullQuerySubscription subscription = new PullQuerySubscription(\n         subscriber,\n         () -> {\n+          ksqlEngine.executePullQuery(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMzM0MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516433340", "bodyText": "Yes, I still need to remove all the PullQueryExecutor code. I am leaving it for last because it helps with debugging to verify what the correct behavior should be.", "author": "vpapavas", "createdAt": "2020-11-03T05:22:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODI5NA=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java\nindex 86b2d0284d..799281dad4 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java\n\n@@ -48,7 +49,6 @@ class PullQueryPublisher implements Flow.Publisher<Collection<StreamedRow>> {\n   private final KsqlEngine ksqlEngine;\n   private final ServiceContext serviceContext;\n   private final ConfiguredStatement<Query> query;\n-  private final PullQueryExecutor pullQueryExecutor;\n   private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n   private final long startTimeNanos;\n   private final RoutingFilterFactory routingFilterFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg1MzE1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516853152", "bodyText": "Does anyone know what the code below is doing and why it is needed?", "author": "vpapavas", "createdAt": "2020-11-03T17:54:01Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+            + keyFields.size()\n+            + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMjcxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517722718", "bodyText": "I think because SelectValueMapper is shared with persistent queries and it expects this so it can write errors to the processing topic.  I'm not sure if we really would want that for pull queries or if it's just shoehorned in here because the code is shared.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg1MzE1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\nindex eaa0700680..3baeecbb2d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java\n\n@@ -15,23 +15,19 @@\n \n package io.confluent.ksql.physical.pull.operators;\n \n+import com.google.common.annotations.VisibleForTesting;\n import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n import io.confluent.ksql.execution.streams.materialization.TableRow;\n import io.confluent.ksql.execution.transform.KsqlTransformer;\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.planner.plan.ProjectNode;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n import io.confluent.ksql.util.KsqlConfig;\n import java.util.ArrayList;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwODkzNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517008937", "bodyText": "There are several fields that seem not used: routingFilterFactory, serviceContext, routingOptions. If we plan to only add their usage in other PRs let's just remove them for now in this PR.", "author": "guozhangwang", "createdAt": "2020-11-03T23:10:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 6af97b0dfe..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwOTc3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517009779", "bodyText": "See my other comment: routingFilterFactory is passed but not used.", "author": "guozhangwang", "createdAt": "2020-11-03T23:12:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        statement.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      checkRateLimit(rateLimiter);\n+    }\n+\n+\n+    try {\n+      final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n+      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n+          queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n+          new ColumnReferenceRewriter()::process\n+      );\n+      final KsqlConfig ksqlConfig = sessionConfig.getConfig(false);\n+      final LogicalPlanNode logicalPlan = buildAndValidateLogicalPlan(\n+          statement, analysis, ksqlConfig);\n+      final PullPhysicalPlan physicalPlan = buildPullPhysicalPlan(\n+          ksqlEngine,\n+          logicalPlan,\n+          ksqlConfig,\n+          analysis,\n+          routingFilterFactory,", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 7b741f27e6..eb9b486593 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -133,70 +120,49 @@ final class EngineExecutor {\n     }\n \n     final QueryPlan queryPlan = plan.getQueryPlan().get();\n-    plan.getDdlCommand().map(ddl -> executeDdl(ddl, plan.getStatementText(), true));\n-    return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n+    plan.getDdlCommand().map(ddl ->\n+        executeDdl(ddl, plan.getStatementText(), true, queryPlan.getSources()));\n+    return ExecuteResult.of(executePersistentQuery(\n+        queryPlan,\n+        plan.getStatementText(),\n+        plan.getDdlCommand().isPresent())\n+    );\n   }\n \n+  /**\n+   * Evaluates a pull query by first analyzing it, then building the logical plan and finally\n+   * the physical plan. The execution is then done using the physical plan in a pipelined manner.\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used for HA routing\n+   * @param routingOptions Configuration parameters used for HA routing\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of evaluating the pull query\n+   */\n   PullQueryResult executePullQuery(\n-      final KsqlExecutionContext ksqlEngine,\n       final ConfiguredStatement<Query> statement,\n       final RoutingFilterFactory routingFilterFactory,\n-      final Map<String, Object> requestProperties,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final RateLimiter rateLimiter\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n       throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n     }\n     final SessionConfig sessionConfig = statement.getSessionConfig();\n-    if (!sessionConfig.getConfig(false)\n-        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n-      throw new KsqlStatementException(\n-          \"Pull queries are disabled.\"\n-              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-              + System.lineSeparator()\n-              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n-              + \"this feature.\"\n-              + System.lineSeparator(),\n-          statement.getStatementText());\n-    }\n-\n-    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n-        sessionConfig.getConfig(false),\n-        statement.getSessionConfig().getOverrides(),\n-        requestProperties\n-    );\n-\n-    // If internal listeners are in use, we require the request to come from that listener to\n-    // treat it as having been forwarded.\n-    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n-        // Trust the forward request option if isInternalRequest isn't available.\n-        && isInternalRequest.orElse(true);\n-\n-    // Only check the rate limit at the forwarding host\n-    if (!isAlreadyForwarded) {\n-      checkRateLimit(rateLimiter);\n-    }\n-\n \n     try {\n       final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n       final ImmutableAnalysis analysis = new RewrittenAnalysis(\n           queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n-          new ColumnReferenceRewriter()::process\n+          new PullQueryExecutionUtil.ColumnReferenceRewriter()::process\n       );\n       final KsqlConfig ksqlConfig = sessionConfig.getConfig(false);\n       final LogicalPlanNode logicalPlan = buildAndValidateLogicalPlan(\n           statement, analysis, ksqlConfig);\n       final PullPhysicalPlan physicalPlan = buildPullPhysicalPlan(\n-          ksqlEngine,\n           logicalPlan,\n           ksqlConfig,\n           analysis,\n-          routingFilterFactory,\n-          routingOptions,\n           statement);\n       final HARouting routing = new HARouting(\n           ksqlConfig, physicalPlan, routingFilterFactory, routingOptions, statement, serviceContext,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzI0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517013243", "bodyText": "This is a meta comment: I feel it is a sub-optimal code pattern to pass objects around multiple classes just to trigger their functions at different occasions :) pullQueryMetrics here is an example: we pass it along through many classes, just to trigger its recording functions at processLocal/Remote/Error. I think this class can be created and maintained by a single class and all its triggering can happen at that class. In this example I'm thinking KsqlEngine alone can be the one maintaining this object.", "author": "guozhangwang", "createdAt": "2020-11-03T23:23:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics,", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3ODI0NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523278245", "bodyText": "pullQueryMetrics is actually used in many classes and not only KsqlEngine. The most important one is OldApiUtils where we measures the size of the request/response and the only access to this is through the KsqlRestApplication. The same for the other endpoints where we want to measure latency. The only access point is KsqlRestApplication.", "author": "vpapavas", "createdAt": "2020-11-13T23:07:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzI0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxNTQ4OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517015488", "bodyText": "@agavra @vpapavas for my own education: what part of the query execution logic we put in KsqlEngine and which we put in EngineExecutor? Right now it seems we just use the former as the entry class and directly call the corresponding function (with the same method name) in the latter. Why not just consolidate them into a single class?", "author": "guozhangwang", "createdAt": "2020-11-03T23:30:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\nindex 7b741f27e6..eb9b486593 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java\n\n@@ -133,70 +120,49 @@ final class EngineExecutor {\n     }\n \n     final QueryPlan queryPlan = plan.getQueryPlan().get();\n-    plan.getDdlCommand().map(ddl -> executeDdl(ddl, plan.getStatementText(), true));\n-    return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n+    plan.getDdlCommand().map(ddl ->\n+        executeDdl(ddl, plan.getStatementText(), true, queryPlan.getSources()));\n+    return ExecuteResult.of(executePersistentQuery(\n+        queryPlan,\n+        plan.getStatementText(),\n+        plan.getDdlCommand().isPresent())\n+    );\n   }\n \n+  /**\n+   * Evaluates a pull query by first analyzing it, then building the logical plan and finally\n+   * the physical plan. The execution is then done using the physical plan in a pipelined manner.\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used for HA routing\n+   * @param routingOptions Configuration parameters used for HA routing\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of evaluating the pull query\n+   */\n   PullQueryResult executePullQuery(\n-      final KsqlExecutionContext ksqlEngine,\n       final ConfiguredStatement<Query> statement,\n       final RoutingFilterFactory routingFilterFactory,\n-      final Map<String, Object> requestProperties,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final RateLimiter rateLimiter\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   ) {\n \n     if (!statement.getStatement().isPullQuery()) {\n       throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n     }\n     final SessionConfig sessionConfig = statement.getSessionConfig();\n-    if (!sessionConfig.getConfig(false)\n-        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n-      throw new KsqlStatementException(\n-          \"Pull queries are disabled.\"\n-              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-              + System.lineSeparator()\n-              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n-              + \"this feature.\"\n-              + System.lineSeparator(),\n-          statement.getStatementText());\n-    }\n-\n-    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n-        sessionConfig.getConfig(false),\n-        statement.getSessionConfig().getOverrides(),\n-        requestProperties\n-    );\n-\n-    // If internal listeners are in use, we require the request to come from that listener to\n-    // treat it as having been forwarded.\n-    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n-        // Trust the forward request option if isInternalRequest isn't available.\n-        && isInternalRequest.orElse(true);\n-\n-    // Only check the rate limit at the forwarding host\n-    if (!isAlreadyForwarded) {\n-      checkRateLimit(rateLimiter);\n-    }\n-\n \n     try {\n       final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n       final ImmutableAnalysis analysis = new RewrittenAnalysis(\n           queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n-          new ColumnReferenceRewriter()::process\n+          new PullQueryExecutionUtil.ColumnReferenceRewriter()::process\n       );\n       final KsqlConfig ksqlConfig = sessionConfig.getConfig(false);\n       final LogicalPlanNode logicalPlan = buildAndValidateLogicalPlan(\n           statement, analysis, ksqlConfig);\n       final PullPhysicalPlan physicalPlan = buildPullPhysicalPlan(\n-          ksqlEngine,\n           logicalPlan,\n           ksqlConfig,\n           analysis,\n-          routingFilterFactory,\n-          routingOptions,\n           statement);\n       final HARouting routing = new HARouting(\n           ksqlConfig, physicalPlan, routingFilterFactory, routingOptions, statement, serviceContext,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517029722", "bodyText": "This is another meta thought: when I read the blog post https://www.confluent.io/blog/ksqldb-pull-queries-high-availability/ I thought the \"forwarding\" is not to forward the original query statement to the other server, but to forward the already built physical query plan to the node which we already know host the required partition. But after I digested this piece I realized it was actually the former case.\nI'm wondering if this is a better design, such that we only do query compilation / routing at a single point, which is the server when the request from client is firstly received (say, server A), after server A compiled the query statement it will decide which server to route to (say, server B), then route the compiled physical plan to server B, and server B would blindly execute the query and return results. If an error returned indicating server B is not available any more, the server A would re-determine the routing, and so on.\nThe key point here is that only the single node (the entry server A) would do the compilation and routing, therefore we do not need the isInternalRequest boolean any more.", "author": "guozhangwang", "createdAt": "2020-11-04T00:18:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI1NzUzNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523257536", "bodyText": "Yes, I thought about this as well. It's a tradeoff between sending larger messages (the physical plan vs the query) and computation. If we do want to make this change, this would be part of a larger refactoring, and not part of this PR.\nThe routing already works as you describe, in the sense that server B executes the request locally. If it fails, server A will try another server.", "author": "vpapavas", "createdAt": "2020-11-13T22:02:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3NTg2OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523275868", "bodyText": "Yeah this is totally a meta thing which is not to be addressed in this PR. I left it here just to dump my wild thoughts here for future references.\nRegarding the trade-off, I think with some encoding the number of bytes that we need to transmit between servers with the physical plan would not be orders of magnitude larger (my bold claim, of course :P) but the benefit that only one single server makes the compilation decision to achieve consistent behavior could be huge.", "author": "guozhangwang", "createdAt": "2020-11-13T22:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\nindex 00484b8743..9c6271e194 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java\n\n@@ -126,17 +135,26 @@ public interface KsqlExecutionContext {\n    */\n   TransientQueryMetadata executeQuery(\n       ServiceContext serviceContext,\n-      ConfiguredStatement<Query> statement\n+      ConfiguredStatement<Query> statement,\n+      boolean excludeTombstones\n   );\n \n+  /**\n+   * Executes a pull query by first creating a logical plan and then translating it to a physical\n+   * plan. The physical plan is then traversed for every row in the state store.\n+   * @param serviceContext The service context to execute the query in\n+   * @param statement The pull query\n+   * @param routingFilterFactory The filters used to route requests for HA routing\n+   * @param routingOptions Configuration parameters used for routing requests\n+   * @param pullQueryMetrics JMX metrics\n+   * @return the rows that are the result of the query evaluation.\n+   */\n   PullQueryResult executePullQuery(\n       ServiceContext serviceContext,\n-      RoutingFilterFactory routingFilterFactory,\n       ConfiguredStatement<Query> statement,\n-      Map<String, Object> requestProperties,\n-      Optional<Boolean> isInternalRequest,\n-      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      RateLimiter rateLimiter\n+      RoutingFilterFactory routingFilterFactory,\n+      RoutingOptions routingOptions,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics\n   );\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjAwOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517032008", "bodyText": "It is a bit weird to actually \"execute\" the query in a routeQuery method. Maybe just name it executeOrRouteQuery?\nAlso please see my other comment about the query forwarding: I'd suggest we only forward the the compiled physical query plan to the destination node.", "author": "guozhangwang", "createdAt": "2020-11-04T00:26:54Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517032503", "bodyText": "Why make this function as a synchronous round-trip? Could we do it in a nio, i.e. only send the request, and then allowing the service executor thread to move on to the next partition, and later loop back and check on the socket whether resp is received.", "author": "guozhangwang", "createdAt": "2020-11-04T00:28:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyNDkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517724911", "bodyText": "Currently, we do multiple requests in parallel using the executorService.  We should maybe make this logic use async rather than a threadpool and futures, but it accomplishes the same thing at the moment.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzc4MTA4Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517781086", "bodyText": "Yeah I agree the current code achieves the same thing, but using a threadpool of 100 threads by default could be costly than using a single thread (or at most, we only need one thread per destination socket). Anyways, as I mentioned in the meta comment I feel this is not necessarily the scope of the PR and we can just refactor it later if people agree to the approach.", "author": "guozhangwang", "createdAt": "2020-11-05T04:08:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMzUxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517033514", "bodyText": "About the code structure: I'd suggest we extract the execute-query-if-local out of this class into EngineExecutor directly, and only do forwarding in this class.\nAlso as a follow-up improvement the forwarding can be done in an async way: for each partition that needs forwarding, do that in NIO instead of sync round-trips similar to Kafka: just poll on the socket doing reads and writes when necessary, and then upon completely receiving the resp complete the registered future.", "author": "guozhangwang", "createdAt": "2020-11-04T00:32:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNTU3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517035579", "bodyText": "nit: space after //.", "author": "guozhangwang", "createdAt": "2020-11-04T00:40:36Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 6af97b0dfe..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNjg4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517036883", "bodyText": "The method names are not consistent here: if we want to just want getters, then I'd suggest renaming to getIfSkipForwardRequest and GetIfDebugRequest respectively.", "author": "guozhangwang", "createdAt": "2020-11-04T00:45:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {\n+    if (requestProperties.containsKey(key)) {\n+      return (Boolean) requestProperties.get(key);\n+    }\n+    return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n+  }\n+\n+  public boolean isDebugRequest() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n+      return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n+    }\n+    return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n+  }\n+\n+  @Override\n+  public Set<Integer> getPartitions() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nsimilarity index 75%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\nrename to ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nindex 202ba15124..3090395466 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\n\n@@ -13,7 +13,7 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.engine;\n+package io.confluent.ksql.rest.server.resources.streaming;\n \n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.util.KsqlConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNjk2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517036963", "bodyText": "This name is confusing, better be getMaxOffsetLagAllowed.", "author": "guozhangwang", "createdAt": "2020-11-04T00:45:39Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {\n+    if (requestProperties.containsKey(key)) {\n+      return (Boolean) requestProperties.get(key);\n+    }\n+    return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n+  }\n+\n+  public boolean isDebugRequest() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n+      return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n+    }\n+    return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n+  }\n+\n+  @Override\n+  public Set<Integer> getPartitions() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS)) {\n+      @SuppressWarnings(\"unchecked\")\n+      final List<String> partitions = (List<String>) requestProperties.get(\n+          KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS);\n+      return partitions.stream()\n+          .map(partition -> {\n+            try {\n+              return Integer.parseInt(partition);\n+            } catch (NumberFormatException e) {\n+              throw new IllegalStateException(\"Internal request got a bad partition \"\n+                                                  + partition);\n+            }\n+          }).collect(Collectors.toSet());\n+    }\n+    return Collections.emptySet();\n+  }\n+\n+  @Override\n+  public long getOffsetLagAllowed() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nsimilarity index 75%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\nrename to ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\nindex 202ba15124..3090395466 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryConfigRoutingOptions.java\n\n@@ -13,7 +13,7 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.engine;\n+package io.confluent.ksql.rest.server.resources.streaming;\n \n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.util.KsqlConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzE5OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517037199", "bodyText": "nit: some times we use space after // and some times we do not, better be consistent here. Maybe just always use space?", "author": "guozhangwang", "createdAt": "2020-11-04T00:46:35Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {\n+\n+    //We only know at runtime which partitions to get from which node.", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzODM4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517038382", "bodyText": "Also, just want to point out that in the future the specific host's store capabilities would also be taken into consideration when compiling the pull query, which means we would be able to know locations at compilation time, not only at runtime.", "author": "guozhangwang", "createdAt": "2020-11-04T00:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzE5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\nindex af191509bc..fb4b07cc4e 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n\n@@ -17,7 +17,6 @@ package io.confluent.ksql.physical.pull;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n import io.confluent.ksql.query.QueryId;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzQ2Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517037467", "bodyText": "pullQueryMetrics not used.", "author": "guozhangwang", "createdAt": "2020-11-04T00:47:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\nindex af191509bc..fb4b07cc4e 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n\n@@ -17,7 +17,6 @@ package io.confluent.ksql.physical.pull;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n import io.confluent.ksql.query.QueryId;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTA3Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039073", "bodyText": "This sort of validates my thoughts: the location can be inferred at compilation time since it is part of the plan anyways, as we get them via pullPhysicalPlan.getMaterialization().locator(), we can just put into the routing factory / options as part of the physical plan compilation.", "author": "guozhangwang", "createdAt": "2020-11-04T00:53:43Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {\n+\n+    //We only know at runtime which partitions to get from which node.\n+    //That's why we need to set this explicitly for the dataSource operators\n+    dataSourceOperator.setPartitionLocations(locations);\n+\n+    open();\n+    final List<List<?>> localResult = new ArrayList<>();\n+    List<?> row = null;\n+    while ((row = (List<?>)next()) != null) {\n+      localResult.add(row);\n+    }\n+    close();\n+\n+    return localResult;\n+  }\n+\n+  private void open() {\n+    root.open();\n+  }\n+\n+  private Object next() {\n+    return root.next();\n+  }\n+\n+  private void close() {\n+    root.close();\n+  }\n+\n+  public Materialization getMaterialization() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NTk0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523295944", "bodyText": "I don't understand how figuring out the hosts/partitions can be done at compile time. First we compile the query into a physical plan and then we try to route it. Depending on which node is down, the location changes at runtime.", "author": "vpapavas", "createdAt": "2020-11-14T00:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTA3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\nindex af191509bc..fb4b07cc4e 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n\n@@ -17,7 +17,6 @@ package io.confluent.ksql.physical.pull;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n import io.confluent.ksql.query.QueryId;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTc2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039766", "bodyText": "I'd suggest we declare rootPhysicalOp as currentPhysicalOp , and then at line 156 check that currentPhysicalOp instanceof currentPhysicalOp before assigning, so that we can fail fast.", "author": "guozhangwang", "createdAt": "2020-11-04T00:56:18Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      // For now assume only single source which is the case for pull queries\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    if (dataSourceOperator == null) {\n+      throw new IllegalStateException(\"DataSourceOperator cannot be null in Pull physical plan\");\n+    }\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NDk1OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523294958", "bodyText": "I am not following here. I need a pointer to the root operator of the physical plan.", "author": "vpapavas", "createdAt": "2020-11-14T00:08:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTc2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 6af97b0dfe..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MDczOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517040739", "bodyText": "Could we also include the actual getDataSourceType as well.\nAlso, for other thrown exceptions, I find that we tend to not include some key information into the exception message that may make debugging harder. I'd suggest as a rule of thumb to always include all variable values if they participate in the condition that leads to exception.", "author": "guozhangwang", "createdAt": "2020-11-04T01:00:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      // For now assume only single source which is the case for pull queries\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    if (dataSourceOperator == null) {\n+      throw new IllegalStateException(\"DataSourceOperator cannot be null in Pull physical plan\");\n+    }\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {\n+      return new KeyedTableLookupOperator(mat, logicalNode);\n+    } else {\n+      return new KeyedWindowedTableLookupOperator(\n+          mat, logicalNode, whereInfo.getWindowBounds().get());\n+    }\n+  }\n+\n+  private PersistentQueryMetadata findMaterializingQuery(\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis\n+  ) {\n+    final MetaStore metaStore = executionContext.getMetaStore();\n+\n+    final SourceName sourceName = getSourceName(analysis);\n+\n+    final Set<String> queries = metaStore.getQueriesWithSink(sourceName);\n+    if (queries.isEmpty()) {\n+      throw notMaterializedException(sourceName);\n+    }\n+    if (queries.size() > 1) {\n+      throw new KsqlException(\n+        \"Multiple queries currently materialize '\" + sourceName + \"'.\"\n+        + \" KSQL currently only supports pull queries when the table has only been\"\n+        + \" materialized once.\");\n+    }\n+\n+    final QueryId queryId = new QueryId(Iterables.get(queries, 0));\n+\n+    final PersistentQueryMetadata query = executionContext\n+        .getPersistentQuery(queryId)\n+        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n+\n+    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n+      throw new KsqlException(\"Pull queries are not supported on streams.\");", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 6af97b0dfe..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MjY5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517042690", "bodyText": "Javadoc for this class regarding 1) what metadata it contains, 2) what assumption it makes (e.g.  what root operator should be`) would be highly appreciated :)", "author": "guozhangwang", "createdAt": "2020-11-04T01:08:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\nindex af191509bc..fb4b07cc4e 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java\n\n@@ -17,7 +17,6 @@ package io.confluent.ksql.physical.pull;\n \n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n import io.confluent.ksql.query.QueryId;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MzEwMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043103", "bodyText": "Javadoc for this class regarding the common pattern of the generated physical plan (e.g. should it always be a scan -> filter), what validation it does, what metadata (e.g. materialization) it relies on would be highly appreciated :)", "author": "guozhangwang", "createdAt": "2020-11-04T01:10:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NjY0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523296641", "bodyText": "The metadata/validation information is going to change with the next PR so I'd rather add it when the code is done. I don't want to end up with wrong javadocs.", "author": "vpapavas", "createdAt": "2020-11-14T00:15:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MzEwMw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\nindex 6af97b0dfe..19cff1ae61 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java\n\n@@ -17,18 +17,18 @@ package io.confluent.ksql.physical.pull;\n \n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n-import io.confluent.ksql.KsqlExecutionContext;\n import io.confluent.ksql.analyzer.ImmutableAnalysis;\n import io.confluent.ksql.analyzer.PullQueryValidator;\n import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Materialization;\n import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.logging.processing.ProcessingLogContext;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n import io.confluent.ksql.metastore.MetaStore;\n import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n import io.confluent.ksql.model.WindowType;\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.parser.tree.AllColumns;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0Mzk4OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043989", "bodyText": "Javadocs regarding which metadata it wraps in is appreciated.", "author": "guozhangwang", "createdAt": "2020-11-04T01:13:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java", "diffHunk": "@@ -0,0 +1,542 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.BoundType;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n+import com.google.common.collect.Range;\n+import com.google.common.collect.Sets;\n+import com.google.common.collect.Sets.SetView;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.Literal;\n+import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.NullLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.schema.ksql.Column;\n+import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.utils.FormatOptions;\n+import io.confluent.ksql.util.GrammaticalJoiner;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public final class WhereInfo {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\nindex 8725f553a0..4823a3675d 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java\n\n@@ -55,6 +55,12 @@ import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n \n+/**\n+ * Extracts and validates the conditions in the WHERE clause of a pull query.\n+ * The assumptions are that the conditions must be either a single equality on a key or the IN\n+ * predicate on a list of keys. If the table is windowed, the WHERE clause can have addtionally\n+ * conditions on the window bounds, windowstart and windowend.\n+ */\n public final class WhereInfo {\n \n   private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcxOTc3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517719774", "bodyText": "I think much of PullQueryExecutor.UnitTests tests this.  It would be good to create a HARoutingTest with that logic.", "author": "AlanConfluent", "createdAt": "2020-11-05T00:58:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nsimilarity index 76%\nrename from ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\nrename to ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\nindex 83f17e672a..50e6993260 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/HARouting.java\n\n@@ -13,12 +13,11 @@\n  * specific language governing permissions and limitations under the License.\n  */\n \n-package io.confluent.ksql.physical.pull.operators;\n+package io.confluent.ksql.physical.pull;\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Iterables;\n import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n import io.confluent.ksql.execution.streams.RoutingOptions;\n import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517721287", "bodyText": "What if resultIterator.hasNext() is false, but keyIterator.hasNext() is true?  You would return null below when there might be more.  It seems like you could recursively call next() after setting up the nextKey and resultIterator.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:03:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,137 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<WindowedRow> resultIterator;\n+  private Iterator<Struct> keyIterator;\n+  private Iterator<KsqlPartitionLocation> partitionLocationIterator;\n+  private KsqlPartitionLocation nextLocation;\n+  private Struct nextKey;\n+\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    partitionLocationIterator = partitionLocations.iterator();\n+    if (partitionLocationIterator.hasNext()) {\n+      nextLocation = partitionLocationIterator.next();\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table windowed queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+      if (keyIterator.hasNext()) {\n+        nextKey = keyIterator.next();\n+        resultIterator = mat.windowed().get(\n+            nextKey,\n+            nextLocation.getPartition(),\n+            windowBounds.getStart(),\n+            windowBounds.getEnd())\n+            .iterator();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    // Exhausted resultIterator\n+    if (!keyIterator.hasNext()) {\n+      if (partitionLocationIterator.hasNext()) {\n+        nextLocation = partitionLocationIterator.next();\n+      } else {\n+        // Exhausted all iterators\n+        return null;\n+      }\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+    }\n+    nextKey = keyIterator.next();\n+    resultIterator = mat.windowed().get(\n+        nextKey,\n+        nextLocation.getPartition(),\n+        windowBounds.getStart(),\n+        windowBounds.getEnd())\n+        .iterator();\n+    if (resultIterator.hasNext()) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwMDU0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523300544", "bodyText": "resultIterator.hasNext() is false, but keyIterator.hasNext() is true it will go to line 91 and get the next keyIterator keyIterator.next(). Am I missing something?", "author": "vpapavas", "createdAt": "2020-11-14T00:34:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0NDYyNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524544624", "bodyText": "If you were to call this.next() again, it would do what you're saying and see that there are more keys, but from what I can see, it doesn't do that by default (and hence my recursive comment).\nSpecifically, imagine you're looking up two keys, 1 and 2.  If you do resultIterator = mat.windowed().get( .. for 1 and get nothing, resultIterator.hasNext() will be false, and you'll fall through to return null below.\nI guess maybe that's the correct if you want to return nulls for empty lookups, but then you have to do a null check with the caller.  I was effectively imagining that you would just continue on to the next non empty iterator.", "author": "AlanConfluent", "createdAt": "2020-11-16T20:14:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\nindex a7c4b621a5..11277a2d9f 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java\n\n@@ -124,6 +124,16 @@ public class KeyedWindowedTableLookupOperator\n     return null;\n   }\n \n+  @Override\n+  public AbstractPhysicalOperator getChild(final int index) {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public List<AbstractPhysicalOperator> getChildren() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n   @Override\n   public List<KsqlPartitionLocation> getPartitionLocations() {\n     return partitionLocations;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTQ1Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517721456", "bodyText": "This has the same issue as in KeyedWindowedTableLookupOperator", "author": "AlanConfluent", "createdAt": "2020-11-05T01:04:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+  private Iterator<Struct> keyIterator;\n+  private Iterator<KsqlPartitionLocation> partitionLocationIterator;\n+  private KsqlPartitionLocation nextLocation;\n+  private Struct nextKey;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    partitionLocationIterator = partitionLocations.iterator();\n+    if (partitionLocationIterator.hasNext()) {\n+      nextLocation = partitionLocationIterator.next();\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+      if (keyIterator.hasNext()) {\n+        nextKey = keyIterator.next();\n+        resultIterator = mat.nonWindowed()\n+            .get(nextKey, nextLocation.getPartition())\n+            .map(ImmutableList::of)\n+            .orElse(ImmutableList.of()).iterator();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    // Exhausted resultIterator\n+    if (!keyIterator.hasNext()) {\n+      if (partitionLocationIterator.hasNext()) {\n+        nextLocation = partitionLocationIterator.next();\n+      } else {\n+        // Exhausted all iterators\n+        return null;\n+      }\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+    }\n+    nextKey = keyIterator.next();\n+    resultIterator = mat.nonWindowed()\n+        .get(nextKey, nextLocation.getPartition())\n+        .map(ImmutableList::of)\n+        .orElse(ImmutableList.of()).iterator();\n+    if (resultIterator.hasNext()) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\nindex a04193f88d..cf8fc96495 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java\n\n@@ -47,8 +47,8 @@ public class KeyedTableLookupOperator\n       final Materialization mat,\n       final DataSourceNode logicalNode\n   ) {\n-    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n     this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyNjM3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517726377", "bodyText": "Do you want to delete this file and it's test file?  (Of couse, it would be great to migrate all of those tests to their updated places).", "author": "AlanConfluent", "createdAt": "2020-11-05T01:21:29Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -65,6 +65,7 @@\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\ndeleted file mode 100644\nindex abc4ddf47c..0000000000\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ /dev/null\n\n@@ -1,1398 +0,0 @@\n-/*\n- * Copyright 2019 Confluent Inc.\n- *\n- * Licensed under the Confluent Community License (the \"License\"); you may not use\n- * this file except in compliance with the License.  You may obtain a copy of the\n- * License at\n- *\n- * http://www.confluent.io/confluent-community-license\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n- * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations under the License.\n- */\n-\n-package io.confluent.ksql.rest.server.execution;\n-\n-import static java.util.Objects.requireNonNull;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.collect.BoundType;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.ImmutableSet;\n-import com.google.common.collect.Iterables;\n-import com.google.common.collect.Range;\n-import com.google.common.collect.Sets;\n-import com.google.common.collect.Sets.SetView;\n-import com.google.common.util.concurrent.RateLimiter;\n-import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.analyzer.PullQueryValidator;\n-import io.confluent.ksql.analyzer.QueryAnalyzer;\n-import io.confluent.ksql.analyzer.RewrittenAnalysis;\n-import io.confluent.ksql.config.SessionConfig;\n-import io.confluent.ksql.engine.rewrite.ExpressionTreeRewriter.Context;\n-import io.confluent.ksql.execution.context.QueryContext;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n-import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n-import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n-import io.confluent.ksql.execution.expression.tree.Expression;\n-import io.confluent.ksql.execution.expression.tree.InPredicate;\n-import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n-import io.confluent.ksql.execution.expression.tree.Literal;\n-import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n-import io.confluent.ksql.execution.expression.tree.LongLiteral;\n-import io.confluent.ksql.execution.expression.tree.NullLiteral;\n-import io.confluent.ksql.execution.expression.tree.QualifiedColumnReferenceExp;\n-import io.confluent.ksql.execution.expression.tree.StringLiteral;\n-import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n-import io.confluent.ksql.execution.expression.tree.VisitParentExpressionVisitor;\n-import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n-import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n-import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n-import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n-import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n-import io.confluent.ksql.execution.streams.materialization.TableRow;\n-import io.confluent.ksql.execution.transform.KsqlTransformer;\n-import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n-import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n-import io.confluent.ksql.execution.util.ExpressionTypeManager;\n-import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n-import io.confluent.ksql.logging.processing.ProcessingLogger;\n-import io.confluent.ksql.metastore.MetaStore;\n-import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n-import io.confluent.ksql.model.WindowType;\n-import io.confluent.ksql.name.ColumnName;\n-import io.confluent.ksql.name.SourceName;\n-import io.confluent.ksql.parser.tree.AllColumns;\n-import io.confluent.ksql.parser.tree.Query;\n-import io.confluent.ksql.parser.tree.Select;\n-import io.confluent.ksql.parser.tree.SingleColumn;\n-import io.confluent.ksql.query.QueryId;\n-import io.confluent.ksql.rest.Errors;\n-import io.confluent.ksql.rest.SessionProperties;\n-import io.confluent.ksql.rest.client.RestResponse;\n-import io.confluent.ksql.rest.entity.StreamedRow;\n-import io.confluent.ksql.rest.entity.StreamedRow.Header;\n-import io.confluent.ksql.rest.entity.TableRows;\n-import io.confluent.ksql.rest.entity.TableRowsFactory;\n-import io.confluent.ksql.rest.server.resources.KsqlRestException;\n-import io.confluent.ksql.schema.ksql.Column;\n-import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n-import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n-import io.confluent.ksql.schema.ksql.PhysicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n-import io.confluent.ksql.schema.ksql.types.SqlType;\n-import io.confluent.ksql.schema.utils.FormatOptions;\n-import io.confluent.ksql.serde.connect.ConnectSchemas;\n-import io.confluent.ksql.services.ServiceContext;\n-import io.confluent.ksql.statement.ConfiguredStatement;\n-import io.confluent.ksql.util.GrammaticalJoiner;\n-import io.confluent.ksql.util.KsqlConfig;\n-import io.confluent.ksql.util.KsqlException;\n-import io.confluent.ksql.util.KsqlRequestConfig;\n-import io.confluent.ksql.util.KsqlServerException;\n-import io.confluent.ksql.util.KsqlStatementException;\n-import io.confluent.ksql.util.PersistentQueryMetadata;\n-import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n-import java.time.Duration;\n-import java.time.Instant;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.LinkedHashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.Objects;\n-import java.util.Optional;\n-import java.util.Set;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.TimeUnit;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n-import org.apache.kafka.connect.data.ConnectSchema;\n-import org.apache.kafka.connect.data.Field;\n-import org.apache.kafka.connect.data.Struct;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n-@SuppressWarnings(\"UnstableApiUsage\")\n-public final class PullQueryExecutor {\n-  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n-\n-  private static final Logger LOG = LoggerFactory.getLogger(PullQueryExecutor.class);\n-\n-  private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n-      Type.EQUAL,\n-      Type.GREATER_THAN,\n-      Type.GREATER_THAN_OR_EQUAL,\n-      Type.LESS_THAN,\n-      Type.LESS_THAN_OR_EQUAL\n-  );\n-\n-  private static final String VALID_WINDOW_BOUNDS_COLUMNS =\n-      GrammaticalJoiner.and().join(SystemColumns.windowBoundsColumnNames());\n-\n-  private static final String VALID_WINDOW_BOUNDS_TYPES_STRING =\n-      GrammaticalJoiner.and().join(VALID_WINDOW_BOUNDS_TYPES);\n-\n-  private final KsqlExecutionContext executionContext;\n-  private final RoutingFilterFactory routingFilterFactory;\n-  private final RateLimiter rateLimiter;\n-  private final ExecutorService executorService;\n-\n-  public PullQueryExecutor(\n-      final KsqlExecutionContext executionContext,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final KsqlConfig ksqlConfig\n-  ) {\n-    this(\n-        executionContext,\n-        routingFilterFactory,\n-        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG),\n-        Executors.newFixedThreadPool(\n-            ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n-        )\n-    );\n-  }\n-\n-  @VisibleForTesting\n-  PullQueryExecutor(\n-      final KsqlExecutionContext executionContext,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final int maxQps, final ExecutorService executorService\n-  ) {\n-    this.executionContext = requireNonNull(executionContext, \"executionContext\");\n-    this.routingFilterFactory = requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n-    this.rateLimiter = RateLimiter.create(maxQps);\n-    this.executorService = requireNonNull(executorService, \"executorService\");\n-  }\n-\n-  @SuppressWarnings(\"unused\") // Needs to match validator API.\n-  public static void validate(\n-      final ConfiguredStatement<Query> statement,\n-      final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n-  ) {\n-    throw new KsqlRestException(Errors.queryEndpoint(statement.getStatementText()));\n-  }\n-\n-  public PullQueryResult execute(\n-      final ConfiguredStatement<Query> statement,\n-      final Map<String, Object> requestProperties,\n-      final ServiceContext serviceContext,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n-  ) {\n-    if (!statement.getStatement().isPullQuery()) {\n-      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n-    }\n-\n-    final SessionConfig sessionConfig = statement.getSessionConfig();\n-\n-    if (!sessionConfig.getConfig(false)\n-        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n-      throw new KsqlStatementException(\n-          \"Pull queries are disabled.\"\n-              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-              + System.lineSeparator()\n-              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n-              + \"this feature.\",\n-          statement.getStatementText());\n-    }\n-\n-    try {\n-      // Not using session.getConfig(true) due to performance issues,\n-      // see: https://github.com/confluentinc/ksql/issues/6407\n-      final RoutingOptions routingOptions = new ConfigRoutingOptions(\n-          sessionConfig.getConfig(false),\n-          statement.getSessionConfig().getOverrides(),\n-          requestProperties\n-      );\n-\n-      // If internal listeners are in use, we require the request to come from that listener to\n-      // treat it as having been forwarded.\n-      final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n-          // Trust the forward request option if isInternalRequest isn't available.\n-          && isInternalRequest.orElse(true);\n-\n-      // Only check the rate limit at the forwarding host\n-      if (!isAlreadyForwarded) {\n-        checkRateLimit();\n-      }\n-\n-      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n-          analyze(statement, executionContext),\n-          new ColumnReferenceRewriter()::process\n-      );\n-\n-      final PersistentQueryMetadata query = findMaterializingQuery(executionContext, analysis);\n-\n-      final WhereInfo whereInfo = extractWhereInfo(analysis, query);\n-\n-      final QueryId queryId = uniqueQueryId();\n-\n-      final QueryContext.Stacker contextStacker = new Stacker();\n-\n-      final Materialization mat = query\n-          .getMaterialization(queryId, contextStacker)\n-          .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n-\n-      final List<Struct> keys = whereInfo.keysBound.stream()\n-          .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-          .collect(ImmutableList.toImmutableList());\n-\n-      final List<KsqlPartitionLocation> locations = mat.locator().locate(\n-          keys,\n-          routingOptions,\n-          routingFilterFactory\n-      );\n-\n-      final Function<List<KsqlPartitionLocation>, PullQueryContext> contextFactory\n-          = (locationsForHost) ->\n-          new PullQueryContext(\n-              locationsForHost,\n-              mat,\n-              analysis,\n-              whereInfo,\n-              queryId,\n-              contextStacker,\n-              pullQueryMetrics);\n-\n-      return handlePullQuery(\n-          statement,\n-          executionContext,\n-          serviceContext,\n-          routingOptions,\n-          contextFactory,\n-          queryId,\n-          locations,\n-          executorService,\n-          PullQueryExecutor::routeQuery);\n-\n-    } catch (final Exception e) {\n-      pullQueryMetrics.ifPresent(metrics -> metrics.recordErrorRate(1));\n-      throw new KsqlStatementException(\n-          e.getMessage() == null ? \"Server Error\" : e.getMessage(),\n-          statement.getStatementText(),\n-          e\n-      );\n-    }\n-  }\n-\n-  public void close(final Duration timeout) {\n-    try {\n-      executorService.shutdown();\n-      executorService.awaitTermination(timeout.toMillis(), TimeUnit.MILLISECONDS);\n-    } catch (final InterruptedException e) {\n-      Thread.currentThread().interrupt();\n-    }\n-  }\n-\n-  private static void validateSchemas(final List<LogicalSchema> schemas) {\n-    final LogicalSchema schema = Iterables.getLast(schemas);\n-    for (LogicalSchema s : schemas) {\n-      if (!schema.equals(s)) {\n-        throw new KsqlException(\"Schemas from different hosts should be identical\");\n-      }\n-    }\n-  }\n-\n-  @VisibleForTesting\n-  void checkRateLimit() {\n-    if (!rateLimiter.tryAcquire()) {\n-      throw new KsqlException(\"Host is at rate limit for pull queries. Currently set to \"\n-          + rateLimiter.getRate() + \" qps.\");\n-    }\n-  }\n-\n-  @VisibleForTesting\n-  interface RouteQuery {\n-    TableRows routeQuery(\n-        KsqlNode node,\n-        ConfiguredStatement<Query> statement,\n-        KsqlExecutionContext executionContext,\n-        ServiceContext serviceContext,\n-        PullQueryContext pullQueryContext\n-    );\n-  }\n-\n-  @VisibleForTesting\n-  static PullQueryResult handlePullQuery(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext,\n-      final RoutingOptions routingOptions,\n-      final Function<List<KsqlPartitionLocation>, PullQueryContext> contextFactory,\n-      final QueryId queryId,\n-      final List<KsqlPartitionLocation> locations,\n-      final ExecutorService executorService,\n-      final RouteQuery routeQuery\n-  ) throws InterruptedException {\n-    final boolean anyPartitionsEmpty = locations.stream()\n-        .anyMatch(location -> location.getNodes().isEmpty());\n-    if (anyPartitionsEmpty) {\n-      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-          statement.getStatementText());\n-      throw new MaterializationException(String.format(\n-          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n-          statement.getStatementText()));\n-    }\n-\n-    // The source nodes associated with each of the rows\n-    final List<KsqlNode> sourceNodes = new ArrayList<>();\n-    // Each of the table rows returned, aggregated across nodes\n-    final List<List<?>> tableRows = new ArrayList<>();\n-    // Each of the schemas returned, aggregated across nodes\n-    final List<LogicalSchema> schemas = new ArrayList<>();\n-    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n-    // For each round, each set of partition location objects is grouped by host, and all\n-    // keys associated with that host are batched together. For any requests that fail,\n-    // the partition location objects will be added to remainingLocations, and the next round\n-    // will attempt to fetch them from the next node in their prioritized list.\n-    // For example, locations might be:\n-    // [ Partition 0 <Host 1, Host 2>,\n-    //   Partition 1 <Host 2, Host 1>,\n-    //   Partition 2 <Host 1, Host 2> ]\n-    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n-    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n-    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n-    for (int round = 0; ; round++) {\n-      // Group all partition location objects by their nth round node\n-      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n-          = groupByHost(statement, remainingLocations, round);\n-\n-      // Make requests to each host, specifying the partitions we're interested in from\n-      // this host.\n-      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n-      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n-        final KsqlNode node = entry.getKey();\n-        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n-\n-        futures.put(node, executorService.submit(() ->  {\n-          final TableRows rows = routeQuery.routeQuery(\n-              node, statement, executionContext, serviceContext, pullQueryContext);\n-          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n-              routingOptions.isDebugRequest()\n-                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n-          return new PullQueryResult(rows, debugNodes);\n-        }));\n-      }\n-\n-      // Go through all of the results of the requests, either aggregating rows or adding\n-      // the locations to the nextRoundRemaining list.\n-      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n-          = ImmutableList.builder();\n-      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n-        final Future<PullQueryResult> future = entry.getValue();\n-        final KsqlNode node = entry.getKey();\n-        try {\n-          final PullQueryResult result = future.get();\n-          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n-          schemas.add(result.getTableRows().getSchema());\n-          tableRows.addAll(result.getTableRows().getRows());\n-        } catch (ExecutionException e) {\n-          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n-          nextRoundRemaining.addAll(groupedByHost.get(node));\n-        }\n-      }\n-      remainingLocations = nextRoundRemaining.build();\n-\n-      // If there are no partition locations remaining, then we're done.\n-      if (remainingLocations.size() == 0) {\n-        validateSchemas(schemas);\n-        return new PullQueryResult(\n-            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n-                tableRows),\n-            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Groups all of the partition locations by the round-th entry in their prioritized list\n-   * of host nodes.\n-   * @param statement the statement from which this request came\n-   * @param locations the list of partition locations to parse\n-   * @param round which round this is\n-   * @return A map of node to list of partition locations\n-   */\n-  private static Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n-      final ConfiguredStatement<Query> statement,\n-      final List<KsqlPartitionLocation> locations,\n-      final int round) {\n-    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n-    for (KsqlPartitionLocation location : locations) {\n-      // If one of the partitions required is out of nodes, then we cannot continue.\n-      if (round >= location.getNodes().size()) {\n-        throw new MaterializationException(String.format(\n-            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n-            statement.getStatementText()));\n-      }\n-      final KsqlNode nextHost = location.getNodes().get(round);\n-      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n-    }\n-    return groupedByHost;\n-  }\n-\n-  private static TableRows routeQuery(\n-      final KsqlNode node,\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    if (node.isLocal()) {\n-      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n-               statement.getStatementText(), node.location(), System.currentTimeMillis());\n-      pullQueryContext.pullQueryMetrics\n-          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n-      return queryRowsLocally(\n-          statement,\n-          executionContext,\n-          pullQueryContext);\n-    } else {\n-      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n-                statement.getStatementText(), node.location(), System.currentTimeMillis());\n-      pullQueryContext.pullQueryMetrics\n-          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n-      return forwardTo(node, statement, serviceContext, pullQueryContext);\n-    }\n-  }\n-\n-  private static TableRows queryRowsLocally(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    final Result result;\n-    if (pullQueryContext.whereInfo.windowBounds.isPresent()) {\n-      final WindowBounds windowBounds = pullQueryContext.whereInfo.windowBounds.get();\n-\n-      final ImmutableList.Builder<TableRow> allRows = ImmutableList.builder();\n-      for (KsqlPartitionLocation location : pullQueryContext.locations) {\n-        if (!location.getKeys().isPresent()) {\n-          throw new IllegalStateException(\"Window queries should be done with keys\");\n-        }\n-        for (Struct key : location.getKeys().get()) {\n-          final List<? extends TableRow> rows = pullQueryContext.mat.windowed()\n-              .get(key, location.getPartition(), windowBounds.start,\n-                  windowBounds.end);\n-          allRows.addAll(rows);\n-        }\n-      }\n-      result = new Result(pullQueryContext.mat.schema(), allRows.build());\n-    } else {\n-      final ImmutableList.Builder<TableRow> allRows = ImmutableList.builder();\n-      for (KsqlPartitionLocation location : pullQueryContext.locations) {\n-        if (!location.getKeys().isPresent()) {\n-          throw new IllegalStateException(\"Window queries should be done with keys\");\n-        }\n-        for (Struct key : location.getKeys().get()) {\n-          final List<? extends TableRow> rows = pullQueryContext.mat.nonWindowed()\n-              .get(key, location.getPartition())\n-              .map(ImmutableList::of)\n-              .orElse(ImmutableList.of());\n-          allRows.addAll(rows);\n-        }\n-      }\n-      result = new Result(pullQueryContext.mat.schema(), allRows.build());\n-    }\n-\n-    final LogicalSchema outputSchema;\n-    final List<List<?>> rows;\n-    if (isSelectStar(statement.getStatement().getSelect())) {\n-      outputSchema = TableRowsFactory.buildSchema(\n-          result.schema, pullQueryContext.mat.windowType().isPresent());\n-      rows = TableRowsFactory.createRows(result.rows);\n-    } else {\n-      final List<SelectExpression> projection = pullQueryContext.analysis.getSelectItems().stream()\n-          .map(SingleColumn.class::cast)\n-          .map(si -> SelectExpression\n-              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n-          .collect(Collectors.toList());\n-\n-      outputSchema = selectOutputSchema(\n-          result, executionContext, projection, pullQueryContext.mat.windowType());\n-\n-      rows = handleSelects(\n-          result,\n-          statement,\n-          executionContext,\n-          pullQueryContext.analysis,\n-          outputSchema,\n-          projection,\n-          pullQueryContext.mat.windowType(),\n-          pullQueryContext.queryId,\n-          pullQueryContext.contextStacker\n-      );\n-    }\n-    return new TableRows(\n-        statement.getStatementText(),\n-        pullQueryContext.queryId,\n-        outputSchema,\n-        rows\n-    );\n-  }\n-\n-  private static TableRows forwardTo(\n-      final KsqlNode owner,\n-      final ConfiguredStatement<Query> statement,\n-      final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n-    // standby data when we are reading active for example.\n-    final String partitions = pullQueryContext.locations.stream()\n-        .map(location -> Integer.toString(location.getPartition()))\n-        .collect(Collectors.joining(\",\"));\n-    // Add skip forward flag to properties\n-    final Map<String, Object> requestProperties = ImmutableMap.of(\n-        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n-        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n-        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n-    final RestResponse<List<StreamedRow>> response = serviceContext\n-        .getKsqlClient()\n-        .makeQueryRequest(\n-            owner.location(),\n-            statement.getStatementText(),\n-            statement.getSessionConfig().getOverrides(),\n-            requestProperties\n-        );\n-\n-    if (response.isErroneous()) {\n-      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n-    }\n-\n-    final List<StreamedRow> streamedRows = response.getResponse();\n-    if (streamedRows.isEmpty()) {\n-      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n-    }\n-\n-    final Header header = streamedRows.get(0).getHeader()\n-        .orElseThrow(() -> new KsqlServerException(\"Expected header in first row\"));\n-\n-    final ImmutableList.Builder<List<?>> rows = ImmutableList.builder();\n-\n-    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n-      if (row.getErrorMessage().isPresent()) {\n-        throw new KsqlStatementException(\n-            row.getErrorMessage().get().getMessage(),\n-            statement.getStatementText()\n-        );\n-      }\n-\n-      if (!row.getRow().isPresent()) {\n-        throw new KsqlServerException(\"Unexpected forwarding response\");\n-      }\n-\n-      rows.add(row.getRow().get().values());\n-    }\n-\n-    return new TableRows(\n-        statement.getStatementText(),\n-        header.getQueryId(),\n-        header.getSchema(),\n-        rows.build()\n-    );\n-  }\n-\n-  private static QueryId uniqueQueryId() {\n-    return new QueryId(\"query_\" + System.currentTimeMillis());\n-  }\n-\n-  private static ImmutableAnalysis analyze(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext\n-  ) {\n-    final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(executionContext.getMetaStore(), \"\");\n-\n-    return queryAnalyzer.analyze(statement.getStatement(), Optional.empty());\n-  }\n-\n-  static final class PullQueryContext {\n-\n-    private final List<KsqlPartitionLocation> locations;\n-    private final Materialization mat;\n-    private final ImmutableAnalysis analysis;\n-    private final WhereInfo whereInfo;\n-    private final QueryId queryId;\n-    private final QueryContext.Stacker contextStacker;\n-    private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n-\n-    private PullQueryContext(\n-        final List<KsqlPartitionLocation> locations,\n-        final Materialization mat,\n-        final ImmutableAnalysis analysis,\n-        final WhereInfo whereInfo,\n-        final QueryId queryId,\n-        final QueryContext.Stacker contextStacker,\n-        final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n-    ) {\n-      this.locations = Objects.requireNonNull(locations, \"locations\");\n-      this.mat = Objects.requireNonNull(mat, \"materialization\");\n-      this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n-      this.whereInfo = Objects.requireNonNull(whereInfo, \"whereInfo\");\n-      this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n-      this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n-      this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n-    }\n-  }\n-\n-  private static final class WindowBounds {\n-\n-    private final Range<Instant> start;\n-    private final Range<Instant> end;\n-\n-    private WindowBounds(\n-        final Range<Instant> start,\n-        final Range<Instant> end\n-    ) {\n-      this.start = Objects.requireNonNull(start, \"startBounds\");\n-      this.end = Objects.requireNonNull(end, \"endBounds\");\n-    }\n-  }\n-\n-  private static final class WhereInfo {\n-\n-    private final List<Object> keysBound;\n-    private final Optional<WindowBounds> windowBounds;\n-\n-    private WhereInfo(\n-        final List<Object> keysBound,\n-        final Optional<WindowBounds> windowBounds\n-    ) {\n-      this.keysBound = keysBound;\n-      this.windowBounds = Objects.requireNonNull(windowBounds);\n-    }\n-  }\n-\n-  private static final class Result {\n-\n-    private final LogicalSchema schema;\n-    private final List<? extends TableRow> rows;\n-\n-    private Result(\n-        final LogicalSchema schema,\n-        final List<? extends TableRow> rows\n-    ) {\n-      this.schema = Objects.requireNonNull(schema, \"schema\");\n-      this.rows = Objects.requireNonNull(rows, \"rows\");\n-    }\n-  }\n-\n-  private static WhereInfo extractWhereInfo(\n-      final ImmutableAnalysis analysis,\n-      final PersistentQueryMetadata query\n-  ) {\n-    final boolean windowed = query.getResultTopic().getKeyFormat().isWindowed();\n-\n-    final Expression where = analysis.getWhereExpression()\n-        .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n-\n-    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n-    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n-    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n-    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n-      throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n-    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n-      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n-    }\n-\n-    final List<Object> keys;\n-    if (keyComparison.size() > 0) {\n-      keys = ImmutableList.of(\n-          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n-    } else {\n-      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n-    }\n-\n-    if (!windowed) {\n-      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n-          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n-        throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n-      }\n-\n-      return new WhereInfo(keys, Optional.empty());\n-    }\n-\n-    final WindowBounds windowBounds =\n-        extractWhereClauseWindowBounds(keyAndWindowBounds);\n-\n-    return new WhereInfo(keys, Optional.of(windowBounds));\n-  }\n-\n-  private static List<Object> extractKeysFromInPredicate(\n-      final List<InPredicate> inPredicates,\n-      final boolean windowed,\n-      final LogicalSchema schema\n-  ) {\n-    final InPredicate inPredicate = Iterables.getLast(inPredicates);\n-    final List<Object> result = new ArrayList<>();\n-    for (Expression expression : inPredicate.getValueList().getValues()) {\n-      if (!(expression instanceof Literal)) {\n-        throw new KsqlException(\"Only comparison to literals is currently supported: \"\n-            + inPredicate);\n-      }\n-      if (expression instanceof NullLiteral) {\n-        throw new KsqlException(\"Primary key columns can not be NULL: \" + inPredicate);\n-      }\n-      final Object value = ((Literal) expression).getValue();\n-      result.add(coerceKey(schema, value, windowed));\n-    }\n-    return result;\n-  }\n-\n-  private static Object extractKeyWhereClause(\n-      final List<ComparisonExpression> comparisons,\n-      final boolean windowed,\n-      final LogicalSchema schema\n-  ) {\n-    final ComparisonExpression comparison = Iterables.getLast(comparisons);\n-    if (comparison.getType() != Type.EQUAL) {\n-      final ColumnName keyColumn = Iterables.getOnlyElement(schema.key()).name();\n-      throw invalidWhereClauseException(\"Bound on '\" + keyColumn.text()\n-          + \"' must currently be '='\", windowed);\n-    }\n-\n-    final Expression other = getNonColumnRefSide(comparison);\n-    if (!(other instanceof Literal)) {\n-      throw new KsqlException(\"Ony comparison to literals is currently supported: \" + comparison);\n-    }\n-\n-    if (other instanceof NullLiteral) {\n-      throw new KsqlException(\"Primary key columns can not be NULL: \" + comparison);\n-    }\n-\n-    final Object right = ((Literal) other).getValue();\n-    return coerceKey(schema, right, windowed);\n-  }\n-\n-  private static Object coerceKey(\n-      final LogicalSchema schema,\n-      final Object right,\n-      final boolean windowed\n-  ) {\n-    if (schema.key().size() != 1) {\n-      throw invalidWhereClauseException(\"Only single KEY column supported\", windowed);\n-    }\n-\n-    final Column keyColumn = schema.key().get(0);\n-\n-    return DefaultSqlValueCoercer.INSTANCE.coerce(right, keyColumn.type())\n-        .orElseThrow(() -> new KsqlException(\"'\" + right + \"' can not be converted \"\n-            + \"to the type of the key column: \" + keyColumn.toString(FormatOptions.noEscape())))\n-        .orElse(null);\n-  }\n-\n-  private static WindowBounds extractWhereClauseWindowBounds(\n-      final KeyAndWindowBounds keyAndWindowBounds\n-  ) {\n-    return new WindowBounds(\n-        extractWhereClauseWindowBounds(ComparisonTarget.WINDOWSTART,\n-            keyAndWindowBounds.getWindowStartExpression()),\n-        extractWhereClauseWindowBounds(ComparisonTarget.WINDOWEND,\n-            keyAndWindowBounds.getWindowEndExpression())\n-    );\n-  }\n-\n-  private static Range<Instant> extractWhereClauseWindowBounds(\n-      final ComparisonTarget windowType,\n-      final List<ComparisonExpression> comparisons\n-  ) {\n-    if (comparisons.isEmpty()) {\n-      return Range.all();\n-    }\n-\n-    final Map<Type, List<ComparisonExpression>> byType = comparisons.stream()\n-        .collect(Collectors.groupingBy(PullQueryExecutor::getSimplifiedBoundType));\n-\n-    final SetView<Type> unsupported = Sets.difference(byType.keySet(), VALID_WINDOW_BOUNDS_TYPES);\n-    if (!unsupported.isEmpty()) {\n-      throw invalidWhereClauseException(\n-          \"Unsupported \" + windowType + \" bounds: \" + unsupported, true);\n-    }\n-\n-    final String duplicates = byType.entrySet().stream()\n-        .filter(e -> e.getValue().size() > 1)\n-        .map(e -> e.getKey() + \": \" + e.getValue())\n-        .collect(Collectors.joining(System.lineSeparator()));\n-\n-    if (!duplicates.isEmpty()) {\n-      throw invalidWhereClauseException(\n-          \"Duplicate \" + windowType + \" bounds on: \" + duplicates, true);\n-    }\n-\n-    final Map<Type, ComparisonExpression> singles = byType.entrySet().stream()\n-        .collect(Collectors.toMap(Entry::getKey, e -> e.getValue().get(0)));\n-\n-    final ComparisonExpression equals = singles.get(Type.EQUAL);\n-    if (equals != null) {\n-      if (byType.size() > 1) {\n-        throw invalidWhereClauseException(\n-            \"`\" + equals + \"` cannot be combined with other \" + windowType + \" bounds\",\n-            true\n-        );\n-      }\n-\n-      return Range.singleton(asInstant(getNonColumnRefSide(equals)));\n-    }\n-\n-    final Optional<ComparisonExpression> upper =\n-        Optional.ofNullable(singles.get(Type.LESS_THAN));\n-\n-    final Optional<ComparisonExpression> lower =\n-        Optional.ofNullable(singles.get(Type.GREATER_THAN));\n-\n-    return extractWindowBound(lower, upper);\n-  }\n-\n-  private static Type getSimplifiedBoundType(final ComparisonExpression comparison) {\n-    final Type type = comparison.getType();\n-    final boolean inverted = comparison.getRight() instanceof UnqualifiedColumnReferenceExp;\n-\n-    switch (type) {\n-      case LESS_THAN:\n-      case LESS_THAN_OR_EQUAL:\n-        return inverted ? Type.GREATER_THAN : Type.LESS_THAN;\n-      case GREATER_THAN:\n-      case GREATER_THAN_OR_EQUAL:\n-        return inverted ? Type.LESS_THAN : Type.GREATER_THAN;\n-      default:\n-        return type;\n-    }\n-  }\n-\n-  private static Range<Instant> extractWindowBound(\n-      final Optional<ComparisonExpression> lowerComparison,\n-      final Optional<ComparisonExpression> upperComparison\n-  ) {\n-    if (!lowerComparison.isPresent() && !upperComparison.isPresent()) {\n-      return Range.all();\n-    }\n-\n-    if (!lowerComparison.isPresent()) {\n-      final Instant upper = asInstant(getNonColumnRefSide(upperComparison.get()));\n-      final BoundType upperType = getRangeBoundType(upperComparison.get());\n-      return Range.upTo(upper, upperType);\n-    }\n-\n-    if (!upperComparison.isPresent()) {\n-      final Instant lower = asInstant(getNonColumnRefSide(lowerComparison.get()));\n-      final BoundType lowerType = getRangeBoundType(lowerComparison.get());\n-      return Range.downTo(lower, lowerType);\n-    }\n-\n-    final Instant lower = asInstant(getNonColumnRefSide(lowerComparison.get()));\n-    final BoundType lowerType = getRangeBoundType(lowerComparison.get());\n-\n-    final Instant upper = asInstant(getNonColumnRefSide(upperComparison.get()));\n-    final BoundType upperType = getRangeBoundType(upperComparison.get());\n-\n-    return Range.range(lower, lowerType, upper, upperType);\n-  }\n-\n-  private static BoundType getRangeBoundType(final ComparisonExpression lowerComparison) {\n-    final boolean openBound = lowerComparison.getType() == Type.LESS_THAN\n-        || lowerComparison.getType() == Type.GREATER_THAN;\n-\n-    return openBound\n-        ? BoundType.OPEN\n-        : BoundType.CLOSED;\n-  }\n-\n-  private static Expression getNonColumnRefSide(final ComparisonExpression comparison) {\n-    return comparison.getRight() instanceof UnqualifiedColumnReferenceExp\n-        ? comparison.getLeft()\n-        : comparison.getRight();\n-  }\n-\n-  private static Instant asInstant(final Expression other) {\n-    if (other instanceof IntegerLiteral) {\n-      return Instant.ofEpochMilli(((IntegerLiteral) other).getValue());\n-    }\n-\n-    if (other instanceof LongLiteral) {\n-      return Instant.ofEpochMilli(((LongLiteral) other).getValue());\n-    }\n-\n-    if (other instanceof StringLiteral) {\n-      final String text = ((StringLiteral) other).getValue();\n-      try {\n-        final long timestamp = new PartialStringToTimestampParser()\n-            .parse(text);\n-\n-        return Instant.ofEpochMilli(timestamp);\n-      } catch (final Exception e) {\n-        throw invalidWhereClauseException(\"Failed to parse datetime: \" + text, true);\n-      }\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"Window bounds must be an INT, BIGINT or STRING containing a datetime.\",\n-        true\n-    );\n-  }\n-\n-  private enum ComparisonTarget {\n-    WINDOWSTART,\n-    WINDOWEND\n-  }\n-\n-  private static class KeyAndWindowBounds {\n-    private List<ComparisonExpression> keyColExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowStartExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowEndExpression = new ArrayList<>();\n-    private List<InPredicate> inPredicate = new ArrayList<>();\n-\n-    KeyAndWindowBounds() {\n-    }\n-\n-    public KeyAndWindowBounds addKeyColExpression(final ComparisonExpression keyColExpression) {\n-      this.keyColExpression.add(keyColExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addWindowStartExpression(\n-        final ComparisonExpression windowStartExpression) {\n-      this.windowStartExpression.add(windowStartExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addWindowEndExpression(\n-        final ComparisonExpression windowEndExpression) {\n-      this.windowEndExpression.add(windowEndExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addInPredicate(final InPredicate inPredicate) {\n-      this.inPredicate.add(inPredicate);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds merge(final KeyAndWindowBounds other) {\n-      keyColExpression.addAll(other.keyColExpression);\n-      windowStartExpression.addAll(other.windowStartExpression);\n-      windowEndExpression.addAll(other.windowEndExpression);\n-      inPredicate.addAll(other.inPredicate);\n-      return this;\n-    }\n-\n-    public List<ComparisonExpression> getKeyColExpression() {\n-      return keyColExpression;\n-    }\n-\n-    public List<ComparisonExpression> getWindowStartExpression() {\n-      return windowStartExpression;\n-    }\n-\n-    public List<ComparisonExpression> getWindowEndExpression() {\n-      return windowEndExpression;\n-    }\n-\n-    public List<InPredicate> getInPredicate() {\n-      return inPredicate;\n-    }\n-  }\n-\n-  private static KeyAndWindowBounds extractComparisons(\n-      final Expression exp,\n-      final PersistentQueryMetadata query\n-  ) {\n-    if (exp instanceof ComparisonExpression) {\n-      final ComparisonExpression comparison = (ComparisonExpression) exp;\n-      return extractWhereClauseTarget(comparison, query);\n-    }\n-\n-    if (exp instanceof InPredicate) {\n-      final InPredicate inPredicate = (InPredicate) exp;\n-      return extractWhereClauseTarget(inPredicate, query);\n-    }\n-\n-    if (exp instanceof LogicalBinaryExpression) {\n-      final LogicalBinaryExpression binary = (LogicalBinaryExpression) exp;\n-      if (binary.getType() != LogicalBinaryExpression.Type.AND) {\n-        throw invalidWhereClauseException(\"Only AND expressions are supported: \" + exp, false);\n-      }\n-\n-      final KeyAndWindowBounds left = extractComparisons(binary.getLeft(), query);\n-      final KeyAndWindowBounds right = extractComparisons(binary.getRight(), query);\n-      return left.merge(right);\n-    }\n-\n-    throw invalidWhereClauseException(\"Unsupported expression: \" + exp, false);\n-  }\n-\n-  private static KeyAndWindowBounds extractWhereClauseTarget(\n-      final ComparisonExpression comparison,\n-      final PersistentQueryMetadata query\n-  ) {\n-    final UnqualifiedColumnReferenceExp column;\n-    if (comparison.getRight() instanceof UnqualifiedColumnReferenceExp) {\n-      column = (UnqualifiedColumnReferenceExp) comparison.getRight();\n-    } else if (comparison.getLeft() instanceof UnqualifiedColumnReferenceExp) {\n-      column = (UnqualifiedColumnReferenceExp) comparison.getLeft();\n-    } else {\n-      throw invalidWhereClauseException(\"Invalid WHERE clause: \" + comparison, false);\n-    }\n-\n-    final ColumnName columnName = column.getColumnName();\n-    if (columnName.equals(SystemColumns.WINDOWSTART_NAME)) {\n-      return new KeyAndWindowBounds().addWindowStartExpression(comparison);\n-    }\n-\n-    if (columnName.equals(SystemColumns.WINDOWEND_NAME)) {\n-      return new KeyAndWindowBounds().addWindowEndExpression(comparison);\n-    }\n-\n-    final ColumnName keyColumn = Iterables.getOnlyElement(query.getLogicalSchema().key()).name();\n-    if (columnName.equals(keyColumn)) {\n-      return new KeyAndWindowBounds().addKeyColExpression(comparison);\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"WHERE clause on unsupported column: \" + columnName.text(),\n-        false\n-    );\n-  }\n-\n-  private static KeyAndWindowBounds extractWhereClauseTarget(\n-      final InPredicate inPredicate,\n-      final PersistentQueryMetadata query\n-  ) {\n-    final UnqualifiedColumnReferenceExp column\n-        = (UnqualifiedColumnReferenceExp) inPredicate.getValue();\n-    final ColumnName keyColumn = Iterables.getOnlyElement(query.getLogicalSchema().key()).name();\n-    if (column.getColumnName().equals(keyColumn)) {\n-      return new KeyAndWindowBounds().addInPredicate(inPredicate);\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"IN expression on unsupported column: \" + column.getColumnName().text(),\n-        false\n-    );\n-  }\n-\n-  private static boolean isSelectStar(final Select select) {\n-    final boolean someStars = select.getSelectItems().stream()\n-        .anyMatch(s -> s instanceof AllColumns);\n-\n-    if (someStars && select.getSelectItems().size() != 1) {\n-      throw new KsqlException(\"Pull queries only support wildcards in the projects \"\n-          + \"if they are the only expression\");\n-    }\n-\n-    return someStars;\n-  }\n-\n-  private static List<List<?>> handleSelects(\n-      final Result input,\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ImmutableAnalysis analysis,\n-      final LogicalSchema outputSchema,\n-      final List<SelectExpression> projection,\n-      final Optional<WindowType> windowType,\n-      final QueryId queryId,\n-      final Stacker contextStacker\n-  ) {\n-    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n-        .noneMatch(SystemColumns::isSystemColumn);\n-\n-    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n-        .noneMatch(input.schema::isKeyColumn);\n-\n-    final LogicalSchema intermediateSchema;\n-    final Function<TableRow, GenericRow> preSelectTransform;\n-    if (noSystemColumns && noKeyColumns) {\n-      intermediateSchema = input.schema;\n-      preSelectTransform = TableRow::value;\n-    } else {\n-      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n-      final boolean windowed = windowType.isPresent();\n-\n-      intermediateSchema = input.schema\n-          .withPseudoAndKeyColsInValue(windowed);\n-\n-      preSelectTransform = row -> {\n-        final Struct key = row.key();\n-        final GenericRow value = row.value();\n-\n-        final List<Object> keyFields = key.schema().fields().stream()\n-            .map(key::get)\n-            .collect(Collectors.toList());\n-\n-        value.ensureAdditionalCapacity(\n-            1 // ROWTIME\n-            + keyFields.size()\n-            + row.window().map(w -> 2).orElse(0)\n-        );\n-\n-        value.append(row.rowTime());\n-        value.appendAll(keyFields);\n-\n-        row.window().ifPresent(window -> {\n-          value.append(window.start().toEpochMilli());\n-          value.append(window.end().toEpochMilli());\n-        });\n-\n-        return value;\n-      };\n-    }\n-\n-    final KsqlConfig ksqlConfig = statement.getSessionConfig().getConfig(true);\n-\n-    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n-        projection,\n-        intermediateSchema,\n-        ksqlConfig,\n-        executionContext.getMetaStore()\n-    );\n-\n-    final ProcessingLogger logger = executionContext\n-        .getProcessingLogContext()\n-        .getLoggerFactory()\n-        .getLogger(\n-            QueryLoggerUtil.queryLoggerName(\n-                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n-        );\n-\n-    final KsqlTransformer<Object, GenericRow> transformer = select\n-        .getTransformer(logger);\n-\n-    final ImmutableList.Builder<List<?>> output = ImmutableList.builder();\n-    input.rows.forEach(r -> {\n-      final GenericRow intermediate = preSelectTransform.apply(r);\n-\n-      final GenericRow mapped = transformer.transform(\n-          r.key(),\n-          intermediate,\n-          new PullProcessingContext(r.rowTime())\n-      );\n-      validateProjection(mapped, outputSchema);\n-      output.add(mapped.values());\n-    });\n-\n-    return output.build();\n-  }\n-\n-  private static void validateProjection(\n-      final GenericRow fullRow,\n-      final LogicalSchema schema\n-  ) {\n-    final int actual = fullRow.size();\n-    final int expected = schema.columns().size();\n-    if (actual != expected) {\n-      throw new IllegalStateException(\"Row column count mismatch.\"\n-          + \" expected:\" + expected\n-          + \", got:\" + actual\n-      );\n-    }\n-  }\n-\n-  private static LogicalSchema selectOutputSchema(\n-      final Result input,\n-      final KsqlExecutionContext executionContext,\n-      final List<SelectExpression> selectExpressions,\n-      final Optional<WindowType> windowType\n-  ) {\n-    final Builder schemaBuilder = LogicalSchema.builder();\n-\n-    // Copy meta & key columns into the value schema as SelectValueMapper expects it:\n-    final LogicalSchema schema = input.schema\n-        .withPseudoAndKeyColsInValue(windowType.isPresent());\n-\n-    final ExpressionTypeManager expressionTypeManager =\n-        new ExpressionTypeManager(schema, executionContext.getMetaStore());\n-\n-    for (final SelectExpression select : selectExpressions) {\n-      final SqlType type = expressionTypeManager.getExpressionSqlType(select.getExpression());\n-\n-      if (input.schema.isKeyColumn(select.getAlias())\n-          || select.getAlias().equals(SystemColumns.WINDOWSTART_NAME)\n-          || select.getAlias().equals(SystemColumns.WINDOWEND_NAME)\n-      ) {\n-        schemaBuilder.keyColumn(select.getAlias(), type);\n-      } else {\n-        schemaBuilder.valueColumn(select.getAlias(), type);\n-      }\n-    }\n-    return schemaBuilder.build();\n-  }\n-\n-  private static PersistentQueryMetadata findMaterializingQuery(\n-      final KsqlExecutionContext executionContext,\n-      final ImmutableAnalysis analysis\n-  ) {\n-    final MetaStore metaStore = executionContext.getMetaStore();\n-\n-    final SourceName sourceName = getSourceName(analysis);\n-\n-    final Set<String> queries = metaStore.getQueriesWithSink(sourceName);\n-    if (queries.isEmpty()) {\n-      throw notMaterializedException(sourceName);\n-    }\n-    if (queries.size() > 1) {\n-      throw new KsqlException(\"Multiple queries currently materialize '\" + sourceName + \"'.\"\n-          + \" KSQL currently only supports pull queries when the table has only been\"\n-          + \" materialized once.\");\n-    }\n-\n-    final QueryId queryId = new QueryId(Iterables.get(queries, 0));\n-\n-    final PersistentQueryMetadata query = executionContext\n-        .getPersistentQuery(queryId)\n-        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n-\n-    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n-      throw new KsqlException(\"Pull queries are not supported on streams.\");\n-    }\n-\n-    return query;\n-  }\n-\n-  private static SourceName getSourceName(final ImmutableAnalysis analysis) {\n-    final DataSource source = analysis.getFrom().getDataSource();\n-    return source.getName();\n-  }\n-\n-  private static KsqlException notMaterializedException(final SourceName sourceTable) {\n-    return new KsqlException(\n-        \"Can't pull from \" + sourceTable + \" as it's not a materialized table.\"\n-        + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-    );\n-  }\n-\n-  private static KsqlException invalidWhereClauseException(\n-      final String msg,\n-      final boolean windowed\n-  ) {\n-    final String additional = !windowed\n-        ? \"\"\n-        : System.lineSeparator()\n-            + \" - (optionally) limits the time bounds of the windowed table.\"\n-            + System.lineSeparator()\n-            + \"\\t Bounds on \" + VALID_WINDOW_BOUNDS_COLUMNS + \" are supported\"\n-            + System.lineSeparator()\n-            + \"\\t Supported operators are \" + VALID_WINDOW_BOUNDS_TYPES_STRING;\n-\n-    return new KsqlException(msg + \". \"\n-        + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-        + System.lineSeparator()\n-        + \"Pull queries require a WHERE clause that:\"\n-        + System.lineSeparator()\n-        + \" - limits the query to a single key, e.g. `SELECT * FROM X WHERE <key-column>=Y;`.\"\n-        + additional\n-    );\n-  }\n-\n-  private static Struct asKeyStruct(final Object keyValue, final PhysicalSchema physicalSchema) {\n-    final ConnectSchema keySchema = ConnectSchemas\n-        .columnsToConnectSchema(physicalSchema.keySchema().columns());\n-\n-    final Field keyField = Iterables.getOnlyElement(keySchema.fields());\n-\n-    final Struct key = new Struct(keySchema);\n-    key.put(keyField, keyValue);\n-    return key;\n-  }\n-\n-  private static final class ColumnReferenceRewriter\n-      extends VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n-\n-    private ColumnReferenceRewriter() {\n-      super(Optional.empty());\n-    }\n-\n-    @Override\n-    public Optional<Expression> visitQualifiedColumnReference(\n-        final QualifiedColumnReferenceExp node,\n-        final Context<Void> ctx\n-    ) {\n-      return Optional.of(new UnqualifiedColumnReferenceExp(node.getColumnName()));\n-    }\n-  }\n-\n-  private static final class ConfigRoutingOptions implements RoutingOptions {\n-\n-    private final KsqlConfig ksqlConfig;\n-    private final Map<String, ?> configOverrides;\n-    private final Map<String, ?> requestProperties;\n-\n-    ConfigRoutingOptions(\n-        final KsqlConfig ksqlConfig,\n-        final Map<String, ?> configOverrides,\n-        final Map<String, ?> requestProperties\n-    ) {\n-      this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n-      this.configOverrides = configOverrides;\n-      this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n-    }\n-\n-    private long getLong(final String key) {\n-      if (configOverrides.containsKey(key)) {\n-        return (Long) configOverrides.get(key);\n-      }\n-      return ksqlConfig.getLong(key);\n-    }\n-\n-    private boolean getForwardedFlag(final String key) {\n-      if (requestProperties.containsKey(key)) {\n-        return (Boolean) requestProperties.get(key);\n-      }\n-      return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n-    }\n-\n-    public boolean isDebugRequest() {\n-      if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n-        return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n-      }\n-      return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n-    }\n-\n-    @Override\n-    public Set<Integer> getPartitions() {\n-      if (requestProperties.containsKey(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS)) {\n-        @SuppressWarnings(\"unchecked\")\n-        final List<String> partitions = (List<String>) requestProperties.get(\n-            KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS);\n-        return partitions.stream()\n-            .map(partition -> {\n-              try {\n-                return Integer.parseInt(partition);\n-              } catch (NumberFormatException e) {\n-                throw new IllegalStateException(\"Internal request got a bad partition \"\n-                    + partition);\n-              }\n-            }).collect(Collectors.toSet());\n-      }\n-      return Collections.emptySet();\n-    }\n-\n-    @Override\n-    public long getOffsetLagAllowed() {\n-      return getLong(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG);\n-    }\n-\n-    @Override\n-    public boolean skipForwardRequest() {\n-      return getForwardedFlag(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING);\n-    }\n-  }\n-}\n\\ No newline at end of file\n"}}, {"oid": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "url": "https://github.com/confluentinc/ksql/commit/41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "message": "tests pass", "committedDate": "2020-11-16T19:00:08Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0ODE2NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524548164", "bodyText": "Here is where you do the null check.  My original thinking was mostly that if you cannot reference which key this is returning null for, there's not really any point in returning null at all.  Maybe you feel differently.", "author": "AlanConfluent", "createdAt": "2020-11-16T20:21:14Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+\n+/**\n+ * Represents the physical plan for pull queries. It is a tree of physical operators that gets\n+ * created from the translation of the logical plan.\n+ * The root operator is always a ProjectOperator whereas the leaves are scan operators that scan\n+ * the data stores.\n+ */\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations) {\n+\n+    // We only know at runtime which partitions to get from which node.\n+    // That's why we need to set this explicitly for the dataSource operators\n+    dataSourceOperator.setPartitionLocations(locations);\n+\n+    open();\n+    final List<List<?>> localResult = new ArrayList<>();\n+    List<?> row = null;\n+    while ((row = (List<?>)next()) != null) {", "originalCommit": "0b69065fad8de495182284c27ef6cebc05ac0655", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxMDExOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524810119", "bodyText": "You were right, I wasn't handling correctly the case where a key does not exist in the sate store. Fixed it now", "author": "vpapavas", "createdAt": "2020-11-17T00:41:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0ODE2NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzMTM0OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524831348", "bodyText": "@Before runs before every test, not once before all the tests. If you want these to be populated once, which I think you do, it should be in the constructor", "author": "agavra", "createdAt": "2020-11-17T01:45:21Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.MaterializedTable;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.ks.KsLocator;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@SuppressWarnings({\"UnstableApiUsage\", \"unchecked\"})\n+@RunWith(MockitoJUnitRunner.class)\n+public class KeyedTableLookupOperatorTest {\n+\n+  private final List<KsqlPartitionLocation> singleKeyPartitionLocations = new ArrayList<>();\n+  private final List<KsqlPartitionLocation> multipleKeysPartitionLocations = new ArrayList<>();\n+\n+  @Mock\n+  private KsqlNode node1;\n+  @Mock\n+  private KsqlNode node2;\n+  @Mock\n+  private KsqlNode node3;\n+  @Mock\n+  private Materialization materialization;\n+  @Mock\n+  private MaterializedTable nonWindowedTable;\n+  @Mock\n+  private DataSourceNode logicalNode;\n+  @Mock\n+  private Struct KEY1;\n+  @Mock\n+  private Struct KEY2;\n+  @Mock\n+  private Struct KEY3;\n+  @Mock\n+  private Struct KEY4;\n+  @Mock\n+  private Row ROW1;\n+  @Mock\n+  private Row ROW3;\n+  @Mock\n+  private Row ROW4;\n+\n+\n+  @Before", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6aab39a243472d5256f849fd4d07c3305fe5c349", "chunk": "diff --git a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java\nindex 69aa466712..4aca98d6b1 100644\n--- a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java\n+++ b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java\n\n@@ -30,10 +30,15 @@ import io.confluent.ksql.execution.streams.materialization.Row;\n import io.confluent.ksql.execution.streams.materialization.ks.KsLocator;\n import io.confluent.ksql.planner.plan.DataSourceNode;\n import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Optional;\n+import java.util.Set;\n import org.apache.kafka.connect.data.Struct;\n import org.junit.Before;\n+import org.junit.BeforeClass;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.mockito.Mock;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzMzI5Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524833292", "bodyText": "I think it makes sense to add an assert that selectValueMapper was never called (Mockito.verifyNoInteractions(selectValueMapper)). This will (1) make sure we're not calling unnecessary code, and (2) makes the test easier to understand (I asked myself why we didn't need to mock out the mapper for this method)", "author": "agavra", "createdAt": "2020-11-17T01:51:21Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.Range;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.Window;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n+import io.confluent.ksql.execution.util.StructKeyUtil;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.kstream.internals.TimeWindow;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class ProjectOperatorTest {\n+\n+  private static final LogicalSchema SCHEMA = LogicalSchema.builder()\n+      .keyColumn(ColumnName.of(\"k0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v1\"), SqlTypes.STRING)\n+      .build();\n+\n+  private static final Struct A_KEY = StructKeyUtil\n+      .keyBuilder(ColumnName.of(\"k0\"), SqlTypes.STRING).build(\"k\", 0);\n+  private static final long A_ROWTIME = 12335L;\n+\n+  private static final Window A_WINDOW = Window.of(Instant.now(), Instant.now().plusMillis(10));\n+  private static final TimeWindow STREAM_WINDOW = new TimeWindow(\n+      A_WINDOW.start().toEpochMilli(),\n+      A_WINDOW.end().toEpochMilli()\n+  );\n+\n+  @Mock\n+  private KsqlConfig ksqlConfig;\n+  @Mock\n+  private MetaStore metaStore;\n+  @Mock\n+  private ProcessingLogger logger;\n+  @Mock\n+  private Materialization mat;\n+  @Mock\n+  private LogicalSchema outputSchema;\n+  @Mock\n+  private SelectValueMapperFactorySupplier selectValueMapperFactorySupplier;\n+  @Mock\n+  private ProjectNode logicalNode;\n+  @Mock\n+  private AbstractPhysicalOperator child;\n+  @Mock\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  @Mock\n+  private SelectValueMapper<Object> selectValueMapper;\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarNonWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        false,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    row.key().schema().fields().stream().map(row.key()::get).forEach(rowList::add);\n+    rowList.addAll(row.value().values());\n+    assertThat(projectOperator.next(), is(rowList));", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6aab39a243472d5256f849fd4d07c3305fe5c349", "chunk": "diff --git a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\nindex 022316ce55..d5aad4d543 100644\n--- a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\n+++ b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\n\n@@ -50,6 +50,7 @@ import org.apache.kafka.streams.kstream.internals.TimeWindow;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.mockito.Mock;\n+import org.mockito.Mockito;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzNDMzMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524834331", "bodyText": "nit: this applies to all tests, but this is what belongs in the //When: part (it makes it easy to identify what is setup and what the test is actually doing. I know this PR has gone on for a while so I won't ask you to refactor all the tests, but going forward it makes tests really easy to read when then //When portion contains the code that you're testing.\nFor example:\n// When:\nList<?> result = projectOperator.next();\n\n// Then:\nfinal List<Object> expected = new ArrayList<>();\nwindowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(expected::add);\nexpected.add(windowedRow.window().get().start().toEpochMilli());\nexpected.add(windowedRow.window().get().end().toEpochMilli());\nexpected.addAll(windowedRow.value().values());\nassertThat(result, is(expected)); \nCompare that with:\n// Then:\nfinal List<Object> expected = new ArrayList<>();\nwindowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(expected::add);\nexpected.add(windowedRow.window().get().start().toEpochMilli());\nexpected.add(windowedRow.window().get().end().toEpochMilli());\nexpected.addAll(windowedRow.value().values());\nassertThat(result, is(rowList)); \nassertThat(projectOperator.next(), is(expected)); \nFor the second one I need to dig in to figure out what is the production code being called.", "author": "agavra", "createdAt": "2020-11-17T01:54:53Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.Range;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.Window;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n+import io.confluent.ksql.execution.util.StructKeyUtil;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.kstream.internals.TimeWindow;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class ProjectOperatorTest {\n+\n+  private static final LogicalSchema SCHEMA = LogicalSchema.builder()\n+      .keyColumn(ColumnName.of(\"k0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v1\"), SqlTypes.STRING)\n+      .build();\n+\n+  private static final Struct A_KEY = StructKeyUtil\n+      .keyBuilder(ColumnName.of(\"k0\"), SqlTypes.STRING).build(\"k\", 0);\n+  private static final long A_ROWTIME = 12335L;\n+\n+  private static final Window A_WINDOW = Window.of(Instant.now(), Instant.now().plusMillis(10));\n+  private static final TimeWindow STREAM_WINDOW = new TimeWindow(\n+      A_WINDOW.start().toEpochMilli(),\n+      A_WINDOW.end().toEpochMilli()\n+  );\n+\n+  @Mock\n+  private KsqlConfig ksqlConfig;\n+  @Mock\n+  private MetaStore metaStore;\n+  @Mock\n+  private ProcessingLogger logger;\n+  @Mock\n+  private Materialization mat;\n+  @Mock\n+  private LogicalSchema outputSchema;\n+  @Mock\n+  private SelectValueMapperFactorySupplier selectValueMapperFactorySupplier;\n+  @Mock\n+  private ProjectNode logicalNode;\n+  @Mock\n+  private AbstractPhysicalOperator child;\n+  @Mock\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  @Mock\n+  private SelectValueMapper<Object> selectValueMapper;\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarNonWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        false,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    row.key().schema().fields().stream().map(row.key()::get).forEach(rowList::add);\n+    rowList.addAll(row.value().values());\n+    assertThat(projectOperator.next(), is(rowList));\n+  }\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        true,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final WindowedRow windowedRow = WindowedRow.of(\n+        SCHEMA,\n+        new Windowed<>(A_KEY, STREAM_WINDOW),\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(windowedRow);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    windowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(rowList::add);\n+    rowList.add(windowedRow.window().get().start().toEpochMilli());\n+    rowList.add(windowedRow.window().get().end().toEpochMilli());\n+    rowList.addAll(windowedRow.value().values());\n+    assertThat(projectOperator.next(), is(rowList));\n+  }\n+\n+  @Test\n+  public void shouldCallTransformWithCorrectArguments() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        SCHEMA,\n+        false,\n+        false,\n+        true,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    when(selectValueMapperFactorySupplier.create(any(), any(), any(), any()))\n+        .thenReturn(selectValueMapper);\n+    when(selectValueMapper.getTransformer(logger)).thenReturn(transformer);\n+    when(transformer.transform(any(), any(), any())).thenReturn(GenericRow.genericRow(\"k\", \"a\", \"b\"));\n+    when(mat.schema()).thenReturn(SCHEMA);\n+    projectOperator.open();\n+    projectOperator.next();", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6aab39a243472d5256f849fd4d07c3305fe5c349", "chunk": "diff --git a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\nindex 022316ce55..d5aad4d543 100644\n--- a/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\n+++ b/ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java\n\n@@ -50,6 +50,7 @@ import org.apache.kafka.streams.kstream.internals.TimeWindow;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.mockito.Mock;\n+import org.mockito.Mockito;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n"}}, {"oid": "4672c3d67d24bcad993664b0d44e28b45151ac23", "url": "https://github.com/confluentinc/ksql/commit/4672c3d67d24bcad993664b0d44e28b45151ac23", "message": "first iteration on pull physical plan\n\nadded ha routing and windowed table\n\nfix checkstyle\n\nall tests pass\n\nremove comments\n\nfix regression in engineexecutor\n\nAddress comments\n\nrefactoring to include in predicate changes\n\nfixing tests\n\ntrying to fix rqt test\n\naddress alan's comments\n\nfixed import\n\naddress almog's comments\n\nadd tests for operators\n\nadding test for project operator\n\nadded test for HA routing\n\naddress comments and add tests\n\ntests pass\n\nstyling and remove unnecessary changes\n\nfix bug in next of lookup operators", "committedDate": "2020-11-17T23:31:05Z", "type": "commit"}, {"oid": "6aab39a243472d5256f849fd4d07c3305fe5c349", "url": "https://github.com/confluentinc/ksql/commit/6aab39a243472d5256f849fd4d07c3305fe5c349", "message": "improved tests", "committedDate": "2020-11-17T23:31:08Z", "type": "commit"}, {"oid": "6aab39a243472d5256f849fd4d07c3305fe5c349", "url": "https://github.com/confluentinc/ksql/commit/6aab39a243472d5256f849fd4d07c3305fe5c349", "message": "improved tests", "committedDate": "2020-11-17T23:31:08Z", "type": "forcePushed"}, {"oid": "e3493f4c369b4ce8bf07886f3c9c1ece8152fb33", "url": "https://github.com/confluentinc/ksql/commit/e3493f4c369b4ce8bf07886f3c9c1ece8152fb33", "message": "fix compilation error", "committedDate": "2020-11-18T01:17:59Z", "type": "commit"}, {"oid": "4488fb328573a66f4cefb3e76f4d25c7114df5f7", "url": "https://github.com/confluentinc/ksql/commit/4488fb328573a66f4cefb3e76f4d25c7114df5f7", "message": "wrong error message", "committedDate": "2020-11-18T04:20:55Z", "type": "commit"}, {"oid": "5044d1e7215e1049039e1b344cb4fbcc87e0bf1e", "url": "https://github.com/confluentinc/ksql/commit/5044d1e7215e1049039e1b344cb4fbcc87e0bf1e", "message": "empty: trying to fix jenkins", "committedDate": "2020-11-18T18:27:34Z", "type": "commit"}]}