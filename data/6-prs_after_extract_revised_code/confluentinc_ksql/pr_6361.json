{"pr_number": 6361, "pr_title": "feat: new command to restore ksqlDB command topic backups", "pr_createdAt": "2020-10-05T18:57:15Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6361", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDUwODcyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r500508729", "bodyText": "nit: we shouldn't check these in if this is a specific checkstyle error to your local environment", "author": "stevenpyzhang", "createdAt": "2020-10-06T18:26:25Z", "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/StreamAggregateBuilderTest.java", "diffHunk": "@@ -431,6 +431,7 @@ public void shouldBuildAggregatorParamsCorrectlyForUnwindowedAggregate() {\n   }\n \n   @Test\n+  @SuppressWarnings(\"RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT\")", "originalCommit": "20b7cc56e16f17cff64aecbd01381e36fe639b68", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a6dfc9893755b546b3553aa5f03c466117c3f367", "chunk": "diff --git a/ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/StreamAggregateBuilderTest.java b/ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/StreamAggregateBuilderTest.java\nindex 7a8fa330d1..cfab1f8be1 100644\n--- a/ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/StreamAggregateBuilderTest.java\n+++ b/ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/StreamAggregateBuilderTest.java\n\n@@ -431,7 +431,6 @@ public class StreamAggregateBuilderTest {\n   }\n \n   @Test\n-  @SuppressWarnings(\"RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT\")\n   public void shouldBuildTumblingWindowedAggregateCorrectly() {\n     // Given:\n     givenTumblingWindowedAggregate();\n"}}, {"oid": "a6dfc9893755b546b3553aa5f03c466117c3f367", "url": "https://github.com/confluentinc/ksql/commit/a6dfc9893755b546b3553aa5f03c466117c3f367", "message": "fix: use transactions to restore the commands", "committedDate": "2020-10-15T16:51:03Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0MjI3Mg==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r505842272", "bodyText": "For the verify statements in this file, can you use InOrder to verify the calls are being made properly? (we're enqueueing a record, then committing before moving onto the next record.", "author": "stevenpyzhang", "createdAt": "2020-10-15T20:56:09Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/restore/KsqlRestoreCommandTopicTest.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server.restore;\n+\n+import com.google.common.collect.ImmutableMap;\n+import io.confluent.ksql.services.KafkaTopicClient;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.clients.producer.RecordMetadata;\n+import org.apache.kafka.common.config.TopicConfig;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.junit.Assert.assertThrows;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoMoreInteractions;\n+import static org.mockito.Mockito.verifyZeroInteractions;\n+import static org.mockito.Mockito.when;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class KsqlRestoreCommandTopicTest {\n+  private static final String COMMAND_TOPIC_NAME = \"command_topic_name\";\n+\n+  private static final int INTERNAL_TOPIC_PARTITION_COUNT = 1;\n+  private static final short INTERNAL_TOPIC_REPLICAS_COUNT = 1;\n+\n+  private static final ImmutableMap<String, ?> INTERNAL_TOPIC_CONFIG = ImmutableMap.of(\n+      TopicConfig.RETENTION_MS_CONFIG, -1L,\n+      TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_DELETE,\n+      TopicConfig.UNCLEAN_LEADER_ELECTION_ENABLE_CONFIG, false,\n+      TopicConfig.MIN_IN_SYNC_REPLICAS_CONFIG, INTERNAL_TOPIC_REPLICAS_COUNT\n+  );\n+\n+  private static final Pair<byte[], byte[]> COMMAND_1 = createStreamCommand(\"stream1\");\n+  private static final Pair<byte[], byte[]> COMMAND_2 = createStreamCommand(\"stream2\");\n+  private static final Pair<byte[], byte[]> COMMAND_3 = createStreamCommand(\"stream3\");\n+\n+  private static final ProducerRecord<byte[], byte[]> RECORD_1 = newRecord(COMMAND_1);\n+  private static final ProducerRecord<byte[], byte[]> RECORD_2 = newRecord(COMMAND_2);\n+  private static final ProducerRecord<byte[], byte[]> RECORD_3 = newRecord(COMMAND_3);\n+\n+  private static final List<Pair<byte[], byte[]>> BACKUP_COMMANDS =\n+      Arrays.asList(COMMAND_1, COMMAND_2, COMMAND_3);\n+\n+  private static Pair<byte[], byte[]> createStreamCommand(final String streamName) {\n+    return Pair.of(\n+        String.format(\"\\\"stream/%s/create\\\"\", streamName).getBytes(StandardCharsets.UTF_8),\n+        String.format(\"{\\\"statement\\\":\\\"CREATE STREAM %s (id INT) WITH (kafka_topic='%s')\\\",\"\n+                + \"\\\"streamsProperties\\\":{},\\\"originalProperties\\\":{},\\\"plan\\\":null}\",\n+            streamName, streamName).getBytes(StandardCharsets.UTF_8)\n+    );\n+  }\n+\n+  private static ProducerRecord<byte[], byte[]> newRecord(final Pair<byte[], byte[]> command) {\n+    return new ProducerRecord<>(\n+        COMMAND_TOPIC_NAME,\n+        0,\n+        command.getLeft(),\n+        command.getRight());\n+  }\n+\n+  @Mock\n+  private KafkaTopicClient topicClient;\n+  @Mock\n+  private Producer<byte[], byte[]> kafkaProducer;\n+  @Mock\n+  private Future<RecordMetadata> future1;\n+  @Mock\n+  private Future<RecordMetadata> future2;\n+  @Mock\n+  private Future<RecordMetadata> future3;\n+\n+  private KsqlRestoreCommandTopic restoreCommandTopic;\n+\n+\n+  @Before\n+  public void setup() {\n+    final KsqlConfig serverConfig = new KsqlConfig(ImmutableMap.of(\n+        KsqlConfig.KSQL_INTERNAL_TOPIC_REPLICAS_PROPERTY, INTERNAL_TOPIC_REPLICAS_COUNT,\n+        KsqlConfig.KSQL_INTERNAL_TOPIC_MIN_INSYNC_REPLICAS_PROPERTY, INTERNAL_TOPIC_REPLICAS_COUNT\n+    ));\n+\n+    restoreCommandTopic = new KsqlRestoreCommandTopic(\n+        serverConfig,\n+        COMMAND_TOPIC_NAME,\n+        topicClient,\n+        () -> kafkaProducer\n+    );\n+\n+    when(kafkaProducer.send(RECORD_1)).thenReturn(future1);\n+    when(kafkaProducer.send(RECORD_2)).thenReturn(future2);\n+    when(kafkaProducer.send(RECORD_3)).thenReturn(future3);\n+  }\n+\n+  @Test\n+  public void shouldCreateAndRestoreCommandTopic() throws ExecutionException, InterruptedException {\n+    // Given:\n+    when(topicClient.isTopicExists(COMMAND_TOPIC_NAME)).thenReturn(false);\n+\n+    // When:\n+    restoreCommandTopic.restore(BACKUP_COMMANDS);\n+\n+    // Then:\n+    verifyCreateTopic(COMMAND_TOPIC_NAME);", "originalCommit": "a6dfc9893755b546b3553aa5f03c466117c3f367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODUwMzA2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r508503069", "bodyText": "Done", "author": "spena", "createdAt": "2020-10-20T13:30:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0MjI3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e7cb9ef4b880410f019242e7615e69228081555d", "chunk": "diff --git a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/restore/KsqlRestoreCommandTopicTest.java b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/restore/KsqlRestoreCommandTopicTest.java\nindex 40b0e12a05..3eacbcc483 100644\n--- a/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/restore/KsqlRestoreCommandTopicTest.java\n+++ b/ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/restore/KsqlRestoreCommandTopicTest.java\n\n@@ -27,6 +27,7 @@ import org.apache.kafka.common.config.TopicConfig;\n import org.junit.Before;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.InOrder;\n import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg5NzIwNg==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r505897206", "bodyText": "Do we need to actually split this into two classes? BackupReplayFile and BackupInputFile\nIt doesn't really look like there's much difference between the two so it's not clear to me why having both is necessary.", "author": "stevenpyzhang", "createdAt": "2020-10-15T22:21:29Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java", "diffHunk": "@@ -16,36 +16,21 @@\n package io.confluent.ksql.rest.server;\n \n import io.confluent.ksql.util.KsqlException;\n-import io.confluent.ksql.util.Pair;\n import java.io.Closeable;\n import java.io.File;\n import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n-import java.nio.charset.StandardCharsets;\n-import java.nio.file.Files;\n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.Objects;\n import org.apache.kafka.clients.consumer.ConsumerRecord;\n \n /**\n  * A file that is used by the backup service to replay command_topic commands.\n  */\n-public final class BackupReplayFile implements Closeable {\n-  private static final String KEY_VALUE_SEPARATOR_STR = \":\";\n-  private static final String NEW_LINE_SEPARATOR_STR = \"\\n\";\n-\n-  private static final byte[] KEY_VALUE_SEPARATOR_BYTES =\n-      KEY_VALUE_SEPARATOR_STR.getBytes(StandardCharsets.UTF_8);\n-  private static final byte[] NEW_LINE_SEPARATOR_BYTES =\n-      NEW_LINE_SEPARATOR_STR.getBytes(StandardCharsets.UTF_8);\n-\n-  private final File file;\n+public final class BackupReplayFile extends BackupInputFile implements Closeable {\n   private final FileOutputStream writer;\n \n   public BackupReplayFile(final File file) {", "originalCommit": "a6dfc9893755b546b3553aa5f03c466117c3f367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzk5OTE5MA==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r507999190", "bodyText": "There's a slightly difference. The BackupReplayFile opens the file for writing. It fails if there are no permissions for writing. I created the BackupInputFile just for that, so it can open it if only read permissions are set.", "author": "spena", "createdAt": "2020-10-19T19:11:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg5NzIwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODUwMzU1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6361#discussion_r508503552", "bodyText": "I reverted the BackupInputFile. I added two static methods to the BackupReplayFile:\nBackupReplayFile.readOnly(file);\nBackupReplayFile.writetable(file);", "author": "spena", "createdAt": "2020-10-20T13:30:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg5NzIwNg=="}], "type": "inlineReview", "revised_code": {"commit": "d443f436e7f32eece93a17f5ff43b516c3bbef54", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java\nindex e5c7a30d9d..e525835cf2 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java\n\n@@ -16,22 +16,50 @@\n package io.confluent.ksql.rest.server;\n \n import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n import java.io.Closeable;\n import java.io.File;\n import java.io.FileNotFoundException;\n import java.io.FileOutputStream;\n import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n import org.apache.kafka.clients.consumer.ConsumerRecord;\n \n /**\n  * A file that is used by the backup service to replay command_topic commands.\n  */\n-public final class BackupReplayFile extends BackupInputFile implements Closeable {\n+public final class BackupReplayFile implements Closeable {\n+  private static final String KEY_VALUE_SEPARATOR_STR = \":\";\n+  private static final String NEW_LINE_SEPARATOR_STR = \"\\n\";\n+\n+  private static final byte[] KEY_VALUE_SEPARATOR_BYTES =\n+      KEY_VALUE_SEPARATOR_STR.getBytes(StandardCharsets.UTF_8);\n+  private static final byte[] NEW_LINE_SEPARATOR_BYTES =\n+      NEW_LINE_SEPARATOR_STR.getBytes(StandardCharsets.UTF_8);\n+\n+  private final File file;\n   private final FileOutputStream writer;\n \n-  public BackupReplayFile(final File file) {\n-    super(file);\n-    this.writer = createWriter(file);\n+  public static BackupReplayFile readOnly(final File file) {\n+    return new BackupReplayFile(file, false);\n+  }\n+\n+  public static BackupReplayFile writable(final File file) {\n+    return new BackupReplayFile(file, true);\n+  }\n+\n+  private BackupReplayFile(final File file, final boolean write) {\n+    this.file = Objects.requireNonNull(file, \"file\");\n+\n+    if (write) {\n+      this.writer = createWriter(file);\n+    } else {\n+      this.writer = null;\n+    }\n   }\n \n   private static FileOutputStream createWriter(final File file) {\n"}}, {"oid": "e7cb9ef4b880410f019242e7615e69228081555d", "url": "https://github.com/confluentinc/ksql/commit/e7cb9ef4b880410f019242e7615e69228081555d", "message": "test: add integration test", "committedDate": "2020-10-19T23:31:09Z", "type": "forcePushed"}, {"oid": "d443f436e7f32eece93a17f5ff43b516c3bbef54", "url": "https://github.com/confluentinc/ksql/commit/d443f436e7f32eece93a17f5ff43b516c3bbef54", "message": "refactor: revert BackupInputFile split", "committedDate": "2020-10-20T13:12:34Z", "type": "forcePushed"}, {"oid": "33d6831b852c755599e81837fdda66c6b0f48322", "url": "https://github.com/confluentinc/ksql/commit/33d6831b852c755599e81837fdda66c6b0f48322", "message": "refactor: revert BackupInputFile split", "committedDate": "2020-10-20T14:41:42Z", "type": "forcePushed"}, {"oid": "75cc9913207f545f8875a847ba303e53dfcd9b80", "url": "https://github.com/confluentinc/ksql/commit/75cc9913207f545f8875a847ba303e53dfcd9b80", "message": "refactor: revert BackupInputFile split", "committedDate": "2020-10-20T19:01:27Z", "type": "forcePushed"}, {"oid": "586fc817eafaa76368f40161fcb781c519eeefca", "url": "https://github.com/confluentinc/ksql/commit/586fc817eafaa76368f40161fcb781c519eeefca", "message": "feat: new ksql-restore-command-topic to restore backups", "committedDate": "2020-10-20T21:09:15Z", "type": "commit"}, {"oid": "4a61d963f1f25e1e4ec8ada845a9709394d3702b", "url": "https://github.com/confluentinc/ksql/commit/4a61d963f1f25e1e4ec8ada845a9709394d3702b", "message": "fix: use transactions to restore the commands", "committedDate": "2020-10-20T21:09:15Z", "type": "commit"}, {"oid": "1a3c664e8423ee62c37f92fecf0c6c6dd8aa1212", "url": "https://github.com/confluentinc/ksql/commit/1a3c664e8423ee62c37f92fecf0c6c6dd8aa1212", "message": "fix: address feedback\n\n- use inOrder on unit tests", "committedDate": "2020-10-20T21:09:15Z", "type": "commit"}, {"oid": "8ca99e5c210349eba5a8a3281b7840e739a1650f", "url": "https://github.com/confluentinc/ksql/commit/8ca99e5c210349eba5a8a3281b7840e739a1650f", "message": "test: add integration test", "committedDate": "2020-10-20T21:09:16Z", "type": "commit"}, {"oid": "4db06da3cc5d2a1e38ec949430655b10dd09f289", "url": "https://github.com/confluentinc/ksql/commit/4db06da3cc5d2a1e38ec949430655b10dd09f289", "message": "refactor: revert BackupInputFile split", "committedDate": "2020-10-20T21:09:16Z", "type": "commit"}, {"oid": "4db06da3cc5d2a1e38ec949430655b10dd09f289", "url": "https://github.com/confluentinc/ksql/commit/4db06da3cc5d2a1e38ec949430655b10dd09f289", "message": "refactor: revert BackupInputFile split", "committedDate": "2020-10-20T21:09:16Z", "type": "forcePushed"}]}