{"pr_number": 587, "pr_title": "Update RecordFileParser.loadRecordFile() to match design", "pr_createdAt": "2020-03-08T18:21:01Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/587", "timeline": [{"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-08T18:32:57Z", "type": "commit"}, {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-08T18:32:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NDQzOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389764439", "bodyText": "nit: Combine declaration and assignment", "author": "steven-sheehy", "createdAt": "2020-03-09T15:24:42Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,25 +143,16 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) {\n         String fileName = streamFileData.getFilename();\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        recordFile = recordStreamFileListener.onStart(streamFileData);", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4MTY4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389881684", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:30:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NDQzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -145,17 +140,16 @@ public class RecordFileParser implements FileParser {\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n                 ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        Optional<RecordFile> recordFile;\n-        recordFile = recordStreamFileListener.onStart(streamFileData);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n         if (recordFile.isEmpty()) {\n             return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NTI3Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389765272", "bodyText": "Change to catch Exception since you're only rethrowing IOException and could miss a RuntimeException.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:25:53Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NzQyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389897426", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NTI3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -285,7 +276,7 @@ public class RecordFileParser implements FileParser {\n             try {\n                 loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } catch (ImporterException e) {\n+            } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", name, e);\n                 recordStreamFileListener.onError();\n                 return;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NzYxOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389767619", "bodyText": "Since this is returning here on error, you might as well move the catch up even higher to parse() and consolidate all error handling in one spot.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:29:14Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {\n+                log.error(\"Error parsing file {}\", name, e);\n+                recordStreamFileListener.onError();", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1Mzc0OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391253748", "bodyText": "trying to keep fs and db (onError) logic in different functions so that splitting out RecordFileReader (fs-dependent) would be cleaner. Let's leave it like this for now, no harm.", "author": "apeksharma", "createdAt": "2020-03-11T20:37:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NzYxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -285,7 +276,7 @@ public class RecordFileParser implements FileParser {\n             try {\n                 loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } catch (ImporterException e) {\n+            } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", name, e);\n                 recordStreamFileListener.onError();\n                 return;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MTk2OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389771969", "bodyText": "Please change back to Exception (catch and rethrow ImporterException first) since you will miss unchecked exceptions. That or remove this catch and catch Exception in layer above, but then you miss out on formatted timing message. That may not be a big deal since we have metrics and timings for errors is probably not important.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:35:43Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NTk3NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389895974", "bodyText": "done the latter.", "author": "apeksharma", "createdAt": "2020-03-09T18:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MTk2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -164,82 +158,80 @@ public class RecordFileParser implements FileParser {\n             int version = dis.readInt();\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n             while (dis.available() != 0) {\n-                    byte typeDelimiter = dis.readByte();\n-\n-                    switch (typeDelimiter) {\n-                        case FileDelimiter.RECORD_TYPE_PREV_HASH:\n-                            byte[] readFileHash = new byte[48];\n-                            dis.read(readFileHash);\n-\n-                            if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n-                                log.error(\"Previous file hash not available\");\n-                                expectedPrevFileHash = Hex.encodeHexString(readFileHash);\n+                byte typeDelimiter = dis.readByte();\n+\n+                switch (typeDelimiter) {\n+                    case FileDelimiter.RECORD_TYPE_PREV_HASH:\n+                        byte[] readFileHash = new byte[48];\n+                        dis.read(readFileHash);\n+                        String actualPrevFileHash = Hex.encodeHexString(readFileHash);\n+                        if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n+                            log.error(\"Previous file hash not available\");\n+                            expectedPrevFileHash = actualPrevFileHash;\n+                        }\n+                        log.trace(\"actual file hash = {}, expected file hash = {}\", actualPrevFileHash,\n+                                expectedPrevFileHash);\n+                        if (!actualPrevFileHash.contentEquals(expectedPrevFileHash)) {\n+                            if (applicationStatusRepository\n+                                    .findByStatusCode(ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER)\n+                                    .compareTo(Utility.getFileName(fileName)) < 0) {\n+                                // last file for which mismatch is allowed is in the past\n+                                throw new ParserException(String.format(\n+                                        \"Hash mismatch for file %s. Actual = %s, Expected = %s\",\n+                                        fileName, expectedPrevFileHash, actualPrevFileHash));\n                             }\n-\n-                            String actualPrevFileHash = Hex.encodeHexString(readFileHash);\n-                            log.trace(\"actual file hash = {}, expected file hash = {}\", actualPrevFileHash,\n-                                    expectedPrevFileHash);\n-                            if (!actualPrevFileHash.contentEquals(expectedPrevFileHash)) {\n-                                if (applicationStatusRepository\n-                                        .findByStatusCode(ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER)\n-                                        .compareTo(Utility.getFileName(fileName)) < 0) {\n-                                    // last file for which mismatch is allowed is in the past\n-                                    throw new ParserException(String.format(\n-                                            \"Hash mismatch for file %s. Actual = %s, Expected = %s\",\n-                                            fileName, expectedPrevFileHash, actualPrevFileHash));\n-                                }\n+                        }\n+                        break;\n+                    case FileDelimiter.RECORD_TYPE_RECORD:\n+                        counter++;\n+\n+                        int byteLength = dis.readInt();\n+                        byte[] transactionRawBytes = new byte[byteLength];\n+                        dis.readFully(transactionRawBytes);\n+                        Transaction transaction = Transaction.parseFrom(transactionRawBytes);\n+\n+                        byteLength = dis.readInt();\n+                        byte[] recordRawBytes = new byte[byteLength];\n+                        dis.readFully(recordRawBytes);\n+                        TransactionRecord txRecord = TransactionRecord.parseFrom(recordRawBytes);\n+\n+                        try {\n+                            if (log.isTraceEnabled()) {\n+                                log.trace(\"Transaction = {}, Record = {}\", Utility\n+                                        .printProtoMessage(transaction), Utility.printProtoMessage(txRecord));\n+                            } else {\n+                                log.debug(\"Storing transaction with consensus timestamp {}\", () -> Utility\n+                                        .printProtoMessage(txRecord.getConsensusTimestamp()));\n                             }\n-                            break;\n-                        case FileDelimiter.RECORD_TYPE_RECORD:\n-                            counter++;\n-\n-                            int byteLength = dis.readInt();\n-                            byte[] transactionRawBytes = new byte[byteLength];\n-                            dis.readFully(transactionRawBytes);\n-                            Transaction transaction = Transaction.parseFrom(transactionRawBytes);\n-\n-                            byteLength = dis.readInt();\n-                            byte[] recordRawBytes = new byte[byteLength];\n-                            dis.readFully(recordRawBytes);\n-                            TransactionRecord txRecord = TransactionRecord.parseFrom(recordRawBytes);\n-\n-                            try {\n-                                if (log.isTraceEnabled()) {\n-                                    log.trace(\"Transaction = {}, Record = {}\", Utility\n-                                            .printProtoMessage(transaction), Utility.printProtoMessage(txRecord));\n-                                } else {\n-                                    log.debug(\"Storing transaction with consensus timestamp {}\", () -> Utility\n-                                            .printProtoMessage(txRecord.getConsensusTimestamp()));\n-                                }\n \n-                                recordItemListener.onItem(\n-                                        new RecordItem(transaction, txRecord, transactionRawBytes, recordRawBytes));\n-                            } finally {\n-                                // TODO: Refactor to not parse TransactionBody twice\n-                                DataCase dc = Utility.getTransactionBody(transaction).getDataCase();\n-                                String type = dc != null && dc != DataCase.DATA_NOT_SET ? dc.name() : \"UNKNOWN\";\n-                                transactionSizeMetric.tag(\"type\", type)\n-                                        .register(meterRegistry)\n-                                        .record(transactionRawBytes.length);\n-\n-                                Instant consensusTimestamp = Utility\n-                                        .convertToInstant(txRecord.getConsensusTimestamp());\n-                                transactionLatencyMetric.tag(\"type\", type)\n-                                        .register(meterRegistry)\n-                                        .record(Duration.between(consensusTimestamp, Instant.now()));\n-                            }\n-                            break;\n-                        case FileDelimiter.RECORD_TYPE_SIGNATURE:\n-                            int sigLength = dis.readInt();\n-                            byte[] sigBytes = new byte[sigLength];\n-                            dis.readFully(sigBytes);\n-                            log.trace(\"File {} has signature {}\", fileName, Hex.encodeHexString(sigBytes));\n-                            break;\n-\n-                        default:\n-                            throw new ParserException(String.format(\n-                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n-                    }\n+                            recordItemListener.onItem(\n+                                    new RecordItem(transaction, txRecord, transactionRawBytes, recordRawBytes));\n+                        } finally {\n+                            // TODO: Refactor to not parse TransactionBody twice\n+                            DataCase dc = Utility.getTransactionBody(transaction).getDataCase();\n+                            String type = dc != null && dc != DataCase.DATA_NOT_SET ? dc.name() : \"UNKNOWN\";\n+                            transactionSizeMetric.tag(\"type\", type)\n+                                    .register(meterRegistry)\n+                                    .record(transactionRawBytes.length);\n+\n+                            Instant consensusTimestamp = Utility\n+                                    .convertToInstant(txRecord.getConsensusTimestamp());\n+                            transactionLatencyMetric.tag(\"type\", type)\n+                                    .register(meterRegistry)\n+                                    .record(Duration.between(consensusTimestamp, Instant.now()));\n+                        }\n+                        break;\n+                    case FileDelimiter.RECORD_TYPE_SIGNATURE:\n+                        int sigLength = dis.readInt();\n+                        byte[] sigBytes = new byte[sigLength];\n+                        dis.readFully(sigBytes);\n+                        log.trace(\"File {} has signature {}\", fileName, Hex.encodeHexString(sigBytes));\n+                        break;\n+\n+                    default:\n+                        throw new ParserException(String.format(\n+                                \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n+                }\n             }\n \n             String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MzQ2NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389773464", "bodyText": "This whole block has an extra indentation after try/catch removal.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:37:56Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NjA5NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389886095", "bodyText": "left such for easier first review since diffs are cleaner.\nre-aligning now.", "author": "apeksharma", "createdAt": "2020-03-09T18:38:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MzQ2NA=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -145,17 +140,16 @@ public class RecordFileParser implements FileParser {\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n                 ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        Optional<RecordFile> recordFile;\n-        recordFile = recordStreamFileListener.onStart(streamFileData);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n         if (recordFile.isEmpty()) {\n             return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3NTMxMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389775312", "bodyText": "This metric is now always unsuccessful since you don't set success to true.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:40:41Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {\n+            throw new ParserException(String.format(\"Error parsing record file %s after %s\", fileName, stopwatch), e);\n         } finally {\n             log.info(\"Finished parsing {} transactions from record file {} in {}\", counter, fileName, stopwatch);\n-\n             parseDurationMetric.tag(\"type\", \"record\")\n                     .tag(\"success\", success.toString())", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NzMxMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389897312", "bodyText": "ahh. fixed", "author": "apeksharma", "createdAt": "2020-03-09T18:59:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3NTMxMg=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -164,82 +158,80 @@ public class RecordFileParser implements FileParser {\n             int version = dis.readInt();\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n             while (dis.available() != 0) {\n-                    byte typeDelimiter = dis.readByte();\n-\n-                    switch (typeDelimiter) {\n-                        case FileDelimiter.RECORD_TYPE_PREV_HASH:\n-                            byte[] readFileHash = new byte[48];\n-                            dis.read(readFileHash);\n-\n-                            if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n-                                log.error(\"Previous file hash not available\");\n-                                expectedPrevFileHash = Hex.encodeHexString(readFileHash);\n+                byte typeDelimiter = dis.readByte();\n+\n+                switch (typeDelimiter) {\n+                    case FileDelimiter.RECORD_TYPE_PREV_HASH:\n+                        byte[] readFileHash = new byte[48];\n+                        dis.read(readFileHash);\n+                        String actualPrevFileHash = Hex.encodeHexString(readFileHash);\n+                        if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n+                            log.error(\"Previous file hash not available\");\n+                            expectedPrevFileHash = actualPrevFileHash;\n+                        }\n+                        log.trace(\"actual file hash = {}, expected file hash = {}\", actualPrevFileHash,\n+                                expectedPrevFileHash);\n+                        if (!actualPrevFileHash.contentEquals(expectedPrevFileHash)) {\n+                            if (applicationStatusRepository\n+                                    .findByStatusCode(ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER)\n+                                    .compareTo(Utility.getFileName(fileName)) < 0) {\n+                                // last file for which mismatch is allowed is in the past\n+                                throw new ParserException(String.format(\n+                                        \"Hash mismatch for file %s. Actual = %s, Expected = %s\",\n+                                        fileName, expectedPrevFileHash, actualPrevFileHash));\n                             }\n-\n-                            String actualPrevFileHash = Hex.encodeHexString(readFileHash);\n-                            log.trace(\"actual file hash = {}, expected file hash = {}\", actualPrevFileHash,\n-                                    expectedPrevFileHash);\n-                            if (!actualPrevFileHash.contentEquals(expectedPrevFileHash)) {\n-                                if (applicationStatusRepository\n-                                        .findByStatusCode(ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER)\n-                                        .compareTo(Utility.getFileName(fileName)) < 0) {\n-                                    // last file for which mismatch is allowed is in the past\n-                                    throw new ParserException(String.format(\n-                                            \"Hash mismatch for file %s. Actual = %s, Expected = %s\",\n-                                            fileName, expectedPrevFileHash, actualPrevFileHash));\n-                                }\n+                        }\n+                        break;\n+                    case FileDelimiter.RECORD_TYPE_RECORD:\n+                        counter++;\n+\n+                        int byteLength = dis.readInt();\n+                        byte[] transactionRawBytes = new byte[byteLength];\n+                        dis.readFully(transactionRawBytes);\n+                        Transaction transaction = Transaction.parseFrom(transactionRawBytes);\n+\n+                        byteLength = dis.readInt();\n+                        byte[] recordRawBytes = new byte[byteLength];\n+                        dis.readFully(recordRawBytes);\n+                        TransactionRecord txRecord = TransactionRecord.parseFrom(recordRawBytes);\n+\n+                        try {\n+                            if (log.isTraceEnabled()) {\n+                                log.trace(\"Transaction = {}, Record = {}\", Utility\n+                                        .printProtoMessage(transaction), Utility.printProtoMessage(txRecord));\n+                            } else {\n+                                log.debug(\"Storing transaction with consensus timestamp {}\", () -> Utility\n+                                        .printProtoMessage(txRecord.getConsensusTimestamp()));\n                             }\n-                            break;\n-                        case FileDelimiter.RECORD_TYPE_RECORD:\n-                            counter++;\n-\n-                            int byteLength = dis.readInt();\n-                            byte[] transactionRawBytes = new byte[byteLength];\n-                            dis.readFully(transactionRawBytes);\n-                            Transaction transaction = Transaction.parseFrom(transactionRawBytes);\n-\n-                            byteLength = dis.readInt();\n-                            byte[] recordRawBytes = new byte[byteLength];\n-                            dis.readFully(recordRawBytes);\n-                            TransactionRecord txRecord = TransactionRecord.parseFrom(recordRawBytes);\n-\n-                            try {\n-                                if (log.isTraceEnabled()) {\n-                                    log.trace(\"Transaction = {}, Record = {}\", Utility\n-                                            .printProtoMessage(transaction), Utility.printProtoMessage(txRecord));\n-                                } else {\n-                                    log.debug(\"Storing transaction with consensus timestamp {}\", () -> Utility\n-                                            .printProtoMessage(txRecord.getConsensusTimestamp()));\n-                                }\n \n-                                recordItemListener.onItem(\n-                                        new RecordItem(transaction, txRecord, transactionRawBytes, recordRawBytes));\n-                            } finally {\n-                                // TODO: Refactor to not parse TransactionBody twice\n-                                DataCase dc = Utility.getTransactionBody(transaction).getDataCase();\n-                                String type = dc != null && dc != DataCase.DATA_NOT_SET ? dc.name() : \"UNKNOWN\";\n-                                transactionSizeMetric.tag(\"type\", type)\n-                                        .register(meterRegistry)\n-                                        .record(transactionRawBytes.length);\n-\n-                                Instant consensusTimestamp = Utility\n-                                        .convertToInstant(txRecord.getConsensusTimestamp());\n-                                transactionLatencyMetric.tag(\"type\", type)\n-                                        .register(meterRegistry)\n-                                        .record(Duration.between(consensusTimestamp, Instant.now()));\n-                            }\n-                            break;\n-                        case FileDelimiter.RECORD_TYPE_SIGNATURE:\n-                            int sigLength = dis.readInt();\n-                            byte[] sigBytes = new byte[sigLength];\n-                            dis.readFully(sigBytes);\n-                            log.trace(\"File {} has signature {}\", fileName, Hex.encodeHexString(sigBytes));\n-                            break;\n-\n-                        default:\n-                            throw new ParserException(String.format(\n-                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n-                    }\n+                            recordItemListener.onItem(\n+                                    new RecordItem(transaction, txRecord, transactionRawBytes, recordRawBytes));\n+                        } finally {\n+                            // TODO: Refactor to not parse TransactionBody twice\n+                            DataCase dc = Utility.getTransactionBody(transaction).getDataCase();\n+                            String type = dc != null && dc != DataCase.DATA_NOT_SET ? dc.name() : \"UNKNOWN\";\n+                            transactionSizeMetric.tag(\"type\", type)\n+                                    .register(meterRegistry)\n+                                    .record(transactionRawBytes.length);\n+\n+                            Instant consensusTimestamp = Utility\n+                                    .convertToInstant(txRecord.getConsensusTimestamp());\n+                            transactionLatencyMetric.tag(\"type\", type)\n+                                    .register(meterRegistry)\n+                                    .record(Duration.between(consensusTimestamp, Instant.now()));\n+                        }\n+                        break;\n+                    case FileDelimiter.RECORD_TYPE_SIGNATURE:\n+                        int sigLength = dis.readInt();\n+                        byte[] sigBytes = new byte[sigLength];\n+                        dis.readFully(sigBytes);\n+                        log.trace(\"File {} has signature {}\", fileName, Hex.encodeHexString(sigBytes));\n+                        break;\n+\n+                    default:\n+                        throw new ParserException(String.format(\n+                                \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n+                }\n             }\n \n             String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3ODUxMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389778513", "bodyText": "Can you enhance this to not Hex.encodeHexString(readFileHash) twice if previous is empty?", "author": "steven-sheehy", "createdAt": "2020-03-09T15:45:22Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();\n \n                     switch (typeDelimiter) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4ODE1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389888153", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:42:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3ODUxMw=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex ea2ba5f01..8a9a50ab0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n\n@@ -145,17 +140,16 @@ public class RecordFileParser implements FileParser {\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n                 ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-        Optional<RecordFile> recordFile;\n-        recordFile = recordStreamFileListener.onStart(streamFileData);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n         if (recordFile.isEmpty()) {\n             return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc5MDgyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389790826", "bodyText": "Can you add a test for when processed hash is empty in db? Ops does this quite a bit to reset environments.", "author": "steven-sheehy", "createdAt": "2020-03-09T16:03:31Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -165,7 +165,9 @@ void invalidFile() throws Exception {\n         recordFileParser.parse();\n \n         // then\n-        assertNoneProcessed();\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verify(recordStreamFileListener).onError();\n     }\n ", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1NjczNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391256735", "bodyText": "discussed offline.", "author": "apeksharma", "createdAt": "2020-03-11T20:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc5MDgyNg=="}], "type": "inlineReview", "revised_code": {"commit": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "chunk": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 4404f7cec..d6c39ea96 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n\n@@ -173,21 +174,23 @@ public class RecordFileParserTest extends IntegrationTest {\n     @Test\n     void hashMismatch() throws Exception {\n         // given\n-        applicationStatusRepository.updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, \"123\");\n+        applicationStatusRepository.updateStatusValue(LAST_PROCESSED_RECORD_HASH, \"123\");\n         fileCopier.copy();\n \n         // when\n         recordFileParser.parse();\n \n         // then\n-        assertNoneProcessed();\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n     void bypassHashMismatch() throws Exception {\n         // given\n         applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER, \"2019-09-01T00:00:00.000000Z.rcd\");\n+                RECORD_HASH_MISMATCH_BYPASS_UNTIL_AFTER, \"2019-09-01T00:00:00.000000Z.rcd\");\n         fileCopier.copy();\n \n         // when\n"}}, {"oid": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-11T21:08:15Z", "type": "commit"}, {"oid": "e556179de4e99e8077a60a7fb380bf8504b3a703", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e556179de4e99e8077a60a7fb380bf8504b3a703", "message": "add @cacheput\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-11T22:20:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTYzMTA3OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391631079", "bodyText": "This section seems like one of those bloated sections. It's not easy to get a view of all that needs to be done and it's not possible to test each case separately.\nCould we make each case call a method that handles the given scenario (e.g. readPreviousHash(), readRecord()/readTransaction() and readSignature()).\nThese are then more isolated and can be tested and more easily managed.", "author": "Nana-EC", "createdAt": "2020-03-12T13:47:07Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,125 +138,105 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n-        Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n+        if (recordFile.isEmpty()) {\n+            return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n-                    byte typeDelimiter = dis.readByte();\n-\n-                    switch (typeDelimiter) {\n-                        case FileDelimiter.RECORD_TYPE_PREV_HASH:\n-                            byte[] readFileHash = new byte[48];\n-                            dis.read(readFileHash);\n-\n-                            if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n-                                log.error(\"Previous file hash not available\");\n-                                expectedPrevFileHash = Hex.encodeHexString(readFileHash);\n+                byte typeDelimiter = dis.readByte();\n+\n+                switch (typeDelimiter) {", "originalCommit": "e556179de4e99e8077a60a7fb380bf8504b3a703", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc3MTY3NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391771675", "bodyText": "yes, and share them, i think this piece of code is partially duplicated in some other place too.\nTried not doing those in this PR though - keep changes small for faster easier reviews & quick progress (although that doesn't seem to be working).\nAbout your suggestion, yes, in one of the followup changes.", "author": "apeksharma", "createdAt": "2020-03-12T17:16:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTYzMTA3OQ=="}], "type": "inlineReview", "revised_code": null}]}