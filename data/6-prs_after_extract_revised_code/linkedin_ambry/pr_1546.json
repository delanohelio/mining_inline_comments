{"pr_number": 1546, "pr_title": "Core changes of leader based replication. ", "pr_createdAt": "2020-06-02T05:27:26Z", "pr_url": "https://github.com/linkedin/ambry/pull/1546", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY3MjU3Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r434672573", "bodyText": "Are these instanceof checks needed? Maybe the ReplicationEngine implementation can check during construction if LEADER_BASED replication is supported and throw an exception if it is misconfigured.", "author": "cgtz", "createdAt": "2020-06-03T15:52:37Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -459,8 +483,11 @@ public void replicate() {\n             // Skip stores that were stopped during call to getReplicaMetadataResponse\n             if (!remoteReplicaInfo.getLocalStore().isStarted()) {\n               exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-              remoteReplicaInfo.setExchangeMetadataResponse(\n-                  new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+              if (replicatingFromRemoteColo && replicationConfig.replicationModelType.equals(\n+                  ReplicationModelType.LEADER_BASED) && replicationEngine instanceof ReplicationManager) {", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex add599d55..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -483,8 +515,7 @@ public class ReplicaThread implements Runnable {\n             // Skip stores that were stopped during call to getReplicaMetadataResponse\n             if (!remoteReplicaInfo.getLocalStore().isStarted()) {\n               exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-              if (replicatingFromRemoteColo && replicationConfig.replicationModelType.equals(\n-                  ReplicationModelType.LEADER_BASED) && replicationEngine instanceof ReplicationManager) {\n+              if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n                 remoteReplicaInfo.setExchangeMetadataResponse(\n                     new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n               }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTE3NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435685174", "bodyText": "Why this is a readLock? I think it's supposed to be writeLock.", "author": "jsjtzyy", "createdAt": "2020-06-05T04:35:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java", "diffHunk": "@@ -105,6 +106,24 @@ RemoteReplicaInfo removeReplicaInfoIfPresent(ReplicaId remoteReplica) {\n     return replicaInfoToRemove;\n   }\n \n+  /**\n+   * Go through remote replicas of this partition and compare the messages written to store with messages\n+   * found missing during the previous replication cycle. This is used during leader-based replication where missing\n+   * store messages found in metadata exchange are not fetched for non-leader remote replicas in cross colo\n+   * data centers. Instead, we wait for them to come from intra-dc replication.\n+   * @param messageInfoList list of messages written to local store.\n+   */\n+  void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTUxMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435685511", "bodyText": "nvm,  readLock is probably ok here.", "author": "jsjtzyy", "createdAt": "2020-06-05T04:37:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTE3NA=="}], "type": "inlineReview", "revised_code": {"commit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\nindex 8a7e124a6..f5fb1bbe3 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\n\n@@ -116,7 +116,7 @@ public class PartitionInfo {\n   void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n     rwLock.readLock().lock();\n     try {\n-      for(RemoteReplicaInfo remoteReplicaInfo : remoteReplicas){\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicas) {\n         remoteReplicaInfo.compareAndRemoveMissingStoreMessages(messageInfoList);\n       }\n     } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4ODIzNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435688235", "bodyText": "minor: can use exchangeMetadataResponse.missingStoreMessages.isEmpty()", "author": "jsjtzyy", "createdAt": "2020-06-05T04:49:52Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -222,9 +242,104 @@ public boolean equals(Object obj) {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // and replica threads updating missing store messages in compareAndRemoveMissingStoreMessages() after they are\n+    // written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in exchangeMetadataResponse are written to store by parallel replica\n+    // threads between the time exchangeMetadataResponse is calculated and set here. So, we look up the local store\n+    // again and remove messages that are now found from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * checks if the metadata response for this replica is empty or if there are no missing store keys present in it.\n+   * If this replica is a non-leader in remote colo and leader-based replication is enabled, replica threads will not\n+   * send next metadata request for it until all missing keys in this metadata response come via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.size() == 0;", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 0004229bb..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -236,91 +238,95 @@ public class RemoteReplicaInfo {\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in compareAndRemoveMissingStoreMessages() after they are\n-    // written to local store via intra-dc replication.\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n-    // It is possible that missing store messages in exchangeMetadataResponse are written to store by parallel replica\n-    // threads between the time exchangeMetadataResponse is calculated and set here. So, we look up the local store\n-    // again and remove messages that are now found from exchangeMetadataResponse.missingStoreMessages set.\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n     compareAndRemoveMissingStoreMessages(null);\n   }\n \n   /**\n-   * checks if the metadata response for this replica is empty or if there are no missing store keys present in it.\n-   * If this replica is a non-leader in remote colo and leader-based replication is enabled, replica threads will not\n-   * send next metadata request for it until all missing keys in this metadata response come via intra-dc replication.\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n    * @return true if metadata response is empty (null) or there are no missing store keys in it.\n    */\n   synchronized boolean isExchangeMetadataResponseEmpty() {\n     return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n-        || exchangeMetadataResponse.missingStoreMessages.size() == 0;\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n   }\n \n   /**\n-   * Compare messages written to local store with missing store messages found during the previous replication cycle\n-   * for this replica. If there are matching messages (based on store key), compare the blob metadata and apply\n-   * delete, ttl-update and un-delete if needed and remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n-   * When all the missing store messages are found written, update the current token with exchangeMetadataResponse.remoteToken.\n+   * Check if missing store messages for this replica (cached in previous replication cycle) are now found in store by\n+   * comparing with list of messages that are recently added to store (input param: messagesWrittenToStore). If input\n+   * list 'messagesWrittenToStore' is not provided, check for missing messages by directly looking into store.\n+   * If there are matching messages (based on store key), do the following:\n+   *    1. Compare blob metadata in local store with cached remote message info and reconcile ttl-update, delete and un-delete states.\n+   *    2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *    3. When all the missing store messages are found in store, move the token forward.\n    * @param messagesWrittenToStore list of messages written to local store\n    */\n   synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n-    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null) {\n       try {\n-        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n-\n-        //convert remote keys to local keys\n-        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n-            .map(MessageInfo::getStoreKey)\n-            .collect(Collectors.toList());\n-        storeKeyConverter.dropCache();\n-        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n-\n-        // If we are provided with list of messages written to store, check if previously stored missing messages\n-        // are found in them\n+        List<MessageInfo> missingMessagesFoundInStore = new ArrayList<>();\n         if (messagesWrittenToStore != null) {\n+          // Check if missing messages for this replica are now found to store by comparing with\n+          // messages provided in input parameter.\n           Set<StoreKey> keysWrittenToStore =\n               messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n           for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n             if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n-              messagesFoundInStore.add(messageInfo);\n+              missingMessagesFoundInStore.add(messageInfo);\n             }\n           }\n         } else {\n-          // This is hit when we call compareAndRemoveMissingStoreMessages() during setExchangeMetadataResponse(). It is\n-          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n-          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n-          // again to find if any missing messages are written.\n+          // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n+          // by doing findMissingKeys() operation on store.\n+          // Use case: While replica thread for this replica is storing the metadata response with missing key information,\n+          // it is possible that some of the missing keys are written to store by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, if there are missing keys available in local store again.\n+\n           Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n           for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n-            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n             if (convertedKey != null) {\n               remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n             }\n           }\n+\n+          // Find the set of keys that are still missing in the store\n           Set<StoreKey> convertedMissingStoreKeys =\n               localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+\n+          // Filter the remote messages whose keys are now found in store, i.e. not present in convertedMissingStoreKeys set.\n           remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n             if (!convertedMissingStoreKeys.contains(convertedKey)) {\n-              messagesFoundInStore.add(messageInfo);\n+              missingMessagesFoundInStore.add(messageInfo);\n             }\n           });\n         }\n \n-        // Go through the messages found in store and re-apply any blob properties (delete, ttl-update and un-delete)\n-        // and delete them from the missingStoreMessages set. If the set becomes empty, move the token forward.\n-        for (MessageInfo messageInfo : messagesFoundInStore) {\n-          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : missingMessagesFoundInStore) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n \n-          // 1. compare blob metadata with the cached remote message info and apply delete, ttl-update and un-delete if needed\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n           if (localStoreKey != null) {\n-            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+            replicaThread.applyUpdatesToBlobInLocalStore(messageInfo, this, localStoreKey);\n           }\n \n           // 2. remove found message from the missing set\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4ODU3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435688571", "bodyText": "nit: format this file", "author": "jsjtzyy", "createdAt": "2020-06-05T04:51:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java", "diffHunk": "@@ -105,6 +106,24 @@ RemoteReplicaInfo removeReplicaInfoIfPresent(ReplicaId remoteReplica) {\n     return replicaInfoToRemove;\n   }\n \n+  /**\n+   * Go through remote replicas of this partition and compare the messages written to store with messages\n+   * found missing during the previous replication cycle. This is used during leader-based replication where missing\n+   * store messages found in metadata exchange are not fetched for non-leader remote replicas in cross colo\n+   * data centers. Instead, we wait for them to come from intra-dc replication.\n+   * @param messageInfoList list of messages written to local store.\n+   */\n+  void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();\n+    try {\n+      for(RemoteReplicaInfo remoteReplicaInfo : remoteReplicas){", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\nindex 8a7e124a6..f5fb1bbe3 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java\n\n@@ -116,7 +116,7 @@ public class PartitionInfo {\n   void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n     rwLock.readLock().lock();\n     try {\n-      for(RemoteReplicaInfo remoteReplicaInfo : remoteReplicas){\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicas) {\n         remoteReplicaInfo.compareAndRemoveMissingStoreMessages(messageInfoList);\n       }\n     } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5MTEyNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435691125", "bodyText": "You need to check if partitionInfo == null here,  it's possible partition is being concurrently removed from this node", "author": "jsjtzyy", "createdAt": "2020-06-05T05:02:22Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -503,4 +507,23 @@ protected void stopPartitionReplication(PartitionId partitionId) {\n       }\n     }\n   }\n+\n+  /**\n+   * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+   * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+   * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+   * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+   * missing messages are written to store.\n+   * @param partitionId partition ID of the messages written to store\n+   * @param messageInfoList list of messages written to store\n+   */\n+  void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();\n+    try {\n+      PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+      partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\nindex 4addd80e4..ff14376d5 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n\n@@ -507,23 +549,4 @@ public abstract class ReplicationEngine implements ReplicationAPI {\n       }\n     }\n   }\n-\n-  /**\n-   * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n-   * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n-   * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n-   * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n-   * missing messages are written to store.\n-   * @param partitionId partition ID of the messages written to store\n-   * @param messageInfoList list of messages written to store\n-   */\n-  void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n-    rwLock.readLock().lock();\n-    try {\n-      PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n-      partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n-    } finally {\n-      rwLock.readLock().unlock();\n-    }\n-  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435699115", "bodyText": "We probably don't need to pass in ReplicationEngine, instead we can pass in something like leaderBasedReplicationTracker or leaderBasedReplicationCoordinator or leaderBasedReplicationAdmin that helps to coordinate/update info across replication threads. The component is instantiated only when model == ReplicationModelType.LEADER_BASED. Thus, we can check if this component is null and don't have to check many other things like line350~351", "author": "jsjtzyy", "createdAt": "2020-06-05T05:35:39Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -122,15 +123,16 @@ public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, Cluster\n       ReplicaSyncUpManager replicaSyncUpManager) {\n     this(threadName, findTokenHelper, clusterMap, correlationIdGenerator, dataNodeId, connectionPool, replicationConfig,\n         replicationMetrics, notification, storeKeyConverter, transformer, metricRegistry, replicatingOverSsl,\n-        datacenterName, responseHandler, time, replicaSyncUpManager, null);\n+        datacenterName, responseHandler, time, replicaSyncUpManager, null, null);\n   }\n \n   public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, ClusterMap clusterMap,\n       AtomicInteger correlationIdGenerator, DataNodeId dataNodeId, ConnectionPool connectionPool,\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo) {\n+      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo,\n+      ReplicationEngine replicationEngine) {", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyMzc0Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436023746", "bodyText": "If we decide to pass in a component rather than ReplicationEngine, we can even move the method onMessageWriteForPartition() from ReplicationEngine to ReplicationManager (for better isolation). The component should be simple and lightweight, which is an inner class like ClusterMapChangeListenerImpl and PartitionStateChangeListenerImpl, what do you think?", "author": "jsjtzyy", "createdAt": "2020-06-05T16:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3ODQ4Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436078483", "bodyText": "cc @cgtz  because you have a similar comment. Feel free to offer your insights here.", "author": "jsjtzyy", "createdAt": "2020-06-05T18:00:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex add599d55..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -111,19 +112,19 @@ public class ReplicaThread implements Runnable {\n   private final Condition pauseCondition = lock.newCondition();\n   private final ReplicaSyncUpManager replicaSyncUpManager;\n   private final int maxReplicaCountPerRequest;\n+  private final Predicate skipPredicate;\n   private volatile boolean allDisabled = false;\n-  private final PartitionLeaderInfo partitionLeaderInfo;\n-  private final ReplicationEngine replicationEngine;\n+  private final ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin;\n \n   public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, ClusterMap clusterMap,\n       AtomicInteger correlationIdGenerator, DataNodeId dataNodeId, ConnectionPool connectionPool,\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager) {\n+      ReplicaSyncUpManager replicaSyncUpManager, Predicate skipPredicate) {\n     this(threadName, findTokenHelper, clusterMap, correlationIdGenerator, dataNodeId, connectionPool, replicationConfig,\n         replicationMetrics, notification, storeKeyConverter, transformer, metricRegistry, replicatingOverSsl,\n-        datacenterName, responseHandler, time, replicaSyncUpManager, null, null);\n+        datacenterName, responseHandler, time, replicaSyncUpManager, skipPredicate, null);\n   }\n \n   public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, ClusterMap clusterMap,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MTc1NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436441755", "bodyText": "To align with naming convention in this file, could you rename the config name of ReplicationModelType?\npublic final ReplicationModelType replicationModelAcrossDatacenters;", "author": "jsjtzyy", "createdAt": "2020-06-08T03:31:40Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -202,6 +202,14 @@\n   @Default(\"false\")\n   public final boolean replicationEnableHttp2;\n \n+  /**", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\nindex 518c82358..090560164 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n\n@@ -203,12 +203,31 @@ public class ReplicationConfig {\n   public final boolean replicationEnableHttp2;\n \n   /**\n-   * The time (in ms) to wait before doing cross colo fetch for standby replicas.\n-   * This is applicable if leader based replication is enabled.\n+   * How long (in days) a container must be replicated before it's been deleted during compaction.\n    */\n-  @Config(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\")\n-  @Default(\"5000\")\n-  public final long replicationWaitTimeForCrossColoFetchForStandbyReplicasMs;\n+  @Config(\"replication.container.deletion.retention.days\")\n+  @Default(\"14\")\n+  public final int replicationContainerDeletionRetentionDays;\n+\n+  /**\n+   * True to enable skip deprecated containers in replication.\n+   */\n+  @Config(\"replication.container.deletion.enabled\")\n+  @Default(\"false\")\n+  public final boolean replicationContainerDeletionEnabled;\n+\n+  /**\n+   * The time (in seconds) for standby replicas to wait before fetching missing keys from replicas in cross colo\n+   * data centers. This is applicable during leader based replication where standby replicas don't fetch the missing\n+   * keys found in metadata exchange from cross colo replicas and expect them to come from leader replica in\n+   * local data center via intra-dc replication. This time out ensures that standby replicas are not stuck indefinitely\n+   * waiting for the missing keys to come via intra-dc replication by doing cross colo fetch themselves.\n+   * Default value is 120 seconds. If configured to -1, this timeout doesn't take effect, i.e. cross colo fetch for\n+   * standby replicas is never done.\n+   */\n+  @Config(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\")\n+  @Default(\"120\")\n+  public final int replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds;\n \n   public ReplicationConfig(VerifiableProperties verifiableProperties) {\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0Mjk3Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436442976", "bodyText": "Can we rename this to \"replication.standby.wait.timeout.to.tigger.cross.colo.fetch.second\"?\nCan we use second as time unit? 5000 ms is a little short, I would suggest 120 secs (2min)\n(Also, could you elaborate a little more about the purpose to introduce such timeout? It's better to present more context in the comment.)", "author": "jsjtzyy", "createdAt": "2020-06-08T03:39:26Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -202,6 +202,14 @@\n   @Default(\"false\")\n   public final boolean replicationEnableHttp2;\n \n+  /**\n+   * The time (in ms) to wait before doing cross colo fetch for standby replicas.\n+   * This is applicable if leader based replication is enabled.\n+   */\n+  @Config(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\")\n+  @Default(\"5000\")\n+  public final long replicationWaitTimeForCrossColoFetchForStandbyReplicasMs;", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\nindex 518c82358..090560164 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n\n@@ -203,12 +203,31 @@ public class ReplicationConfig {\n   public final boolean replicationEnableHttp2;\n \n   /**\n-   * The time (in ms) to wait before doing cross colo fetch for standby replicas.\n-   * This is applicable if leader based replication is enabled.\n+   * How long (in days) a container must be replicated before it's been deleted during compaction.\n    */\n-  @Config(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\")\n-  @Default(\"5000\")\n-  public final long replicationWaitTimeForCrossColoFetchForStandbyReplicasMs;\n+  @Config(\"replication.container.deletion.retention.days\")\n+  @Default(\"14\")\n+  public final int replicationContainerDeletionRetentionDays;\n+\n+  /**\n+   * True to enable skip deprecated containers in replication.\n+   */\n+  @Config(\"replication.container.deletion.enabled\")\n+  @Default(\"false\")\n+  public final boolean replicationContainerDeletionEnabled;\n+\n+  /**\n+   * The time (in seconds) for standby replicas to wait before fetching missing keys from replicas in cross colo\n+   * data centers. This is applicable during leader based replication where standby replicas don't fetch the missing\n+   * keys found in metadata exchange from cross colo replicas and expect them to come from leader replica in\n+   * local data center via intra-dc replication. This time out ensures that standby replicas are not stuck indefinitely\n+   * waiting for the missing keys to come via intra-dc replication by doing cross colo fetch themselves.\n+   * Default value is 120 seconds. If configured to -1, this timeout doesn't take effect, i.e. cross colo fetch for\n+   * standby replicas is never done.\n+   */\n+  @Config(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\")\n+  @Default(\"120\")\n+  public final int replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds;\n \n   public ReplicationConfig(VerifiableProperties verifiableProperties) {\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MzUwMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436443500", "bodyText": "Can we use -1 to represent no timeout?", "author": "jsjtzyy", "createdAt": "2020-06-08T03:42:20Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -247,5 +255,8 @@ public ReplicationConfig(VerifiableProperties verifiableProperties) {\n     replicationModelType = ReplicationModelType.valueOf(\n         verifiableProperties.getString(\"replication.model.across.datacenters\", ReplicationModelType.ALL_TO_ALL.name()));\n     replicationEnableHttp2 = verifiableProperties.getBoolean(\"replication.enable.http2\", false);\n+    replicationWaitTimeForCrossColoFetchForStandbyReplicasMs =\n+        verifiableProperties.getLongInRange(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\", 5000,\n+            0, Long.MAX_VALUE);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\nindex 518c82358..090560164 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n\n@@ -252,11 +271,15 @@ public class ReplicationConfig {\n     replicationEnabledWithVcrCluster = verifiableProperties.getBoolean(\"replication.enabled.with.vcr.cluster\", false);\n     String vcrRecoveryPartitions = verifiableProperties.getString(\"replication.vcr.recovery.partitions\", \"\");\n     replicationVcrRecoveryPartitions = Utils.splitString(vcrRecoveryPartitions, \",\", HashSet::new);\n-    replicationModelType = ReplicationModelType.valueOf(\n+    replicationModelAcrossDatacenters = ReplicationModelType.valueOf(\n         verifiableProperties.getString(\"replication.model.across.datacenters\", ReplicationModelType.ALL_TO_ALL.name()));\n     replicationEnableHttp2 = verifiableProperties.getBoolean(\"replication.enable.http2\", false);\n-    replicationWaitTimeForCrossColoFetchForStandbyReplicasMs =\n-        verifiableProperties.getLongInRange(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\", 5000,\n-            0, Long.MAX_VALUE);\n+    replicationContainerDeletionRetentionDays =\n+        verifiableProperties.getInt(\"replication.container.deletion.retention.days\", 14);\n+    replicationContainerDeletionEnabled =\n+        verifiableProperties.getBoolean(\"replication.container.deletion.enabled\", false);\n+    replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds =\n+        verifiableProperties.getIntInRange(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\", 120,\n+            -1, Integer.MAX_VALUE);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1NDEyOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436454129", "bodyText": "typo: occurred", "author": "jsjtzyy", "createdAt": "2020-06-08T04:43:02Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,\n+                replicaId.getDataNodeId());\n+\n+            exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+\n+            break;\n+          }\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occured while updating exchangeMetadataResponse for Remote replica: {}\", replicaId, e);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1OTk3NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436459975", "bodyText": "Do we need to execute this piece of code every time compareAndRemoveMissingStoreMessages is called? Can we cache the converted result?", "author": "jsjtzyy", "createdAt": "2020-06-08T05:11:58Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwMjU1NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439102555", "bodyText": "Yeah, we don't need to execute this code to convert remote keys (of stored missing message infos) to local keys every time as it is duplicate work. Made changes to store the remoteKeyToLocalKeyMap along with missing message information in the ExchangeMetadataResponse itself.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1OTk3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NDM4Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436464383", "bodyText": "add a log here as well for debugging purpose", "author": "jsjtzyy", "createdAt": "2020-06-08T05:31:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,\n+                replicaId.getDataNodeId());\n+\n+            exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+\n+            break;\n+          }\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occured while updating exchangeMetadataResponse for Remote replica: {}\", replicaId, e);\n+        // reset stored metadata response so that metadata request is sent again for this replica\n+        exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+      }\n+    } else {\n+      // reset stored metadata response so that metadata request is sent again for this replica", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyMjQwNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439922404", "bodyText": "and also I wonder in which case this else branch will happen?", "author": "jsjtzyy", "createdAt": "2020-06-15T04:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NDM4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTIxNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436465215", "bodyText": "if the messageInfo is a PUT, can we skip applyUpdatesOnLocalStoreKey?", "author": "jsjtzyy", "createdAt": "2020-06-08T05:35:17Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwNzQzMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439107430", "bodyText": "Sure, we can skip applying updates (ttlupdate, delete or undelete) to blob in local store if received message info is a PUT.  But, I am just thinking if is safe to leave as it is to have this operation identical to what we do in processReplicaMetadataResponse() when messages received in metadata response are found in local store.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:33:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTIxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTY5Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436465692", "bodyText": "A general question: how do we deal with several messages associated with same key? (i.e. during on replication cycle, we have both PUT and DELETE message associated with certain blob id)", "author": "jsjtzyy", "createdAt": "2020-06-08T05:37:13Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIxNTc5OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439215798", "bodyText": "It seems like in a given metadata response, if there are several messages associated with same key in remote node, we get a consolidated/merged message info reflecting its latest value. For example, if we find both PUT and DELETE for same blob id, we only get DELETE. Similarly, if we find PUT and TTLUPDATE, we get one message info with TTL field updated to PUT message. Please correct me in case I am wrong here.\nJust wanted to note that I just separated code to apply ttlupdate/delete/undelete that we do currently in processReplicaMetadataResponse() when we find a key in local store during metadata exchange to the method 'applyUpdatesToBlobInLocalStore()' in order to reapply the same logic when we find key later in this case.", "author": "Arun-LinkedIn", "createdAt": "2020-06-12T05:35:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTY5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDU1MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r437684551", "bodyText": "newly to new", "author": "cgtz", "createdAt": "2020-06-09T20:01:34Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzNjE0NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438236145", "bodyText": "exiting -> existing?", "author": "cgtz", "createdAt": "2020-06-10T16:00:18Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 82389f2a1..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -241,7 +243,7 @@ public class RemoteReplicaInfo {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n     // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI0NDA2OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438244068", "bodyText": "Since ReplicationManager extends ReplicationEngine, it seems more natural to either move LeaderBasedReplicationAdmin to ReplicationEngine or have it in its own file", "author": "cgtz", "createdAt": "2020-06-10T16:10:35Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -302,26 +335,32 @@ private int getReplicaThreadIndexToUse(String datacenter) {\n    * Get thread pool for given datacenter. Create thread pool for a datacenter if its thread pool doesn't exist.\n    * @param datacenter The datacenter String.\n    * @param startThread If thread needs to be started when create.\n+   * @param leaderBasedReplicationAdmin to co-ordinate replication between leader and standby replicas of a partition\n+   *                                    during leader based replication.\n    * @return List of {@link ReplicaThread}s. Return null if number of replication thread in config is 0 for this DC.\n    */\n-  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread) {\n+  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin) {\n     int numOfThreadsInPool =\n         datacenter.equals(dataNodeId.getDatacenterName()) ? replicationConfig.replicationNumOfIntraDCReplicaThreads\n             : replicationConfig.replicationNumOfInterDCReplicaThreads;\n     if (numOfThreadsInPool <= 0) {\n       return null;\n     }\n     return replicaThreadPoolByDc.computeIfAbsent(datacenter,\n-        key -> createThreadPool(datacenter, numOfThreadsInPool, startThread));\n+        key -> createThreadPool(datacenter, numOfThreadsInPool, startThread, leaderBasedReplicationAdmin));\n   }\n \n   /**\n    * Create thread pool for a datacenter.\n    * @param datacenter The datacenter String.\n    * @param numberOfThreads Number of threads to create for the thread pool.\n    * @param startThread If thread needs to be started when create.\n+   * @param leaderBasedReplicationAdmin to co-ordinate replication between leader and standby replicas of a partition\n+   *                                    during leader based replication.\n    */\n-  private List<ReplicaThread> createThreadPool(String datacenter, int numberOfThreads, boolean startThread) {\n+  private List<ReplicaThread> createThreadPool(String datacenter, int numberOfThreads, boolean startThread,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin) {", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\nindex 9f400b5a1..d2189b50f 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n\n@@ -335,12 +330,9 @@ public abstract class ReplicationEngine implements ReplicationAPI {\n    * Get thread pool for given datacenter. Create thread pool for a datacenter if its thread pool doesn't exist.\n    * @param datacenter The datacenter String.\n    * @param startThread If thread needs to be started when create.\n-   * @param leaderBasedReplicationAdmin to co-ordinate replication between leader and standby replicas of a partition\n-   *                                    during leader based replication.\n    * @return List of {@link ReplicaThread}s. Return null if number of replication thread in config is 0 for this DC.\n    */\n-  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread,\n-      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin) {\n+  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread) {\n     int numOfThreadsInPool =\n         datacenter.equals(dataNodeId.getDatacenterName()) ? replicationConfig.replicationNumOfIntraDCReplicaThreads\n             : replicationConfig.replicationNumOfInterDCReplicaThreads;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5NjI1Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438896252", "bodyText": "swallowing this exception means that one may end up with a partial list of remoteReplicaInfos. Is that ok for the callers of this method?", "author": "cgtz", "createdAt": "2020-06-11T15:56:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -210,20 +229,27 @@ public boolean removeReplica(ReplicaId replicaId) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    for (ReplicaId remoteReplica : peerReplicas) {\n-      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-      // to determine the token flush interval\n-      FindToken findToken =\n-          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n-      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-      remoteReplicaInfos.add(remoteReplicaInfo);\n-    }\n-    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-      replicationMetrics.addLagMetricForPartition(partition);\n+    try {\n+      for (ReplicaId remoteReplica : peerReplicas) {\n+        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+        // to determine the token flush interval\n+        FindToken findToken =\n+            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+        RemoteReplicaInfo remoteReplicaInfo = null;\n+        remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n+            TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+            SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo(),\n+            storeKeyConverterFactory.getStoreKeyConverter());\n+\n+        replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n+        remoteReplicaInfos.add(remoteReplicaInfo);\n+      }\n+      if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n+        replicationMetrics.addLagMetricForPartition(partition);\n+      }\n+    } catch (Exception e) {\n+      logger.error(\"Encountered exception instantiating RemoteReplicaInfos\", e);", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwMTEwMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439101102", "bodyText": "Sure, you are right, may be it is not ok to end up with partial list of remoteReplicaInfos. Removed try/catch block for handling the exception now. Previously, added this to handle exception from instantiation of StoreKeyConverter object being passed (added in this PR) to RemoteReplicaInfo constructor. Made changes to avoid passing StoreKeyConverter to RemoteReplicaInfo and instead directly store the converted keys in RemoteReplicaInfo.exchageMetadataResponse.remoteKeyToLocalKeyMap.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5NjI1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 06c3fc3a0..5b9dcc900 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -229,27 +233,21 @@ public class ReplicationManager extends ReplicationEngine {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    try {\n-      for (ReplicaId remoteReplica : peerReplicas) {\n-        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-        // to determine the token flush interval\n-        FindToken findToken =\n-            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-        RemoteReplicaInfo remoteReplicaInfo = null;\n-        remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-            TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-            SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo(),\n-            storeKeyConverterFactory.getStoreKeyConverter());\n-\n-        replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-        remoteReplicaInfos.add(remoteReplicaInfo);\n-      }\n-      if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-        replicationMetrics.addLagMetricForPartition(partition);\n-      }\n-    } catch (Exception e) {\n-      logger.error(\"Encountered exception instantiating RemoteReplicaInfos\", e);\n+    for (ReplicaId remoteReplica : peerReplicas) {\n+      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+      // to determine the token flush interval\n+      FindToken findToken =\n+          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n+          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+\n+      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n+      remoteReplicaInfos.add(remoteReplicaInfo);\n+    }\n+    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n+      replicationMetrics.addLagMetricForPartition(partition);\n     }\n     return remoteReplicaInfos;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5ODI2NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438898264", "bodyText": "looks like this line isn't needed: remoteReplicaInfo = null; remoteReplicaInfo = ...; -> remoteReplicaInfo = ...", "author": "cgtz", "createdAt": "2020-06-11T15:59:23Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -210,20 +229,27 @@ public boolean removeReplica(ReplicaId replicaId) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    for (ReplicaId remoteReplica : peerReplicas) {\n-      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-      // to determine the token flush interval\n-      FindToken findToken =\n-          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n-      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-      remoteReplicaInfos.add(remoteReplicaInfo);\n-    }\n-    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-      replicationMetrics.addLagMetricForPartition(partition);\n+    try {\n+      for (ReplicaId remoteReplica : peerReplicas) {\n+        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+        // to determine the token flush interval\n+        FindToken findToken =\n+            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+        RemoteReplicaInfo remoteReplicaInfo = null;", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 06c3fc3a0..5b9dcc900 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -229,27 +233,21 @@ public class ReplicationManager extends ReplicationEngine {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    try {\n-      for (ReplicaId remoteReplica : peerReplicas) {\n-        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-        // to determine the token flush interval\n-        FindToken findToken =\n-            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-        RemoteReplicaInfo remoteReplicaInfo = null;\n-        remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-            TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-            SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo(),\n-            storeKeyConverterFactory.getStoreKeyConverter());\n-\n-        replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-        remoteReplicaInfos.add(remoteReplicaInfo);\n-      }\n-      if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-        replicationMetrics.addLagMetricForPartition(partition);\n-      }\n-    } catch (Exception e) {\n-      logger.error(\"Encountered exception instantiating RemoteReplicaInfos\", e);\n+    for (ReplicaId remoteReplica : peerReplicas) {\n+      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+      // to determine the token flush interval\n+      FindToken findToken =\n+          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n+          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n+\n+      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n+      remoteReplicaInfos.add(remoteReplicaInfo);\n+    }\n+    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n+      replicationMetrics.addLagMetricForPartition(partition);\n     }\n     return remoteReplicaInfos;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkwMTUyMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438901522", "bodyText": "Could PartitionLeaderInfo be compressed into LeaderBasedReplicationAdmin unless there is a future use case for PLI to be used separately from LBRA? It seems like most methods of LBRA just call the similarly named method of PLI.", "author": "cgtz", "createdAt": "2020-06-11T16:04:39Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -451,4 +487,197 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    LeaderBasedReplicationAdmin() {\n+      partitionLeaderInfo = new PartitionLeaderInfo();\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.addPartition(partitionName);\n+    }\n+\n+    /**\n+     * Remove a leader partition from the map of leader partitions.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.removePartition(partitionName);\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      partitionLeaderInfo.refreshPeerLeadersForAllPartitions();\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return partitionLeaderInfo.getPeerLeaderReplicasByPartition();\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     * @param partitionName name of local leader partition\n+     * @param replicaId remote replica to be checked\n+     * @return true if remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     */\n+    public boolean isPeerReplicaLeaderForPartition(String partitionName, ReplicaId replicaId) {\n+      return partitionLeaderInfo.isPeerReplicaLeaderForPartition(partitionName, replicaId);\n+    }\n+\n+    /**\n+     * Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+     */\n+    class PartitionLeaderInfo {", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNTg3Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439935873", "bodyText": "Sure, compressed PartitionLeaderInfo into LeaderBasedReplicationAdmin.", "author": "Arun-LinkedIn", "createdAt": "2020-06-15T05:22:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkwMTUyMg=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 06c3fc3a0..5b9dcc900 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -492,10 +487,15 @@ public class ReplicationManager extends ReplicationEngine {\n    * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n    */\n   class LeaderBasedReplicationAdmin {\n-    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n \n     LeaderBasedReplicationAdmin() {\n-      partitionLeaderInfo = new PartitionLeaderInfo();\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxNzQ3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438917471", "bodyText": "It looks like refreshPeerLeadersForAllPartitions has a slightly different way of building the set of peerLeaderReplicas. Could both of these methods use the same approach (whichever one you prefer)?", "author": "cgtz", "createdAt": "2020-06-11T16:29:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -451,4 +487,197 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    LeaderBasedReplicationAdmin() {\n+      partitionLeaderInfo = new PartitionLeaderInfo();\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.addPartition(partitionName);\n+    }\n+\n+    /**\n+     * Remove a leader partition from the map of leader partitions.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.removePartition(partitionName);\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      partitionLeaderInfo.refreshPeerLeadersForAllPartitions();\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return partitionLeaderInfo.getPeerLeaderReplicasByPartition();\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     * @param partitionName name of local leader partition\n+     * @param replicaId remote replica to be checked\n+     * @return true if remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     */\n+    public boolean isPeerReplicaLeaderForPartition(String partitionName, ReplicaId replicaId) {\n+      return partitionLeaderInfo.isPeerReplicaLeaderForPartition(partitionName, replicaId);\n+    }\n+\n+    /**\n+     * Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+     */\n+    class PartitionLeaderInfo {\n+\n+      private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+      private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+      public PartitionLeaderInfo() {\n+\n+        // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+        // on local server until it has finished participating with Helix. It will be updated after server participates\n+        // with Helix and receives LEADER transition (via onPartitionBecomeLeaderFromStandby()).\n+      }\n+\n+      /**\n+       * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+       * @return an unmodifiable map of peer leader replicas stored by partition\n+       */\n+      public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+        return Collections.unmodifiableMap(peerLeaderReplicasByPartition);\n+      }\n+\n+      /**\n+       * Add a leader partition and its set of peer leader replicas. This method is thread safe.\n+       * @param partitionName name of the partition to be added\n+       */\n+      public void addPartition(String partitionName) {\n+\n+        // 1. get local replica from store manager\n+        ReplicaId localReplica = storeManager.getReplica(partitionName);\n+\n+        // Read-write lock avoids contention from threads removing old leader partitions (removePartition()) and\n+        // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+        rwLockForLeaderReplicaUpdates.writeLock().lock();\n+        try {\n+          // 2. Get the peer leader replicas from all data centers for this partition\n+          List<? extends ReplicaId> leaderReplicas =\n+              localReplica.getPartitionId().getReplicaIdsByState(ReplicaState.LEADER, null);\n+\n+          // 3. Collect and log the list of peer leader replicas associated with this partition\n+          Set<ReplicaId> peerLeaderReplicas = new HashSet<>();", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNjExNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439936116", "bodyText": "Yeah, true. Made changes to keep the approach same in both methods.", "author": "Arun-LinkedIn", "createdAt": "2020-06-15T05:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxNzQ3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 06c3fc3a0..5b9dcc900 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -492,10 +487,15 @@ public class ReplicationManager extends ReplicationEngine {\n    * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n    */\n   class LeaderBasedReplicationAdmin {\n-    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n \n     LeaderBasedReplicationAdmin() {\n-      partitionLeaderInfo = new PartitionLeaderInfo();\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTY2MzY2Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439663667", "bodyText": "Can we add logger.info here to print out the replication model that is adopted in this class?", "author": "jsjtzyy", "createdAt": "2020-06-12T22:17:27Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -58,22 +63,36 @@\n   protected boolean started = false;\n   private final StoreConfig storeConfig;\n   private final DataNodeId currentNode;\n-  private final ReadWriteLock rwLock = new ReentrantReadWriteLock();\n   private final boolean trackPerPartitionLagInMetric;\n+  protected LeaderBasedReplicationAdmin leaderBasedReplicationAdmin = null;\n \n   public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,\n       StoreConfig storeConfig, StoreManager storeManager, StoreKeyFactory storeKeyFactory, ClusterMap clusterMap,\n       ScheduledExecutorService scheduler, DataNodeId dataNode, ConnectionPool connectionPool,\n       MetricRegistry metricRegistry, NotificationSystem requestNotification,\n       StoreKeyConverterFactory storeKeyConverterFactory, String transformerClassName,\n       ClusterParticipant clusterParticipant) throws ReplicationException {\n+    this(replicationConfig, clusterMapConfig, storeConfig, storeManager, storeKeyFactory, clusterMap, scheduler,\n+        dataNode, connectionPool, metricRegistry, requestNotification, storeKeyConverterFactory, transformerClassName,\n+        clusterParticipant, null);\n+  }\n+\n+  public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,\n+      StoreConfig storeConfig, StoreManager storeManager, StoreKeyFactory storeKeyFactory, ClusterMap clusterMap,\n+      ScheduledExecutorService scheduler, DataNodeId dataNode, ConnectionPool connectionPool,\n+      MetricRegistry metricRegistry, NotificationSystem requestNotification,\n+      StoreKeyConverterFactory storeKeyConverterFactory, String transformerClassName,\n+      ClusterParticipant clusterParticipant, FindTokenHelper findTokenHelper) throws ReplicationException {\n     super(replicationConfig, clusterMapConfig, storeKeyFactory, clusterMap, scheduler, dataNode,\n         clusterMap.getReplicaIds(dataNode), connectionPool, metricRegistry, requestNotification,\n-        storeKeyConverterFactory, transformerClassName, clusterParticipant, storeManager);\n+        storeKeyConverterFactory, transformerClassName, clusterParticipant, storeManager, findTokenHelper);\n     this.storeConfig = storeConfig;\n     this.currentNode = dataNode;\n     trackPerPartitionLagInMetric = replicationConfig.replicationTrackPerDatacenterLagFromLocal;\n     clusterMap.registerClusterMapListener(new ClusterMapChangeListenerImpl());\n+    if (replicationConfig.replicationModelAcrossDatacenters.equals(ReplicationModelType.LEADER_BASED)) {\n+      leaderBasedReplicationAdmin = new LeaderBasedReplicationAdmin();\n+    }", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex f91002a6e..5b9dcc900 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -71,10 +72,10 @@ public class ReplicationManager extends ReplicationEngine {\n       ScheduledExecutorService scheduler, DataNodeId dataNode, ConnectionPool connectionPool,\n       MetricRegistry metricRegistry, NotificationSystem requestNotification,\n       StoreKeyConverterFactory storeKeyConverterFactory, String transformerClassName,\n-      ClusterParticipant clusterParticipant) throws ReplicationException {\n+      ClusterParticipant clusterParticipant, Predicate skipPredicate) throws ReplicationException {\n     this(replicationConfig, clusterMapConfig, storeConfig, storeManager, storeKeyFactory, clusterMap, scheduler,\n         dataNode, connectionPool, metricRegistry, requestNotification, storeKeyConverterFactory, transformerClassName,\n-        clusterParticipant, null);\n+        clusterParticipant, skipPredicate, null, SystemTime.getInstance());\n   }\n \n   public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxMzM4Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439913386", "bodyText": "minor: complete the comment please", "author": "jsjtzyy", "createdAt": "2020-06-15T03:28:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -99,6 +111,16 @@ Port getPort() {\n     return this.port;\n   }\n \n+  /**\n+   * Set the store information.\n+   * This is ONLY used in UNIT TEST to set mock in-memory local store to be used during replication. For production\n+   * code, store will be provided during construction of this object from StorageManager.\n+   * @param localStore", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 4f92ef849..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -113,9 +113,9 @@ public class RemoteReplicaInfo {\n \n   /**\n    * Set the store information.\n-   * This is ONLY used in UNIT TEST to set mock in-memory local store to be used during replication. For production\n-   * code, store will be provided during construction of this object from StorageManager.\n-   * @param localStore\n+   * This is ONLY used in UNIT TESTs to set mock in-memory local store for using in replication. For production\n+   * code, {@link Store} will be provided during construction of this object from StorageManager.\n+   * @param localStore Underlying store to store blobs\n    */\n   void setLocalStore(Store localStore) {\n     this.localStore = localStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxOTk1OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439919959", "bodyText": "I would like to double check the condition, isn't it supposed to be convertedMissingStoreKeys.contains(convertedKey)? Correct me if I misunderstood this.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:03:34Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +230,126 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Check if missing store messages for this replica (cached in previous replication cycle) are now found in store by\n+   * comparing with list of messages that are recently added to store (input param: messagesWrittenToStore). If input\n+   * list 'messagesWrittenToStore' is not provided, check for missing messages by directly looking into store.\n+   * If there are matching messages (based on store key), do the following:\n+   *    1. Compare blob metadata in local store with cached remote message info and reconcile ttl-update, delete and un-delete states.\n+   *    2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *    3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null) {\n+      try {\n+        List<MessageInfo> missingMessagesFoundInStore = new ArrayList<>();\n+        if (messagesWrittenToStore != null) {\n+          // Check if missing messages for this replica are now found to store by comparing with\n+          // messages provided in input parameter.\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n+          // by doing findMissingKeys() operation on store.\n+          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n+          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE4MzM4NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r441183384", "bodyText": "Ignore this comment, the initial logic is correct.", "author": "jsjtzyy", "createdAt": "2020-06-16T22:45:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxOTk1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 4f92ef849..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -292,9 +292,10 @@ public class RemoteReplicaInfo {\n         } else {\n           // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n           // by doing findMissingKeys() operation on store.\n-          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n-          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n-          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          // Use case: While replica thread for this replica is storing the metadata response with missing key information,\n+          // it is possible that some of the missing keys are written to store by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, if there are missing keys available in local store again.\n+\n           Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n           for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n             StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyMTQ0Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439921442", "bodyText": "If you look at AmbryServerReplica toString() method, replicaId already contains node info. You can either remove replicaId.getDataNodeId() or change replicaId to replicaId.getPartitionId().toPathString().", "author": "jsjtzyy", "createdAt": "2020-06-15T04:11:38Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +230,126 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Check if missing store messages for this replica (cached in previous replication cycle) are now found in store by\n+   * comparing with list of messages that are recently added to store (input param: messagesWrittenToStore). If input\n+   * list 'messagesWrittenToStore' is not provided, check for missing messages by directly looking into store.\n+   * If there are matching messages (based on store key), do the following:\n+   *    1. Compare blob metadata in local store with cached remote message info and reconcile ttl-update, delete and un-delete states.\n+   *    2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *    3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null) {\n+      try {\n+        List<MessageInfo> missingMessagesFoundInStore = new ArrayList<>();\n+        if (messagesWrittenToStore != null) {\n+          // Check if missing messages for this replica are now found to store by comparing with\n+          // messages provided in input parameter.\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n+          // by doing findMissingKeys() operation on store.\n+          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n+          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : missingMessagesFoundInStore) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesToBlobInLocalStore(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 4f92ef849..50b2b6def 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -292,9 +292,10 @@ public class RemoteReplicaInfo {\n         } else {\n           // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n           // by doing findMissingKeys() operation on store.\n-          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n-          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n-          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          // Use case: While replica thread for this replica is storing the metadata response with missing key information,\n+          // it is possible that some of the missing keys are written to store by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, if there are missing keys available in local store again.\n+\n           Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n           for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n             StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyNDQ4MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439924480", "bodyText": "nit: let's directly use leaderBasedReplicationAdmin as argument name to align with its class name.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:27:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -130,7 +130,8 @@ public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, Cluster\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo) {\n+      ReplicaSyncUpManager replicaSyncUpManager,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationTracker) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -119,10 +121,10 @@ public class ReplicaThread implements Runnable {\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager) {\n+      ReplicaSyncUpManager replicaSyncUpManager, Predicate skipPredicate) {\n     this(threadName, findTokenHelper, clusterMap, correlationIdGenerator, dataNodeId, connectionPool, replicationConfig,\n         replicationMetrics, notification, storeKeyConverter, transformer, metricRegistry, replicatingOverSsl,\n-        datacenterName, responseHandler, time, replicaSyncUpManager, null);\n+        datacenterName, responseHandler, time, replicaSyncUpManager, skipPredicate, null);\n   }\n \n   public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, ClusterMap clusterMap,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyNzE0Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439927142", "bodyText": "The partitionName is a pure number, it's supposed to be toPathString() instead of toString()", "author": "jsjtzyy", "createdAt": "2020-06-15T04:41:27Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -340,9 +341,21 @@ public void replicate() {\n             || !remoteReplicaInfo.getLocalStore().isStarted()) {\n           continue;\n         }\n+\n+        // If leader based replication is enabled, don't include standby replicas until their missing store\n+        // keys from previous metadata exchange are received via intra-dc replication.\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -345,7 +349,7 @@ public class ReplicaThread implements Runnable {\n         // If leader based replication is enabled, don't include standby replicas until their missing store\n         // keys from previous metadata exchange are received via intra-dc replication.\n         if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n           ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n           if (!leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplica)\n               && !remoteReplicaInfo.isExchangeMetadataResponseEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyODE3Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439928177", "bodyText": "Updating fixMissingStoreKeysTimeInMs can be out of if block", "author": "jsjtzyy", "createdAt": "2020-06-15T04:46:50Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n+                  exchangeMetadataResponseListForReplicasToFetch);\n+              fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -356,65 +360,79 @@ public class ReplicaThread implements Runnable {\n       }\n       logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n \n-      if (activeReplicasPerNode.size() > 0) {\n-        allCaughtUp = false;\n-        // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n-        // no limit.\n-        List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n-            maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n-                : Collections.singletonList(activeReplicasPerNode);\n+      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n+      // only in leader-based replication.\n+      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+      // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+      // This is a safety feature to ensure that standby replicas are not stuck by fetching the missing keys directly\n+      // from cross colo replicas.\n+      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n+          getRemoteReplicasTimedOutOnNoProgress(remoteNode);\n \n-        // use a variable to track current replica list to replicate (for logging purpose)\n+      if (activeReplicasPerNode.size() > 0 || inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+\n+        // use a variable to track current replica list to replicate. It includes both activeReplicasPerNode and\n+        // inactiveReplicasPerNodeTimedOutOnNoProgress. This is used for checking out connection and logging.\n         List<RemoteReplicaInfo> currentReplicaList = activeReplicasPerNode;\n+        currentReplicaList.addAll(inactiveReplicasPerNodeTimedOutOnNoProgress);\n+\n         try {\n+          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n           connectedChannel =\n-              connectionPool.checkOutConnection(remoteNode.getHostname(), activeReplicasPerNode.get(0).getPort(),\n+              connectionPool.checkOutConnection(remoteNode.getHostname(), currentReplicaList.get(0).getPort(),\n                   replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n           checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n-          for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n-            exchangeMetadataTimeInMs = -1;\n-            fixMissingStoreKeysTimeInMs = -1;\n-            currentReplicaList = replicaSubList;\n-            logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n-                exchangeMetadata(connectedChannel, replicaSubList);\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-\n-            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n-            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n-                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n \n-            if (replicasToFetchMissingStoreKeys.size() > 0) {\n-              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n-                  exchangeMetadataResponseListForReplicasToFetch);\n+          if (activeReplicasPerNode.size() > 0) {\n+            allCaughtUp = false;\n+            // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n+            // no limit.\n+            List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n+                maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n+                    : Collections.singletonList(activeReplicasPerNode);\n+\n+            for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n+              exchangeMetadataTimeInMs = -1;\n+              fixMissingStoreKeysTimeInMs = -1;\n+              currentReplicaList = replicaSubList;\n+              logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n+                  exchangeMetadata(connectedChannel, replicaSubList);\n+              exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+\n+              List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n+              getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n+                  exchangeMetadataResponseListForLeaderReplicas);\n+\n+              if (leaderReplicaList.size() > 0) {\n+                fixMissingStoreKeys(connectedChannel, leaderReplicaList, exchangeMetadataResponseListForLeaderReplicas);\n+              }\n               fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             }\n           }\n \n-          // Send a special request to do cross colo fetches for all standby replicas if their missing keys\n-          // in previous metadata exchange have not arrived for\n-          // time duration > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n-          // This is applicable only for LEADER_BASED replication and cross-colo threads.\n-          List<RemoteReplicaInfo> remoteReplicasWithOldMissingKeys = getRemoteReplicasWithOldMissingKeys(remoteNode);\n-          if (remoteReplicasWithOldMissingKeys.size() > 0) {\n-            logger.debug(\"Cross colo replication request for standby remote replicas {} on remote node {}\",\n-                remoteReplicasWithOldMissingKeys, remoteNode);\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList = remoteReplicasWithOldMissingKeys.stream()\n-                .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n-                .collect(Collectors.toList());\n+          if (inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+            currentReplicaList = inactiveReplicasPerNodeTimedOutOnNoProgress;\n+            logger.debug(\n+                \"Sending get request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n+                currentReplicaList);\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n+                inactiveReplicasPerNodeTimedOutOnNoProgress.stream()\n+                    .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                    .collect(Collectors.toList());\n             fixMissingStoreKeysTimeInMs = -1;\n-            fixMissingStoreKeys(connectedChannel, remoteReplicasWithOldMissingKeys, exchangeMetadataResponseList);\n+            fixMissingStoreKeys(connectedChannel, inactiveReplicasPerNodeTimedOutOnNoProgress,\n+                exchangeMetadataResponseListForInactiveReplicas);\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n         } catch (Throwable e) {\n           if (checkoutConnectionTimeInMs == -1) {\n             // throwable happened in checkout connection phase\n             checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(activeReplicasPerNode.get(0).getReplicaId(), e);\n+            responseHandler.onEvent(currentReplicaList.get(0).getReplicaId(), e);\n           } else if (exchangeMetadataTimeInMs == -1) {\n             // throwable happened in exchange metadata phase\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyOTIzNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439929236", "bodyText": "Let's move this into if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) block.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:51:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1210,60 +1243,66 @@ public class ReplicaThread implements Runnable {\n    * intra-dc replication via leader in local data center.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n-   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n-   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n    *                                                       replicas. It will be populated in this method.\n    * @throws IllegalArgumentException\n    */\n-  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n-      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n \n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating with cross-colo replicas, include only remote\n+      // leader replicas. We will be fetching missing keys for only leader replicas. For standby replicas, we will wait\n+      // for the missing keys to come via intra-dc replication.\n+\n       if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n         throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n             + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n       }\n       for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n         RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n-        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n-        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n         ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n \n         // Check if local replica and remote replica are leaders for this partition.\n         if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n-          replicasToFetchMissingStoreKeys.add(remoteReplicaInfo);\n-          exchangeMetadataResponseListForReplicasToFetch.add(exchangeMetadataResponse);\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n         }\n       }\n     } else {\n-      replicasToFetchMissingStoreKeys.addAll(remoteReplicaInfos);\n-      exchangeMetadataResponseListForReplicasToFetch.addAll(exchangeMetadataResponseList);\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n     }\n   }\n \n   /**\n    * Returns list of standby remote replica infos from a given remote node whose keys in their metadata responses\n-   * haven't arrived for long time so that we can do cross colo fetches on them.\n+   * haven't arrived for time (in secs) > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds\n+   * so that we can do cross colo fetches on them.\n    * @return list of remote replica infos\n    */\n-  private List<RemoteReplicaInfo> getRemoteReplicasWithOldMissingKeys(DataNodeId remoteNode) {\n+  private List<RemoteReplicaInfo> getRemoteReplicasTimedOutOnNoProgress(DataNodeId remoteNode) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n \n-    // Scenario: If leader based replication is enabled and we are replicating from remote colo, check if there are replicas\n-    // whose missing keys haven't arrived for long time. This is applicable for standby replicas where we don't do GET\n-    // for the missing keys and wait for them to arrive (and thereby advance token) via intra-dc replication.\n-    // This ensure token is not stuck for standby replicas.\n+    // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+    // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+    // This is a safety feature to ensure that token is not stuck for standby replicas by doing cross colo GETs if\n+    // their missing keys have not arrived via intra-dc replication for\n+    // time duration (in secs) > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n+    // Note: If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n \n-    // Config: We wait for replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds before including\n-    // the replica for cross colo fetch. If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, we\n-    // don't do this force cross colo fetch.\n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n-        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds >= 0) {\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n       for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicateGroupedByNode.get(remoteNode)) {\n         if (!remoteReplicaInfo.isExchangeMetadataResponseEmpty()\n-            && (time.milliseconds() - remoteReplicaInfo.getExchangeMetadataResponse().timeStamp)\n+            && (time.seconds() - remoteReplicaInfo.getExchangeMetadataResponse().metadataReceivedTimeSec)\n             > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n           remoteReplicaInfos.add(remoteReplicaInfo);\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyOTQ2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439929460", "bodyText": "Use toPathString() instead of toString().", "author": "jsjtzyy", "createdAt": "2020-06-15T04:53:00Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1210,60 +1243,66 @@ public class ReplicaThread implements Runnable {\n    * intra-dc replication via leader in local data center.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n-   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n-   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n    *                                                       replicas. It will be populated in this method.\n    * @throws IllegalArgumentException\n    */\n-  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n-      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n \n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating with cross-colo replicas, include only remote\n+      // leader replicas. We will be fetching missing keys for only leader replicas. For standby replicas, we will wait\n+      // for the missing keys to come via intra-dc replication.\n+\n       if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n         throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n             + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n       }\n       for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n         RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n-        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n-        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n         ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n \n         // Check if local replica and remote replica are leaders for this partition.\n         if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n-          replicasToFetchMissingStoreKeys.add(remoteReplicaInfo);\n-          exchangeMetadataResponseListForReplicasToFetch.add(exchangeMetadataResponse);\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n         }\n       }\n     } else {\n-      replicasToFetchMissingStoreKeys.addAll(remoteReplicaInfos);\n-      exchangeMetadataResponseListForReplicasToFetch.addAll(exchangeMetadataResponseList);\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n     }\n   }\n \n   /**\n    * Returns list of standby remote replica infos from a given remote node whose keys in their metadata responses\n-   * haven't arrived for long time so that we can do cross colo fetches on them.\n+   * haven't arrived for time (in secs) > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds\n+   * so that we can do cross colo fetches on them.\n    * @return list of remote replica infos\n    */\n-  private List<RemoteReplicaInfo> getRemoteReplicasWithOldMissingKeys(DataNodeId remoteNode) {\n+  private List<RemoteReplicaInfo> getRemoteReplicasTimedOutOnNoProgress(DataNodeId remoteNode) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n \n-    // Scenario: If leader based replication is enabled and we are replicating from remote colo, check if there are replicas\n-    // whose missing keys haven't arrived for long time. This is applicable for standby replicas where we don't do GET\n-    // for the missing keys and wait for them to arrive (and thereby advance token) via intra-dc replication.\n-    // This ensure token is not stuck for standby replicas.\n+    // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+    // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+    // This is a safety feature to ensure that token is not stuck for standby replicas by doing cross colo GETs if\n+    // their missing keys have not arrived via intra-dc replication for\n+    // time duration (in secs) > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n+    // Note: If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n \n-    // Config: We wait for replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds before including\n-    // the replica for cross colo fetch. If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, we\n-    // don't do this force cross colo fetch.\n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n-        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds >= 0) {\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n       for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicateGroupedByNode.get(remoteNode)) {\n         if (!remoteReplicaInfo.isExchangeMetadataResponseEmpty()\n-            && (time.milliseconds() - remoteReplicaInfo.getExchangeMetadataResponse().timeStamp)\n+            && (time.seconds() - remoteReplicaInfo.getExchangeMetadataResponse().metadataReceivedTimeSec)\n             > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n           remoteReplicaInfos.add(remoteReplicaInfo);\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzMDQxOA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439930418", "bodyText": "Note that fixMissingStoreKeys() method has replicasToReplicatePerNode.size() == 0 check at the very beginning. If the size is 0, it throws exception. However, in a rare case where all replicas in this subList are standby replicas, the replicasToFetchMissingStoreKeys could be 0, we should graceful skip it rather than throw an exception. Could you make a minor change in fixMissingStoreKeys ?", "author": "jsjtzyy", "createdAt": "2020-06-15T04:57:55Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -356,65 +360,79 @@ public class ReplicaThread implements Runnable {\n       }\n       logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n \n-      if (activeReplicasPerNode.size() > 0) {\n-        allCaughtUp = false;\n-        // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n-        // no limit.\n-        List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n-            maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n-                : Collections.singletonList(activeReplicasPerNode);\n+      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n+      // only in leader-based replication.\n+      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+      // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+      // This is a safety feature to ensure that standby replicas are not stuck by fetching the missing keys directly\n+      // from cross colo replicas.\n+      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n+          getRemoteReplicasTimedOutOnNoProgress(remoteNode);\n \n-        // use a variable to track current replica list to replicate (for logging purpose)\n+      if (activeReplicasPerNode.size() > 0 || inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+\n+        // use a variable to track current replica list to replicate. It includes both activeReplicasPerNode and\n+        // inactiveReplicasPerNodeTimedOutOnNoProgress. This is used for checking out connection and logging.\n         List<RemoteReplicaInfo> currentReplicaList = activeReplicasPerNode;\n+        currentReplicaList.addAll(inactiveReplicasPerNodeTimedOutOnNoProgress);\n+\n         try {\n+          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n           connectedChannel =\n-              connectionPool.checkOutConnection(remoteNode.getHostname(), activeReplicasPerNode.get(0).getPort(),\n+              connectionPool.checkOutConnection(remoteNode.getHostname(), currentReplicaList.get(0).getPort(),\n                   replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n           checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n-          for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n-            exchangeMetadataTimeInMs = -1;\n-            fixMissingStoreKeysTimeInMs = -1;\n-            currentReplicaList = replicaSubList;\n-            logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n-                exchangeMetadata(connectedChannel, replicaSubList);\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-\n-            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n-            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n-                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n \n-            if (replicasToFetchMissingStoreKeys.size() > 0) {\n-              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n-                  exchangeMetadataResponseListForReplicasToFetch);\n+          if (activeReplicasPerNode.size() > 0) {\n+            allCaughtUp = false;\n+            // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n+            // no limit.\n+            List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n+                maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n+                    : Collections.singletonList(activeReplicasPerNode);\n+\n+            for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n+              exchangeMetadataTimeInMs = -1;\n+              fixMissingStoreKeysTimeInMs = -1;\n+              currentReplicaList = replicaSubList;\n+              logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n+                  exchangeMetadata(connectedChannel, replicaSubList);\n+              exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+\n+              List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n+              getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n+                  exchangeMetadataResponseListForLeaderReplicas);\n+\n+              if (leaderReplicaList.size() > 0) {\n+                fixMissingStoreKeys(connectedChannel, leaderReplicaList, exchangeMetadataResponseListForLeaderReplicas);\n+              }\n               fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             }\n           }\n \n-          // Send a special request to do cross colo fetches for all standby replicas if their missing keys\n-          // in previous metadata exchange have not arrived for\n-          // time duration > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n-          // This is applicable only for LEADER_BASED replication and cross-colo threads.\n-          List<RemoteReplicaInfo> remoteReplicasWithOldMissingKeys = getRemoteReplicasWithOldMissingKeys(remoteNode);\n-          if (remoteReplicasWithOldMissingKeys.size() > 0) {\n-            logger.debug(\"Cross colo replication request for standby remote replicas {} on remote node {}\",\n-                remoteReplicasWithOldMissingKeys, remoteNode);\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList = remoteReplicasWithOldMissingKeys.stream()\n-                .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n-                .collect(Collectors.toList());\n+          if (inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+            currentReplicaList = inactiveReplicasPerNodeTimedOutOnNoProgress;\n+            logger.debug(\n+                \"Sending get request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n+                currentReplicaList);\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n+                inactiveReplicasPerNodeTimedOutOnNoProgress.stream()\n+                    .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                    .collect(Collectors.toList());\n             fixMissingStoreKeysTimeInMs = -1;\n-            fixMissingStoreKeys(connectedChannel, remoteReplicasWithOldMissingKeys, exchangeMetadataResponseList);\n+            fixMissingStoreKeys(connectedChannel, inactiveReplicasPerNodeTimedOutOnNoProgress,\n+                exchangeMetadataResponseListForInactiveReplicas);\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n         } catch (Throwable e) {\n           if (checkoutConnectionTimeInMs == -1) {\n             // throwable happened in checkout connection phase\n             checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(activeReplicasPerNode.get(0).getReplicaId(), e);\n+            responseHandler.onEvent(currentReplicaList.get(0).getReplicaId(), e);\n           } else if (exchangeMetadataTimeInMs == -1) {\n             // throwable happened in exchange metadata phase\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNjQzNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439936437", "bodyText": "Add a metric for this case to evaluate how many cross-colo requests are sent due to no progress on specific replicas.\nAlso, we can add a to-do here to improve this: fetch blob from local leader first, if the result is Blob_Not_Found, we do the cross-colo request.\nIn most cases, fetching blob from local leader should be able to unblock the replication on standby replica.", "author": "jsjtzyy", "createdAt": "2020-06-15T05:25:20Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n+                  exchangeMetadataResponseListForReplicasToFetch);\n+              fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            }\n+          }\n+\n+          // Send a special request to do cross colo fetches for all standby replicas if their missing keys\n+          // in previous metadata exchange have not arrived for\n+          // time duration > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n+          // This is applicable only for LEADER_BASED replication and cross-colo threads.\n+          List<RemoteReplicaInfo> remoteReplicasWithOldMissingKeys = getRemoteReplicasWithOldMissingKeys(remoteNode);\n+          if (remoteReplicasWithOldMissingKeys.size() > 0) {\n+            logger.debug(\"Cross colo replication request for standby remote replicas {} on remote node {}\",\n+                remoteReplicasWithOldMissingKeys, remoteNode);\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseList = remoteReplicasWithOldMissingKeys.stream()\n+                .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                .collect(Collectors.toList());\n+            fixMissingStoreKeysTimeInMs = -1;\n+            fixMissingStoreKeys(connectedChannel, remoteReplicasWithOldMissingKeys, exchangeMetadataResponseList);", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -356,65 +360,79 @@ public class ReplicaThread implements Runnable {\n       }\n       logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n \n-      if (activeReplicasPerNode.size() > 0) {\n-        allCaughtUp = false;\n-        // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n-        // no limit.\n-        List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n-            maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n-                : Collections.singletonList(activeReplicasPerNode);\n+      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n+      // only in leader-based replication.\n+      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+      // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+      // This is a safety feature to ensure that standby replicas are not stuck by fetching the missing keys directly\n+      // from cross colo replicas.\n+      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n+          getRemoteReplicasTimedOutOnNoProgress(remoteNode);\n \n-        // use a variable to track current replica list to replicate (for logging purpose)\n+      if (activeReplicasPerNode.size() > 0 || inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+\n+        // use a variable to track current replica list to replicate. It includes both activeReplicasPerNode and\n+        // inactiveReplicasPerNodeTimedOutOnNoProgress. This is used for checking out connection and logging.\n         List<RemoteReplicaInfo> currentReplicaList = activeReplicasPerNode;\n+        currentReplicaList.addAll(inactiveReplicasPerNodeTimedOutOnNoProgress);\n+\n         try {\n+          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n           connectedChannel =\n-              connectionPool.checkOutConnection(remoteNode.getHostname(), activeReplicasPerNode.get(0).getPort(),\n+              connectionPool.checkOutConnection(remoteNode.getHostname(), currentReplicaList.get(0).getPort(),\n                   replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n           checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n-          for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n-            exchangeMetadataTimeInMs = -1;\n-            fixMissingStoreKeysTimeInMs = -1;\n-            currentReplicaList = replicaSubList;\n-            logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n-                exchangeMetadata(connectedChannel, replicaSubList);\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n-\n-            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n-            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n-                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n \n-            if (replicasToFetchMissingStoreKeys.size() > 0) {\n-              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n-                  exchangeMetadataResponseListForReplicasToFetch);\n+          if (activeReplicasPerNode.size() > 0) {\n+            allCaughtUp = false;\n+            // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n+            // no limit.\n+            List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n+                maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n+                    : Collections.singletonList(activeReplicasPerNode);\n+\n+            for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n+              exchangeMetadataTimeInMs = -1;\n+              fixMissingStoreKeysTimeInMs = -1;\n+              currentReplicaList = replicaSubList;\n+              logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n+                  exchangeMetadata(connectedChannel, replicaSubList);\n+              exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+              startTimeInMs = SystemTime.getInstance().milliseconds();\n+\n+              List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n+              getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n+                  exchangeMetadataResponseListForLeaderReplicas);\n+\n+              if (leaderReplicaList.size() > 0) {\n+                fixMissingStoreKeys(connectedChannel, leaderReplicaList, exchangeMetadataResponseListForLeaderReplicas);\n+              }\n               fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             }\n           }\n \n-          // Send a special request to do cross colo fetches for all standby replicas if their missing keys\n-          // in previous metadata exchange have not arrived for\n-          // time duration > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n-          // This is applicable only for LEADER_BASED replication and cross-colo threads.\n-          List<RemoteReplicaInfo> remoteReplicasWithOldMissingKeys = getRemoteReplicasWithOldMissingKeys(remoteNode);\n-          if (remoteReplicasWithOldMissingKeys.size() > 0) {\n-            logger.debug(\"Cross colo replication request for standby remote replicas {} on remote node {}\",\n-                remoteReplicasWithOldMissingKeys, remoteNode);\n-            List<ExchangeMetadataResponse> exchangeMetadataResponseList = remoteReplicasWithOldMissingKeys.stream()\n-                .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n-                .collect(Collectors.toList());\n+          if (inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n+            currentReplicaList = inactiveReplicasPerNodeTimedOutOnNoProgress;\n+            logger.debug(\n+                \"Sending get request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n+                currentReplicaList);\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n+                inactiveReplicasPerNodeTimedOutOnNoProgress.stream()\n+                    .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                    .collect(Collectors.toList());\n             fixMissingStoreKeysTimeInMs = -1;\n-            fixMissingStoreKeys(connectedChannel, remoteReplicasWithOldMissingKeys, exchangeMetadataResponseList);\n+            fixMissingStoreKeys(connectedChannel, inactiveReplicasPerNodeTimedOutOnNoProgress,\n+                exchangeMetadataResponseListForInactiveReplicas);\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n         } catch (Throwable e) {\n           if (checkoutConnectionTimeInMs == -1) {\n             // throwable happened in checkout connection phase\n             checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(activeReplicasPerNode.get(0).getReplicaId(), e);\n+            responseHandler.onEvent(currentReplicaList.get(0).getReplicaId(), e);\n           } else if (exchangeMetadataTimeInMs == -1) {\n             // throwable happened in exchange metadata phase\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzODAwMw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439938003", "bodyText": "How about renaming this to getRemoteReplicasTimedOutOnNoProgress?", "author": "jsjtzyy", "createdAt": "2020-06-15T05:32:10Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          replicasToFetchMissingStoreKeys.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForReplicasToFetch.add(exchangeMetadataResponse);\n+        }\n+      }\n+    } else {\n+      replicasToFetchMissingStoreKeys.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForReplicasToFetch.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of standby remote replica infos from a given remote node whose keys in their metadata responses\n+   * haven't arrived for long time so that we can do cross colo fetches on them.\n+   * @return list of remote replica infos\n+   */\n+  private List<RemoteReplicaInfo> getRemoteReplicasWithOldMissingKeys(DataNodeId remoteNode) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1210,60 +1243,66 @@ public class ReplicaThread implements Runnable {\n    * intra-dc replication via leader in local data center.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n-   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n-   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n    *                                                       replicas. It will be populated in this method.\n    * @throws IllegalArgumentException\n    */\n-  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n-      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n-      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n \n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating with cross-colo replicas, include only remote\n+      // leader replicas. We will be fetching missing keys for only leader replicas. For standby replicas, we will wait\n+      // for the missing keys to come via intra-dc replication.\n+\n       if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n         throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n             + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n       }\n       for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n         RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n-        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n-        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n         ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n \n         // Check if local replica and remote replica are leaders for this partition.\n         if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n-          replicasToFetchMissingStoreKeys.add(remoteReplicaInfo);\n-          exchangeMetadataResponseListForReplicasToFetch.add(exchangeMetadataResponse);\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n         }\n       }\n     } else {\n-      replicasToFetchMissingStoreKeys.addAll(remoteReplicaInfos);\n-      exchangeMetadataResponseListForReplicasToFetch.addAll(exchangeMetadataResponseList);\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n     }\n   }\n \n   /**\n    * Returns list of standby remote replica infos from a given remote node whose keys in their metadata responses\n-   * haven't arrived for long time so that we can do cross colo fetches on them.\n+   * haven't arrived for time (in secs) > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds\n+   * so that we can do cross colo fetches on them.\n    * @return list of remote replica infos\n    */\n-  private List<RemoteReplicaInfo> getRemoteReplicasWithOldMissingKeys(DataNodeId remoteNode) {\n+  private List<RemoteReplicaInfo> getRemoteReplicasTimedOutOnNoProgress(DataNodeId remoteNode) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n \n-    // Scenario: If leader based replication is enabled and we are replicating from remote colo, check if there are replicas\n-    // whose missing keys haven't arrived for long time. This is applicable for standby replicas where we don't do GET\n-    // for the missing keys and wait for them to arrive (and thereby advance token) via intra-dc replication.\n-    // This ensure token is not stuck for standby replicas.\n+    // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+    // metadata exchange and wait for them to come via leader in local data center through intra-dc replication.\n+    // This is a safety feature to ensure that token is not stuck for standby replicas by doing cross colo GETs if\n+    // their missing keys have not arrived via intra-dc replication for\n+    // time duration (in secs) > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n+    // Note: If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n \n-    // Config: We wait for replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds before including\n-    // the replica for cross colo fetch. If replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, we\n-    // don't do this force cross colo fetch.\n     if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n-        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds >= 0) {\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n       for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicateGroupedByNode.get(remoteNode)) {\n         if (!remoteReplicaInfo.isExchangeMetadataResponseEmpty()\n-            && (time.milliseconds() - remoteReplicaInfo.getExchangeMetadataResponse().timeStamp)\n+            && (time.seconds() - remoteReplicaInfo.getExchangeMetadataResponse().metadataReceivedTimeSec)\n             > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n           remoteReplicaInfos.add(remoteReplicaInfo);\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTk0ODAxOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439948019", "bodyText": "Could you explain the purpose of this class and where it is used?", "author": "jsjtzyy", "createdAt": "2020-06-15T06:09:03Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1161,6 +1320,19 @@ ReplicationMetrics getReplicationMetrics() {\n     }\n   }\n \n+  /**\n+   *\n+   */\n+  public static class RemoteMessageAndLocalStoreKeyInfo {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex fd512e91f..8b8b9d07a 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1320,19 +1359,6 @@ public class ReplicaThread implements Runnable {\n     }\n   }\n \n-  /**\n-   *\n-   */\n-  public static class RemoteMessageAndLocalStoreKeyInfo {\n-    MessageInfo remoteMessageInfo;\n-    StoreKey localStoreKey;\n-\n-    public RemoteMessageAndLocalStoreKeyInfo(MessageInfo remoteMessageInfo, StoreKey localStoreKey) {\n-      this.remoteMessageInfo = remoteMessageInfo;\n-      this.localStoreKey = localStoreKey;\n-    }\n-  }\n-\n   boolean isThreadUp() {\n     return running;\n   }\n"}}, {"oid": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "url": "https://github.com/linkedin/ambry/commit/5c3a4e66ac5069624d780d0497a748db9572dbcc", "message": "Changes for:\n1. Adding logger.info when leader-based replication is used.\n2. Using correct string ID for Partitions, i.e. partitionId.toPathString() instead of partitionId.toString().\n3. Few other minor changes like renaming of methods, variable names, etc.", "committedDate": "2020-06-16T01:03:44Z", "type": "forcePushed"}, {"oid": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "url": "https://github.com/linkedin/ambry/commit/511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "message": "1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'", "committedDate": "2020-06-23T19:48:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1NzkyNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444557924", "bodyText": "I have a problem with changing configuration name here. It's a high risk action, which might break the close source ambryli. Please make sure that nothing will break before moving on with this change.", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:13:10Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -192,7 +192,7 @@\n    */\n   @Config(\"replication.model.across.datacenters\")\n   @Default(\"ALL_TO_ALL\")\n-  public final ReplicationModelType replicationModelType;\n+  public final ReplicationModelType replicationModelAcrossDatacenters;", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\nindex 090560164..cda21a781 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n\n@@ -190,7 +193,7 @@ public class ReplicationConfig {\n    * If set to \"ALL_TO_ALL\", inter colo replication will be in an all-to-all fashion, i.e. each replica talks to all other replicas irrespective of their state.\n    * Intra colo replication will continue as all-to-all fashion in both the models.\n    */\n-  @Config(\"replication.model.across.datacenters\")\n+  @Config(REPLICATION_MODEL_ACROSS_DATACENTERS)\n   @Default(\"ALL_TO_ALL\")\n   public final ReplicationModelType replicationModelAcrossDatacenters;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1ODkyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444558920", "bodyText": "nit: Can we use a constant string for config here, since this is a newly add config. Check out REPLICATION_CLOUD_TOKEN_FACTORY in the same file.", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:16:22Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -216,6 +216,19 @@\n   @Default(\"false\")\n   public final boolean replicationContainerDeletionEnabled;\n \n+  /**\n+   * The time (in seconds) for standby replicas to wait before fetching missing keys from replicas in cross colo\n+   * data centers. This is applicable during leader based replication where standby replicas don't fetch the missing\n+   * keys found in metadata exchange from cross colo replicas and expect them to come from leader replica in\n+   * local data center via intra-dc replication. This time out ensures that standby replicas are not stuck indefinitely\n+   * waiting for the missing keys to come via intra-dc replication by doing cross colo fetch themselves.\n+   * Default value is 120 seconds. If configured to -1, this timeout doesn't take effect, i.e. cross colo fetch for\n+   * standby replicas is never done.\n+   */\n+  @Config(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\")\n+  @Default(\"120\")\n+  public final int replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds;\n+", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\nindex 090560164..cda21a781 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java\n\n@@ -225,7 +228,7 @@ public class ReplicationConfig {\n    * Default value is 120 seconds. If configured to -1, this timeout doesn't take effect, i.e. cross colo fetch for\n    * standby replicas is never done.\n    */\n-  @Config(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\")\n+  @Config(REPLICATION_STANDBY_WAIT_TIMEOUT_TO_TRIGGER_CROSS_COLO_FETCH_SECONDS)\n   @Default(\"120\")\n   public final int replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU2MDM4Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444560382", "bodyText": "typo: ttl_update, undelete", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:20:55Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -739,68 +856,10 @@ private void processReplicaMetadataResponse(Set<MessageInfo> missingRemoteStoreM\n               remoteNode, threadName, remoteReplicaInfo.getReplicaId(), localKey);\n         }\n       } else {\n-        // the key is present in the local store. Mark it for deletion if it is deleted in the remote store and not\n-        // deleted yet locally\n-        MessageInfo localMessageInfo = remoteReplicaInfo.getLocalStore().findKey(localKey);\n-        boolean deletedLocally = localMessageInfo.isDeleted();\n-        boolean ttlUpdatedLocally = localMessageInfo.isTtlUpdated();\n-        short localLifeVersion = localMessageInfo.getLifeVersion();\n-        short remoteLifeVersion = messageInfo.getLifeVersion();\n-        if (localLifeVersion > remoteLifeVersion) {\n-          // if the lifeVersion in local store is greater than the remote lifeVersion, then nothing needs to be done.\n-          continue;\n-        } else if (localLifeVersion == remoteLifeVersion) {\n-          // we are operating in the same version, in this case, delete would be the final state.\n-          if (!deletedLocally) {\n-            // Only adds record when it's not deleted yet. Since delete is the final state for this lifeVersion, if there\n-            // is a delete record for the current lifeVersion, then nothing needs to be done.\n-            MessageInfo info = new MessageInfo(localKey, 0, localKey.getAccountId(), localKey.getContainerId(),\n-                messageInfo.getOperationTimeMs(), remoteLifeVersion);\n-            if (messageInfo.isTtlUpdated() && !ttlUpdatedLocally) {\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            }\n-            if (messageInfo.isDeleted()) {\n-              applyDelete(info, remoteReplicaInfo);\n-            }\n-          }\n-        } else {\n-          // if we are here, then the remote lifeVersion is greater than the local lifeVersion.\n-          // we need to reconcile the local state with the remote state.\n-          //\n-          // There are three states we have to reconcile: lifeVersion, ttl_update, is_deleted.\n-          // To reconcile lifeVersion and is_deleted, we have to add a Delete or Undelete record, based on what the final state is.\n-          // to reconcile ttl_update, if the final state is delete, then, we have to add ttl_update before delete, other, we can add ttl_update after undelete.\n-          MessageInfo info = new MessageInfo(localKey, 0, localKey.getAccountId(), localKey.getContainerId(),\n-              messageInfo.getOperationTimeMs(), remoteLifeVersion);\n-          boolean shouldInsertTtlUpdate = false;\n-          if (messageInfo.isTtlUpdated() && !ttlUpdatedLocally) {\n-            // make a patch for ttl update\n-            // if the remote state is delete, then we can't insert TTL_UPDATE after delete, we have to insert a ttl_update here\n-            if (messageInfo.isDeleted()) {\n-              // since ttl update can only follow Put or Undelete, make sure it's not locally deleted.\n-              // we can reuse the lifeVersion for undelete and ttl update, since the delete would be the final state of\n-              // this lifeVersion.\n-              if (deletedLocally) {\n-                applyUndelete(info, remoteReplicaInfo);\n-              }\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            } else {\n-              // if final state is not delete, then to bump lifeVersion in local store to remote lifeVersion, we have to\n-              // add a undelete, and then add a ttl update.\n-              shouldInsertTtlUpdate = true;\n-            }\n-          }\n-\n-          // if we are here, then the ttl update is matched\n-          if (messageInfo.isDeleted()) {\n-            applyDelete(info, remoteReplicaInfo);\n-          } else {\n-            applyUndelete(info, remoteReplicaInfo);\n-            if (shouldInsertTtlUpdate) {\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            }\n-          }\n-        }\n+        // The key is present in the local store. Compare blob properties (ttl-update, delete, un-delete fields) in", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 1502452d1..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -856,24 +872,28 @@ public class ReplicaThread implements Runnable {\n               remoteNode, threadName, remoteReplicaInfo.getReplicaId(), localKey);\n         }\n       } else {\n-        // The key is present in the local store. Compare blob properties (ttl-update, delete, un-delete fields) in\n+        // The key is present in the local store. Compare blob properties (ttl_update, delete, undelete fields) in\n         // received message info with blob in local store and apply updates as needed. For ex, mark local blob for deletion if\n         // it is deleted in the remote store and not deleted yet locally.\n+\n+        // if the blob is from deprecated container, then nothing needs to be done.\n+        if (skipPredicate != null && skipPredicate.test(messageInfo)) {\n+          continue;\n+        }\n         applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localKey);\n       }\n     }\n     if (replicatingFromRemoteColo) {\n       replicationMetrics.interColoProcessMetadataResponseTime.get(datacenterName)\n-          .update(SystemTime.getInstance().milliseconds() - startTime);\n+          .update(time.milliseconds() - startTime);\n     } else {\n-      replicationMetrics.intraColoProcessMetadataResponseTime.update(\n-          SystemTime.getInstance().milliseconds() - startTime);\n+      replicationMetrics.intraColoProcessMetadataResponseTime.update(time.milliseconds() - startTime);\n     }\n   }\n \n   /**\n    * Compares blob metadata in received message from remote replica with the blob in local store and updates its\n-   * ttl-update/delete/un-delete properties. This is called when a replicated blob from remote replica is found on local store.\n+   * ttl_update/delete/undelete properties. This is called when a replicated blob from remote replica is found on local store.\n    * @param messageInfo message information of the blob from remote replica\n    * @param remoteReplicaInfo remote replica information\n    * @param localKey local blob information\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3MjE3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444572171", "bodyText": "nit: we should probably pass dataNodeToRemoteReplicaInfo map to this method, instead of replicasToReplicateGroupedByNode inside the method.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T00:02:07Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -343,43 +345,114 @@ public void replicate() {\n             || !remoteReplicaInfo.getLocalStore().isStarted()) {\n           continue;\n         }\n+\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          // If leader based replication is enabled, don't include remote standby replicas until their missing store\n+          // keys from previous metadata exchange are received via intra-dc replication.\n+          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+          ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n+          if (!leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplica)\n+              && !remoteReplicaInfo.isExchangeMetadataResponseEmpty()) {\n+            continue;\n+          }\n+        }\n         activeReplicasPerNode.add(remoteReplicaInfo);\n       }\n       logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n-      if (activeReplicasPerNode.size() > 0) {\n+\n+      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n+      // only in leader-based replication.\n+      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+      // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n+      // This is a safety feature to ensure that standby replicas are not stuck waiting for the keys to come from leader\n+      // by fetching the missing keys themselves.\n+      // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n+      // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n+      // This will involve co-ordination between replica threads containing replicas of same partition.\n+      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n+          getRemoteReplicasTimedOutOnNoProgress(remoteNode);", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 1502452d1..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -333,155 +348,157 @@ public class ReplicaThread implements Runnable {\n       long checkoutConnectionTimeInMs = -1;\n       long exchangeMetadataTimeInMs = -1;\n       long fixMissingStoreKeysTimeInMs = -1;\n-      long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n+      long replicationStartTimeInMs = time.milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n-      // Get a list of active replicas that needs be included for this replication cycle\n-      List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n-      for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n-        ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n-        boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n-        if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n-            || !remoteReplicaInfo.getLocalStore().isStarted()) {\n-          continue;\n-        }\n-\n-        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-          // If leader based replication is enabled, don't include remote standby replicas until their missing store\n-          // keys from previous metadata exchange are received via intra-dc replication.\n-          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n-          ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n-          if (!leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplica)\n-              && !remoteReplicaInfo.isExchangeMetadataResponseEmpty()) {\n+      // use a variable to track current replica list to replicate (for logging purpose)\n+      List<RemoteReplicaInfo> currentReplicaList = new ArrayList<>();\n+      try {\n+        // Get a list of active replicas that needs be included for this replication cycle\n+        List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n+        for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n+          ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n+          boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n+          if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n+              || remoteReplicaInfo.getLocalStore().getCurrentState() == ReplicaState.OFFLINE) {\n             continue;\n           }\n-        }\n-        activeReplicasPerNode.add(remoteReplicaInfo);\n-      }\n-      logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n-\n-      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n-      // only in leader-based replication.\n-      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n-      // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n-      // This is a safety feature to ensure that standby replicas are not stuck waiting for the keys to come from leader\n-      // by fetching the missing keys themselves.\n-      // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n-      // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n-      // This will involve co-ordination between replica threads containing replicas of same partition.\n-      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n-          getRemoteReplicasTimedOutOnNoProgress(remoteNode);\n-\n-      if (activeReplicasPerNode.size() > 0 || inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n-\n-        // Set boolean 'allCaughtUp' to false as long as we have replicas (either\n-        // activeReplicasPerNode or inactiveReplicasPerNodeTimedOutOnNoProgress) to replicate from.\n-        allCaughtUp = false;\n-\n-        // use a variable to track current replica list to replicate. It includes both activeReplicasPerNode and\n-        // inactiveReplicasPerNodeTimedOutOnNoProgress. This is used for checking out connection and logging.\n-        List<RemoteReplicaInfo> currentReplicaList = activeReplicasPerNode;\n-        currentReplicaList.addAll(inactiveReplicasPerNodeTimedOutOnNoProgress);\n \n-        try {\n+          if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+            // In leader-based cross colo replication, missing blobs are only exchanged between leader replica pairs (i.e.\n+            // local replica and remote replica are leaders of their partition). For all non-leader replica pairs (i.e.\n+            // leader <-> standby, standby <-> leader, standby <-> standby), we expect their missing keys to come from\n+            // leader pair exchanges via intra-dc replication.\n+\n+            // Check and process missing keys of standby replicas from metadata exchange of previous replication cycle\n+            // which might be now obtained from local leader via intra-dc replication.\n+            processMissingKeysFromPreviousMetadataResponse(remoteReplicaInfo);\n+\n+            // If we still have some missing keys from previous metadata exchange, don't include this replica for\n+            // current replication cycle to avoid sending duplicate metadata request.\n+            if (containsMissingKeysFromPreviousMetadataExchange(remoteReplicaInfo)) {\n+              continue;\n+            }\n+          }\n+          activeReplicasPerNode.add(remoteReplicaInfo);\n+        }\n+        logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n+\n+        currentReplicaList = activeReplicasPerNode;\n+        if (activeReplicasPerNode.size() > 0) {\n+          allCaughtUp = false;\n+          // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n+          // no limit.\n+          List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n+              maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n+                  : Collections.singletonList(activeReplicasPerNode);\n           // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n           connectedChannel =\n-              connectionPool.checkOutConnection(remoteNode.getHostname(), currentReplicaList.get(0).getPort(),\n+              connectionPool.checkOutConnection(remoteNode.getHostname(), activeReplicasPerNode.get(0).getPort(),\n                   replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n-          checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-\n-          if (activeReplicasPerNode.size() > 0) {\n-            // if maxReplicaCountPerRequest > 0, split remote replicas on same node into multiple lists; otherwise there is\n-            // no limit.\n-            List<List<RemoteReplicaInfo>> activeReplicaSubLists =\n-                maxReplicaCountPerRequest > 0 ? Utils.partitionList(activeReplicasPerNode, maxReplicaCountPerRequest)\n-                    : Collections.singletonList(activeReplicasPerNode);\n-\n-            for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n-              exchangeMetadataTimeInMs = -1;\n-              fixMissingStoreKeysTimeInMs = -1;\n-              currentReplicaList = replicaSubList;\n-              logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n-              startTimeInMs = SystemTime.getInstance().milliseconds();\n-              List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n-                  exchangeMetadata(connectedChannel, replicaSubList);\n-              exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-              startTimeInMs = SystemTime.getInstance().milliseconds();\n+          checkoutConnectionTimeInMs = time.milliseconds() - startTimeInMs;\n+          // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n+          for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n+            exchangeMetadataTimeInMs = -1;\n+            fixMissingStoreKeysTimeInMs = -1;\n+            currentReplicaList = replicaSubList;\n+            logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n+            startTimeInMs = time.milliseconds();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n+                exchangeMetadata(connectedChannel, replicaSubList);\n+            exchangeMetadataTimeInMs = time.milliseconds() - startTimeInMs;\n+\n+            if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+              // If leader based replication is enabled and we are replicating from remote colo, fetch the missing blobs\n+              // only for local leader replicas from their corresponding peer leader replicas (Leader <-> Leader).\n+              // Non-leader replica pairs (standby <-> leaders, leader <-> standby, standby <-> standby) will get their\n+              // missing blobs from their leader pair exchanges and intra-dc replication.\n \n               List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n               List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n               getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n                   exchangeMetadataResponseListForLeaderReplicas);\n+              replicaSubList = leaderReplicaList;\n+              exchangeMetadataResponseList = exchangeMetadataResponseListForLeaderReplicas;\n+            }\n \n-              if (leaderReplicaList.size() > 0) {\n-                fixMissingStoreKeys(connectedChannel, leaderReplicaList, exchangeMetadataResponseListForLeaderReplicas);\n-              }\n-              fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            startTimeInMs = time.milliseconds();\n+            if (replicaSubList.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n             }\n+            fixMissingStoreKeysTimeInMs = time.milliseconds() - startTimeInMs;\n           }\n+        }\n \n-          if (inactiveReplicasPerNodeTimedOutOnNoProgress.size() > 0) {\n-            // Sending GET request for remote standby replicas that have timed out waiting for missing keys. This is\n-            // applicable only for leader-based replication (please see how inactiveReplicasPerNodeTimedOutOnNoProgress list\n-            // is constructed for more details).\n-            currentReplicaList = inactiveReplicasPerNodeTimedOutOnNoProgress;\n-\n-            // Get the stored exchange metadata responses (containing the missing blobs) for these replicas.\n-            // Note: It is possible that some (or all) of missing blobs in timed out replicas are written to store in\n-            // parallel by intra-dc replica threads. Exchange metadata list below will contain current missing\n-            // blob information and we will only send GET requests for them. If all the missing blobs in all\n-            // timed out replicas arrived by this time, no GET request will be sent in fixMissingStoreKeys().\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          // Get a list of inactive standby replicas whose missing keys haven't arrived for long time.\n+          // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+          // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n+          // This is a safety condition to ensure that standby replicas are not stuck waiting for the keys to come from leader\n+          // by fetching the missing keys themselves.\n+          // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n+          // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n+          // This will involve co-ordination between replica threads containing replicas of same partition.\n+          List<RemoteReplicaInfo> standbyReplicasTimedOutOnNoProgress =\n+              getRemoteStandbyReplicasTimedOutOnNoProgress(replicasToReplicatePerNode);\n+          if (standbyReplicasTimedOutOnNoProgress.size() > 0) {\n+            allCaughtUp = false;\n+            currentReplicaList = standbyReplicasTimedOutOnNoProgress;\n+            if (connectedChannel == null) {\n+              connectedChannel = connectionPool.checkOutConnection(remoteNode.getHostname(),\n+                  standbyReplicasTimedOutOnNoProgress.get(0).getPort(),\n+                  replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n+              checkoutConnectionTimeInMs = time.milliseconds() - startTimeInMs;\n+            }\n             List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n-                inactiveReplicasPerNodeTimedOutOnNoProgress.stream()\n+                standbyReplicasTimedOutOnNoProgress.stream()\n                     .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n                     .collect(Collectors.toList());\n-\n-            // Set exchange metadata time to 0. This is used to help with debugging (while handling exception below) to\n-            // tell that there is no issue with metadata exchange if we are in this step.\n             exchangeMetadataTimeInMs = 0;\n-\n             fixMissingStoreKeysTimeInMs = -1;\n             logger.debug(\n                 \"Sending GET request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n                 currentReplicaList);\n-            fixMissingStoreKeys(connectedChannel, inactiveReplicasPerNodeTimedOutOnNoProgress,\n+            fixMissingStoreKeys(connectedChannel, standbyReplicasTimedOutOnNoProgress,\n                 exchangeMetadataResponseListForInactiveReplicas);\n-            fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            fixMissingStoreKeysTimeInMs = time.milliseconds() - startTimeInMs;\n           }\n-        } catch (Throwable e) {\n-          if (checkoutConnectionTimeInMs == -1) {\n-            // throwable happened in checkout connection phase\n-            checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(currentReplicaList.get(0).getReplicaId(), e);\n-          } else if (exchangeMetadataTimeInMs == -1) {\n-            // throwable happened in exchange metadata phase\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          } else if (fixMissingStoreKeysTimeInMs == -1) {\n-            // throwable happened in fix missing store phase\n-            fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          }\n-          logger.error(\n-              \"Error while talking to peer: Remote node: {}, Thread name: {}, Remote replicas: {}, Current active \"\n-                  + \"remote replica list: {}, Checkout connection time: {}, Exchange metadata time: {}, Fix missing \"\n-                  + \"store key time {}\", remoteNode, threadName, replicasToReplicatePerNode, currentReplicaList,\n-              checkoutConnectionTimeInMs, exchangeMetadataTimeInMs, fixMissingStoreKeysTimeInMs, e);\n-          replicationMetrics.incrementReplicationErrors(replicatingOverSsl);\n-          if (connectedChannel != null) {\n-            connectionPool.destroyConnection(connectedChannel);\n-            connectedChannel = null;\n-          }\n-        } finally {\n-          long totalReplicationTime = SystemTime.getInstance().milliseconds() - replicationStartTimeInMs;\n-          replicationMetrics.updateTotalReplicationTime(totalReplicationTime, replicatingFromRemoteColo,\n-              replicatingOverSsl, datacenterName);\n-          if (connectedChannel != null) {\n-            connectionPool.checkInConnection(connectedChannel);\n-          }\n-          context.stop();\n-          portTypeBasedContext.stop();\n         }\n+      } catch (Throwable e) {\n+        if (checkoutConnectionTimeInMs == -1) {\n+          // throwable happened in checkout connection phase\n+          checkoutConnectionTimeInMs = time.milliseconds() - startTimeInMs;\n+          responseHandler.onEvent(currentReplicaList.get(0).getReplicaId(), e);\n+        } else if (exchangeMetadataTimeInMs == -1) {\n+          // throwable happened in exchange metadata phase\n+          exchangeMetadataTimeInMs = time.milliseconds() - startTimeInMs;\n+        } else if (fixMissingStoreKeysTimeInMs == -1) {\n+          // throwable happened in fix missing store phase\n+          fixMissingStoreKeysTimeInMs = time.milliseconds() - startTimeInMs;\n+        }\n+        logger.error(\n+            \"Error while talking to peer: Remote node: {}, Thread name: {}, Remote replicas: {}, Current active \"\n+                + \"remote replica list: {}, Checkout connection time: {}, Exchange metadata time: {}, Fix missing \"\n+                + \"store key time {}\", remoteNode, threadName, replicasToReplicatePerNode, currentReplicaList,\n+            checkoutConnectionTimeInMs, exchangeMetadataTimeInMs, fixMissingStoreKeysTimeInMs, e);\n+        replicationMetrics.incrementReplicationErrors(replicatingOverSsl);\n+        if (connectedChannel != null) {\n+          connectionPool.destroyConnection(connectedChannel);\n+          connectedChannel = null;\n+        }\n+      } finally {\n+        long totalReplicationTime = time.milliseconds() - replicationStartTimeInMs;\n+        replicationMetrics.updateTotalReplicationTime(totalReplicationTime, replicatingFromRemoteColo,\n+            replicatingOverSsl, datacenterName);\n+        if (connectedChannel != null) {\n+          connectionPool.checkInConnection(connectedChannel);\n+        }\n+        context.stop();\n+        portTypeBasedContext.stop();\n       }\n     }\n+\n     long sleepDurationMs = 0;\n     if (allCaughtUp && replicationConfig.replicationReplicaThreadIdleSleepDurationMs > 0) {\n       sleepDurationMs = replicationConfig.replicationReplicaThreadIdleSleepDurationMs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNTIzOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444615239", "bodyText": "I have noticed that every time we have a statement exchangeMetadataResponseList.add, this statement follows, can we move this statement outside of the exchangeMetadata method, or put it in the finally block of exchangeMetadata method.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T02:50:43Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -517,25 +627,31 @@ public void replicate() {\n                 // Must have just been stopped, just skip it and move on.\n                 logger.info(\"Local store not started for remote replica: {}\", remoteReplicaInfo.getReplicaId());\n                 exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-                remoteReplicaInfo.setExchangeMetadataResponse(\n-                    new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+                  remoteReplicaInfo.setExchangeMetadataResponse(\n+                      new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                }", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 1502452d1..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -535,111 +552,90 @@ public class ReplicaThread implements Runnable {\n             // Skip stores that were stopped during call to getReplicaMetadataResponse\n             if (!remoteReplicaInfo.getLocalStore().isStarted()) {\n               exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-              if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-                remoteReplicaInfo.setExchangeMetadataResponse(\n-                    new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-              }\n-              continue;\n-            }\n-            try {\n-              logger.trace(\"Remote node: {} Thread name: {} Remote replica: {} Token from remote: {} Replica lag: {} \",\n-                  remoteNode, threadName, remoteReplicaInfo.getReplicaId(), replicaMetadataResponseInfo.getFindToken(),\n-                  replicaMetadataResponseInfo.getRemoteReplicaLagInBytes());\n-              Set<MessageInfo> remoteMissingStoreMessages =\n-                  getMissingStoreMessages(replicaMetadataResponseInfo, remoteNode, remoteReplicaInfo);\n-              processReplicaMetadataResponse(remoteMissingStoreMessages, replicaMetadataResponseInfo, remoteReplicaInfo,\n-                  remoteNode, remoteKeyToLocalKeyMap);\n-\n-              // Get a remote key to local key sub map for missing keys of this replica. It will be stored along with\n-              // missing store messages in ExchangeMetadataResponse. This is needed during leader based replication where\n-              // metadata response is stored for standby replicas to track the missing keys via intra-dc replication.\n-              Map<StoreKey, StoreKey> remoteKeyToLocalKeySubMap = new HashMap<>();\n-              remoteMissingStoreMessages.forEach(remoteMissingStoreMessage -> {\n-                StoreKey remoteKey = remoteMissingStoreMessage.getStoreKey();\n-                remoteKeyToLocalKeySubMap.put(remoteKey, remoteKeyToLocalKeyMap.get(remoteKey));\n-              });\n-\n-              ExchangeMetadataResponse exchangeMetadataResponse =\n-                  new ExchangeMetadataResponse(remoteMissingStoreMessages, replicaMetadataResponseInfo.getFindToken(),\n-                      replicaMetadataResponseInfo.getRemoteReplicaLagInBytes(), time.seconds(),\n-                      remoteKeyToLocalKeySubMap);\n-\n-              // update replication lag in ReplicaSyncUpManager\n-              if (replicaSyncUpManager != null\n-                  && remoteReplicaInfo.getLocalStore().getCurrentState() == ReplicaState.BOOTSTRAP) {\n-                ReplicaId localReplica = remoteReplicaInfo.getLocalReplicaId();\n-                ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n-                boolean updated = replicaSyncUpManager.updateLagBetweenReplicas(localReplica, remoteReplica,\n-                    exchangeMetadataResponse.localLagFromRemoteInBytes);\n-                // if updated is false, it means local replica is not found in replicaSyncUpManager and is therefore not\n-                // in bootstrap state.\n-                if (updated && replicaSyncUpManager.isSyncUpComplete(localReplica)) {\n-                  // complete BOOTSTRAP -> STANDBY transition\n-                  remoteReplicaInfo.getLocalStore().setCurrentState(ReplicaState.STANDBY);\n-                  replicaSyncUpManager.onBootstrapComplete(localReplica);\n-                  remoteReplicaInfo.getLocalStore().completeBootstrap();\n+            } else {\n+              try {\n+                logger.trace(\n+                    \"Remote node: {} Thread name: {} Remote replica: {} Token from remote: {} Replica lag: {} \",\n+                    remoteNode, threadName, remoteReplicaInfo.getReplicaId(),\n+                    replicaMetadataResponseInfo.getFindToken(),\n+                    replicaMetadataResponseInfo.getRemoteReplicaLagInBytes());\n+                Set<MessageInfo> remoteMissingStoreMessages =\n+                    getMissingStoreMessages(replicaMetadataResponseInfo, remoteNode, remoteReplicaInfo);\n+                processReplicaMetadataResponse(remoteMissingStoreMessages, replicaMetadataResponseInfo,\n+                    remoteReplicaInfo, remoteNode, remoteKeyToLocalKeyMap);\n+\n+                // Get a remote key to local key sub map for missing keys of this replica. It will be stored along with\n+                // missing store messages in ExchangeMetadataResponse. This is needed during leader based replication where\n+                // metadata response is stored for standby replicas to track the missing keys via intra-dc replication.\n+                Map<StoreKey, StoreKey> remoteKeyToLocalKeySubMap = new HashMap<>();\n+                remoteMissingStoreMessages.forEach(remoteMissingStoreMessage -> {\n+                  StoreKey remoteKey = remoteMissingStoreMessage.getStoreKey();\n+                  remoteKeyToLocalKeySubMap.put(remoteKey, remoteKeyToLocalKeyMap.get(remoteKey));\n+                });\n+\n+                ExchangeMetadataResponse exchangeMetadataResponse =\n+                    new ExchangeMetadataResponse(remoteMissingStoreMessages, replicaMetadataResponseInfo.getFindToken(),\n+                        replicaMetadataResponseInfo.getRemoteReplicaLagInBytes(), time.seconds(),\n+                        remoteKeyToLocalKeySubMap);\n+\n+                // update replication lag in ReplicaSyncUpManager\n+                if (replicaSyncUpManager != null\n+                    && remoteReplicaInfo.getLocalStore().getCurrentState() == ReplicaState.BOOTSTRAP) {\n+                  ReplicaId localReplica = remoteReplicaInfo.getLocalReplicaId();\n+                  ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n+                  boolean updated = replicaSyncUpManager.updateLagBetweenReplicas(localReplica, remoteReplica,\n+                      exchangeMetadataResponse.localLagFromRemoteInBytes);\n+                  // if updated is false, it means local replica is not found in replicaSyncUpManager and is therefore not\n+                  // in bootstrap state.\n+                  if (updated && replicaSyncUpManager.isSyncUpComplete(localReplica)) {\n+                    // complete BOOTSTRAP -> STANDBY transition\n+                    remoteReplicaInfo.getLocalStore().setCurrentState(ReplicaState.STANDBY);\n+                    replicaSyncUpManager.onBootstrapComplete(localReplica);\n+                    remoteReplicaInfo.getLocalStore().completeBootstrap();\n+                  }\n                 }\n-              }\n-\n-              // add exchangeMetadataResponse to list after replicaSyncUpManager(if not null) has completed update. The\n-              // reason is replicaSyncUpManager may also throw exception and add one more exchangeMetadataResponse\n-              // associated with same RemoteReplicaInfo.\n-              exchangeMetadataResponseList.add(exchangeMetadataResponse);\n-\n-              // Also, store the meta data exchange received for the remote replica. If leader based replication is enabled,\n-              // standby replicas will not send GET request for the missing store keys and wait for them to come\n-              // via intra-dc replication. Once all the missing keys are received via intra-dc replication,\n-              // standby replicas will advance the remote token and send the next metadata request.\n-              if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-                remoteReplicaInfo.setExchangeMetadataResponse(exchangeMetadataResponse);\n-              }\n \n-              // If remote token has not moved forward, wait for back off time before resending next metadata request\n-              if (remoteReplicaInfo.getToken().equals(exchangeMetadataResponse.remoteToken)) {\n-                remoteReplicaInfo.setReEnableReplicationTime(\n-                    time.milliseconds() + replicationConfig.replicationSyncedReplicaBackoffDurationMs);\n-                syncedBackOffCount.inc();\n-              }\n+                // add exchangeMetadataResponse to list after replicaSyncUpManager(if not null) has completed update. The\n+                // reason is replicaSyncUpManager may also throw exception and add one more exchangeMetadataResponse\n+                // associated with same RemoteReplicaInfo.\n+                exchangeMetadataResponseList.add(exchangeMetadataResponse);\n \n-              // There are no missing keys. We just advance the token\n-              if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n-                remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n-                remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n-                // reset stored metadata response for this replica\n-                remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+                // If remote token has not moved forward, wait for back off time before resending next metadata request\n+                if (remoteReplicaInfo.getToken().equals(exchangeMetadataResponse.remoteToken)) {\n+                  remoteReplicaInfo.setReEnableReplicationTime(\n+                      time.milliseconds() + replicationConfig.replicationSyncedReplicaBackoffDurationMs);\n+                  syncedBackOffCount.inc();\n+                }\n \n-                logger.trace(\n-                    \"Remote node: {} Thread name: {} Remote replica: {} Token after speaking to remote node: {}\",\n-                    remoteNode, threadName, remoteReplicaInfo.getReplicaId(), exchangeMetadataResponse.remoteToken);\n-              }\n+                // There are no missing keys. We just advance the token\n+                if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+                  remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+                  remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+                  logger.trace(\n+                      \"Remote node: {} Thread name: {} Remote replica: {} Token after speaking to remote node: {}\",\n+                      remoteNode, threadName, remoteReplicaInfo.getReplicaId(), exchangeMetadataResponse.remoteToken);\n+                }\n \n-              replicationMetrics.updateLagMetricForRemoteReplica(remoteReplicaInfo,\n-                  exchangeMetadataResponse.localLagFromRemoteInBytes);\n-              if (replicaMetadataResponseInfo.getMessageInfoList().size() > 0) {\n-                replicationMetrics.updateCatchupPointMetricForCloudReplica(remoteReplicaInfo,\n-                    replicaMetadataResponseInfo.getMessageInfoList()\n-                        .get(replicaMetadataResponseInfo.getMessageInfoList().size() - 1)\n-                        .getOperationTimeMs());\n-              }\n-            } catch (Exception e) {\n-              if (e instanceof StoreException\n-                  && ((StoreException) e).getErrorCode() == StoreErrorCodes.Store_Not_Started) {\n-                // Must have just been stopped, just skip it and move on.\n-                logger.info(\"Local store not started for remote replica: {}\", remoteReplicaInfo.getReplicaId());\n-                exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-                if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-                  remoteReplicaInfo.setExchangeMetadataResponse(\n-                      new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                replicationMetrics.updateLagMetricForRemoteReplica(remoteReplicaInfo,\n+                    exchangeMetadataResponse.localLagFromRemoteInBytes);\n+                if (replicaMetadataResponseInfo.getMessageInfoList().size() > 0) {\n+                  replicationMetrics.updateCatchupPointMetricForCloudReplica(remoteReplicaInfo,\n+                      replicaMetadataResponseInfo.getMessageInfoList()\n+                          .get(replicaMetadataResponseInfo.getMessageInfoList().size() - 1)\n+                          .getOperationTimeMs());\n                 }\n-              } else {\n-                logger.error(\"Remote node: {} Thread name: {} Remote replica: {}\", remoteNode, threadName,\n-                    remoteReplicaInfo.getReplicaId(), e);\n-                replicationMetrics.updateLocalStoreError(remoteReplicaInfo.getReplicaId());\n-                responseHandler.onEvent(remoteReplicaInfo.getReplicaId(), e);\n-                exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Unknown_Error));\n-                if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n-                  remoteReplicaInfo.setExchangeMetadataResponse(\n-                      new ExchangeMetadataResponse(ServerErrorCode.Unknown_Error));\n+              } catch (Exception e) {\n+                if (e instanceof StoreException\n+                    && ((StoreException) e).getErrorCode() == StoreErrorCodes.Store_Not_Started) {\n+                  // Must have just been stopped, just skip it and move on.\n+                  logger.info(\"Local store not started for remote replica: {}\", remoteReplicaInfo.getReplicaId());\n+                  exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                } else {\n+                  logger.error(\"Remote node: {} Thread name: {} Remote replica: {}\", remoteNode, threadName,\n+                      remoteReplicaInfo.getReplicaId(), e);\n+                  replicationMetrics.updateLocalStoreError(remoteReplicaInfo.getReplicaId());\n+                  responseHandler.onEvent(remoteReplicaInfo.getReplicaId(), e);\n+                  exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Unknown_Error));\n                 }\n               }\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQyNjg5MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446426890", "bodyText": "nit: I find the words here are confusing, \"should be a leader locally\" doesn't really convey what this function would do, which is it checks if the local and remote replica are both the  leaders for given partition.\nSay if the partition is 100, and when the local replica becomes leader from standby, this map would have an entry {\"100\": List of remote leaders} inserted. But if the local replica becomes standby from leader, this entry would be removed.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T21:52:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,142 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+    LeaderBasedReplicationAdmin() {\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas. This method is thread safe.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+\n+      // Read-write lock avoids contention from threads removing old leader partitions (removePartition()) and\n+      // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        // Get the peer leader replicas from all data centers for this partition\n+        Set<ReplicaId> peerLeaderReplicas = getPeerLeaderReplicaSet(partitionName);\n+        logger.info(\"Adding leader Partition {} with list of peer leader replicas {}\", partitionName,\n+            peerLeaderReplicas);\n+        peerLeaderReplicasByPartition.put(partitionName, peerLeaderReplicas);\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Remove a partition from the map of leader partitions. This method is thread safe.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      // Read-write lock avoids contention from threads adding new leaders (addPartition()) and\n+      // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        logger.info(\"Removing leader Partition {}\", partitionName);\n+        peerLeaderReplicasByPartition.remove(partitionName);\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers. This method is thread safe.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      // Read-write lock usage: Avoids contention between threads doing the following activities:\n+      // 1. Adding new leaders (in addPeerLeadersByPartition())\n+      // 2. Removing old leaders (in removePartition())\n+      // 3. Refreshing remote leader set for existing leaders (current method).\n+      // Explanation for point 3: Multiple threads from different cluster change handlers (we have one cluster change handler for each DC)\n+      // can trigger onRoutingTableUpdate() in parallel which calls this method to refresh leader partitions.\n+      // We need to make sure that the sequence of gathering remote leaders (from RoutingTableSnapshot of each DC) and updating the map is an atomic operation.\n+\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        for (Map.Entry<String, Set<ReplicaId>> entry : peerLeaderReplicasByPartition.entrySet()) {\n+          String partitionName = entry.getKey();\n+          Set<ReplicaId> previousPeerLeaderReplicas = entry.getValue();\n+          Set<ReplicaId> currentPeerLeaderReplicas = getPeerLeaderReplicaSet(partitionName);\n+          if (!previousPeerLeaderReplicas.equals(currentPeerLeaderReplicas)) {\n+            logger.info(\"Refreshing leader Partition {} with list of peer leader replicas {}\", partitionName,\n+                currentPeerLeaderReplicas);\n+            peerLeaderReplicasByPartition.put(partitionName, currentPeerLeaderReplicas);\n+          }\n+        }\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return Collections.unmodifiableMap(peerLeaderReplicasByPartition);\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 0cb9f6a57..3b0ed0c34 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -510,13 +510,10 @@ public class ReplicationManager extends ReplicationEngine {\n      * @param messageInfoList list of messages written to store\n      */\n     void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n-      rwLock.readLock().lock();\n-      try {\n-        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n-        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n-      } finally {\n-        rwLock.readLock().unlock();\n-      }\n+      partitionToPartitionInfo.computeIfPresent(partitionId, (k, v) -> {\n+        v.updateReplicaInfosOnMessageWrite(messageInfoList);\n+        return v;\n+      });\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzMjY1OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446432658", "bodyText": "why use concurrentHashMap here, if all the operations are protected by a read write lock?", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:11:46Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,142 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 0cb9f6a57..3b0ed0c34 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -510,13 +510,10 @@ public class ReplicationManager extends ReplicationEngine {\n      * @param messageInfoList list of messages written to store\n      */\n     void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n-      rwLock.readLock().lock();\n-      try {\n-        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n-        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n-      } finally {\n-        rwLock.readLock().unlock();\n-      }\n+      partitionToPartitionInfo.computeIfPresent(partitionId, (k, v) -> {\n+        v.updateReplicaInfosOnMessageWrite(messageInfoList);\n+        return v;\n+      });\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzNjMyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446436320", "bodyText": "We should probably add a metric here to record this error, just in case we want to be alerted.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:25:28Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex ea06676c5..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1268,9 +1305,10 @@ public class ReplicaThread implements Runnable {\n   }\n \n   /**\n-   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n-   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n-   * intra-dc replication via leader in local data center.\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzNzE2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446437160", "bodyText": "nit: the function's name is too verbose, can we make it a bit shorter, something like applyUpdatesForMissingKeys.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:28:40Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex ea06676c5..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1268,9 +1305,10 @@ public class ReplicaThread implements Runnable {\n   }\n \n   /**\n-   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n-   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n-   * intra-dc replication via leader in local data center.\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzODQ3OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446438478", "bodyText": "nit: same here, can we find a shorter name?", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:33:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);\n+      // reset stored metadata response so that metadata request is sent again for this replica\n+      remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+    }\n+  }\n+\n+  /**\n+   * Checks if the input remote replica is a standby replica and has any messages from its previous metadata\n+   * exchange still missing in local store, i.e. they haven't arrived from leader via intra-dc replication.\n+   * @param remoteReplicaInfo remote replica information\n+   * @return true if missing messages in previous metadata exchange are not yet received\n+   */\n+  private boolean containsMissingKeysFromPreviousMetadataExchangeForStandbyReplica(", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex ea06676c5..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1268,9 +1305,10 @@ public class ReplicaThread implements Runnable {\n   }\n \n   /**\n-   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n-   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n-   * intra-dc replication via leader in local data center.\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446444207", "bodyText": "nit: the function name and comments are misleading, it's not only between leaders, it's also between standby and leader if it's local.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:57:21Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc4MTgwNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446781806", "bodyText": "Actually, I didn't see fetches between local standby <-> standby, local standby <-> leader in replicate() method.", "author": "jsjtzyy", "createdAt": "2020-06-29T05:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NDA2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447884060", "bodyText": "The method is changed. It used to have replicatingFromRemoteColo if-else statement here within the method. Now it's moved outside. This is fine. It's less confusing.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:11:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw=="}], "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex ea06676c5..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1268,9 +1305,10 @@ public class ReplicaThread implements Runnable {\n   }\n \n   /**\n-   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n-   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n-   * intra-dc replication via leader in local data center.\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0ODg4OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446448888", "bodyText": "nit: the repilcatingFromRemoteColo and leaderBaseReplicationAdmin check seem unnecessary, for this method only used when they are true.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T23:19:11Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex ea06676c5..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1268,9 +1305,10 @@ public class ReplicaThread implements Runnable {\n   }\n \n   /**\n-   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n-   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n-   * intra-dc replication via leader in local data center.\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxMjIxNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446712216", "bodyText": "minor:  that are written to store by other replica threads", "author": "jsjtzyy", "createdAt": "2020-06-28T23:31:00Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,46 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n+   * cycle) with messages that are written to store by other replicas. If there", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 2eb8fc8c9..00afc2b13 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -236,16 +236,15 @@ public class RemoteReplicaInfo {\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n-    // after they are written to local store via intra-dc replication.\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse received for this replica\n+    // and replica threads going through existing metadata response (via updateMissingMessagesInMetadataResponse()) to\n+    // to compare newly written messages to store with missing message set in metadata response.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n   /**\n-   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n-   * cycle) with messages that are written to store by other replicas. If there\n-   * are matching messages (based on their store key), remove them from stored metadata response information.\n+   * Update missing store messages found for this replica in its recent exchange metadata response by comparing\n+   * (based on the store key) with messages that are written to store by other replica threads.\n    * @param messagesWrittenToStore list of messages written to local store\n    */\n   synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxNzIyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446717220", "bodyText": "Although readLock may not cause any issue, I think we can simplify this and rely on concurrent map to enforce strict protection in multi-threaded environment:\n        partitionToPartitionInfo.computeIfPresent(partitionId, (k, v) -> {\n          v.updateReplicaInfosOnMessageWrite(messageInfoList);\n          return v;\n        });", "author": "jsjtzyy", "createdAt": "2020-06-29T00:15:41Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,143 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+    LeaderBasedReplicationAdmin() {\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\nindex 21121765c..3b0ed0c34 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java\n\n@@ -510,13 +510,10 @@ public class ReplicationManager extends ReplicationEngine {\n      * @param messageInfoList list of messages written to store\n      */\n     void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n-      rwLock.readLock().lock();\n-      try {\n-        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n-        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n-      } finally {\n-        rwLock.readLock().unlock();\n-      }\n+      partitionToPartitionInfo.computeIfPresent(partitionId, (k, v) -> {\n+        v.updateReplicaInfosOnMessageWrite(messageInfoList);\n+        return v;\n+      });\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxODkzNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446718934", "bodyText": "I need a little more clarification here:  if messageInfo from missingStoreMessages is DELETE/TTLUpdate etc rather than PUT, do we apply these updates?", "author": "jsjtzyy", "createdAt": "2020-06-29T00:29:48Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,46 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n+   * cycle) with messages that are written to store by other replicas. If there\n+   * are matching messages (based on their store key), remove them from stored metadata response information.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n+\n+    Set<MessageInfo> missingStoreMessages = exchangeMetadataResponse.getMissingStoreMessages();\n+    if (missingStoreMessages != null && !missingStoreMessages.isEmpty()) {\n+      Set<StoreKey> keysWrittenToStore =\n+          messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+      Set<MessageInfo> missingMessagesFoundInStore = new HashSet<>();\n+      for (MessageInfo messageInfo : missingStoreMessages) {\n+        if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+          missingMessagesFoundInStore.add(messageInfo);\n+        }\n+      }\n+      exchangeMetadataResponse.removeMissingStoreMessages(missingMessagesFoundInStore);", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg3NjE5Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447876196", "bodyText": "if it's delete, then we don't need it. a Delete MessageInfo would remove the blob key from the missingStoreMessages. So the blob key will not be in this set at the first beginning.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T17:57:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxODkzNA=="}], "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 2eb8fc8c9..00afc2b13 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -236,16 +236,15 @@ public class RemoteReplicaInfo {\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n-    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n-    // after they are written to local store via intra-dc replication.\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse received for this replica\n+    // and replica threads going through existing metadata response (via updateMissingMessagesInMetadataResponse()) to\n+    // to compare newly written messages to store with missing message set in metadata response.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n   /**\n-   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n-   * cycle) with messages that are written to store by other replicas. If there\n-   * are matching messages (based on their store key), remove them from stored metadata response information.\n+   * Update missing store messages found for this replica in its recent exchange metadata response by comparing\n+   * (based on the store key) with messages that are written to store by other replica threads.\n    * @param messagesWrittenToStore list of messages written to local store\n    */\n   synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc0Nzg2MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446747861", "bodyText": "minor: can be removed. (Also, please format this file)", "author": "jsjtzyy", "createdAt": "2020-06-29T03:05:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -28,13 +28,15 @@\n import com.github.ambry.network.ConnectionPool;\n import com.github.ambry.notification.NotificationSystem;\n import com.github.ambry.server.StoreManager;\n+import com.github.ambry.store.MessageInfo;", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\nindex ff14376d5..d2189b50f 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java\n\n@@ -41,6 +41,9 @@ import com.github.ambry.utils.Utils;\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc2NDk3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446764971", "bodyText": "minor: you might need to rebase. My recent PR has updated this condition.", "author": "jsjtzyy", "createdAt": "2020-06-29T04:26:14Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -335,28 +336,46 @@ public void replicate() {\n       long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n-      List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n-      for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n-        ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n-        boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n-        if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n-            || !remoteReplicaInfo.getLocalStore().isStarted()) {\n-          continue;\n+      // use a variable to track current replica list to replicate (for logging purpose)\n+      List<RemoteReplicaInfo> currentReplicaList = new ArrayList<>();\n+      try {\n+        // Get a list of active replicas that needs be included for this replication cycle\n+        List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n+        for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n+          ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n+          boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n+          if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n+              || !remoteReplicaInfo.getLocalStore().isStarted()) {", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 064c6fa90..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -333,7 +348,7 @@ public class ReplicaThread implements Runnable {\n       long checkoutConnectionTimeInMs = -1;\n       long exchangeMetadataTimeInMs = -1;\n       long fixMissingStoreKeysTimeInMs = -1;\n-      long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n+      long replicationStartTimeInMs = time.milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n       // use a variable to track current replica list to replicate (for logging purpose)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc2NTgwMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446765801", "bodyText": "May I ask why we moved try to here?", "author": "jsjtzyy", "createdAt": "2020-06-29T04:29:54Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -335,28 +336,46 @@ public void replicate() {\n       long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n-      List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n-      for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n-        ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n-        boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n-        if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n-            || !remoteReplicaInfo.getLocalStore().isStarted()) {\n-          continue;\n+      // use a variable to track current replica list to replicate (for logging purpose)\n+      List<RemoteReplicaInfo> currentReplicaList = new ArrayList<>();\n+      try {", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 064c6fa90..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -333,7 +348,7 @@ public class ReplicaThread implements Runnable {\n       long checkoutConnectionTimeInMs = -1;\n       long exchangeMetadataTimeInMs = -1;\n       long fixMissingStoreKeysTimeInMs = -1;\n-      long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n+      long replicationStartTimeInMs = time.milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n       // use a variable to track current replica list to replicate (for logging purpose)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3MDMzOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446770339", "bodyText": "Imagine a scenario where we are applying TtlUpdate or Delete, the store returns Already_Updated or ID_Deleted (it might be updated by other threads concurrently), then we reset the ExchangeMetadataResponse and send metadata request again. This should be fine eventually because next time the update should succeed. However, can we consider this scenario a success without resetting the ExchangeMetadataResponse? (I think this is more efficient)", "author": "jsjtzyy", "createdAt": "2020-06-29T04:49:15Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1282,186 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n+   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n+   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+      ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+      // Check if local replica and remote replica are leaders for this partition.\n+      if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponse(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NTUzMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447885532", "bodyText": "Don't worry about this case, since the applyTtlUpdate method already catches the Already_Updated exception. We will not see the 'Already_UpdatedandID_Deleted` exception being promoted here.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:13:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3MDMzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 064c6fa90..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1284,9 +1306,9 @@ public class ReplicaThread implements Runnable {\n \n   /**\n    * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n-   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n-   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n-   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3NTYwMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446775601", "bodyText": "minor:  String partitionName = remoteReplica.getPartitionId().toPathString();", "author": "jsjtzyy", "createdAt": "2020-06-29T05:11:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1282,186 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n+   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n+   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+      ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+      // Check if local replica and remote replica are leaders for this partition.\n+      if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponse(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);\n+      // reset stored metadata response so that metadata request is sent again for this replica\n+      remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+    }\n+  }\n+\n+  /**\n+   * Checks if the input remote replica is a standby replica and has any messages from its previous metadata\n+   * exchange still missing in local store, i.e. they haven't arrived from leader via intra-dc replication.\n+   * @param remoteReplicaInfo remote replica information\n+   * @return true if missing messages in previous metadata exchange are not yet received\n+   */\n+  boolean containsMissingKeysFromPreviousMetadataExchange(RemoteReplicaInfo remoteReplicaInfo) {\n+    String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+    ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 064c6fa90..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1284,9 +1306,9 @@ public class ReplicaThread implements Runnable {\n \n   /**\n    * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n-   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n-   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n-   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n    * @param remoteReplicaInfos list of all remote replicas\n    * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n    * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3NzMzMw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446777333", "bodyText": "minor: we probably can replace all SystemTime.getInstance() with time in this file.", "author": "jsjtzyy", "createdAt": "2020-06-29T05:18:52Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -371,44 +390,96 @@ public void replicate() {\n             List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+\n+            if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+              // If leader based replication is enabled and we are replicating from remote colo, fetch the missing blobs\n+              // only for local leader replicas from their corresponding peer leader replicas (Leader <-> Leader).\n+              // Non-leader replica pairs (standby <-> leaders, leader <-> standby, standby <-> standby) will get their\n+              // missing blobs from their leader pair exchanges and intra-dc replication.\n+              List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n+              getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n+                  exchangeMetadataResponseListForLeaderReplicas);\n+              replicaSubList = leaderReplicaList;\n+              exchangeMetadataResponseList = exchangeMetadataResponseListForLeaderReplicas;\n+            }\n+\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+            if (replicaSubList.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+            }\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n-        } catch (Throwable e) {\n-          if (checkoutConnectionTimeInMs == -1) {\n-            // throwable happened in checkout connection phase\n-            checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(activeReplicasPerNode.get(0).getReplicaId(), e);\n-          } else if (exchangeMetadataTimeInMs == -1) {\n-            // throwable happened in exchange metadata phase\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          } else if (fixMissingStoreKeysTimeInMs == -1) {\n-            // throwable happened in fix missing store phase\n+        }\n+\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          // Get a list of inactive standby replicas whose missing keys haven't arrived for long time.\n+          // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+          // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n+          // This is a safety condition to ensure that standby replicas are not stuck waiting for the keys to come from leader\n+          // by fetching the missing keys themselves.\n+          // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n+          // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n+          // This will involve co-ordination between replica threads containing replicas of same partition.\n+          List<RemoteReplicaInfo> standbyReplicasTimedOutOnNoProgress =\n+              getRemoteStandbyReplicasTimedOutOnNoProgress(replicasToReplicatePerNode);\n+          if (standbyReplicasTimedOutOnNoProgress.size() > 0) {\n+            allCaughtUp = false;\n+            currentReplicaList = standbyReplicasTimedOutOnNoProgress;\n+            if (connectedChannel == null) {\n+              connectedChannel = connectionPool.checkOutConnection(remoteNode.getHostname(),\n+                  standbyReplicasTimedOutOnNoProgress.get(0).getPort(),\n+                  replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n+              checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            }\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n+                standbyReplicasTimedOutOnNoProgress.stream()\n+                    .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                    .collect(Collectors.toList());\n+            exchangeMetadataTimeInMs = 0;\n+            fixMissingStoreKeysTimeInMs = -1;\n+            logger.debug(\n+                \"Sending GET request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n+                currentReplicaList);\n+            fixMissingStoreKeys(connectedChannel, standbyReplicasTimedOutOnNoProgress,\n+                exchangeMetadataResponseListForInactiveReplicas);\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n-          logger.error(\n-              \"Error while talking to peer: Remote node: {}, Thread name: {}, Remote replicas: {}, Current active \"\n-                  + \"remote replica list: {}, Checkout connection time: {}, Exchange metadata time: {}, Fix missing \"\n-                  + \"store key time {}\", remoteNode, threadName, replicasToReplicatePerNode, currentReplicaList,\n-              checkoutConnectionTimeInMs, exchangeMetadataTimeInMs, fixMissingStoreKeysTimeInMs, e);\n-          replicationMetrics.incrementReplicationErrors(replicatingOverSsl);\n-          if (connectedChannel != null) {\n-            connectionPool.destroyConnection(connectedChannel);\n-            connectedChannel = null;\n-          }\n-        } finally {\n-          long totalReplicationTime = SystemTime.getInstance().milliseconds() - replicationStartTimeInMs;\n-          replicationMetrics.updateTotalReplicationTime(totalReplicationTime, replicatingFromRemoteColo,\n-              replicatingOverSsl, datacenterName);\n-          if (connectedChannel != null) {\n-            connectionPool.checkInConnection(connectedChannel);\n-          }\n-          context.stop();\n-          portTypeBasedContext.stop();\n         }\n+      } catch (Throwable e) {\n+        if (checkoutConnectionTimeInMs == -1) {\n+          // throwable happened in checkout connection phase\n+          checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 064c6fa90..72b469658 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -379,23 +396,25 @@ public class ReplicaThread implements Runnable {\n           connectedChannel =\n               connectionPool.checkOutConnection(remoteNode.getHostname(), activeReplicasPerNode.get(0).getPort(),\n                   replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n-          checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+          checkoutConnectionTimeInMs = time.milliseconds() - startTimeInMs;\n           // we checkout ConnectedChannel once and replicate remote replicas in batch via same ConnectedChannel\n           for (List<RemoteReplicaInfo> replicaSubList : activeReplicaSubLists) {\n             exchangeMetadataTimeInMs = -1;\n             fixMissingStoreKeysTimeInMs = -1;\n             currentReplicaList = replicaSubList;\n             logger.debug(\"Exchanging metadata with {} remote replicas on {}\", currentReplicaList.size(), remoteNode);\n-            startTimeInMs = SystemTime.getInstance().milliseconds();\n+            startTimeInMs = time.milliseconds();\n             List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n                 exchangeMetadata(connectedChannel, replicaSubList);\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            exchangeMetadataTimeInMs = time.milliseconds() - startTimeInMs;\n \n             if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n               // If leader based replication is enabled and we are replicating from remote colo, fetch the missing blobs\n               // only for local leader replicas from their corresponding peer leader replicas (Leader <-> Leader).\n               // Non-leader replica pairs (standby <-> leaders, leader <-> standby, standby <-> standby) will get their\n               // missing blobs from their leader pair exchanges and intra-dc replication.\n+\n               List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n               List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n               getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n"}}, {"oid": "2360821368cc9e35edf30a99ad2291b1b21336f8", "url": "https://github.com/linkedin/ambry/commit/2360821368cc9e35edf30a99ad2291b1b21336f8", "message": "Squashing commits into one\n\nCore changes of leader based replication. It contains following:\n1. Filter leader and non-leader replicas in replica threads.\n2. Limit cross colo fetching of missing keys to leaders only.\n3. Store the missing keys information for standby replicas and track them via intra-dc replication.\n4. Update the remote token for standby replicas once all the missing keys are obtained.\n5. Changes to do cross colo fetch for standby replicas if missing keys haven't arrived for long time\n\nAdding unit test cases for leader based replication\n\nChanges:\n1. Extended range of config param replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds to take -1 to indicate that time out is disbled.\n2. Stored remoteKeyToLocalKeyMap in exchangeMetadataResponse to make use of converted keys when standby replicas update local blob properties of missing keys (lazily) after they are written to store via intra-dc replication.\n\nChanges to merge class PartitionLeaderInfo into LeaderBasedReplicationAdmin and unit testing force cross colo fetches for standby replicas\n\nAdd metrics to track number of cross colo get requests sent and bytes fetch rate for standby replicas which timed out waiting for missing keys to come from local leader.\n\nUnit test changes to verify following:\n 1. Standby replicas use up to date remote token when they become leaders.\n 2. Replication metrics for tracking cross colo get requests for standby replicas timed out on waiting for missing keys.\n\n1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'\n\nChanges to move mutable logic out of class RemoteReplicaInfo into Replica threads\n\nAddressing following review comments:\n 1. Replace systemTime.getInstance() with member variable time in ReplicaThread\n 2. Using ConcurrentHashMap.computeIfPresent() instead of read lock\n 3. Few other minor comments", "committedDate": "2020-06-29T22:10:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2MDM5Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447360392", "bodyText": "Minor: can use  stream().filter().collect()", "author": "lightningrob", "createdAt": "2020-06-30T01:51:30Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,45 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse received for this replica\n+    // and replica threads going through existing metadata response (via updateMissingMessagesInMetadataResponse()) to\n+    // to compare newly written messages to store with missing message set in metadata response.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Update missing store messages found for this replica in its recent exchange metadata response by comparing\n+   * (based on the store key) with messages that are written to store by other replica threads.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n+\n+    Set<MessageInfo> missingStoreMessages = exchangeMetadataResponse.getMissingStoreMessages();\n+    if (missingStoreMessages != null && !missingStoreMessages.isEmpty()) {\n+      Set<StoreKey> keysWrittenToStore =\n+          messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+      Set<MessageInfo> missingMessagesFoundInStore = new HashSet<>();", "originalCommit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNDE2OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448034169", "bodyText": "Sure, updated code to use stream().filter().collect()", "author": "Arun-LinkedIn", "createdAt": "2020-06-30T23:29:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2MDM5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\nindex 00afc2b13..ee30f5989 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java\n\n@@ -248,17 +247,13 @@ public class RemoteReplicaInfo {\n    * @param messagesWrittenToStore list of messages written to local store\n    */\n   synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n-\n     Set<MessageInfo> missingStoreMessages = exchangeMetadataResponse.getMissingStoreMessages();\n     if (missingStoreMessages != null && !missingStoreMessages.isEmpty()) {\n       Set<StoreKey> keysWrittenToStore =\n           messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n-      Set<MessageInfo> missingMessagesFoundInStore = new HashSet<>();\n-      for (MessageInfo messageInfo : missingStoreMessages) {\n-        if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n-          missingMessagesFoundInStore.add(messageInfo);\n-        }\n-      }\n+      Set<MessageInfo> missingMessagesFoundInStore = missingStoreMessages.stream()\n+          .filter(message -> keysWrittenToStore.contains(message.getStoreKey()))\n+          .collect(Collectors.toSet());\n       exchangeMetadataResponse.removeMissingStoreMessages(missingMessagesFoundInStore);\n     }\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg1Mzc5OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447853799", "bodyText": "@Arun-LinkedIn you need to add license here to pass the travis test. See other file for reference.", "author": "jsjtzyy", "createdAt": "2020-06-30T17:22:10Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java", "diffHunk": "@@ -0,0 +1,1177 @@\n+package com.github.ambry.replication;", "originalCommit": "4ece61e6d5ef9a2f41dda612d6eb42016e143540", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNDQ2OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448034469", "bodyText": "Thanks for letting me know. Added the license text.", "author": "Arun-LinkedIn", "createdAt": "2020-06-30T23:29:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg1Mzc5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java b/ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java\nindex 8dfbbda10..67823901a 100644\n--- a/ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java\n+++ b/ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java\n\n@@ -1,3 +1,17 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+\n package com.github.ambry.replication;\n \n import com.codahale.metrics.MetricRegistry;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4MjAxNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447882016", "bodyText": "the indentation is wonky", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:07:49Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -298,6 +297,22 @@ public void addRemoteReplicaInfo(RemoteReplicaInfo remoteReplicaInfo) {\n \n   /**\n    * Do replication for replicas grouped by {@link DataNodeId}\n+   * A replication cycle between two replicas involves the following steps:\n+   *    1. Exchange metadata : to fetch the blobs added to remote replica since the last synchronization offset and go through\n+   *       the local store to filter the ones missing locally\n+   *    2. Fetch missing keys: to fetch the blobs missing locally from remote replica by issuing GET requests and add them to\n+   *       the local store\n+   *  During cross-colo replication, depending on the {@link ReplicationModelType}, the second step to fetch missing\n+   *  keys happens in either all-to-all fashion (i.e. fetched from all cross colo replicas) or is limited to only leader\n+   *  replica pairs (i.e both local and remote replicas should be leaders of their partition).\n+   *  Here is a table listing on what is exchanged between local and remote replicas based on their roles (leader or\n+   *  standby) when {@link ReplicationModelType is LEADER_BASED}.\n+   *\n+   *                   |   Local Leader\t    |    Local Standby\t  |     Remote Leader\t  |  Remote Standby\n+   *      --------------------------------------------------------------------------------------------------\n+   *       Leader: \t   |        ---         |  metadata and data  |   metadata and data\t|   metadata only", "originalCommit": "4ece61e6d5ef9a2f41dda612d6eb42016e143540", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 05e8a1fc9..d84289b0d 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -298,20 +298,24 @@ public class ReplicaThread implements Runnable {\n   /**\n    * Do replication for replicas grouped by {@link DataNodeId}\n    * A replication cycle between two replicas involves the following steps:\n-   *    1. Exchange metadata : to fetch the blobs added to remote replica since the last synchronization offset and go through\n-   *       the local store to filter the ones missing locally\n-   *    2. Fetch missing keys: to fetch the blobs missing locally from remote replica by issuing GET requests and add them to\n+   *    1. Exchange metadata : fetch the metadata of blobs added to remote replica since the last synchronization point\n+   *    and filter the ones missing in local store.\n+   *    2. Fetch missing blobs: fetch the missing blobs by issuing GET request to remote replica and write them to\n    *       the local store\n-   *  During cross-colo replication, depending on the {@link ReplicationModelType}, the second step to fetch missing\n-   *  keys happens in either all-to-all fashion (i.e. fetched from all cross colo replicas) or is limited to only leader\n-   *  replica pairs (i.e both local and remote replicas should be leaders of their partition).\n-   *  Here is a table listing on what is exchanged between local and remote replicas based on their roles (leader or\n-   *  standby) when {@link ReplicationModelType is LEADER_BASED}.\n    *\n-   *                   |   Local Leader\t    |    Local Standby\t  |     Remote Leader\t  |  Remote Standby\n-   *      --------------------------------------------------------------------------------------------------\n-   *       Leader: \t   |        ---         |  metadata and data  |   metadata and data\t|   metadata only\n-   *       Standby: \t |  metadata and data |  metadata and data\t|   metadata only\t    |   metadata only\n+   *  During cross-colo replication, depending on the {@link ReplicationModelType}, the missing blobs are either fetched\n+   *  from all remote replicas (if modelType == ALL_TO_ALL) or only fetched for local leader replicas from their remote\n+   *  leader replicas (if modelType == LEADER_BASED). In the latter case, non-leader replica pairs (leader <-> standby,\n+   *  standby <-> leader, standby <-> standby) will get their missing blobs from their corresponding leader<->leader\n+   *  exchanges and intra-dc replication.\n+   *\n+   *  Here is a table listing on what is exchanged between local and remote replicas based on their roles\n+   *  (leader/standby) when {@link ReplicationModelType is LEADER_BASED}.\n+   *\n+   *              |   Local Leader    |     Local Standby   |   Remote Leader   |  Remote Standby\n+   *            -------------------------------------------------------------------------------------\n+   *     Leader:  |        ---        |  metadata and data  | metadata and data |   metadata only\n+   *     Standby: | metadata and data |  metadata and data  | metadata only     |   metadata only\n    *\n    */\n   public void replicate() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEzMzEwNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448133107", "bodyText": "I wonder why not put this logic in the code block starting from line 438 and pass in a boolean value to fixMissingStoreKeys and getMessagesForMissingKeys.  I see two benefits:\n\nyou don't have to if leaderBasedReplicationAdmin = null again;\nyou can skip some RemoteReplicaInfo associated with local leader replica;", "author": "jsjtzyy", "createdAt": "2020-07-01T06:02:09Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -884,14 +1029,25 @@ private GetResponse getMessagesForMissingKeys(ConnectedChannel connectedChannel,\n           GetRequest.Replication_Client_Id_Prefix + dataNodeId.getHostname() + \"[\" + dataNodeId.getDatacenterName()\n               + \"]\", MessageFormatFlags.All, partitionRequestInfoList,\n           replicationConfig.replicationIncludeAll ? GetOption.Include_All : GetOption.None);\n-      long startTime = SystemTime.getInstance().milliseconds();\n+      long startTime = time.milliseconds();\n       try {\n         connectedChannel.send(getRequest);\n         ChannelOutput channelOutput = connectedChannel.receive();\n         getResponse = GetResponse.readFrom(new DataInputStream(channelOutput.getInputStream()), clusterMap);\n-        long getRequestTime = SystemTime.getInstance().milliseconds() - startTime;\n+        long getRequestTime = time.milliseconds() - startTime;\n+        boolean remoteColoGetRequestForStandby = false;\n+        if (leaderBasedReplicationAdmin != null && replicatingFromRemoteColo) {\n+          // If leader-based replication is enabled, we should ideally send cross colo GET requests only between leaders.\n+          // However, if standby replicas time out waiting for their keys to come from leader, we send cross colo GETs\n+          // for them. Set 'remoteColoGetRequestForStandby' to true so that we track number of such cross colo GETs for standby replicas.\n+          ReplicaId localReplica = replicasToReplicatePerNode.get(0).getLocalReplicaId();\n+          ReplicaId remoteReplica = replicasToReplicatePerNode.get(0).getReplicaId();\n+          if (!leaderBasedReplicationAdmin.isLeaderPair(localReplica, remoteReplica)) {\n+            remoteColoGetRequestForStandby = true;\n+          }\n+        }", "originalCommit": "62994a9e5a1a62640ae9b9af87cc0a96c1bae64f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 1574964de..d84289b0d 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1035,17 +1038,6 @@ public class ReplicaThread implements Runnable {\n         ChannelOutput channelOutput = connectedChannel.receive();\n         getResponse = GetResponse.readFrom(new DataInputStream(channelOutput.getInputStream()), clusterMap);\n         long getRequestTime = time.milliseconds() - startTime;\n-        boolean remoteColoGetRequestForStandby = false;\n-        if (leaderBasedReplicationAdmin != null && replicatingFromRemoteColo) {\n-          // If leader-based replication is enabled, we should ideally send cross colo GET requests only between leaders.\n-          // However, if standby replicas time out waiting for their keys to come from leader, we send cross colo GETs\n-          // for them. Set 'remoteColoGetRequestForStandby' to true so that we track number of such cross colo GETs for standby replicas.\n-          ReplicaId localReplica = replicasToReplicatePerNode.get(0).getLocalReplicaId();\n-          ReplicaId remoteReplica = replicasToReplicatePerNode.get(0).getReplicaId();\n-          if (!leaderBasedReplicationAdmin.isLeaderPair(localReplica, remoteReplica)) {\n-            remoteColoGetRequestForStandby = true;\n-          }\n-        }\n         replicationMetrics.updateGetRequestTime(getRequestTime, replicatingFromRemoteColo, replicatingOverSsl,\n             datacenterName, remoteColoGetRequestForStandby);\n         if (getResponse.getError() != ServerErrorCode.No_Error) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEzNDA0Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448134046", "bodyText": "This condition can be improved. Instead of using metadata received timestamp. We can use the last timestamp when at least one messageInfo is removed from missing set. This is more reasonable for the method name \"no progress\", it may make a slow progress and timed out in middle way.  (This comment is optional, you can add a TODO here for further improvement)", "author": "jsjtzyy", "createdAt": "2020-07-01T06:05:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1135,6 +1306,189 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      ReplicaId localReplica = remoteReplicaInfo.getLocalReplicaId();\n+      ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n+      // Check if local replica and remote replica are leaders for their partition.\n+      if (leaderBasedReplicationAdmin.isLeaderPair(localReplica, remoteReplica)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos whose missing blobs in their metadata response haven't arrived within\n+   * time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {", "originalCommit": "62994a9e5a1a62640ae9b9af87cc0a96c1bae64f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\nindex 1574964de..d84289b0d 100644\n--- a/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n+++ b/ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java\n\n@@ -1348,16 +1331,16 @@ public class ReplicaThread implements Runnable {\n    */\n   List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n \n-    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n-    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n-    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n-    // the blobs themselves in order to avoid being stuck.\n+    // Use case: In leader-based cross colo replication, non-leader replica pairs don't fetch blobs for missing keys\n+    // found in metadata exchange and expect them to come from leader<->leader replication and intra-dc replication.\n+    // However, if for any reason, some of their missing blobs never arrive via local leader, this is a safety feature\n+    // for standbys to fetch the blobs themselves in order to avoid being stuck.\n \n     // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n     // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n-    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n-    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n-    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+    // PUT and DELETE together in its replication cycle. Due to that, deleted blob is not fetched by leader and is not\n+    // replicated from leader to standby. As a result, the corresponding PUT record in standby's missing blobs set is\n+    // never received.\n \n     // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n     // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NDc3Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448654776", "bodyText": "minor: can be package private", "author": "jsjtzyy", "createdAt": "2020-07-01T22:48:05Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java", "diffHunk": "@@ -51,6 +51,28 @@\n     this.clusterMap = clusterMap;\n   }\n \n+  /**\n+   * Adds an in-memory store to a partition if not present already\n+   * @param partitionId partition id\n+   * @param listener listener for store events\n+   */\n+  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java b/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\nindex 6a6de3595..f6e7d21d0 100644\n--- a/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\n+++ b/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\n\n@@ -56,7 +56,7 @@ public class MockHost {\n    * @param partitionId partition id\n    * @param listener listener for store events\n    */\n-  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n+  void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n     storesByPartition.computeIfAbsent(partitionId, partitionId1 -> new InMemoryStore(partitionId,\n         infosByPartition.computeIfAbsent(partitionId1,\n             (Function<PartitionId, List<MessageInfo>>) partitionId2 -> new ArrayList<>()),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NDg1Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448654857", "bodyText": "same here, can be package private", "author": "jsjtzyy", "createdAt": "2020-07-01T22:48:19Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java", "diffHunk": "@@ -51,6 +51,28 @@\n     this.clusterMap = clusterMap;\n   }\n \n+  /**\n+   * Adds an in-memory store to a partition if not present already\n+   * @param partitionId partition id\n+   * @param listener listener for store events\n+   */\n+  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n+    storesByPartition.computeIfAbsent(partitionId, partitionId1 -> new InMemoryStore(partitionId,\n+        infosByPartition.computeIfAbsent(partitionId1,\n+            (Function<PartitionId, List<MessageInfo>>) partitionId2 -> new ArrayList<>()),\n+        buffersByPartition.computeIfAbsent(partitionId1,\n+            (Function<PartitionId, List<ByteBuffer>>) partitionId22 -> new ArrayList<>()), listener));\n+  }\n+\n+  /**\n+   * Gets the in-memory store for the partition\n+   * @param partitionId partition id\n+   * @return in-memory store\n+   */\n+  public InMemoryStore getStore(PartitionId partitionId) {", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java b/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\nindex 6a6de3595..f6e7d21d0 100644\n--- a/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\n+++ b/ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java\n\n@@ -56,7 +56,7 @@ public class MockHost {\n    * @param partitionId partition id\n    * @param listener listener for store events\n    */\n-  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n+  void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n     storesByPartition.computeIfAbsent(partitionId, partitionId1 -> new InMemoryStore(partitionId,\n         infosByPartition.computeIfAbsent(partitionId1,\n             (Function<PartitionId, List<MessageInfo>>) partitionId2 -> new ArrayList<>()),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NzE2Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448657166", "bodyText": "Minor: this can be simplified as:\nSet<ReplicaId> peerLeaderReplicasInClusterMap =\nnew HashSet<>(existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null));", "author": "jsjtzyy", "createdAt": "2020-07-01T22:55:28Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java", "diffHunk": "@@ -705,23 +553,36 @@ public void replicaFromStandbyToLeaderTest() throws Exception {\n     ClusterMapConfig clusterMapConfig = new ClusterMapConfig(verifiableProperties);\n     MockHelixParticipant.metricRegistry = new MetricRegistry();\n     MockHelixParticipant mockHelixParticipant = new MockHelixParticipant(clusterMapConfig);\n+\n+    ReplicationConfig initialReplicationConfig = replicationConfig;\n+    properties.setProperty(\"replication.model.across.datacenters\", \"LEADER_BASED\");\n+    replicationConfig = new ReplicationConfig(new VerifiableProperties(properties));\n+\n     Pair<StorageManager, ReplicationManager> managers =\n         createStorageManagerAndReplicationManager(clusterMap, clusterMapConfig, mockHelixParticipant);\n     StorageManager storageManager = managers.getFirst();\n     MockReplicationManager replicationManager = (MockReplicationManager) managers.getSecond();\n-    PartitionId existingPartition = replicationManager.partitionToPartitionInfo.keySet().iterator().next();\n-    String currentDataCenter =\n-        storageManager.getReplica(existingPartition.toString()).getDataNodeId().getDatacenterName();\n-    mockHelixParticipant.onPartitionBecomeLeaderFromStandby(existingPartition.toPathString());\n-    Set<ReplicaId> peerLeaderReplicasInReplicationManager =\n-        replicationManager.partitionLeaderInfo.getPeerLeaderReplicasByPartition().get(existingPartition.toPathString());\n-    Set<ReplicaId> peerLeaderReplicasInClusterMap = existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null)\n-        .stream()\n-        .filter(r -> !r.getDataNodeId().getDatacenterName().equals(currentDataCenter))\n-        .collect(Collectors.toSet());\n-    assertThat(\"Mismatch in list of leader peer replicas stored by partition in replication manager and cluster map\",\n-        peerLeaderReplicasInReplicationManager, is(peerLeaderReplicasInClusterMap));\n+\n+    List<ReplicaId> replicaIds = clusterMap.getReplicaIds(replicationManager.dataNodeId);\n+    for (ReplicaId replicaId : replicaIds) {\n+      MockReplicaId mockReplicaId = (MockReplicaId) replicaId;\n+      if (mockReplicaId.getReplicaState() == ReplicaState.LEADER) {\n+        PartitionId existingPartition = mockReplicaId.getPartitionId();\n+        mockHelixParticipant.onPartitionBecomeLeaderFromStandby(existingPartition.toPathString());\n+        Set<ReplicaId> peerLeaderReplicasInReplicationManager =\n+            replicationManager.leaderBasedReplicationAdmin.getLeaderPartitionToPeerLeaderReplicas()\n+                .get(existingPartition.toPathString());\n+        Set<ReplicaId> peerLeaderReplicasInClusterMap =\n+            existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null).stream().collect(Collectors.toSet());", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "chunk": "diff --git a/ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java b/ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java\nindex d7d1470c3..3a2e1db03 100644\n--- a/ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java\n+++ b/ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java\n\n@@ -573,7 +573,7 @@ public class ReplicationTest extends ReplicationTestHelper {\n             replicationManager.leaderBasedReplicationAdmin.getLeaderPartitionToPeerLeaderReplicas()\n                 .get(existingPartition.toPathString());\n         Set<ReplicaId> peerLeaderReplicasInClusterMap =\n-            existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null).stream().collect(Collectors.toSet());\n+            new HashSet<>(existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null));\n         peerLeaderReplicasInClusterMap.remove(mockReplicaId);\n         assertThat(\n             \"Mismatch in list of leader peer replicas stored by partition in replication manager and cluster map\",\n"}}, {"oid": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "url": "https://github.com/linkedin/ambry/commit/01180f8ffb17df83bd13648ac5f4dce48e224a19", "message": "Make methods package-private", "committedDate": "2020-07-02T16:46:22Z", "type": "forcePushed"}, {"oid": "d684f9304301899e86f39c2d576bfb463b3d0396", "url": "https://github.com/linkedin/ambry/commit/d684f9304301899e86f39c2d576bfb463b3d0396", "message": "Squashing commits into one\n\nCore changes of leader based replication. It contains following:\n1. Filter leader and non-leader replicas in replica threads.\n2. Limit cross colo fetching of missing keys to leaders only.\n3. Store the missing keys information for standby replicas and track them via intra-dc replication.\n4. Update the remote token for standby replicas once all the missing keys are obtained.\n5. Changes to do cross colo fetch for standby replicas if missing keys haven't arrived for long time\n\nAdding unit test cases for leader based replication\n\nChanges:\n1. Extended range of config param replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds to take -1 to indicate that time out is disbled.\n2. Stored remoteKeyToLocalKeyMap in exchangeMetadataResponse to make use of converted keys when standby replicas update local blob properties of missing keys (lazily) after they are written to store via intra-dc replication.\n\nChanges to merge class PartitionLeaderInfo into LeaderBasedReplicationAdmin and unit testing force cross colo fetches for standby replicas\n\nAdd metrics to track number of cross colo get requests sent and bytes fetch rate for standby replicas which timed out waiting for missing keys to come from local leader.\n\nUnit test changes to verify following:\n 1. Standby replicas use up to date remote token when they become leaders.\n 2. Replication metrics for tracking cross colo get requests for standby replicas timed out on waiting for missing keys.\n\n1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'\n\nChanges to move mutable logic out of class RemoteReplicaInfo into Replica threads\n\nAddressing following review comments:\n 1. Replace systemTime.getInstance() with member variable time in ReplicaThread\n 2. Using ConcurrentHashMap.computeIfPresent() instead of read lock\n 3. Few other minor comments", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "f59adab6b3eb2beb6b912815e13176cf320cacd0", "url": "https://github.com/linkedin/ambry/commit/f59adab6b3eb2beb6b912815e13176cf320cacd0", "message": "Move LeaderBasedReplicationAdmin into ReplicationEngine", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "fe62e68db29e95e0d14b8230afdd118e070718d3", "url": "https://github.com/linkedin/ambry/commit/fe62e68db29e95e0d14b8230afdd118e070718d3", "message": "Add license text to new unit test files", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "eab7daa5ae11d3fa7f7026d7e78734c49641389a", "url": "https://github.com/linkedin/ambry/commit/eab7daa5ae11d3fa7f7026d7e78734c49641389a", "message": "Refine explanation in comments further and move try statement in replicate() method to right place", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "13f19075714b120e4f08d3cdedc5e4a2d2806573", "url": "https://github.com/linkedin/ambry/commit/13f19075714b120e4f08d3cdedc5e4a2d2806573", "message": "1. Pass in a boolean value to fixMissingStoreKeys to tell if we fetching blobs for standby replicas\n2. Use the last timestamp when at least one messageInfo is removed from missing set instead of metadata received timestamp", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "e2e94d3d6081c70ae750faeb192e318b50ed7fea", "url": "https://github.com/linkedin/ambry/commit/e2e94d3d6081c70ae750faeb192e318b50ed7fea", "message": "Make methods package-private", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "e2e94d3d6081c70ae750faeb192e318b50ed7fea", "url": "https://github.com/linkedin/ambry/commit/e2e94d3d6081c70ae750faeb192e318b50ed7fea", "message": "Make methods package-private", "committedDate": "2020-07-02T19:27:35Z", "type": "forcePushed"}]}