{"pr_number": 1522, "pr_title": "Introduce abstraction around InstanceConfigs", "pr_createdAt": "2020-05-18T20:51:57Z", "pr_url": "https://github.com/linkedin/ambry/pull/1522", "timeline": [{"oid": "f19c35f56ed450ae74e567ce6715de4703741bb7", "url": "https://github.com/linkedin/ambry/commit/f19c35f56ed450ae74e567ce6715de4703741bb7", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called ServerConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages.", "committedDate": "2020-05-18T21:20:17Z", "type": "forcePushed"}, {"oid": "a4e5af74231d4bc38c92135099a5034ce8648077", "url": "https://github.com/linkedin/ambry/commit/a4e5af74231d4bc38c92135099a5034ce8648077", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages.", "committedDate": "2020-05-19T23:33:19Z", "type": "forcePushed"}, {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "url": "https://github.com/linkedin/ambry/commit/6f3e45853c58a0de6d479c391f17ed99bdb028fe", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages.", "committedDate": "2020-05-21T01:08:28Z", "type": "commit"}, {"oid": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "url": "https://github.com/linkedin/ambry/commit/6f3e45853c58a0de6d479c391f17ed99bdb028fe", "message": "Introduce abstraction around InstanceConfigs\n\nThis PR introduces a new data object called DataNodeConfig and associated\nshims to convert InstanceConfig change notification into ServerConfigs.\n\nThis will provide a framework for future work to move away from storing\nambry specific server metadata in the InstanceConfigs, which comes with\nsome Helix performance and reliability advantages.", "committedDate": "2020-05-21T01:08:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MDA5MA==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r428750090", "bodyText": "Nice written to use observe pattern so that when DataNodeConfig changes state, the clusterChangeHandler are notified and updated through onDataNodeConfigChange!", "author": "SophieGuo410", "createdAt": "2020-05-21T15:58:33Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Objects;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.api.listeners.InstanceConfigChangeListener;\n+import org.apache.helix.model.InstanceConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.clustermap.ClusterMapUtils.*;\n+\n+\n+/**\n+ * An implementation of {@link DataNodeConfigSource} that converts between {@link InstanceConfig}s received by an\n+ * {@link InstanceConfigChangeListener} and {@link DataNodeConfig}s.\n+ */\n+public class InstanceConfigToDataNodeConfigAdapter implements DataNodeConfigSource {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(InstanceConfigToDataNodeConfigAdapter.class);\n+  private final HelixManager helixManager;\n+  private final ClusterMapConfig clusterMapConfig;\n+\n+  /**\n+   * @param helixManager the {@link HelixManager} to use as the source of truth for {@link InstanceConfig}s.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   */\n+  public InstanceConfigToDataNodeConfigAdapter(HelixManager helixManager, ClusterMapConfig clusterMapConfig) {\n+    this.helixManager = helixManager;\n+    this.clusterMapConfig = clusterMapConfig;\n+  }\n+\n+  @Override\n+  public void addServerConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception {\n+    helixManager.addInstanceConfigChangeListener((InstanceConfigChangeListener) (instanceConfigs, context) -> {\n+      Iterable<DataNodeConfig> dataNodeConfigs =\n+          () -> instanceConfigs.stream().map(this::convert).filter(Objects::nonNull).iterator();\n+      listener.onDataNodeConfigChange(dataNodeConfigs);", "originalCommit": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java\nindex 28e071e6c..cbe363a82 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/InstanceConfigToDataNodeConfigAdapter.java\n\n@@ -80,6 +80,8 @@ public class InstanceConfigToDataNodeConfigAdapter implements DataNodeConfigSour\n         getHttp2PortStr(instanceConfig), getRackId(instanceConfig), getXid(instanceConfig));\n     dataNodeConfig.getSealedReplicas().addAll(getSealedReplicas(instanceConfig));\n     dataNodeConfig.getStoppedReplicas().addAll(getStoppedReplicas(instanceConfig));\n+    // TODO uncomment this line once 1534 is merged\n+    // dataNodeConfig.getDisabledReplicas().addAll(getDisabledReplicas(instanceConfig));\n     instanceConfig.getRecord().getMapFields().forEach((mountPath, diskProps) -> {\n       if (diskProps.get(DISK_STATE) == null) {\n         // Check if this map field actually holds disk properties, since we can't tell from just the field key (the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDAzNDc4OA==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r430034788", "bodyText": "I will introduce another list of disabledReplicas in InstanceConfig (and will be migrated to DataNodeConfig in near future). Could you add a set of disabled replicas as a placeholder here?  For now it should be empty and no router logic depends on it. The purpose of disabledReplicas is to allow server to disable replicas on bad disk (also triggers state transition) and to automatically re-enable these replicas when disk is replaced and server is restarted.", "author": "jsjtzyy", "createdAt": "2020-05-25T18:00:06Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();", "originalCommit": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjAxMjgyOQ==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r432012829", "bodyText": "Is this introduced in #1534? I will take a look at that PR. Will disabledReplicas be cleared when a server is restarted and store startup succeeds?", "author": "cgtz", "createdAt": "2020-05-28T17:43:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDAzNDc4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjAxNDA2Ng==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r432014066", "bodyText": "Yes, that's true, it will be cleared if store starts successfully (which means disk is good or replaced). If you need more context, we can discuss it offline.", "author": "jsjtzyy", "createdAt": "2020-05-28T17:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDAzNDc4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjkxNDkzNg==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r436914936", "bodyText": "Added a placeholder for disabled replicas", "author": "cgtz", "createdAt": "2020-06-08T18:40:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDAzNDc4OA=="}], "type": "inlineReview", "revised_code": {"commit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex f2d3e00aa..34c3cd558 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -35,6 +35,7 @@ class DataNodeConfig {\n   private final long xid;\n   private final Set<String> sealedReplicas = new HashSet<>();\n   private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n   private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQ4NzI2Ng==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r433487266", "bodyText": "I wonder why these two sets are mutable?", "author": "jsjtzyy", "createdAt": "2020-06-01T21:00:17Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.", "originalCommit": "6f3e45853c58a0de6d479c391f17ed99bdb028fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIzMDk0OA==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r434230948", "bodyText": "I have not implemented this in this PR, but I was planning on HelixParticipant directly modifying these sets in DataNodeConfig for things like adding replicas and sealing partitions. If you prefer, I can introduce a builder with a copy constructor, but I felt like that was not needed given that this is similar to how InstanceConfig is treated/mutated in HelixParticipant.", "author": "cgtz", "createdAt": "2020-06-02T23:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQ4NzI2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex f2d3e00aa..34c3cd558 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -35,6 +35,7 @@ class DataNodeConfig {\n   private final long xid;\n   private final Set<String> sealedReplicas = new HashSet<>();\n   private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n   private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n \n   /**\n"}}, {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab", "url": "https://github.com/linkedin/ambry/commit/f77253fbd2c0c342617c1cff8dce8330265eebab", "message": "Add placeholder for disabled replics", "committedDate": "2020-06-08T18:40:29Z", "type": "commit"}, {"oid": "f77253fbd2c0c342617c1cff8dce8330265eebab", "url": "https://github.com/linkedin/ambry/commit/f77253fbd2c0c342617c1cff8dce8330265eebab", "message": "Add placeholder for disabled replics", "committedDate": "2020-06-08T18:40:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU5MTc5MQ==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437591791", "bodyText": "nit: format this file", "author": "jsjtzyy", "createdAt": "2020-06-09T17:16:05Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex 34c3cd558..f397ec55c 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -61,7 +61,7 @@ class DataNodeConfig {\n   }\n \n   /**\n-    * @return a name that can be used as a unique key for this server.\n+   * @return a name that can be used as a unique key for this server.\n    */\n   String getInstanceName() {\n     return instanceName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDc1Mg==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437624752", "bodyText": "typo: replicas", "author": "jsjtzyy", "createdAt": "2020-06-09T18:12:36Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';\n+  }\n+\n+  /**\n+   * Configuration scoped to a single disk on a server.\n+   */\n+  static class DiskConfig {\n+    private final HardwareState state;\n+    private final long diskCapacity;\n+    private final Map<String, ReplicaConfig> replicaConfigs = new HashMap<>();\n+\n+    /**\n+     * @param state the configured {@link HardwareState} of the disk.\n+     * @param diskCapacity the capacity of the disk in bytes.\n+     */\n+    DiskConfig(HardwareState state, long diskCapacity) {\n+      this.state = state;\n+      this.diskCapacity = diskCapacity;\n+    }\n+\n+    /**\n+     * @return the configured {@link HardwareState} of the disk.\n+     */\n+    HardwareState getState() {\n+      return state;\n+    }\n+\n+    /**\n+     * @return the capacity of the disk in bytes.\n+     */\n+    long getDiskCapacity() {\n+      return diskCapacity;\n+    }\n+\n+    /**\n+     * @return a map from partition name to {@link ReplicaConfig} for all the repliccas on the server.", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex 34c3cd558..f397ec55c 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -61,7 +61,7 @@ class DataNodeConfig {\n   }\n \n   /**\n-    * @return a name that can be used as a unique key for this server.\n+   * @return a name that can be used as a unique key for this server.\n    */\n   String getInstanceName() {\n     return instanceName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNjcwNA==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437626704", "bodyText": "minor:  could you add disabledReplicas as well?", "author": "jsjtzyy", "createdAt": "2020-06-09T18:16:01Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex 34c3cd558..f397ec55c 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -61,7 +61,7 @@ class DataNodeConfig {\n   }\n \n   /**\n-    * @return a name that can be used as a unique key for this server.\n+   * @return a name that can be used as a unique key for this server.\n    */\n   String getInstanceName() {\n     return instanceName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyODMxNQ==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437628315", "bodyText": "Can we rename diskCapacity to diskCapacityInBytes?  Same for replicaCapacity.", "author": "jsjtzyy", "createdAt": "2020-06-09T18:18:52Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+\n+/**\n+ * A data object for configs scoped to a single data node.\n+ */\n+class DataNodeConfig {\n+  private final String instanceName;\n+  private final String hostName;\n+  private final int port;\n+  private final String datacenterName;\n+  private final Integer sslPort;\n+  private final Integer http2Port;\n+  private final String rackId;\n+  private final long xid;\n+  private final Set<String> sealedReplicas = new HashSet<>();\n+  private final Set<String> stoppedReplicas = new HashSet<>();\n+  private final Set<String> disabledReplicas = new HashSet<>();\n+  private final Map<String, DiskConfig> diskConfigs = new HashMap<>();\n+\n+  /**\n+   * @param instanceName a name that can be used as a unique key for this server.\n+   * @param hostName the host name of the server.\n+   * @param port the port of the server.\n+   * @param datacenterName the datacenter this server is in.\n+   * @param sslPort the ssl port, or {@code null} if the server does not have one.\n+   * @param http2Port the HTTP2 port, or {@code null} if the server does not have one.\n+   * @param rackId an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   * @param xid  the xid for this server.\n+   */\n+  DataNodeConfig(String instanceName, String hostName, int port, String datacenterName, Integer sslPort,\n+      Integer http2Port, String rackId, long xid) {\n+    this.instanceName = instanceName;\n+    this.hostName = hostName;\n+    this.port = port;\n+    this.datacenterName = datacenterName;\n+    this.sslPort = sslPort;\n+    this.http2Port = http2Port;\n+    this.rackId = rackId;\n+    this.xid = xid;\n+  }\n+\n+  /**\n+    * @return a name that can be used as a unique key for this server.\n+   */\n+  String getInstanceName() {\n+    return instanceName;\n+  }\n+\n+  /**\n+   * @return the host name of the server.\n+   */\n+  String getHostName() {\n+    return hostName;\n+  }\n+\n+  /**\n+   * @return the port of the server.\n+   */\n+  int getPort() {\n+    return port;\n+  }\n+\n+  /**\n+   * @return the datacenter this server is in.\n+   */\n+  String getDatacenterName() {\n+    return datacenterName;\n+  }\n+\n+  /**\n+   * @return the ssl port, or {@code null} if the server does not have one.\n+   */\n+  Integer getSslPort() {\n+    return sslPort;\n+  }\n+\n+  /**\n+   * @return the HTTP2 port, or {@code null} if the server does not have one.\n+   */\n+  Integer getHttp2Port() {\n+    return http2Port;\n+  }\n+\n+  /**\n+   * @return an identifier for the rack or cabinet that the server is in for computing failure domains.\n+   */\n+  String getRackId() {\n+    return rackId;\n+  }\n+\n+  /**\n+   * @return the xid for this server. After {@link SimpleClusterChangeHandler} is retired, this field will be removed.\n+   */\n+  long getXid() {\n+    return xid;\n+  }\n+\n+  /**\n+   * @return the set of sealed replicas on this server. This set is mutable.\n+   */\n+  Set<String> getSealedReplicas() {\n+    return sealedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of stopped replicas on this server. This set is mutable.\n+   */\n+  Set<String> getStoppedReplicas() {\n+    return stoppedReplicas;\n+  }\n+\n+  /**\n+   * @return the set of disabled replicas on this server. This set is mutable.\n+   */\n+  Set<String> getDisabledReplicas() {\n+    return disabledReplicas;\n+  }\n+\n+  /**\n+   * @return a map from mount path to {@link DiskConfig} for all the disks on the server. This map is mutable.\n+   */\n+  Map<String, DiskConfig> getDiskConfigs() {\n+    return diskConfigs;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"ServerConfig{\" + \"instanceName='\" + instanceName + '\\'' + \", hostName='\" + hostName + '\\'' + \", port=\"\n+        + port + \", datacenterName='\" + datacenterName + '\\'' + \", sslPort=\" + sslPort + \", http2Port=\" + http2Port\n+        + \", rackId='\" + rackId + '\\'' + \", xid=\" + xid + \", sealedReplicas=\" + sealedReplicas + \", stoppedReplicas=\"\n+        + stoppedReplicas + \", diskConfigs=\" + diskConfigs + '}';\n+  }\n+\n+  /**\n+   * Configuration scoped to a single disk on a server.\n+   */\n+  static class DiskConfig {\n+    private final HardwareState state;\n+    private final long diskCapacity;", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\nindex 34c3cd558..f397ec55c 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfig.java\n\n@@ -61,7 +61,7 @@ class DataNodeConfig {\n   }\n \n   /**\n-    * @return a name that can be used as a unique key for this server.\n+   * @return a name that can be used as a unique key for this server.\n    */\n   String getInstanceName() {\n     return instanceName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1MzYwMQ==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437753601", "bodyText": "rename to addDataNodeConfigChangeListener?", "author": "jsjtzyy", "createdAt": "2020-06-09T22:18:00Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+/**\n+ * A source of {@link DataNodeConfig}s for a cluster. Can be used for config change notification and administration.\n+ */\n+interface DataNodeConfigSource {\n+  /**\n+   * Attach a listener that will be notified when there are new or updated {@link DataNodeConfig}s.\n+   * @param listener the {@link DataNodeConfigChangeListener} to attach.\n+   */\n+  void addServerConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception;", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java\nindex 707eb3b7f..b25d9ed01 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DataNodeConfigSource.java\n\n@@ -23,6 +23,5 @@ interface DataNodeConfigSource {\n    * Attach a listener that will be notified when there are new or updated {@link DataNodeConfig}s.\n    * @param listener the {@link DataNodeConfigChangeListener} to attach.\n    */\n-  void addServerConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception;\n+  void addDataNodeConfigChangeListener(DataNodeConfigChangeListener listener) throws Exception;\n }\n-\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTk0Nw==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437771947", "bodyText": "minor: based on {@link DataNodeConfig}(s)", "author": "jsjtzyy", "createdAt": "2020-06-09T23:11:41Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -275,25 +275,19 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   }\n \n   /**\n-   * Add new instance or update existing instance based on {@link InstanceConfig}(s). This may also invoke callbacks in\n-   * some clustermap change listeners (i.e. {@link PartitionSelectionHelper}, ReplicationManager)\n-   * @param instanceConfigs the {@link InstanceConfig}(s) used to update in-mem cluster map.\n-   * @throws Exception\n+   * Add new instances or update existing instances based on {@link InstanceConfig}(s). This may also invoke callbacks", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\nindex 428ad5f0f..146a43310 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n\n@@ -275,7 +274,7 @@ public class DynamicClusterChangeHandler implements HelixClusterChangeHandler {\n   }\n \n   /**\n-   * Add new instances or update existing instances based on {@link InstanceConfig}(s). This may also invoke callbacks\n+   * Add new instances or update existing instances based on {@link DataNodeConfig}(s). This may also invoke callbacks\n    * in some clustermap change listeners (i.e. {@link PartitionSelectionHelper}, ReplicationManager)\n    * @param dataNodeConfigs the {@link DataNodeConfig}(s) used to update in-mem cluster map.\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcyMw==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437776723", "bodyText": "minor: {@link DataNodeConfig}", "author": "jsjtzyy", "createdAt": "2020-06-09T23:26:37Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -433,22 +425,22 @@ private void updateReplicaStateAndOverrideIfNeeded(AmbryReplica replica, List<St\n \n   /**\n    * Create a new instance(node) and initialize disks/replicas on it.\n-   * @param instanceConfig the {@link InstanceConfig} to create new instance\n+   * @param dataNodeConfig the {@link InstanceConfig} to create new instance", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\nindex 428ad5f0f..146a43310 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n\n@@ -425,7 +424,7 @@ public class DynamicClusterChangeHandler implements HelixClusterChangeHandler {\n \n   /**\n    * Create a new instance(node) and initialize disks/replicas on it.\n-   * @param dataNodeConfig the {@link InstanceConfig} to create new instance\n+   * @param dataNodeConfig the {@link DataNodeConfig} to create new instance\n    * @return a list of newly added replicas;\n    * @throws Exception if there is an exception in instantiating the {@link ResourceStatePolicy}\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NzI2Ng==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437777266", "bodyText": "same here, {@link DataNodeConfig}", "author": "jsjtzyy", "createdAt": "2020-06-09T23:28:27Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -458,67 +450,52 @@ private void updateReplicaStateAndOverrideIfNeeded(AmbryReplica replica, List<St\n    * that partition is being constructed. If partition override is enabled, the seal state of replica is determined by\n    * partition info in HelixPropertyStore, if disabled, the seal state is determined by instanceConfig.\n    * @param datanode the {@link AmbryDataNode} that is being initialized.\n-   * @param instanceConfig the {@link InstanceConfig} associated with this datanode.\n+   * @param dataNodeConfig the {@link InstanceConfig} associated with this datanode.", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\nindex 428ad5f0f..146a43310 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java\n\n@@ -448,9 +447,9 @@ public class DynamicClusterChangeHandler implements HelixClusterChangeHandler {\n   /**\n    * Initialize the disks and replicas on the given node. Create partitions if this is the first time a replica of\n    * that partition is being constructed. If partition override is enabled, the seal state of replica is determined by\n-   * partition info in HelixPropertyStore, if disabled, the seal state is determined by instanceConfig.\n+   * partition info in HelixPropertyStore, if disabled, the seal state is determined by {@code dataNodeConfig}.\n    * @param datanode the {@link AmbryDataNode} that is being initialized.\n-   * @param dataNodeConfig the {@link InstanceConfig} associated with this datanode.\n+   * @param dataNodeConfig the {@link DataNodeConfig} associated with this datanode.\n    * @return a list of newly added replicas on this node.\n    * @throws Exception if creation of {@link AmbryDisk} throws an Exception.\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4MzkwMQ==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437783901", "bodyText": "can remove this comment", "author": "jsjtzyy", "createdAt": "2020-06-09T23:50:35Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java", "diffHunk": "@@ -270,86 +268,71 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n    * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n-   * @param instanceConfigs the list of {@link InstanceConfig}s containing the information about the sealed states of replicas.\n+   * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n+   *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n    */\n-  private void initializeInstances(List<InstanceConfig> instanceConfigs) throws Exception {\n+  private void initializeInstances(Iterable<DataNodeConfig> dataNodeConfigs) throws Exception {\n     logger.info(\"Initializing cluster information from {}\", dcName);\n-    for (InstanceConfig instanceConfig : instanceConfigs) {\n-      int schemaVersion = getSchemaVersion(instanceConfig);\n-      switch (schemaVersion) {\n-        case 0:\n-          String instanceName = instanceConfig.getInstanceName();\n-          long instanceXid = getXid(instanceConfig);\n-          if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n-            logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n-            // HTTP2 port null for now, until it's populated to Helix\n-            AmbryDataNode datanode =\n-                new AmbryServerDataNode(getDcName(instanceConfig), clusterMapConfig, instanceConfig.getHostName(),\n-                    Integer.parseInt(instanceConfig.getPort()), getRackId(instanceConfig),\n-                    getSslPortStr(instanceConfig), getHttp2PortStr(instanceConfig), instanceXid,\n-                    helixClusterManagerCallback);\n-            initializeDisksAndReplicasOnNode(datanode, instanceConfig);\n-            instanceNameToAmbryDataNode.put(instanceName, datanode);\n-          } else {\n-            logger.info(\n-                \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n-                instanceName, instanceXid, currentXid.get());\n-            helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n-          }\n-          break;\n-        default:\n-          logger.error(\"Unknown InstanceConfig schema version: {}, ignoring.\", schemaVersion);\n-          break;\n+    for (DataNodeConfig dataNodeConfig : dataNodeConfigs) {\n+      String instanceName = dataNodeConfig.getInstanceName();\n+      long instanceXid = dataNodeConfig.getXid();\n+      if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n+        logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n+        // HTTP2 port null for now, until it's populated to Helix", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\nindex dc42f6648..1e86e9c80 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\n\n@@ -267,7 +266,7 @@ public class SimpleClusterChangeHandler implements HelixClusterChangeHandler {\n \n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n-   * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n+   * cluster. A {@link DataNodeConfig} will only be looked at if the xid in it is <= currentXid.\n    * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n    *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4NDEwMA==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r437784100", "bodyText": "the given list of {@link DataNodeConfig}", "author": "jsjtzyy", "createdAt": "2020-06-09T23:51:15Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java", "diffHunk": "@@ -270,86 +268,71 @@ public void registerClusterMapListener(ClusterMapChangeListener clusterMapChange\n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n    * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n-   * @param instanceConfigs the list of {@link InstanceConfig}s containing the information about the sealed states of replicas.\n+   * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n+   *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n    */\n-  private void initializeInstances(List<InstanceConfig> instanceConfigs) throws Exception {\n+  private void initializeInstances(Iterable<DataNodeConfig> dataNodeConfigs) throws Exception {\n     logger.info(\"Initializing cluster information from {}\", dcName);\n-    for (InstanceConfig instanceConfig : instanceConfigs) {\n-      int schemaVersion = getSchemaVersion(instanceConfig);\n-      switch (schemaVersion) {\n-        case 0:\n-          String instanceName = instanceConfig.getInstanceName();\n-          long instanceXid = getXid(instanceConfig);\n-          if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n-            logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n-            // HTTP2 port null for now, until it's populated to Helix\n-            AmbryDataNode datanode =\n-                new AmbryServerDataNode(getDcName(instanceConfig), clusterMapConfig, instanceConfig.getHostName(),\n-                    Integer.parseInt(instanceConfig.getPort()), getRackId(instanceConfig),\n-                    getSslPortStr(instanceConfig), getHttp2PortStr(instanceConfig), instanceXid,\n-                    helixClusterManagerCallback);\n-            initializeDisksAndReplicasOnNode(datanode, instanceConfig);\n-            instanceNameToAmbryDataNode.put(instanceName, datanode);\n-          } else {\n-            logger.info(\n-                \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n-                instanceName, instanceXid, currentXid.get());\n-            helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n-          }\n-          break;\n-        default:\n-          logger.error(\"Unknown InstanceConfig schema version: {}, ignoring.\", schemaVersion);\n-          break;\n+    for (DataNodeConfig dataNodeConfig : dataNodeConfigs) {\n+      String instanceName = dataNodeConfig.getInstanceName();\n+      long instanceXid = dataNodeConfig.getXid();\n+      if (instanceName.equals(selfInstanceName) || instanceXid <= currentXid.get()) {\n+        logger.info(\"Adding node {} and its disks and replicas\", instanceName);\n+        // HTTP2 port null for now, until it's populated to Helix\n+        AmbryDataNode datanode =\n+            new AmbryServerDataNode(dataNodeConfig.getDatacenterName(), clusterMapConfig, dataNodeConfig.getHostName(),\n+                dataNodeConfig.getPort(), dataNodeConfig.getRackId(), dataNodeConfig.getSslPort(),\n+                dataNodeConfig.getHttp2Port(), instanceXid, helixClusterManagerCallback);\n+        initializeDisksAndReplicasOnNode(datanode, dataNodeConfig);\n+        instanceNameToAmbryDataNode.put(instanceName, datanode);\n+      } else {\n+        logger.info(\n+            \"Ignoring instanceConfig for {} because the xid associated with it ({}) is later than current xid ({})\",\n+            instanceName, instanceXid, currentXid.get());\n+        helixClusterManagerMetrics.ignoredUpdatesCount.inc();\n       }\n     }\n     logger.info(\"Initialized cluster information from {}\", dcName);\n   }\n \n   /**\n    * Go over the given list of {@link InstanceConfig}s and update the both sealed and stopped states of replicas.", "originalCommit": "f77253fbd2c0c342617c1cff8dce8330265eebab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\nindex dc42f6648..1e86e9c80 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/SimpleClusterChangeHandler.java\n\n@@ -267,7 +266,7 @@ public class SimpleClusterChangeHandler implements HelixClusterChangeHandler {\n \n   /**\n    * Populate the initial data from the admin connection. Create nodes, disks, partitions and replicas for the entire\n-   * cluster. An {@link InstanceConfig} will only be looked at if the xid in it is <= currentXid.\n+   * cluster. A {@link DataNodeConfig} will only be looked at if the xid in it is <= currentXid.\n    * @param dataNodeConfigs the list of {@link DataNodeConfig}s containing the information about the sealed states of\n    *                        replicas.\n    * @throws Exception if creation of {@link AmbryDataNode}s or {@link AmbryDisk}s throw an Exception.\n"}}, {"oid": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "url": "https://github.com/linkedin/ambry/commit/7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "message": "Address comments", "committedDate": "2020-06-10T15:39:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUyMzQ4Mg==", "url": "https://github.com/linkedin/ambry/pull/1522#discussion_r440523482", "bodyText": "Sorry, I didn't catch this when I was reviewing the code. It mistakenly assigned StoppedReplicas to sealedReplicas", "author": "jsjtzyy", "createdAt": "2020-06-16T00:46:29Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/DynamicClusterChangeHandler.java", "diffHunk": "@@ -310,81 +303,79 @@ private void addOrUpdateInstanceInfos(List<InstanceConfig> instanceConfigs) thro\n   /**\n    * Update info of an existing instance. This may happen in following cases: (1) new replica is added; (2) old replica\n    * is removed; (3) replica's state has changed (i.e. becomes seal/unseal).\n-   * @param instanceConfig the {@link InstanceConfig} used to update info of instance.\n+   * @param dataNodeConfig the {@link DataNodeConfig} used to update info of instance.\n    * @return a pair of lists: (1) new added replicas; (2) removed old replicas, during this update.\n    */\n-  private Pair<List<ReplicaId>, List<ReplicaId>> updateInstanceInfo(InstanceConfig instanceConfig) throws Exception {\n+  private Pair<List<ReplicaId>, List<ReplicaId>> updateInstanceInfo(DataNodeConfig dataNodeConfig) throws Exception {\n     final List<ReplicaId> addedReplicas = new ArrayList<>();\n     final List<ReplicaId> removedReplicas = new ArrayList<>();\n-    String instanceName = instanceConfig.getInstanceName();\n+    String instanceName = dataNodeConfig.getInstanceName();\n     logger.info(\"Updating replicas info for existing node {}\", instanceName);\n-    List<String> sealedReplicas = getSealedReplicas(instanceConfig);\n-    List<String> stoppedReplicas = getStoppedReplicas(instanceConfig);\n+    Set<String> sealedReplicas = dataNodeConfig.getStoppedReplicas();\n+    Set<String> stoppedReplicas = dataNodeConfig.getSealedReplicas();", "originalCommit": "7fbf11f5177df6a8750ffffd86f8fb30296d4cce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}