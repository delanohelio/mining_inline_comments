{"pr_number": 1559, "pr_title": "Support Hybrid Compaction Policy", "pr_createdAt": "2020-06-11T20:49:19Z", "pr_url": "https://github.com/linkedin/ambry/pull/1559", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzODIzMA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439138230", "bodyText": "we can make this static.", "author": "justinlin-linkedin", "createdAt": "2020-06-12T00:12:48Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy{\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private final Logger logger = LoggerFactory.getLogger(getClass());", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIwMjE5OQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r441202199", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-16T23:46:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzODIzMA=="}], "type": "inlineReview", "revised_code": {"commit": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 20ced174a..cfaeaea3d 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -16,7 +16,6 @@ package com.github.ambry.store;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzODY3MA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439138670", "bodyText": "nit: need to format this file.", "author": "justinlin-linkedin", "createdAt": "2020-06-12T00:13:36Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy{", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIwMzg1Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r441203853", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-16T23:52:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzODY3MA=="}], "type": "inlineReview", "revised_code": {"commit": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 20ced174a..cfaeaea3d 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -16,7 +16,6 @@ package com.github.ambry.store;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzOTgyMg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439139822", "bodyText": "info logs seem to verbose. Can you change it to trace?", "author": "justinlin-linkedin", "createdAt": "2020-06-12T00:15:39Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy{\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private final Logger logger = LoggerFactory.getLogger(getClass());\n+  private final SafeCounterWithoutLock counter;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    counter = new SafeCounterWithoutLock();\n+  }\n+\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats)\n+      throws StoreException {\n+    return selectCompactionPolicy().getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity,\n+        segmentHeaderSize, logSegmentsNotInJournal, blobStoreStats);\n+  }\n+\n+  /**\n+   * Selects which compaction policy needs to be used for current compaction cycle.\n+   * @return CompactAllPolicy if the round number of compaction reach to storeConfig.storeCompactionPolicySwitchPeriod.\n+   * Othewise @return StatsBasedCompactionPolicy.\n+   */\n+  CompactionPolicy selectCompactionPolicy(){\n+    if (counter.incrementAndGet() == 0) {\n+      logger.info(\"Return CompactAllPolicy this round\");", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIwNDExNg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r441204116", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-16T23:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEzOTgyMg=="}], "type": "inlineReview", "revised_code": {"commit": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 20ced174a..cfaeaea3d 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -16,7 +16,6 @@ package com.github.ambry.store;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE0MDIxOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439140219", "bodyText": "nit: Select which compaction policy to use ...", "author": "justinlin-linkedin", "createdAt": "2020-06-12T00:16:22Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy{\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private final Logger logger = LoggerFactory.getLogger(getClass());\n+  private final SafeCounterWithoutLock counter;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    counter = new SafeCounterWithoutLock();\n+  }\n+\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats)\n+      throws StoreException {\n+    return selectCompactionPolicy().getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity,\n+        segmentHeaderSize, logSegmentsNotInJournal, blobStoreStats);\n+  }\n+\n+  /**\n+   * Selects which compaction policy needs to be used for current compaction cycle.", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIwNDI3Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r441204277", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-16T23:53:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE0MDIxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 20ced174a..cfaeaea3d 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -16,7 +16,6 @@ package com.github.ambry.store;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE0MzgzMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439143833", "bodyText": "I don't feel good about the way we count the compaction round. All blobStore(partition) uses the same CompactionPolicy instance, they would interface each other and in some cases causes unexpected result.\nAssume we have 7 partitions in one host, and compaction manager trigger compaction on each one of them in the same order alway, p1, p2, p3...p7, p1, p2, p3... p7. In this case, P7 would always use CompactionAllPolicy and the other partitions would always use statsbased compaction policy.\nI think what we need is a per partition HybridCompactionPolicy. It can't be shared by partitions, because it's no longer a stateless object.", "author": "justinlin-linkedin", "createdAt": "2020-06-12T00:23:38Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy{", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg4OTg5OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r441889898", "bodyText": "Thanks for the advise. Implemented with first approach that maintains a map which key is replicaId and value is the counter.", "author": "SophieGuo410", "createdAt": "2020-06-17T23:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE0MzgzMw=="}], "type": "inlineReview", "revised_code": {"commit": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 20ced174a..cfaeaea3d 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -16,7 +16,6 @@ package com.github.ambry.store;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"oid": "11ae1f010e007d329f2a6da7b11dfd141dcceae7", "url": "https://github.com/linkedin/ambry/commit/11ae1f010e007d329f2a6da7b11dfd141dcceae7", "message": "support per replica compaction policy", "committedDate": "2020-06-16T08:20:52Z", "type": "forcePushed"}, {"oid": "f4f49ee6630105534f58a53de8846ef808ba321f", "url": "https://github.com/linkedin/ambry/commit/f4f49ee6630105534f58a53de8846ef808ba321f", "message": "support per replica compaction policy", "committedDate": "2020-06-16T16:17:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTAwOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443099009", "bodyText": "we actually don't have to differentiate the compaction policy factory when creating and incrementing the couter. We can just increment it for every policy.", "author": "justinlin-linkedin", "createdAt": "2020-06-20T04:03:56Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java", "diffHunk": "@@ -173,15 +178,30 @@ boolean removeBlobStore(BlobStore store) {\n     return true;\n   }\n \n+  /**\n+   * Get the current replicaToCounterMap policy.\n+   * @return {@link this.replicaToCounterMap}\n+   */\n+  Map<ReplicaId, CompactionPolicyCounter> getReplicaToCounterMap(){\n+    return this.replicaToCounterMap;\n+  }\n+\n   /**\n    * Get compaction details for a given {@link BlobStore} if any\n    * @param blobStore the {@link BlobStore} for which compaction details are requested\n    * @return the {@link CompactionDetails} containing the details about log segments that needs to be compacted.\n    * {@code null} if compaction is not required\n    * @throws StoreException when {@link BlobStore} is not started\n    */\n-  private CompactionDetails getCompactionDetails(BlobStore blobStore) throws StoreException {\n-    return blobStore.getCompactionDetails(compactionPolicy);\n+  CompactionDetails getCompactionDetails(BlobStore blobStore) throws StoreException {\n+    ReplicaId replicaId = blobStore.getReplicaId();\n+    if (compactionPolicyFactory != null && compactionPolicyFactory instanceof HybridCompactionPolicyFactory) {\n+      CompactionPolicyCounter compactionPolicyCounter =\n+          replicaToCounterMap.getOrDefault(replicaId, new CompactionPolicyCounter(storeConfig));\n+      compactionPolicyCounter.increment();\n+      replicaToCounterMap.put(replicaId, compactionPolicyCounter);\n+    }", "originalCommit": "2ebd942e2fcfdc1f780c8f39ddca7677bcfad106", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzk3MjYyMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443972623", "bodyText": "Move map inside Hybrid compaction policy.", "author": "SophieGuo410", "createdAt": "2020-06-23T05:36:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTAwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "1d7e07bba09f5382aae90529afb62d58dac5b739", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\nindex 5ca6cfe13..bebe97404 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n\n@@ -178,14 +178,6 @@ class CompactionManager {\n     return true;\n   }\n \n-  /**\n-   * Get the current replicaToCounterMap policy.\n-   * @return {@link this.replicaToCounterMap}\n-   */\n-  Map<ReplicaId, CompactionPolicyCounter> getReplicaToCounterMap(){\n-    return this.replicaToCounterMap;\n-  }\n-\n   /**\n    * Get compaction details for a given {@link BlobStore} if any\n    * @param blobStore the {@link BlobStore} for which compaction details are requested\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTE0Ng==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443099146", "bodyText": "let's set a limit here by using getInt(name, default, min, max). This would make sure that period would be 0 or negative number.", "author": "justinlin-linkedin", "createdAt": "2020-06-20T04:06:02Z", "path": "ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java", "diffHunk": "@@ -339,6 +346,7 @@ public StoreConfig(VerifiableProperties verifiableProperties) {\n     storeMaxNumberOfEntriesToReturnFromJournal =\n         verifiableProperties.getIntInRange(\"store.max.number.of.entries.to.return.from.journal\", 5000, 1, 10000);\n     storeDeletedMessageRetentionDays = verifiableProperties.getInt(\"store.deleted.message.retention.days\", 7);\n+    storeCompactionPolicySwitchPeriod = verifiableProperties.getInt(\"store.compaction.policy.switch.period\", 7);", "originalCommit": "2ebd942e2fcfdc1f780c8f39ddca7677bcfad106", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzk3MjY2Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443972667", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-23T05:36:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTE0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "1d7e07bba09f5382aae90529afb62d58dac5b739", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\nindex 543744e48..b483ac32d 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n\n@@ -346,7 +346,7 @@ public class StoreConfig {\n     storeMaxNumberOfEntriesToReturnFromJournal =\n         verifiableProperties.getIntInRange(\"store.max.number.of.entries.to.return.from.journal\", 5000, 1, 10000);\n     storeDeletedMessageRetentionDays = verifiableProperties.getInt(\"store.deleted.message.retention.days\", 7);\n-    storeCompactionPolicySwitchPeriod = verifiableProperties.getInt(\"store.compaction.policy.switch.period\", 7);\n+    storeCompactionPolicySwitchPeriod = verifiableProperties.getIntInRange(\"store.compaction.policy.switch.period\", 7, 1, 10);\n     storeContainerDeletionRetentionDays = verifiableProperties.getInt(\"store.container.deletion.retention.days\", 14);\n     storeHardDeleteOperationsBytesPerSec =\n         verifiableProperties.getIntInRange(\"store.hard.delete.operations.bytes.per.sec\", 100 * 1024, 1,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTI2Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443099267", "bodyText": "not used.", "author": "justinlin-linkedin", "createdAt": "2020-06-20T04:08:36Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import java.util.concurrent.atomic.AtomicInteger;", "originalCommit": "2ebd942e2fcfdc1f780c8f39ddca7677bcfad106", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzk3MjY5Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443972697", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-06-23T05:36:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTI2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "1d7e07bba09f5382aae90529afb62d58dac5b739", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\nindex a61603ca7..ecb7a997e 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n\n@@ -14,13 +14,12 @@\n package com.github.ambry.store;\n \n import com.github.ambry.config.StoreConfig;\n-import java.util.concurrent.atomic.AtomicInteger;\n \n \n /**\n  * A counter used to switch {@link CompactAllPolicy}.\n  */\n-public class CompactionPolicyCounter {\n+class CompactionPolicyCounter {\n   private final StoreConfig storeConfig;\n \n   CompactionPolicyCounter(StoreConfig storeConfig) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTcyNg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443099726", "bodyText": "I was wonder if you would consider this way. Using BlobStoreStats to pass store id, which is essentially the same as replica id number, to CompactionPolicy. And in CompactionPolicy, we keep a map from store id to a counter? In this way, we don't have to change interface here.", "author": "justinlin-linkedin", "createdAt": "2020-06-20T04:18:04Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java", "diffHunk": "@@ -37,6 +37,6 @@\n    * @throws StoreException\n    */\n   CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n-      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats)\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, CompactionPolicyCounter compactionPolicyCounter)", "originalCommit": "2ebd942e2fcfdc1f780c8f39ddca7677bcfad106", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzk3Mjk3OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443972978", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-23T05:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTcyNg=="}], "type": "inlineReview", "revised_code": {"commit": "1d7e07bba09f5382aae90529afb62d58dac5b739", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\nindex f333d7a9e..e383050e7 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n\n@@ -37,6 +37,6 @@ interface CompactionPolicy {\n    * @throws StoreException\n    */\n   CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n-      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, CompactionPolicyCounter compactionPolicyCounter)\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats)\n       throws StoreException;\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTc0OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443099748", "bodyText": "nit: drop public and make this class package-private.", "author": "justinlin-linkedin", "createdAt": "2020-06-20T04:18:36Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+\n+/**\n+ * A counter used to switch {@link CompactAllPolicy}.\n+ */\n+public class CompactionPolicyCounter {", "originalCommit": "2ebd942e2fcfdc1f780c8f39ddca7677bcfad106", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzk3MjkwMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r443972903", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-23T05:37:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA5OTc0OA=="}], "type": "inlineReview", "revised_code": {"commit": "1d7e07bba09f5382aae90529afb62d58dac5b739", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\nindex a61603ca7..ecb7a997e 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n\n@@ -14,13 +14,12 @@\n package com.github.ambry.store;\n \n import com.github.ambry.config.StoreConfig;\n-import java.util.concurrent.atomic.AtomicInteger;\n \n \n /**\n  * A counter used to switch {@link CompactAllPolicy}.\n  */\n-public class CompactionPolicyCounter {\n+class CompactionPolicyCounter {\n   private final StoreConfig storeConfig;\n \n   CompactionPolicyCounter(StoreConfig storeConfig) {\n"}}, {"oid": "1d7e07bba09f5382aae90529afb62d58dac5b739", "url": "https://github.com/linkedin/ambry/commit/1d7e07bba09f5382aae90529afb62d58dac5b739", "message": "maintain map inside compactionPolicy", "committedDate": "2020-06-22T23:56:06Z", "type": "forcePushed"}, {"oid": "3d80a04f6baec2b65fbab26492daf637320f1110", "url": "https://github.com/linkedin/ambry/commit/3d80a04f6baec2b65fbab26492daf637320f1110", "message": "maintain map inside compactionPolicy", "committedDate": "2020-06-23T05:31:34Z", "type": "forcePushed"}, {"oid": "294aaf326878a6f232abd0a123c23cd0bef33d6c", "url": "https://github.com/linkedin/ambry/commit/294aaf326878a6f232abd0a123c23cd0bef33d6c", "message": "Support Hybrid Compaction Policy", "committedDate": "2020-06-26T16:18:04Z", "type": "commit"}, {"oid": "0c3ca1f649486fa1be6196bf9709ba75c8c5d3ea", "url": "https://github.com/linkedin/ambry/commit/0c3ca1f649486fa1be6196bf9709ba75c8c5d3ea", "message": "support per replica compaction policy", "committedDate": "2020-06-26T16:18:04Z", "type": "commit"}, {"oid": "32c91b6d72b663931f6fb58d21220403cf7c2571", "url": "https://github.com/linkedin/ambry/commit/32c91b6d72b663931f6fb58d21220403cf7c2571", "message": "format change", "committedDate": "2020-06-26T16:18:04Z", "type": "commit"}, {"oid": "b7548a3e5720c29f31539d35b837245f37dc9aa0", "url": "https://github.com/linkedin/ambry/commit/b7548a3e5720c29f31539d35b837245f37dc9aa0", "message": "update to regular counter", "committedDate": "2020-06-26T16:18:04Z", "type": "commit"}, {"oid": "58e53947adc7d484b3568134078ee31a47c6f471", "url": "https://github.com/linkedin/ambry/commit/58e53947adc7d484b3568134078ee31a47c6f471", "message": "maintain map inside compactionPolicy", "committedDate": "2020-06-26T16:18:04Z", "type": "commit"}, {"oid": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "url": "https://github.com/linkedin/ambry/commit/769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "message": "upgrade HybridCompactionPolicy", "committedDate": "2020-06-26T16:22:10Z", "type": "commit"}, {"oid": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "url": "https://github.com/linkedin/ambry/commit/769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "message": "upgrade HybridCompactionPolicy", "committedDate": "2020-06-26T16:22:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM1NDIwMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r446354203", "bodyText": "why not just use jackson's objectmapper for de-serilization http://tutorials.jenkov.com/java-json/jackson-objectmapper.html#jackson-objectmapper-example. It would be just oneliner.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T18:50:46Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+import static com.github.ambry.utils.Utils.*;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACTION_POLICY_COUNTER = \"compactionPolicyCounter\";\n+  private static final String VALUE = \"value\";\n+  private static final String LAST_COMPACT_ALL_TIME = \"lastCompactAllTime\";\n+  private static final String COMPACT_POLICY_INFO_PATH = \"/compactionPolicyInfo.\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   * @throws StoreException\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = blobToCompactionPolicySwitchInfoMap.getOrDefault(storeId,\n+        new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig), INIT_COMPACT_ALL_TIME));\n+    blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, null);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactionTime\" : 1593128052284\n+   * }\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private void recoverCompactionPolicySwitchInfo(CompactionPolicySwitchInfo compactionPolicySwitchInfo, File file) {", "originalCommit": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE0NDk2Mg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447144962", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T17:46:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM1NDIwMw=="}], "type": "inlineReview", "revised_code": {"commit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 251697253..e30256f80 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -17,17 +17,15 @@ import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.io.File;\n import java.io.IOException;\n+import java.nio.file.Paths;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n-import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.codehaus.jackson.map.ObjectMapper;\n \n-import static com.github.ambry.utils.Utils.*;\n-\n \n /**\n  * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM2MjkxOA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r446362918", "bodyText": "logger.error", "author": "justinlin-linkedin", "createdAt": "2020-06-26T19:10:45Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+import static com.github.ambry.utils.Utils.*;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACTION_POLICY_COUNTER = \"compactionPolicyCounter\";\n+  private static final String VALUE = \"value\";\n+  private static final String LAST_COMPACT_ALL_TIME = \"lastCompactAllTime\";\n+  private static final String COMPACT_POLICY_INFO_PATH = \"/compactionPolicyInfo.\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   * @throws StoreException\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = blobToCompactionPolicySwitchInfoMap.getOrDefault(storeId,\n+        new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig), INIT_COMPACT_ALL_TIME));\n+    blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, null);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactionTime\" : 1593128052284\n+   * }\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private void recoverCompactionPolicySwitchInfo(CompactionPolicySwitchInfo compactionPolicySwitchInfo, File file) {\n+    try {\n+      JSONObject jsonObject = new JSONObject(readStringFromFile(file.toString()));\n+      JSONObject compactionPolicyCounter =\n+          jsonObject.has(COMPACTION_POLICY_COUNTER) ? jsonObject.getJSONObject(COMPACTION_POLICY_COUNTER) : null;\n+      int compactionPolicyCounterValue = INIT_COUNTER_VALUE;\n+      if (compactionPolicyCounter != null) {\n+        compactionPolicyCounterValue =\n+            compactionPolicyCounter.has(VALUE) ? compactionPolicyCounter.getInt(VALUE) : INIT_COUNTER_VALUE;\n+      } else {\n+        logger.trace(\"CompactionPolicyCounter is null\");\n+      }\n+      long lastCompactAllTime =\n+          jsonObject.has(LAST_COMPACT_ALL_TIME) ? jsonObject.getLong(LAST_COMPACT_ALL_TIME) : INIT_COMPACT_ALL_TIME;\n+      compactionPolicySwitchInfo.setLastCompactAllTime(lastCompactAllTime);\n+      compactionPolicySwitchInfo.getCompactionPolicyCounter().setValue(compactionPolicyCounterValue);\n+    } catch (IOException e) {\n+      logger.trace(\"tempFile : {} is not exist\", file);", "originalCommit": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE0NTAzOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447145039", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T17:46:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjM2MjkxOA=="}], "type": "inlineReview", "revised_code": {"commit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 251697253..e30256f80 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -17,17 +17,15 @@ import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.io.File;\n import java.io.IOException;\n+import java.nio.file.Paths;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n-import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.codehaus.jackson.map.ObjectMapper;\n \n-import static com.github.ambry.utils.Utils.*;\n-\n \n /**\n  * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNTgxOA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r446415818", "bodyText": "we can make logic a bit better without checking file every time selecting a policy. Something like\nif (!blobToCompactionPolicySwitchInfos.contain(storeId)) {\n    File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH))\n    if (file.exists()) {\n        ObjectMapper objectMapper = new ObjectMapper();\n        CompactionPolicySwitchInfo switchInfo = objectMapper.readValue(file, CompactionPolicySwithInfo.class);\n        blobToCompactionPolicySwtichInfos.put(storeId, switchInfo);\n    } else {\n        blobToCompactionPolicySwtichInfos.put(storeId, new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig), INIT_COMPACT_ALL_TIME));\n    }\n}", "author": "justinlin-linkedin", "createdAt": "2020-06-26T21:22:14Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+import static com.github.ambry.utils.Utils.*;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACTION_POLICY_COUNTER = \"compactionPolicyCounter\";\n+  private static final String VALUE = \"value\";\n+  private static final String LAST_COMPACT_ALL_TIME = \"lastCompactAllTime\";\n+  private static final String COMPACT_POLICY_INFO_PATH = \"/compactionPolicyInfo.\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   * @throws StoreException\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = blobToCompactionPolicySwitchInfoMap.getOrDefault(storeId,\n+        new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig), INIT_COMPACT_ALL_TIME));\n+    blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(dataDir, storeId, compactionPolicySwitchInfo);", "originalCommit": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE0NTExNQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447145115", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T17:46:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNTgxOA=="}], "type": "inlineReview", "revised_code": {"commit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 251697253..e30256f80 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -17,17 +17,15 @@ import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.io.File;\n import java.io.IOException;\n+import java.nio.file.Paths;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n-import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.codehaus.jackson.map.ObjectMapper;\n \n-import static com.github.ambry.utils.Utils.*;\n-\n \n /**\n  * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNzIzMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r446417233", "bodyText": "you can omit leading slash for two reasons\n\nIt's less cross-platform compatible, we can always use File.separator. Not that it matters here, just a nice pattern.\nUse Paths.get is probably a better way to concatenate different parts of the file path.\n\nAlso, dataDir already has the partition id/replica id/store id as the last part of the filepath, we don't need to suffix storeId in the filename here. But we can add .json as extension, just to indicate this is a json formatted file.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T21:26:20Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+import static com.github.ambry.utils.Utils.*;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACTION_POLICY_COUNTER = \"compactionPolicyCounter\";\n+  private static final String VALUE = \"value\";\n+  private static final String LAST_COMPACT_ALL_TIME = \"lastCompactAllTime\";\n+  private static final String COMPACT_POLICY_INFO_PATH = \"/compactionPolicyInfo.\";", "originalCommit": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE0NTE4Mg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447145182", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T17:46:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNzIzMw=="}], "type": "inlineReview", "revised_code": {"commit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 251697253..e30256f80 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -17,17 +17,15 @@ import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.io.File;\n import java.io.IOException;\n+import java.nio.file.Paths;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n-import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.codehaus.jackson.map.ObjectMapper;\n \n-import static com.github.ambry.utils.Utils.*;\n-\n \n /**\n  * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNzYyOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r446417629", "bodyText": "please pass dataDir here.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T21:27:23Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+import static com.github.ambry.utils.Utils.*;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACTION_POLICY_COUNTER = \"compactionPolicyCounter\";\n+  private static final String VALUE = \"value\";\n+  private static final String LAST_COMPACT_ALL_TIME = \"lastCompactAllTime\";\n+  private static final String COMPACT_POLICY_INFO_PATH = \"/compactionPolicyInfo.\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   * @throws StoreException\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = blobToCompactionPolicySwitchInfoMap.getOrDefault(storeId,\n+        new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig), INIT_COMPACT_ALL_TIME));\n+    blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, null);", "originalCommit": "769d92403ae7200c7fe1f3ea2ab5a116a6a7cac7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE0NTI2MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447145261", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T17:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNzYyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 251697253..e30256f80 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -17,17 +17,15 @@ import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import java.io.File;\n import java.io.IOException;\n+import java.nio.file.Paths;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n-import org.json.JSONObject;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.codehaus.jackson.map.ObjectMapper;\n \n-import static com.github.ambry.utils.Utils.*;\n-\n \n /**\n  * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n"}}, {"oid": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "url": "https://github.com/linkedin/ambry/commit/876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "message": "address comments", "committedDate": "2020-06-29T07:21:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIyOTExMA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447229110", "bodyText": "typo: swith-> switch", "author": "zzmao", "createdAt": "2020-06-29T20:19:21Z", "path": "ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java", "diffHunk": "@@ -81,6 +81,13 @@\n   @Default(\"7\")\n   public final int storeDeletedMessageRetentionDays;\n \n+  /**\n+   * How often the HybridCompactionPolicy swith from StatsBasedCompactionPolicy to CompactAllPolicy.", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjcwNQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282705", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIyOTExMA=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\nindex 42d95a355..a88fea50a 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n\n@@ -82,7 +82,7 @@ public class StoreConfig {\n   public final int storeDeletedMessageRetentionDays;\n \n   /**\n-   * How often the HybridCompactionPolicy swith from StatsBasedCompactionPolicy to CompactAllPolicy.\n+   * How often the HybridCompactionPolicy switch from StatsBasedCompactionPolicy to CompactAllPolicy.\n    */\n   @Config(\"store.compaction.policy.switch.period\")\n   @Default(\"7\")\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIyOTYzOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447229639", "bodyText": "Looks like this method is not used.", "author": "zzmao", "createdAt": "2020-06-29T20:20:23Z", "path": "ambry-store/src/main/java/com/github/ambry/store/BlobStore.java", "diffHunk": "@@ -1081,6 +1081,13 @@ public long getEndPositionOfLastPut() throws StoreException {\n     return replicaStatusDelegates;\n   }\n \n+  /**\n+   * @return a {@link ReplicaId} associated with this store\n+   */\n+  public ReplicaId getReplicaId() {", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjYxMw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282613", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIyOTYzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/BlobStore.java b/ambry-store/src/main/java/com/github/ambry/store/BlobStore.java\nindex efd04b63f..3763378ed 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/BlobStore.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/BlobStore.java\n\n@@ -1081,13 +1081,6 @@ public class BlobStore implements Store {\n     return replicaStatusDelegates;\n   }\n \n-  /**\n-   * @return a {@link ReplicaId} associated with this store\n-   */\n-  public ReplicaId getReplicaId() {\n-    return replicaId;\n-  }\n-\n   @Override\n   public void shutdown() throws StoreException {\n     shutdown(false);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjY1Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447232653", "bodyText": "not used.", "author": "zzmao", "createdAt": "2020-06-29T20:25:58Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java", "diffHunk": "@@ -13,12 +13,15 @@\n  */\n package com.github.ambry.store;\n \n+import com.github.ambry.clustermap.ReplicaId;", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\nindex f2f24fbfc..c226a352c 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n\n@@ -13,15 +13,12 @@\n  */\n package com.github.ambry.store;\n \n-import com.github.ambry.clustermap.ReplicaId;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import com.github.ambry.utils.Utils;\n import java.util.Collection;\n import java.util.EnumSet;\n-import java.util.HashMap;\n import java.util.HashSet;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.LinkedBlockingDeque;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjY5NA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447232694", "bodyText": "not used.", "author": "zzmao", "createdAt": "2020-06-29T20:26:04Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java", "diffHunk": "@@ -13,12 +13,15 @@\n  */\n package com.github.ambry.store;\n \n+import com.github.ambry.clustermap.ReplicaId;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import com.github.ambry.utils.Utils;\n import java.util.Collection;\n import java.util.EnumSet;\n+import java.util.HashMap;", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjgwMQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282801", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\nindex f2f24fbfc..c226a352c 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n\n@@ -13,15 +13,12 @@\n  */\n package com.github.ambry.store;\n \n-import com.github.ambry.clustermap.ReplicaId;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import com.github.ambry.utils.Utils;\n import java.util.Collection;\n import java.util.EnumSet;\n-import java.util.HashMap;\n import java.util.HashSet;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.LinkedBlockingDeque;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjc0OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447232748", "bodyText": "not used.", "author": "zzmao", "createdAt": "2020-06-29T20:26:10Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java", "diffHunk": "@@ -13,12 +13,15 @@\n  */\n package com.github.ambry.store;\n \n+import com.github.ambry.clustermap.ReplicaId;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import com.github.ambry.utils.Utils;\n import java.util.Collection;\n import java.util.EnumSet;\n+import java.util.HashMap;\n import java.util.HashSet;\n+import java.util.Map;", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjQ2Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282467", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:08:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjc0OA=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\nindex f2f24fbfc..c226a352c 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionManager.java\n\n@@ -13,15 +13,12 @@\n  */\n package com.github.ambry.store;\n \n-import com.github.ambry.clustermap.ReplicaId;\n import com.github.ambry.config.StoreConfig;\n import com.github.ambry.utils.Time;\n import com.github.ambry.utils.Utils;\n import java.util.Collection;\n import java.util.EnumSet;\n-import java.util.HashMap;\n import java.util.HashSet;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.LinkedBlockingDeque;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjk0Ng==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447232946", "bodyText": "java doc", "author": "zzmao", "createdAt": "2020-06-29T20:26:34Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java", "diffHunk": "@@ -33,10 +33,11 @@\n    *                                {@link Journal}\n    * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n    * {@link CompactionDetails} are requested\n+   * @param dataDir", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjM0OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282348", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:08:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzMjk0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\nindex 940276df1..946951e06 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n\n@@ -33,7 +33,7 @@ interface CompactionPolicy {\n    *                                {@link Journal}\n    * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n    * {@link CompactionDetails} are requested\n-   * @param dataDir\n+   * @param dataDir The directory to use to store compactionPolicyInfo\n    * @return {@link CompactionDetails} containing the details of segments to be compacted\n    * @throws StoreException\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzNjM3MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447236371", "bodyText": "add a field called \"lastCompactionAllTime\"?", "author": "zzmao", "createdAt": "2020-06-29T20:32:50Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactionTime\" : 1593128052284", "originalCommit": "876ad65183dc1dc22fd1f9a5a13bccbeb8714715", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4MjI2Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447282267", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-29T22:08:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzIzNjM3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex e30256f80..432edbf87 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -99,9 +99,11 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n    * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n    * {\n    *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n    *     \"value\" : 1\n    *   },\n-   *   \"lastCompactionTime\" : 1593128052284\n+   *   \"lastCompactAllTime\" : 1593463435900\n    * }\n    * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n    */\n"}}, {"oid": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "url": "https://github.com/linkedin/ambry/commit/fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "message": "address comments", "committedDate": "2020-06-29T20:56:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUzNDc2MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r439534761", "bodyText": "Is this still a TODO?", "author": "lightningrob", "createdAt": "2020-06-12T16:53:42Z", "path": "ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java", "diffHunk": "@@ -209,6 +209,7 @@ private void getDeprecatedContainers() {\n           deprecatedContainers.add(new Pair<>(container.getParentAccountId(), container.getId()));\n         }\n       });\n+      //TODO: Filter out the INACTIVE containers from deprecatedContainers set if it's already been compacted.", "originalCommit": "2d93b812d7ed78f8c47c4f87fe346177cf0d6360", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4MzM1NA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447883354", "bodyText": "Yes. That's an optimize that I plan to implement in a separate pr.", "author": "SophieGuo410", "createdAt": "2020-06-30T18:10:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUzNDc2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "294aaf326878a6f232abd0a123c23cd0bef33d6c", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java b/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java\nindex 085441bfc..0f3325409 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java\n\n@@ -205,7 +205,8 @@ class BlobStoreCompactor {\n     deprecatedContainers.clear();\n     if (accountService != null) {\n       accountService.getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS).forEach((container) -> {\n-        if (container.getDeleteTriggerTime() + TimeUnit.DAYS.toMillis(config.storeContainerDeletionRetentionDays) >= System.currentTimeMillis()) {\n+        if (container.getDeleteTriggerTime() + TimeUnit.DAYS.toMillis(config.storeContainerDeletionRetentionDays)\n+            <= System.currentTimeMillis()) {\n           deprecatedContainers.add(new Pair<>(container.getParentAccountId(), container.getId()));\n         }\n       });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzMTA0Ng==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447331046", "bodyText": "Please add Days to end to be consistent (and clearer).", "author": "lightningrob", "createdAt": "2020-06-30T00:14:35Z", "path": "ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java", "diffHunk": "@@ -81,6 +81,13 @@\n   @Default(\"7\")\n   public final int storeDeletedMessageRetentionDays;\n \n+  /**\n+   * How often the HybridCompactionPolicy switch from StatsBasedCompactionPolicy to CompactAllPolicy.\n+   */\n+  @Config(\"store.compaction.policy.switch.period\")\n+  @Default(\"7\")\n+  public final int storeCompactionPolicySwitchPeriod;", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTU5OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447415598", "bodyText": "Updated. And I separated the storeCompactionPolicySwitchTimestampDays and storeCompactionPolicySwitchCounterDays to make the tuning more flexible.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:19:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzMTA0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\nindex a88fea50a..cf6c82722 100644\n--- a/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n+++ b/ambry-api/src/main/java/com/github/ambry/config/StoreConfig.java\n\n@@ -82,11 +82,18 @@ public class StoreConfig {\n   public final int storeDeletedMessageRetentionDays;\n \n   /**\n-   * How often the HybridCompactionPolicy switch from StatsBasedCompactionPolicy to CompactAllPolicy.\n+   * How often the HybridCompactionPolicy switch from StatsBasedCompactionPolicy to CompactAllPolicy based on timestamp.\n    */\n-  @Config(\"store.compaction.policy.switch.period\")\n+  @Config(\"store.compaction.policy.switch.timestamp.days\")\n   @Default(\"7\")\n-  public final int storeCompactionPolicySwitchPeriod;\n+  public final int storeCompactionPolicySwitchTimestampDays;\n+\n+  /**\n+   * How often the HybridCompactionPolicy switch from StatsBasedCompactionPolicy to CompactAllPolicy based on counter value.\n+   */\n+  @Config(\"store.compaction.policy.switch.counter.days\")\n+  @Default(\"7\")\n+  public final int storeCompactionPolicySwitchCounterDays;\n \n   /**\n    * How long (in days) a container must be in DELETE_IN_PROGRESS state before it's been deleted during compaction.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzMTgwNA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447331804", "bodyText": "for this blob store.", "author": "lightningrob", "createdAt": "2020-06-30T00:17:01Z", "path": "ambry-store/src/main/java/com/github/ambry/store/BlobStoreStats.java", "diffHunk": "@@ -1117,6 +1117,13 @@ void cancel() {\n     }\n   }\n \n+  /**\n+   * @return the storeId for this blob.", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTc5Mg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447415792", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzMTgwNA=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/BlobStoreStats.java b/ambry-store/src/main/java/com/github/ambry/store/BlobStoreStats.java\nindex 018568423..6007a95b5 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/BlobStoreStats.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/BlobStoreStats.java\n\n@@ -1118,12 +1118,19 @@ class BlobStoreStats implements StoreStats, Closeable {\n   }\n \n   /**\n-   * @return the storeId for this blob.\n+   * @return the storeId for this {@link BlobStore}.\n    */\n   String getStoreId() {\n     return this.storeId;\n   }\n \n+  /**\n+   * @return the {@link StoreMetrics} for this {@link BlobStore}.\n+   */\n+  StoreMetrics getMetrics() {\n+    return this.metrics;\n+  }\n+\n   /**\n    * An action to take on a single {@link IndexEntry}\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNTA3Ng==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447335076", "bodyText": "Does this refer to CompactionPolicySwitchInfo or something else?", "author": "lightningrob", "createdAt": "2020-06-30T00:25:47Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java", "diffHunk": "@@ -33,10 +33,11 @@\n    *                                {@link Journal}\n    * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n    * {@link CompactionDetails} are requested\n+   * @param dataDir The directory to use to store compactionPolicyInfo", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjA1MA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416050", "bodyText": "Updated with CompactionPolicySwitchInfo. Sorry for the confusion.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:20:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNTA3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\nindex 946951e06..26b22cd16 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicy.java\n\n@@ -33,7 +33,7 @@ interface CompactionPolicy {\n    *                                {@link Journal}\n    * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n    * {@link CompactionDetails} are requested\n-   * @param dataDir The directory to use to store compactionPolicyInfo\n+   * @param dataDir The directory to use to store {@link CompactionPolicySwitchInfo}\n    * @return {@link CompactionDetails} containing the details of segments to be compacted\n    * @throws StoreException\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNjE3Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447336173", "bodyText": "Reason for these methods to use Value instead of Counter?  Some convention required?", "author": "lightningrob", "createdAt": "2020-06-30T00:28:38Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import org.codehaus.jackson.annotate.JsonAutoDetect;\n+import org.codehaus.jackson.annotate.JsonPropertyOrder;\n+\n+\n+/**\n+ * A counter used to switch {@link CompactAllPolicy}.\n+ */\n+@JsonPropertyOrder({\"storeCompactionPolicySwitchPeriod\", \"counter\"})\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY)\n+class CompactionPolicyCounter {\n+  private int storeCompactionPolicySwitchPeriod;\n+  private int counter;\n+\n+  CompactionPolicyCounter(int storeCompactionPolicySwitchPeriod) {\n+    this.storeCompactionPolicySwitchPeriod = storeCompactionPolicySwitchPeriod;\n+  }\n+\n+  //make sure objectMapper can work correctly\n+  CompactionPolicyCounter() {\n+  }\n+\n+  public int getValue() {", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNzUxOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447337519", "bodyText": "Also add method javadocs.", "author": "lightningrob", "createdAt": "2020-06-30T00:32:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNjE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjI0MA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416240", "bodyText": "Change to counter to be more clear and added the javadocs.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:21:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzNjE3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\nindex c3c4c730b..778b84a1f 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicyCounter.java\n\n@@ -20,29 +20,42 @@ import org.codehaus.jackson.annotate.JsonPropertyOrder;\n /**\n  * A counter used to switch {@link CompactAllPolicy}.\n  */\n-@JsonPropertyOrder({\"storeCompactionPolicySwitchPeriod\", \"counter\"})\n+@JsonPropertyOrder({\"storeCompactionPolicySwitchCounterDays\", \"counter\"})\n @JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY)\n class CompactionPolicyCounter {\n-  private int storeCompactionPolicySwitchPeriod;\n+  private int storeCompactionPolicySwitchCounterDays;\n   private int counter;\n \n-  CompactionPolicyCounter(int storeCompactionPolicySwitchPeriod) {\n-    this.storeCompactionPolicySwitchPeriod = storeCompactionPolicySwitchPeriod;\n+  CompactionPolicyCounter(int storeCompactionPolicySwitchCounterDays) {\n+    this.storeCompactionPolicySwitchCounterDays = storeCompactionPolicySwitchCounterDays;\n   }\n \n-  //make sure objectMapper can work correctly\n+  /**\n+   * make sure objectMapper can work correctly\n+   */\n   CompactionPolicyCounter() {\n   }\n \n-  public int getValue() {\n+  /**\n+   * Gets the current counter.\n+   * @return the value of the counter.\n+   */\n+  public int getCounter() {\n     return counter;\n   }\n \n-  public void setValue(int val) {\n-    this.counter = val;\n+  /**\n+   * Set the current counter value;\n+   * @param counter the counter value to determine which {@link CompactionPolicy} to use for each compaction cycle.\n+   */\n+  public void setCounter(int counter) {\n+    this.counter = counter;\n   }\n \n+  /**\n+   * Increment the counter value each compaction cycle and mod storeCompactionPolicySwitchPeriodDays.\n+   */\n   public void increment() {\n-    counter = (counter + 1) % storeCompactionPolicySwitchPeriod;\n+    counter = (counter + 1) % storeCompactionPolicySwitchCounterDays;\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzODAyNg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447338026", "bodyText": "Javadocs", "author": "lightningrob", "createdAt": "2020-06-30T00:34:43Z", "path": "ambry-store/src/main/java/com/github/ambry/store/CompactionPolicySwitchInfo.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import org.codehaus.jackson.annotate.JsonAutoDetect;\n+import org.codehaus.jackson.annotate.JsonPropertyOrder;\n+\n+\n+/**\n+ * The {@link CompactionPolicy} info to determine when to use which {@link CompactionPolicy}.\n+ */\n+@JsonPropertyOrder({\"compactionPolicyCounter\", \"lastCompactionTime\"})\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY)\n+public class CompactionPolicySwitchInfo {\n+  private CompactionPolicyCounter compactionPolicyCounter;\n+  private long lastCompactAllTime;\n+\n+  CompactionPolicySwitchInfo(CompactionPolicyCounter compactionPolicyCounter, long lastCompactAllTime) {\n+    this.compactionPolicyCounter = compactionPolicyCounter;\n+    this.lastCompactAllTime = lastCompactAllTime;\n+  }\n+\n+  //make sure objectMapper can work correctly\n+  CompactionPolicySwitchInfo() {\n+  }\n+\n+  CompactionPolicyCounter getCompactionPolicyCounter() {", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjM4MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416381", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:21:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMzODAyNg=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicySwitchInfo.java b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicySwitchInfo.java\nindex ef83b209f..b26ba700c 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicySwitchInfo.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/CompactionPolicySwitchInfo.java\n\n@@ -26,23 +26,42 @@ public class CompactionPolicySwitchInfo {\n   private CompactionPolicyCounter compactionPolicyCounter;\n   private long lastCompactAllTime;\n \n+  /**\n+   * Constructor to create {@link CompactionPolicySwitchInfo} object.\n+   * @param compactionPolicyCounter Counter used to switch {@link CompactAllPolicy}\n+   * @param lastCompactAllTime last time when {@link CompactAllPolicy} has been selected.\n+   */\n   CompactionPolicySwitchInfo(CompactionPolicyCounter compactionPolicyCounter, long lastCompactAllTime) {\n     this.compactionPolicyCounter = compactionPolicyCounter;\n     this.lastCompactAllTime = lastCompactAllTime;\n   }\n \n-  //make sure objectMapper can work correctly\n+  /**\n+   * make sure objectMapper can work correctly\n+   */\n   CompactionPolicySwitchInfo() {\n   }\n \n+  /**\n+   * Get current {@link CompactionPolicyCounter}\n+   * @return {@link CompactionPolicyCounter}\n+   */\n   CompactionPolicyCounter getCompactionPolicyCounter() {\n     return this.compactionPolicyCounter;\n   }\n \n+  /**\n+   * Get the last time when {@link CompactAllPolicy} has been selected.\n+   * @return the last time when {@link CompactAllPolicy} has been selected.\n+   */\n   long getLastCompactAllTime() {\n     return this.lastCompactAllTime;\n   }\n \n+  /**\n+   * Set the last time when {@link CompactAllPolicy} has been selected.\n+   * @param lastCompactAllTime last time when {@link CompactAllPolicy} has been selected.\n+   */\n   void setLastCompactAllTime(long lastCompactAllTime) {\n     this.lastCompactAllTime = lastCompactAllTime;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MDQ4Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447340483", "bodyText": "Minor: more like getOrRecover.  Or just get, since reading from file is an impl detail.", "author": "lightningrob", "createdAt": "2020-06-30T00:43:05Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjY4MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416681", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:23:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MDQ4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTA2OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447341068", "bodyText": "Do you actually have both counter and value?", "author": "lightningrob", "createdAt": "2020-06-30T00:45:11Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjc5NQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416795", "bodyText": "Updated to have counter only.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:23:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTA2OA=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTM1NQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447341355", "bodyText": "Use static ObjectMapper.", "author": "lightningrob", "createdAt": "2020-06-30T00:46:06Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjg5Nw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416897", "bodyText": "Done.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:23:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTM1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTc4Mg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447341782", "bodyText": "If we're eating the exception and using default, should add an error metric since it likely indicates a bug.", "author": "lightningrob", "createdAt": "2020-06-30T00:47:27Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNjk5OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447416998", "bodyText": "Add the metrics.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MTc4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MzU4OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447343588", "bodyText": "What happens if we reset the info and host crashes before CompactAll compaction makes much progress?  After restart, will it go back to StatsBased?", "author": "lightningrob", "createdAt": "2020-06-30T00:53:57Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+    if (readyToTriggerCompactionAllPolicy(compactionPolicySwitchInfo)) {\n+      logger.trace(\"Return CompactAllPolicy this round\");\n+      updateCompactionInfo(compactionPolicySwitchInfo);\n+      return new CompactAllPolicy(storeConfig, time);\n+    } else {\n+      if (compactionPolicySwitchInfo.getCompactionPolicyCounter() == null) {\n+        logger.trace(\"Counter is null\");\n+      } else {\n+        logger.trace(\"Return StatsBasedCompactionPolicy this round\");\n+      }\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+  }\n+\n+  /**\n+   * Determine which compactionPolicy to use for current compaction cycle.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @return {@code true} if the counter value equals to 0 or it's storeCompactionPolicySwitchPeriod days past the start time of CompactAllPolicy.\n+   */\n+  private boolean readyToTriggerCompactionAllPolicy(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    return compactionPolicySwitchInfo.getCompactionPolicyCounter() != null\n+        && compactionPolicySwitchInfo.getCompactionPolicyCounter().getValue() == 0 ||\n+        compactionPolicySwitchInfo.getLastCompactAllTime() + TimeUnit.DAYS.toMillis(\n+            storeConfig.storeCompactionPolicySwitchPeriod) <= System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * Update the {@link CompactionPolicySwitchInfo} before the start of {@link CompactAllPolicy}", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyMDA3NQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447420075", "bodyText": "In this situation, after restart it will resume the compaction which handled in compaction design and after it finished, it will go to StatsBased.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:34:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MzU4OA=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MzY3OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447343678", "bodyText": "Extra lines at end.", "author": "lightningrob", "createdAt": "2020-06-30T00:54:19Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+    if (readyToTriggerCompactionAllPolicy(compactionPolicySwitchInfo)) {\n+      logger.trace(\"Return CompactAllPolicy this round\");\n+      updateCompactionInfo(compactionPolicySwitchInfo);\n+      return new CompactAllPolicy(storeConfig, time);\n+    } else {\n+      if (compactionPolicySwitchInfo.getCompactionPolicyCounter() == null) {\n+        logger.trace(\"Counter is null\");\n+      } else {\n+        logger.trace(\"Return StatsBasedCompactionPolicy this round\");\n+      }\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+  }\n+\n+  /**\n+   * Determine which compactionPolicy to use for current compaction cycle.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @return {@code true} if the counter value equals to 0 or it's storeCompactionPolicySwitchPeriod days past the start time of CompactAllPolicy.\n+   */\n+  private boolean readyToTriggerCompactionAllPolicy(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    return compactionPolicySwitchInfo.getCompactionPolicyCounter() != null\n+        && compactionPolicySwitchInfo.getCompactionPolicyCounter().getValue() == 0 ||\n+        compactionPolicySwitchInfo.getLastCompactAllTime() + TimeUnit.DAYS.toMillis(\n+            storeConfig.storeCompactionPolicySwitchPeriod) <= System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * Update the {@link CompactionPolicySwitchInfo} before the start of {@link CompactAllPolicy}\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   */\n+  private void updateCompactionInfo(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    compactionPolicySwitchInfo.setLastCompactAllTime(System.currentTimeMillis());\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().setValue(INIT_COUNTER_VALUE);\n+  }\n+\n+  /**\n+   * @return blobToCompactionPolicySwitchInfoMap which key is storeId and value is {@link CompactionPolicySwitchInfo}\n+   */\n+  Map<String, CompactionPolicySwitchInfo> getBlobToCompactionPolicySwitchInfoMap() {\n+    return this.blobToCompactionPolicySwitchInfoMap;\n+  }\n+\n+  /**\n+   * Back up {@link CompactionPolicySwitchInfo} in Json format for each {@link BlobStore}\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   */\n+  private void backUpCompactionPolicyInfo(String dataDir, String storeId,\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (dataDir != null && !dataDir.isEmpty()) {\n+      File tempFile = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      try {\n+        tempFile.createNewFile();\n+        mapper.defaultPrettyPrintingWriter().writeValue(tempFile, compactionPolicySwitchInfo);\n+      } catch (IOException e) {\n+        logger.error(\"Exception while store compaction policy info for local report. Output file path - {}\",\n+            tempFile.getAbsolutePath(), e);\n+      }\n+    }\n+  }\n+}\n+", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyMDY0Mg==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447420642", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:35:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0MzY3OA=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NDYxOQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447344619", "bodyText": "Minor: saying \"for each store\" implies the method does something for every store, but it's only acting on one.", "author": "lightningrob", "createdAt": "2020-06-30T00:57:14Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+    if (readyToTriggerCompactionAllPolicy(compactionPolicySwitchInfo)) {\n+      logger.trace(\"Return CompactAllPolicy this round\");\n+      updateCompactionInfo(compactionPolicySwitchInfo);\n+      return new CompactAllPolicy(storeConfig, time);\n+    } else {\n+      if (compactionPolicySwitchInfo.getCompactionPolicyCounter() == null) {\n+        logger.trace(\"Counter is null\");\n+      } else {\n+        logger.trace(\"Return StatsBasedCompactionPolicy this round\");\n+      }\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+  }\n+\n+  /**\n+   * Determine which compactionPolicy to use for current compaction cycle.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @return {@code true} if the counter value equals to 0 or it's storeCompactionPolicySwitchPeriod days past the start time of CompactAllPolicy.\n+   */\n+  private boolean readyToTriggerCompactionAllPolicy(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    return compactionPolicySwitchInfo.getCompactionPolicyCounter() != null\n+        && compactionPolicySwitchInfo.getCompactionPolicyCounter().getValue() == 0 ||\n+        compactionPolicySwitchInfo.getLastCompactAllTime() + TimeUnit.DAYS.toMillis(\n+            storeConfig.storeCompactionPolicySwitchPeriod) <= System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * Update the {@link CompactionPolicySwitchInfo} before the start of {@link CompactAllPolicy}\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   */\n+  private void updateCompactionInfo(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    compactionPolicySwitchInfo.setLastCompactAllTime(System.currentTimeMillis());\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().setValue(INIT_COUNTER_VALUE);\n+  }\n+\n+  /**\n+   * @return blobToCompactionPolicySwitchInfoMap which key is storeId and value is {@link CompactionPolicySwitchInfo}\n+   */\n+  Map<String, CompactionPolicySwitchInfo> getBlobToCompactionPolicySwitchInfoMap() {\n+    return this.blobToCompactionPolicySwitchInfoMap;\n+  }\n+\n+  /**\n+   * Back up {@link CompactionPolicySwitchInfo} in Json format for each {@link BlobStore}", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEwMzQ0NA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r448103444", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-01T04:07:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NDYxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NzM2OQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447347369", "bodyText": "Don't you want to do the update either way?", "author": "lightningrob", "createdAt": "2020-06-30T01:06:18Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+    if (readyToTriggerCompactionAllPolicy(compactionPolicySwitchInfo)) {\n+      logger.trace(\"Return CompactAllPolicy this round\");\n+      updateCompactionInfo(compactionPolicySwitchInfo);", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyMTcwOA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447421708", "bodyText": "I updated the method name to updateCompactionInfoWhenCompactAll to avoid confusion. This method is used to keep record of the last time when we run CompactAllPolicy, so if we passed \"storeCompactionPolicySwitchTimestampDays\" days since we run compactAllPolicy, we will re-run it again.", "author": "SophieGuo410", "createdAt": "2020-06-30T05:39:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NzM2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NzgxOA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447347818", "bodyText": "This method name is a mouthful.  Is there a downside to the caller first calling updateCompactionInfo() and then this method which could just be selectCompactionPolicy()?", "author": "lightningrob", "createdAt": "2020-06-30T01:07:49Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getAndRecoverCompactionPolicySwitchInfo(storeId, dataDir);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, storeId, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get and Recover the CompactionPolicySwitchInfo from file.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getAndRecoverCompactionPolicySwitchInfo(String storeId, String dataDir) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchPeriod\" : 3,\n+   *     \"counter\" : 1,\n+   *     \"value\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593463435900\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file) {\n+    try {\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchPeriod),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ1NDA5OQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447454099", "bodyText": "I will only update the compactionPolicySwitchInfo when we trigger the compactAllPolicy. Already re-named the method name to updateCompactionInfoWhenCompactAll() instead of updateCompactionInfo().", "author": "SophieGuo410", "createdAt": "2020-06-30T07:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0NzgxOA=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 432edbf87..5a1e98ae0 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -36,7 +36,7 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n   private final StoreConfig storeConfig;\n   private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n   private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n-  private final ObjectMapper mapper = new ObjectMapper();\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n   private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n   private static final int INIT_COMPACT_ALL_TIME = 0;\n   private static final int INIT_COUNTER_VALUE = 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0ODE3MQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447348171", "bodyText": "Minor: please move private utility methods to bottom.", "author": "lightningrob", "createdAt": "2020-06-30T01:09:05Z", "path": "ambry-store/src/test/java/com/github/ambry/store/CompactionPolicyTest.java", "diffHunk": "@@ -82,6 +94,135 @@ public CompactionPolicyTest(String compactionPolicyFactoryStr) throws Exception\n     mockBlobStoreStats = blobStore.getBlobStoreStats();\n     CompactionPolicyFactory compactionPolicyFactory = Utils.getObj(compactionPolicyFactoryStr, config, time);\n     compactionPolicy = compactionPolicyFactory.getCompactionPolicy();\n+    dataDirPath = Paths.get(MOUNT_PATH).toAbsolutePath();\n+  }\n+\n+  private void cleanupBackupFiles() throws IOException {", "originalCommit": "fb0055eeaaa4b6fe9a7b43fa92bb682084648645", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ1NDM0Ng==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447454346", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-06-30T07:00:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM0ODE3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "chunk": "diff --git a/ambry-store/src/test/java/com/github/ambry/store/CompactionPolicyTest.java b/ambry-store/src/test/java/com/github/ambry/store/CompactionPolicyTest.java\nindex 819c633c8..29d95ac84 100644\n--- a/ambry-store/src/test/java/com/github/ambry/store/CompactionPolicyTest.java\n+++ b/ambry-store/src/test/java/com/github/ambry/store/CompactionPolicyTest.java\n\n@@ -136,7 +136,8 @@ public class CompactionPolicyTest {\n     cleanupBackupFiles();\n     // with compaction enabled.\n     properties.setProperty(\"store.compaction.triggers\", \"Periodic\");\n-    properties.setProperty(\"store.compaction.policy.switch.period\", \"3\");\n+    properties.setProperty(\"store.compaction.policy.switch.counter.days\", \"3\");\n+    properties.setProperty(\"store.compaction.policy.switch.timestamp.days\", \"7\");\n     properties.setProperty(\"store.compaction.policy.factory\", \"com.github.ambry.store.HybridCompactionPolicyFactory\");\n     config = new StoreConfig(new VerifiableProperties(properties));\n     MetricRegistry metricRegistry = new MetricRegistry();\n"}}, {"oid": "fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "url": "https://github.com/linkedin/ambry/commit/fd1255131f5ad909d4b5c25cfeeb0813a10fcfc8", "message": "address comments", "committedDate": "2020-06-30T05:35:45Z", "type": "forcePushed"}, {"oid": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "url": "https://github.com/linkedin/ambry/commit/b9046a816f853978ca1e09cf85f9e17f41aab6c1", "message": "address comments", "committedDate": "2020-06-30T07:00:46Z", "type": "commit"}, {"oid": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "url": "https://github.com/linkedin/ambry/commit/b9046a816f853978ca1e09cf85f9e17f41aab6c1", "message": "address comments", "committedDate": "2020-06-30T07:00:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODQ2OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447898468", "bodyText": "shouldn't we increment the counter before select which policy to use?", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:36:24Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();", "originalCommit": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzkwODc0Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447908743", "bodyText": "That's the tricky part. I'm planning to increment after the backup with two reasons:\n\nwhen counter equals to 0, it will run compactAllPolicy. which means if we don't have any back up files yet, we will run compact all policy.\nif we are running compactAll for a long time and host restart, the file backs up the current status and re-run compactAll instead of statsBased.\nLet me know if you have any other concern.", "author": "SophieGuo410", "createdAt": "2020-06-30T18:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODQ2OA=="}], "type": "inlineReview", "revised_code": {"commit": "d823eab417029ca34052d3f19bf7d2aef81acb44", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 5a1e98ae0..57edc4eed 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -66,8 +66,8 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n     String storeId = blobStoreStats.getStoreId();\n     CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n     CompactionPolicy selectCompactionPolicy =\n-        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n-    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo, storeId, dataDir);\n+    logger.info(\"Current compaction policy  is : {} for store : {}, dataDir : {}\", selectCompactionPolicy, storeId, dataDir);\n     backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n     compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n     return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODc4NA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447898784", "bodyText": "please add datadir and store id in the info log.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:37:00Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);", "originalCommit": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk0MDk4MA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447940980", "bodyText": "Done.", "author": "SophieGuo410", "createdAt": "2020-06-30T19:53:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODc4NA=="}], "type": "inlineReview", "revised_code": {"commit": "d823eab417029ca34052d3f19bf7d2aef81acb44", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 5a1e98ae0..57edc4eed 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -66,8 +66,8 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n     String storeId = blobStoreStats.getStoreId();\n     CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n     CompactionPolicy selectCompactionPolicy =\n-        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n-    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo, storeId, dataDir);\n+    logger.info(\"Current compaction policy  is : {} for store : {}, dataDir : {}\", selectCompactionPolicy, storeId, dataDir);\n     backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n     compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n     return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5OTI0OA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447899248", "bodyText": "nit: please add datadir or store id in the log.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:37:48Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get the CompactionPolicySwitchInfo from file or blobToCompactionPolicySwitchInfoMap.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getCompactionPolicySwitchInfo(String storeId, String dataDir, BlobStoreStats blobStoreStats) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file, blobStoreStats);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchCounterDays),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchCounterDays\" : 3,\n+   *     \"counter\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593492962651\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file, BlobStoreStats blobStoreStats) {\n+    try {\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      blobStoreStats.getMetrics().blobStoreRecoverCompactionPolicySwitchInfoErrorCount.inc();\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchCounterDays),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");", "originalCommit": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk0MTA2Mw==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447941063", "bodyText": "Done.", "author": "SophieGuo410", "createdAt": "2020-06-30T19:53:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5OTI0OA=="}], "type": "inlineReview", "revised_code": {"commit": "d823eab417029ca34052d3f19bf7d2aef81acb44", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 5a1e98ae0..57edc4eed 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -66,8 +66,8 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n     String storeId = blobStoreStats.getStoreId();\n     CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n     CompactionPolicy selectCompactionPolicy =\n-        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n-    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo, storeId, dataDir);\n+    logger.info(\"Current compaction policy  is : {} for store : {}, dataDir : {}\", selectCompactionPolicy, storeId, dataDir);\n     backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n     compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n     return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzkwNDQ1NQ==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447904455", "bodyText": "nit: I encourage to create and write data to a temporary file and then rename the temporary file to COMPACT_POLICY_INFO_PATH file\nSomething like\nFile tempFile = new File(dataDir, COMPACT_POLICY_INFO_PATH + \".temp\");\nif (!tempFile.exists()) {\n    tempFile.createNewFile();\n}\nobjectMapper.defaultPrettyPrintingWriter().writeValue(tempFile, compactionPolicySwitchInfo);\ntempFile.renameTo(new File(dataDir, COMPACT_POLICY_INFO_PATH);\n\nThe reason to use a temporary file and rename it after is that POSIX guarantees file rename is an atomic operation, but not the file write. The json file is pretty small so that file writing should be atomic, but it's just a good pattern to follow.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:46:50Z", "path": "ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.store;\n+\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.utils.Time;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * HybridCompactionPolicy will run compaction with StatsBasedCompactionPolicy more frequently and with CompactAllPolicy\n+ * one time out of storeCompactionPolicySwitchPeriod.\n+ */\n+public class HybridCompactionPolicy implements CompactionPolicy {\n+  private final Time time;\n+  private final StoreConfig storeConfig;\n+  private static final Logger logger = LoggerFactory.getLogger(HybridCompactionPolicy.class);\n+  private final Map<String, CompactionPolicySwitchInfo> blobToCompactionPolicySwitchInfoMap;\n+  private static final ObjectMapper objectMapper = new ObjectMapper();\n+  private static final String COMPACT_POLICY_INFO_PATH = File.separator + \"compactionPolicyInfo.json\";\n+  private static final int INIT_COMPACT_ALL_TIME = 0;\n+  private static final int INIT_COUNTER_VALUE = 0;\n+\n+  HybridCompactionPolicy(StoreConfig storeConfig, Time time) {\n+    this.storeConfig = storeConfig;\n+    this.time = time;\n+    this.blobToCompactionPolicySwitchInfoMap = new HashMap<>();\n+  }\n+\n+  /**\n+   * @param totalCapacity Total capacity of the {@link BlobStore}\n+   * @param usedCapacity Used capacity of the {@link BlobStore}\n+   * @param segmentCapacity Segment capacity of a {@link LogSegment}\n+   * @param segmentHeaderSize Segment header size of a {@link LogSegment}\n+   * @param logSegmentsNotInJournal {@link List<String> } of log segment names which has non overlapping entries with\n+   *                                {@link Journal}\n+   * @param blobStoreStats {@link BlobStoreStats} pertaining to the {@link BlobStore} for which\n+   * {@link CompactionDetails} are requested\n+   * @param dataDir the dir to store {@link CompactionPolicySwitchInfo}\n+   * @return {@link CompactAllPolicy} or {@link StatsBasedCompactionPolicy}'s {@link CompactionDetails} depends on the switching rules.\n+   */\n+  @Override\n+  public CompactionDetails getCompactionDetails(long totalCapacity, long usedCapacity, long segmentCapacity,\n+      long segmentHeaderSize, List<String> logSegmentsNotInJournal, BlobStoreStats blobStoreStats, String dataDir)\n+      throws StoreException {\n+    String storeId = blobStoreStats.getStoreId();\n+    CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n+    CompactionPolicy selectCompactionPolicy =\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n+    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+    backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n+    return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n+        logSegmentsNotInJournal, blobStoreStats, dataDir);\n+  }\n+\n+  /**\n+   * Get the CompactionPolicySwitchInfo from file or blobToCompactionPolicySwitchInfoMap.\n+   * @param dataDir The directory to store the file.\n+   * @param storeId id of the BlobStore\n+   * @return {@link CompactionPolicySwitchInfo} gets from map or recover from file if needed.\n+   */\n+  private CompactionPolicySwitchInfo getCompactionPolicySwitchInfo(String storeId, String dataDir, BlobStoreStats blobStoreStats) {\n+    if (!blobToCompactionPolicySwitchInfoMap.containsKey(storeId)) {\n+      File file = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());\n+      if (file.exists()) {\n+        CompactionPolicySwitchInfo compactionPolicySwitchInfo = recoverCompactionPolicySwitchInfo(file, blobStoreStats);\n+        blobToCompactionPolicySwitchInfoMap.put(storeId, compactionPolicySwitchInfo);\n+      } else {\n+        blobToCompactionPolicySwitchInfoMap.put(storeId,\n+            new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchCounterDays),\n+                INIT_COMPACT_ALL_TIME));\n+      }\n+    }\n+    return blobToCompactionPolicySwitchInfoMap.get(storeId);\n+  }\n+\n+  /**\n+   * Recover the {@link CompactionPolicySwitchInfo} from backup file.\n+   * {\n+   *   \"compactionPolicyCounter\" : {\n+   *     \"storeCompactionPolicySwitchCounterDays\" : 3,\n+   *     \"counter\" : 1\n+   *   },\n+   *   \"lastCompactAllTime\" : 1593492962651\n+   * }\n+   * @param file the backup file stores {@link CompactionPolicySwitchInfo}\n+   */\n+  private CompactionPolicySwitchInfo recoverCompactionPolicySwitchInfo(File file, BlobStoreStats blobStoreStats) {\n+    try {\n+      return objectMapper.readValue(file, CompactionPolicySwitchInfo.class);\n+    } catch (IOException e) {\n+      logger.error(\"Could not deserialize file : {} into {} Object\", file, CompactionPolicySwitchInfo.class.getName());\n+      blobStoreStats.getMetrics().blobStoreRecoverCompactionPolicySwitchInfoErrorCount.inc();\n+      return new CompactionPolicySwitchInfo(new CompactionPolicyCounter(storeConfig.storeCompactionPolicySwitchCounterDays),\n+          INIT_COMPACT_ALL_TIME);\n+    }\n+  }\n+\n+  /**\n+   * Selects which compaction policy to use for current compaction cycle.\n+   * @return {@link CompactionPolicy} to use for current compaction cycle(Selects between {@link StatsBasedCompactionPolicy} and {@link CompactAllPolicy}).\n+   */\n+  CompactionPolicy selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(\n+      CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (compactionPolicySwitchInfo == null) {\n+      logger.trace(\"CompactionPolicySwitchInfo is null\");\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+    if (readyToTriggerCompactionAllPolicy(compactionPolicySwitchInfo)) {\n+      logger.trace(\"Return CompactAllPolicy this round\");\n+      updateCompactionInfoWhenCompactAll(compactionPolicySwitchInfo);\n+      return new CompactAllPolicy(storeConfig, time);\n+    } else {\n+      if (compactionPolicySwitchInfo.getCompactionPolicyCounter() == null) {\n+        logger.trace(\"Counter is null\");\n+      } else {\n+        logger.trace(\"Return StatsBasedCompactionPolicy this round\");\n+      }\n+      return new StatsBasedCompactionPolicy(storeConfig, time);\n+    }\n+  }\n+\n+  /**\n+   * Determine which compactionPolicy to use for current compaction cycle.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   * @return {@code true} if the counter value equals to 0 or it's storeCompactionPolicySwitchPeriod days past the start time of CompactAllPolicy.\n+   */\n+  private boolean readyToTriggerCompactionAllPolicy(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    return compactionPolicySwitchInfo.getCompactionPolicyCounter() != null\n+        && compactionPolicySwitchInfo.getCompactionPolicyCounter().getCounter() == 0 ||\n+        compactionPolicySwitchInfo.getLastCompactAllTime() + TimeUnit.DAYS.toMillis(\n+            storeConfig.storeCompactionPolicySwitchTimestampDays) <= System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * Update the {@link CompactionPolicySwitchInfo} before the start of {@link CompactAllPolicy}\n+   * Once the compactAllPolicy has been triggered, no matter it's been triggered by timestamp or counter value\n+   * the lastCompactAllTime will be set to current time and the counter value will reset to 0.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   */\n+  private void updateCompactionInfoWhenCompactAll(CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    compactionPolicySwitchInfo.setLastCompactAllTime(System.currentTimeMillis());\n+    compactionPolicySwitchInfo.getCompactionPolicyCounter().setCounter(INIT_COUNTER_VALUE);\n+  }\n+\n+  /**\n+   * @return blobToCompactionPolicySwitchInfoMap which key is storeId and value is {@link CompactionPolicySwitchInfo}\n+   */\n+  Map<String, CompactionPolicySwitchInfo> getBlobToCompactionPolicySwitchInfoMap() {\n+    return this.blobToCompactionPolicySwitchInfoMap;\n+  }\n+\n+  /**\n+   * Back up {@link CompactionPolicySwitchInfo} in Json format for certain {@link BlobStore}\n+   * @param dataDir The directory to store the file.\n+   * @param compactionPolicySwitchInfo the info to determine which {@link CompactionPolicy} to use this round.\n+   */\n+  private void backUpCompactionPolicyInfo(String dataDir, CompactionPolicySwitchInfo compactionPolicySwitchInfo) {\n+    if (dataDir != null && !dataDir.isEmpty()) {\n+      File tempFile = new File(Paths.get(dataDir, COMPACT_POLICY_INFO_PATH).toString());", "originalCommit": "b9046a816f853978ca1e09cf85f9e17f41aab6c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk0MTgzOA==", "url": "https://github.com/linkedin/ambry/pull/1559#discussion_r447941838", "bodyText": "Updated to use temp file and rename after write. I didn't add the file exist check since createNewFile() is able to handle it.", "author": "SophieGuo410", "createdAt": "2020-06-30T19:55:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzkwNDQ1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "d823eab417029ca34052d3f19bf7d2aef81acb44", "chunk": "diff --git a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\nindex 5a1e98ae0..57edc4eed 100644\n--- a/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n+++ b/ambry-store/src/main/java/com/github/ambry/store/HybridCompactionPolicy.java\n\n@@ -66,8 +66,8 @@ public class HybridCompactionPolicy implements CompactionPolicy {\n     String storeId = blobStoreStats.getStoreId();\n     CompactionPolicySwitchInfo compactionPolicySwitchInfo = getCompactionPolicySwitchInfo(storeId, dataDir, blobStoreStats);\n     CompactionPolicy selectCompactionPolicy =\n-        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo);\n-    logger.info(\"Current compaction policy  is : {}\", selectCompactionPolicy);\n+        selectCompactionPolicyAndUpdateCompactionPolicySwitchInfo(compactionPolicySwitchInfo, storeId, dataDir);\n+    logger.info(\"Current compaction policy  is : {} for store : {}, dataDir : {}\", selectCompactionPolicy, storeId, dataDir);\n     backUpCompactionPolicyInfo(dataDir, compactionPolicySwitchInfo);\n     compactionPolicySwitchInfo.getCompactionPolicyCounter().increment();\n     return selectCompactionPolicy.getCompactionDetails(totalCapacity, usedCapacity, segmentCapacity, segmentHeaderSize,\n"}}, {"oid": "d823eab417029ca34052d3f19bf7d2aef81acb44", "url": "https://github.com/linkedin/ambry/commit/d823eab417029ca34052d3f19bf7d2aef81acb44", "message": "minor fix", "committedDate": "2020-06-30T19:17:03Z", "type": "commit"}, {"oid": "785decb02a1d5f38a47eadd0dfdb54c9f6e066e9", "url": "https://github.com/linkedin/ambry/commit/785decb02a1d5f38a47eadd0dfdb54c9f6e066e9", "message": "minor fix", "committedDate": "2020-07-01T04:05:58Z", "type": "commit"}]}