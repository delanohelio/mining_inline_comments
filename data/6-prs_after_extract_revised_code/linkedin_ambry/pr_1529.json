{"pr_number": 1529, "pr_title": "Leverage stats aggregation result to select containers to be marked as INACTIVE", "pr_createdAt": "2020-05-21T07:26:28Z", "pr_url": "https://github.com/linkedin/ambry/pull/1529", "timeline": [{"oid": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "url": "https://github.com/linkedin/ambry/commit/5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "message": "ContainerDeletion_aggregation_phase1", "committedDate": "2020-05-21T17:57:08Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NjkyMQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429046921", "bodyText": "should we use Deprecated for naming consistency?", "author": "zzmao", "createdAt": "2020-05-22T05:17:28Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -345,6 +351,70 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainers(StatsSnapshot statsSnapshot) {", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDUzNTY4MA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r430535680", "bodyText": "I've updated the method name from selectInvalidContainers to selectInvalidContainerCandidates which stands for select all containers which will be marked as Invalid during this aggregation cycle.", "author": "SophieGuo410", "createdAt": "2020-05-26T16:12:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NjkyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU1MTA4OA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r430551088", "bodyText": "OK. It means you select DELETE_IN_PROGRESS and mark it as INACTIVE in the end.", "author": "zzmao", "createdAt": "2020-05-26T16:35:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NjkyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 16ce8f43d..c2f75f9bd 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -355,30 +351,30 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainers(StatsSnapshot statsSnapshot) {\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n     Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-    Set<Container> invalidContainerSet = new HashSet<>();\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n     getValidContainers(accountToContainerMap, statsSnapshot, null);\n-    Set<Container> deprecatedContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n-    for (Container container : deprecatedContainerSet) {\n+    Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+    for (Container container : deleteInProgressContainerSet) {\n       String containerIdToString = \"C[\" + container.getId() + \"]\";\n       String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n       if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString)\n           .contains(containerIdToString)) {\n         logger.info(\"Container {} has not been deleted yet\", container);\n       } else {\n-        invalidContainerSet.add(container);\n+        invalidContainerCandidateSet.add(container);\n       }\n     }\n-    return invalidContainerSet;\n+    return invalidContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n   public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerSet = selectInvalidContainers(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerSet);\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzExMQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429047111", "bodyText": "Not used.", "author": "zzmao", "createdAt": "2020-05-22T05:18:19Z", "path": "ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java", "diffHunk": "@@ -13,10 +13,12 @@\n  */\n package com.github.ambry.account;\n \n+import com.github.ambry.server.StatsSnapshot;", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDUzMDgwOQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r430530809", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-05-26T16:05:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjQyNw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222427", "bodyText": "you probably didn't push the latest branch, this is still there", "author": "jsjtzyy", "createdAt": "2020-06-06T01:04:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzExMQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\nindex 0d528046f..ddeef5a31 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\n\n@@ -18,7 +18,6 @@ import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Objects;\n-import java.util.Set;\n import java.util.function.Consumer;\n \n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzEzNA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429047134", "bodyText": "Not used.", "author": "zzmao", "createdAt": "2020-05-22T05:18:24Z", "path": "ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java", "diffHunk": "@@ -13,10 +13,12 @@\n  */\n package com.github.ambry.account;\n \n+import com.github.ambry.server.StatsSnapshot;\n import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Objects;\n+import java.util.Set;", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\nindex 0d528046f..ddeef5a31 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/InMemoryUnknownAccountService.java\n\n@@ -18,7 +18,6 @@ import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Objects;\n-import java.util.Set;\n import java.util.function.Consumer;\n \n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzIyNw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429047227", "bodyText": "Not used.", "author": "zzmao", "createdAt": "2020-05-22T05:18:53Z", "path": "ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java", "diffHunk": "@@ -14,6 +14,7 @@\n package com.github.ambry.account;\n \n import com.github.ambry.config.JsonAccountConfig;\n+import com.github.ambry.server.StatsSnapshot;", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDUzMDkxMQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r430530911", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-05-26T16:06:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0NzIyNw=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\nindex 72dd3912b..125b2b2f7 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\n\n@@ -14,7 +14,6 @@\n package com.github.ambry.account;\n \n import com.github.ambry.config.JsonAccountConfig;\n-import com.github.ambry.server.StatsSnapshot;\n import java.io.IOException;\n import java.nio.charset.StandardCharsets;\n import java.nio.file.Files;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0ODEwOQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429048109", "bodyText": "deleteInProgressContianerSet?", "author": "zzmao", "createdAt": "2020-05-22T05:22:53Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -345,6 +351,70 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainers(StatsSnapshot statsSnapshot) {\n+    Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+    Set<Container> invalidContainerSet = new HashSet<>();\n+    getValidContainers(accountToContainerMap, statsSnapshot, null);\n+    Set<Container> deprecatedContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0ODQwOA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429048408", "bodyText": "I am a little bit confused about the naming here.\nIn last PR, deprecated includes INACTIVE and DELETE_IN_PROGRESS , right?", "author": "zzmao", "createdAt": "2020-05-22T05:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0ODEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDUzNDEyNQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r430534125", "bodyText": "I've updated the name from deprecatedContainerSet to deleteInProgressContainerSet which include all containers marked as DELETE_IN_PROGRESS.", "author": "SophieGuo410", "createdAt": "2020-05-26T16:10:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA0ODEwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 16ce8f43d..c2f75f9bd 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -355,30 +351,30 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainers(StatsSnapshot statsSnapshot) {\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n     Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-    Set<Container> invalidContainerSet = new HashSet<>();\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n     getValidContainers(accountToContainerMap, statsSnapshot, null);\n-    Set<Container> deprecatedContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n-    for (Container container : deprecatedContainerSet) {\n+    Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+    for (Container container : deleteInProgressContainerSet) {\n       String containerIdToString = \"C[\" + container.getId() + \"]\";\n       String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n       if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString)\n           .contains(containerIdToString)) {\n         logger.info(\"Container {} has not been deleted yet\", container);\n       } else {\n-        invalidContainerSet.add(container);\n+        invalidContainerCandidateSet.add(container);\n       }\n     }\n-    return invalidContainerSet;\n+    return invalidContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n   public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerSet = selectInvalidContainers(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerSet);\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r429050187", "bodyText": "pass in accountService here is a little bit weird. I am think if any other solution..", "author": "zzmao", "createdAt": "2020-05-22T05:31:23Z", "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "diffHunk": "@@ -31,7 +32,7 @@\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n    * @throws IOException\n    */\n-  void participate(List<AmbryHealthReport> ambryHealthReports) throws IOException;\n+  void participate(List<AmbryHealthReport> ambryHealthReports, AccountService accountService) throws IOException;", "originalCommit": "5b73b9aef34f5a5e0daf9d57979e157475c5f4ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUxMzc3Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431513773", "bodyText": "@jsjtzyy   do you have any recommendation for this? I hope we don't add AccountService to Cluster related classes.", "author": "zzmao", "createdAt": "2020-05-28T00:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUxNzk0MQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431517941", "bodyText": "Let me think it through. Probably add a listener?", "author": "jsjtzyy", "createdAt": "2020-05-28T00:32:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU5MjYzMw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431592633", "bodyText": "Please refer to partitionStateChangeListeners in HelixParticipant. If we want to decouple AccountService from ClusterParticipant, we can add another type of listener, i.e TaskCompletionListener.", "author": "jsjtzyy", "createdAt": "2020-05-28T05:39:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk4NzQzMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431987432", "bodyText": "After second thought, maybe TaskCompletionCallback makes more sense, because the purpose to pass in account service is to update account in ZK after the task is done and result is ready to read.", "author": "jsjtzyy", "createdAt": "2020-05-28T17:00:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM1NzcxNg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r433357716", "bodyText": "Updated. I use callback interface and implement accountServiceCallback to decouple accountService from clusterParticipant.", "author": "SophieGuo410", "createdAt": "2020-06-01T16:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MDE4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\nindex f66bba9c5..321480a08 100644\n--- a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n+++ b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n\n@@ -30,9 +30,10 @@ public interface ClusterParticipant extends AutoCloseable {\n   /**\n    * Initiate the participation of cluster participant.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n+   * @param callback\n    * @throws IOException\n    */\n-  void participate(List<AmbryHealthReport> ambryHealthReports, AccountService accountService) throws IOException;\n+  void participate(List<AmbryHealthReport> ambryHealthReports, Callback callback) throws IOException;\n \n   /**\n    * Set or reset the sealed state of the given replica.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU5ODI5Mg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431598292", "bodyText": "This still looks like a synchronous way to call some methods from accountService.  Try to initiate another thread to unblock current thread.", "author": "jsjtzyy", "createdAt": "2020-05-28T05:58:37Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java", "diffHunk": "@@ -81,16 +86,20 @@ public TaskResult run() {\n           statsWrappersJSON.put(instanceName, record.getRecord().getSimpleField(statsFieldName));\n         }\n       }\n-      Pair<String, String> results = clusterAggregator.doWork(statsWrappersJSON, statsReportType);\n+      ObjectMapper mapper = new ObjectMapper();\n+      Pair<StatsSnapshot, StatsSnapshot> results = clusterAggregator.doWork(statsWrappersJSON, statsReportType);\n       String resultId = String.format(\"Aggregated_%s\", healthReportName);\n       ZNRecord znRecord = new ZNRecord(resultId);\n-      znRecord.setSimpleField(RAW_VALID_SIZE_FIELD_NAME, results.getFirst());\n-      znRecord.setSimpleField(VALID_SIZE_FIELD_NAME, results.getSecond());\n+      znRecord.setSimpleField(RAW_VALID_SIZE_FIELD_NAME, mapper.writeValueAsString(results.getFirst()));\n+      znRecord.setSimpleField(VALID_SIZE_FIELD_NAME, mapper.writeValueAsString(results.getSecond()));\n       znRecord.setSimpleField(TIMESTAMP_FIELD_NAME, String.valueOf(SystemTime.getInstance().milliseconds()));\n       znRecord.setListField(ERROR_OCCURRED_INSTANCES_FIELD_NAME,\n           clusterAggregator.getExceptionOccurredInstances(statsReportType));\n       String path = String.format(\"/%s\", resultId);\n       manager.getHelixPropertyStore().set(path, znRecord, AccessOption.PERSISTENT);\n+      if (statsReportType.equals(StatsReportType.ACCOUNT_REPORT)) {\n+        accountService.selectInvalidContainersAndMarkInZK(results.getFirst());\n+      }", "originalCommit": "1ed5b8d9c7f8a428a4e5efdda0c44b7c92fd611f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYwNTE2Nw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431605167", "bodyText": "Inside selectInvalidContainersAndMarkInZK I have two main method, I was trying to start a new thread for markContainerZkNodesInactive, but this update will be include in another PR, so I marked as TODO. But for selectInvalidContainerCandidates() I thought it's ok to run at current thread as we discussed. Please correct me if I'm wrong.", "author": "SophieGuo410", "createdAt": "2020-05-28T06:20:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU5ODI5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk4NjQ1NA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r431986454", "bodyText": "OK, that makes sense. I saw the TODO but didn't know how you will implement it. The plan sounds good to me, the remaining thing is, like @zzmao said, whether we should pass in accountService to this component. If we decide to decouple them, we can either use a listener or callback.", "author": "jsjtzyy", "createdAt": "2020-05-28T16:59:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU5ODI5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\nindex 6e8fdbc0a..45ef1ea27 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n\n@@ -87,7 +89,7 @@ class HelixHealthReportAggregatorTask extends UserContentStore implements Task {\n         }\n       }\n       ObjectMapper mapper = new ObjectMapper();\n-      Pair<StatsSnapshot, StatsSnapshot> results = clusterAggregator.doWork(statsWrappersJSON, statsReportType);\n+      results = clusterAggregator.doWork(statsWrappersJSON, statsReportType);\n       String resultId = String.format(\"Aggregated_%s\", healthReportName);\n       ZNRecord znRecord = new ZNRecord(resultId);\n       znRecord.setSimpleField(RAW_VALID_SIZE_FIELD_NAME, mapper.writeValueAsString(results.getFirst()));\n"}}, {"oid": "c8a7c9e1438766c22ecef64304a7a18888b57b2c", "url": "https://github.com/linkedin/ambry/commit/c8a7c9e1438766c22ecef64304a7a18888b57b2c", "message": "use callback to decouple accountService from clusterParticipant", "committedDate": "2020-06-01T05:17:00Z", "type": "forcePushed"}, {"oid": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "url": "https://github.com/linkedin/ambry/commit/7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "message": "use callback to decouple accountService from clusterParticipant", "committedDate": "2020-06-01T06:36:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE5NTU2Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436195563", "bodyText": "minor: can be removed", "author": "jsjtzyy", "createdAt": "2020-06-05T22:42:05Z", "path": "ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java", "diffHunk": "@@ -22,6 +22,7 @@\n import java.util.Collection;\n import java.util.Objects;\n import java.util.Random;\n+import java.util.Set;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEzNzkzMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454137932", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE5NTU2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\nindex 125b2b2f7..2904de5bd 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/JsonAccountService.java\n\n@@ -22,7 +22,6 @@ import java.nio.file.attribute.FileTime;\n import java.util.Collection;\n import java.util.Objects;\n import java.util.Random;\n-import java.util.Set;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE5NjA4NQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436196085", "bodyText": "We usually don't import external dependency (i.e. Guava), unless there is really needed.", "author": "jsjtzyy", "createdAt": "2020-06-05T22:44:25Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -17,11 +17,16 @@\n import com.github.ambry.commons.TopicListener;\n import com.github.ambry.config.HelixAccountServiceConfig;\n import com.github.ambry.router.Router;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.google.common.base.Preconditions;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -18,7 +18,6 @@ import com.github.ambry.commons.TopicListener;\n import com.github.ambry.config.HelixAccountServiceConfig;\n import com.github.ambry.router.Router;\n import com.github.ambry.server.StatsSnapshot;\n-import com.google.common.base.Preconditions;\n import java.io.IOException;\n import java.util.Collection;\n import java.util.HashMap;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwMTIxNg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436201216", "bodyText": "Replace this with:\nObjects.requireNonNull(keyName, \"keyName should not be null since every container will have it's corresponding accountId\");", "author": "jsjtzyy", "createdAt": "2020-06-05T23:07:41Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  }\n+\n+  /**\n+   * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n+   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   */\n+  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+    // TODO: mark the given containers status to INACTIVE in zookeeper.\n+  }\n+\n+  /**\n+   * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n+   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n+   * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n+   */\n+  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n+      String keyName) {\n+    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n+      return;\n+    } else {\n+      for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n+        if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n+          Preconditions.checkNotNull(keyName,\n+              \"keyName should not be null since every container will have it's corresponding accountId\");", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEzODA4Ng==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454138086", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:45:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwMTIxNg=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTA3Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436209073", "bodyText": "Since you have a return in if branch, you can move this piece of code out of else branch.", "author": "jsjtzyy", "createdAt": "2020-06-05T23:48:20Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  }\n+\n+  /**\n+   * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n+   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   */\n+  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+    // TODO: mark the given containers status to INACTIVE in zookeeper.\n+  }\n+\n+  /**\n+   * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n+   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n+   * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n+   */\n+  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n+      String keyName) {\n+    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n+      return;\n+    } else {\n+      for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEzODI3Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454138273", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:46:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTA3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxMDAwNw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436210007", "bodyText": "Suggest renaming this method, as it doesn't return anything. Also, Valid is a bit of ambiguous here. Maybe we call it searchNonEmptyContainers", "author": "jsjtzyy", "createdAt": "2020-06-05T23:54:07Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  }\n+\n+  /**\n+   * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n+   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   */\n+  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+    // TODO: mark the given containers status to INACTIVE in zookeeper.\n+  }\n+\n+  /**\n+   * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n+   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n+   * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n+   */\n+  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDEzODczMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454138732", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:47:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxMDAwNw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNTE5Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436215193", "bodyText": "In which case, this else will happen? I think we shouldn't recursively call this method here. Let me know if I am wrong.", "author": "jsjtzyy", "createdAt": "2020-06-06T00:28:16Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  }\n+\n+  /**\n+   * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n+   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   */\n+  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+    // TODO: mark the given containers status to INACTIVE in zookeeper.\n+  }\n+\n+  /**\n+   * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n+   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n+   * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n+   */\n+  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n+      String keyName) {\n+    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n+      return;\n+    } else {\n+      for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n+        if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n+          Preconditions.checkNotNull(keyName,\n+              \"keyName should not be null since every container will have it's corresponding accountId\");\n+          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+        } else if (entry.getKey().startsWith(\"A\")) {\n+          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n+          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+        } else {\n+          getValidContainers(accountToContainerMap, entry.getValue(), null);", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MTY5Nw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454141697", "bodyText": "I'm thinking that if for the future we probably will have multiple level of subMap under container level. For example like separate the statsReport by month, so with this it will quickly jump out of recursion. If you think it's unnecessary, please let me know. I can remove it.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:53:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNTE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcxNDM5Nw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454714397", "bodyText": "Let's remove it for now. If we really need this, we can add later.", "author": "jsjtzyy", "createdAt": "2020-07-15T00:07:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNTE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2NjM4MQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454766381", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-07-15T03:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNTE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjE0OQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436216149", "bodyText": "According to the comment and code logic, I would suggest changing Invalid to Inactive in this method. InactiveContainerCandidates sounds more reasonable", "author": "jsjtzyy", "createdAt": "2020-06-06T00:35:57Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MTgxOA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454141818", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:53:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjE0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjM5NQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436216395", "bodyText": "rename accountToContainerMap to nonEmptyContainersByAccount", "author": "jsjtzyy", "createdAt": "2020-06-06T00:36:56Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MTg5MQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454141891", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:53:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjM5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjgzNw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436216837", "bodyText": "add a log here for debugging as well", "author": "jsjtzyy", "createdAt": "2020-06-06T00:37:54Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MjI0NQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454142245", "bodyText": "Updated. Thanks for the nit.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:54:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNjgzNw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNzIxMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436217212", "bodyText": "same here, Invalid -> Inactive", "author": "jsjtzyy", "createdAt": "2020-06-06T00:38:45Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MjMyOQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454142329", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNzIxMg=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNzk2NA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436217964", "bodyText": "rename markContainerZkNodesInactive to markContainerInactiveOnZk", "author": "jsjtzyy", "createdAt": "2020-06-06T00:40:36Z", "path": "ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java", "diffHunk": "@@ -343,6 +347,71 @@ private void onAccountChangeMessage(String topic, String message) {\n     }\n   }\n \n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n+   * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n+   */\n+  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+    if (statsSnapshot != null) {\n+      Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n+      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n+      for (Container container : deleteInProgressContainerSet) {\n+        String containerIdToString = \"C[\" + container.getId() + \"]\";\n+        String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n+        if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n+          logger.info(\"Container {} has not been deleted yet\", container);\n+        } else {\n+          invalidContainerCandidateSet.add(container);\n+        }\n+      }\n+    }\n+    return invalidContainerCandidateSet;\n+  }\n+\n+  /**\n+   * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n+   */\n+  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n+    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  }\n+\n+  /**\n+   * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n+   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   */\n+  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MjU4MQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454142581", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:55:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIxNzk2NA=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\nindex 0113e4d5a..d8656a996 100644\n--- a/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n+++ b/ambry-account/src/main/java/com/github/ambry/account/HelixAccountService.java\n\n@@ -351,62 +350,61 @@ public class HelixAccountService extends AbstractAccountService implements Accou\n    * Selects {@link Container}s to be marked as INACTIVE. Check the valid data size of each DELETE_IN_PROGRESS container\n    * from {@link StatsSnapshot} and select the ones with zero data size to be marked as INACTIVE.\n    */\n-  Set<Container> selectInvalidContainerCandidates(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = new HashSet<>();\n+  Set<Container> selectInactiveContainerCandidates(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = new HashSet<>();\n     if (statsSnapshot != null) {\n       Map<String, Set<String>> accountToContainerMap = new HashMap<>();\n-      getValidContainers(accountToContainerMap, statsSnapshot, null);\n+      searchNonEmptyContainers(accountToContainerMap, statsSnapshot, null);\n       Set<Container> deleteInProgressContainerSet = getContainersByStatus(Container.ContainerStatus.DELETE_IN_PROGRESS);\n       for (Container container : deleteInProgressContainerSet) {\n         String containerIdToString = \"C[\" + container.getId() + \"]\";\n         String accountIdToString = \"A[\" + container.getParentAccountId() + \"]\";\n         if (accountToContainerMap.containsKey(accountIdToString) && accountToContainerMap.get(accountIdToString).contains(containerIdToString)) {\n-          logger.info(\"Container {} has not been deleted yet\", container);\n+          logger.debug(\"Container {} has not been compacted yet\", container);\n         } else {\n-          invalidContainerCandidateSet.add(container);\n+          logger.info(\"Container {} has been compacted already\", container);\n+          inactiveContainerCandidateSet.add(container);\n         }\n       }\n     }\n-    return invalidContainerCandidateSet;\n+    return inactiveContainerCandidateSet;\n   }\n \n   /**\n    * Selects {@link Container}s to be marked as INACTIVE and marked in zookeeper.\n    */\n-  public void selectInvalidContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n-    Set<Container> invalidContainerCandidateSet = selectInvalidContainerCandidates(statsSnapshot);\n-    markContainerZkNodesInactive(invalidContainerCandidateSet);\n+  public void selectInactiveContainersAndMarkInZK(StatsSnapshot statsSnapshot) {\n+    Set<Container> inactiveContainerCandidateSet = selectInactiveContainerCandidates(statsSnapshot);\n+    markContainerInactiveOnZk(inactiveContainerCandidateSet);\n   }\n \n   /**\n    * Mark the given {@link Container}s status to INACTIVE in zookeeper.\n-   * @param invalidContainerSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n+   * @param inactiveContainerCandidateSet DELETE_IN_PROGRESS {@link Container} set which has been deleted successfully during compaction.\n    */\n-  private void markContainerZkNodesInactive(Set<Container> invalidContainerSet) {\n+  private void markContainerInactiveOnZk(Set<Container> inactiveContainerCandidateSet) {\n     // TODO: mark the given containers status to INACTIVE in zookeeper.\n   }\n \n   /**\n    * Gets valid data size {@link Container}s. The qualified {@link Container}s' raw valid data size should be larger than zero.\n-   * @param accountToContainerMap it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n+   * @param nonEmptyContainersByAccount it holds a mapping of {@link Account}s to {@link Container}s which raw valid data size larger than zero.\n    * @param statsSnapshot the {@link StatsSnapshot} generated from cluster wide aggregation.\n    * @param keyName the key of subMap for each level of {@link StatsSnapshot}.\n    */\n-  private void getValidContainers(Map<String, Set<String>> accountToContainerMap, StatsSnapshot statsSnapshot,\n-      String keyName) {\n-    if (statsSnapshot.getSubMap() == null || statsSnapshot.getSubMap().isEmpty()) {\n-      return;\n-    } else {\n+  private void searchNonEmptyContainers(Map<String, Set<String>> nonEmptyContainersByAccount,\n+      StatsSnapshot statsSnapshot, String keyName) {\n+    if (statsSnapshot.getSubMap() != null && !statsSnapshot.getSubMap().isEmpty()) {\n       for (Map.Entry<String, StatsSnapshot> entry : statsSnapshot.getSubMap().entrySet()) {\n         if (entry.getKey().startsWith(\"C\") && entry.getValue().getValue() > 0) {\n-          Preconditions.checkNotNull(keyName,\n+          Objects.requireNonNull(keyName,\n               \"keyName should not be null since every container will have it's corresponding accountId\");\n-          accountToContainerMap.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n+          nonEmptyContainersByAccount.getOrDefault(keyName, new HashSet<>()).add(entry.getKey());\n         } else if (entry.getKey().startsWith(\"A\")) {\n-          accountToContainerMap.putIfAbsent(entry.getKey(), new HashSet<>());\n-          getValidContainers(accountToContainerMap, entry.getValue(), entry.getKey());\n+          nonEmptyContainersByAccount.putIfAbsent(entry.getKey(), new HashSet<>());\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), entry.getKey());\n         } else {\n-          getValidContainers(accountToContainerMap, entry.getValue(), null);\n+          searchNonEmptyContainers(nonEmptyContainersByAccount, entry.getValue(), null);\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMTAxMQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436221011", "bodyText": "Raw use of the Callback, change it to Callback<StatsSnapshot> ?\nAlso update the java doc of this constructor please.", "author": "jsjtzyy", "createdAt": "2020-06-06T00:51:38Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java", "diffHunk": "@@ -60,16 +64,19 @@\n    * @param statsReportType the type of stats report\n    */\n   HelixHealthReportAggregatorTask(TaskCallbackContext context, long relevantTimePeriodInMs, String healthReportName,\n-      String statsFieldName, StatsReportType statsReportType) {\n+      String statsFieldName, StatsReportType statsReportType, Callback callback) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MjkwMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454142902", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:56:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMTAxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\nindex 72e21a420..b3fcca9a6 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n\n@@ -62,9 +62,10 @@ class HelixHealthReportAggregatorTask extends UserContentStore implements Task {\n    * @param healthReportName Name of the health report\n    * @param statsFieldName Stats field name\n    * @param statsReportType the type of stats report\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    */\n   HelixHealthReportAggregatorTask(TaskCallbackContext context, long relevantTimePeriodInMs, String healthReportName,\n-      String statsFieldName, StatsReportType statsReportType, Callback callback) {\n+      String statsFieldName, StatsReportType statsReportType, Callback<StatsSnapshot> callback) {\n     manager = context.getManager();\n     clusterAggregator = new HelixClusterAggregator(relevantTimePeriodInMs);\n     this.healthReportName = healthReportName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMTA4NQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436221085", "bodyText": "minor: complete the comment here.", "author": "jsjtzyy", "createdAt": "2020-06-06T00:52:25Z", "path": "ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2019 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.account;\n+\n+import com.github.ambry.router.Callback;\n+import com.github.ambry.server.StatsSnapshot;\n+\n+\n+public class AccountServiceCallback implements Callback<StatsSnapshot> {\n+  private final AccountService accountService;\n+\n+  /**\n+   * Construct a AccountServiceCallback object\n+   * @param accountService the {@link AccountService} associated with this callback.\n+   */\n+  public AccountServiceCallback(AccountService accountService) {\n+    this.accountService = accountService;\n+  }\n+\n+  /**\n+   * When the aggregation report has been generated successfully, this method will be invoked and associated {@link AccountService}\n+   * will", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0Mjk4Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454142983", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:56:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMTA4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java b/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\nindex 6b068ea54..273e29a4a 100644\n--- a/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\n+++ b/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\n\n@@ -15,10 +15,13 @@ package com.github.ambry.account;\n \n import com.github.ambry.router.Callback;\n import com.github.ambry.server.StatsSnapshot;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n \n public class AccountServiceCallback implements Callback<StatsSnapshot> {\n   private final AccountService accountService;\n+  private static final Logger logger = LoggerFactory.getLogger(AccountServiceCallback.class);\n \n   /**\n    * Construct a AccountServiceCallback object\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjE0Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222143", "bodyText": "I know the exception doesn't affect the account service callback but others might don't. We can add logger.info here if exception is not null. We can say \"Aggregator task encountered an exception but result is not null. Processing the result as aggregation is complete.\"   You can also add comment saying \"Exception occurred when updating Helix property store, not in aggregation phase, the result is still solid.\"", "author": "jsjtzyy", "createdAt": "2020-06-06T01:01:57Z", "path": "ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2019 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.account;\n+\n+import com.github.ambry.router.Callback;\n+import com.github.ambry.server.StatsSnapshot;\n+\n+\n+public class AccountServiceCallback implements Callback<StatsSnapshot> {\n+  private final AccountService accountService;\n+\n+  /**\n+   * Construct a AccountServiceCallback object\n+   * @param accountService the {@link AccountService} associated with this callback.\n+   */\n+  public AccountServiceCallback(AccountService accountService) {\n+    this.accountService = accountService;\n+  }\n+\n+  /**\n+   * When the aggregation report has been generated successfully, this method will be invoked and associated {@link AccountService}\n+   * will\n+   * @param results the StatsSnapshot whose values represents aggregated stats across all partitions.\n+   * @param exception Exception won't affect the execution.", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzA2OA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143068", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:56:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjE0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java b/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\nindex 6b068ea54..273e29a4a 100644\n--- a/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\n+++ b/ambry-api/src/main/java/com/github/ambry/account/AccountServiceCallback.java\n\n@@ -15,10 +15,13 @@ package com.github.ambry.account;\n \n import com.github.ambry.router.Callback;\n import com.github.ambry.server.StatsSnapshot;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n \n public class AccountServiceCallback implements Callback<StatsSnapshot> {\n   private final AccountService accountService;\n+  private static final Logger logger = LoggerFactory.getLogger(AccountServiceCallback.class);\n \n   /**\n    * Construct a AccountServiceCallback object\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjUwMg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222502", "bodyText": "minor: can be removed", "author": "jsjtzyy", "createdAt": "2020-06-06T01:05:45Z", "path": "ambry-api/src/main/java/com/github/ambry/account/AccountService.java", "diffHunk": "@@ -13,6 +13,8 @@\n  */\n package com.github.ambry.account;\n \n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.utils.Pair;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzE2Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143163", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:56:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjUwMg=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/account/AccountService.java b/ambry-api/src/main/java/com/github/ambry/account/AccountService.java\nindex 63fda21c2..04f78bd65 100644\n--- a/ambry-api/src/main/java/com/github/ambry/account/AccountService.java\n+++ b/ambry-api/src/main/java/com/github/ambry/account/AccountService.java\n\n@@ -14,7 +14,6 @@\n package com.github.ambry.account;\n \n import com.github.ambry.server.StatsSnapshot;\n-import com.github.ambry.utils.Pair;\n import java.io.Closeable;\n import java.util.Collection;\n import java.util.HashSet;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjU2OQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222569", "bodyText": "add some description here", "author": "jsjtzyy", "createdAt": "2020-06-06T01:06:26Z", "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "diffHunk": "@@ -29,9 +30,10 @@\n   /**\n    * Initiate the participation of cluster participant.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n+   * @param callback", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzIzNw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143237", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjU2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\nindex 321480a08..dc34dc731 100644\n--- a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n+++ b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n\n@@ -30,10 +32,10 @@ public interface ClusterParticipant extends AutoCloseable {\n   /**\n    * Initiate the participation of cluster participant.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n-   * @param callback\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    * @throws IOException\n    */\n-  void participate(List<AmbryHealthReport> ambryHealthReports, Callback callback) throws IOException;\n+  void participate(List<AmbryHealthReport> ambryHealthReports, Callback<StatsSnapshot> callback) throws IOException;\n \n   /**\n    * Set or reset the sealed state of the given replica.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjc0Mg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222742", "bodyText": "Looks like you imported a different type of Callback (should be account service callback not router callback).", "author": "jsjtzyy", "createdAt": "2020-06-06T01:08:00Z", "path": "ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java", "diffHunk": "@@ -14,6 +14,7 @@\n \n package com.github.ambry.clustermap;\n \n+import com.github.ambry.router.Callback;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzYxNA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143614", "bodyText": "the router callback is the interface, and I implement with account service callback. Let me know if I misunderstanding something.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:57:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjc0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2Njc1OQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454766759", "bodyText": "After discussion, I moved the callback interface to commons dir which is more reasonable.", "author": "SophieGuo410", "createdAt": "2020-07-15T03:21:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjc0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\nindex 321480a08..dc34dc731 100644\n--- a/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n+++ b/ambry-api/src/main/java/com/github/ambry/clustermap/ClusterParticipant.java\n\n@@ -16,8 +16,10 @@ package com.github.ambry.clustermap;\n \n import com.github.ambry.router.Callback;\n import com.github.ambry.server.AmbryHealthReport;\n+import com.github.ambry.server.StatsSnapshot;\n import java.io.IOException;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.List;\n import java.util.Map;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjg1Ng==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222856", "bodyText": "minor: update java doc of this method", "author": "jsjtzyy", "createdAt": "2020-06-06T01:09:02Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java", "diffHunk": "@@ -53,7 +53,7 @@\n    * for each partition.\n    * @throws IOException\n    */\n-  Pair<String, String> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {\n+  Pair<StatsSnapshot, StatsSnapshot> doWork(Map<String, String> statsWrappersJSON, StatsReportType type) throws IOException {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzY3Ng==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143676", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:57:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjg1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java\nindex b0782a250..bdf425848 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixClusterAggregator.java\n\n@@ -48,7 +48,7 @@ public class HelixClusterAggregator {\n    * @param statsWrappersJSON a {@link Map} of instance name to JSON string representation of {@link StatsWrapper} objects from the\n    *                          node level\n    * @param type the type of stats report to be aggregated, which is defined in {@link StatsReportType}\n-   * @return a {@link Pair} of Strings whose values represents aggregated stats across all partitions.\n+   * @return a {@link Pair} of StatsSnapshot whose values represents aggregated stats across all partitions.\n    * First element is the raw (sum) aggregated stats and second element is valid aggregated stats for all replicas\n    * for each partition.\n    * @throws IOException\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMjg5OQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436222899", "bodyText": "same here", "author": "jsjtzyy", "createdAt": "2020-06-06T01:09:31Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java", "diffHunk": "@@ -14,7 +14,9 @@\n \n package com.github.ambry.clustermap;\n \n+import com.github.ambry.router.Callback;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\nindex 72e21a420..6e8fdbc0a 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixHealthReportAggregatorTask.java\n\n@@ -14,7 +14,7 @@\n \n package com.github.ambry.clustermap;\n \n-import com.github.ambry.router.Callback;\n+import com.github.ambry.account.AccountService;\n import com.github.ambry.server.StatsReportType;\n import com.github.ambry.server.StatsSnapshot;\n import com.github.ambry.utils.Pair;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzA5MA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223090", "bodyText": "add some description", "author": "jsjtzyy", "createdAt": "2020-06-06T01:11:16Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -100,16 +101,17 @@ public void setInitialLocalPartitions(Collection<String> localPartitions) {\n    * Initiate the participation by registering via the {@link HelixManager} as a participant to the associated\n    * Helix cluster.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n+   * @param callback", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0Mzc4Ng==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143786", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzA5MA=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\nindex 7fff1eb30..79ac5caf1 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n\n@@ -101,11 +102,11 @@ public class HelixParticipant implements ClusterParticipant, PartitionStateChang\n    * Initiate the participation by registering via the {@link HelixManager} as a participant to the associated\n    * Helix cluster.\n    * @param ambryHealthReports {@link List} of {@link AmbryHealthReport} to be registered to the participant.\n-   * @param callback\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    * @throws IOException if there is an error connecting to the Helix cluster.\n    */\n   @Override\n-  public void participate(List<AmbryHealthReport> ambryHealthReports, Callback callback) throws IOException {\n+  public void participate(List<AmbryHealthReport> ambryHealthReports, Callback<StatsSnapshot> callback) throws IOException {\n     logger.info(\"Initiating the participation. The specified state model is {}\",\n         clusterMapConfig.clustermapStateModelDefinition);\n     StateMachineEngine stateMachineEngine = manager.getStateMachineEngine();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzEyMA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223120", "bodyText": "same here", "author": "jsjtzyy", "createdAt": "2020-06-06T01:11:21Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -15,6 +15,7 @@\n \n import com.codahale.metrics.MetricRegistry;\n import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.router.Callback;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\nindex 7fff1eb30..79ac5caf1 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n\n@@ -17,6 +17,7 @@ import com.codahale.metrics.MetricRegistry;\n import com.github.ambry.config.ClusterMapConfig;\n import com.github.ambry.router.Callback;\n import com.github.ambry.server.AmbryHealthReport;\n+import com.github.ambry.server.StatsSnapshot;\n import com.github.ambry.utils.Utils;\n import java.io.IOException;\n import java.util.ArrayList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzE2Nw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223167", "bodyText": "minor: update java doc of this method", "author": "jsjtzyy", "createdAt": "2020-06-06T01:11:50Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java", "diffHunk": "@@ -395,7 +397,7 @@ private boolean removeOldReplicaInfo(ReplicaId replicaId, InstanceConfig instanc\n    * @param healthReports the {@link List} of {@link AmbryHealthReport}s that may require the registration of\n    * corresponding {@link HelixHealthReportAggregatorTask}s.\n    */\n-  private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports) {\n+  private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports, Callback callback) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0Mzg1NQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143855", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:58:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzE2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\nindex 7fff1eb30..79ac5caf1 100644\n--- a/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n+++ b/ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipant.java\n\n@@ -396,8 +419,9 @@ public class HelixParticipant implements ClusterParticipant, PartitionStateChang\n    * @param engine the {@link StateMachineEngine} to register the task state model.\n    * @param healthReports the {@link List} of {@link AmbryHealthReport}s that may require the registration of\n    * corresponding {@link HelixHealthReportAggregatorTask}s.\n+   * @param callback a callback which will be invoked when the aggregation report has been generated successfully.\n    */\n-  private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports, Callback callback) {\n+  private void registerHealthReportTasks(StateMachineEngine engine, List<AmbryHealthReport> healthReports, Callback<StatsSnapshot> callback) {\n     Map<String, TaskFactory> taskFactoryMap = new HashMap<>();\n     for (final AmbryHealthReport healthReport : healthReports) {\n       if (healthReport.getAggregateIntervalInMinutes() != Utils.Infinite_Time) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzYxMw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223613", "bodyText": "Callback -> Callback<StatsSnapshot>", "author": "jsjtzyy", "createdAt": "2020-06-06T01:15:32Z", "path": "ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java", "diffHunk": "@@ -293,8 +295,9 @@ public void startup() throws InstantiationException {\n       if (vcrClusterSpectator != null) {\n         vcrClusterSpectator.spectate();\n       }\n+      Callback accountServiceCallback = new AccountServiceCallback(accountService);", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0MzkyOA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454143928", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:58:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzYxMw=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java b/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\nindex 6c04eca4d..1d0950908 100644\n--- a/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\n+++ b/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\n\n@@ -295,7 +307,7 @@ public class AmbryServer {\n       if (vcrClusterSpectator != null) {\n         vcrClusterSpectator.spectate();\n       }\n-      Callback accountServiceCallback = new AccountServiceCallback(accountService);\n+      Callback<StatsSnapshot> accountServiceCallback = new AccountServiceCallback(accountService);\n       for (ClusterParticipant clusterParticipant : clusterParticipants) {\n         clusterParticipant.participate(ambryHealthReports, accountServiceCallback);\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzczNQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223735", "bodyText": "remove this and make sure all the Callback related imports are updated in this PR", "author": "jsjtzyy", "createdAt": "2020-06-06T01:16:08Z", "path": "ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java", "diffHunk": "@@ -63,6 +64,7 @@\n import com.github.ambry.rest.RestRequestResponseHandlerFactory;\n import com.github.ambry.rest.RestRequestService;\n import com.github.ambry.rest.StorageServerNettyFactory;\n+import com.github.ambry.router.Callback;", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java b/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\nindex 6c04eca4d..1d0950908 100644\n--- a/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\n+++ b/ambry-server/src/main/java/com/github/ambry/server/AmbryServer.java\n\n@@ -52,18 +52,18 @@ import com.github.ambry.network.PortType;\n import com.github.ambry.network.SocketServer;\n import com.github.ambry.network.http2.Http2BlockingChannelPool;\n import com.github.ambry.network.http2.Http2ClientMetrics;\n+import com.github.ambry.network.http2.Http2ServerMetrics;\n import com.github.ambry.notification.NotificationSystem;\n import com.github.ambry.protocol.AmbryRequests;\n import com.github.ambry.protocol.RequestHandlerPool;\n import com.github.ambry.replication.CloudToStoreReplicationManager;\n import com.github.ambry.replication.FindTokenHelper;\n import com.github.ambry.replication.ReplicationManager;\n+import com.github.ambry.replication.ReplicationSkipPredicate;\n+import com.github.ambry.rest.NettyMetrics;\n import com.github.ambry.rest.NioServer;\n import com.github.ambry.rest.NioServerFactory;\n-import com.github.ambry.rest.RestRequestHandler;\n-import com.github.ambry.rest.RestRequestResponseHandlerFactory;\n-import com.github.ambry.rest.RestRequestService;\n-import com.github.ambry.rest.StorageServerNettyFactory;\n+import com.github.ambry.store.MessageInfo;\n import com.github.ambry.router.Callback;\n import com.github.ambry.store.StorageManager;\n import com.github.ambry.store.StoreKeyConverterFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzkxNA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r436223914", "bodyText": "minor: format this file", "author": "jsjtzyy", "createdAt": "2020-06-06T01:17:30Z", "path": "ambry-test-utils/src/main/java/com/github/ambry/utils/TestUtils.java", "diffHunk": "@@ -420,5 +424,39 @@ public boolean isZkServerStarted() {\n     }\n     return true;\n   }\n+\n+  /**\n+   * Generate certain type of {@link StatsSnapshot} based on the given parameters that would have been produced by a\n+   * {@link com.github.ambry.store.Store}.\n+   * @param accountCount number of account entry in the {@link StatsSnapshot}\n+   * @param containerCount number of container entry in the {@link StatsSnapshot}\n+   * @param random the random generator to be used\n+   * @param type the type of stats report to be generated for the store\n+   * @return the generated store level {@link StatsSnapshot}\n+   */\n+  public static StatsSnapshot generateStoreStats(int accountCount, int containerCount, Random random, StatsReportType type) {", "originalCommit": "7f1c4dfa31918169b2dbb67d69bbd4723ef4b19c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDE0NDAzNg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454144036", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-14T06:58:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIyMzkxNA=="}], "type": "inlineReview", "revised_code": {"commit": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "chunk": "diff --git a/ambry-test-utils/src/main/java/com/github/ambry/utils/TestUtils.java b/ambry-test-utils/src/main/java/com/github/ambry/utils/TestUtils.java\nindex af593d8fa..355da47ee 100644\n--- a/ambry-test-utils/src/main/java/com/github/ambry/utils/TestUtils.java\n+++ b/ambry-test-utils/src/main/java/com/github/ambry/utils/TestUtils.java\n\n@@ -434,7 +434,8 @@ public class TestUtils {\n    * @param type the type of stats report to be generated for the store\n    * @return the generated store level {@link StatsSnapshot}\n    */\n-  public static StatsSnapshot generateStoreStats(int accountCount, int containerCount, Random random, StatsReportType type) {\n+  public static StatsSnapshot generateStoreStats(int accountCount, int containerCount, Random random,\n+      StatsReportType type) {\n     Map<String, StatsSnapshot> subMap = new HashMap<>();\n     long totalSize = 0;\n     for (int i = 0; i < accountCount; i++) {\n"}}, {"oid": "9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "url": "https://github.com/linkedin/ambry/commit/9f1ea72e8cd8f6c770da2adc5713403362c99d1b", "message": "address comments", "committedDate": "2020-07-14T06:36:46Z", "type": "forcePushed"}, {"oid": "44e10fd56285f2de086e8c264072eec4de974263", "url": "https://github.com/linkedin/ambry/commit/44e10fd56285f2de086e8c264072eec4de974263", "message": "address comments", "committedDate": "2020-07-14T06:39:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2NzYxNg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454767616", "bodyText": "can be removed", "author": "jsjtzyy", "createdAt": "2020-07-15T03:25:13Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -56,6 +59,7 @@\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.junit.runners.Parameterized;\n+import org.mockito.Mockito;", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzNTI2Ng==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455335266", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-15T20:53:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2NzYxNg=="}], "type": "inlineReview", "revised_code": {"commit": "cd8ded3f5f955b141188330e620ac48320be7e1e", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..421a544d1 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -59,7 +58,6 @@ import org.junit.Before;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.junit.runners.Parameterized;\n-import org.mockito.Mockito;\n \n import static com.github.ambry.account.Account.*;\n import static com.github.ambry.account.AccountTestUtils.*;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2NzY1MQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454767651", "bodyText": "can be removed", "author": "jsjtzyy", "createdAt": "2020-07-15T03:25:21Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -14,11 +14,14 @@\n package com.github.ambry.account;\n \n import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.clustermap.HelixClusterAggregator;", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzNTMyMw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455335323", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-15T20:53:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2NzY1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "cd8ded3f5f955b141188330e620ac48320be7e1e", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..421a544d1 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -14,7 +14,6 @@\n package com.github.ambry.account;\n \n import com.codahale.metrics.MetricRegistry;\n-import com.github.ambry.clustermap.HelixClusterAggregator;\n import com.github.ambry.clustermap.HelixStoreOperator;\n import com.github.ambry.config.HelixAccountServiceConfig;\n import com.github.ambry.config.HelixPropertyStoreConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODAzMA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454768030", "bodyText": "Set -> Set<Short>", "author": "jsjtzyy", "createdAt": "2020-07-15T03:26:58Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -200,6 +203,53 @@ public void testCreateAccount() {\n     assertAccountsInAccountService(idToRefAccountMap.values(), NUM_REF_ACCOUNT, accountService);\n   }\n \n+  /**\n+   * Tests select INVALID {@link Container}s from DELETE_IN_PROGRESS {@link Container}s.\n+   */\n+  @Test\n+  public void testSelectInvalidContainer() throws Exception {\n+    //generates store stats\n+    int accountCount = 1;\n+    int containerCount = 3;\n+    StatsSnapshot statsSnapshot =\n+        generateStoreStats(accountCount, containerCount, random, StatsReportType.ACCOUNT_REPORT);\n+\n+    // a set that records the account ids that have already been taken.\n+    Set accountIdSet = new HashSet<>();", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzODYxOA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455338618", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-15T20:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODAzMA=="}], "type": "inlineReview", "revised_code": {"commit": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..5197d7697 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -246,7 +246,7 @@ public class HelixAccountServiceTest {\n       accountId++;\n     }\n     updateAccountsAndAssertAccountExistence(accountsToUpdate, 4, true);\n-    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInactiveContainerCandidates(statsSnapshot);\n+    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInvalidContainers(statsSnapshot);\n     assertTrue(\"Mismatch in container Set after detect\", expectContainerSet.equals(invalidContainerSet));\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODI4OA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454768288", "bodyText": "INVALID -> INACTIVE", "author": "jsjtzyy", "createdAt": "2020-07-15T03:27:57Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -200,6 +203,53 @@ public void testCreateAccount() {\n     assertAccountsInAccountService(idToRefAccountMap.values(), NUM_REF_ACCOUNT, accountService);\n   }\n \n+  /**\n+   * Tests select INVALID {@link Container}s from DELETE_IN_PROGRESS {@link Container}s.", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzODcyOQ==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455338729", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-15T20:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..5197d7697 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -246,7 +246,7 @@ public class HelixAccountServiceTest {\n       accountId++;\n     }\n     updateAccountsAndAssertAccountExistence(accountsToUpdate, 4, true);\n-    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInactiveContainerCandidates(statsSnapshot);\n+    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInvalidContainers(statsSnapshot);\n     assertTrue(\"Mismatch in container Set after detect\", expectContainerSet.equals(invalidContainerSet));\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODM1Mw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454768353", "bodyText": "testSelectInactiveContainer", "author": "jsjtzyy", "createdAt": "2020-07-15T03:28:13Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -200,6 +203,53 @@ public void testCreateAccount() {\n     assertAccountsInAccountService(idToRefAccountMap.values(), NUM_REF_ACCOUNT, accountService);\n   }\n \n+  /**\n+   * Tests select INVALID {@link Container}s from DELETE_IN_PROGRESS {@link Container}s.\n+   */\n+  @Test\n+  public void testSelectInvalidContainer() throws Exception {", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzOTcxMw==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455339713", "bodyText": "Updated.", "author": "SophieGuo410", "createdAt": "2020-07-15T21:00:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODM1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..5197d7697 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -246,7 +246,7 @@ public class HelixAccountServiceTest {\n       accountId++;\n     }\n     updateAccountsAndAssertAccountExistence(accountsToUpdate, 4, true);\n-    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInactiveContainerCandidates(statsSnapshot);\n+    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInvalidContainers(statsSnapshot);\n     assertTrue(\"Mismatch in container Set after detect\", expectContainerSet.equals(invalidContainerSet));\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODU4NA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454768584", "bodyText": "format this file", "author": "jsjtzyy", "createdAt": "2020-07-15T03:29:00Z", "path": "ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java", "diffHunk": "@@ -200,6 +203,53 @@ public void testCreateAccount() {\n     assertAccountsInAccountService(idToRefAccountMap.values(), NUM_REF_ACCOUNT, accountService);\n   }\n \n+  /**\n+   * Tests select INVALID {@link Container}s from DELETE_IN_PROGRESS {@link Container}s.\n+   */\n+  @Test\n+  public void testSelectInvalidContainer() throws Exception {\n+    //generates store stats\n+    int accountCount = 1;\n+    int containerCount = 3;\n+    StatsSnapshot statsSnapshot =\n+        generateStoreStats(accountCount, containerCount, random, StatsReportType.ACCOUNT_REPORT);\n+\n+    // a set that records the account ids that have already been taken.\n+    Set accountIdSet = new HashSet<>();\n+    // generate a single reference account and container that can be referenced by refAccount and refContainer respectively.\n+    refAccountId = Utils.getRandomShort(random);\n+    accountIdSet.add(refAccountId);\n+    generateRefAccounts(idToRefAccountMap, idToRefContainerMap, accountIdSet, 2, 3);\n+    accountService = mockHelixAccountServiceFactory.getAccountService();\n+    accountService.updateAccounts(idToRefAccountMap.values());\n+    assertAccountsInAccountService(idToRefAccountMap.values(), 2, accountService);\n+\n+    Set<Container> expectContainerSet = new HashSet<>();\n+    List<Account> accountsToUpdate = new ArrayList<>();\n+    int accountId = 0;\n+    for (Account account : accountService.getAllAccounts()) {\n+      AccountBuilder accountBuilder =\n+          new AccountBuilder((short) accountId, \"A[\" + accountId + \"]\", AccountStatus.ACTIVE);\n+      int containerId = 0;\n+      for (Container container : account.getAllContainers()) {\n+        ContainerBuilder containerBuilder =\n+            new ContainerBuilder((short) containerId, \"C[\" + containerId + \"]\", ContainerStatus.DELETE_IN_PROGRESS,\n+                container.getDescription() + \"--extra\", (short) accountId);\n+        accountBuilder.addOrUpdateContainer(containerBuilder.build());\n+\n+        containerId++;\n+      }\n+      accountsToUpdate.add(accountBuilder.build());\n+      if (accountId == 1) {\n+        expectContainerSet.addAll(accountsToUpdate.get(accountId).getAllContainers());\n+      }\n+      accountId++;\n+    }\n+    updateAccountsAndAssertAccountExistence(accountsToUpdate, 4, true);\n+    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInactiveContainerCandidates(statsSnapshot);", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzOTg1Mg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455339852", "bodyText": "done!", "author": "SophieGuo410", "createdAt": "2020-07-15T21:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODU4NA=="}], "type": "inlineReview", "revised_code": {"commit": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "chunk": "diff --git a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\nindex 6d0885783..5197d7697 100644\n--- a/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n+++ b/ambry-account/src/test/java/com/github/ambry/account/HelixAccountServiceTest.java\n\n@@ -246,7 +246,7 @@ public class HelixAccountServiceTest {\n       accountId++;\n     }\n     updateAccountsAndAssertAccountExistence(accountsToUpdate, 4, true);\n-    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInactiveContainerCandidates(statsSnapshot);\n+    Set<Container> invalidContainerSet = ((HelixAccountService) accountService).selectInvalidContainers(statsSnapshot);\n     assertTrue(\"Mismatch in container Set after detect\", expectContainerSet.equals(invalidContainerSet));\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODg4NA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454768884", "bodyText": "format this file", "author": "jsjtzyy", "createdAt": "2020-07-15T03:30:03Z", "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixClusterAggregatorTest.java", "diffHunk": "@@ -103,7 +104,7 @@ public void testDoWorkBasic() throws IOException {\n       }\n \n       // Verify cluster wide raw stats aggregation\n-      StatsSnapshot rawSnapshot = mapper.readValue(aggregatedRawAndValidStats.getFirst(), StatsSnapshot.class);\n+      StatsSnapshot rawSnapshot = mapper.readValue(mapper.writeValueAsString(aggregatedRawAndValidStats.getFirst()), StatsSnapshot.class);", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzOTk2NA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455339964", "bodyText": "done!", "author": "SophieGuo410", "createdAt": "2020-07-15T21:00:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2ODg4NA=="}], "type": "inlineReview", "revised_code": {"commit": "cd8ded3f5f955b141188330e620ac48320be7e1e", "chunk": "diff --git a/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixClusterAggregatorTest.java b/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixClusterAggregatorTest.java\nindex ce3ecff0f..efaa8d7b1 100644\n--- a/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixClusterAggregatorTest.java\n+++ b/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixClusterAggregatorTest.java\n\n@@ -104,7 +105,8 @@ public class HelixClusterAggregatorTest {\n       }\n \n       // Verify cluster wide raw stats aggregation\n-      StatsSnapshot rawSnapshot = mapper.readValue(mapper.writeValueAsString(aggregatedRawAndValidStats.getFirst()), StatsSnapshot.class);\n+      StatsSnapshot rawSnapshot =\n+          mapper.readValue(mapper.writeValueAsString(aggregatedRawAndValidStats.getFirst()), StatsSnapshot.class);\n       assertEquals(\"Mismatch in total value of \" + type, nodeCount * expectedSnapshot.getValue(),\n           rawSnapshot.getValue());\n       if (type == StatsReportType.ACCOUNT_REPORT) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2OTUwNg==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r454769506", "bodyText": "Seems never used, can be removed. (Also format this file)", "author": "jsjtzyy", "createdAt": "2020-07-15T03:32:32Z", "path": "ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixParticipantTest.java", "diffHunk": "@@ -77,6 +79,7 @@ public HelixParticipantTest(String stateModelDef) {\n     props.setProperty(\"clustermap.state.model.definition\", stateModelDef);\n     this.stateModelDef = stateModelDef;\n     helixManagerFactory = new MockHelixManagerFactory();\n+    accountService = Mockito.mock(AccountService.class);", "originalCommit": "9091194f43c0bb55c8b0b542cfd48554d1a55efd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTM0MDEyOA==", "url": "https://github.com/linkedin/ambry/pull/1529#discussion_r455340128", "bodyText": "Removed.", "author": "SophieGuo410", "createdAt": "2020-07-15T21:00:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc2OTUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "cd8ded3f5f955b141188330e620ac48320be7e1e", "chunk": "diff --git a/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixParticipantTest.java b/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixParticipantTest.java\nindex 8bc5457d8..91921401c 100644\n--- a/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixParticipantTest.java\n+++ b/ambry-clustermap/src/test/java/com/github/ambry/clustermap/HelixParticipantTest.java\n\n@@ -79,7 +77,6 @@ public class HelixParticipantTest {\n     props.setProperty(\"clustermap.state.model.definition\", stateModelDef);\n     this.stateModelDef = stateModelDef;\n     helixManagerFactory = new MockHelixManagerFactory();\n-    accountService = Mockito.mock(AccountService.class);\n   }\n \n   /**\n"}}, {"oid": "ba98547eed7812ff20cb70690f4cab1e58e19d2d", "url": "https://github.com/linkedin/ambry/commit/ba98547eed7812ff20cb70690f4cab1e58e19d2d", "message": "ContainerDeletion_aggregation_phase1", "committedDate": "2020-07-15T19:14:45Z", "type": "commit"}, {"oid": "ea9a3b894736ec0fd9b92024045bdd39a82c7f51", "url": "https://github.com/linkedin/ambry/commit/ea9a3b894736ec0fd9b92024045bdd39a82c7f51", "message": "address comments", "committedDate": "2020-07-15T19:14:45Z", "type": "commit"}, {"oid": "30d4e7c8cd23e9fe2ad48bf9decc3cf3172b04f8", "url": "https://github.com/linkedin/ambry/commit/30d4e7c8cd23e9fe2ad48bf9decc3cf3172b04f8", "message": "use callback to decouple accountService from clusterParticipant", "committedDate": "2020-07-15T19:14:45Z", "type": "commit"}, {"oid": "464d0603f916805a95365b6b3f1f3e0a2f485b2f", "url": "https://github.com/linkedin/ambry/commit/464d0603f916805a95365b6b3f1f3e0a2f485b2f", "message": "address comments", "committedDate": "2020-07-15T19:14:45Z", "type": "commit"}, {"oid": "890c6851db92884b7db0959bce0c09bfd3a9bb18", "url": "https://github.com/linkedin/ambry/commit/890c6851db92884b7db0959bce0c09bfd3a9bb18", "message": "move callback interface to common dir and remove redundant code", "committedDate": "2020-07-15T19:14:45Z", "type": "commit"}, {"oid": "cd8ded3f5f955b141188330e620ac48320be7e1e", "url": "https://github.com/linkedin/ambry/commit/cd8ded3f5f955b141188330e620ac48320be7e1e", "message": "format change and add config file", "committedDate": "2020-07-15T19:16:11Z", "type": "forcePushed"}, {"oid": "34732febe9fb6ece3d2e8b83eea4273fc32387a8", "url": "https://github.com/linkedin/ambry/commit/34732febe9fb6ece3d2e8b83eea4273fc32387a8", "message": "format change and add config file", "committedDate": "2020-07-15T19:23:02Z", "type": "commit"}, {"oid": "34732febe9fb6ece3d2e8b83eea4273fc32387a8", "url": "https://github.com/linkedin/ambry/commit/34732febe9fb6ece3d2e8b83eea4273fc32387a8", "message": "format change and add config file", "committedDate": "2020-07-15T19:23:02Z", "type": "forcePushed"}]}