{"pr_number": 1402, "pr_title": "Add more tests to hard deleter for undelete record", "pr_createdAt": "2020-02-27T01:50:28Z", "pr_url": "https://github.com/linkedin/ambry/pull/1402", "timeline": [{"oid": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "url": "https://github.com/linkedin/ambry/commit/800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "message": "Add even more tests", "committedDate": "2020-02-28T21:41:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MjE3OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386652178", "bodyText": "java doc for this class please", "author": "jsjtzyy", "createdAt": "2020-03-02T21:11:13Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -653,22 +680,39 @@ private void performHardDeletes(List<MessageInfo> messageInfoList) throws StoreE\n     }\n   }\n \n+  class HardDeletePersistItem {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MTEzNQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387381135", "bodyText": "updated", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MjE3OA=="}], "type": "inlineReview", "revised_code": {"commit": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..791be5813 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -680,39 +675,24 @@ public class HardDeleter implements Runnable {\n     }\n   }\n \n-  class HardDeletePersistItem {\n-    BlobReadOptions blobReadOptions;\n-    byte[] messagesStoreRecoveryInfo;\n-    // The startToken when this blob is fetched from index.\n-    StoreFindToken startTokenForBlobReadOptions;\n-\n-    HardDeletePersistItem(BlobReadOptions blobReadOptions, byte[] messagesStoreRecoveryInfo, StoreFindToken token) {\n-      this.blobReadOptions = blobReadOptions;\n-      this.messagesStoreRecoveryInfo = messagesStoreRecoveryInfo;\n-      this.startTokenForBlobReadOptions = token;\n-    }\n-\n-    HardDeletePersistItem(BlobReadOptions blobReadOptions, byte[] messagesStoreRecoveryInfo) {\n-      this(blobReadOptions, messagesStoreRecoveryInfo, null);\n-    }\n-  }\n-\n   /**\n    * An object of this class contains all the information required for performing the hard delete recovery for the\n    * associated blob. This is the information that is persisted from time to time.\n    */\n   class HardDeletePersistInfo {\n-    private List<HardDeletePersistItem> items;\n+    private List<BlobReadOptions> blobReadOptionsList;\n+    private List<StoreFindToken> startTokenForBlobReadOptions;\n+    private List<byte[]> messageStoreRecoveryInfoList;\n \n     HardDeletePersistInfo() {\n-      this.items = new ArrayList<>();\n+      this.blobReadOptionsList = new ArrayList<>();\n+      this.startTokenForBlobReadOptions = new ArrayList<>();\n+      this.messageStoreRecoveryInfoList = new ArrayList<>();\n     }\n \n     HardDeletePersistInfo(DataInputStream stream, StoreKeyFactory storeKeyFactory) throws IOException {\n       this();\n       int numBlobsToRecover = stream.readInt();\n-      List<BlobReadOptions> blobReadOptionsList = new ArrayList<>();\n-      List<byte[]> messageStoreRecoveryInfoList = new ArrayList<>();\n       for (int i = 0; i < numBlobsToRecover; i++) {\n         blobReadOptionsList.add(BlobReadOptions.fromBytes(stream, storeKeyFactory, log));\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MzE0MA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386653140", "bodyText": "What if recovery range has been pruned but failed to persist cleanup token, will it be a problem?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:13:05Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -352,6 +359,24 @@ void preLogFlush() {\n   void postLogFlush() {\n     /* start token saved before the flush is now safe to be persisted */\n     startTokenSafeToPersist = startTokenBeforeLogFlush;\n+\n+    hardDeleteLock.lock();\n+    try {\n+      // PersistCleanupToken because startTokenSafeToPersist changed.\n+      pruneHardDeleteRecoveryRange();\n+      persistCleanupToken();", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MjExMA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387382110", "bodyText": "It's fine if it's fails to persist, then we will wait for the next one.\nThe assumption is that the file on the disk contains a valid range and all the records between this range. And every time we change the file (prune and then persist), we replace the old range with a new one. If we fail to persist it, then next time when we restart, we are going to recover from a older range, which is totally fine, since the hard delete operation is idempotent.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:49:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MzE0MA=="}], "type": "inlineReview", "revised_code": {"commit": "a4412c6929a5950386f6a2af694a703be3d41531", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..4d0cfeaba 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -355,11 +356,11 @@ public class HardDeleter implements Runnable {\n \n   /**\n    * This method will be called after the log is flushed.\n+   * In production, this will be called in the PersistentIndex's IndexPersistor thread.\n    */\n   void postLogFlush() {\n     /* start token saved before the flush is now safe to be persisted */\n     startTokenSafeToPersist = startTokenBeforeLogFlush;\n-\n     hardDeleteLock.lock();\n     try {\n       // PersistCleanupToken because startTokenSafeToPersist changed.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1ODY5OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386658698", "bodyText": "any reason to change the ordering here? Throttle the hard delete I/O ?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:23:58Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -625,9 +652,9 @@ private void performHardDeletes(List<MessageInfo> messageInfoList) throws StoreE\n           throw new StoreException(\"Aborting hard deletes as store is shutting down\",\n               StoreErrorCodes.Store_Shutting_Down);\n         }\n+        diskIOScheduler.getSlice(HARD_DELETE_CLEANUP_JOB_NAME, HARD_DELETE_CLEANUP_JOB_NAME, logWriteInfo.size);", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzAxMQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383011", "bodyText": "the reason for changing the order is to use diskIOScheduler.getSlice to throw an exception before  modify the log file. The reason why I want to throw an exception is to mock the situation when we persist the HardDeleteRecoveryRange but fail to actually hard delete the records in the log file. Under such situation, we can test if the recovery actually works or not.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:52:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1ODY5OA=="}], "type": "inlineReview", "revised_code": {"commit": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..791be5813 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -652,9 +647,9 @@ public class HardDeleter implements Runnable {\n           throw new StoreException(\"Aborting hard deletes as store is shutting down\",\n               StoreErrorCodes.Store_Shutting_Down);\n         }\n-        diskIOScheduler.getSlice(HARD_DELETE_CLEANUP_JOB_NAME, HARD_DELETE_CLEANUP_JOB_NAME, logWriteInfo.size);\n         logWriteInfo.logSegment.writeFrom(logWriteInfo.channel, logWriteInfo.offset, logWriteInfo.size);\n         metrics.hardDeleteDoneCount.inc(1);\n+        diskIOScheduler.getSlice(HARD_DELETE_CLEANUP_JOB_NAME, HARD_DELETE_CLEANUP_JOB_NAME, logWriteInfo.size);\n       }\n     } catch (IOException e) {\n       StoreErrorCodes errorCode = StoreException.resolveErrorCode(e);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MDk5OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386660998", "bodyText": "The method looks good, minor suggestion is to align with your comment and do a token type check at the very beginning. (Reject Journal based token)", "author": "jsjtzyy", "createdAt": "2020-03-02T21:28:46Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -705,52 +751,64 @@ int getSize() {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(blobReadOptionsList.size());\n+      dataOutputStream.writeInt(items.size());\n \n       /* Write all the blobReadOptions */\n-      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n-        dataOutputStream.write(blobReadOptions.toBytes());\n+      for (HardDeletePersistItem item : items) {\n+        dataOutputStream.write(item.blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n+      for (HardDeletePersistItem item : items) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(recoveryInfo.length);\n+        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(recoveryInfo);\n+        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n+     * Token passed to this method has to be a indexed based one.\n      */\n-    void pruneTill(StoreKey storeKey) {\n-      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n-      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n-      while (blobReadOptionsListIterator.hasNext()) {\n-      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n-         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n-         later occurrence is the one really associated with this token, it does not affect the safety.\n-         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n-        messageStoreRecoveryListIterator.next();\n-        if (blobReadOptionsListIterator.next().getMessageInfo().getStoreKey().equals(storeKey)) {\n-          break;\n+    void pruneTill(StoreFindToken token) {\n+      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n+      while (itemsIterator.hasNext()) {\n+        HardDeletePersistItem item = itemsIterator.next();\n+        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {\n+          itemsIterator.remove();\n         } else {\n-          blobReadOptionsListIterator.remove();\n-          messageStoreRecoveryListIterator.remove();\n+          if (compareTwoTokens(item.startTokenForBlobReadOptions, token) >= 0) {\n+            break;\n+          } else {\n+            itemsIterator.remove();\n+          }\n         }\n       }\n     }\n \n-    private List<BlobReadOptions> getBlobReadOptionsList() {\n-      return blobReadOptionsList;\n+    /**\n+     * Compare two StoreFindTokens and return the result as an integer like compareTo interface.\n+     * These two tokens have to be IndexBased tokens.\n+     * @param token1 The first token to compare.\n+     * @param token2 The second tokent to compare.\n+     * @return 0 means they are equal. negative number means token1 is less than token2. postive number means the opposite.\n+     */\n+    int compareTwoTokens(StoreFindToken token1, StoreFindToken token2) {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzA2NQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383065", "bodyText": "good catch, updated.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:52:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MDk5OA=="}], "type": "inlineReview", "revised_code": {"commit": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..791be5813 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -751,52 +731,49 @@ public class HardDeleter implements Runnable {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(items.size());\n+      dataOutputStream.writeInt(blobReadOptionsList.size());\n \n       /* Write all the blobReadOptions */\n-      for (HardDeletePersistItem item : items) {\n-        dataOutputStream.write(item.blobReadOptions.toBytes());\n+      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n+        dataOutputStream.write(blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (HardDeletePersistItem item : items) {\n+      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n+        dataOutputStream.writeInt(recoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n+        dataOutputStream.write(recoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n-     * Token passed to this method has to be a indexed based one.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n      */\n     void pruneTill(StoreFindToken token) {\n-      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n-      while (itemsIterator.hasNext()) {\n-        HardDeletePersistItem item = itemsIterator.next();\n-        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {\n-          itemsIterator.remove();\n+      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n+      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n+      Iterator<StoreFindToken> startTokenForBlobReadOptionsListIterator = startTokenForBlobReadOptions.iterator();\n+      while (startTokenForBlobReadOptionsListIterator.hasNext()) {\n+      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n+         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n+         later occurrence is the one really associated with this token, it does not affect the safety.\n+         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n+        messageStoreRecoveryListIterator.next();\n+        blobReadOptionsListIterator.next();\n+        if (compareTwoTokens(startTokenForBlobReadOptionsListIterator.next(), token) >= 0) {\n+          break;\n         } else {\n-          if (compareTwoTokens(item.startTokenForBlobReadOptions, token) >= 0) {\n-            break;\n-          } else {\n-            itemsIterator.remove();\n-          }\n+          blobReadOptionsListIterator.remove();\n+          messageStoreRecoveryListIterator.remove();\n+          startTokenForBlobReadOptionsListIterator.remove();\n         }\n       }\n     }\n \n-    /**\n-     * Compare two StoreFindTokens and return the result as an integer like compareTo interface.\n-     * These two tokens have to be IndexBased tokens.\n-     * @param token1 The first token to compare.\n-     * @param token2 The second tokent to compare.\n-     * @return 0 means they are equal. negative number means token1 is less than token2. postive number means the opposite.\n-     */\n     int compareTwoTokens(StoreFindToken token1, StoreFindToken token2) {\n       if (token1.equals(token2)) {\n         return 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2NzkzMA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386667930", "bodyText": "Could you explain a little bit about this case?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:42:27Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -705,52 +751,64 @@ int getSize() {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(blobReadOptionsList.size());\n+      dataOutputStream.writeInt(items.size());\n \n       /* Write all the blobReadOptions */\n-      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n-        dataOutputStream.write(blobReadOptions.toBytes());\n+      for (HardDeletePersistItem item : items) {\n+        dataOutputStream.write(item.blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n+      for (HardDeletePersistItem item : items) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(recoveryInfo.length);\n+        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(recoveryInfo);\n+        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n+     * Token passed to this method has to be a indexed based one.\n      */\n-    void pruneTill(StoreKey storeKey) {\n-      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n-      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n-      while (blobReadOptionsListIterator.hasNext()) {\n-      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n-         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n-         later occurrence is the one really associated with this token, it does not affect the safety.\n-         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n-        messageStoreRecoveryListIterator.next();\n-        if (blobReadOptionsListIterator.next().getMessageInfo().getStoreKey().equals(storeKey)) {\n-          break;\n+    void pruneTill(StoreFindToken token) {\n+      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n+      while (itemsIterator.hasNext()) {\n+        HardDeletePersistItem item = itemsIterator.next();\n+        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzQ0NA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383444", "bodyText": "The very first time when we starting scanning through the log file, we are using a Uninitialized FindToken. And since it's at the very first beginning of a log file, we can assume they are always prior to any IndexBased FindToken.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2NzkzMA=="}], "type": "inlineReview", "revised_code": {"commit": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..791be5813 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -751,52 +731,49 @@ public class HardDeleter implements Runnable {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(items.size());\n+      dataOutputStream.writeInt(blobReadOptionsList.size());\n \n       /* Write all the blobReadOptions */\n-      for (HardDeletePersistItem item : items) {\n-        dataOutputStream.write(item.blobReadOptions.toBytes());\n+      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n+        dataOutputStream.write(blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (HardDeletePersistItem item : items) {\n+      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n+        dataOutputStream.writeInt(recoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n+        dataOutputStream.write(recoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n-     * Token passed to this method has to be a indexed based one.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n      */\n     void pruneTill(StoreFindToken token) {\n-      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n-      while (itemsIterator.hasNext()) {\n-        HardDeletePersistItem item = itemsIterator.next();\n-        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {\n-          itemsIterator.remove();\n+      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n+      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n+      Iterator<StoreFindToken> startTokenForBlobReadOptionsListIterator = startTokenForBlobReadOptions.iterator();\n+      while (startTokenForBlobReadOptionsListIterator.hasNext()) {\n+      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n+         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n+         later occurrence is the one really associated with this token, it does not affect the safety.\n+         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n+        messageStoreRecoveryListIterator.next();\n+        blobReadOptionsListIterator.next();\n+        if (compareTwoTokens(startTokenForBlobReadOptionsListIterator.next(), token) >= 0) {\n+          break;\n         } else {\n-          if (compareTwoTokens(item.startTokenForBlobReadOptions, token) >= 0) {\n-            break;\n-          } else {\n-            itemsIterator.remove();\n-          }\n+          blobReadOptionsListIterator.remove();\n+          messageStoreRecoveryListIterator.remove();\n+          startTokenForBlobReadOptionsListIterator.remove();\n         }\n       }\n     }\n \n-    /**\n-     * Compare two StoreFindTokens and return the result as an integer like compareTo interface.\n-     * These two tokens have to be IndexBased tokens.\n-     * @param token1 The first token to compare.\n-     * @param token2 The second tokent to compare.\n-     * @return 0 means they are equal. negative number means token1 is less than token2. postive number means the opposite.\n-     */\n     int compareTwoTokens(StoreFindToken token1, StoreFindToken token2) {\n       if (token1.equals(token2)) {\n         return 0;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3MTI2Ng==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386671266", "bodyText": "For concurrency, let's make sure all variables shared by HardDeleter thread and Index persistor thread to be volatile.", "author": "jsjtzyy", "createdAt": "2020-03-02T21:49:07Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -89,9 +89,9 @@\n    * startTokenBeforeLogFlush: This token is set to the current start token just before log flush and once the log is\n    *                           flushed, this is used to set startTokenSafeToPersist.\n    */\n-  private FindToken startToken;\n   private FindToken startTokenBeforeLogFlush;\n-  private FindToken startTokenSafeToPersist;\n+  private volatile FindToken startTokenSafeToPersist;", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzQ2NA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383464", "bodyText": "sure.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3MTI2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "a4412c6929a5950386f6a2af694a703be3d41531", "chunk": "diff --git a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\nindex e2be9f48c..4d0cfeaba 100644\n--- a/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n+++ b/ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java\n\n@@ -89,10 +89,10 @@ public class HardDeleter implements Runnable {\n    * startTokenBeforeLogFlush: This token is set to the current start token just before log flush and once the log is\n    *                           flushed, this is used to set startTokenSafeToPersist.\n    */\n-  private FindToken startTokenBeforeLogFlush;\n+  private volatile FindToken startTokenBeforeLogFlush;\n   private volatile FindToken startTokenSafeToPersist;\n-  private FindToken startToken;\n-  private FindToken endToken;\n+  private volatile FindToken startToken;\n+  private volatile FindToken endToken;\n   private StoreFindToken recoveryEndToken;\n   private HardDeletePersistInfo hardDeleteRecoveryRange = new HardDeletePersistInfo();\n   private boolean isCaughtUp = false;\n"}}, {"oid": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "url": "https://github.com/linkedin/ambry/commit/d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "message": "Add more tests to hard deleter for undelete record", "committedDate": "2020-03-04T00:01:35Z", "type": "commit"}, {"oid": "e4345cd6237deb736526c9f1bf7351120e3942c0", "url": "https://github.com/linkedin/ambry/commit/e4345cd6237deb736526c9f1bf7351120e3942c0", "message": "Add even more tests", "committedDate": "2020-03-04T00:01:35Z", "type": "commit"}, {"oid": "a4412c6929a5950386f6a2af694a703be3d41531", "url": "https://github.com/linkedin/ambry/commit/a4412c6929a5950386f6a2af694a703be3d41531", "message": "Add something", "committedDate": "2020-03-04T00:46:07Z", "type": "commit"}, {"oid": "a4412c6929a5950386f6a2af694a703be3d41531", "url": "https://github.com/linkedin/ambry/commit/a4412c6929a5950386f6a2af694a703be3d41531", "message": "Add something", "committedDate": "2020-03-04T00:46:07Z", "type": "forcePushed"}]}