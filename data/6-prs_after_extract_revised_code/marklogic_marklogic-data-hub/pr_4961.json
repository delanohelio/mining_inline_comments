{"pr_number": 4961, "pr_title": "DHFPROD-6274: Install Spark modules for reading if not present", "pr_createdAt": "2020-12-08T19:50:23Z", "pr_url": "https://github.com/marklogic/marklogic-data-hub/pull/4961", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ2ODAxNg==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539468016", "bodyText": "I believe this needs to load readLib.sjs and partition-lib.xqy as well, since initializeRead.sjs depends on those.", "author": "rjrudin", "createdAt": "2020-12-09T16:44:20Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java", "diffHunk": "@@ -153,6 +161,10 @@ private InputStreamHandle readCustomInitializeApiDefinition(Map<String, String>\n                 throw new RuntimeException(\"Unable to read custom API module for initializing Read job: \" + options.get(key) + \"; cause: \" + ex.getMessage(), ex);\n             }\n         }\n+        else {\n+            loadModuleIfNotPresent(\"/marklogic-data-hub-spark-connector/initializeRead.sjs\", Format.TEXT);", "originalCommit": "6fb5d4f1765f76eabdc6853e7b90b7282723f7c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUzMTYwMA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539531600", "bodyText": "Hi @rjrudin, readLib.sjs and partition-lib.xqy are loaded to the data-hub-MODULES in the \"determineReadRowsEndpointParams\" method so they will be present in the database before we reach here. Also, currently i have not put any condition for loading  readLib.sjs and partition-lib.xqy. Hence they will always be loaded if they are not present. Please let me know if we need to add a condition.", "author": "anu3990", "createdAt": "2020-12-09T18:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ2ODAxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU2NDE1Mg==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539564152", "bodyText": "I see - determineReadRowsEndpointParams is called before initializeRead is called. Sounds good.", "author": "rjrudin", "createdAt": "2020-12-09T18:56:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ2ODAxNg=="}], "type": "inlineReview", "revised_code": {"commit": "b3571c19436fd003880f6301167dd6786d7a83db", "chunk": "diff --git a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\nindex f68a009e7..f85fcbe52 100644\n--- a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n+++ b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n\n@@ -162,8 +161,8 @@ public class HubDataSourceReader extends LoggingObject implements DataSourceRead\n             }\n         }\n         else {\n-            loadModuleIfNotPresent(\"/marklogic-data-hub-spark-connector/initializeRead.sjs\", Format.TEXT);\n-            loadModuleIfNotPresent(\"/marklogic-data-hub-spark-connector/initializeRead.api\", Format.JSON);\n+            moduleWriter.loadModuleIfNotPresent(\"/marklogic-data-hub-spark-connector/initializeRead.sjs\", Format.TEXT);\n+            moduleWriter.loadModuleIfNotPresent(\"/marklogic-data-hub-spark-connector/initializeRead.api\", Format.JSON);\n         }\n \n         return initializeDefinition;\n"}}, {"oid": "0fc111b4d6f094c5cc4c5ff7aed6faa05fc03211", "url": "https://github.com/marklogic/marklogic-data-hub/commit/0fc111b4d6f094c5cc4c5ff7aed6faa05fc03211", "message": "DHFPROD-6274: Install Spark modules for reading if not present", "committedDate": "2020-12-09T19:31:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMTA1MA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539601050", "bodyText": "Just realized this is duplicated from HubDataSourceWriter!\nLet's instead have a ModuleWriter class with methods of loadModuleIfNotPresent and endpointExists. It should go in the \"v2\" package since it's generic to read/write. Its constructor should accept a HubClient which it'll use to interact with the modules database.", "author": "rjrudin", "createdAt": "2020-12-09T19:52:50Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java", "diffHunk": "@@ -204,6 +221,35 @@ private JsonNode determineReadRowsEndpointParams(Map<String, String> options) {\n         return endpointParams;\n     }\n \n+    private void loadModuleIfNotPresent(String modulePath, Format format) {", "originalCommit": "0fc111b4d6f094c5cc4c5ff7aed6faa05fc03211", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYxNTY2Mg==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539615662", "bodyText": "Done", "author": "anu3990", "createdAt": "2020-12-09T20:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMTA1MA=="}], "type": "inlineReview", "revised_code": {"commit": "b3571c19436fd003880f6301167dd6786d7a83db", "chunk": "diff --git a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\nindex f68a009e7..f85fcbe52 100644\n--- a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n+++ b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n\n@@ -221,35 +220,7 @@ public class HubDataSourceReader extends LoggingObject implements DataSourceRead\n         return endpointParams;\n     }\n \n-    private void loadModuleIfNotPresent(String modulePath, Format format) {\n-        if (!endpointExists(modulePath)) {\n-            try {\n-                DocumentManager modMgr = hubClient.getModulesClient().newDocumentManager();\n-                DocumentMetadataHandle metadata = buildDocumentMetadata(hubClientConfig);\n-                logger.info(\"Loading module: \" + modulePath);\n-                modMgr.write(modulePath, metadata, new InputStreamHandle(new ClassPathResource(modulePath).getInputStream()).withFormat(format));\n-            } catch (IOException e) {\n-                throw new RuntimeException(\"Unable to write endpoint at path: \" + modulePath + \"; cause: \" + e.getMessage(), e);\n-            }\n-        }\n-    }\n \n-    private boolean endpointExists(String scriptPath) {\n-        return !(hubClient.getModulesClient().newJSONDocumentManager().exists(scriptPath) == null);\n-    }\n-\n-    private DocumentMetadataHandle buildDocumentMetadata(HubClientConfig hubClientConfig) {\n-        DocumentMetadataHandle metadata = new DocumentMetadataHandle();\n-        String modulePermissions = hubClientConfig.getModulePermissions();\n-        new DefaultDocumentPermissionsParser().parsePermissions(modulePermissions, metadata.getPermissions());\n-\n-        // It seems preferable to use this collection so that modules loaded by the connector are considered OOTB\n-        // modules. Otherwise, if the modules are not loaded in this collection, tasks like mlClearUserModules will\n-        // delete them, which does not seem expected.\n-        metadata.getCollections().addAll(\"hub-core-module\");\n-\n-        return metadata;\n-    }\n }\n \n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMTIwNQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539601205", "bodyText": "This can go into ModuleWriter as well.", "author": "rjrudin", "createdAt": "2020-12-09T19:53:05Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java", "diffHunk": "@@ -204,6 +221,35 @@ private JsonNode determineReadRowsEndpointParams(Map<String, String> options) {\n         return endpointParams;\n     }\n \n+    private void loadModuleIfNotPresent(String modulePath, Format format) {\n+        if (!endpointExists(modulePath)) {\n+            try {\n+                DocumentManager modMgr = hubClient.getModulesClient().newDocumentManager();\n+                DocumentMetadataHandle metadata = buildDocumentMetadata(hubClientConfig);\n+                logger.info(\"Loading module: \" + modulePath);\n+                modMgr.write(modulePath, metadata, new InputStreamHandle(new ClassPathResource(modulePath).getInputStream()).withFormat(format));\n+            } catch (IOException e) {\n+                throw new RuntimeException(\"Unable to write endpoint at path: \" + modulePath + \"; cause: \" + e.getMessage(), e);\n+            }\n+        }\n+    }\n+\n+    private boolean endpointExists(String scriptPath) {\n+        return !(hubClient.getModulesClient().newJSONDocumentManager().exists(scriptPath) == null);\n+    }\n+\n+    private DocumentMetadataHandle buildDocumentMetadata(HubClientConfig hubClientConfig) {", "originalCommit": "0fc111b4d6f094c5cc4c5ff7aed6faa05fc03211", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYxNTczNQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4961#discussion_r539615735", "bodyText": "Done", "author": "anu3990", "createdAt": "2020-12-09T20:16:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMTIwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "b3571c19436fd003880f6301167dd6786d7a83db", "chunk": "diff --git a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\nindex f68a009e7..f85fcbe52 100644\n--- a/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n+++ b/marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubDataSourceReader.java\n\n@@ -221,35 +220,7 @@ public class HubDataSourceReader extends LoggingObject implements DataSourceRead\n         return endpointParams;\n     }\n \n-    private void loadModuleIfNotPresent(String modulePath, Format format) {\n-        if (!endpointExists(modulePath)) {\n-            try {\n-                DocumentManager modMgr = hubClient.getModulesClient().newDocumentManager();\n-                DocumentMetadataHandle metadata = buildDocumentMetadata(hubClientConfig);\n-                logger.info(\"Loading module: \" + modulePath);\n-                modMgr.write(modulePath, metadata, new InputStreamHandle(new ClassPathResource(modulePath).getInputStream()).withFormat(format));\n-            } catch (IOException e) {\n-                throw new RuntimeException(\"Unable to write endpoint at path: \" + modulePath + \"; cause: \" + e.getMessage(), e);\n-            }\n-        }\n-    }\n \n-    private boolean endpointExists(String scriptPath) {\n-        return !(hubClient.getModulesClient().newJSONDocumentManager().exists(scriptPath) == null);\n-    }\n-\n-    private DocumentMetadataHandle buildDocumentMetadata(HubClientConfig hubClientConfig) {\n-        DocumentMetadataHandle metadata = new DocumentMetadataHandle();\n-        String modulePermissions = hubClientConfig.getModulePermissions();\n-        new DefaultDocumentPermissionsParser().parsePermissions(modulePermissions, metadata.getPermissions());\n-\n-        // It seems preferable to use this collection so that modules loaded by the connector are considered OOTB\n-        // modules. Otherwise, if the modules are not loaded in this collection, tasks like mlClearUserModules will\n-        // delete them, which does not seem expected.\n-        metadata.getCollections().addAll(\"hub-core-module\");\n-\n-        return metadata;\n-    }\n }\n \n \n"}}, {"oid": "b3571c19436fd003880f6301167dd6786d7a83db", "url": "https://github.com/marklogic/marklogic-data-hub/commit/b3571c19436fd003880f6301167dd6786d7a83db", "message": "DHFPROD-6274: Install Spark modules for reading if not present", "committedDate": "2020-12-09T20:15:21Z", "type": "commit"}, {"oid": "b3571c19436fd003880f6301167dd6786d7a83db", "url": "https://github.com/marklogic/marklogic-data-hub/commit/b3571c19436fd003880f6301167dd6786d7a83db", "message": "DHFPROD-6274: Install Spark modules for reading if not present", "committedDate": "2020-12-09T20:15:21Z", "type": "forcePushed"}]}