{"pr_number": 240, "pr_title": "HH 108440 fix nab-kafka at most once semantics", "pr_createdAt": "2020-04-29T22:53:00Z", "pr_url": "https://github.com/hhru/nuts-and-bolts/pull/240", "timeline": [{"oid": "cddae9913c558fd459ff276af0a378d2cf32477d", "url": "https://github.com/hhru/nuts-and-bolts/commit/cddae9913c558fd459ff276af0a378d2cf32477d", "message": "HH-108440 up kafka-test-utils", "committedDate": "2020-04-30T18:01:59Z", "type": "commit"}, {"oid": "1e9d6dd1c450b2ad2c506fbad201e06bc683adab", "url": "https://github.com/hhru/nuts-and-bolts/commit/1e9d6dd1c450b2ad2c506fbad201e06bc683adab", "message": "HH-108440 use 5 topic partitions from tests", "committedDate": "2020-05-01T16:01:28Z", "type": "commit"}, {"oid": "e2d1f056325eac919a3c0e01caf39819b7e7342e", "url": "https://github.com/hhru/nuts-and-bolts/commit/e2d1f056325eac919a3c0e01caf39819b7e7342e", "message": "HH-108449 fix config provider", "committedDate": "2020-05-01T16:03:20Z", "type": "commit"}, {"oid": "39517a063d745afe0e33c80b6883fe649b367fba", "url": "https://github.com/hhru/nuts-and-bolts/commit/39517a063d745afe0e33c80b6883fe649b367fba", "message": "HH-108440 use manual acks system", "committedDate": "2020-05-01T16:04:18Z", "type": "commit"}, {"oid": "39517a063d745afe0e33c80b6883fe649b367fba", "url": "https://github.com/hhru/nuts-and-bolts/commit/39517a063d745afe0e33c80b6883fe649b367fba", "message": "HH-108440 use manual acks system", "committedDate": "2020-05-01T16:04:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYwOTk3Nw==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418609977", "bodyText": "\u041f\u0440\u0438\u0448\u043b\u043e\u0441\u044c \u0432\u0432\u0435\u0441\u0442\u0438 \u043a\u043b\u0430\u0441\u0441, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u043e\u043a\u0438\u043d\u0443\u0442\u044c \u0432\u044b\u0437\u043e\u0432 kafkaConsumer.onMessagesBatch \u0432 \u0441\u043f\u0440\u0438\u043d\u0433\u043e\u0432\u044b\u0439 KafkaContainer:\n\u041a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440 \u043d\u0443\u0436\u0435\u043d \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0437\u0434\u0430\u0442\u044c  \u043d\u0430\u0448 kafkaConsumer, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u043e\u043d \u0434\u043e\u043b\u0436\u0435\u043d \u043e\u0431\u0440\u0430\u0449\u0430\u0442\u044c\u0441\u044f \u043a \u043a\u043e\u043d\u0441\u0443\u043c\u0435\u0440\u0443", "author": "bokshitsky", "createdAt": "2020-05-01T16:07:15Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/ConsumeStrategyInternal.java", "diffHunk": "@@ -0,0 +1,20 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.List;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+\n+\n+class ConsumeStrategyInternal<T> {", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "chunk": "diff --git a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/ConsumeStrategyInternal.java b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/ConsumeStrategyInternal.java\ndeleted file mode 100644\nindex 642ad340..00000000\n--- a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/ConsumeStrategyInternal.java\n+++ /dev/null\n\n@@ -1,20 +0,0 @@\n-package ru.hh.nab.kafka.consumer;\n-\n-import java.util.List;\n-import org.apache.kafka.clients.consumer.Consumer;\n-import org.apache.kafka.clients.consumer.ConsumerRecord;\n-\n-\n-class ConsumeStrategyInternal<T> {\n-\n-  private volatile KafkaConsumer<T> kafkaConsumer;\n-\n-  public void setKafkaConsumer(KafkaConsumer<T> kafkaConsumer) {\n-    this.kafkaConsumer = kafkaConsumer;\n-  }\n-\n-  void invokeOnConsumer(List<ConsumerRecord<String, T>> messages, Consumer<?, ?> consumer) {\n-    kafkaConsumer.onMessagesBatch(messages, consumer);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMDQ0MA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418610440", "bodyText": "\u041b\u043e\u0433\u0438\u043a\u0430 backoffa \u0441\u043a\u043e\u043f\u0438\u0440\u043e\u0432\u0430\u043d\u0430 \u0438\u0437 SeekToCurrentBatchErrorHandler \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e, \u0434\u0430\u0436\u0435 \u043d\u0435 \u0447\u0438\u0442\u0430\u044f\n\u041c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043b\u043e\u0433\u0438\u043a\u0430 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0444\u0435\u0439\u043b\u0430 - \u043f\u0430\u0434\u0430\u0435\u043c \u043d\u0435 \u0432 \u043d\u0430\u0447\u0430\u043b\u043e \u0431\u0430\u0442\u0447\u0430, \u0430 \u043d\u0430 \u0442\u043e \u043c\u0435\u0441\u0442\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u0435 ack-\u043d\u0443\u043b\u0438 \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0437", "author": "bokshitsky", "createdAt": "2020-05-01T16:08:13Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/SeekToFirstNotAckedMessageErrorHandler.java", "diffHunk": "@@ -0,0 +1,92 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Optional;\n+import static java.util.stream.Collectors.toMap;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+import org.springframework.kafka.KafkaException;\n+import org.springframework.kafka.listener.ContainerAwareBatchErrorHandler;\n+import org.springframework.kafka.listener.MessageListenerContainer;\n+import org.springframework.util.backoff.BackOff;\n+import org.springframework.util.backoff.BackOffExecution;\n+\n+class SeekToFirstNotAckedMessageErrorHandler<T> implements ContainerAwareBatchErrorHandler {\n+\n+  private final ThreadLocal<BackOffExecution> backOffs = new ThreadLocal<>();\n+\n+  private final ThreadLocal<Long> lastInterval = new ThreadLocal<>();\n+\n+  private final BackOff backOff;\n+  private volatile KafkaConsumer<T> kafkaConsumer;\n+\n+  public SeekToFirstNotAckedMessageErrorHandler(BackOff backOff) {\n+    this.backOff = backOff;\n+  }\n+\n+  public void setKafkaConsumer(KafkaConsumer<T> kafkaConsumer) {\n+    this.kafkaConsumer = kafkaConsumer;\n+  }\n+\n+  @Override\n+  public void handle(Exception thrownException, ConsumerRecords<?, ?> data, Consumer<?, ?> consumer,\n+                     MessageListenerContainer container) {\n+\n+    List<ConsumerRecord<String, T>> currentBatch = kafkaConsumer.getCurrentBatch();\n+    if (!currentBatch.isEmpty()) {\n+      LinkedHashMap<TopicPartition, OffsetAndMetadata> offsetsToSeek = currentBatch.stream().collect(toMap(\n+          record -> new TopicPartition(record.topic(), record.partition()),\n+          record -> new OffsetAndMetadata(record.offset()),\n+          (offset1, offset2) -> offset1,\n+          LinkedHashMap::new\n+      ));\n+\n+      Optional.ofNullable(kafkaConsumer.getLastAckedBatchRecord()).ifPresent(lastAckedBatchRecord -> {\n+        for (ConsumerRecord<String, T> record : kafkaConsumer.getCurrentBatch()) {\n+          offsetsToSeek.put(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1));\n+          if (record == lastAckedBatchRecord) {\n+            break;\n+          }\n+        }\n+      });\n+\n+      offsetsToSeek.forEach(consumer::seek);\n+    }\n+\n+    if (this.backOff != null) {", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyOTA3OQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420729079", "bodyText": "\u043c\u0431 \u0443\u043d\u0430\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0442\u043e\u0433\u0434\u0430 \u043e\u0442 SeekToCurrentBatchErrorHandler?", "author": "Iskuskov", "createdAt": "2020-05-06T11:48:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMDQ0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgzOTUwNA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420839504", "bodyText": "\u041e\u0442 \u043d\u0435\u0433\u043e \u043d\u0435 \u0431\u0443\u0434\u0435\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043d\u0438 \u043e\u0434\u0438\u043d \u043c\u0435\u0442\u043e\u0434, \u0432\u0440\u043e\u0434\u0435 \u0441\u043c\u044b\u0441\u043b\u0430 \u043d\u0435\u0442 \u0442\u043e\u0433\u0434\u0430", "author": "bokshitsky", "createdAt": "2020-05-06T14:32:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMDQ0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg3NzA0Ng==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420877046", "bodyText": "\u0434\u0430, \u044f \u0447\u0442\u043e-\u0442\u043e \u043f\u043e\u0434\u0443\u043c\u0430\u043b, \u0447\u0442\u043e \u0442\u0430\u043c handle() \u043c\u043e\u0436\u043d\u043e \u0432\u044b\u0442\u0430\u0449\u0438\u0442\u044c, \u043d\u043e \u0442\u0430\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0447\u0430\u0441\u0442\u044c \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u0430", "author": "Iskuskov", "createdAt": "2020-05-06T15:20:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMDQ0MA=="}], "type": "inlineReview", "revised_code": {"commit": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "chunk": "diff --git a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/SeekToFirstNotAckedMessageErrorHandler.java b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/SeekToFirstNotAckedMessageErrorHandler.java\nindex 4ce48799..0e0d6566 100644\n--- a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/SeekToFirstNotAckedMessageErrorHandler.java\n+++ b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/SeekToFirstNotAckedMessageErrorHandler.java\n\n@@ -22,13 +22,10 @@ class SeekToFirstNotAckedMessageErrorHandler<T> implements ContainerAwareBatchEr\n   private final ThreadLocal<Long> lastInterval = new ThreadLocal<>();\n \n   private final BackOff backOff;\n-  private volatile KafkaConsumer<T> kafkaConsumer;\n+  private final KafkaConsumer<T> kafkaConsumer;\n \n-  public SeekToFirstNotAckedMessageErrorHandler(BackOff backOff) {\n+  public SeekToFirstNotAckedMessageErrorHandler(BackOff backOff, KafkaConsumer<T> kafkaConsumer) {\n     this.backOff = backOff;\n-  }\n-\n-  public void setKafkaConsumer(KafkaConsumer<T> kafkaConsumer) {\n     this.kafkaConsumer = kafkaConsumer;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMTExMA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418611110", "bodyText": "\u0421\u0435\u0439\u0447\u0430\u0441 \u0437\u0430\u0445\u0430\u0440\u0434\u043a\u043e\u0434\u0438\u043b KafkaInternalTopicAck \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u0447\u0438\u043d\u0438\u0442\u044c \u0432 \u0442\u0435\u043a\u0443\u0449\u0438\u0445 \u043a\u043e\u043d\u0441\u0443\u043c\u0435\u0440\u0430\u0445 \u0441\u0435\u043c\u0430\u043d\u0442\u0438\u043a\u0443, \u043d\u043e \u0432\u043e\u043e\u0431\u0449\u0435 \u044d\u0442\u043e \u0437\u0430\u0445\u043e\u0434 \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e\u0431\u044b \u043d\u0430\u0443\u0447\u0438\u0442\u044c nab-\u043a\u0430\u0444\u043a\u0443 \u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043e\u0444\u0444\u0441\u0435\u0442\u044b \u0432 \u043b\u044e\u0431\u043e\u043c \u043d\u0443\u0436\u043d\u043e\u043c \u043c\u0435\u0441\u0442\u0435, \u0430 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0441\u0430\u043c\u043e\u0439 \u043a\u0430\u0444\u043a\u0435", "author": "bokshitsky", "createdAt": "2020-05-01T16:09:40Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaConsumer.java", "diffHunk": "@@ -1,12 +1,66 @@\n package ru.hh.nab.kafka.consumer;\n \n-import org.apache.kafka.common.TopicPartition;\n import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.common.TopicPartition;\n+import org.springframework.kafka.listener.AbstractMessageListenerContainer;\n+\n+public class KafkaConsumer<T> {\n+\n+  private final AbstractMessageListenerContainer<String, T> springKafkaContainer;\n+\n+  private final ThreadLocal<List<ConsumerRecord<String, T>>> currentBatch = new InheritableThreadLocal<>();\n+  private final ThreadLocal<ConsumerRecord<String, T>> lastAckedBatchRecord = new InheritableThreadLocal<>();\n+  private final ConsumeStrategy<T> consumeStrategy;\n+\n+  public KafkaConsumer(AbstractMessageListenerContainer<String, T> springKafkaContainer, ConsumeStrategy<T> consumeStrategy) {\n+    this.springKafkaContainer = springKafkaContainer;\n+    this.consumeStrategy = consumeStrategy;\n+  }\n+\n+  void start() {\n+    springKafkaContainer.start();\n+  }\n+\n+  void stop(Runnable callback) {\n+    springKafkaContainer.stop(callback);\n+  }\n+\n+  void stop() {\n+    springKafkaContainer.stop();\n+  }\n+\n+  public Collection<TopicPartition> getAssignedPartitions() {\n+    return springKafkaContainer.getAssignedPartitions();\n+  }\n+\n+  public ConsumerRecord<String, T> getLastAckedBatchRecord() {\n+    return lastAckedBatchRecord.get();\n+  }\n \n-public interface KafkaConsumer {\n+  public List<ConsumerRecord<String, T>> getCurrentBatch() {\n+    return currentBatch.get();\n+  }\n \n-  void stopConsumer();\n+  public void setLastAckedBatchRecord(ConsumerRecord<String, T> record) {\n+    lastAckedBatchRecord.set(record);\n+  }\n \n-  Collection<TopicPartition> getAssignedPartitions();\n+  public void onMessagesBatch(List<ConsumerRecord<String, T>> messages, Consumer<?, ?> consumer) {\n+    List<ConsumerRecord<String, T>> sortedBatch = messages.stream().sorted(\n+        Comparator.comparing((Function<ConsumerRecord<String, T>, String>) ConsumerRecord::topic)\n+            .thenComparingInt(ConsumerRecord::partition)\n+            .thenComparingLong(ConsumerRecord::offset)\n+    ).collect(Collectors.toUnmodifiableList());\n \n+    lastAckedBatchRecord.remove();\n+    currentBatch.set(sortedBatch);\n+    Ack<T> ack = new KafkaInternalTopicAck<>(this, consumer);", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc0OTI4MQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420749281", "bodyText": "\u0442\u0438\u043f\u043e \u0432 \u0431\u0430\u0437\u0443 \u043a\u0443\u0434\u0430-\u043d\u0438\u0431\u0443\u0434\u044c?", "author": "Iskuskov", "createdAt": "2020-05-06T12:25:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgzNzMwMg==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420837302", "bodyText": "\u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 - \u0434\u0430, \u0435\u0441\u043b\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439 \u0442\u043e\u0436\u0435 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0432 \u0437\u0430\u043f\u0438\u0441\u0438 \u0438\u0445 \u0432 \u0431\u0430\u0437\u0443 - \u043f\u043e\u043b\u0443\u0447\u0438\u043c exactlyOnce", "author": "bokshitsky", "createdAt": "2020-05-06T14:30:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxMTExMA=="}], "type": "inlineReview", "revised_code": {"commit": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "chunk": "diff --git a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaConsumer.java b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaConsumer.java\nindex f8bcefdd..e9a8cc42 100644\n--- a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaConsumer.java\n+++ b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaConsumer.java\n\n@@ -18,9 +18,10 @@ public class KafkaConsumer<T> {\n   private final ThreadLocal<ConsumerRecord<String, T>> lastAckedBatchRecord = new InheritableThreadLocal<>();\n   private final ConsumeStrategy<T> consumeStrategy;\n \n-  public KafkaConsumer(AbstractMessageListenerContainer<String, T> springKafkaContainer, ConsumeStrategy<T> consumeStrategy) {\n-    this.springKafkaContainer = springKafkaContainer;\n+  public KafkaConsumer(ConsumeStrategy<T> consumeStrategy,\n+                       Function<KafkaConsumer<T>, AbstractMessageListenerContainer<String, T>> springContainerProvider) {\n     this.consumeStrategy = consumeStrategy;\n+    this.springKafkaContainer = springContainerProvider.apply(this);\n   }\n \n   void start() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNDExNw==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418614117", "bodyText": "\u041f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u044d\u0442\u043e\u0439 \u0448\u0442\u0443\u043a\u0438 \u0431\u044b\u043b\u0430 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u0434\u0430\u0436\u0435 \u0441\u0434\u0435\u043b\u0430\u0432 \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u044b\u0439 Ack (\u0437\u0430\u043f\u0438\u0441\u0430\u0432 \u043e\u0444\u0444\u0441\u0435\u0442\u044b \u0432 \u043a\u0430\u0444\u043a\u0443) - \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0443\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043f\u0440\u0438 \u043b\u044e\u0431\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u0435 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u043b\u0438\u0441\u044c \u0432 \u043d\u0430\u0447\u0430\u043b\u043e \u0431\u0430\u0442\u0447\u0430 (seek \u0432\u043d\u0443\u0442\u0440\u0438 SeekToCurrentBatchErrorHandler), \u0438 \u043e\u043d\u0438 \u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u043b\u0438\u0441\u044c \u0441\u043d\u043e\u0432\u0430 (\u0441\u043b\u043e\u043c\u0430\u043d\u043d\u044b\u0439 at-most-once)\n\u0412 \u044d\u0442\u043e\u0439 \u0432\u0435\u0442\u043a\u0435 \u043c\u044b 1) \u0437\u0430\u043c\u0435\u043d\u044f\u0435\u043c \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e errorHandler - \u0434\u0435\u043b\u0430\u0435\u043c seek \u043d\u0435 \u0432 \u043d\u0430\u0447\u0430\u043b\u043e \u0431\u0430\u0442\u0447\u0430, \u0430 \u043a \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044e \u0438\u0434\u0443\u0449\u0435\u043c\u0443 \u0441\u0440\u0430\u0437\u0443 \u0437\u0430 \u0442\u0435\u043c, \u0447\u0442\u043e \u043c\u044b \u0430\u043a\u043d\u0443\u043b\u0438) 2) \u0434\u0435\u043b\u0430\u0435\u043c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0430\u043a\u043d\u0443\u0442\u044c \u043d\u0435 \u0432\u0435\u0441\u044c \u0431\u0430\u0442\u0447\u0430, \u0430 \u043a\u0430\u043a\u043e\u0435-\u0442\u043e \u043a\u043e\u043d\u043a\u0440\u0435\u043d\u043e\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 + \u0434\u0435\u043b\u0430\u0435\u043c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u044d\u0442\u043e \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e - \u0447\u0442\u043e \u043f\u043e\u043c\u043e\u0436\u0435\u0442 \u0441\u043d\u0438\u0437\u0438\u0442\u044c \u0434\u0443\u0431\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043f\u0440\u0438 at-least-once \u0441\u0435\u043c\u0430\u043d\u0442\u0438\u043a\u0435", "author": "bokshitsky", "createdAt": "2020-05-01T16:16:30Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java", "diffHunk": "@@ -38,68 +38,52 @@ public DefaultConsumerFactory(ConfigProvider configProvider,\n     this.statsDSender = statsDSender;\n   }\n \n-  public <T> KafkaConsumer subscribe(String topicName,\n-                                     String operationName,\n-                                     Class<T> messageClass,\n-                                     ConsumeStrategy<T> messageConsumer) {\n-\n+  public <T> KafkaConsumer<T> subscribe(String topicName,\n+                                        String operationName,\n+                                        Class<T> messageClass,\n+                                        ConsumeStrategy<T> consumeStrategy) {\n     ConsumerFactory<String, T> consumerFactory = getSpringConsumerFactory(topicName, messageClass);\n-\n     ConsumerGroupId consumerGroupId = new ConsumerGroupId(configProvider.getServiceName(), topicName, operationName);\n+\n+    ConsumeStrategyInternal<T> consumeStrategyInternal = new ConsumeStrategyInternal<>();\n+\n     ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n         consumerGroupId,\n-        adaptToSpring(monitor(consumerGroupId, messageConsumer))\n+        (BatchConsumerAwareMessageListener<String, T>) consumeStrategyInternal::invokeOnConsumer,\n+        topicName\n     );\n \n-    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, topicName);\n-    container.start();\n+    SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName);\n+    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);\n \n-    return new KafkaConsumer() {\n-      @Override\n-      public void stopConsumer() {\n-        container.stop();\n-      }\n+    KafkaConsumer<T> kafkaConsumer = new KafkaConsumer<>(container, monitor(consumerGroupId, consumeStrategy));\n+    consumeStrategyInternal.setKafkaConsumer(kafkaConsumer);\n+    errorHandler.setKafkaConsumer(kafkaConsumer);\n \n-      @Override\n-      public Collection<TopicPartition> getAssignedPartitions() {\n-        return container.getAssignedPartitions();\n-      }\n-    };\n+    kafkaConsumer.start();\n+    return kafkaConsumer;\n   }\n \n   private <T> ConsumeStrategy<T> monitor(ConsumerGroupId consumerGroupId, ConsumeStrategy<T> consumeStrategy) {\n     return new MonitoringConsumeStrategy<>(statsDSender, consumerGroupId, consumeStrategy);\n   }\n \n-  private <T> BatchAcknowledgingMessageListener<String, T> adaptToSpring(ConsumeStrategy<T> consumeStrategy) {\n-    return (data, acknowledgment) -> consumeStrategy.onMessagesBatch(data, new Ack() {\n-      @Override\n-      public void acknowledge() {\n-        acknowledgment.acknowledge();\n-      }\n-\n-      @Override\n-      public void nack(int index, long sleep) {\n-        acknowledgment.nack(index, sleep);\n-      }\n-    });\n-  }\n-\n   private <T> ConcurrentMessageListenerContainer<String, T> getSpringMessageListenerContainer(ConsumerFactory<String, T> consumerFactory,\n                                                                                               ContainerProperties containerProperties,\n-                                                                                              String topicName) {\n+                                                                                              BatchErrorHandler errorHandler) {\n     var container = new ConcurrentMessageListenerContainer<>(consumerFactory, containerProperties);\n-    SeekToCurrentBatchErrorHandler errorHandler = new SeekToCurrentBatchErrorHandler();", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc5NzY5Nw==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420797697", "bodyText": "\u0422\u0430\u043a \u043f\u043e\u043d\u0438\u043c\u0430\u044e, \u0447\u0442\u043e \u0442\u0430\u043a \u0441\u0434\u0435\u043b\u0430\u043d\u043e \u043d\u0435\u0441\u043f\u0440\u043e\u0441\u0442\u0430 (\u0442\u043e\u0447\u043d\u0435\u0435 \u043d\u0435 \u0441\u0434\u0435\u043b\u0430\u043d\u043e), \u0432 \u0434\u043e\u043a\u0430\u0445 \u0442\u0430\u043a\u043e\u0435:\n\nthe SeekToCurrentBatchErrorHandler has no mechanism to recover after a certain number of failures. One reason for this is there is no guarantee that, when a batch is redelivered, the batch has the same number of records and/or the redelivered records are in the same order. It is impossible, therefore, to maintain retry state for a batch.", "author": "Iskuskov", "createdAt": "2020-05-06T13:39:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNDExNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgzMjM2NQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420832365", "bodyText": "\u0412\u0420\u043e\u0434\u0435 \u043a\u043e\u043c\u043c\u0435\u043d\u0442 \u0443 \u043d\u0438\u0445 \u0447\u0443\u0442\u043a\u0430 \u043f\u0440\u043e \u0434\u0440\u0443\u0433\u043e\u0435 - \u043f\u0440\u043e \u0442\u043e, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043a\u043e\u043b-\u0432\u043e \u0444\u0435\u0439\u043b\u043e\u0432 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435", "author": "bokshitsky", "createdAt": "2020-05-06T14:23:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNDExNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgzOTM3OQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420839379", "bodyText": "\u044d\u0442\u043e \u0434\u0430, \u044f \u0441\u043a\u043e\u0440\u0435\u0435 \u043f\u0440\u043e \u0441\u0430\u043c\u0443 \u043c\u0435\u0445\u0430\u043d\u0438\u043a\u0443", "author": "Iskuskov", "createdAt": "2020-05-06T14:32:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNDExNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg3MjUwNg==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420872506", "bodyText": "\u041d\u0443 \u0441\u0443\u0434\u044f \u043f\u043e \u0442\u0435\u0441\u0442\u0430\u043c - \u043c\u0435\u0445\u0430\u043d\u0438\u043a\u0430 \u0443 \u043d\u0430\u0441 \u0432\u0440\u043e\u0434\u0435 \u0440\u0430\u0431\u043e\u0447\u0430\u044f", "author": "bokshitsky", "createdAt": "2020-05-06T15:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNDExNw=="}], "type": "inlineReview", "revised_code": {"commit": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "chunk": "diff --git a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\nindex aa58f4bd..ec124031 100644\n--- a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\n+++ b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\n\n@@ -45,20 +47,17 @@ public class DefaultConsumerFactory implements KafkaConsumerFactory {\n     ConsumerFactory<String, T> consumerFactory = getSpringConsumerFactory(topicName, messageClass);\n     ConsumerGroupId consumerGroupId = new ConsumerGroupId(configProvider.getServiceName(), topicName, operationName);\n \n-    ConsumeStrategyInternal<T> consumeStrategyInternal = new ConsumeStrategyInternal<>();\n+    Function<KafkaConsumer<T>, AbstractMessageListenerContainer<String, T>> springContainerProvider = (kafkaConsumer) -> {\n+      ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n+          consumerGroupId,\n+          (BatchConsumerAwareMessageListener<String, T>) kafkaConsumer::onMessagesBatch,\n+          topicName\n+      );\n+      SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName, kafkaConsumer);\n+      return getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);\n+    };\n \n-    ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n-        consumerGroupId,\n-        (BatchConsumerAwareMessageListener<String, T>) consumeStrategyInternal::invokeOnConsumer,\n-        topicName\n-    );\n-\n-    SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName);\n-    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);\n-\n-    KafkaConsumer<T> kafkaConsumer = new KafkaConsumer<>(container, monitor(consumerGroupId, consumeStrategy));\n-    consumeStrategyInternal.setKafkaConsumer(kafkaConsumer);\n-    errorHandler.setKafkaConsumer(kafkaConsumer);\n+    KafkaConsumer<T> kafkaConsumer = new KafkaConsumer<>(monitor(consumerGroupId, consumeStrategy), springContainerProvider);\n \n     kafkaConsumer.start();\n     return kafkaConsumer;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNTYyOA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418615628", "bodyText": "\u043d\u0430\u0437\u0432\u0430\u043b seek \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0435 \u0441 \u0442\u0435\u043c, \u0447\u0442\u043e \u0434\u0435\u043b\u0430\u0435\u043c \u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0439 consumer\n\u043f\u043e \u0444\u0430\u043a\u0442\u0443 \u044d\u0442\u0430 \u0448\u0442\u0443\u043a\u0430 \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u0433\u043e\u0434\u0438\u0442\u044c\u0441\u044f, \u043a\u043e\u0433\u0434\u0430 \u0445\u043e\u0442\u0438\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c atLeastOnce:\nhandle batch{\n  batch.forEach(m->{\n    process(m)\n   *ack.seek(m)*\n})\nack.acknowledge()\n}\n\n\u0422.\u0435. \u0433\u043b\u043e\u0431\u0430\u043b\u044c\u043d\u044b\u0439 ack \u0432 \u043a\u0430\u0444\u043a\u0443 \u043c\u044b \u043d\u0435 \u0434\u0435\u043b\u0430\u0435\u043c, \u043d\u043e \u0441\u0434\u0432\u0438\u0433\u0430\u0435\u043c \u0443\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u044c \u0432 \u043f\u0430\u043c\u044f\u0442\u0438 \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u043a\u043e\u043d\u0441\u0443\u043c\u0435\u0440\u0430 - \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0443\u0431\u043b\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0435\u0441\u043b\u0438 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u0441\u043e\u0432\u0441\u0435\u043c \u0441\u043b\u043e\u043c\u0430\u043d\u043d\u043e\u0435 \u0438 \u043d\u0435 \u0447\u0438\u043d\u0438\u0442\u0441\u044f (\u0430 \u043d\u0435 \u043b\u043e\u0432\u0438\u0442 \u0442\u0430\u0439\u043c\u0430\u0443\u0442 \u0433\u0434\u0435-\u043d\u0438\u0431\u0443\u0434\u044c)", "author": "bokshitsky", "createdAt": "2020-05-01T16:20:10Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/Ack.java", "diffHunk": "@@ -1,26 +1,13 @@\n package ru.hh.nab.kafka.consumer;\n \n-public interface Ack {\n-  /**\n-   * Invoked when the record or batch for which the acknowledgment has been created has\n-   * been processed. Calling this method implies that all the previous messages in the\n-   * partition have been processed already.\n-   */\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+\n+public interface Ack<T> {\n+\n   void acknowledge();\n \n-  /**\n-   * Negatively acknowledge the record at an index in a batch - commit the offset(s) of\n-   * records before the index and re-seek the partitions so that the record at the index\n-   * and subsequent records will be redelivered after the sleep time. Must be called on\n-   * the consumer thread.\n-   * <p>\n-   * <b>When using group management,\n-   * {@code sleep + time spent processing the records before the index} must be less\n-   * than the consumer {@code max.poll.interval.ms} property, to avoid a rebalance.</b>\n-   *\n-   * @param index the index of the failed record in the batch.\n-   * @param sleepMs the time to sleep.\n-   * @since 2.3\n-   */\n-  void nack(int index, long sleepMs);\n+  void acknowledge(ConsumerRecord<String, T> lastProcessedRecord);\n+\n+  void seek(ConsumerRecord<String, T> lastProcessedRecord);", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc1NDIzMg==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420754232", "bodyText": "\u043d\u0430 \u0441\u0430\u043c\u043e\u043c \u0434\u0435\u043b\u0435 \u043e\u043d\u043e \u043d\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u043b\u043e \u0434\u0430\u0436\u0435 \u043a\u043e\u0433\u0434\u0430 \u043f\u044b\u0442\u0430\u043b\u0438\u0441\u044c \u0441\u0434\u0435\u043b\u0430\u0442\u044c atMostOnce \u0432 \u0432\u0438\u0434\u0435\nhandle batch{\n  ack.acknowledge()\n  batch.forEach(m->{\n    process(m)\n})\n}", "author": "Iskuskov", "createdAt": "2020-05-06T12:34:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNTYyOA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNzQzNQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418617435", "bodyText": "\u041d\u0435\u0441\u043c\u043e\u0442\u0440\u044f \u043d\u0430 \u0442\u0430\u0439\u043c\u0430\u0443\u0442\u044b \u0432\u044b\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u0432 \u0442\u0435\u0441\u0442\u0430\u0445, \u0442\u0435\u0441\u0442\u044b \u0432 \u0446\u0435\u043b\u043e\u043c \u0431\u0435\u0433\u0443\u0442 \u0431\u044b\u0441\u0442\u0440\u043e", "author": "bokshitsky", "createdAt": "2020-05-01T16:24:29Z", "path": "nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java", "diffHunk": "@@ -0,0 +1,232 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.ArrayList;\n+import static java.util.Collections.synchronizedList;\n+import static java.util.Collections.synchronizedSet;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+import java.util.stream.Stream;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import static org.awaitility.Awaitility.await;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotEquals;\n+import static org.junit.Assert.assertTrue;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.test.context.ContextConfiguration;\n+import ru.hh.nab.kafka.KafkaTestConfig;\n+\n+@ContextConfiguration(classes = {KafkaTestConfig.class})\n+public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bd6f278ea713c8bea10a2d496e13504fd1200720", "chunk": "diff --git a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\nindex 5c977ba5..36ac6424 100644\n--- a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n+++ b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n\n@@ -59,7 +59,7 @@ public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {\n     AtomicBoolean failed = new AtomicBoolean(false);\n     startConsumer((messages, ack) -> messages.forEach(m -> {\n       processedMessages.add(m.value());\n-      if (processedMessages.size() == 40){\n+      if (processedMessages.size() == 40) {\n         ack.seek(m);\n       }\n       if (!failed.get() && processedMessages.size() == 45) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxOTc1NA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r418619754", "bodyText": "\u0415\u0441\u043b\u0438 \u0442\u0435\u0441\u0442\u0438\u0442\u044c \u043d\u0430 1-\u0439 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 - \u043c\u043e\u0436\u043d\u043e \u043d\u0435 \u043f\u043e\u0439\u043c\u0430\u0442\u044c \u043a\u0430\u043a\u0438\u0445-\u0442\u043e \u043f\u0440\u043e\u0431\u043b\u0435\u043c", "author": "bokshitsky", "createdAt": "2020-05-01T16:29:35Z", "path": "nab-tests/src/test/java/ru/hh/nab/kafka/KafkaTestConfig.java", "diffHunk": "@@ -25,7 +26,7 @@\n \n   @Bean\n   public TestKafkaWithJsonMessages testKafka() {\n-    return KafkaTestUtils.startKafkaWithJsonMessages(new ObjectMapper());\n+    return KafkaTestUtils.startKafkaWithJsonMessages(new ObjectMapper(), Map.of(\"num.partitions\", \"5\"));", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcyMTExNQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420721115", "bodyText": "\u041c\u043d\u0435 \u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043c\u043e\u0436\u043d\u043e \u0442\u0443\u0442 \u043f\u0435\u0440\u0435\u043f\u0438\u0441\u0430\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u043d\u0443\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0434\u0435\u043b\u0430\u0442\u044c \u043f\u043e\u0442\u043e\u043c setKafkaConsumer, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0432\u043d\u0435\u0441\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 containerProperties \u0432\u043d\u0443\u0442\u0440\u044c \u0442\u0432\u043e\u0435\u0433\u043e KafkaConsumer. \u0417\u0430\u043e\u0434\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u0447\u0438\u0442\u0430\u0435\u043c\u0435\u0439 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043a\u043e\u043d\u0441\u044c\u044e\u043c\u0435\u0440\u0430", "author": "Aulust", "createdAt": "2020-05-06T11:32:54Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java", "diffHunk": "@@ -38,68 +38,52 @@ public DefaultConsumerFactory(ConfigProvider configProvider,\n     this.statsDSender = statsDSender;\n   }\n \n-  public <T> KafkaConsumer subscribe(String topicName,\n-                                     String operationName,\n-                                     Class<T> messageClass,\n-                                     ConsumeStrategy<T> messageConsumer) {\n-\n+  public <T> KafkaConsumer<T> subscribe(String topicName,\n+                                        String operationName,\n+                                        Class<T> messageClass,\n+                                        ConsumeStrategy<T> consumeStrategy) {\n     ConsumerFactory<String, T> consumerFactory = getSpringConsumerFactory(topicName, messageClass);\n-\n     ConsumerGroupId consumerGroupId = new ConsumerGroupId(configProvider.getServiceName(), topicName, operationName);\n+\n+    ConsumeStrategyInternal<T> consumeStrategyInternal = new ConsumeStrategyInternal<>();\n+\n     ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n         consumerGroupId,\n-        adaptToSpring(monitor(consumerGroupId, messageConsumer))\n+        (BatchConsumerAwareMessageListener<String, T>) consumeStrategyInternal::invokeOnConsumer,\n+        topicName\n     );\n \n-    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, topicName);\n-    container.start();\n+    SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName);\n+    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "chunk": "diff --git a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\nindex aa58f4bd..ec124031 100644\n--- a/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\n+++ b/nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/DefaultConsumerFactory.java\n\n@@ -45,20 +47,17 @@ public class DefaultConsumerFactory implements KafkaConsumerFactory {\n     ConsumerFactory<String, T> consumerFactory = getSpringConsumerFactory(topicName, messageClass);\n     ConsumerGroupId consumerGroupId = new ConsumerGroupId(configProvider.getServiceName(), topicName, operationName);\n \n-    ConsumeStrategyInternal<T> consumeStrategyInternal = new ConsumeStrategyInternal<>();\n+    Function<KafkaConsumer<T>, AbstractMessageListenerContainer<String, T>> springContainerProvider = (kafkaConsumer) -> {\n+      ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n+          consumerGroupId,\n+          (BatchConsumerAwareMessageListener<String, T>) kafkaConsumer::onMessagesBatch,\n+          topicName\n+      );\n+      SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName, kafkaConsumer);\n+      return getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);\n+    };\n \n-    ContainerProperties containerProperties = getSpringConsumerContainerProperties(\n-        consumerGroupId,\n-        (BatchConsumerAwareMessageListener<String, T>) consumeStrategyInternal::invokeOnConsumer,\n-        topicName\n-    );\n-\n-    SeekToFirstNotAckedMessageErrorHandler<T> errorHandler = getBatchErrorHandler(topicName);\n-    var container = getSpringMessageListenerContainer(consumerFactory, containerProperties, errorHandler);\n-\n-    KafkaConsumer<T> kafkaConsumer = new KafkaConsumer<>(container, monitor(consumerGroupId, consumeStrategy));\n-    consumeStrategyInternal.setKafkaConsumer(kafkaConsumer);\n-    errorHandler.setKafkaConsumer(kafkaConsumer);\n+    KafkaConsumer<T> kafkaConsumer = new KafkaConsumer<>(monitor(consumerGroupId, consumeStrategy), springContainerProvider);\n \n     kafkaConsumer.start();\n     return kafkaConsumer;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcwNDQyNQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420704425", "bodyText": "\u043d\u0435 \u0445\u043e\u0447\u0435\u0448\u044c TestBase?", "author": "Iskuskov", "createdAt": "2020-05-06T10:58:00Z", "path": "nab-tests/src/test/java/ru/hh/nab/kafka/consumer/KafkaConsumerTestbase.java", "diffHunk": "@@ -0,0 +1,40 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.UUID;\n+import java.util.concurrent.TimeUnit;\n+import javax.inject.Inject;\n+import static org.awaitility.Awaitility.await;\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Before;\n+import org.springframework.test.context.junit4.AbstractJUnit4SpringContextTests;\n+import ru.hh.kafka.test.TestKafkaWithJsonMessages;\n+\n+public abstract class KafkaConsumerTestbase extends AbstractJUnit4SpringContextTests {", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcwODg1MA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420708850", "bodyText": "\u043f\u043e \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f\u043c \u0442\u0435\u0441\u0442\u043e\u0432 - \u043e\u0431\u044b\u0447\u043d\u043e \u0432\u0440\u043e\u0434\u0435 \u0432 should-\u043d\u043e\u0442\u0430\u0446\u0438\u0438 (\u0440\u044f\u0434\u043e\u043c \u0432 KafkaConsumerFactoryTest \u0442\u043e\u0436\u0435 \u0442\u0430\u043a)", "author": "Iskuskov", "createdAt": "2020-05-06T11:06:57Z", "path": "nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java", "diffHunk": "@@ -0,0 +1,232 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.ArrayList;\n+import static java.util.Collections.synchronizedList;\n+import static java.util.Collections.synchronizedSet;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+import java.util.stream.Stream;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import static org.awaitility.Awaitility.await;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotEquals;\n+import static org.junit.Assert.assertTrue;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.test.context.ContextConfiguration;\n+import ru.hh.nab.kafka.KafkaTestConfig;\n+\n+@ContextConfiguration(classes = {KafkaTestConfig.class})\n+public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {\n+\n+  private static AtomicInteger ID_SEQUENCE = new AtomicInteger(0);\n+  private List<String> processedMessages;\n+  private KafkaConsumer<String> consumer;\n+\n+  @Before\n+  public void setUp() {\n+    processedMessages = synchronizedList(new ArrayList<>());\n+  }\n+\n+  @Test\n+  public void testNoGlobalAckPerformed() throws InterruptedException {", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgwMTU0NQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420801545", "bodyText": "\u0441\u043c\u043e\u0442\u0440\u0438 \u0441\u0430\u043c, \u043a\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0435", "author": "Iskuskov", "createdAt": "2020-05-06T13:44:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcwODg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg3MzIzNg==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420873236", "bodyText": "\u041d\u0443 \u0442\u0443\u0442  \u0441\u043b\u043e\u0436\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e should-\u043d\u043e\u0442\u0430\u0446\u0438\u044e \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c - \u0442\u0435\u0441\u0442\u0438\u043c \"\u0442\u0438\u043f\u0430 \u0441\u0435\u043c\u0430\u043d\u0442\u0438\u043a\u0443\"", "author": "bokshitsky", "createdAt": "2020-05-06T15:15:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcwODg1MA=="}], "type": "inlineReview", "revised_code": {"commit": "bd6f278ea713c8bea10a2d496e13504fd1200720", "chunk": "diff --git a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\nindex 5c977ba5..36ac6424 100644\n--- a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n+++ b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n\n@@ -59,7 +59,7 @@ public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {\n     AtomicBoolean failed = new AtomicBoolean(false);\n     startConsumer((messages, ack) -> messages.forEach(m -> {\n       processedMessages.add(m.value());\n-      if (processedMessages.size() == 40){\n+      if (processedMessages.size() == 40) {\n         ack.seek(m);\n       }\n       if (!failed.get() && processedMessages.size() == 45) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDcwOTQxNQ==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420709415", "bodyText": ") {", "author": "Iskuskov", "createdAt": "2020-05-06T11:08:11Z", "path": "nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java", "diffHunk": "@@ -0,0 +1,232 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.ArrayList;\n+import static java.util.Collections.synchronizedList;\n+import static java.util.Collections.synchronizedSet;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import static java.util.stream.Collectors.groupingBy;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+import java.util.stream.Stream;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import static org.awaitility.Awaitility.await;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotEquals;\n+import static org.junit.Assert.assertTrue;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.test.context.ContextConfiguration;\n+import ru.hh.nab.kafka.KafkaTestConfig;\n+\n+@ContextConfiguration(classes = {KafkaTestConfig.class})\n+public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {\n+\n+  private static AtomicInteger ID_SEQUENCE = new AtomicInteger(0);\n+  private List<String> processedMessages;\n+  private KafkaConsumer<String> consumer;\n+\n+  @Before\n+  public void setUp() {\n+    processedMessages = synchronizedList(new ArrayList<>());\n+  }\n+\n+  @Test\n+  public void testNoGlobalAckPerformed() throws InterruptedException {\n+    putMessagesIntoKafka(117);\n+\n+    startConsumer((messages, ack) -> messages.forEach(m -> processedMessages.add(m.value())));\n+    assertProcessedMessagesCount(117);\n+\n+    consumeAllRemainingMessages();\n+    assertProcessedMessagesCount(234);\n+    assertUniqueProcessedMessagesCount(117);\n+  }\n+\n+  @Test\n+  public void testSeek() throws InterruptedException {\n+    putMessagesIntoKafka(117);\n+    AtomicBoolean failed = new AtomicBoolean(false);\n+    startConsumer((messages, ack) -> messages.forEach(m -> {\n+      processedMessages.add(m.value());\n+      if (processedMessages.size() == 40){", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bd6f278ea713c8bea10a2d496e13504fd1200720", "chunk": "diff --git a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\nindex 5c977ba5..36ac6424 100644\n--- a/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n+++ b/nab-tests/src/test/java/ru/hh/nab/kafka/consumer/ConsumerRecoveryAfterFailTest.java\n\n@@ -59,7 +59,7 @@ public class ConsumerRecoveryAfterFailTest extends KafkaConsumerTestbase {\n     AtomicBoolean failed = new AtomicBoolean(false);\n     startConsumer((messages, ack) -> messages.forEach(m -> {\n       processedMessages.add(m.value());\n-      if (processedMessages.size() == 40){\n+      if (processedMessages.size() == 40) {\n         ack.seek(m);\n       }\n       if (!failed.get() && processedMessages.size() == 45) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc0NjY4Mw==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420746683", "bodyText": "\u0432\u0440\u043e\u0434\u0435 \u0431\u044b \u043d\u0435\u0442 \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0439, \u0447\u0442\u043e \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0435 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u043d\u0430 \u0435\u0434\u0438\u043d\u0438\u0446\u0443 \u0431\u043e\u043b\u044c\u0448\u0435", "author": "Iskuskov", "createdAt": "2020-05-06T12:21:20Z", "path": "nab-kafka/src/main/java/ru/hh/nab/kafka/consumer/KafkaInternalTopicAck.java", "diffHunk": "@@ -0,0 +1,59 @@\n+package ru.hh.nab.kafka.consumer;\n+\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+\n+public class KafkaInternalTopicAck<T> implements Ack<T> {\n+\n+  private final KafkaConsumer<T> kafkaConsumer;\n+  private final Consumer<?, ?> consumer;\n+  private Integer lastCommittedIndex = null;\n+\n+  public KafkaInternalTopicAck(KafkaConsumer<T> kafkaConsumer,\n+                               Consumer<?, ?> consumer) {\n+    this.kafkaConsumer = kafkaConsumer;\n+    this.consumer = consumer;\n+  }\n+\n+  @Override\n+  public void acknowledge() {\n+    List<ConsumerRecord<String, T>> currentBatch = kafkaConsumer.getCurrentBatch();\n+    if (!currentBatch.isEmpty()) {\n+      ConsumerRecord<String, T> lastRecord = currentBatch.get(currentBatch.size() - 1);\n+      acknowledge(lastRecord);\n+    }\n+  }\n+\n+  @Override\n+  public void acknowledge(ConsumerRecord<String, T> processedMessage) {\n+    List<ConsumerRecord<String, T>> currentBatch = kafkaConsumer.getCurrentBatch();\n+    if (lastCommittedIndex != null && lastCommittedIndex >= currentBatch.size()) {\n+      return;\n+    }\n+\n+    Integer startIndex = Optional.ofNullable(lastCommittedIndex).map(lci -> lci + 1).orElse(0);\n+    LinkedHashMap<TopicPartition, OffsetAndMetadata> offsetsToCommit = Stream.concat(\n+        currentBatch.subList(startIndex, currentBatch.size()).stream().takeWhile(message -> message != processedMessage),\n+        Stream.of(processedMessage)\n+    ).collect(Collectors.toMap(\n+        message -> new TopicPartition(message.topic(), message.partition()),\n+        message -> new OffsetAndMetadata(message.offset() + 1),", "originalCommit": "39517a063d745afe0e33c80b6883fe649b367fba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgzMzgwNw==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420833807", "bodyText": "\u042d\u0442\u043e \u0437\u043d\u0430\u0447\u0438\u0442 \"\u0432 \u0441\u043b\u0435\u0434 \u0440\u0430\u0437 \u043d\u0430\u0447\u0438\u043d\u0430\u0442\u044c \u0437\u0430\u043f\u0440\u0430\u0448\u0438\u0432\u0430\u0442 \u043d\u0430 \u0435\u0434\u0438\u043d\u0438\u0446\u0443 \u0431\u043e\u043b\u044c\u0448\u0435\" (\u0435\u0441\u043b\u0438 \u0442\u0430\u043c \u043d\u0435 \u0431\u0443\u0434\u0435\u0442 \u0437\u0430\u043f\u0438\u0441\u0438 - \u0437\u043d\u0430\u0447\u0438\u0442 \u0431\u0443\u0434\u0435\u0442 \u0431\u0440\u0430\u0442\u044c\u0441\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0430\u044f)\n\u0412 \u0441\u044b\u0440\u0446\u0430\u0445 springKafka \u043a\u0430\u043a \u0440\u0430\u0437 \u0442\u0430\u043a\u043e\u0435 \u0438 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442", "author": "bokshitsky", "createdAt": "2020-05-06T14:25:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc0NjY4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg2NTQyNA==", "url": "https://github.com/hhru/nuts-and-bolts/pull/240#discussion_r420865424", "bodyText": "\u0434\u0430, \u0432\u043e\u0442 \u043f\u0440\u043e \u044d\u0442\u043e \u0438 \u0432\u043e\u043f\u0440\u043e\u0441, \u0442\u043e\u0433\u0434\u0430 \u043e\u043a", "author": "Iskuskov", "createdAt": "2020-05-06T15:05:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDc0NjY4Mw=="}], "type": "inlineReview", "revised_code": null}, {"oid": "cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "url": "https://github.com/hhru/nuts-and-bolts/commit/cefc5c73bf9bdb8646bcb29658abbb88b4c151d5", "message": "HH-108440 do not use proxy class", "committedDate": "2020-05-06T14:22:09Z", "type": "commit"}, {"oid": "bd6f278ea713c8bea10a2d496e13504fd1200720", "url": "https://github.com/hhru/nuts-and-bolts/commit/bd6f278ea713c8bea10a2d496e13504fd1200720", "message": "HH-108440 fix", "committedDate": "2020-05-06T14:27:01Z", "type": "commit"}, {"oid": "bd6f278ea713c8bea10a2d496e13504fd1200720", "url": "https://github.com/hhru/nuts-and-bolts/commit/bd6f278ea713c8bea10a2d496e13504fd1200720", "message": "HH-108440 fix", "committedDate": "2020-05-06T14:27:01Z", "type": "forcePushed"}]}