{"pr_number": 12098, "pr_title": "[CDAP-16612] Make sure correct classpath is used when using ssh for s\u2026", "pr_createdAt": "2020-04-21T13:43:45Z", "pr_url": "https://github.com/cdapio/cdap/pull/12098", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMwODQ3NA==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412308474", "bodyText": "Should it be ISOLATED?", "author": "chtyim", "createdAt": "2020-04-21T16:31:33Z", "path": "cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/distributed/DistributedProgramRunner.java", "diffHunk": "@@ -194,6 +194,10 @@ public final ProgramController run(final Program program, ProgramOptions oldOpti\n                                                          cConf.get(Constants.AppFabric.TEMP_DIR)).getAbsoluteFile());\n     try {\n       final ProgramLaunchConfig launchConfig = new ProgramLaunchConfig();\n+      if (clusterMode == ClusterMode.ON_PREMISE) {", "originalCommit": "a6510f356059f7ac60f71815a5a25a3a682c02a1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2dd9de5c8e34cb98c1670a8a27bd14b5d4faf9e", "chunk": "diff --git a/cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/distributed/DistributedProgramRunner.java b/cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/distributed/DistributedProgramRunner.java\nindex 6565313604b..9b64c3f5c6b 100644\n--- a/cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/distributed/DistributedProgramRunner.java\n+++ b/cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/distributed/DistributedProgramRunner.java\n\n@@ -194,7 +194,7 @@ public abstract class DistributedProgramRunner implements ProgramRunner, Program\n                                                          cConf.get(Constants.AppFabric.TEMP_DIR)).getAbsoluteFile());\n     try {\n       final ProgramLaunchConfig launchConfig = new ProgramLaunchConfig();\n-      if (clusterMode == ClusterMode.ON_PREMISE) {\n+      if (clusterMode == ClusterMode.ISOLATED) {\n         // For isolated mode, the hadoop classes comes from the hadoop classpath in the target cluster directly\n         launchConfig.addExtraClasspath(Collections.singletonList(\"$HADOOP_CLASSPATH\"));\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMyMzY4OA==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412323688", "bodyText": "Why only for spark runner?", "author": "chtyim", "createdAt": "2020-04-21T16:52:11Z", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java", "diffHunk": "@@ -137,15 +140,24 @@ protected void setupLaunchConfig(ProgramLaunchConfig launchConfig, Program progr\n     ApplicationSpecification appSpec = program.getApplicationSpecification();\n     SparkSpecification spec = appSpec.getSpark().get(program.getName());\n \n-    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\",\n-                                                                   options.getUserArguments().asMap());\n+    Arguments userArguments = options.getUserArguments();\n+    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\", userArguments.asMap());\n     // Add runnable. Only one instance for the spark client\n     launchConfig.addRunnable(spec.getName(), new SparkTwillRunnable(spec.getName()), 1,\n                              clientArgs, spec.getClientResources(), 0);\n \n     Map<String, String> extraEnv = new HashMap<>();\n     extraEnv.put(Constants.SPARK_COMPAT_ENV, sparkCompat.getCompat());\n \n+    if (userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) &&", "originalCommit": "a6510f356059f7ac60f71815a5a25a3a682c02a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMyNDEzMA==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412324130", "bodyText": "Also, it shouldn't matter of the launch type.", "author": "chtyim", "createdAt": "2020-04-21T16:52:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMyMzY4OA=="}], "type": "inlineReview", "revised_code": {"commit": "e2dd9de5c8e34cb98c1670a8a27bd14b5d4faf9e", "chunk": "diff --git a/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java b/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\nindex 6f08c358fa4..0a24406bfa6 100644\n--- a/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\n+++ b/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\n\n@@ -149,10 +149,10 @@ public final class DistributedSparkProgramRunner extends DistributedProgramRunne\n     Map<String, String> extraEnv = new HashMap<>();\n     extraEnv.put(Constants.SPARK_COMPAT_ENV, sparkCompat.getCompat());\n \n-    if (userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) &&\n-      userArguments.getOption(SystemArguments.RUNTIME_MANAGER_TYPE).equals(\"ssh\")) {\n-      // For isolated mode, the hadoop classes comes from the hadoop classpath in the target cluster directly\n-      launchConfig.addExtraClasspath(Collections.singletonList(\"$HADOOP_CLASSPATH\"));\n+    if (!userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) ||\n+      (userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) &&\n+        !userArguments.getOption(SystemArguments.RUNTIME_MANAGER_TYPE).equals(\"ssh\"))) {\n+      launchConfig.addExtraClasspath(MapReduceContainerHelper.addMapReduceClassPath(hConf, new ArrayList<String>()));\n     }\n \n     // No need to rewrite YARN client\n"}}, {"oid": "e2dd9de5c8e34cb98c1670a8a27bd14b5d4faf9e", "url": "https://github.com/cdapio/cdap/commit/e2dd9de5c8e34cb98c1670a8a27bd14b5d4faf9e", "message": "[CDAP-16612] Make sure correct classpath is used when using ssh for streaming pipeline launch", "committedDate": "2020-04-21T17:30:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM2OTM4Mw==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412369383", "bodyText": "What is this for?", "author": "chtyim", "createdAt": "2020-04-21T17:54:37Z", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java", "diffHunk": "@@ -137,15 +140,24 @@ protected void setupLaunchConfig(ProgramLaunchConfig launchConfig, Program progr\n     ApplicationSpecification appSpec = program.getApplicationSpecification();\n     SparkSpecification spec = appSpec.getSpark().get(program.getName());\n \n-    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\",\n-                                                                   options.getUserArguments().asMap());\n+    Arguments userArguments = options.getUserArguments();\n+    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\", userArguments.asMap());\n     // Add runnable. Only one instance for the spark client\n     launchConfig.addRunnable(spec.getName(), new SparkTwillRunnable(spec.getName()), 1,\n                              clientArgs, spec.getClientResources(), 0);\n \n     Map<String, String> extraEnv = new HashMap<>();\n     extraEnv.put(Constants.SPARK_COMPAT_ENV, sparkCompat.getCompat());\n \n+    if (!userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) ||", "originalCommit": "e2dd9de5c8e34cb98c1670a8a27bd14b5d4faf9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjU0MDMzOQ==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412540339", "bodyText": "Had offline discussion about this condition. Made changes as per the discussion. Testing manually now.", "author": "CuriousVini", "createdAt": "2020-04-21T22:40:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM2OTM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjU3MzU1Mg==", "url": "https://github.com/cdapio/cdap/pull/12098#discussion_r412573552", "bodyText": "Had offline discussion about this condition. Made changes as per the discussion. Testing manually now.", "author": "CuriousVini", "createdAt": "2020-04-22T00:02:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjM2OTM4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "5152ac26d16cfa847dbeb2313695c06afed4a90d", "chunk": "diff --git a/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java b/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\nindex 0a24406bfa6..53cf303aa2f 100644\n--- a/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\n+++ b/cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/distributed/DistributedSparkProgramRunner.java\n\n@@ -140,26 +140,22 @@ public final class DistributedSparkProgramRunner extends DistributedProgramRunne\n     ApplicationSpecification appSpec = program.getApplicationSpecification();\n     SparkSpecification spec = appSpec.getSpark().get(program.getName());\n \n-    Arguments userArguments = options.getUserArguments();\n-    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\", userArguments.asMap());\n+    Map<String, String> clientArgs = RuntimeArguments.extractScope(\"task\", \"client\",\n+                                                                   options.getUserArguments().asMap());\n     // Add runnable. Only one instance for the spark client\n     launchConfig.addRunnable(spec.getName(), new SparkTwillRunnable(spec.getName()), 1,\n                              clientArgs, spec.getClientResources(), 0);\n \n     Map<String, String> extraEnv = new HashMap<>();\n     extraEnv.put(Constants.SPARK_COMPAT_ENV, sparkCompat.getCompat());\n-\n-    if (!userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) ||\n-      (userArguments.hasOption(SystemArguments.RUNTIME_MANAGER_TYPE) &&\n-        !userArguments.getOption(SystemArguments.RUNTIME_MANAGER_TYPE).equals(\"ssh\"))) {\n-      launchConfig.addExtraClasspath(MapReduceContainerHelper.addMapReduceClassPath(hConf, new ArrayList<String>()));\n-    }\n-\n-    // No need to rewrite YARN client\n-    cConf.setBoolean(Constants.AppFabric.SPARK_YARN_CLIENT_REWRITE, false);\n     extraEnv.put(SparkPackageUtils.SPARK_YARN_MODE, \"true\");\n     extraEnv.putAll(SparkPackageUtils.getSparkClientEnv());\n \n+    if (sparkCompat.getCompat().equals(SparkCompat.SPARK2_2_11.getCompat())) {\n+      // No need to rewrite YARN client\n+      cConf.setBoolean(Constants.AppFabric.SPARK_YARN_CLIENT_REWRITE, false);\n+    }\n+\n     // Add extra resources, classpath, dependencies, env and setup ClassAcceptor\n     Map<String, LocalizeResource> localizeResources = new HashMap<>();\n     SparkPackageUtils.prepareSparkResources(sparkCompat, locationFactory, tempDir, localizeResources, extraEnv);\n"}}, {"oid": "5152ac26d16cfa847dbeb2313695c06afed4a90d", "url": "https://github.com/cdapio/cdap/commit/5152ac26d16cfa847dbeb2313695c06afed4a90d", "message": "[CDAP-16612] Make sure correct classpath is used when using ssh for streaming pipeline launch", "committedDate": "2020-04-21T22:39:48Z", "type": "commit"}, {"oid": "5152ac26d16cfa847dbeb2313695c06afed4a90d", "url": "https://github.com/cdapio/cdap/commit/5152ac26d16cfa847dbeb2313695c06afed4a90d", "message": "[CDAP-16612] Make sure correct classpath is used when using ssh for streaming pipeline launch", "committedDate": "2020-04-21T22:39:48Z", "type": "forcePushed"}]}