{"pr_number": 458, "pr_title": "Tcp line", "pr_createdAt": "2020-06-29T08:49:57Z", "pr_url": "https://github.com/questdb/questdb/pull/458", "timeline": [{"oid": "3f72542c2df6654af3b68c3bc9f310cd2b782138", "url": "https://github.com/questdb/questdb/commit/3f72542c2df6654af3b68c3bc9f310cd2b782138", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-23T17:33:36Z", "type": "commit"}, {"oid": "f824420ba3a9712d6d37eb6277d662d87ad28d0c", "url": "https://github.com/questdb/questdb/commit/f824420ba3a9712d6d37eb6277d662d87ad28d0c", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-23T17:33:36Z", "type": "commit"}, {"oid": "a48a4c31046c76bc0e3384f313d5e16ec071fde6", "url": "https://github.com/questdb/questdb/commit/a48a4c31046c76bc0e3384f313d5e16ec071fde6", "message": "chore: Fix merge issue", "committedDate": "2020-06-23T17:37:54Z", "type": "commit"}, {"oid": "bb48d9e60f90e360ab7543ef5e513b0a97abc53e", "url": "https://github.com/questdb/questdb/commit/bb48d9e60f90e360ab7543ef5e513b0a97abc53e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-24T08:39:58Z", "type": "commit"}, {"oid": "bf44d5f1e145e964cc7bf9f70b56e43e67d757bd", "url": "https://github.com/questdb/questdb/commit/bf44d5f1e145e964cc7bf9f70b56e43e67d757bd", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-06-24T08:40:26Z", "type": "commit"}, {"oid": "3f264a5f0faa291edeb76f3623d2a7317e420bfb", "url": "https://github.com/questdb/questdb/commit/3f264a5f0faa291edeb76f3623d2a7317e420bfb", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-24T09:16:19Z", "type": "commit"}, {"oid": "e97387d6a7b7ce5bd2e231ff2dc2312a1636be1a", "url": "https://github.com/questdb/questdb/commit/e97387d6a7b7ce5bd2e231ff2dc2312a1636be1a", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T08:47:35Z", "type": "commit"}, {"oid": "9626c1cc6b11cb5bfc0fe0a4af2256795a85396a", "url": "https://github.com/questdb/questdb/commit/9626c1cc6b11cb5bfc0fe0a4af2256795a85396a", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T13:36:30Z", "type": "commit"}, {"oid": "c6a8590e6fc63044142628403448ae31775d2a92", "url": "https://github.com/questdb/questdb/commit/c6a8590e6fc63044142628403448ae31775d2a92", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-25T14:15:27Z", "type": "commit"}, {"oid": "373af9110f82847bd7ea4e633932f7d446773b2e", "url": "https://github.com/questdb/questdb/commit/373af9110f82847bd7ea4e633932f7d446773b2e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n switch to WorkerPool for writers", "committedDate": "2020-06-26T10:19:20Z", "type": "commit"}, {"oid": "a95d756694952f559d5a1719b54c61e6331aaf67", "url": "https://github.com/questdb/questdb/commit/a95d756694952f559d5a1719b54c61e6331aaf67", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n fix issue on disconnect when writers havn't been able to keep up", "committedDate": "2020-06-26T12:49:56Z", "type": "commit"}, {"oid": "425aa7ac6a326a156d60b2f25b75c176b8a5ddc9", "url": "https://github.com/questdb/questdb/commit/425aa7ac6a326a156d60b2f25b75c176b8a5ddc9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add configuration for worker pools", "committedDate": "2020-06-26T13:43:42Z", "type": "commit"}, {"oid": "2b6fdad53778923d934984c354aaf68b25b84e53", "url": "https://github.com/questdb/questdb/commit/2b6fdad53778923d934984c354aaf68b25b84e53", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-06-26T13:49:21Z", "type": "commit"}, {"oid": "8609aa8bb2cb7d75fa383a2b51c610d097327b77", "url": "https://github.com/questdb/questdb/commit/8609aa8bb2cb7d75fa383a2b51c610d097327b77", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add table stats", "committedDate": "2020-06-26T14:29:53Z", "type": "commit"}, {"oid": "09797e8111a678ee1b437967eb4a3fe28309af92", "url": "https://github.com/questdb/questdb/commit/09797e8111a678ee1b437967eb4a3fe28309af92", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n add load balancing", "committedDate": "2020-06-26T21:39:41Z", "type": "commit"}, {"oid": "bf033314f942ddd78cfd0790d76097c019c610e9", "url": "https://github.com/questdb/questdb/commit/bf033314f942ddd78cfd0790d76097c019c610e9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP\n fix test", "committedDate": "2020-06-27T07:32:26Z", "type": "commit"}, {"oid": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "url": "https://github.com/questdb/questdb/commit/216efe6f6ef6849c83782e9df3d3e498af89f17b", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-29T08:42:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyMzE5MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446923190", "bodyText": "could be\n(value.charAt(0) | 32) == 't'", "author": "bluestreak01", "createdAt": "2020-06-29T12:13:52Z", "path": "core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package io.questdb.cutlass.line;\n+\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.std.Numbers;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+\n+public class CairoLineProtoParserSupport {\n+    private final static Log LOG = LogFactory.getLog(CairoLineProtoParserSupport.class);\n+    public static final ObjList<ColumnWriter> writers = new ObjList<>();\n+\n+    static {\n+        writers.extendAndSet(ColumnType.LONG, CairoLineProtoParserSupport::putLong);\n+        writers.extendAndSet(ColumnType.BOOLEAN, CairoLineProtoParserSupport::putBoolean);\n+        writers.extendAndSet(ColumnType.STRING, CairoLineProtoParserSupport::putStr);\n+        writers.extendAndSet(ColumnType.SYMBOL, CairoLineProtoParserSupport::putSymbol);\n+        writers.extendAndSet(ColumnType.DOUBLE, CairoLineProtoParserSupport::putDouble);\n+    }\n+\n+    public interface ColumnWriter {\n+        void write(TableWriter.Row row, int columnIndex, CharSequence value) throws BadCastException;\n+    }\n+\n+    public static class BadCastException extends Exception {\n+        private static final BadCastException INSTANCE = new BadCastException();\n+    }\n+\n+    public static int getValueType(CharSequence token) {\n+        int len = token.length();\n+        switch (token.charAt(len - 1)) {\n+            case 'i':\n+                return ColumnType.LONG;\n+            case 'e':\n+                // tru(e)\n+                // fals(e)\n+            case 't':\n+            case 'T':\n+                // t\n+                // T\n+            case 'f':\n+            case 'F':\n+                // f\n+                // F\n+                return ColumnType.BOOLEAN;\n+            case '\"':\n+                if (len < 2 || token.charAt(0) != '\\\"') {\n+                    LOG.error().$(\"incorrectly quoted string: \").$(token).$();\n+                    return -1;\n+                }\n+                return ColumnType.STRING;\n+            default:\n+                return ColumnType.DOUBLE;\n+        }\n+    }\n+\n+    private static boolean isTrue(CharSequence value) {\n+        final char firstChar = value.charAt(0);\n+        return firstChar == 't' || firstChar == 'T';", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java b/core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java\nindex 6d19766ad..38c2548c9 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/CairoLineProtoParserSupport.java\n\n@@ -57,8 +57,7 @@ public class CairoLineProtoParserSupport {\n     }\n \n     private static boolean isTrue(CharSequence value) {\n-        final char firstChar = value.charAt(0);\n-        return firstChar == 't' || firstChar == 'T';\n+        return (value.charAt(0) | 32) == 't';\n     }\n \n     public static void putSymbol(TableWriter.Row row, int index, CharSequence value) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyNDUwMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446924500", "bodyText": "this is controversial. So here we have data from socket, but no internal queue items to handle the input. We are failing in essence. I think we need to stay in the loop or have a way to return to the job without being triggered by the IO", "author": "bluestreak01", "createdAt": "2020-06-29T12:16:10Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\nindex 66986b580..05bbc3638 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n\n@@ -36,8 +36,7 @@ class LineTcpConnectionContext implements IOContext, Mutable {\n             LineTcpMeasurementEvent event = scheduler.getNewEvent();\n             if (null == event) {\n                 // Waiting for writer threads to drain queue, request callback as soon as possible\n-                dispatcher.registerChannel(this, IOOperation.READ);\n-                dispatcher.registerChannel(this, IOOperation.WRITE);\n+                LOG.info().$('[').$(fd).$(\"] queue full, could not start reading new records, consider increasing queue size or number of writer jobs\").$();\n                 return true;\n             }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyNjI3MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446926270", "bodyText": "same here, we do not have enough throughput. Cannot rely on IO to help us restart,", "author": "bluestreak01", "createdAt": "2020-06-29T12:19:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);\n+                return true;\n+            }\n+\n+            // Read as much data as possible\n+            int len = (int) (recvBufEnd - recvBufPos);\n+            if (len > 0 && !peerDisconnected) {\n+                int nRead = nf.recv(fd, recvBufPos, len);\n+                if (nRead < 0) {\n+                    if (recvBufPos != recvBufStart) {\n+                        LOG.info().$('[').$(fd).$(\"] disconnected with partial measurement, \").$(recvBufPos - recvBufStart).$(\" unprocessed bytes\").$();\n+                    }\n+                    peerDisconnected = true;\n+                } else {\n+                    recvBufPos += nRead;\n+                }\n+            }\n+\n+            // Process as much data as possible\n+            long recvBufLineStart = recvBufStart;\n+            do {\n+                long recvBufLineNext = event.parseLine(recvBufLineStart, recvBufPos);\n+                if (recvBufLineNext == -1) {\n+                    break;\n+                }\n+                if (!event.isError()) {\n+                    scheduler.commitNewEvent(event);\n+                    event = scheduler.getNewEvent();\n+                } else {\n+                    LOG.error().$('[').$(fd).$(\"] failed to parse measurement, code \").$(event.getErrorCode()).$(\" at \").$(event.getErrorPosition()).$(\" in \")\n+                            .$(byteCharSequence.of(recvBufLineStart, recvBufLineNext - 1)).$();\n+                }\n+                recvBufLineStart = recvBufLineNext;\n+            } while (recvBufLineStart != recvBufPos && null != event);\n+\n+            // Compact input buffer\n+            if (recvBufLineStart != recvBufStart) {\n+                len = (int) (recvBufPos - recvBufLineStart);\n+                if (len > 0) {\n+                    Unsafe.getUnsafe().copyMemory(recvBufLineStart, recvBufStart, len);\n+                }\n+                recvBufPos = recvBufStart + len;\n+            }\n+\n+            // Check if we are waiting for writer threads\n+            if (null == event) {\n+                // Waiting for writer threads to drain queue, request callback as soon as possible\n+                dispatcher.registerChannel(this, IOOperation.READ);\n+                dispatcher.registerChannel(this, IOOperation.WRITE);", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\nindex 66986b580..05bbc3638 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n\n@@ -36,8 +36,7 @@ class LineTcpConnectionContext implements IOContext, Mutable {\n             LineTcpMeasurementEvent event = scheduler.getNewEvent();\n             if (null == event) {\n                 // Waiting for writer threads to drain queue, request callback as soon as possible\n-                dispatcher.registerChannel(this, IOOperation.READ);\n-                dispatcher.registerChannel(this, IOOperation.WRITE);\n+                LOG.info().$('[').$(fd).$(\"] queue full, could not start reading new records, consider increasing queue size or number of writer jobs\").$();\n                 return true;\n             }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkyOTA4OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446929089", "bodyText": "There is Chars.toString() to track instances where we convert char sequence to string more easier", "author": "bluestreak01", "createdAt": "2020-06-29T12:24:16Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkzMjIzOA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446932238", "bodyText": "there is more efficient way to check that map item exists and then insert it\nint keyIndex = map.keyIndex(tableName);\nif ( keyIndex > -1) {\n // table name is new to the map\n ...\n value = new ...\n map.putAt(keyIndex, tableName, value);\n} else {\n  value = map.valueAt(keyIndex);\n}", "author": "bluestreak01", "createdAt": "2020-06-29T12:29:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0Nzc4Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446947783", "bodyText": "We might be able to get away creating stats objects. Table name is already a key in map, does not have to be on object.\nCharSequenceLongHashMap does not exist, but i can be easily created using CharSequenceIntHashMap.\nThen the long can be decoded using Numbers.decodeHighInt() and Numbers.decodeLowInt", "author": "bluestreak01", "createdAt": "2020-06-29T12:53:56Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                writer.commit();\n+            }\n+\n+            private void preprocessEvent(LineTcpMeasurementEvent event) {\n+                error = false;\n+                nMeasurementValues = event.getNValues();\n+                colTypes.ensureCapacity(nMeasurementValues);\n+                colIndexMappings.ensureCapacity(nMeasurementValues);\n+                parseTypes(event);\n+            }\n+\n+            private void parseTypes(LineTcpMeasurementEvent event) {\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colType;\n+                    if (n < event.getFirstFieldIndex()) {\n+                        colType = ColumnType.SYMBOL;\n+                    } else {\n+                        colType = CairoLineProtoParserSupport.getValueType(event.getValue(n));\n+                    }\n+                    colTypes.add(n, colType);\n+                }\n+            }\n+\n+            private void parseNames(LineTcpMeasurementEvent event) {\n+                RecordMetadata metadata = writer.getMetadata();\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colIndex = metadata.getColumnIndexQuiet(event.getName(n));\n+                    if (colIndex == -1) {\n+                        colIndex = metadata.getColumnCount();\n+                        writer.addColumn(event.getName(n), colTypes.getQuick(n));\n+                    } else {\n+                        if (metadata.getColumnType(colIndex) != colTypes.getQuick(n)) {\n+                            LOG.error().$(\"mismatched column and value types [table=\").$(writer.getName())\n+                                    .$(\", column=\").$(metadata.getColumnName(colIndex))\n+                                    .$(\", columnType=\").$(ColumnType.nameOf(metadata.getColumnType(colIndex)))\n+                                    .$(\", valueType=\").$(ColumnType.nameOf(colTypes.getQuick(n)))\n+                                    .$(']').$();\n+                            error = true;\n+                            return;\n+                        }\n+                    }\n+                    colIndexMappings.add(n, colIndex);\n+                }\n+            }\n+\n+            private int getColumnType(int i) {\n+                return colTypes.getQuick(i);\n+            }\n+\n+            @Override\n+            public void close() {\n+                if (null != writer) {\n+                    LOG.info().$(name).$(\" closed parser [name=\").$(writer.getName()).$(']').$();\n+                    writer.close();\n+                    writer = null;\n+                }\n+            }\n+\n+        }\n+\n+        private class TableStructureAdapter implements TableStructure {\n+            private LineTcpMeasurementEvent event;\n+            private Parser parser;\n+            private int columnCount;\n+            private int timestampIndex;\n+\n+            @Override\n+            public int getColumnCount() {\n+                return columnCount;\n+            }\n+\n+            @Override\n+            public CharSequence getColumnName(int columnIndex) {\n+                if (columnIndex == getTimestampIndex()) {\n+                    return \"timestamp\";\n+                }\n+                return event.getName(columnIndex);\n+            }\n+\n+            @Override\n+            public int getColumnType(int columnIndex) {\n+                if (columnIndex == getTimestampIndex()) {\n+                    return ColumnType.TIMESTAMP;\n+                }\n+                return parser.getColumnType(columnIndex);\n+            }\n+\n+            @Override\n+            public int getIndexBlockCapacity(int columnIndex) {\n+                return 0;\n+            }\n+\n+            @Override\n+            public boolean isIndexed(int columnIndex) {\n+                return false;\n+            }\n+\n+            @Override\n+            public boolean isSequential(int columnIndex) {\n+                return false;\n+            }\n+\n+            @Override\n+            public int getPartitionBy() {\n+                return PartitionBy.NONE;\n+            }\n+\n+            @Override\n+            public boolean getSymbolCacheFlag(int columnIndex) {\n+                return cairoConfiguration.getDefaultSymbolCacheFlag();\n+            }\n+\n+            @Override\n+            public int getSymbolCapacity(int columnIndex) {\n+                return cairoConfiguration.getDefaultSymbolCapacity();\n+            }\n+\n+            @Override\n+            public CharSequence getTableName() {\n+                return event.getTableName();\n+            }\n+\n+            @Override\n+            public int getTimestampIndex() {\n+                return timestampIndex;\n+            }\n+\n+            TableStructureAdapter of(LineTcpMeasurementEvent event, Parser parser) {\n+                this.event = event;\n+                this.parser = parser;\n+                this.timestampIndex = event.getNValues();\n+                this.columnCount = timestampIndex + 1;\n+                return this;\n+            }\n+        }\n+    }\n+\n+    private static class TableStats {", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0ODM1Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446948357", "bodyText": "could be a single return statement", "author": "bluestreak01", "createdAt": "2020-06-29T12:54:53Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk0ODY1Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446948657", "bodyText": "return is unnecessary", "author": "bluestreak01", "createdAt": "2020-06-29T12:55:20Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5MTM0Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r446991346", "bodyText": "Locking up queue element for so long is not great. The job has to be able to parse the event into its own, thread-local state. Then copy the state onto queue as quickly as possible. This will also deal with the situation when queue being full in a localized way.", "author": "bluestreak01", "createdAt": "2020-06-29T13:56:52Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java", "diffHunk": "@@ -0,0 +1,148 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import io.questdb.cutlass.line.tcp.LineTcpMeasurementScheduler.LineTcpMeasurementEvent;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.network.IOContext;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IOOperation;\n+import io.questdb.network.NetworkFacade;\n+import io.questdb.std.Mutable;\n+import io.questdb.std.Unsafe;\n+import io.questdb.std.str.DirectByteCharSequence;\n+\n+class LineTcpConnectionContext implements IOContext, Mutable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpConnectionContext.class);\n+    private final NetworkFacade nf;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private long fd;\n+    private IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private long recvBufStart;\n+    private long recvBufEnd;\n+    private long recvBufPos;\n+    private boolean peerDisconnected;\n+    private final DirectByteCharSequence byteCharSequence = new DirectByteCharSequence();\n+\n+    LineTcpConnectionContext(LineTcpReceiverConfiguration configuration, LineTcpMeasurementScheduler scheduler) {\n+        nf = configuration.getNetworkFacade();\n+        this.scheduler = scheduler;\n+        recvBufStart = Unsafe.malloc(configuration.getNetMsgBufferSize());\n+        recvBufEnd = recvBufStart + configuration.getNetMsgBufferSize();\n+    }\n+\n+    // returns true if busy\n+    boolean handleIO() {\n+        try {\n+            LineTcpMeasurementEvent event = scheduler.getNewEvent();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MTI2MQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447641261", "bodyText": "There is a trade off here, we can either always commit the queue state quickly (within one call to handelO()) or propagate our waiting state back to the TCP peer producer by not reading from the TCP socket. Since the Sequence  implementation is for a single producer, holding onto the sequence cursor for long has no bad effects.", "author": "patrickSpaceSurfer", "createdAt": "2020-06-30T12:24:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5MTM0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\nindex 66986b580..05bbc3638 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpConnectionContext.java\n\n@@ -36,8 +36,7 @@ class LineTcpConnectionContext implements IOContext, Mutable {\n             LineTcpMeasurementEvent event = scheduler.getNewEvent();\n             if (null == event) {\n                 // Waiting for writer threads to drain queue, request callback as soon as possible\n-                dispatcher.registerChannel(this, IOOperation.READ);\n-                dispatcher.registerChannel(this, IOOperation.WRITE);\n+                LOG.info().$('[').$(fd).$(\"] queue full, could not start reading new records, consider increasing queue size or number of writer jobs\").$();\n                 return true;\n             }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMDI0MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447000240", "bodyText": "it looks like parser can boil down to the map of table writers. Parser state is transient for the row of data and can be part of the WriterJob", "author": "bluestreak01", "createdAt": "2020-06-29T14:09:10Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMTM5NA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447001394", "bodyText": "commit() rate should be configurable to avoid committing every row. Commit can definitely be done when either X rows reached or queue becomes empty", "author": "bluestreak01", "createdAt": "2020-06-29T14:10:46Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                writer.commit();", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzAwMTYzNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r447001635", "bodyText": "we also need to cancel row on CairoException", "author": "bluestreak01", "createdAt": "2020-06-29T14:11:06Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,745 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableStats> statsByTableName;\n+    private final int[] loadByThread;\n+    // TODO\n+    private final int nUpdatesPerLoadRebalance = 1000;\n+    private final double maxLoadRatio;\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        statsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        maxLoadRatio = 1d + 1d / writerWorkerPool.getWorkerCount();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            do {\n+                nextEventCursor = pubSeq.next();\n+            } while (nextEventCursor == -2);\n+            if (nextEventCursor < 0) {\n+                nextEventCursor = -1;\n+                return null;\n+            }\n+        }\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableStats stats = statsByTableName.get(event.getTableName());\n+        if (null == stats) {\n+            String tableName = event.getTableName().toString();\n+            calcThreadLoad();\n+            int leastLoad = Integer.MAX_VALUE;\n+            int threadId = 0;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] < leastLoad) {\n+                    leastLoad = loadByThread[n];\n+                    threadId = n;\n+                }\n+            }\n+            stats = new TableStats(tableName, threadId);\n+            statsByTableName.put(tableName, stats);\n+            LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+        }\n+        event.threadId = stats.threadId;\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (stats.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableStats stats = statsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableStats stats = statsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = statsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableStats stats = statsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            statsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = -1;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == -1;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            try {\n+                long cursor;\n+                while ((cursor = sequence.next()) < 0) {\n+                    if (cursor == -1) {\n+                        return false;\n+                    }\n+                }\n+                LineTcpMeasurementEvent event = queue.get(cursor);\n+                boolean eventProcessed;\n+                try {\n+                    if (event.threadId == id) {\n+                        eventProcessed = processNextEvent(event);\n+                    } else {\n+                        if (event.isRebalanceEvent()) {\n+                            eventProcessed = processRebalance(event);\n+                        } else {\n+                            eventProcessed = true;\n+                        }\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                    eventProcessed = true;\n+                }\n+                if (eventProcessed) {\n+                    sequence.done(cursor);\n+                }\n+            } catch (RuntimeException ex) {\n+                LOG.error().$(ex).$();\n+            }\n+            return true;\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(event.getTableName().toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+                return true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (BadCastException ignore) {", "originalCommit": "216efe6f6ef6849c83782e9df3d3e498af89f17b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3452b15d99990624cd6adc89193dde71cfce0d3", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex f8bf40b4a..a4c65a4e5 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -94,15 +94,19 @@ class LineTcpMeasurementScheduler implements Closeable {\n \n     LineTcpMeasurementEvent getNewEvent() {\n         assert !closed();\n-        if (nextEventCursor == -1) {\n-            do {\n-                nextEventCursor = pubSeq.next();\n-            } while (nextEventCursor == -2);\n-            if (nextEventCursor < 0) {\n-                nextEventCursor = -1;\n-                return null;\n-            }\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n         }\n+\n         return queue.get(nextEventCursor);\n     }\n \n"}}, {"oid": "51bb90d218b0b843ff671f5410836fb822833e73", "url": "https://github.com/questdb/questdb/commit/51bb90d218b0b843ff671f5410836fb822833e73", "message": "chore: Create LineTCPSenderMain benchmark", "committedDate": "2020-06-30T12:00:47Z", "type": "commit"}, {"oid": "e3452b15d99990624cd6adc89193dde71cfce0d3", "url": "https://github.com/questdb/questdb/commit/e3452b15d99990624cd6adc89193dde71cfce0d3", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T12:28:41Z", "type": "commit"}, {"oid": "4da1dee8c65869f3c7cc612c5c825a733ee38f9f", "url": "https://github.com/questdb/questdb/commit/4da1dee8c65869f3c7cc612c5c825a733ee38f9f", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T12:43:31Z", "type": "commit"}, {"oid": "37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "url": "https://github.com/questdb/questdb/commit/37e77a3ec71f88d0766c4f6010dab4b8ccd09066", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-06-30T14:02:47Z", "type": "commit"}, {"oid": "c5b3609592c1a8027d75382d1b2d5246557dc0e1", "url": "https://github.com/questdb/questdb/commit/c5b3609592c1a8027d75382d1b2d5246557dc0e1", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T10:21:34Z", "type": "commit"}, {"oid": "7195d602b56edb80b5417bd316bb4ecb44a1925e", "url": "https://github.com/questdb/questdb/commit/7195d602b56edb80b5417bd316bb4ecb44a1925e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T10:41:19Z", "type": "commit"}, {"oid": "0f39e159e090833b01ba11b9eaa1ed6cf2f13b1e", "url": "https://github.com/questdb/questdb/commit/0f39e159e090833b01ba11b9eaa1ed6cf2f13b1e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T13:23:35Z", "type": "commit"}, {"oid": "2a8db1080a2f129b1fef81713f5fbdb45f41802e", "url": "https://github.com/questdb/questdb/commit/2a8db1080a2f129b1fef81713f5fbdb45f41802e", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T13:39:04Z", "type": "commit"}, {"oid": "b13b945253cdadd139b7fb56c5a9404652511687", "url": "https://github.com/questdb/questdb/commit/b13b945253cdadd139b7fb56c5a9404652511687", "message": "chore: Create LineTCPSenderMain benchmark", "committedDate": "2020-07-01T13:39:28Z", "type": "commit"}, {"oid": "28efc299dea57a715a3b72defbe8f2bc75c6d3f5", "url": "https://github.com/questdb/questdb/commit/28efc299dea57a715a3b72defbe8f2bc75c6d3f5", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T14:34:47Z", "type": "commit"}, {"oid": "23103b296e04c7d637539f6da343d6207ce401cb", "url": "https://github.com/questdb/questdb/commit/23103b296e04c7d637539f6da343d6207ce401cb", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T14:56:51Z", "type": "commit"}, {"oid": "560fa8f8302a5ec05c315ec9e363fde1c5a2529b", "url": "https://github.com/questdb/questdb/commit/560fa8f8302a5ec05c315ec9e363fde1c5a2529b", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-07-01T15:04:40Z", "type": "commit"}, {"oid": "026b8e7c6aaf31bc3887103eebc323a38b432871", "url": "https://github.com/questdb/questdb/commit/026b8e7c6aaf31bc3887103eebc323a38b432871", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-01T18:22:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY0NjExMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448646110", "bodyText": "This is a little bit of rock'n'roll style server inclusion :)\nWe should do this orderly:\n\ncreate an instance if configuration enables one\ndispose of the instance when server shuts down", "author": "bluestreak01", "createdAt": "2020-07-01T22:21:57Z", "path": "core/src/main/java/io/questdb/ServerMain.java", "diffHunk": "@@ -187,6 +204,7 @@ public static void main(String[] args) throws Exception {\n                 );\n             }\n \n+            LineTcpServer.create(configuration.getCairoConfiguration(), configuration.getLineTcpReceiverConfiguration(), workerPool, log, cairoEngine, messageBus);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0d4cb369d689e010b841a6449c591e194c591ad8", "chunk": "diff --git a/core/src/main/java/io/questdb/ServerMain.java b/core/src/main/java/io/questdb/ServerMain.java\nindex 7c2f4e559..8be69a0c1 100644\n--- a/core/src/main/java/io/questdb/ServerMain.java\n+++ b/core/src/main/java/io/questdb/ServerMain.java\n\n@@ -204,7 +204,8 @@ public class ServerMain {\n                 );\n             }\n \n-            LineTcpServer.create(configuration.getCairoConfiguration(), configuration.getLineTcpReceiverConfiguration(), workerPool, log, cairoEngine, messageBus);\n+            LineTcpServer lineTcpServer = LineTcpServer.create(configuration.getCairoConfiguration(), configuration.getLineTcpReceiverConfiguration(), workerPool, log, cairoEngine,\n+                    messageBus);\n             startQuestDb(workerPool, lineProtocolReceiver, log);\n             logWebConsoleUrls(log, configuration);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkxODEyMw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448918123", "bodyText": "this is a defunct pool, how does this work?", "author": "bluestreak01", "createdAt": "2020-07-02T10:53:47Z", "path": "core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java", "diffHunk": "@@ -24,16 +24,39 @@\n \n package io.questdb;\n \n+import java.io.Closeable;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n import io.questdb.cairo.CairoEngine;\n import io.questdb.griffin.FunctionFactoryCache;\n import io.questdb.log.Log;\n import io.questdb.mp.WorkerPool;\n import io.questdb.mp.WorkerPoolConfiguration;\n-import org.jetbrains.annotations.Nullable;\n-\n-import java.io.Closeable;\n \n public interface WorkerPoolAwareConfiguration extends WorkerPoolConfiguration {\n+    public static WorkerPoolAwareConfiguration USE_SHARED_CONFIGURATION = new WorkerPoolAwareConfiguration() {\n+        @Override\n+        public int[] getWorkerAffinity() {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public int getWorkerCount() {\n+            return 0;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0NjA4Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449446086", "bodyText": "WorkerPoolAwareConfiguration.configureWorkerPool uses the shared pool if workerCount is 0", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkxODEyMw=="}], "type": "inlineReview", "revised_code": {"commit": "6d30c4340cb3486b9810d1059d5cd1a1194ca285", "chunk": "diff --git a/core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java b/core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java\nindex ce0a03c3a..89c93ad48 100644\n--- a/core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java\n+++ b/core/src/main/java/io/questdb/WorkerPoolAwareConfiguration.java\n\n@@ -53,7 +53,7 @@ public interface WorkerPoolAwareConfiguration extends WorkerPoolConfiguration {\n \n         @Override\n         public boolean isEnabled() {\n-            throw new UnsupportedOperationException();\n+            return true;\n         }\n \n     };\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk0ODA5Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448948092", "bodyText": "this can be a character switch", "author": "bluestreak01", "createdAt": "2020-07-02T11:56:42Z", "path": "core/src/main/java/io/questdb/PropServerConfiguration.java", "diffHunk": "@@ -458,27 +516,56 @@ public PropServerConfiguration(String root, Properties properties) throws Server\n         this.lineUdpOwnThread = getBoolean(properties, \"line.udp.own.thread\", false);\n         this.lineUdpUnicast = getBoolean(properties, \"line.udp.unicast\", false);\n         this.lineUdpCommitMode = getCommitMode(properties, \"line.udp.commit.mode\");\n+        this.lineUdpTimestampAdapter = getLineTimestampAdaptor(properties, \"line.udp.timestamp\");\n+\n+        this.lineTcpEnabled = getBoolean(properties, \"line.tcp.enabled\", true);\n+        if (lineTcpEnabled) {\n+            lineTcpNetActiveConnectionLimit = getInt(properties, \"line.tcp.net.active.connection.limit\", 10);\n+            parseBindTo(properties, \"line.tcp.net.bind.to\", \"0.0.0.0:9009\", (a, p) -> {\n+                lineTcpNetBindIPv4Address = a;\n+                lineTcpNetBindPort = p;\n+            });\n \n-        final String lineUdpTimestampSwitch = getString(properties, \"line.udp.timestamp\", \"n\");\n+            this.lineTcpNetEventCapacity = getInt(properties, \"line.tcp.net.event.capacity\", 1024);\n+            this.lineTcpNetIOQueueCapacity = getInt(properties, \"line.tcp.net.io.queue.capacity\", 1024);\n+            this.lineTcpNetIdleConnectionTimeout = getLong(properties, \"line.tcp.net.idle.timeout\", 300_000);\n+            this.lineTcpNetInterestQueueCapacity = getInt(properties, \"line.tcp.net.interest.queue.capacity\", 1024);\n+            this.lineTcpNetListenBacklog = getInt(properties, \"line.tcp.net.listen.backlog\", 50_000);\n+            this.lineTcpNetRcvBufSize = getIntSize(properties, \"line.tcp.net.recv.buf.size\", -1);\n+            this.lineTcpConnectionPoolInitialCapacity = getInt(properties, \"line.tcp.connection.pool.capacity\", 64);\n+            this.lineTcpTimestampAdapter = getLineTimestampAdaptor(properties, \"line.tcp.timestamp\");\n+            this.lineTcpMsgBufferSize = getIntSize(properties, \"line.tcp.msg.buffer.size\", 2048);\n+            this.lineTcpMaxMeasurementSize = getIntSize(properties, \"line.tcp.max.measurement.size\", 2048);\n+            if (lineTcpMaxMeasurementSize > lineTcpMsgBufferSize) {\n+                throw new IllegalArgumentException(\n+                        \"line.tcp.max.measurement.size (\" + this.lineTcpMaxMeasurementSize + \") cannot be more than line.tcp.msg.buffer.size (\" + this.lineTcpMsgBufferSize + \")\");\n+            }\n+            this.lineTcpWriterQueueSize = getIntSize(properties, \"line.tcp.writer.queue.size\", 128);\n+            this.lineTcpWorkerCount = getInt(properties, \"line.tcp.worker.count\", 0);\n+            this.lineTcpWorkerAffinity = getAffinity(properties, \"line.tcp.worker.affinity\", lineTcpWorkerCount);\n+            this.lineTcpWorkerPoolHaltOnError = getBoolean(properties, \"line.tcp.halt.on.error\", false);\n+            this.lineTcpNUpdatesPerLoadRebalance = getInt(properties, \"line.tcp.n.updates.per.load.balance\", 10_000);\n+            this.lineTcpMaxLoadRatio = getDouble(properties, \"line.tcp.max.load.ratio\", 1.9);\n+            this.lineTcpMaxUncommittedRows = getInt(properties, \"line.tcp.max.uncommitted.rows\", 1000);\n+            this.lineTcpMaintenanceJobHysteresisInMs = getInt(properties, \"line.tcp.maintenance.job.hysteresis.in.ms\", 250);\n+        }\n+    }\n+\n+    private LineProtoTimestampAdapter getLineTimestampAdaptor(Properties properties, String propNm) {\n+        final String lineUdpTimestampSwitch = getString(properties, propNm, \"n\");", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0Njk5MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449446990", "bodyText": "The property allows millisecond \"ms\" and minute \"m\"", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:21:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk0ODA5Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk1OTIxMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448959210", "bodyText": "this isn't a big deal, but on a server with 20 cores there will be 20 identical classes created by java for this lambda. Perhaps we can create lambda instance outside of the loop?", "author": "bluestreak01", "createdAt": "2020-07-02T12:17:45Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);\n+            }\n+        };\n+        workerPool.assign(new SynchronizedJob() {\n+            @Override\n+            protected boolean runSerially() {\n+                int n = busyContexts.size();\n+                while (n > 0) {\n+                    n--;\n+                    if (!busyContexts.getQuick(n).handleIO()) {\n+                        busyContexts.remove(n);\n+                    }\n+                }\n+                return dispatcher.processIOQueue(processor);\n+            }\n+        });\n+\n+        for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n+            // http context factory has thread local pools\n+            // therefore we need each thread to clean their thread locals individually\n+            workerPool.assign(i, () -> {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0d4cb369d689e010b841a6449c591e194c591ad8", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\nindex 95e5aaeee..7cf018d2b 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n\n@@ -89,12 +89,11 @@ public class LineTcpServer implements Closeable {\n             }\n         });\n \n+        final Closeable cleaner = () -> contextFactory.closeContextPool();\n         for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n             // http context factory has thread local pools\n             // therefore we need each thread to clean their thread locals individually\n-            workerPool.assign(i, () -> {\n-                contextFactory.closeContextPool();\n-            });\n+            workerPool.assign(i, cleaner);\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDMyNA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448960324", "bodyText": "same minor thing here, creating identical lambdas in a loop", "author": "bluestreak01", "createdAt": "2020-07-02T12:19:55Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ2MDE4NQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449460185", "bodyText": "These are not identical writerJob is scoped to the inside of the loop", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T08:47:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDMyNA=="}], "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448960933", "bodyText": "rebalances  is not a word. It gets consistently highlighted with spell check. Perhaps we can create a different term?", "author": "bluestreak01", "createdAt": "2020-07-02T12:20:58Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2NzYzMg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450067632", "bodyText": "https://dictionary.cambridge.org/dictionary/english/rebalance", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T08:35:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2OTk0Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450069947", "bodyText": "haha, intellij doesn't agree", "author": "bluestreak01", "createdAt": "2020-07-06T08:39:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MDkzMw=="}], "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MTQ1Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448961453", "bodyText": "This un-typed, perhaps not logged correctly and un-tested. In any case we should not be throwing new instance and concatenating strings here.\nWe need to throw some \"bad\" line protocol text at the system.", "author": "bluestreak01", "createdAt": "2020-07-02T12:22:02Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2OTA5Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450069093", "bodyText": "This is a failure scenario, bug in our code (not triggered by third party input). I can change it to an assert or an Error if you like", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T08:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MTQ1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2MjI0Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448962242", "bodyText": "this can potentially be done branch-free, would be interesting to know if JIT does it for us", "author": "bluestreak01", "createdAt": "2020-07-02T12:23:36Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NDg2OA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448964868", "bodyText": "this method is inverted everywhere, perhaps we can optimise here", "author": "bluestreak01", "createdAt": "2020-07-02T12:28:37Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NTYwNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448965605", "bodyText": "This is strange line, I can see below that timestampAddress does get set to 0, but this line is never triggered by any of the tests. Can we review what's happening here?", "author": "bluestreak01", "createdAt": "2020-07-02T12:30:00Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NTM4Mw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r450085383", "bodyText": "This happens when the measurement does not include a timestamp and we use the received time.\nI have added the following test to cover it\nLineTcpConnectionContextTest#testUseReceivedTimestamp1", "author": "patrickSpaceSurfer", "createdAt": "2020-07-06T09:05:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NTYwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NjgyNQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448966825", "bodyText": "this is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:32:19Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2Njk2OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448966969", "bodyText": "return value is unused", "author": "bluestreak01", "createdAt": "2020-07-02T12:32:35Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2NzY1Mg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448967652", "bodyText": "exception typing is lacking. This code is untested.", "author": "bluestreak01", "createdAt": "2020-07-02T12:33:54Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MDQ4Ng==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448970486", "bodyText": "this is never called", "author": "bluestreak01", "createdAt": "2020-07-02T12:39:03Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTMxNg==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971316", "bodyText": "This never happens in tests. We should also catch \"CairoError\". writer.commit() is liable to throw that.\nCould we stick to \"message [context]\" style of logging for the thread name too?", "author": "bluestreak01", "createdAt": "2020-07-02T12:40:28Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTczOQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971739", "bodyText": "toString() at the end is unnecessary", "author": "bluestreak01", "createdAt": "2020-07-02T12:41:05Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTkwMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448971900", "bodyText": "this branch can be simplified", "author": "bluestreak01", "createdAt": "2020-07-02T12:41:23Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NjU3NQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448976575", "bodyText": "this property is never read", "author": "bluestreak01", "createdAt": "2020-07-02T12:49:42Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3Njk2MQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448976961", "bodyText": "likewise here, we should catch CairoError as well", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:16Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NzEzMA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977130", "bodyText": "cancel is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:32Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {\n+                    row.cancel();", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NzMyOQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977329", "bodyText": "type mismatch is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:50:49Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java", "diffHunk": "@@ -0,0 +1,812 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.util.Arrays;\n+\n+import io.questdb.cairo.AppendMemory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.cairo.CairoException;\n+import io.questdb.cairo.CairoSecurityContext;\n+import io.questdb.cairo.ColumnType;\n+import io.questdb.cairo.PartitionBy;\n+import io.questdb.cairo.TableStructure;\n+import io.questdb.cairo.TableUtils;\n+import io.questdb.cairo.TableWriter;\n+import io.questdb.cairo.TableWriter.Row;\n+import io.questdb.cairo.sql.RecordMetadata;\n+import io.questdb.cutlass.line.CachedCharSequence;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport;\n+import io.questdb.cutlass.line.CairoLineProtoParserSupport.BadCastException;\n+import io.questdb.cutlass.line.CharSequenceCache;\n+import io.questdb.cutlass.line.LineProtoParser;\n+import io.questdb.cutlass.line.LineProtoTimestampAdapter;\n+import io.questdb.cutlass.line.TruncatedLineProtoLexer;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.FanOut;\n+import io.questdb.mp.Job;\n+import io.questdb.mp.RingQueue;\n+import io.questdb.mp.SCSequence;\n+import io.questdb.mp.SPSequence;\n+import io.questdb.mp.Sequence;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.std.CharSequenceObjHashMap;\n+import io.questdb.std.Chars;\n+import io.questdb.std.IntList;\n+import io.questdb.std.LongList;\n+import io.questdb.std.NumericException;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.microtime.MicrosecondClock;\n+import io.questdb.std.str.Path;\n+import io.questdb.std.time.MillisecondClock;\n+\n+class LineTcpMeasurementScheduler implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpMeasurementScheduler.class);\n+    private static int REBALANCE_EVENT_ID = -1;\n+    private static int INCOMPLETE_EVENT_ID = -2;\n+    private final CairoEngine engine;\n+    private final CairoSecurityContext securityContext;\n+    private final CairoConfiguration cairoConfiguration;\n+    private final MillisecondClock milliClock;\n+    private RingQueue<LineTcpMeasurementEvent> queue;\n+    private Sequence pubSeq;\n+    private long nextEventCursor = -1;\n+    private final CharSequenceObjHashMap<TableUpdateDetails> tableUpdateDetailsByTableName;\n+    private final int[] loadByThread;\n+\n+    private final int nUpdatesPerLoadRebalance;\n+    private final double maxLoadRatio;\n+    private final int maxUncommittedRows;\n+    private final long maintenanceJobHysteresisInMs;\n+\n+    private int nLoadCheckCycles = 0;\n+    private int nRebalances = 0;\n+\n+    LineTcpMeasurementScheduler(CairoConfiguration cairoConfiguration, LineTcpReceiverConfiguration lineConfiguration, CairoEngine engine, WorkerPool writerWorkerPool) {\n+        this.engine = engine;\n+        this.securityContext = lineConfiguration.getCairoSecurityContext();\n+        this.cairoConfiguration = cairoConfiguration;\n+        this.milliClock = cairoConfiguration.getMillisecondClock();\n+        tableUpdateDetailsByTableName = new CharSequenceObjHashMap<>();\n+        loadByThread = new int[writerWorkerPool.getWorkerCount()];\n+        int maxMeasurementSize = lineConfiguration.getMaxMeasurementSize();\n+        int queueSize = lineConfiguration.getWriterQueueSize();\n+        queue = new RingQueue<>(() -> {\n+            return new LineTcpMeasurementEvent(maxMeasurementSize, lineConfiguration.getMicrosecondClock(), lineConfiguration.getTimestampAdapter());\n+        }, queueSize);\n+        pubSeq = new SPSequence(queueSize);\n+\n+        int nWriterThreads = writerWorkerPool.getWorkerCount();\n+        Sequence[] subSeqById = new Sequence[nWriterThreads];\n+        if (nWriterThreads > 1) {\n+            FanOut fanOut = new FanOut();\n+            for (int n = 0, sz = nWriterThreads; n < sz; n++) {\n+                SCSequence subSeq = new SCSequence();\n+                fanOut.and(subSeq);\n+                subSeqById[n] = subSeq;\n+                WriterJob writerJob = new WriterJob(n, subSeq);\n+                writerWorkerPool.assign(n, writerJob);\n+                writerWorkerPool.assign(n, writerJob::close);\n+            }\n+            pubSeq.then(fanOut).then(pubSeq);\n+        } else {\n+            SCSequence subSeq = new SCSequence();\n+            pubSeq.then(subSeq).then(pubSeq);\n+            WriterJob writerJob = new WriterJob(0, subSeq);\n+            writerWorkerPool.assign(0, writerJob);\n+            writerWorkerPool.assign(0, writerJob::close);\n+        }\n+\n+        nUpdatesPerLoadRebalance = lineConfiguration.getnUpdatesPerLoadRebalance();\n+        maxLoadRatio = lineConfiguration.getMaxLoadRatio();\n+        maxUncommittedRows = lineConfiguration.getMaxUncommittedRows();\n+        maintenanceJobHysteresisInMs = lineConfiguration.getMaintenanceJobHysteresisInMs();\n+    }\n+\n+    LineTcpMeasurementEvent getNewEvent() {\n+        assert !closed();\n+        if (nextEventCursor != -1 || (nextEventCursor = pubSeq.next()) > -1) {\n+            return queue.get(nextEventCursor);\n+        }\n+\n+        while (nextEventCursor == -2) {\n+            nextEventCursor = pubSeq.next();\n+        }\n+\n+        if (nextEventCursor < 0) {\n+            nextEventCursor = -1;\n+            return null;\n+        }\n+\n+        return queue.get(nextEventCursor);\n+    }\n+\n+    void commitNewEvent(LineTcpMeasurementEvent event, boolean complete) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+\n+        TableUpdateDetails tableUpdateDetails;\n+        if (complete) {\n+            int keyIndex = tableUpdateDetailsByTableName.keyIndex(event.getTableName());\n+            if (keyIndex > -1) {\n+                String tableName = Chars.toString(event.getTableName());\n+                calcThreadLoad();\n+                int leastLoad = Integer.MAX_VALUE;\n+                int threadId = 0;\n+                for (int n = 0; n < loadByThread.length; n++) {\n+                    if (loadByThread[n] < leastLoad) {\n+                        leastLoad = loadByThread[n];\n+                        threadId = n;\n+                    }\n+                }\n+                tableUpdateDetails = new TableUpdateDetails(tableName, threadId);\n+                tableUpdateDetailsByTableName.putAt(keyIndex, tableName, tableUpdateDetails);\n+                LOG.info().$(\"assigned \").$(tableName).$(\" to thread \").$(threadId).$();\n+            } else {\n+                tableUpdateDetails = tableUpdateDetailsByTableName.valueAt(keyIndex);\n+            }\n+\n+            event.threadId = tableUpdateDetails.threadId;\n+        } else {\n+            tableUpdateDetails = null;\n+            event.threadId = INCOMPLETE_EVENT_ID;\n+        }\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+\n+        if (null != tableUpdateDetails && tableUpdateDetails.nUpdates++ > nUpdatesPerLoadRebalance) {\n+            loadRebalance();\n+        }\n+    }\n+\n+    void commitRebalanceEvent(LineTcpMeasurementEvent event, int fromThreadId, int toThreadId, String tableName) {\n+        assert !closed();\n+        if (nextEventCursor == -1) {\n+            throw new IllegalStateException(\"Cannot commit without prior call to getNewEvent()\");\n+        }\n+\n+        assert queue.get(nextEventCursor) == event;\n+        event.createRebalanceEvent(fromThreadId, toThreadId, tableName);\n+        pubSeq.done(nextEventCursor);\n+        nextEventCursor = -1;\n+    }\n+\n+    private boolean closed() {\n+        return null == pubSeq;\n+    }\n+\n+    private void loadRebalance() {\n+        LOG.info().$(\"load check cycle \").$(++nLoadCheckCycles).$();\n+        calcThreadLoad();\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        int fromThreadId = -1;\n+        int toThreadId = -1;\n+        String tableNameToMove = null;\n+        int maxLoad = Integer.MAX_VALUE;\n+        while (true) {\n+            int highestLoad = Integer.MIN_VALUE;\n+            int highestLoadedThreadId = -1;\n+            int lowestLoad = Integer.MAX_VALUE;\n+            int lowestLoadedThreadId = -1;\n+            for (int n = 0; n < loadByThread.length; n++) {\n+                if (loadByThread[n] >= maxLoad) {\n+                    continue;\n+                }\n+\n+                if (highestLoad < loadByThread[n]) {\n+                    highestLoad = loadByThread[n];\n+                    highestLoadedThreadId = n;\n+                }\n+\n+                if (lowestLoad > loadByThread[n]) {\n+                    lowestLoad = loadByThread[n];\n+                    lowestLoadedThreadId = n;\n+                }\n+            }\n+\n+            if (highestLoadedThreadId == -1 || lowestLoadedThreadId == -1 || highestLoadedThreadId == lowestLoadedThreadId) {\n+                break;\n+            }\n+\n+            double loadRatio = (double) highestLoad / (double) lowestLoad;\n+            if (loadRatio < maxLoadRatio) {\n+                // Load is not sufficiently unbalanced\n+                break;\n+            }\n+\n+            int nTables = 0;\n+            lowestLoad = Integer.MAX_VALUE;\n+            String leastLoadedTableName = null;\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+                if (stats.threadId == highestLoadedThreadId && stats.nUpdates > 0) {\n+                    nTables++;\n+                    if (stats.nUpdates < lowestLoad) {\n+                        lowestLoad = stats.nUpdates;\n+                        leastLoadedTableName = stats.tableName;\n+                    }\n+                }\n+            }\n+\n+            if (nTables < 2) {\n+                // The most loaded thread only has 1 table with load assigned to it\n+                maxLoad = highestLoad;\n+                continue;\n+            }\n+\n+            fromThreadId = highestLoadedThreadId;\n+            toThreadId = lowestLoadedThreadId;\n+            tableNameToMove = leastLoadedTableName;\n+            break;\n+        }\n+\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            stats.nUpdates = 0;\n+        }\n+\n+        if (null != tableNameToMove) {\n+            LineTcpMeasurementEvent event = getNewEvent();\n+            if (null == event) {\n+                return;\n+            }\n+            LOG.info().$(\"rebalance cycle \").$(++nRebalances).$(\" moving \").$(tableNameToMove).$(\" from \").$(fromThreadId).$(\" to \").$(toThreadId).$();\n+            commitRebalanceEvent(event, fromThreadId, toThreadId, tableNameToMove);\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNameToMove);\n+            stats.threadId = toThreadId;\n+        }\n+    }\n+\n+    private void calcThreadLoad() {\n+        Arrays.fill(loadByThread, 0);\n+        ObjList<CharSequence> tableNames = tableUpdateDetailsByTableName.keys();\n+        for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+            TableUpdateDetails stats = tableUpdateDetailsByTableName.get(tableNames.get(n));\n+            loadByThread[stats.threadId] += stats.nUpdates;\n+        }\n+    }\n+\n+    int[] getLoadByThread() {\n+        return loadByThread;\n+    }\n+\n+    int getnRebalances() {\n+        return nRebalances;\n+    }\n+\n+    int getnLoadCheckCycles() {\n+        return nLoadCheckCycles;\n+    }\n+\n+    @Override\n+    public void close() {\n+        // Both the writer and the net worker pools must have been closed so that their respective cleaners have run\n+        if (null != pubSeq) {\n+            pubSeq = null;\n+            tableUpdateDetailsByTableName.clear();\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                queue.get(n).close();\n+            }\n+        }\n+    }\n+\n+    static class LineTcpMeasurementEvent implements Closeable {\n+        private TruncatedLineProtoLexer lexer;\n+        private final CharSequenceCache cache;\n+        private final MicrosecondClock clock;\n+        private final LineProtoTimestampAdapter timestampAdapter;\n+        private long measurementNameAddress;\n+        private final LongList addresses = new LongList();\n+        private int firstFieldIndex;\n+        private long timestampAddress;\n+        private int errorPosition;\n+        private int errorCode;\n+        private int threadId;\n+        private long timestamp;\n+\n+        private int rebalanceFromThreadId;\n+        private int rebalanceToThreadId;\n+        private String rebalanceTableName;\n+        private boolean rebalanceReleasedByFromThread;\n+\n+        private LineTcpMeasurementEvent(int maxMeasurementSize, MicrosecondClock clock, LineProtoTimestampAdapter timestampAdapter) {\n+            lexer = new TruncatedLineProtoLexer(maxMeasurementSize);\n+            cache = lexer.getCharSequenceCache();\n+            this.clock = clock;\n+            this.timestampAdapter = timestampAdapter;\n+            lexer.withParser(new LineProtoParser() {\n+                @Override\n+                public void onLineEnd(CharSequenceCache cache) {\n+                }\n+\n+                @Override\n+                public void onEvent(CachedCharSequence token, int type, CharSequenceCache cache) {\n+                    assert cache == LineTcpMeasurementEvent.this.cache;\n+                    switch (type) {\n+                        case EVT_MEASUREMENT:\n+                            assert measurementNameAddress == 0;\n+                            measurementNameAddress = token.getCacheAddress();\n+                            break;\n+\n+                        case EVT_TAG_NAME:\n+                        case EVT_TAG_VALUE:\n+                            assert firstFieldIndex == -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_FIELD_NAME:\n+                            if (firstFieldIndex == -1) {\n+                                firstFieldIndex = addresses.size() / 2;\n+                            }\n+                        case EVT_FIELD_VALUE:\n+                            assert firstFieldIndex != -1;\n+                            addresses.add(token.getCacheAddress());\n+                            break;\n+                        case EVT_TIMESTAMP:\n+                            assert timestampAddress == 0;\n+                            timestampAddress = token.getCacheAddress();\n+                            break;\n+\n+                        default:\n+                            throw new RuntimeException(\"Unrecognised type \" + type);\n+\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(int position, int state, int code) {\n+                    assert errorPosition == -1;\n+                    errorPosition = position;\n+                    errorCode = code;\n+                }\n+            });\n+        }\n+\n+        long parseLine(long bytesPtr, long hi) {\n+            clear();\n+            long recvBufLineNext = lexer.parseLine(bytesPtr, hi);\n+            if (recvBufLineNext != -1) {\n+                if (!isError() && firstFieldIndex == -1) {\n+                    errorPosition = (int) (recvBufLineNext - bytesPtr);\n+                    errorCode = LineProtoParser.ERROR_EMPTY;\n+                }\n+\n+                if (!isError()) {\n+                    if (timestampAddress == 0) {\n+                        timestamp = clock.getTicks();\n+                    }\n+                }\n+            }\n+            return recvBufLineNext;\n+        }\n+\n+        private void clear() {\n+            measurementNameAddress = 0;\n+            addresses.clear();\n+            firstFieldIndex = -1;\n+            timestampAddress = 0;\n+            errorPosition = -1;\n+        }\n+\n+        boolean isError() {\n+            return errorPosition != -1;\n+        }\n+\n+        int getErrorPosition() {\n+            return errorPosition;\n+        }\n+\n+        int getErrorCode() {\n+            return errorCode;\n+        }\n+\n+        CharSequence getTableName() {\n+            return cache.get(measurementNameAddress);\n+        }\n+\n+        long getTimestamp() {\n+            if (timestampAddress != 0) {\n+                try {\n+                    timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n+                    timestampAddress = 0;\n+                } catch (NumericException e) {\n+                    LOG.info().$(\"invalid timestamp: \").$(cache.get(timestampAddress)).$();\n+                    timestamp = Long.MIN_VALUE;\n+                }\n+            }\n+            return timestamp;\n+        }\n+\n+        CharSequence getName(int i) {\n+            return cache.get(addresses.getQuick(2 * i));\n+        }\n+\n+        int getNValues() {\n+            return addresses.size() / 2;\n+        }\n+\n+        CharSequence getValue(int i) {\n+            return cache.get(addresses.getQuick(2 * i + 1));\n+        }\n+\n+        int getFirstFieldIndex() {\n+            return firstFieldIndex;\n+        }\n+\n+        LineTcpMeasurementEvent createRebalanceEvent(int fromThreadId, int toThreadId, String tableName) {\n+            clear();\n+            threadId = REBALANCE_EVENT_ID;\n+            rebalanceFromThreadId = fromThreadId;\n+            rebalanceToThreadId = toThreadId;\n+            rebalanceTableName = tableName;\n+            return this;\n+        }\n+\n+        boolean isRebalanceEvent() {\n+            return threadId == REBALANCE_EVENT_ID;\n+        }\n+\n+        @Override\n+        public void close() {\n+            lexer.close();\n+            lexer = null;\n+        }\n+    }\n+\n+    private class WriterJob implements Job {\n+        private final int id;\n+        private final Sequence sequence;\n+        private final CharSequenceObjHashMap<Parser> parserCache = new CharSequenceObjHashMap<>();\n+        private final AppendMemory appendMemory = new AppendMemory();\n+        private final Path path = new Path();\n+        private final TableStructureAdapter tableStructureAdapter = new TableStructureAdapter();\n+        private final String name;\n+        private long lastMaintenanceJobMillis = 0;\n+\n+        private WriterJob(int id, Sequence sequence) {\n+            super();\n+            this.id = id;\n+            this.sequence = sequence;\n+            this.name = \"tcp-line-writer-\" + id;\n+        }\n+\n+        private void close() {\n+            // Finish all jobs in the queue before stopping\n+            for (int n = 0; n < queue.getCapacity(); n++) {\n+                if (!run(id)) {\n+                    break;\n+                }\n+            }\n+\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0; n < tableNames.size(); n++) {\n+                parserCache.get(tableNames.get(n)).close();\n+            }\n+            parserCache.clear();\n+            appendMemory.close();\n+            path.close();\n+        }\n+\n+        @Override\n+        public boolean run(int workerId) {\n+            assert workerId == id;\n+            boolean busy = drainQueue();\n+            doMaintenance(busy);\n+            return busy;\n+        }\n+\n+        private boolean drainQueue() {\n+            boolean busy = false;\n+            while (true) {\n+                try {\n+                    long cursor;\n+                    while ((cursor = sequence.next()) < 0) {\n+                        if (cursor == -1) {\n+                            return busy;\n+                        }\n+                    }\n+                    busy = true;\n+                    LineTcpMeasurementEvent event = queue.get(cursor);\n+                    boolean eventProcessed;\n+                    try {\n+                        if (event.threadId == id) {\n+                            eventProcessed = processNextEvent(event);\n+                        } else {\n+                            if (event.isRebalanceEvent()) {\n+                                eventProcessed = processRebalance(event);\n+                            } else {\n+                                eventProcessed = true;\n+                            }\n+                        }\n+                    } catch (RuntimeException ex) {\n+                        LOG.error().$(ex).$();\n+                        eventProcessed = true;\n+                    }\n+                    if (eventProcessed) {\n+                        sequence.done(cursor);\n+                    }\n+                } catch (RuntimeException ex) {\n+                    LOG.error().$(ex).$();\n+                }\n+            }\n+        }\n+\n+        private void doMaintenance(boolean busy) {\n+            long millis = milliClock.getTicks();\n+            if (busy && (millis - lastMaintenanceJobMillis) < maintenanceJobHysteresisInMs) {\n+                return;\n+            }\n+\n+            lastMaintenanceJobMillis = millis;\n+            ObjList<CharSequence> tableNames = parserCache.keys();\n+            for (int n = 0, sz = tableNames.size(); n < sz; n++) {\n+                Parser parser = parserCache.get(tableNames.get(n));\n+                parser.doMaintenance();\n+            }\n+        }\n+\n+        private boolean processNextEvent(LineTcpMeasurementEvent event) {\n+            Parser parser = parserCache.get(event.getTableName());\n+            if (null == parser) {\n+                parser = new Parser();\n+                try {\n+                    parser.processFirstEvent(engine, securityContext, event);\n+                } catch (CairoException ex) {\n+                    LOG.info().$(name).$(\" could not create parser [name=\").$(event.getTableName()).$(\", ex=\").$(ex.getFlyweightMessage()).$(']').$();\n+                    parser.close();\n+                    return false;\n+                }\n+                LOG.info().$(name).$(\" created parser [name=\").$(event.getTableName()).$(']').$();\n+                parserCache.put(Chars.toString(event.getTableName()).toString(), parser);\n+                return true;\n+            } else {\n+                parser.processEvent(event);\n+                return true;\n+            }\n+        }\n+\n+        private boolean processRebalance(LineTcpMeasurementEvent event) {\n+            if (event.rebalanceToThreadId == id) {\n+                if (!event.rebalanceReleasedByFromThread) {\n+                    return false;\n+                }\n+\n+                return true;\n+            }\n+\n+            if (event.rebalanceFromThreadId == id) {\n+                Parser parser = parserCache.get(event.rebalanceTableName);\n+                parserCache.remove(event.rebalanceTableName);\n+                parser.close();\n+                event.rebalanceReleasedByFromThread = true;\n+            }\n+\n+            return true;\n+        }\n+\n+        private class Parser implements Closeable {\n+            private TableWriter writer;\n+            private final IntList colTypes = new IntList();\n+            private final IntList colIndexMappings = new IntList();\n+            private int nUncommitted = 0;\n+            private long lastCommitMillis = 0;\n+\n+            private transient int nMeasurementValues;\n+            private transient boolean error;\n+\n+            private void processFirstEvent(CairoEngine engine, CairoSecurityContext securityContext, LineTcpMeasurementEvent event) {\n+                assert null == writer;\n+                int status = engine.getStatus(securityContext, path, event.getTableName(), 0, event.getTableName().length());\n+                if (status == TableUtils.TABLE_EXISTS) {\n+                    writer = engine.getWriter(securityContext, event.getTableName());\n+                    processEvent(event);\n+                    return;\n+                }\n+\n+                preprocessEvent(event);\n+                engine.creatTable(\n+                        securityContext,\n+                        appendMemory,\n+                        path,\n+                        tableStructureAdapter.of(event, this));\n+                int nValues = event.getNValues();\n+                for (int n = 0; n < nValues; n++) {\n+                    colIndexMappings.add(n, n);\n+                }\n+                writer = engine.getWriter(securityContext, event.getTableName());\n+                addRow(event);\n+            }\n+\n+            private void processEvent(LineTcpMeasurementEvent event) {\n+                assert event.getTableName().equals(writer.getName());\n+                preprocessEvent(event);\n+                parseNames(event);\n+                addRow(event);\n+            }\n+\n+            private void addRow(LineTcpMeasurementEvent event) {\n+                if (error) {\n+                    return;\n+                }\n+                long timestamp = event.getTimestamp();\n+                Row row = writer.newRow(timestamp);\n+                try {\n+                    for (int i = 0; i < nMeasurementValues; i++) {\n+                        int columnType = colTypes.getQuick(i);\n+                        int columnIndex = colIndexMappings.getQuick(i);\n+                        CairoLineProtoParserSupport.writers.getQuick(columnType).write(row, columnIndex, event.getValue(i));\n+                    }\n+                    row.append();\n+                } catch (CairoException | BadCastException ignore) {\n+                    row.cancel();\n+                }\n+                nUncommitted++;\n+                if (nUncommitted > maxUncommittedRows) {\n+                    commit();\n+                }\n+            }\n+\n+            private void commit() {\n+                writer.commit();\n+                nUncommitted = 0;\n+                lastCommitMillis = milliClock.getTicks();\n+            }\n+\n+            private void preprocessEvent(LineTcpMeasurementEvent event) {\n+                error = false;\n+                nMeasurementValues = event.getNValues();\n+                colTypes.ensureCapacity(nMeasurementValues);\n+                colIndexMappings.ensureCapacity(nMeasurementValues);\n+                parseTypes(event);\n+            }\n+\n+            private void parseTypes(LineTcpMeasurementEvent event) {\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colType;\n+                    if (n < event.getFirstFieldIndex()) {\n+                        colType = ColumnType.SYMBOL;\n+                    } else {\n+                        colType = CairoLineProtoParserSupport.getValueType(event.getValue(n));\n+                    }\n+                    colTypes.add(n, colType);\n+                }\n+            }\n+\n+            private void parseNames(LineTcpMeasurementEvent event) {\n+                RecordMetadata metadata = writer.getMetadata();\n+                for (int n = 0; n < nMeasurementValues; n++) {\n+                    int colIndex = metadata.getColumnIndexQuiet(event.getName(n));\n+                    if (colIndex == -1) {\n+                        colIndex = metadata.getColumnCount();\n+                        writer.addColumn(event.getName(n), colTypes.getQuick(n));\n+                    } else {\n+                        if (metadata.getColumnType(colIndex) != colTypes.getQuick(n)) {\n+                            LOG.error().$(\"mismatched column and value types [table=\").$(writer.getName())", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "72c907453a86e33dc990a5c16fef5791921b5ce7", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\nindex 15abb4d0f..ba164323a 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpMeasurementScheduler.java\n\n@@ -408,7 +408,7 @@ class LineTcpMeasurementScheduler implements Closeable {\n             return cache.get(measurementNameAddress);\n         }\n \n-        long getTimestamp() {\n+        long getTimestamp() throws NumericException {\n             if (timestampAddress != 0) {\n                 try {\n                     timestamp = timestampAdapter.getMicros(cache.get(timestampAddress));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3Nzg3MA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448977870", "bodyText": "this entire class is untested", "author": "bluestreak01", "createdAt": "2020-07-02T12:51:43Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0d4cb369d689e010b841a6449c591e194c591ad8", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\nindex 95e5aaeee..7cf018d2b 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n\n@@ -89,12 +89,11 @@ public class LineTcpServer implements Closeable {\n             }\n         });\n \n+        final Closeable cleaner = () -> contextFactory.closeContextPool();\n         for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n             // http context factory has thread local pools\n             // therefore we need each thread to clean their thread locals individually\n-            workerPool.assign(i, () -> {\n-                contextFactory.closeContextPool();\n-            });\n+            workerPool.assign(i, cleaner);\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3ODQ3Nw==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448978477", "bodyText": "exception is redundant", "author": "bluestreak01", "createdAt": "2020-07-02T12:52:34Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);\n+            }\n+        };\n+        workerPool.assign(new SynchronizedJob() {\n+            @Override\n+            protected boolean runSerially() {\n+                int n = busyContexts.size();\n+                while (n > 0) {\n+                    n--;\n+                    if (!busyContexts.getQuick(n).handleIO()) {\n+                        busyContexts.remove(n);\n+                    }\n+                }\n+                return dispatcher.processIOQueue(processor);\n+            }\n+        });\n+\n+        for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n+            // http context factory has thread local pools\n+            // therefore we need each thread to clean their thread locals individually\n+            workerPool.assign(i, () -> {\n+                contextFactory.closeContextPool();\n+            });\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        Misc.free(scheduler);\n+        Misc.free(contextFactory);\n+        Misc.free(dispatcher);\n+    }\n+\n+    private class LineTcpConnectionContextFactory implements IOContextFactory<LineTcpConnectionContext>, Closeable, EagerThreadSetup {\n+        private final ThreadLocal<WeakObjectPool<LineTcpConnectionContext>> contextPool;\n+        private boolean closed = false;\n+\n+        public LineTcpConnectionContextFactory(CairoEngine engine, LineTcpReceiverConfiguration configuration, @Nullable MessageBus messageBus, int workerCount) {\n+            this.contextPool = new ThreadLocal<>(\n+                    () -> new WeakObjectPool<>(() -> new LineTcpConnectionContext(configuration, scheduler, engine.getConfiguration().getMillisecondClock()),\n+                            configuration.getConnectionPoolInitialCapacity()));\n+        }\n+\n+        @Override\n+        public void setup() {\n+            contextPool.get();\n+        }\n+\n+        @Override\n+        public void close() throws IOException {", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0d4cb369d689e010b841a6449c591e194c591ad8", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\nindex 95e5aaeee..7cf018d2b 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n\n@@ -89,12 +89,11 @@ public class LineTcpServer implements Closeable {\n             }\n         });\n \n+        final Closeable cleaner = () -> contextFactory.closeContextPool();\n         for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n             // http context factory has thread local pools\n             // therefore we need each thread to clean their thread locals individually\n-            workerPool.assign(i, () -> {\n-                contextFactory.closeContextPool();\n-            });\n+            workerPool.assign(i, cleaner);\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4Mjg3OQ==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r448982879", "bodyText": "When queue is full, we should put backpressure on TCP stack. Right now we will start filling up busyContexts list, which does not feel right.\nI would like to suggest cache last context we could not put on the queue and stay on it until it goes away. Only then call dispatcher.processIOQueue()", "author": "bluestreak01", "createdAt": "2020-07-02T12:59:41Z", "path": "core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java", "diffHunk": "@@ -0,0 +1,150 @@\n+package io.questdb.cutlass.line.tcp;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+import org.jetbrains.annotations.Nullable;\n+\n+import io.questdb.MessageBus;\n+import io.questdb.WorkerPoolAwareConfiguration;\n+import io.questdb.WorkerPoolAwareConfiguration.ServerFactory;\n+import io.questdb.cairo.CairoConfiguration;\n+import io.questdb.cairo.CairoEngine;\n+import io.questdb.log.Log;\n+import io.questdb.log.LogFactory;\n+import io.questdb.mp.EagerThreadSetup;\n+import io.questdb.mp.SynchronizedJob;\n+import io.questdb.mp.WorkerPool;\n+import io.questdb.network.IOContextFactory;\n+import io.questdb.network.IODispatcher;\n+import io.questdb.network.IODispatchers;\n+import io.questdb.network.IORequestProcessor;\n+import io.questdb.std.Misc;\n+import io.questdb.std.ObjList;\n+import io.questdb.std.ThreadLocal;\n+import io.questdb.std.WeakObjectPool;\n+\n+public class LineTcpServer implements Closeable {\n+    private static final Log LOG = LogFactory.getLog(LineTcpServer.class);\n+\n+    @Nullable\n+    public static LineTcpServer create(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            WorkerPool sharedWorkerPool,\n+            Log log,\n+            CairoEngine cairoEngine,\n+            MessageBus messageBus\n+    ) {\n+        if (!lineConfiguration.isEnabled()) {\n+            return null;\n+        }\n+\n+        ServerFactory<LineTcpServer, WorkerPoolAwareConfiguration> factory = (netWorkerPoolConfiguration, engine, workerPool, local, bus,\n+                functionfactory) -> new LineTcpServer(\n+                        cairoConfiguration,\n+                        lineConfiguration,\n+                        cairoEngine,\n+                        workerPool,\n+                        bus);\n+        LineTcpServer server = WorkerPoolAwareConfiguration.create(lineConfiguration.getWorkerPoolConfiguration(), sharedWorkerPool, log, cairoEngine, factory, messageBus, null);\n+        return server;\n+    }\n+\n+    private final IODispatcher<LineTcpConnectionContext> dispatcher;\n+    private final LineTcpConnectionContextFactory contextFactory;\n+    private final LineTcpMeasurementScheduler scheduler;\n+    private final ObjList<LineTcpConnectionContext> busyContexts = new ObjList<>();\n+\n+    public LineTcpServer(\n+            CairoConfiguration cairoConfiguration,\n+            LineTcpReceiverConfiguration lineConfiguration,\n+            CairoEngine engine,\n+            WorkerPool workerPool,\n+            MessageBus messageBus\n+    ) {\n+        this.contextFactory = new LineTcpConnectionContextFactory(engine, lineConfiguration, messageBus, workerPool.getWorkerCount());\n+        this.dispatcher = IODispatchers.create(\n+                lineConfiguration\n+                        .getNetDispatcherConfiguration(),\n+                contextFactory);\n+        workerPool.assign(dispatcher);\n+        scheduler = new LineTcpMeasurementScheduler(cairoConfiguration, lineConfiguration, engine, workerPool);\n+        final IORequestProcessor<LineTcpConnectionContext> processor = (operation, context) -> {\n+            if (context.handleIO()) {\n+                busyContexts.add(context);", "originalCommit": "026b8e7c6aaf31bc3887103eebc323a38b432871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTU0Mjk2NA==", "url": "https://github.com/questdb/questdb/pull/458#discussion_r449542964", "bodyText": "We do need to maintain a list, because once the context cant get a queue event it no longer registers with the despatcher. However, I have changed the code to not call the dispatcher.processIOQueue() until there queue is not blocked.", "author": "patrickSpaceSurfer", "createdAt": "2020-07-03T11:51:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4Mjg3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "0d4cb369d689e010b841a6449c591e194c591ad8", "chunk": "diff --git a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\nindex 95e5aaeee..7cf018d2b 100644\n--- a/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n+++ b/core/src/main/java/io/questdb/cutlass/line/tcp/LineTcpServer.java\n\n@@ -89,12 +89,11 @@ public class LineTcpServer implements Closeable {\n             }\n         });\n \n+        final Closeable cleaner = () -> contextFactory.closeContextPool();\n         for (int i = 0, n = workerPool.getWorkerCount(); i < n; i++) {\n             // http context factory has thread local pools\n             // therefore we need each thread to clean their thread locals individually\n-            workerPool.assign(i, () -> {\n-                contextFactory.closeContextPool();\n-            });\n+            workerPool.assign(i, cleaner);\n         }\n     }\n \n"}}, {"oid": "0d4cb369d689e010b841a6449c591e194c591ad8", "url": "https://github.com/questdb/questdb/commit/0d4cb369d689e010b841a6449c591e194c591ad8", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T08:56:22Z", "type": "commit"}, {"oid": "a60f02bf0d674c400141d05c9887434c513d739b", "url": "https://github.com/questdb/questdb/commit/a60f02bf0d674c400141d05c9887434c513d739b", "message": "chore: Fix logging", "committedDate": "2020-07-03T10:39:27Z", "type": "commit"}, {"oid": "bae8e79d437385f144130e81b6d362f96d324614", "url": "https://github.com/questdb/questdb/commit/bae8e79d437385f144130e81b6d362f96d324614", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T12:01:42Z", "type": "commit"}, {"oid": "18b0fa6ae740bf722987bf0a94e1ef506f00ba51", "url": "https://github.com/questdb/questdb/commit/18b0fa6ae740bf722987bf0a94e1ef506f00ba51", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T12:10:06Z", "type": "commit"}, {"oid": "9b6b34fd474aa5a0fdc68716ddefda630048b7fe", "url": "https://github.com/questdb/questdb/commit/9b6b34fd474aa5a0fdc68716ddefda630048b7fe", "message": "Merge remote-tracking branch 'origin/master' into tcp-line", "committedDate": "2020-07-03T12:15:24Z", "type": "commit"}, {"oid": "6d30c4340cb3486b9810d1059d5cd1a1194ca285", "url": "https://github.com/questdb/questdb/commit/6d30c4340cb3486b9810d1059d5cd1a1194ca285", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T14:33:34Z", "type": "commit"}, {"oid": "37fedc698406b47427a3a4f8658cde1e6aee01b9", "url": "https://github.com/questdb/questdb/commit/37fedc698406b47427a3a4f8658cde1e6aee01b9", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T17:39:02Z", "type": "commit"}, {"oid": "2d4cb18f5ccaefc27d96f6a9a4bf6fe31859e0e3", "url": "https://github.com/questdb/questdb/commit/2d4cb18f5ccaefc27d96f6a9a4bf6fe31859e0e3", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-03T21:07:14Z", "type": "commit"}, {"oid": "72c907453a86e33dc990a5c16fef5791921b5ce7", "url": "https://github.com/questdb/questdb/commit/72c907453a86e33dc990a5c16fef5791921b5ce7", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:08:29Z", "type": "commit"}, {"oid": "7aedf3bcefb15950003092da621bf23c9907cd59", "url": "https://github.com/questdb/questdb/commit/7aedf3bcefb15950003092da621bf23c9907cd59", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:25:16Z", "type": "commit"}, {"oid": "fd5b6bc5a6f61a23a331a396a592adea6def32a6", "url": "https://github.com/questdb/questdb/commit/fd5b6bc5a6f61a23a331a396a592adea6def32a6", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T10:29:01Z", "type": "commit"}, {"oid": "aa23c1e18821c47aac4ea13fc4cdeffd4c773d71", "url": "https://github.com/questdb/questdb/commit/aa23c1e18821c47aac4ea13fc4cdeffd4c773d71", "message": "feature(cutlass): Add support for influxdb line protocol over TCP", "committedDate": "2020-07-06T12:27:05Z", "type": "commit"}, {"oid": "fb241985c325fa70ff7173e42eaaeac170cb36c6", "url": "https://github.com/questdb/questdb/commit/fb241985c325fa70ff7173e42eaaeac170cb36c6", "message": "chore(cairo): code cleanup", "committedDate": "2020-07-06T16:31:12Z", "type": "commit"}]}