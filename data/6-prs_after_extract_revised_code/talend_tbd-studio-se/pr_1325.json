{"pr_number": 1325, "pr_title": "patch(TPS-3778): Sqoop issue with parquet/avro format with HDP 2.6 (TBD-9956)", "pr_createdAt": "2020-03-20T09:37:44Z", "pr_url": "https://github.com/Talend/tbd-studio-se/pull/1325", "timeline": [{"oid": "73a87c4aef335583b7fa30c41e48c1bcfe3cc72e", "url": "https://github.com/Talend/tbd-studio-se/commit/73a87c4aef335583b7fa30c41e48c1bcfe3cc72e", "message": "fix(TPS-3778): fix dependency for tSqooImport", "committedDate": "2020-03-20T09:09:45Z", "type": "commit"}, {"oid": "5c1b4c8885fc25180991737626ce1436921e7f86", "url": "https://github.com/Talend/tbd-studio-se/commit/5c1b4c8885fc25180991737626ce1436921e7f86", "message": "fix(TBD-9956): Sqoop issue with parquet/avro format with HDP 2.6", "committedDate": "2020-03-20T09:30:01Z", "type": "commit"}, {"oid": "d9272fdd85c3f53d28340ccf5c34f8af7455c0fa", "url": "https://github.com/Talend/tbd-studio-se/commit/d9272fdd85c3f53d28340ccf5c34f8af7455c0fa", "message": "fix(TBD-9956): update hdpx 'build-in' (#1293)", "committedDate": "2020-03-20T09:30:36Z", "type": "commit"}, {"oid": "efccd2fe680dd89a86d639d4ae241679dbddbbe3", "url": "https://github.com/Talend/tbd-studio-se/commit/efccd2fe680dd89a86d639d4ae241679dbddbbe3", "message": "fix(TBD-9956): fix for avro format (#1307)", "committedDate": "2020-03-20T09:31:04Z", "type": "commit"}, {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "url": "https://github.com/Talend/tbd-studio-se/commit/631883aa4c7b0d837411dcc8ccbab278701c3fb3", "message": "fix(TBD-9956):Sqoop issue with Java API/parquet format/HDP 2.6 (#1313)", "committedDate": "2020-03-20T09:31:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395546224", "bodyText": "Can you clarify why do we impact HBase in scope of this Sqoop fix. Havent seen such modifications in master PRs for TBD-9956", "author": "lbourgeois", "createdAt": "2020-03-20T10:22:53Z", "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java", "diffHunk": "@@ -1,117 +1,138 @@\n-// ============================================================================\r\n-//\r\n-// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\r\n-//\r\n-// This source code is available under agreement available at\r\n-// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\r\n-//\r\n-// You should have received a copy of the agreement\r\n-// along with this program; if not, write to Talend SA\r\n-// 9 rue Pages 92150 Suresnes, France\r\n-//\r\n-// ============================================================================\r\n-package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\r\n-\r\n-import java.util.HashSet;\r\n-import java.util.Set;\r\n-\r\n-import org.apache.commons.lang.StringUtils;\r\n-import org.talend.hadoop.distribution.DistributionModuleGroup;\r\n-import org.talend.hadoop.distribution.ESparkVersion;\r\n-import org.talend.hadoop.distribution.condition.BasicExpression;\r\n-import org.talend.hadoop.distribution.condition.BooleanOperator;\r\n-import org.talend.hadoop.distribution.condition.ComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.EqualityOperator;\r\n-import org.talend.hadoop.distribution.condition.MultiComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\r\n-import org.talend.hadoop.distribution.constants.MRConstant;\r\n-import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\r\n-\r\n-\r\n-/**\r\n- * DOC cmeng  class global comment. Detailled comment\r\n- */\r\n-public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\r\n-\r\n-    protected ComponentCondition conditionNotSpark16;\r\n-\r\n-    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\r\n-        super(pluginAdapter);\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void initConditions() {\r\n-        super.initConditions();\r\n-        conditionNotSpark16 = new SimpleComponentCondition(\r\n-                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\r\n-    }\r\n-\r\n-    @Override\r\n-    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\r\n-        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\r\n-        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\r\n-        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\r\n-            moduleGroups.addAll(moduleGroupsFromSuper);\r\n-        }\r\n-        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\r\n-\r\n-        String spark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\r\n-        String sparkMRRequiredRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\r\n-        String hdfsRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\r\n-        String hdfsNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String tezNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String mapReduceRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark1RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\r\n-\r\n-        checkRuntimeId(spark2RuntimeId);\r\n-        checkRuntimeId(sparkMRRequiredRuntimeId);\r\n-        checkRuntimeId(hdfsRuntimeId);\r\n-        checkRuntimeId(hdfsNotSpark16RuntimeId);\r\n-        checkRuntimeId(tezNotSpark16RuntimeId);\r\n-        checkRuntimeId(mapReduceRuntimeId);\r\n-        checkRuntimeId(atlasSpark1RuntimeId);\r\n-        checkRuntimeId(atlasSpark2RuntimeId);\r\n-\r\n-        ComponentCondition useAtlas = new SimpleComponentCondition(new BasicExpression(MRConstant.USE_ATLAS));\r\n-        ComponentCondition atlasSpark1x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark1);\r\n-        ComponentCondition atlasSpark2x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark2);\r\n-\r\n-        if (StringUtils.isNotBlank(sparkMRRequiredRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(tezNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(tezNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(mapReduceRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark1RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark1RuntimeId, true, atlasSpark1x));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark2RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark2RuntimeId, true, atlasSpark2x));\r\n-        }\r\n-\r\n-        return moduleGroups;\r\n-    }\r\n-}\r\n+// ============================================================================\n+//\n+// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\n+//\n+// This source code is available under agreement available at\n+// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\n+//\n+// You should have received a copy of the agreement\n+// along with this program; if not, write to Talend SA\n+// 9 rue Pages 92150 Suresnes, France\n+//\n+// ============================================================================\n+package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.talend.hadoop.distribution.DistributionModuleGroup;\n+import org.talend.hadoop.distribution.ESparkVersion;\n+import org.talend.hadoop.distribution.condition.BasicExpression;\n+import org.talend.hadoop.distribution.condition.BooleanOperator;\n+import org.talend.hadoop.distribution.condition.ComponentCondition;\n+import org.talend.hadoop.distribution.condition.EqualityOperator;\n+import org.talend.hadoop.distribution.condition.MultiComponentCondition;\n+import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\n+import org.talend.hadoop.distribution.constants.MRConstant;\n+import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\n+\n+\n+/**\n+ * DOC cmeng  class global comment. Detailled comment\n+ */\n+public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\n+\n+    protected ComponentCondition conditionNotSpark16;\n+\n+    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\n+        super(pluginAdapter);\n+    }\n+\n+    @Override\n+    protected void initConditions() {\n+        super.initConditions();\n+        conditionNotSpark16 = new SimpleComponentCondition(\n+                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\n+    }\n+\n+    @Override\n+    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\n+        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\n+        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\n+        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\n+            moduleGroups.addAll(moduleGroupsFromSuper);\n+        }\n+        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\n+\n+        String spark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\n+        String sparkMRRequiredRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\n+        String hdfsRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\n+        String hdfsNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String tezNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String mapReduceRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\n+        String atlasSpark1RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\n+        String atlasSpark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\n+        String sqoopRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_MODULE_GROUP.getModuleName());\n+        String sqoopParquetRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_PARQUET_MODULE_GROUP.getModuleName());\n+        String hBaseRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HBASE_MODULE_GROUP.getModuleName());", "originalCommit": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNDk2NQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395614965", "bodyText": "hbase modifications shouldn't be here. Will revert that.", "author": "sponomarova", "createdAt": "2020-03-20T12:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA=="}], "type": "inlineReview", "revised_code": {"commit": "94def8f3eb8ff0ae9c321df291f8b02924a2d172", "chunk": "diff --git a/main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java b/main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java\nindex d2c29fca2..c9a076631 100644\n--- a/main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java\n+++ b/main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java\n\n@@ -77,8 +77,6 @@ public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGrou\n                 .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_MODULE_GROUP.getModuleName());\n         String sqoopParquetRuntimeId = pluginAdapter\n                 .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_PARQUET_MODULE_GROUP.getModuleName());\n-        String hBaseRuntimeId = pluginAdapter\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HBASE_MODULE_GROUP.getModuleName());\n \n         checkRuntimeId(spark2RuntimeId);\n         checkRuntimeId(sparkMRRequiredRuntimeId);\n"}}, {"oid": "94def8f3eb8ff0ae9c321df291f8b02924a2d172", "url": "https://github.com/Talend/tbd-studio-se/commit/94def8f3eb8ff0ae9c321df291f8b02924a2d172", "message": "fix(TBD-9956): add sqoop to DynamicHDPSparkBatchModuleGroup", "committedDate": "2020-03-20T13:18:42Z", "type": "commit"}, {"oid": "d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0", "url": "https://github.com/Talend/tbd-studio-se/commit/d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0", "message": "fix(TBD-9956): modify 'build-in' for hsp 2.6", "committedDate": "2020-03-20T13:42:46Z", "type": "commit"}, {"oid": "122a01be6c34380d89e170ef5ccd5e8312286654", "url": "https://github.com/Talend/tbd-studio-se/commit/122a01be6c34380d89e170ef5ccd5e8312286654", "message": "fix(TPS-3778): fix hdp 'build-in'/teplate location", "committedDate": "2020-03-20T14:55:42Z", "type": "commit"}, {"oid": "36bd57b5397cbe62881dd08804ba341ea4a89c36", "url": "https://github.com/Talend/tbd-studio-se/commit/36bd57b5397cbe62881dd08804ba341ea4a89c36", "message": "fix(TPS-3778): fix hdp", "committedDate": "2020-03-20T15:06:01Z", "type": "commit"}, {"oid": "ae6d8d479056c39adca0414725e6a2a0400a6d14", "url": "https://github.com/Talend/tbd-studio-se/commit/ae6d8d479056c39adca0414725e6a2a0400a6d14", "message": "fix(TPS-3778): modify template", "committedDate": "2020-03-20T15:25:08Z", "type": "commit"}, {"oid": "26e324c23abd1643fb467caf188dfd54832b09da", "url": "https://github.com/Talend/tbd-studio-se/commit/26e324c23abd1643fb467caf188dfd54832b09da", "message": "fix(TPS-3778): fix 'build-in'", "committedDate": "2020-03-20T15:35:06Z", "type": "commit"}, {"oid": "ce0158e170f93e310a8fd19ee1d74f35a68e9bb3", "url": "https://github.com/Talend/tbd-studio-se/commit/ce0158e170f93e310a8fd19ee1d74f35a68e9bb3", "message": "fix(TPS-3778): fix 'build-in'", "committedDate": "2020-03-20T18:00:22Z", "type": "commit"}, {"oid": "f486addce932d408f75517c83ffb9c1d71aee378", "url": "https://github.com/Talend/tbd-studio-se/commit/f486addce932d408f75517c83ffb9c1d71aee378", "message": "TBD-10095: fixed (#1294)", "committedDate": "2020-03-26T23:55:25Z", "type": "commit"}, {"oid": "32e97637e1de2794acc6012b2d73ada763089f36", "url": "https://github.com/Talend/tbd-studio-se/commit/32e97637e1de2794acc6012b2d73ada763089f36", "message": "add Hadoop prop to avoid avro conflict", "committedDate": "2020-03-27T08:26:05Z", "type": "commit"}, {"oid": "3bf3e9f7b13b9da20936ebd69f3e7e9b6f12523f", "url": "https://github.com/Talend/tbd-studio-se/commit/3bf3e9f7b13b9da20936ebd69f3e7e9b6f12523f", "message": "change hadoop prop to support all cases", "committedDate": "2020-03-27T17:12:55Z", "type": "commit"}, {"oid": "34297fd1573495ca299acb23ac9912bd2a95c8e8", "url": "https://github.com/Talend/tbd-studio-se/commit/34297fd1573495ca299acb23ac9912bd2a95c8e8", "message": "Merge branch 'patch/7.2.1' of github.com:Talend/tbd-studio-se into fix/TPS-3778", "committedDate": "2020-03-27T17:19:04Z", "type": "commit"}]}