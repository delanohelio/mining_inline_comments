{"pr_number": 185, "pr_title": "Full overwrite replication", "pr_createdAt": "2020-05-12T16:29:54Z", "pr_url": "https://github.com/ExpediaGroup/circus-train/pull/185", "timeline": [{"oid": "642932ca0c112d47a59db88ffe8da96e6ca18ac8", "url": "https://github.com/ExpediaGroup/circus-train/commit/642932ca0c112d47a59db88ffe8da96e6ca18ac8", "message": "Added new replication mode to overwrite tables", "committedDate": "2020-05-05T15:49:13Z", "type": "commit"}, {"oid": "068a9d5254716512e9b991ac851ba6e856a131c0", "url": "https://github.com/ExpediaGroup/circus-train/commit/068a9d5254716512e9b991ac851ba6e856a131c0", "message": "Updating changelog", "committedDate": "2020-05-05T15:53:21Z", "type": "commit"}, {"oid": "eb4d269b0148cd47c47c1846820f04555da75bc6", "url": "https://github.com/ExpediaGroup/circus-train/commit/eb4d269b0148cd47c47c1846820f04555da75bc6", "message": "Added integration tests", "committedDate": "2020-05-12T14:16:22Z", "type": "commit"}, {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258", "url": "https://github.com/ExpediaGroup/circus-train/commit/77c6564f7ff0b36066f3796103817d1a9756d258", "message": "Added more tests", "committedDate": "2020-05-12T14:42:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4MDcwOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423880708", "bodyText": "I think this and the added case in the other switch statement needs some tests", "author": "max-jacobs", "createdAt": "2020-05-12T16:44:15Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImpl.java", "diffHunk": "@@ -107,6 +107,7 @@ private Replication createPartitionedTableReplication(\n       replication = new PartitionedTableMetadataMirrorReplication(sourceDatabaseName, sourceTableName,\n           partitionPredicate, source, replica, eventIdFactory, replicaDatabaseName, replicaTableName);\n       break;\n+    case FULL_OVERWRITE:", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887176", "bodyText": "Would recommend moving this method to the DropTableService. Also, on a full overwrite I imagine we will want to delete the current data (right?), but if we're using Beekeeper drop table events will be ignored (unless we add the param to allow drop table events). But even if we do this, we won't want to schedule the table path because then Beekeeper will delete any new data that is added after the delete - Beekeeper doesn't yet go to the Metastore to only schedule the current partitions for deletion on a table drop.\nWe probably want to do an alter all the individual partitions to make sure they're deleted and not the new data? Not sure, is that possible?", "author": "max-jacobs", "createdAt": "2020-05-12T16:53:57Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMDU4MA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423920580", "bodyText": "If the old replica is dropped, and then later the new replica is recreated, and all new data and partitions are put in a new ctp-... folder, won't Beekeeper eventually find and delete all the old ctp paths from the old (dropped) version of the table?  Or what am I missing?", "author": "barnharts4", "createdAt": "2020-05-12T17:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM0NzMxOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424347318", "bodyText": "Spoke with the team, we think that this is true for unpartitioned tables, but for partitioned tables the table path doesn't include the event id, the partition paths do instead. So we can't do a drop without first making sure that Beekeeper isn't listening otherwise we'll lose all the new data too.", "author": "max-jacobs", "createdAt": "2020-05-13T10:52:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\nindex 6dbbd8cd..a1a0eb2d 100644\n--- a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n+++ b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n\n@@ -437,24 +444,25 @@ public class Replica extends HiveEndpoint {\n         tableReplication.getReplicaTableName());\n   }\n \n-  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n-    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n-    try {\n-      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n-        client.dropTable(replicaDatabaseName, replicaTableName);\n-      } else {\n-        throw new MetaStoreClientException(\"No replica table '\"\n-            + replicaDatabaseName\n-            + \".\"\n-            + replicaTableName\n-            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n-            + FULL.name()\n-            + \".\");\n-      }\n-    } catch (TException e) {\n-      throw new MetaStoreClientException(\n-          \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n-    }\n-  }\n+  // private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName)\n+  // {\n+  // LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+  // try {\n+  // if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+  // client.dropTable(replicaDatabaseName, replicaTableName);\n+  // } else {\n+  // throw new MetaStoreClientException(\"No replica table '\"\n+  // + replicaDatabaseName\n+  // + \".\"\n+  // + replicaTableName\n+  // + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+  // + FULL.name()\n+  // + \".\");\n+  // }\n+  // } catch (TException e) {\n+  // throw new MetaStoreClientException(\n+  // \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n+  // }\n+  // }\n \n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4Nzk5NQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887995", "bodyText": "think you need a fail here to make sure this throws an exception", "author": "max-jacobs", "createdAt": "2020-05-12T16:55:05Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java", "diffHunk": "@@ -323,6 +327,60 @@ public void validateReplicaTableMetadataMirrorOnExistingMetadataUpdateTableFails\n     }\n   }\n \n+  @Test\n+  public void validateReplicaTableMetadataMirrorOnExistingFullOverwriteReplicationTableFails()\n+    throws TException, IOException {\n+    try {\n+      existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+      existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL_OVERWRITE.name());\n+      tableReplication.setReplicationMode(METADATA_MIRROR);\n+      replica = newReplica(tableReplication);\n+      replica.validateReplicaTable(DB_NAME, TABLE_NAME);\n+      fail(\"Should have thrown InvalidReplicationModeException\");\n+    } catch (InvalidReplicationModeException e) {\n+      // Check that nothing was written to the metastore\n+      verify(mockMetaStoreClient).getTable(DB_NAME, TABLE_NAME);\n+      verify(mockMetaStoreClient).close();\n+      verifyNoMoreInteractions(mockMetaStoreClient);\n+    }\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationOnExistingTableSucceeds() throws TException {\n+    existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+    existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL.name());\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+    verify(alterTableService).alterTable(eq(mockMetaStoreClient), eq(existingReplicaTable), any(Table.class));\n+    verify(mockMetaStoreClient).updateTableColumnStatistics(columnStatistics);\n+    verify(mockReplicaLocationManager, never()).addCleanUpLocation(anyString(), any(Path.class));\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationWithoutExistingTableFails() throws MetaException, TException {\n+    try {\n+    when(mockMetaStoreClient.tableExists(DB_NAME, TABLE_NAME)).thenReturn(false);\n+\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java b/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java\nindex 20978254..e79cc9e3 100644\n--- a/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java\n+++ b/circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java\n\n@@ -362,23 +361,18 @@ public class ReplicaTest {\n   }\n \n   @Test\n-  public void validateFullOverwriteReplicationWithoutExistingTableFails() throws MetaException, TException {\n-    try {\n+  public void validateFullOverwriteReplicationWithoutExistingTableSucceeds() throws TException {\n     when(mockMetaStoreClient.tableExists(DB_NAME, TABLE_NAME)).thenReturn(false);\n-\n     tableReplication.setReplicationMode(FULL_OVERWRITE);\n+\n     replica\n         .updateMetadata(EVENT_ID, tableAndStatistics,\n             new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n                 Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n             DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n-\n-    } catch (MetaStoreClientException e) {\n-      // Check that nothing was written to the metastore\n-      verify(mockMetaStoreClient).getTable(DB_NAME, TABLE_NAME);\n-      verify(mockMetaStoreClient).close();\n-      verifyNoMoreInteractions(mockMetaStoreClient);\n-    }\n+    verify(alterTableService).alterTable(eq(mockMetaStoreClient), eq(existingReplicaTable), any(Table.class));\n+    verify(mockMetaStoreClient).updateTableColumnStatistics(columnStatistics);\n+    verify(mockReplicaLocationManager, never()).addCleanUpLocation(anyString(), any(Path.class));\n   }\n \n   @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMjM2Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423922363", "bodyText": "Is throwing a No replica table exception necessary here?  What does it buy us?  If a warning were logged here instead, then wouldn't the FULL_OVERWRITE proceed just as a normal FULL operation, and the end result would be just what the user wanted?", "author": "barnharts4", "createdAt": "2020-05-12T17:50:39Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+        client.dropTable(replicaDatabaseName, replicaTableName);\n+      } else {\n+        throw new MetaStoreClientException(\"No replica table '\"\n+            + replicaDatabaseName\n+            + \".\"\n+            + replicaTableName\n+            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+            + FULL.name()\n+            + \".\");\n+      }", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\nindex 6dbbd8cd..a1a0eb2d 100644\n--- a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n+++ b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n\n@@ -437,24 +444,25 @@ public class Replica extends HiveEndpoint {\n         tableReplication.getReplicaTableName());\n   }\n \n-  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n-    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n-    try {\n-      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n-        client.dropTable(replicaDatabaseName, replicaTableName);\n-      } else {\n-        throw new MetaStoreClientException(\"No replica table '\"\n-            + replicaDatabaseName\n-            + \".\"\n-            + replicaTableName\n-            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n-            + FULL.name()\n-            + \".\");\n-      }\n-    } catch (TException e) {\n-      throw new MetaStoreClientException(\n-          \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n-    }\n-  }\n+  // private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName)\n+  // {\n+  // LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+  // try {\n+  // if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+  // client.dropTable(replicaDatabaseName, replicaTableName);\n+  // } else {\n+  // throw new MetaStoreClientException(\"No replica table '\"\n+  // + replicaDatabaseName\n+  // + \".\"\n+  // + replicaTableName\n+  // + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+  // + FULL.name()\n+  // + \".\");\n+  // }\n+  // } catch (TException e) {\n+  // throw new MetaStoreClientException(\n+  // \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n+  // }\n+  // }\n \n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNjA5Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424526096", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private void setupRelicaParameters(Table replicaTable) {\n          \n          \n            \n              private void setupReplicaParameters(Table replicaTable) {", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:24:40Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\nindex c154f565..0c1a5c77 100644\n--- a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n+++ b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n\n@@ -851,123 +850,6 @@ public class CircusTrainHdfsHdfsIntegrationTest {\n     runner.run(config.getAbsolutePath());\n   }\n \n-  @Test\n-  public void partitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable with additional columns\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    TestUtils\n-        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-\n-        List<Partition> partitions = replicaCatalog\n-            .client()\n-            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n-        assertThat(partitions.size(), is(2));\n-        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n-        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  @Test\n-  public void unpartitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    TestUtils\n-        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n-            replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n-    setupRelicaParameters(replicaTable);\n-    if (partitioned) {\n-      addPartitionsToReplica(replicaTable, replicaLocation);\n-    }\n-  }\n-\n-  private void setupRelicaParameters(Table replicaTable) {\n-    List<FieldSchema> columns = replicaTable.getSd().getCols();\n-    columns.add(new FieldSchema(\"age\", \"int\", \"\"));\n-    columns.add(new FieldSchema(\"colour\", \"string\", \"\"));\n-    replicaTable.getSd().setCols(columns);\n-    replicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"dummyEventID\");\n-    replicaTable.putToParameters(\"paramToUpdate\", \"update-me\");\n-  }\n-\n-  private void addPartitionsToReplica(Table replicaTable, URI replicaLocation) throws Exception {\n-    URI partitionAmerica = URI.create(replicaLocation + \"/dummyEventID/continent=America\");\n-    final URI partitionMexico = URI.create(partitionAmerica + \"/country=Mexico\");\n-    replicaCatalog\n-        .client()\n-        .add_partitions(\n-            Arrays.asList(newTablePartition(replicaTable, Arrays.asList(\"America\", \"Mexico\"), partitionMexico)));\n-  }\n-\n   @Test\n   public void replicaInSourceMetastore() throws Exception {\n     helper.createUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, UNPARTITIONED_TABLE));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzg5Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424527893", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                setupRelicaParameters(replicaTable);\n          \n          \n            \n                setupReplicaParameters(replicaTable);", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:27:08Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\nindex c154f565..0c1a5c77 100644\n--- a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n+++ b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n\n@@ -851,123 +850,6 @@ public class CircusTrainHdfsHdfsIntegrationTest {\n     runner.run(config.getAbsolutePath());\n   }\n \n-  @Test\n-  public void partitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable with additional columns\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    TestUtils\n-        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-\n-        List<Partition> partitions = replicaCatalog\n-            .client()\n-            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n-        assertThat(partitions.size(), is(2));\n-        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n-        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  @Test\n-  public void unpartitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    TestUtils\n-        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n-            replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n-    setupRelicaParameters(replicaTable);\n-    if (partitioned) {\n-      addPartitionsToReplica(replicaTable, replicaLocation);\n-    }\n-  }\n-\n-  private void setupRelicaParameters(Table replicaTable) {\n-    List<FieldSchema> columns = replicaTable.getSd().getCols();\n-    columns.add(new FieldSchema(\"age\", \"int\", \"\"));\n-    columns.add(new FieldSchema(\"colour\", \"string\", \"\"));\n-    replicaTable.getSd().setCols(columns);\n-    replicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"dummyEventID\");\n-    replicaTable.putToParameters(\"paramToUpdate\", \"update-me\");\n-  }\n-\n-  private void addPartitionsToReplica(Table replicaTable, URI replicaLocation) throws Exception {\n-    URI partitionAmerica = URI.create(replicaLocation + \"/dummyEventID/continent=America\");\n-    final URI partitionMexico = URI.create(partitionAmerica + \"/country=Mexico\");\n-    replicaCatalog\n-        .client()\n-        .add_partitions(\n-            Arrays.asList(newTablePartition(replicaTable, Arrays.asList(\"America\", \"Mexico\"), partitionMexico)));\n-  }\n-\n   @Test\n   public void replicaInSourceMetastore() throws Exception {\n     helper.createUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, UNPARTITIONED_TABLE));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMDM4OQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424530389", "bodyText": "This function is not just setting params but also adding two new columns to the table. Splitting this function up would be better.", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:30:06Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\nindex c154f565..0c1a5c77 100644\n--- a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n+++ b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java\n\n@@ -851,123 +850,6 @@ public class CircusTrainHdfsHdfsIntegrationTest {\n     runner.run(config.getAbsolutePath());\n   }\n \n-  @Test\n-  public void partitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable with additional columns\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    TestUtils\n-        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-\n-        List<Partition> partitions = replicaCatalog\n-            .client()\n-            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n-        assertThat(partitions.size(), is(2));\n-        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n-        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  @Test\n-  public void unpartitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    // creating replicaTable\n-    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n-    TestUtils\n-        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n-            replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n-        assertThat(hiveTable.getDbName(), is(DATABASE));\n-        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(isExternalTable(hiveTable), is(true));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n-    setupRelicaParameters(replicaTable);\n-    if (partitioned) {\n-      addPartitionsToReplica(replicaTable, replicaLocation);\n-    }\n-  }\n-\n-  private void setupRelicaParameters(Table replicaTable) {\n-    List<FieldSchema> columns = replicaTable.getSd().getCols();\n-    columns.add(new FieldSchema(\"age\", \"int\", \"\"));\n-    columns.add(new FieldSchema(\"colour\", \"string\", \"\"));\n-    replicaTable.getSd().setCols(columns);\n-    replicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"dummyEventID\");\n-    replicaTable.putToParameters(\"paramToUpdate\", \"update-me\");\n-  }\n-\n-  private void addPartitionsToReplica(Table replicaTable, URI replicaLocation) throws Exception {\n-    URI partitionAmerica = URI.create(replicaLocation + \"/dummyEventID/continent=America\");\n-    final URI partitionMexico = URI.create(partitionAmerica + \"/country=Mexico\");\n-    replicaCatalog\n-        .client()\n-        .add_partitions(\n-            Arrays.asList(newTablePartition(replicaTable, Arrays.asList(\"America\", \"Mexico\"), partitionMexico)));\n-  }\n-\n   @Test\n   public void replicaInSourceMetastore() throws Exception {\n     helper.createUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, UNPARTITIONED_TABLE));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMzcxNQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424533715", "bodyText": "same comments here. Typo and splitting up.", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:34:37Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java", "diffHunk": "@@ -273,4 +282,139 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+    TestUtils.createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+\n+    // setting up parameters, additional columns and partitions\n+    setupReplicaTable(replicaTable, true, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_TABLE, (short) -1);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    final URI sourceTableLocation = toUri(\"s3a://source/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(sourceCatalog.client(), DATABASE, UNPARTITIONED_TABLE, sourceTableLocation);\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final File dataFile = temporaryFolder.newFile();\n+    FileUtils.writeStringToFile(dataFile, \"1\\trob\\tbristol\\n2\\tsam\\ttoronto\\n\");\n+    String fileKey = String.format(\"%s/%s/%s\", DATABASE, UNPARTITIONED_TABLE, PART_00000);\n+    s3Client.putObject(\"source\", fileKey, dataFile);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+        String eventId = hiveTable.getParameters().get(REPLICATION_EVENT.parameterName());\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_UNPARTITIONED_TABLE + \"/\" + eventId);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(eventId, startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        // Assert files copied from source\n+        List<S3ObjectSummary> replicaFiles = TestUtils.listObjects(s3Client, \"replica\");\n+        assertThat(replicaFiles.size(), is(1));\n+        assertThat(replicaFiles.get(0).getSize(), is(dataFile.length()));\n+        String fileKey = String\n+            .format(\"%s/%s/%s/%s\", DATABASE, TARGET_UNPARTITIONED_TABLE, eventId, PART_00000);\n+        assertThat(replicaFiles.get(0).getKey(), is(fileKey));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java\nindex 21612b8b..18dd5475 100644\n--- a/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java\n+++ b/circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java\n\n@@ -282,139 +277,4 @@ public class CircusTrainS3S3IntegrationTest {\n     runner.run(config.getAbsolutePath());\n   }\n \n-  @Test\n-  public void partitionedTableFullOverwrite() throws Exception {\n-    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n-    TestUtils.createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_TABLE, replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n-\n-    // setting up parameters, additional columns and partitions\n-    setupReplicaTable(replicaTable, true, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite-replication.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n-        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n-        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n-        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n-        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n-        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n-        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-\n-        List<Partition> partitions = replicaCatalog\n-            .client()\n-            .listPartitions(DATABASE, TARGET_PARTITIONED_TABLE, (short) -1);\n-        assertThat(partitions.size(), is(2));\n-        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n-        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  @Test\n-  public void unpartitionedTableFullOverwrite() throws Exception {\n-    final URI sourceTableLocation = toUri(\"s3a://source/\", DATABASE, UNPARTITIONED_TABLE);\n-    TestUtils.createUnpartitionedTable(sourceCatalog.client(), DATABASE, UNPARTITIONED_TABLE, sourceTableLocation);\n-    // adjusting the sourceTable, mimicking the change we want to update\n-    Table sourceTable = sourceCatalog.client().getTable(DATABASE, UNPARTITIONED_TABLE);\n-    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n-    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n-\n-    final File dataFile = temporaryFolder.newFile();\n-    FileUtils.writeStringToFile(dataFile, \"1\\trob\\tbristol\\n2\\tsam\\ttoronto\\n\");\n-    String fileKey = String.format(\"%s/%s/%s\", DATABASE, UNPARTITIONED_TABLE, PART_00000);\n-    s3Client.putObject(\"source\", fileKey, dataFile);\n-\n-    // creating replicaTable\n-    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, UNPARTITIONED_TABLE);\n-    TestUtils.createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_TABLE, replicaLocation);\n-    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n-    // setting up parameters and additional columns\n-    setupReplicaTable(replicaTable, false, replicaLocation);\n-    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n-\n-    exit.expectSystemExitWithStatus(0);\n-    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite-replication.yml\");\n-    CircusTrainRunner runner = CircusTrainRunner\n-        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n-        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n-            sourceCatalog.driverClassName())\n-        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n-        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n-        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n-        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n-        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n-        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n-        .build();\n-    exit.checkAssertionAfterwards(new Assertion() {\n-      @Override\n-      public void checkAssertion() throws Exception {\n-        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n-        String eventId = hiveTable.getParameters().get(REPLICATION_EVENT.parameterName());\n-        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_UNPARTITIONED_TABLE + \"/\" + eventId);\n-        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n-        assertThat(eventId, startsWith(\"ctt-\"));\n-        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n-        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n-        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n-\n-        // Assert files copied from source\n-        List<S3ObjectSummary> replicaFiles = TestUtils.listObjects(s3Client, \"replica\");\n-        assertThat(replicaFiles.size(), is(1));\n-        assertThat(replicaFiles.get(0).getSize(), is(dataFile.length()));\n-        String fileKey = String\n-            .format(\"%s/%s/%s/%s\", DATABASE, TARGET_UNPARTITIONED_TABLE, eventId, PART_00000);\n-        assertThat(replicaFiles.get(0).getKey(), is(fileKey));\n-      }\n-    });\n-    runner.run(config.getAbsolutePath());\n-  }\n-\n-  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n-    setupRelicaParameters(replicaTable);\n-    if (partitioned) {\n-      addPartitionsToReplica(replicaTable, replicaLocation);\n-    }\n-  }\n-\n-  private void setupRelicaParameters(Table replicaTable) {\n-    List<FieldSchema> columns = replicaTable.getSd().getCols();\n-    columns.add(new FieldSchema(\"age\", \"int\", \"\"));\n-    columns.add(new FieldSchema(\"colour\", \"string\", \"\"));\n-    replicaTable.getSd().setCols(columns);\n-    replicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"dummyEventID\");\n-    replicaTable.putToParameters(\"paramToUpdate\", \"update-me\");\n-  }\n-\n-  private void addPartitionsToReplica(Table replicaTable, URI replicaLocation) throws Exception {\n-    URI partitionAmerica = URI.create(replicaLocation + \"/dummyEventID/continent=America\");\n-    final URI partitionMexico = URI.create(partitionAmerica + \"/country=Mexico\");\n-    replicaCatalog\n-        .client()\n-        .add_partitions(\n-            Arrays.asList(newTablePartition(replicaTable, Arrays.asList(\"America\", \"Mexico\"), partitionMexico)));\n-  }\n-\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjAwNg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042006", "bodyText": "Good spot ;)", "author": "massdosage", "createdAt": "2020-05-14T10:42:29Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -346,12 +351,12 @@ public void validateReplicaTable(String replicaDatabaseName, String replicaTable\n       Optional<Table> oldReplicaTable = getTable(client, replicaDatabaseName, replicaTableName);\n       if (oldReplicaTable.isPresent()) {\n         LOG.debug(\"Existing table found, checking that it is a valid replica.\");\n-        determinValidityOfReplica(replicationMode, oldReplicaTable.get());\n+        determineValidityOfReplica(replicationMode, oldReplicaTable.get());", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjQwNA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042404", "bodyText": "Move this up to below FULL - they feel more \"related\" and I don't think we use the ordering of this enum for anything.", "author": "massdosage", "createdAt": "2020-05-14T10:43:12Z", "path": "circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java", "diffHunk": "@@ -19,6 +19,8 @@\n \n   FULL,\n   METADATA_MIRROR,\n-  METADATA_UPDATE;\n+  METADATA_UPDATE,\n+  FULL_OVERWRITE;", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java b/circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java\nindex 09ceebe8..b7e5ebda 100644\n--- a/circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java\n+++ b/circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java\n\n@@ -18,9 +18,8 @@ package com.hotels.bdp.circustrain.api.conf;\n public enum ReplicationMode {\n \n   FULL,\n+  FULL_OVERWRITE,\n   METADATA_MIRROR,\n-  METADATA_UPDATE,\n-  FULL_OVERWRITE;\n-\n+  METADATA_UPDATE;\n \n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEzMTY4NA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425131684", "bodyText": "This call is a \"new\" addition of the hive API I'm not sure if we use it anywhere else but if we do it is ok but if we don't better to avoid using it as it's not always there on old client.\nBetter to just do the\nTry\ndropTable() \nCatch(NoSuchObjectException e) {\n//nothing to drop table doesn't exist etc.....\n}", "author": "patduin", "createdAt": "2020-05-14T13:22:35Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "chunk": "diff --git a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\nindex 6dbbd8cd..a1a0eb2d 100644\n--- a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n+++ b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n\n@@ -437,24 +444,25 @@ public class Replica extends HiveEndpoint {\n         tableReplication.getReplicaTableName());\n   }\n \n-  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n-    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n-    try {\n-      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n-        client.dropTable(replicaDatabaseName, replicaTableName);\n-      } else {\n-        throw new MetaStoreClientException(\"No replica table '\"\n-            + replicaDatabaseName\n-            + \".\"\n-            + replicaTableName\n-            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n-            + FULL.name()\n-            + \".\");\n-      }\n-    } catch (TException e) {\n-      throw new MetaStoreClientException(\n-          \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n-    }\n-  }\n+  // private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName)\n+  // {\n+  // LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+  // try {\n+  // if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+  // client.dropTable(replicaDatabaseName, replicaTableName);\n+  // } else {\n+  // throw new MetaStoreClientException(\"No replica table '\"\n+  // + replicaDatabaseName\n+  // + \".\"\n+  // + replicaTableName\n+  // + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+  // + FULL.name()\n+  // + \".\");\n+  // }\n+  // } catch (TException e) {\n+  // throw new MetaStoreClientException(\n+  // \"Unable to replace replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"'\", e);\n+  // }\n+  // }\n \n }\n"}}, {"oid": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "url": "https://github.com/ExpediaGroup/circus-train/commit/7f25cff5174805a209500a7cffcb7faf4fe121ff", "message": "Created integration test for new replication mode.", "committedDate": "2020-05-28T11:58:55Z", "type": "commit"}, {"oid": "bb0d8dc12554a6194e6031889b5b78681826737f", "url": "https://github.com/ExpediaGroup/circus-train/commit/bb0d8dc12554a6194e6031889b5b78681826737f", "message": "Cleaning up", "committedDate": "2020-05-28T12:02:24Z", "type": "commit"}, {"oid": "b623630151a38a8a703747896485d295add8b627", "url": "https://github.com/ExpediaGroup/circus-train/commit/b623630151a38a8a703747896485d295add8b627", "message": "Added tests for switch case, and removed comments", "committedDate": "2020-05-28T12:09:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434461002", "bodyText": "I think the TException could be thrown for other reasons too, like network problems etc. So perhaps it would be better to have a try/catch for TException that retrhrows a MetaStoreClientException like in some of the blocks below, and then introduce a \"does table exist\" check in the code (maybe in the service?) and if it doesn't then it just silently continues without throwing an exception (as this is fine, there's no need to drop the replica if it doesn't exist).", "author": "massdosage", "createdAt": "2020-06-03T10:15:58Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -302,6 +304,16 @@ public void updateMetadata(\n     LOG.info(\"Updating replica table metadata.\");\n     TableAndStatistics replicaTable = tableFactory\n         .newReplicaTable(eventId, sourceTable, replicaDatabaseName, replicaTableName, tableLocation, replicationMode);\n+\n+    if (replicationMode == FULL_OVERWRITE) {\n+      LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table and its data.\");\n+      DropTableService dropTableService = new DropTableService();\n+      try {\n+        dropTableService.removeTableParamsAndDrop(client, replicaDatabaseName, replicaTableName);\n+      } catch (TException e) {\n+        LOG.info(\"No replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' found. Nothing to delete.\");", "originalCommit": "b623630151a38a8a703747896485d295add8b627", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2Mzg0OA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434463848", "bodyText": "NoSuchObjectException is the one that get's throw if the table/db doesn't exist", "author": "patduin", "createdAt": "2020-06-03T10:21:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2NjYyMw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434466623", "bodyText": "OK, so we could have a more specific catch block for that here, or do we want to change the service to not throw that and silently continue? Do we have other cases that use it where we want that exception thrown?", "author": "massdosage", "createdAt": "2020-06-03T10:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2NjkzMg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434466932", "bodyText": "Yeah I also realised this. I have fixed it in the other branch I have for deleting data so its now:\n} catch (Exception e) {\n   LOG.info(\"Replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' was not dropped.\");\n}\n\nAnd in the drop table service it catches the NoSuchObj exception and logs that the table wasnt found.", "author": "JayGreeeen", "createdAt": "2020-06-03T10:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ3MDMyMA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434470320", "bodyText": "Do you want to update this branch too? The plan is to merge the branches in separately right? First this one to get the \"drop metadata\" changes in and then the other one gets the \"drop file data\" changes.", "author": "massdosage", "createdAt": "2020-06-03T10:33:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ3NDYxNQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434474615", "bodyText": "Yeah thats the plan. Will update this one with those logs \ud83d\udc4d", "author": "JayGreeeen", "createdAt": "2020-06-03T10:41:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ4MDU1NQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434480555", "bodyText": "I think it is ok that the DropTableService swallows the NoSuchObjectE. But then I agree with Adrian this block should catch and rethrow MetaStoreClientException. Don't log anything that's not up to this class to silently ignore this.", "author": "patduin", "createdAt": "2020-06-03T10:54:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5NjcxMw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434496713", "bodyText": "Thats a good point. Will log the NoSuchObj inside the dropTableService, and here will throw a MetaStoreClientExc in the catch.", "author": "JayGreeeen", "createdAt": "2020-06-03T11:27:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}], "type": "inlineReview", "revised_code": {"commit": "54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "chunk": "diff --git a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\nindex 2dbdf244..eba15cf3 100644\n--- a/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n+++ b/circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java\n\n@@ -311,7 +311,7 @@ public class Replica extends HiveEndpoint {\n       try {\n         dropTableService.removeTableParamsAndDrop(client, replicaDatabaseName, replicaTableName);\n       } catch (TException e) {\n-        LOG.info(\"No replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' found. Nothing to delete.\");\n+        LOG.info(\"Replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' was not dropped.\");\n       }\n     }\n     Optional<Table> oldReplicaTable = getTable(client, replicaDatabaseName, replicaTableName);\n"}}, {"oid": "54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "url": "https://github.com/ExpediaGroup/circus-train/commit/54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "message": "Changing log messages", "committedDate": "2020-06-03T10:43:20Z", "type": "commit"}, {"oid": "c985f96cb80fc03446388ef88e8e364b9c577d8a", "url": "https://github.com/ExpediaGroup/circus-train/commit/c985f96cb80fc03446388ef88e8e364b9c577d8a", "message": "Removing log to throw metastore client exception instead", "committedDate": "2020-06-03T11:28:03Z", "type": "commit"}]}