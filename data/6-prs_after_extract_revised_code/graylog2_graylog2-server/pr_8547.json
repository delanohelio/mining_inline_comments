{"pr_number": 8547, "pr_title": "Implement views code for ES7.", "pr_createdAt": "2020-07-15T11:38:26Z", "pr_url": "https://github.com/Graylog2/graylog2-server/pull/8547", "timeline": [{"oid": "7ddcd1b3ad5da708d8ed0038bd9f93cb5522fc52", "url": "https://github.com/Graylog2/graylog2-server/commit/7ddcd1b3ad5da708d8ed0038bd9f93cb5522fc52", "message": "Provide initial implementation of views code for ES7.", "committedDate": "2020-07-16T08:37:33Z", "type": "forcePushed"}, {"oid": "3fe7ef9c06ef228e047c735b88968c1977920929", "url": "https://github.com/Graylog2/graylog2-server/commit/3fe7ef9c06ef228e047c735b88968c1977920929", "message": "Removing support for multiple query backends based on type.", "committedDate": "2020-07-17T13:21:44Z", "type": "forcePushed"}, {"oid": "578db06e4b01c7987d08ef762916208e4c6e75cf", "url": "https://github.com/Graylog2/graylog2-server/commit/578db06e4b01c7987d08ef762916208e4c6e75cf", "message": "Adding backwards-compatible constructor.", "committedDate": "2020-07-20T12:24:18Z", "type": "forcePushed"}, {"oid": "f4a576a9297cc22656e65dbdcb954b048c8bb852", "url": "https://github.com/Graylog2/graylog2-server/commit/f4a576a9297cc22656e65dbdcb954b048c8bb852", "message": "Adding events index mapping for ES7.", "committedDate": "2020-07-21T13:38:51Z", "type": "forcePushed"}, {"oid": "e06354447723de4e186ca8fdea3318f49f15e835", "url": "https://github.com/Graylog2/graylog2-server/commit/e06354447723de4e186ca8fdea3318f49f15e835", "message": "Fixing extraction of document count from initial search result.", "committedDate": "2020-07-23T09:30:52Z", "type": "forcePushed"}, {"oid": "296206f46b7dc7957e00b46614440937670fa9e3", "url": "https://github.com/Graylog2/graylog2-server/commit/296206f46b7dc7957e00b46614440937670fa9e3", "message": "Fixing extraction of document count from initial search result.", "committedDate": "2020-07-23T13:16:35Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAxOTc1MA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458019750", "bodyText": "Unused. Can be deleted.", "author": "alex-konn", "createdAt": "2020-07-21T11:15:25Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7;\n+\n+import com.google.inject.Scopes;\n+import com.google.inject.TypeLiteral;\n+import com.google.inject.assistedinject.FactoryModuleBuilder;\n+import com.google.inject.binder.LinkedBindingBuilder;\n+import com.google.inject.binder.ScopedBindingBuilder;\n+import com.google.inject.multibindings.MapBinder;\n+import org.graylog.plugins.views.ViewsModule;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n+import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n+import org.graylog.plugins.views.search.engine.QueryBackend;\n+import org.graylog.plugins.views.search.export.ExportBackend;\n+import org.graylog.plugins.views.search.searchtypes.MessageList;\n+import org.graylog.plugins.views.search.searchtypes.events.EventList;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n+import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n+import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n+\n+import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n+\n+public class ViewsESBackendModule extends ViewsModule {\n+    @Override\n+    protected void configure() {\n+        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n+\n+        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n+                .to(ElasticsearchBackend.class);\n+\n+        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n+        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n+        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n+\n+        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n+        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n+        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n+        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n+        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n+        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n+        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n+        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n+        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n+        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n+\n+        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n+        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n+        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n+\n+        bindExportBackend().to(ElasticsearchExportBackend.class);\n+        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n+    }\n+\n+    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n+        return bind(RequestStrategy.class);\n+    }\n+\n+    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n+        return bindExportBackend(SUPPORTED_ES_VERSION);\n+    }\n+\n+    private void registerQueryBackend() {", "originalCommit": "578db06e4b01c7987d08ef762916208e4c6e75cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODQyMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968423", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAxOTc1MA=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\ndeleted file mode 100644\nindex 390052ae33..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\n+++ /dev/null\n\n@@ -1,156 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7;\n-\n-import com.google.inject.Scopes;\n-import com.google.inject.TypeLiteral;\n-import com.google.inject.assistedinject.FactoryModuleBuilder;\n-import com.google.inject.binder.LinkedBindingBuilder;\n-import com.google.inject.binder.ScopedBindingBuilder;\n-import com.google.inject.multibindings.MapBinder;\n-import org.graylog.plugins.views.ViewsModule;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n-import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n-import org.graylog.plugins.views.search.engine.QueryBackend;\n-import org.graylog.plugins.views.search.export.ExportBackend;\n-import org.graylog.plugins.views.search.searchtypes.MessageList;\n-import org.graylog.plugins.views.search.searchtypes.events.EventList;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n-import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n-import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n-\n-import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n-\n-public class ViewsESBackendModule extends ViewsModule {\n-    @Override\n-    protected void configure() {\n-        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n-\n-        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n-                .to(ElasticsearchBackend.class);\n-\n-        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n-        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n-        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n-\n-        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n-        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n-        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n-        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n-        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n-        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n-        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n-        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n-        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n-        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n-\n-        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n-        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n-        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n-\n-        bindExportBackend().to(ElasticsearchExportBackend.class);\n-        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n-    }\n-\n-    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n-        return bind(RequestStrategy.class);\n-    }\n-\n-    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n-        return bindExportBackend(SUPPORTED_ES_VERSION);\n-    }\n-\n-    private void registerQueryBackend() {\n-        registerQueryBackend(SUPPORTED_ES_VERSION, ElasticsearchQueryString.NAME, ElasticsearchBackend.class);\n-    }\n-\n-    private MapBinder<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> pivotBucketHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotBucketHandler(\n-            String name,\n-            Class<? extends ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotBucketHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    protected MapBinder<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> pivotSeriesHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotSeriesHandler(\n-            String name,\n-            Class<? extends ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotSeriesHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    private MapBinder<String, ESSearchTypeHandler<? extends SearchType>> esSearchTypeHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESSearchTypeHandler<? extends SearchType>>() {});\n-    }\n-\n-    private ScopedBindingBuilder registerESSearchTypeHandler(String name, Class<? extends ESSearchTypeHandler<? extends SearchType>> implementation) {\n-        return esSearchTypeHandlerBinder().addBinding(name).to(implementation);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NDIyMQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458084221", "bodyText": "Unused return value. Let's make this void to get rid of the warning.", "author": "alex-konn", "createdAt": "2020-07-21T13:12:14Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7;\n+\n+import com.google.inject.Scopes;\n+import com.google.inject.TypeLiteral;\n+import com.google.inject.assistedinject.FactoryModuleBuilder;\n+import com.google.inject.binder.LinkedBindingBuilder;\n+import com.google.inject.binder.ScopedBindingBuilder;\n+import com.google.inject.multibindings.MapBinder;\n+import org.graylog.plugins.views.ViewsModule;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n+import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n+import org.graylog.plugins.views.search.engine.QueryBackend;\n+import org.graylog.plugins.views.search.export.ExportBackend;\n+import org.graylog.plugins.views.search.searchtypes.MessageList;\n+import org.graylog.plugins.views.search.searchtypes.events.EventList;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n+import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n+import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n+\n+import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n+\n+public class ViewsESBackendModule extends ViewsModule {\n+    @Override\n+    protected void configure() {\n+        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n+\n+        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n+                .to(ElasticsearchBackend.class);\n+\n+        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n+        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n+        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n+\n+        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n+        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n+        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n+        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n+        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n+        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n+        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n+        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n+        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n+        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n+\n+        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n+        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n+        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n+\n+        bindExportBackend().to(ElasticsearchExportBackend.class);\n+        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n+    }\n+\n+    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n+        return bind(RequestStrategy.class);\n+    }\n+\n+    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n+        return bindExportBackend(SUPPORTED_ES_VERSION);\n+    }\n+\n+    private void registerQueryBackend() {\n+        registerQueryBackend(SUPPORTED_ES_VERSION, ElasticsearchQueryString.NAME, ElasticsearchBackend.class);\n+    }\n+\n+    private MapBinder<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> pivotBucketHandlerBinder() {\n+        return MapBinder.newMapBinder(binder(),\n+                TypeLiteral.get(String.class),\n+                new TypeLiteral<ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>>() {});\n+\n+    }\n+\n+    private ScopedBindingBuilder registerPivotBucketHandler(", "originalCommit": "578db06e4b01c7987d08ef762916208e4c6e75cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODQxMg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968412", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NDIyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\ndeleted file mode 100644\nindex 390052ae33..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\n+++ /dev/null\n\n@@ -1,156 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7;\n-\n-import com.google.inject.Scopes;\n-import com.google.inject.TypeLiteral;\n-import com.google.inject.assistedinject.FactoryModuleBuilder;\n-import com.google.inject.binder.LinkedBindingBuilder;\n-import com.google.inject.binder.ScopedBindingBuilder;\n-import com.google.inject.multibindings.MapBinder;\n-import org.graylog.plugins.views.ViewsModule;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n-import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n-import org.graylog.plugins.views.search.engine.QueryBackend;\n-import org.graylog.plugins.views.search.export.ExportBackend;\n-import org.graylog.plugins.views.search.searchtypes.MessageList;\n-import org.graylog.plugins.views.search.searchtypes.events.EventList;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n-import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n-import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n-\n-import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n-\n-public class ViewsESBackendModule extends ViewsModule {\n-    @Override\n-    protected void configure() {\n-        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n-\n-        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n-                .to(ElasticsearchBackend.class);\n-\n-        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n-        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n-        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n-\n-        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n-        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n-        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n-        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n-        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n-        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n-        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n-        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n-        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n-        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n-\n-        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n-        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n-        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n-\n-        bindExportBackend().to(ElasticsearchExportBackend.class);\n-        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n-    }\n-\n-    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n-        return bind(RequestStrategy.class);\n-    }\n-\n-    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n-        return bindExportBackend(SUPPORTED_ES_VERSION);\n-    }\n-\n-    private void registerQueryBackend() {\n-        registerQueryBackend(SUPPORTED_ES_VERSION, ElasticsearchQueryString.NAME, ElasticsearchBackend.class);\n-    }\n-\n-    private MapBinder<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> pivotBucketHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotBucketHandler(\n-            String name,\n-            Class<? extends ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotBucketHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    protected MapBinder<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> pivotSeriesHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotSeriesHandler(\n-            String name,\n-            Class<? extends ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotSeriesHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    private MapBinder<String, ESSearchTypeHandler<? extends SearchType>> esSearchTypeHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESSearchTypeHandler<? extends SearchType>>() {});\n-    }\n-\n-    private ScopedBindingBuilder registerESSearchTypeHandler(String name, Class<? extends ESSearchTypeHandler<? extends SearchType>> implementation) {\n-        return esSearchTypeHandlerBinder().addBinding(name).to(implementation);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NDMwMA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458084300", "bodyText": "Unused return value. Let's make this void to get rid of the warning.", "author": "alex-konn", "createdAt": "2020-07-21T13:12:20Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7;\n+\n+import com.google.inject.Scopes;\n+import com.google.inject.TypeLiteral;\n+import com.google.inject.assistedinject.FactoryModuleBuilder;\n+import com.google.inject.binder.LinkedBindingBuilder;\n+import com.google.inject.binder.ScopedBindingBuilder;\n+import com.google.inject.multibindings.MapBinder;\n+import org.graylog.plugins.views.ViewsModule;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n+import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n+import org.graylog.plugins.views.search.engine.QueryBackend;\n+import org.graylog.plugins.views.search.export.ExportBackend;\n+import org.graylog.plugins.views.search.searchtypes.MessageList;\n+import org.graylog.plugins.views.search.searchtypes.events.EventList;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n+import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n+import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n+import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n+\n+import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n+\n+public class ViewsESBackendModule extends ViewsModule {\n+    @Override\n+    protected void configure() {\n+        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n+\n+        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n+                .to(ElasticsearchBackend.class);\n+\n+        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n+        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n+        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n+\n+        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n+        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n+        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n+        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n+        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n+        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n+        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n+        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n+        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n+        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n+\n+        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n+        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n+        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n+\n+        bindExportBackend().to(ElasticsearchExportBackend.class);\n+        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n+    }\n+\n+    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n+        return bind(RequestStrategy.class);\n+    }\n+\n+    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n+        return bindExportBackend(SUPPORTED_ES_VERSION);\n+    }\n+\n+    private void registerQueryBackend() {\n+        registerQueryBackend(SUPPORTED_ES_VERSION, ElasticsearchQueryString.NAME, ElasticsearchBackend.class);\n+    }\n+\n+    private MapBinder<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> pivotBucketHandlerBinder() {\n+        return MapBinder.newMapBinder(binder(),\n+                TypeLiteral.get(String.class),\n+                new TypeLiteral<ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>>() {});\n+\n+    }\n+\n+    private ScopedBindingBuilder registerPivotBucketHandler(\n+            String name,\n+            Class<? extends ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> implementation\n+    ) {\n+        return pivotBucketHandlerBinder().addBinding(name).to(implementation);\n+    }\n+\n+    protected MapBinder<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> pivotSeriesHandlerBinder() {\n+        return MapBinder.newMapBinder(binder(),\n+                TypeLiteral.get(String.class),\n+                new TypeLiteral<ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>>() {});\n+\n+    }\n+\n+    private ScopedBindingBuilder registerPivotSeriesHandler(", "originalCommit": "578db06e4b01c7987d08ef762916208e4c6e75cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODQwNA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968404", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NDMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\ndeleted file mode 100644\nindex 390052ae33..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/ViewsESBackendModule.java\n+++ /dev/null\n\n@@ -1,156 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7;\n-\n-import com.google.inject.Scopes;\n-import com.google.inject.TypeLiteral;\n-import com.google.inject.assistedinject.FactoryModuleBuilder;\n-import com.google.inject.binder.LinkedBindingBuilder;\n-import com.google.inject.binder.ScopedBindingBuilder;\n-import com.google.inject.multibindings.MapBinder;\n-import org.graylog.plugins.views.ViewsModule;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n-import org.graylog.plugins.views.search.engine.GeneratedQueryContext;\n-import org.graylog.plugins.views.search.engine.QueryBackend;\n-import org.graylog.plugins.views.search.export.ExportBackend;\n-import org.graylog.plugins.views.search.searchtypes.MessageList;\n-import org.graylog.plugins.views.search.searchtypes.events.EventList;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.DateRangeBucket;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Time;\n-import org.graylog.plugins.views.search.searchtypes.pivot.buckets.Values;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Cardinality;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Min;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Percentile;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.StdDev;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Sum;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.SumOfSquares;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Variance;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.ElasticsearchBackend;\n-import org.graylog.storage.elasticsearch7.views.export.ElasticsearchExportBackend;\n-import org.graylog.storage.elasticsearch7.views.export.RequestStrategy;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESEventList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESMessageList;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESDateRangeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESTimeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.buckets.ESValuesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCardinalityHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESCountHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMinHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESPercentilesHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESStdDevHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESSumOfSquaresHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESVarianceHandler;\n-\n-import static org.graylog.storage.elasticsearch7.Elasticsearch7Plugin.SUPPORTED_ES_VERSION;\n-\n-public class ViewsESBackendModule extends ViewsModule {\n-    @Override\n-    protected void configure() {\n-        install(new FactoryModuleBuilder().build(ESGeneratedQueryContext.Factory.class));\n-\n-        bindForVersion(SUPPORTED_ES_VERSION, new TypeLiteral<QueryBackend<? extends GeneratedQueryContext>>() {})\n-                .to(ElasticsearchBackend.class);\n-\n-        registerESSearchTypeHandler(MessageList.NAME, ESMessageList.class);\n-        registerESSearchTypeHandler(EventList.NAME, ESEventList.class);\n-        registerESSearchTypeHandler(Pivot.NAME, ESPivot.class).in(Scopes.SINGLETON);\n-\n-        registerPivotSeriesHandler(Average.NAME, ESAverageHandler.class);\n-        registerPivotSeriesHandler(Cardinality.NAME, ESCardinalityHandler.class);\n-        registerPivotSeriesHandler(Count.NAME, ESCountHandler.class);\n-        registerPivotSeriesHandler(Max.NAME, ESMaxHandler.class);\n-        registerPivotSeriesHandler(Min.NAME, ESMinHandler.class);\n-        registerPivotSeriesHandler(StdDev.NAME, ESStdDevHandler.class);\n-        registerPivotSeriesHandler(Sum.NAME, ESSumHandler.class);\n-        registerPivotSeriesHandler(SumOfSquares.NAME, ESSumOfSquaresHandler.class);\n-        registerPivotSeriesHandler(Variance.NAME, ESVarianceHandler.class);\n-        registerPivotSeriesHandler(Percentile.NAME, ESPercentilesHandler.class);\n-\n-        registerPivotBucketHandler(Values.NAME, ESValuesHandler.class);\n-        registerPivotBucketHandler(Time.NAME, ESTimeHandler.class);\n-        registerPivotBucketHandler(DateRangeBucket.NAME, ESDateRangeHandler.class);\n-\n-        bindExportBackend().to(ElasticsearchExportBackend.class);\n-        bindRequestStrategy().to(org.graylog.storage.elasticsearch7.views.export.Scroll.class);\n-    }\n-\n-    private LinkedBindingBuilder<RequestStrategy> bindRequestStrategy() {\n-        return bind(RequestStrategy.class);\n-    }\n-\n-    private LinkedBindingBuilder<ExportBackend> bindExportBackend() {\n-        return bindExportBackend(SUPPORTED_ES_VERSION);\n-    }\n-\n-    private void registerQueryBackend() {\n-        registerQueryBackend(SUPPORTED_ES_VERSION, ElasticsearchQueryString.NAME, ElasticsearchBackend.class);\n-    }\n-\n-    private MapBinder<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> pivotBucketHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotBucketHandler(\n-            String name,\n-            Class<? extends ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotBucketHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    protected MapBinder<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> pivotSeriesHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>>() {});\n-\n-    }\n-\n-    private ScopedBindingBuilder registerPivotSeriesHandler(\n-            String name,\n-            Class<? extends ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> implementation\n-    ) {\n-        return pivotSeriesHandlerBinder().addBinding(name).to(implementation);\n-    }\n-\n-    private MapBinder<String, ESSearchTypeHandler<? extends SearchType>> esSearchTypeHandlerBinder() {\n-        return MapBinder.newMapBinder(binder(),\n-                TypeLiteral.get(String.class),\n-                new TypeLiteral<ESSearchTypeHandler<? extends SearchType>>() {});\n-    }\n-\n-    private ScopedBindingBuilder registerESSearchTypeHandler(String name, Class<? extends ESSearchTypeHandler<? extends SearchType>> implementation) {\n-        return esSearchTypeHandlerBinder().addBinding(name).to(implementation);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODg3NA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458768874", "bodyText": "Can be private", "author": "alex-konn", "createdAt": "2020-07-22T12:53:53Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes;\n+\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.searchtypes.events.EventList;\n+import org.graylog.plugins.views.search.searchtypes.events.EventSummary;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.SearchHit;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class ESEventList implements ESSearchTypeHandler<EventList> {\n+    @Override\n+    public void doGenerateQueryPart(SearchJob job, Query query, EventList eventList,\n+                                    ESGeneratedQueryContext queryContext) {\n+        queryContext.searchSourceBuilder(eventList)\n+                .size(10000);\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    protected List<Map<String, Object>> extractResult(SearchResponse result) {", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2NTU0MA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459965540", "bodyText": "ESEventListTest is overriding this method.", "author": "dennisoelkers", "createdAt": "2020-07-24T10:08:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODg3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDAxNjIwNg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r460016206", "bodyText": "Oops. Right. Sorry I overlooked that.", "author": "alex-konn", "createdAt": "2020-07-24T12:16:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODg3NA=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java\ndeleted file mode 100644\nindex 1dfd54cd2a..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java\n+++ /dev/null\n\n@@ -1,67 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes;\n-\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.searchtypes.events.EventList;\n-import org.graylog.plugins.views.search.searchtypes.events.EventSummary;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.SearchHit;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.stream.Collectors;\n-import java.util.stream.StreamSupport;\n-\n-public class ESEventList implements ESSearchTypeHandler<EventList> {\n-    @Override\n-    public void doGenerateQueryPart(SearchJob job, Query query, EventList eventList,\n-                                    ESGeneratedQueryContext queryContext) {\n-        queryContext.searchSourceBuilder(eventList)\n-                .size(10000);\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    protected List<Map<String, Object>> extractResult(SearchResponse result) {\n-        return StreamSupport.stream(result.getHits().spliterator(), false)\n-                .map(SearchHit::getSourceAsMap)\n-                .collect(Collectors.toList());\n-    }\n-\n-    @Override\n-    public SearchType.Result doExtractResult(SearchJob job, Query query, EventList searchType, SearchResponse result,\n-                                             Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final Set<String> effectiveStreams = searchType.streams().isEmpty()\n-                ? query.usedStreamIds()\n-                : searchType.streams();\n-        final List<EventSummary> eventSummaries = extractResult(result).stream()\n-                .map(EventSummary::parse)\n-                .filter(eventSummary -> effectiveStreams.containsAll(eventSummary.streams()))\n-                .collect(Collectors.toList());\n-        final EventList.Result.Builder resultBuilder = EventList.Result.builder()\n-                .events(eventSummaries)\n-                .id(searchType.id());\n-        searchType.name().ifPresent(resultBuilder::name);\n-        return resultBuilder\n-                .build();\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODk0NA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458768944", "bodyText": "Unnecessary suppression", "author": "alex-konn", "createdAt": "2020-07-22T12:54:02Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes;\n+\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.searchtypes.events.EventList;\n+import org.graylog.plugins.views.search.searchtypes.events.EventSummary;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.SearchHit;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class ESEventList implements ESSearchTypeHandler<EventList> {\n+    @Override\n+    public void doGenerateQueryPart(SearchJob job, Query query, EventList eventList,\n+                                    ESGeneratedQueryContext queryContext) {\n+        queryContext.searchSourceBuilder(eventList)\n+                .size(10000);\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODM5Mw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968393", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODk0NA=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java\ndeleted file mode 100644\nindex 1dfd54cd2a..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/ESEventList.java\n+++ /dev/null\n\n@@ -1,67 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes;\n-\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.searchtypes.events.EventList;\n-import org.graylog.plugins.views.search.searchtypes.events.EventSummary;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.SearchHit;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.stream.Collectors;\n-import java.util.stream.StreamSupport;\n-\n-public class ESEventList implements ESSearchTypeHandler<EventList> {\n-    @Override\n-    public void doGenerateQueryPart(SearchJob job, Query query, EventList eventList,\n-                                    ESGeneratedQueryContext queryContext) {\n-        queryContext.searchSourceBuilder(eventList)\n-                .size(10000);\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    protected List<Map<String, Object>> extractResult(SearchResponse result) {\n-        return StreamSupport.stream(result.getHits().spliterator(), false)\n-                .map(SearchHit::getSourceAsMap)\n-                .collect(Collectors.toList());\n-    }\n-\n-    @Override\n-    public SearchType.Result doExtractResult(SearchJob job, Query query, EventList searchType, SearchResponse result,\n-                                             Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final Set<String> effectiveStreams = searchType.streams().isEmpty()\n-                ? query.usedStreamIds()\n-                : searchType.streams();\n-        final List<EventSummary> eventSummaries = extractResult(result).stream()\n-                .map(EventSummary::parse)\n-                .filter(eventSummary -> effectiveStreams.containsAll(eventSummary.streams()))\n-                .collect(Collectors.toList());\n-        final EventList.Result.Builder resultBuilder = EventList.Result.builder()\n-                .events(eventSummaries)\n-                .id(searchType.id());\n-        searchType.name().ifPresent(resultBuilder::name);\n-        return resultBuilder\n-                .build();\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3MDQxNg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458770416", "bodyText": "previousAggregation can only be null here", "author": "alex-konn", "createdAt": "2020-07-22T12:56:29Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java", "diffHunk": "@@ -0,0 +1,385 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import one.util.streamex.EntryStream;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.jooq.lambda.tuple.Tuple;\n+import org.jooq.lambda.tuple.Tuple2;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.ArrayDeque;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Stream;\n+\n+public class ESPivot implements ESSearchTypeHandler<Pivot> {\n+    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n+    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n+    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n+    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n+\n+    private static TimeRange allMessagesTimeRange() {\n+        try {\n+            return RelativeRange.create(0);\n+        } catch (InvalidRangeParametersException e){\n+            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n+        }\n+        return null;\n+    }\n+\n+    @Inject\n+    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n+                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n+        this.bucketHandlers = bucketHandlers;\n+        this.seriesHandlers = seriesHandlers;\n+    }\n+\n+    @Override\n+    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n+        LOG.debug(\"Generating aggregation for {}\", pivot);\n+        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n+\n+        final Map<Object, Object> contextMap = queryContext.contextMap();\n+        final AggTypes aggTypes = new AggTypes();\n+        contextMap.put(pivot.id(), aggTypes);\n+\n+        // holds the initial level aggregation to be added to the query\n+        AggregationBuilder topLevelAggregation = null;\n+        // holds the last complete bucket aggregation into which subsequent buckets get added\n+        AggregationBuilder previousAggregation = null;\n+\n+        // add global rollup series if those were requested\n+        if (pivot.rollup()) {\n+            seriesStream(pivot, queryContext, \"global rollup\")\n+                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODM2MA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968360", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3MDQxNg=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\ndeleted file mode 100644\nindex 2c9923c598..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\n+++ /dev/null\n\n@@ -1,385 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n-\n-import com.google.common.base.Preconditions;\n-import com.google.common.collect.ImmutableList;\n-import one.util.streamex.EntryStream;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.joda.time.DateTime;\n-import org.joda.time.DateTimeZone;\n-import org.jooq.lambda.tuple.Tuple;\n-import org.jooq.lambda.tuple.Tuple2;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.inject.Inject;\n-import java.util.ArrayDeque;\n-import java.util.IdentityHashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.Stream;\n-\n-public class ESPivot implements ESSearchTypeHandler<Pivot> {\n-    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n-    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n-    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n-    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n-\n-    private static TimeRange allMessagesTimeRange() {\n-        try {\n-            return RelativeRange.create(0);\n-        } catch (InvalidRangeParametersException e){\n-            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n-        }\n-        return null;\n-    }\n-\n-    @Inject\n-    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n-                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n-        this.bucketHandlers = bucketHandlers;\n-        this.seriesHandlers = seriesHandlers;\n-    }\n-\n-    @Override\n-    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        LOG.debug(\"Generating aggregation for {}\", pivot);\n-        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n-\n-        final Map<Object, Object> contextMap = queryContext.contextMap();\n-        final AggTypes aggTypes = new AggTypes();\n-        contextMap.put(pivot.id(), aggTypes);\n-\n-        // holds the initial level aggregation to be added to the query\n-        AggregationBuilder topLevelAggregation = null;\n-        // holds the last complete bucket aggregation into which subsequent buckets get added\n-        AggregationBuilder previousAggregation = null;\n-\n-        // add global rollup series if those were requested\n-        if (pivot.rollup()) {\n-            seriesStream(pivot, queryContext, \"global rollup\")\n-                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);\n-        }\n-\n-        final Iterator<BucketSpec> rowBuckets = pivot.rowGroups().iterator();\n-        while (rowBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = rowBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating row group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown row_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                if (topLevelAggregation == null) {\n-                    topLevelAggregation = aggregationBuilder;\n-                }\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!rowBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !rowBuckets.hasNext() ? \"leaf row\" : \"row rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-        final Iterator<BucketSpec> colBuckets = pivot.columnGroups().iterator();\n-        while (colBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = colBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating column group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown column_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!colBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !colBuckets.hasNext() ? \"leaf column\" : \"column rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-\n-        final MinAggregationBuilder startTimestamp = AggregationBuilders.min(\"timestamp-min\").field(\"timestamp\");\n-        final MaxAggregationBuilder endTimestamp = AggregationBuilders.max(\"timestamp-max\").field(\"timestamp\");\n-\n-        searchSourceBuilder.aggregation(startTimestamp);\n-        searchSourceBuilder.aggregation(endTimestamp);\n-\n-        if (topLevelAggregation == null) {\n-            LOG.debug(\"No aggregations generated for {}\", pivot);\n-        }\n-    }\n-\n-    private Stream<AggregationBuilder> seriesStream(Pivot pivot, ESGeneratedQueryContext queryContext, String reason) {\n-        return EntryStream.of(pivot.series())\n-                .mapKeyValue((integer, seriesSpec) -> {\n-                    final String seriesName = queryContext.seriesName(seriesSpec, pivot);\n-                    LOG.debug(\"Adding {} series '{}' with name '{}'\", reason, seriesSpec.type(), seriesName);\n-                    final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> esPivotSeriesSpecHandler = seriesHandlers.get(seriesSpec.type());\n-                    if (esPivotSeriesSpecHandler == null) {\n-                        throw new IllegalArgumentException(\"No series handler registered for: \" + seriesSpec.type());\n-                    }\n-                    return esPivotSeriesSpecHandler.createAggregation(seriesName, pivot, seriesSpec, this, queryContext);\n-                })\n-                .filter(Optional::isPresent)\n-                .map(Optional::get);\n-    }\n-\n-    private boolean isAllMessagesTimeRange(TimeRange timeRange) {\n-        return ALL_MESSAGES_TIMERANGE.equals(timeRange);\n-    }\n-\n-    private AbsoluteRange extractEffectiveTimeRange(SearchResponse queryResult, Query query, Pivot pivot) {\n-        final Min min = queryResult.getAggregations().get(\"timestamp-min\");\n-        final Double from = min.getValue();\n-        final Max max = queryResult.getAggregations().get(\"timestamp-max\");\n-        final Double to = max.getValue();\n-        final TimeRange pivotRange = query.effectiveTimeRange(pivot);\n-        return AbsoluteRange.create(\n-                isAllMessagesTimeRange(pivotRange) && from != 0\n-                        ? new DateTime(from.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getFrom(),\n-                isAllMessagesTimeRange(pivotRange) && to != 0\n-                        ? new DateTime(to.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getTo()\n-        );\n-    }\n-\n-    @Override\n-    public SearchType.Result doExtractResult(SearchJob job, Query query, Pivot pivot, SearchResponse queryResult, Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final AbsoluteRange effectiveTimerange = extractEffectiveTimeRange(queryResult, query, pivot);\n-\n-        final PivotResult.Builder resultBuilder = PivotResult.builder()\n-                .id(pivot.id())\n-                .effectiveTimerange(effectiveTimerange)\n-                .total(extractDocumentCount(queryResult, pivot, queryContext));\n-\n-        // pivot results are a table where cells can contain multiple \"values\" and not only scalars:\n-        // each combination of row and column groups can contain all series (if rollup is true)\n-        // if rollup is false, only the \"leaf\" components contain the series\n-        // in the elasticsearch result, rows and columns are simply nested aggregations (first aggregations from rows, then from columns)\n-        // with metric aggregations on the corresponding levels.\n-        // first we iterate over all row groups (whose values generate a \"key array\", corresponding to the nesting level)\n-        // once we exhaust the row groups, we descend into the columns, which get added as values to their corresponding rows\n-        // on each nesting level and combination we have to check for series which we also add as values to the containing row\n-        final HasAggregations initialResult = createInitialResult(queryResult);\n-\n-        processRows(resultBuilder, queryResult, queryContext, pivot, pivot.rowGroups(), new ArrayDeque<>(), initialResult);\n-\n-        return pivot.name().map(resultBuilder::name).orElse(resultBuilder).build();\n-    }\n-\n-    private HasAggregations createInitialResult(SearchResponse queryResult) {\n-        return InitialBucket.create(queryResult);\n-    }\n-\n-    private long extractDocumentCount(SearchResponse queryResult, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        return queryResult.getHits().getTotalHits().value;\n-    }\n-\n-    /*\n-        results from elasticsearch are nested so we need to recurse into the aggregation tree, but our result is a table, thus we need\n-        to keep track of the current row keys manually\n-         */\n-    private void processRows(PivotResult.Builder resultBuilder,\n-                             SearchResponse searchResult,\n-                             ESGeneratedQueryContext queryContext,\n-                             Pivot pivot,\n-                             List<BucketSpec> remainingRows,\n-                             ArrayDeque<String> rowKeys,\n-                             HasAggregations aggregation) {\n-        if (remainingRows.isEmpty()) {\n-            // this is the last row group, so we need to fork into the columns if they exist.\n-            // being here also means that `rowKeys` contains the maximum number of parts, one for each combination of row bucket keys\n-            // we will always add the series for this bucket, because that's the entire point of row groups\n-\n-            final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-            // do the same for columns as we did for the rows\n-            processColumns(rowBuilder, searchResult, queryContext, pivot, pivot.columnGroups(), new ArrayDeque<>(), aggregation);\n-\n-            // also add the series for the entire row\n-            // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-            if (pivot.rollup()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-leaf\");\n-            }\n-            resultBuilder.addRow(rowBuilder.source(\"leaf\").build());\n-        } else {\n-            // this is not a leaf for the rows, so we add its key to the rowKeys and descend into the aggregation tree\n-            // afterwards we'll check if we need to add rollup for intermediate buckets. not all clients need them so they can request\n-            // to not calculate them\n-            final BucketSpec currentBucket = remainingRows.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-            // for each bucket, recurse and eventually collect all the row keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                rowKeys.addLast(bucket.key());\n-                processRows(resultBuilder, searchResult, queryContext, pivot, tail(remainingRows), rowKeys, bucket.aggregation());\n-                rowKeys.removeLast();\n-            });\n-            // also add the series for this row key if the client wants rollups\n-            if (pivot.rollup()) {\n-                final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-                // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-inner\");\n-                resultBuilder.addRow(rowBuilder.source(\"non-leaf\").build());\n-            }\n-\n-        }\n-    }\n-\n-    private void processColumns(PivotResult.Row.Builder rowBuilder,\n-                                SearchResponse searchResult,\n-                                ESGeneratedQueryContext queryContext,\n-                                Pivot pivot,\n-                                List<BucketSpec> remainingColumns,\n-                                ArrayDeque<String> columnKeys,\n-                                HasAggregations aggregation) {\n-        if (remainingColumns.isEmpty()) {\n-            // this is the leaf cell of the pivot table, simply add all the series for the complete column key array\n-            // in the rollup: false case, this is the only set of series that is going to be added to the result\n-            // if we simply don't have any column groups, then don't bother adding the series, this is the special case that\n-            // only row grouping was requested, and the rollup for rows is automatically added anyway. otherwise we'll end up\n-            // with duplicate data entries\n-            if (!columnKeys.isEmpty()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, false, \"col-leaf\");\n-            }\n-        } else {\n-            // for a non-leaf column group, we need to recurse further into the aggregation tree\n-            // and if rollup was requested we'll add intermediate series according to the column keys\n-            final BucketSpec currentBucket = remainingColumns.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-\n-            // for each bucket, recurse and eventually collect all the column keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                columnKeys.addLast(bucket.key());\n-                processColumns(rowBuilder, searchResult, queryContext, pivot, tail(remainingColumns), columnKeys, bucket.aggregation());\n-                columnKeys.removeLast();\n-            });\n-            // also add the series for the base column key if the client wants rollups, the complete column key is processed in the leaf branch\n-            // don't add the empty column key rollup, because that's not the correct bucket here, it's being done in the row-leaf code\n-            if (pivot.rollup() && !columnKeys.isEmpty()) {\n-                // columnKeys is not empty, because this is a rollup per column in a row\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, true, \"col-inner\");\n-            }\n-\n-        }\n-    }\n-\n-    private void processSeries(PivotResult.Row.Builder rowBuilder,\n-                               SearchResponse searchResult,\n-                               ESGeneratedQueryContext queryContext,\n-                               Pivot pivot,\n-                               ArrayDeque<String> columnKeys,\n-                               HasAggregations aggregation,\n-                               boolean rollup,\n-                               String source) {\n-        pivot.series().forEach(seriesSpec -> {\n-            final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> seriesHandler = seriesHandlers.get(seriesSpec.type());\n-            final Aggregation series = seriesHandler.extractAggregationFromResult(pivot, seriesSpec, aggregation, queryContext);\n-            seriesHandler.handleResult(pivot, seriesSpec, searchResult, series, this, queryContext)\n-                    .map(value -> {\n-                        columnKeys.addLast(value.id());\n-                        final PivotResult.Value v = PivotResult.Value.create(columnKeys, value.value(), rollup, source);\n-                        columnKeys.removeLast();\n-                        return v;\n-                    })\n-                    .forEach(rowBuilder::addValue);\n-        });\n-    }\n-\n-    private static <T> List<T> tail(List<T> list) {\n-        Preconditions.checkArgument(!list.isEmpty(), \"List must not be empty!\");\n-        return list.subList(1, list.size());\n-    }\n-\n-    /**\n-     * This solely exists to hide the nasty type signature of the aggregation type map from the rest of the code.\n-     * It's just ugly and in the way.\n-     */\n-    public static class AggTypes {\n-        final IdentityHashMap<PivotSpec, Tuple2<String, Class<? extends Aggregation>>> aggTypeMap = new IdentityHashMap<>();\n-\n-        public void record(PivotSpec pivotSpec, String name, Class<? extends Aggregation> aggClass) {\n-            aggTypeMap.put(pivotSpec, Tuple.tuple(name, aggClass));\n-        }\n-\n-        public Aggregation getSubAggregation(PivotSpec pivotSpec, HasAggregations currentAggregationOrBucket) {\n-            final Tuple2<String, Class<? extends Aggregation>> tuple2 = getTypes(pivotSpec);\n-            return currentAggregationOrBucket.getAggregations().get(tuple2.v1);\n-        }\n-\n-        public Tuple2<String, Class<? extends Aggregation>> getTypes(PivotSpec pivotSpec) {\n-            return aggTypeMap.get(pivotSpec);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgyNDEzMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458824133", "bodyText": "I don't understand why we need the InitialBucket class here, if all we are interested in subsequently is SearchResponse#getAggregations.", "author": "alex-konn", "createdAt": "2020-07-22T14:14:03Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java", "diffHunk": "@@ -0,0 +1,385 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import one.util.streamex.EntryStream;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.jooq.lambda.tuple.Tuple;\n+import org.jooq.lambda.tuple.Tuple2;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.ArrayDeque;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Stream;\n+\n+public class ESPivot implements ESSearchTypeHandler<Pivot> {\n+    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n+    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n+    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n+    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n+\n+    private static TimeRange allMessagesTimeRange() {\n+        try {\n+            return RelativeRange.create(0);\n+        } catch (InvalidRangeParametersException e){\n+            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n+        }\n+        return null;\n+    }\n+\n+    @Inject\n+    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n+                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n+        this.bucketHandlers = bucketHandlers;\n+        this.seriesHandlers = seriesHandlers;\n+    }\n+\n+    @Override\n+    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n+        LOG.debug(\"Generating aggregation for {}\", pivot);\n+        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n+\n+        final Map<Object, Object> contextMap = queryContext.contextMap();\n+        final AggTypes aggTypes = new AggTypes();\n+        contextMap.put(pivot.id(), aggTypes);\n+\n+        // holds the initial level aggregation to be added to the query\n+        AggregationBuilder topLevelAggregation = null;\n+        // holds the last complete bucket aggregation into which subsequent buckets get added\n+        AggregationBuilder previousAggregation = null;\n+\n+        // add global rollup series if those were requested\n+        if (pivot.rollup()) {\n+            seriesStream(pivot, queryContext, \"global rollup\")\n+                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);\n+        }\n+\n+        final Iterator<BucketSpec> rowBuckets = pivot.rowGroups().iterator();\n+        while (rowBuckets.hasNext()) {\n+            final BucketSpec bucketSpec = rowBuckets.next();\n+\n+            final String name = queryContext.nextName();\n+            LOG.debug(\"Creating row group aggregation '{}' as {}\", bucketSpec.type(), name);\n+            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n+            if (handler == null) {\n+                throw new IllegalArgumentException(\"Unknown row_group type \" + bucketSpec.type());\n+            }\n+            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n+            if (generatedAggregation.isPresent()) {\n+                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n+                if (topLevelAggregation == null) {\n+                    topLevelAggregation = aggregationBuilder;\n+                }\n+                // always insert the series for the final row group, or for each one if explicit rollup was requested\n+                if (!rowBuckets.hasNext() || pivot.rollup()) {\n+                    seriesStream(pivot, queryContext, !rowBuckets.hasNext() ? \"leaf row\" : \"row rollup\")\n+                            .forEach(aggregationBuilder::subAggregation);\n+                }\n+                if (previousAggregation != null) {\n+                    previousAggregation.subAggregation(aggregationBuilder);\n+                } else {\n+                    searchSourceBuilder.aggregation(aggregationBuilder);\n+                }\n+                previousAggregation = aggregationBuilder;\n+            }\n+        }\n+        final Iterator<BucketSpec> colBuckets = pivot.columnGroups().iterator();\n+        while (colBuckets.hasNext()) {\n+            final BucketSpec bucketSpec = colBuckets.next();\n+\n+            final String name = queryContext.nextName();\n+            LOG.debug(\"Creating column group aggregation '{}' as {}\", bucketSpec.type(), name);\n+            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n+            if (handler == null) {\n+                throw new IllegalArgumentException(\"Unknown column_group type \" + bucketSpec.type());\n+            }\n+            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n+            if (generatedAggregation.isPresent()) {\n+                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n+                // always insert the series for the final row group, or for each one if explicit rollup was requested\n+                if (!colBuckets.hasNext() || pivot.rollup()) {\n+                    seriesStream(pivot, queryContext, !colBuckets.hasNext() ? \"leaf column\" : \"column rollup\")\n+                            .forEach(aggregationBuilder::subAggregation);\n+                }\n+                if (previousAggregation != null) {\n+                    previousAggregation.subAggregation(aggregationBuilder);\n+                } else {\n+                    searchSourceBuilder.aggregation(aggregationBuilder);\n+                }\n+                previousAggregation = aggregationBuilder;\n+            }\n+        }\n+\n+        final MinAggregationBuilder startTimestamp = AggregationBuilders.min(\"timestamp-min\").field(\"timestamp\");\n+        final MaxAggregationBuilder endTimestamp = AggregationBuilders.max(\"timestamp-max\").field(\"timestamp\");\n+\n+        searchSourceBuilder.aggregation(startTimestamp);\n+        searchSourceBuilder.aggregation(endTimestamp);\n+\n+        if (topLevelAggregation == null) {\n+            LOG.debug(\"No aggregations generated for {}\", pivot);\n+        }\n+    }\n+\n+    private Stream<AggregationBuilder> seriesStream(Pivot pivot, ESGeneratedQueryContext queryContext, String reason) {\n+        return EntryStream.of(pivot.series())\n+                .mapKeyValue((integer, seriesSpec) -> {\n+                    final String seriesName = queryContext.seriesName(seriesSpec, pivot);\n+                    LOG.debug(\"Adding {} series '{}' with name '{}'\", reason, seriesSpec.type(), seriesName);\n+                    final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> esPivotSeriesSpecHandler = seriesHandlers.get(seriesSpec.type());\n+                    if (esPivotSeriesSpecHandler == null) {\n+                        throw new IllegalArgumentException(\"No series handler registered for: \" + seriesSpec.type());\n+                    }\n+                    return esPivotSeriesSpecHandler.createAggregation(seriesName, pivot, seriesSpec, this, queryContext);\n+                })\n+                .filter(Optional::isPresent)\n+                .map(Optional::get);\n+    }\n+\n+    private boolean isAllMessagesTimeRange(TimeRange timeRange) {\n+        return ALL_MESSAGES_TIMERANGE.equals(timeRange);\n+    }\n+\n+    private AbsoluteRange extractEffectiveTimeRange(SearchResponse queryResult, Query query, Pivot pivot) {\n+        final Min min = queryResult.getAggregations().get(\"timestamp-min\");\n+        final Double from = min.getValue();\n+        final Max max = queryResult.getAggregations().get(\"timestamp-max\");\n+        final Double to = max.getValue();\n+        final TimeRange pivotRange = query.effectiveTimeRange(pivot);\n+        return AbsoluteRange.create(\n+                isAllMessagesTimeRange(pivotRange) && from != 0\n+                        ? new DateTime(from.longValue(), DateTimeZone.UTC)\n+                        : query.effectiveTimeRange(pivot).getFrom(),\n+                isAllMessagesTimeRange(pivotRange) && to != 0\n+                        ? new DateTime(to.longValue(), DateTimeZone.UTC)\n+                        : query.effectiveTimeRange(pivot).getTo()\n+        );\n+    }\n+\n+    @Override\n+    public SearchType.Result doExtractResult(SearchJob job, Query query, Pivot pivot, SearchResponse queryResult, Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n+        final AbsoluteRange effectiveTimerange = extractEffectiveTimeRange(queryResult, query, pivot);\n+\n+        final PivotResult.Builder resultBuilder = PivotResult.builder()\n+                .id(pivot.id())\n+                .effectiveTimerange(effectiveTimerange)\n+                .total(extractDocumentCount(queryResult, pivot, queryContext));\n+\n+        // pivot results are a table where cells can contain multiple \"values\" and not only scalars:\n+        // each combination of row and column groups can contain all series (if rollup is true)\n+        // if rollup is false, only the \"leaf\" components contain the series\n+        // in the elasticsearch result, rows and columns are simply nested aggregations (first aggregations from rows, then from columns)\n+        // with metric aggregations on the corresponding levels.\n+        // first we iterate over all row groups (whose values generate a \"key array\", corresponding to the nesting level)\n+        // once we exhaust the row groups, we descend into the columns, which get added as values to their corresponding rows\n+        // on each nesting level and combination we have to check for series which we also add as values to the containing row\n+        final HasAggregations initialResult = createInitialResult(queryResult);\n+\n+        processRows(resultBuilder, queryResult, queryContext, pivot, pivot.rowGroups(), new ArrayDeque<>(), initialResult);\n+\n+        return pivot.name().map(resultBuilder::name).orElse(resultBuilder).build();\n+    }\n+\n+    private HasAggregations createInitialResult(SearchResponse queryResult) {\n+        return InitialBucket.create(queryResult);", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk1MjI4Nw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459952287", "bodyText": "We do need getDocCount() in one case, so the best way seemed to be an implementation of MultiBucketsAggregation.Bucket which combines both getDocCount() and HasAggregations.", "author": "dennisoelkers", "createdAt": "2020-07-24T09:39:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgyNDEzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2NTQ1MA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459965450", "bodyText": "OK, got it. Sorry for missing that.", "author": "alex-konn", "createdAt": "2020-07-24T10:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgyNDEzMw=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\ndeleted file mode 100644\nindex 2c9923c598..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\n+++ /dev/null\n\n@@ -1,385 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n-\n-import com.google.common.base.Preconditions;\n-import com.google.common.collect.ImmutableList;\n-import one.util.streamex.EntryStream;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.joda.time.DateTime;\n-import org.joda.time.DateTimeZone;\n-import org.jooq.lambda.tuple.Tuple;\n-import org.jooq.lambda.tuple.Tuple2;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.inject.Inject;\n-import java.util.ArrayDeque;\n-import java.util.IdentityHashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.Stream;\n-\n-public class ESPivot implements ESSearchTypeHandler<Pivot> {\n-    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n-    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n-    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n-    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n-\n-    private static TimeRange allMessagesTimeRange() {\n-        try {\n-            return RelativeRange.create(0);\n-        } catch (InvalidRangeParametersException e){\n-            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n-        }\n-        return null;\n-    }\n-\n-    @Inject\n-    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n-                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n-        this.bucketHandlers = bucketHandlers;\n-        this.seriesHandlers = seriesHandlers;\n-    }\n-\n-    @Override\n-    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        LOG.debug(\"Generating aggregation for {}\", pivot);\n-        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n-\n-        final Map<Object, Object> contextMap = queryContext.contextMap();\n-        final AggTypes aggTypes = new AggTypes();\n-        contextMap.put(pivot.id(), aggTypes);\n-\n-        // holds the initial level aggregation to be added to the query\n-        AggregationBuilder topLevelAggregation = null;\n-        // holds the last complete bucket aggregation into which subsequent buckets get added\n-        AggregationBuilder previousAggregation = null;\n-\n-        // add global rollup series if those were requested\n-        if (pivot.rollup()) {\n-            seriesStream(pivot, queryContext, \"global rollup\")\n-                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);\n-        }\n-\n-        final Iterator<BucketSpec> rowBuckets = pivot.rowGroups().iterator();\n-        while (rowBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = rowBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating row group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown row_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                if (topLevelAggregation == null) {\n-                    topLevelAggregation = aggregationBuilder;\n-                }\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!rowBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !rowBuckets.hasNext() ? \"leaf row\" : \"row rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-        final Iterator<BucketSpec> colBuckets = pivot.columnGroups().iterator();\n-        while (colBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = colBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating column group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown column_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!colBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !colBuckets.hasNext() ? \"leaf column\" : \"column rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-\n-        final MinAggregationBuilder startTimestamp = AggregationBuilders.min(\"timestamp-min\").field(\"timestamp\");\n-        final MaxAggregationBuilder endTimestamp = AggregationBuilders.max(\"timestamp-max\").field(\"timestamp\");\n-\n-        searchSourceBuilder.aggregation(startTimestamp);\n-        searchSourceBuilder.aggregation(endTimestamp);\n-\n-        if (topLevelAggregation == null) {\n-            LOG.debug(\"No aggregations generated for {}\", pivot);\n-        }\n-    }\n-\n-    private Stream<AggregationBuilder> seriesStream(Pivot pivot, ESGeneratedQueryContext queryContext, String reason) {\n-        return EntryStream.of(pivot.series())\n-                .mapKeyValue((integer, seriesSpec) -> {\n-                    final String seriesName = queryContext.seriesName(seriesSpec, pivot);\n-                    LOG.debug(\"Adding {} series '{}' with name '{}'\", reason, seriesSpec.type(), seriesName);\n-                    final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> esPivotSeriesSpecHandler = seriesHandlers.get(seriesSpec.type());\n-                    if (esPivotSeriesSpecHandler == null) {\n-                        throw new IllegalArgumentException(\"No series handler registered for: \" + seriesSpec.type());\n-                    }\n-                    return esPivotSeriesSpecHandler.createAggregation(seriesName, pivot, seriesSpec, this, queryContext);\n-                })\n-                .filter(Optional::isPresent)\n-                .map(Optional::get);\n-    }\n-\n-    private boolean isAllMessagesTimeRange(TimeRange timeRange) {\n-        return ALL_MESSAGES_TIMERANGE.equals(timeRange);\n-    }\n-\n-    private AbsoluteRange extractEffectiveTimeRange(SearchResponse queryResult, Query query, Pivot pivot) {\n-        final Min min = queryResult.getAggregations().get(\"timestamp-min\");\n-        final Double from = min.getValue();\n-        final Max max = queryResult.getAggregations().get(\"timestamp-max\");\n-        final Double to = max.getValue();\n-        final TimeRange pivotRange = query.effectiveTimeRange(pivot);\n-        return AbsoluteRange.create(\n-                isAllMessagesTimeRange(pivotRange) && from != 0\n-                        ? new DateTime(from.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getFrom(),\n-                isAllMessagesTimeRange(pivotRange) && to != 0\n-                        ? new DateTime(to.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getTo()\n-        );\n-    }\n-\n-    @Override\n-    public SearchType.Result doExtractResult(SearchJob job, Query query, Pivot pivot, SearchResponse queryResult, Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final AbsoluteRange effectiveTimerange = extractEffectiveTimeRange(queryResult, query, pivot);\n-\n-        final PivotResult.Builder resultBuilder = PivotResult.builder()\n-                .id(pivot.id())\n-                .effectiveTimerange(effectiveTimerange)\n-                .total(extractDocumentCount(queryResult, pivot, queryContext));\n-\n-        // pivot results are a table where cells can contain multiple \"values\" and not only scalars:\n-        // each combination of row and column groups can contain all series (if rollup is true)\n-        // if rollup is false, only the \"leaf\" components contain the series\n-        // in the elasticsearch result, rows and columns are simply nested aggregations (first aggregations from rows, then from columns)\n-        // with metric aggregations on the corresponding levels.\n-        // first we iterate over all row groups (whose values generate a \"key array\", corresponding to the nesting level)\n-        // once we exhaust the row groups, we descend into the columns, which get added as values to their corresponding rows\n-        // on each nesting level and combination we have to check for series which we also add as values to the containing row\n-        final HasAggregations initialResult = createInitialResult(queryResult);\n-\n-        processRows(resultBuilder, queryResult, queryContext, pivot, pivot.rowGroups(), new ArrayDeque<>(), initialResult);\n-\n-        return pivot.name().map(resultBuilder::name).orElse(resultBuilder).build();\n-    }\n-\n-    private HasAggregations createInitialResult(SearchResponse queryResult) {\n-        return InitialBucket.create(queryResult);\n-    }\n-\n-    private long extractDocumentCount(SearchResponse queryResult, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        return queryResult.getHits().getTotalHits().value;\n-    }\n-\n-    /*\n-        results from elasticsearch are nested so we need to recurse into the aggregation tree, but our result is a table, thus we need\n-        to keep track of the current row keys manually\n-         */\n-    private void processRows(PivotResult.Builder resultBuilder,\n-                             SearchResponse searchResult,\n-                             ESGeneratedQueryContext queryContext,\n-                             Pivot pivot,\n-                             List<BucketSpec> remainingRows,\n-                             ArrayDeque<String> rowKeys,\n-                             HasAggregations aggregation) {\n-        if (remainingRows.isEmpty()) {\n-            // this is the last row group, so we need to fork into the columns if they exist.\n-            // being here also means that `rowKeys` contains the maximum number of parts, one for each combination of row bucket keys\n-            // we will always add the series for this bucket, because that's the entire point of row groups\n-\n-            final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-            // do the same for columns as we did for the rows\n-            processColumns(rowBuilder, searchResult, queryContext, pivot, pivot.columnGroups(), new ArrayDeque<>(), aggregation);\n-\n-            // also add the series for the entire row\n-            // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-            if (pivot.rollup()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-leaf\");\n-            }\n-            resultBuilder.addRow(rowBuilder.source(\"leaf\").build());\n-        } else {\n-            // this is not a leaf for the rows, so we add its key to the rowKeys and descend into the aggregation tree\n-            // afterwards we'll check if we need to add rollup for intermediate buckets. not all clients need them so they can request\n-            // to not calculate them\n-            final BucketSpec currentBucket = remainingRows.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-            // for each bucket, recurse and eventually collect all the row keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                rowKeys.addLast(bucket.key());\n-                processRows(resultBuilder, searchResult, queryContext, pivot, tail(remainingRows), rowKeys, bucket.aggregation());\n-                rowKeys.removeLast();\n-            });\n-            // also add the series for this row key if the client wants rollups\n-            if (pivot.rollup()) {\n-                final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-                // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-inner\");\n-                resultBuilder.addRow(rowBuilder.source(\"non-leaf\").build());\n-            }\n-\n-        }\n-    }\n-\n-    private void processColumns(PivotResult.Row.Builder rowBuilder,\n-                                SearchResponse searchResult,\n-                                ESGeneratedQueryContext queryContext,\n-                                Pivot pivot,\n-                                List<BucketSpec> remainingColumns,\n-                                ArrayDeque<String> columnKeys,\n-                                HasAggregations aggregation) {\n-        if (remainingColumns.isEmpty()) {\n-            // this is the leaf cell of the pivot table, simply add all the series for the complete column key array\n-            // in the rollup: false case, this is the only set of series that is going to be added to the result\n-            // if we simply don't have any column groups, then don't bother adding the series, this is the special case that\n-            // only row grouping was requested, and the rollup for rows is automatically added anyway. otherwise we'll end up\n-            // with duplicate data entries\n-            if (!columnKeys.isEmpty()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, false, \"col-leaf\");\n-            }\n-        } else {\n-            // for a non-leaf column group, we need to recurse further into the aggregation tree\n-            // and if rollup was requested we'll add intermediate series according to the column keys\n-            final BucketSpec currentBucket = remainingColumns.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-\n-            // for each bucket, recurse and eventually collect all the column keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                columnKeys.addLast(bucket.key());\n-                processColumns(rowBuilder, searchResult, queryContext, pivot, tail(remainingColumns), columnKeys, bucket.aggregation());\n-                columnKeys.removeLast();\n-            });\n-            // also add the series for the base column key if the client wants rollups, the complete column key is processed in the leaf branch\n-            // don't add the empty column key rollup, because that's not the correct bucket here, it's being done in the row-leaf code\n-            if (pivot.rollup() && !columnKeys.isEmpty()) {\n-                // columnKeys is not empty, because this is a rollup per column in a row\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, true, \"col-inner\");\n-            }\n-\n-        }\n-    }\n-\n-    private void processSeries(PivotResult.Row.Builder rowBuilder,\n-                               SearchResponse searchResult,\n-                               ESGeneratedQueryContext queryContext,\n-                               Pivot pivot,\n-                               ArrayDeque<String> columnKeys,\n-                               HasAggregations aggregation,\n-                               boolean rollup,\n-                               String source) {\n-        pivot.series().forEach(seriesSpec -> {\n-            final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> seriesHandler = seriesHandlers.get(seriesSpec.type());\n-            final Aggregation series = seriesHandler.extractAggregationFromResult(pivot, seriesSpec, aggregation, queryContext);\n-            seriesHandler.handleResult(pivot, seriesSpec, searchResult, series, this, queryContext)\n-                    .map(value -> {\n-                        columnKeys.addLast(value.id());\n-                        final PivotResult.Value v = PivotResult.Value.create(columnKeys, value.value(), rollup, source);\n-                        columnKeys.removeLast();\n-                        return v;\n-                    })\n-                    .forEach(rowBuilder::addValue);\n-        });\n-    }\n-\n-    private static <T> List<T> tail(List<T> list) {\n-        Preconditions.checkArgument(!list.isEmpty(), \"List must not be empty!\");\n-        return list.subList(1, list.size());\n-    }\n-\n-    /**\n-     * This solely exists to hide the nasty type signature of the aggregation type map from the rest of the code.\n-     * It's just ugly and in the way.\n-     */\n-    public static class AggTypes {\n-        final IdentityHashMap<PivotSpec, Tuple2<String, Class<? extends Aggregation>>> aggTypeMap = new IdentityHashMap<>();\n-\n-        public void record(PivotSpec pivotSpec, String name, Class<? extends Aggregation> aggClass) {\n-            aggTypeMap.put(pivotSpec, Tuple.tuple(name, aggClass));\n-        }\n-\n-        public Aggregation getSubAggregation(PivotSpec pivotSpec, HasAggregations currentAggregationOrBucket) {\n-            final Tuple2<String, Class<? extends Aggregation>> tuple2 = getTypes(pivotSpec);\n-            return currentAggregationOrBucket.getAggregations().get(tuple2.v1);\n-        }\n-\n-        public Tuple2<String, Class<? extends Aggregation>> getTypes(PivotSpec pivotSpec) {\n-            return aggTypeMap.get(pivotSpec);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzMDgwMg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458830802", "bodyText": "Wouldn't it be enough to pass queryResult::getAggregations instead of initialResult?", "author": "alex-konn", "createdAt": "2020-07-22T14:23:02Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java", "diffHunk": "@@ -0,0 +1,385 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import one.util.streamex.EntryStream;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.jooq.lambda.tuple.Tuple;\n+import org.jooq.lambda.tuple.Tuple2;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.ArrayDeque;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Stream;\n+\n+public class ESPivot implements ESSearchTypeHandler<Pivot> {\n+    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n+    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n+    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n+    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n+\n+    private static TimeRange allMessagesTimeRange() {\n+        try {\n+            return RelativeRange.create(0);\n+        } catch (InvalidRangeParametersException e){\n+            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n+        }\n+        return null;\n+    }\n+\n+    @Inject\n+    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n+                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n+        this.bucketHandlers = bucketHandlers;\n+        this.seriesHandlers = seriesHandlers;\n+    }\n+\n+    @Override\n+    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n+        LOG.debug(\"Generating aggregation for {}\", pivot);\n+        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n+\n+        final Map<Object, Object> contextMap = queryContext.contextMap();\n+        final AggTypes aggTypes = new AggTypes();\n+        contextMap.put(pivot.id(), aggTypes);\n+\n+        // holds the initial level aggregation to be added to the query\n+        AggregationBuilder topLevelAggregation = null;\n+        // holds the last complete bucket aggregation into which subsequent buckets get added\n+        AggregationBuilder previousAggregation = null;\n+\n+        // add global rollup series if those were requested\n+        if (pivot.rollup()) {\n+            seriesStream(pivot, queryContext, \"global rollup\")\n+                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);\n+        }\n+\n+        final Iterator<BucketSpec> rowBuckets = pivot.rowGroups().iterator();\n+        while (rowBuckets.hasNext()) {\n+            final BucketSpec bucketSpec = rowBuckets.next();\n+\n+            final String name = queryContext.nextName();\n+            LOG.debug(\"Creating row group aggregation '{}' as {}\", bucketSpec.type(), name);\n+            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n+            if (handler == null) {\n+                throw new IllegalArgumentException(\"Unknown row_group type \" + bucketSpec.type());\n+            }\n+            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n+            if (generatedAggregation.isPresent()) {\n+                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n+                if (topLevelAggregation == null) {\n+                    topLevelAggregation = aggregationBuilder;\n+                }\n+                // always insert the series for the final row group, or for each one if explicit rollup was requested\n+                if (!rowBuckets.hasNext() || pivot.rollup()) {\n+                    seriesStream(pivot, queryContext, !rowBuckets.hasNext() ? \"leaf row\" : \"row rollup\")\n+                            .forEach(aggregationBuilder::subAggregation);\n+                }\n+                if (previousAggregation != null) {\n+                    previousAggregation.subAggregation(aggregationBuilder);\n+                } else {\n+                    searchSourceBuilder.aggregation(aggregationBuilder);\n+                }\n+                previousAggregation = aggregationBuilder;\n+            }\n+        }\n+        final Iterator<BucketSpec> colBuckets = pivot.columnGroups().iterator();\n+        while (colBuckets.hasNext()) {\n+            final BucketSpec bucketSpec = colBuckets.next();\n+\n+            final String name = queryContext.nextName();\n+            LOG.debug(\"Creating column group aggregation '{}' as {}\", bucketSpec.type(), name);\n+            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n+            if (handler == null) {\n+                throw new IllegalArgumentException(\"Unknown column_group type \" + bucketSpec.type());\n+            }\n+            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n+            if (generatedAggregation.isPresent()) {\n+                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n+                // always insert the series for the final row group, or for each one if explicit rollup was requested\n+                if (!colBuckets.hasNext() || pivot.rollup()) {\n+                    seriesStream(pivot, queryContext, !colBuckets.hasNext() ? \"leaf column\" : \"column rollup\")\n+                            .forEach(aggregationBuilder::subAggregation);\n+                }\n+                if (previousAggregation != null) {\n+                    previousAggregation.subAggregation(aggregationBuilder);\n+                } else {\n+                    searchSourceBuilder.aggregation(aggregationBuilder);\n+                }\n+                previousAggregation = aggregationBuilder;\n+            }\n+        }\n+\n+        final MinAggregationBuilder startTimestamp = AggregationBuilders.min(\"timestamp-min\").field(\"timestamp\");\n+        final MaxAggregationBuilder endTimestamp = AggregationBuilders.max(\"timestamp-max\").field(\"timestamp\");\n+\n+        searchSourceBuilder.aggregation(startTimestamp);\n+        searchSourceBuilder.aggregation(endTimestamp);\n+\n+        if (topLevelAggregation == null) {\n+            LOG.debug(\"No aggregations generated for {}\", pivot);\n+        }\n+    }\n+\n+    private Stream<AggregationBuilder> seriesStream(Pivot pivot, ESGeneratedQueryContext queryContext, String reason) {\n+        return EntryStream.of(pivot.series())\n+                .mapKeyValue((integer, seriesSpec) -> {\n+                    final String seriesName = queryContext.seriesName(seriesSpec, pivot);\n+                    LOG.debug(\"Adding {} series '{}' with name '{}'\", reason, seriesSpec.type(), seriesName);\n+                    final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> esPivotSeriesSpecHandler = seriesHandlers.get(seriesSpec.type());\n+                    if (esPivotSeriesSpecHandler == null) {\n+                        throw new IllegalArgumentException(\"No series handler registered for: \" + seriesSpec.type());\n+                    }\n+                    return esPivotSeriesSpecHandler.createAggregation(seriesName, pivot, seriesSpec, this, queryContext);\n+                })\n+                .filter(Optional::isPresent)\n+                .map(Optional::get);\n+    }\n+\n+    private boolean isAllMessagesTimeRange(TimeRange timeRange) {\n+        return ALL_MESSAGES_TIMERANGE.equals(timeRange);\n+    }\n+\n+    private AbsoluteRange extractEffectiveTimeRange(SearchResponse queryResult, Query query, Pivot pivot) {\n+        final Min min = queryResult.getAggregations().get(\"timestamp-min\");\n+        final Double from = min.getValue();\n+        final Max max = queryResult.getAggregations().get(\"timestamp-max\");\n+        final Double to = max.getValue();\n+        final TimeRange pivotRange = query.effectiveTimeRange(pivot);\n+        return AbsoluteRange.create(\n+                isAllMessagesTimeRange(pivotRange) && from != 0\n+                        ? new DateTime(from.longValue(), DateTimeZone.UTC)\n+                        : query.effectiveTimeRange(pivot).getFrom(),\n+                isAllMessagesTimeRange(pivotRange) && to != 0\n+                        ? new DateTime(to.longValue(), DateTimeZone.UTC)\n+                        : query.effectiveTimeRange(pivot).getTo()\n+        );\n+    }\n+\n+    @Override\n+    public SearchType.Result doExtractResult(SearchJob job, Query query, Pivot pivot, SearchResponse queryResult, Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n+        final AbsoluteRange effectiveTimerange = extractEffectiveTimeRange(queryResult, query, pivot);\n+\n+        final PivotResult.Builder resultBuilder = PivotResult.builder()\n+                .id(pivot.id())\n+                .effectiveTimerange(effectiveTimerange)\n+                .total(extractDocumentCount(queryResult, pivot, queryContext));\n+\n+        // pivot results are a table where cells can contain multiple \"values\" and not only scalars:\n+        // each combination of row and column groups can contain all series (if rollup is true)\n+        // if rollup is false, only the \"leaf\" components contain the series\n+        // in the elasticsearch result, rows and columns are simply nested aggregations (first aggregations from rows, then from columns)\n+        // with metric aggregations on the corresponding levels.\n+        // first we iterate over all row groups (whose values generate a \"key array\", corresponding to the nesting level)\n+        // once we exhaust the row groups, we descend into the columns, which get added as values to their corresponding rows\n+        // on each nesting level and combination we have to check for series which we also add as values to the containing row\n+        final HasAggregations initialResult = createInitialResult(queryResult);\n+\n+        processRows(resultBuilder, queryResult, queryContext, pivot, pivot.rowGroups(), new ArrayDeque<>(), initialResult);", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk1MjM1Nw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459952357", "bodyText": "See #8547 (comment).", "author": "dennisoelkers", "createdAt": "2020-07-24T09:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzMDgwMg=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\ndeleted file mode 100644\nindex 2c9923c598..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/ESPivot.java\n+++ /dev/null\n\n@@ -1,385 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n-\n-import com.google.common.base.Preconditions;\n-import com.google.common.collect.ImmutableList;\n-import one.util.streamex.EntryStream;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotResult;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MaxAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.Min;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.MinAggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.builder.SearchSourceBuilder;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.RelativeRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.joda.time.DateTime;\n-import org.joda.time.DateTimeZone;\n-import org.jooq.lambda.tuple.Tuple;\n-import org.jooq.lambda.tuple.Tuple2;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.inject.Inject;\n-import java.util.ArrayDeque;\n-import java.util.IdentityHashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.Stream;\n-\n-public class ESPivot implements ESSearchTypeHandler<Pivot> {\n-    private static final Logger LOG = LoggerFactory.getLogger(ESPivot.class);\n-    private final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers;\n-    private final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers;\n-    private static final TimeRange ALL_MESSAGES_TIMERANGE = allMessagesTimeRange();\n-\n-    private static TimeRange allMessagesTimeRange() {\n-        try {\n-            return RelativeRange.create(0);\n-        } catch (InvalidRangeParametersException e){\n-            LOG.error(\"Unable to instantiate all messages timerange: \", e);\n-        }\n-        return null;\n-    }\n-\n-    @Inject\n-    public ESPivot(Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers,\n-                   Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers) {\n-        this.bucketHandlers = bucketHandlers;\n-        this.seriesHandlers = seriesHandlers;\n-    }\n-\n-    @Override\n-    public void doGenerateQueryPart(SearchJob job, Query query, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        LOG.debug(\"Generating aggregation for {}\", pivot);\n-        final SearchSourceBuilder searchSourceBuilder = queryContext.searchSourceBuilder(pivot);\n-\n-        final Map<Object, Object> contextMap = queryContext.contextMap();\n-        final AggTypes aggTypes = new AggTypes();\n-        contextMap.put(pivot.id(), aggTypes);\n-\n-        // holds the initial level aggregation to be added to the query\n-        AggregationBuilder topLevelAggregation = null;\n-        // holds the last complete bucket aggregation into which subsequent buckets get added\n-        AggregationBuilder previousAggregation = null;\n-\n-        // add global rollup series if those were requested\n-        if (pivot.rollup()) {\n-            seriesStream(pivot, queryContext, \"global rollup\")\n-                    .forEach(previousAggregation != null ? previousAggregation::subAggregation : searchSourceBuilder::aggregation);\n-        }\n-\n-        final Iterator<BucketSpec> rowBuckets = pivot.rowGroups().iterator();\n-        while (rowBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = rowBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating row group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown row_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                if (topLevelAggregation == null) {\n-                    topLevelAggregation = aggregationBuilder;\n-                }\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!rowBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !rowBuckets.hasNext() ? \"leaf row\" : \"row rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-        final Iterator<BucketSpec> colBuckets = pivot.columnGroups().iterator();\n-        while (colBuckets.hasNext()) {\n-            final BucketSpec bucketSpec = colBuckets.next();\n-\n-            final String name = queryContext.nextName();\n-            LOG.debug(\"Creating column group aggregation '{}' as {}\", bucketSpec.type(), name);\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(bucketSpec.type());\n-            if (handler == null) {\n-                throw new IllegalArgumentException(\"Unknown column_group type \" + bucketSpec.type());\n-            }\n-            final Optional<AggregationBuilder> generatedAggregation = handler.createAggregation(name, pivot, bucketSpec, this, queryContext, query);\n-            if (generatedAggregation.isPresent()) {\n-                final AggregationBuilder aggregationBuilder = generatedAggregation.get();\n-                // always insert the series for the final row group, or for each one if explicit rollup was requested\n-                if (!colBuckets.hasNext() || pivot.rollup()) {\n-                    seriesStream(pivot, queryContext, !colBuckets.hasNext() ? \"leaf column\" : \"column rollup\")\n-                            .forEach(aggregationBuilder::subAggregation);\n-                }\n-                if (previousAggregation != null) {\n-                    previousAggregation.subAggregation(aggregationBuilder);\n-                } else {\n-                    searchSourceBuilder.aggregation(aggregationBuilder);\n-                }\n-                previousAggregation = aggregationBuilder;\n-            }\n-        }\n-\n-        final MinAggregationBuilder startTimestamp = AggregationBuilders.min(\"timestamp-min\").field(\"timestamp\");\n-        final MaxAggregationBuilder endTimestamp = AggregationBuilders.max(\"timestamp-max\").field(\"timestamp\");\n-\n-        searchSourceBuilder.aggregation(startTimestamp);\n-        searchSourceBuilder.aggregation(endTimestamp);\n-\n-        if (topLevelAggregation == null) {\n-            LOG.debug(\"No aggregations generated for {}\", pivot);\n-        }\n-    }\n-\n-    private Stream<AggregationBuilder> seriesStream(Pivot pivot, ESGeneratedQueryContext queryContext, String reason) {\n-        return EntryStream.of(pivot.series())\n-                .mapKeyValue((integer, seriesSpec) -> {\n-                    final String seriesName = queryContext.seriesName(seriesSpec, pivot);\n-                    LOG.debug(\"Adding {} series '{}' with name '{}'\", reason, seriesSpec.type(), seriesName);\n-                    final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> esPivotSeriesSpecHandler = seriesHandlers.get(seriesSpec.type());\n-                    if (esPivotSeriesSpecHandler == null) {\n-                        throw new IllegalArgumentException(\"No series handler registered for: \" + seriesSpec.type());\n-                    }\n-                    return esPivotSeriesSpecHandler.createAggregation(seriesName, pivot, seriesSpec, this, queryContext);\n-                })\n-                .filter(Optional::isPresent)\n-                .map(Optional::get);\n-    }\n-\n-    private boolean isAllMessagesTimeRange(TimeRange timeRange) {\n-        return ALL_MESSAGES_TIMERANGE.equals(timeRange);\n-    }\n-\n-    private AbsoluteRange extractEffectiveTimeRange(SearchResponse queryResult, Query query, Pivot pivot) {\n-        final Min min = queryResult.getAggregations().get(\"timestamp-min\");\n-        final Double from = min.getValue();\n-        final Max max = queryResult.getAggregations().get(\"timestamp-max\");\n-        final Double to = max.getValue();\n-        final TimeRange pivotRange = query.effectiveTimeRange(pivot);\n-        return AbsoluteRange.create(\n-                isAllMessagesTimeRange(pivotRange) && from != 0\n-                        ? new DateTime(from.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getFrom(),\n-                isAllMessagesTimeRange(pivotRange) && to != 0\n-                        ? new DateTime(to.longValue(), DateTimeZone.UTC)\n-                        : query.effectiveTimeRange(pivot).getTo()\n-        );\n-    }\n-\n-    @Override\n-    public SearchType.Result doExtractResult(SearchJob job, Query query, Pivot pivot, SearchResponse queryResult, Aggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final AbsoluteRange effectiveTimerange = extractEffectiveTimeRange(queryResult, query, pivot);\n-\n-        final PivotResult.Builder resultBuilder = PivotResult.builder()\n-                .id(pivot.id())\n-                .effectiveTimerange(effectiveTimerange)\n-                .total(extractDocumentCount(queryResult, pivot, queryContext));\n-\n-        // pivot results are a table where cells can contain multiple \"values\" and not only scalars:\n-        // each combination of row and column groups can contain all series (if rollup is true)\n-        // if rollup is false, only the \"leaf\" components contain the series\n-        // in the elasticsearch result, rows and columns are simply nested aggregations (first aggregations from rows, then from columns)\n-        // with metric aggregations on the corresponding levels.\n-        // first we iterate over all row groups (whose values generate a \"key array\", corresponding to the nesting level)\n-        // once we exhaust the row groups, we descend into the columns, which get added as values to their corresponding rows\n-        // on each nesting level and combination we have to check for series which we also add as values to the containing row\n-        final HasAggregations initialResult = createInitialResult(queryResult);\n-\n-        processRows(resultBuilder, queryResult, queryContext, pivot, pivot.rowGroups(), new ArrayDeque<>(), initialResult);\n-\n-        return pivot.name().map(resultBuilder::name).orElse(resultBuilder).build();\n-    }\n-\n-    private HasAggregations createInitialResult(SearchResponse queryResult) {\n-        return InitialBucket.create(queryResult);\n-    }\n-\n-    private long extractDocumentCount(SearchResponse queryResult, Pivot pivot, ESGeneratedQueryContext queryContext) {\n-        return queryResult.getHits().getTotalHits().value;\n-    }\n-\n-    /*\n-        results from elasticsearch are nested so we need to recurse into the aggregation tree, but our result is a table, thus we need\n-        to keep track of the current row keys manually\n-         */\n-    private void processRows(PivotResult.Builder resultBuilder,\n-                             SearchResponse searchResult,\n-                             ESGeneratedQueryContext queryContext,\n-                             Pivot pivot,\n-                             List<BucketSpec> remainingRows,\n-                             ArrayDeque<String> rowKeys,\n-                             HasAggregations aggregation) {\n-        if (remainingRows.isEmpty()) {\n-            // this is the last row group, so we need to fork into the columns if they exist.\n-            // being here also means that `rowKeys` contains the maximum number of parts, one for each combination of row bucket keys\n-            // we will always add the series for this bucket, because that's the entire point of row groups\n-\n-            final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-            // do the same for columns as we did for the rows\n-            processColumns(rowBuilder, searchResult, queryContext, pivot, pivot.columnGroups(), new ArrayDeque<>(), aggregation);\n-\n-            // also add the series for the entire row\n-            // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-            if (pivot.rollup()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-leaf\");\n-            }\n-            resultBuilder.addRow(rowBuilder.source(\"leaf\").build());\n-        } else {\n-            // this is not a leaf for the rows, so we add its key to the rowKeys and descend into the aggregation tree\n-            // afterwards we'll check if we need to add rollup for intermediate buckets. not all clients need them so they can request\n-            // to not calculate them\n-            final BucketSpec currentBucket = remainingRows.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-            // for each bucket, recurse and eventually collect all the row keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                rowKeys.addLast(bucket.key());\n-                processRows(resultBuilder, searchResult, queryContext, pivot, tail(remainingRows), rowKeys, bucket.aggregation());\n-                rowKeys.removeLast();\n-            });\n-            // also add the series for this row key if the client wants rollups\n-            if (pivot.rollup()) {\n-                final PivotResult.Row.Builder rowBuilder = PivotResult.Row.builder().key(ImmutableList.copyOf(rowKeys));\n-                // columnKeys is empty, because this is a rollup per row bucket, thus for all columns in that bucket (IOW it's not a leaf!)\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, new ArrayDeque<>(), aggregation, true, \"row-inner\");\n-                resultBuilder.addRow(rowBuilder.source(\"non-leaf\").build());\n-            }\n-\n-        }\n-    }\n-\n-    private void processColumns(PivotResult.Row.Builder rowBuilder,\n-                                SearchResponse searchResult,\n-                                ESGeneratedQueryContext queryContext,\n-                                Pivot pivot,\n-                                List<BucketSpec> remainingColumns,\n-                                ArrayDeque<String> columnKeys,\n-                                HasAggregations aggregation) {\n-        if (remainingColumns.isEmpty()) {\n-            // this is the leaf cell of the pivot table, simply add all the series for the complete column key array\n-            // in the rollup: false case, this is the only set of series that is going to be added to the result\n-            // if we simply don't have any column groups, then don't bother adding the series, this is the special case that\n-            // only row grouping was requested, and the rollup for rows is automatically added anyway. otherwise we'll end up\n-            // with duplicate data entries\n-            if (!columnKeys.isEmpty()) {\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, false, \"col-leaf\");\n-            }\n-        } else {\n-            // for a non-leaf column group, we need to recurse further into the aggregation tree\n-            // and if rollup was requested we'll add intermediate series according to the column keys\n-            final BucketSpec currentBucket = remainingColumns.get(0);\n-\n-            // this handler should never be missing, because we used it above to generate the query\n-            // if it is missing for some weird reason, it's ok to fail hard here\n-            final ESPivotBucketSpecHandler<? extends PivotSpec, ? extends Aggregation> handler = bucketHandlers.get(currentBucket.type());\n-            final Aggregation aggregationResult = handler.extractAggregationFromResult(pivot, currentBucket, aggregation, queryContext);\n-            final Stream<ESPivotBucketSpecHandler.Bucket> bucketStream = handler.handleResult(pivot, currentBucket, searchResult, aggregationResult, this, queryContext);\n-\n-            // for each bucket, recurse and eventually collect all the column keys. once we reach a leaf, we'll end up in the other if branch above\n-            bucketStream.forEach(bucket -> {\n-                // push the bucket's key and use its aggregation as the new source for sub-aggregations\n-                columnKeys.addLast(bucket.key());\n-                processColumns(rowBuilder, searchResult, queryContext, pivot, tail(remainingColumns), columnKeys, bucket.aggregation());\n-                columnKeys.removeLast();\n-            });\n-            // also add the series for the base column key if the client wants rollups, the complete column key is processed in the leaf branch\n-            // don't add the empty column key rollup, because that's not the correct bucket here, it's being done in the row-leaf code\n-            if (pivot.rollup() && !columnKeys.isEmpty()) {\n-                // columnKeys is not empty, because this is a rollup per column in a row\n-                processSeries(rowBuilder, searchResult, queryContext, pivot, columnKeys, aggregation, true, \"col-inner\");\n-            }\n-\n-        }\n-    }\n-\n-    private void processSeries(PivotResult.Row.Builder rowBuilder,\n-                               SearchResponse searchResult,\n-                               ESGeneratedQueryContext queryContext,\n-                               Pivot pivot,\n-                               ArrayDeque<String> columnKeys,\n-                               HasAggregations aggregation,\n-                               boolean rollup,\n-                               String source) {\n-        pivot.series().forEach(seriesSpec -> {\n-            final ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation> seriesHandler = seriesHandlers.get(seriesSpec.type());\n-            final Aggregation series = seriesHandler.extractAggregationFromResult(pivot, seriesSpec, aggregation, queryContext);\n-            seriesHandler.handleResult(pivot, seriesSpec, searchResult, series, this, queryContext)\n-                    .map(value -> {\n-                        columnKeys.addLast(value.id());\n-                        final PivotResult.Value v = PivotResult.Value.create(columnKeys, value.value(), rollup, source);\n-                        columnKeys.removeLast();\n-                        return v;\n-                    })\n-                    .forEach(rowBuilder::addValue);\n-        });\n-    }\n-\n-    private static <T> List<T> tail(List<T> list) {\n-        Preconditions.checkArgument(!list.isEmpty(), \"List must not be empty!\");\n-        return list.subList(1, list.size());\n-    }\n-\n-    /**\n-     * This solely exists to hide the nasty type signature of the aggregation type map from the rest of the code.\n-     * It's just ugly and in the way.\n-     */\n-    public static class AggTypes {\n-        final IdentityHashMap<PivotSpec, Tuple2<String, Class<? extends Aggregation>>> aggTypeMap = new IdentityHashMap<>();\n-\n-        public void record(PivotSpec pivotSpec, String name, Class<? extends Aggregation> aggClass) {\n-            aggTypeMap.put(pivotSpec, Tuple.tuple(name, aggClass));\n-        }\n-\n-        public Aggregation getSubAggregation(PivotSpec pivotSpec, HasAggregations currentAggregationOrBucket) {\n-            final Tuple2<String, Class<? extends Aggregation>> tuple2 = getTypes(pivotSpec);\n-            return currentAggregationOrBucket.getAggregations().get(tuple2.v1);\n-        }\n-\n-        public Tuple2<String, Class<? extends Aggregation>> getTypes(PivotSpec pivotSpec) {\n-            return aggTypeMap.get(pivotSpec);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzMjA3MQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458832071", "bodyText": "I'm not sure we need this class (see comments on ESPivot above).", "author": "alex-konn", "createdAt": "2020-07-22T14:24:37Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/InitialBucket.java", "diffHunk": "@@ -0,0 +1,47 @@\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n+\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+\n+import java.io.IOException;\n+\n+public class InitialBucket implements MultiBucketsAggregation.Bucket {", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk1MjM4OA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459952388", "bodyText": "See #8547 (comment).", "author": "dennisoelkers", "createdAt": "2020-07-24T09:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzMjA3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2NTIyNA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459965224", "bodyText": "\ud83d\udc4d", "author": "alex-konn", "createdAt": "2020-07-24T10:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgzMjA3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/InitialBucket.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/InitialBucket.java\ndeleted file mode 100644\nindex a1957cf155..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/InitialBucket.java\n+++ /dev/null\n\n@@ -1,47 +0,0 @@\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot;\n-\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n-\n-import java.io.IOException;\n-\n-public class InitialBucket implements MultiBucketsAggregation.Bucket {\n-    private final long docCount;\n-    private final Aggregations aggregations;\n-\n-    private InitialBucket(long docCount, Aggregations aggregations) {\n-        this.docCount = docCount;\n-        this.aggregations = aggregations;\n-    }\n-\n-    public static InitialBucket create(SearchResponse searchResponse) {\n-        return new InitialBucket(searchResponse.getHits().getTotalHits().value, searchResponse.getAggregations());\n-    }\n-\n-    @Override\n-    public Object getKey() {\n-        throw new IllegalStateException(\"Not implemented!\");\n-    }\n-\n-    @Override\n-    public String getKeyAsString() {\n-        throw new IllegalStateException(\"Not implemented!\");\n-    }\n-\n-    @Override\n-    public long getDocCount() {\n-        return this.docCount;\n-    }\n-\n-    @Override\n-    public Aggregations getAggregations() {\n-        return this.aggregations;\n-    }\n-\n-    @Override\n-    public XContentBuilder toXContent(XContentBuilder xContentBuilder, Params params) throws IOException {\n-        throw new IllegalStateException(\"Not implemented!\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg2MDI4OQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458860289", "bodyText": "If value is null, metricAggregation will also be null, because otherwise value will have been set in the else if clause above.\nI think we can log an error in the else if block instead and get rid of this block.", "author": "alex-konn", "createdAt": "2020-07-22T15:01:46Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series;\n+\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCount;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCountAggregationBuilder;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.jooq.lambda.tuple.Tuple2;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Stream;\n+\n+public class ESCountHandler extends ESPivotSeriesSpecHandler<Count, ValueCount> {\n+    private static final Logger LOG = LoggerFactory.getLogger(ESCountHandler.class);\n+\n+    @Nonnull\n+    @Override\n+    public Optional<AggregationBuilder> doCreateAggregation(String name, Pivot pivot, Count count, ESPivot searchTypeHandler, ESGeneratedQueryContext queryContext) {\n+        final String field = count.field();\n+        if (field == null) {\n+            // doc_count is always present in elasticsearch's bucket aggregations, no need to add it\n+            return Optional.empty();\n+        } else {\n+            // the request was for a field count, we have to add a value_count sub aggregation\n+            final ValueCountAggregationBuilder value = AggregationBuilders.count(name).field(field);\n+            record(queryContext, pivot, count, name, ValueCount.class);\n+            return Optional.of(value);\n+        }\n+    }\n+\n+    @Override\n+    public Stream<Value> doHandleResult(Pivot pivot,\n+                                        Count count,\n+                                        SearchResponse searchResult,\n+                                        ValueCount metricAggregation,\n+                                        ESPivot searchTypeHandler,\n+                                        ESGeneratedQueryContext esGeneratedQueryContext) {\n+        Object value = null;\n+        if (metricAggregation instanceof MultiBucketsAggregation.Bucket) {\n+            value = ((MultiBucketsAggregation.Bucket) metricAggregation).getDocCount();\n+        } else if (metricAggregation instanceof Aggregations) {\n+            value = searchResult.getHits().getTotalHits().value;\n+        } else if (metricAggregation != null) {\n+            value = metricAggregation.getValue();\n+        }\n+        if (value == null) {\n+            LOG.error(\"Unexpected aggregation type {}, returning 0 for the count. This is a bug.\", metricAggregation);", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODMwMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968303", "bodyText": "I restructured it a bit and made the check for valueCount/metricAggregation == null more explicit.", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg2MDI4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java\ndeleted file mode 100644\nindex 068c3f6871..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java\n+++ /dev/null\n\n@@ -1,140 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series;\n-\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCount;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCountAggregationBuilder;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.jooq.lambda.tuple.Tuple2;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nonnull;\n-import java.io.IOException;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.Stream;\n-\n-public class ESCountHandler extends ESPivotSeriesSpecHandler<Count, ValueCount> {\n-    private static final Logger LOG = LoggerFactory.getLogger(ESCountHandler.class);\n-\n-    @Nonnull\n-    @Override\n-    public Optional<AggregationBuilder> doCreateAggregation(String name, Pivot pivot, Count count, ESPivot searchTypeHandler, ESGeneratedQueryContext queryContext) {\n-        final String field = count.field();\n-        if (field == null) {\n-            // doc_count is always present in elasticsearch's bucket aggregations, no need to add it\n-            return Optional.empty();\n-        } else {\n-            // the request was for a field count, we have to add a value_count sub aggregation\n-            final ValueCountAggregationBuilder value = AggregationBuilders.count(name).field(field);\n-            record(queryContext, pivot, count, name, ValueCount.class);\n-            return Optional.of(value);\n-        }\n-    }\n-\n-    @Override\n-    public Stream<Value> doHandleResult(Pivot pivot,\n-                                        Count count,\n-                                        SearchResponse searchResult,\n-                                        ValueCount metricAggregation,\n-                                        ESPivot searchTypeHandler,\n-                                        ESGeneratedQueryContext esGeneratedQueryContext) {\n-        Object value = null;\n-        if (metricAggregation instanceof MultiBucketsAggregation.Bucket) {\n-            value = ((MultiBucketsAggregation.Bucket) metricAggregation).getDocCount();\n-        } else if (metricAggregation instanceof Aggregations) {\n-            value = searchResult.getHits().getTotalHits().value;\n-        } else if (metricAggregation != null) {\n-            value = metricAggregation.getValue();\n-        }\n-        if (value == null) {\n-            LOG.error(\"Unexpected aggregation type {}, returning 0 for the count. This is a bug.\", metricAggregation);\n-            value = 0;\n-        }\n-        return Stream.of(Value.create(count.id(), Count.NAME, value));\n-    }\n-\n-    @Override\n-    protected Aggregation extractAggregationFromResult(Pivot pivot, PivotSpec spec, HasAggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final Tuple2<String, Class<? extends Aggregation>> objects = aggTypes(queryContext, pivot).getTypes(spec);\n-        if (objects == null) {\n-            if (aggregations instanceof MultiBucketsAggregation.Bucket) {\n-                return createValueCount((MultiBucketsAggregation.Bucket) aggregations);\n-            }\n-        } else {\n-            // try to saved sub aggregation type. this might fail if we refer to the total result of the entire result instead of a specific\n-            // value_count aggregation. we'll handle that special case in doHandleResult above\n-            return aggregations.getAggregations().get(objects.v1);\n-        }\n-\n-        return null;\n-    }\n-\n-    private Aggregation createValueCount(MultiBucketsAggregation.Bucket aggregations) {\n-        final Long docCount = aggregations.getDocCount();\n-        return new ValueCount() {\n-            @Override\n-            public long getValue() {\n-                return docCount;\n-            }\n-\n-            @Override\n-            public double value() {\n-                return docCount;\n-            }\n-\n-            @Override\n-            public String getValueAsString() {\n-                return docCount.toString();\n-            }\n-\n-            @Override\n-            public String getName() {\n-                return null;\n-            }\n-\n-            @Override\n-            public String getType() {\n-                return null;\n-            }\n-\n-            @Override\n-            public Map<String, Object> getMetaData() {\n-                return null;\n-            }\n-\n-            @Override\n-            public XContentBuilder toXContent(XContentBuilder xContentBuilder, Params params) throws IOException {\n-                return null;\n-            }\n-        };\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg2MTEzNw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458861137", "bodyText": "Let's rename this to ValueCount.", "author": "alex-konn", "createdAt": "2020-07-22T15:02:54Z", "path": "graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series;\n+\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCount;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCountAggregationBuilder;\n+import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.jooq.lambda.tuple.Tuple2;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.Stream;\n+\n+public class ESCountHandler extends ESPivotSeriesSpecHandler<Count, ValueCount> {\n+    private static final Logger LOG = LoggerFactory.getLogger(ESCountHandler.class);\n+\n+    @Nonnull\n+    @Override\n+    public Optional<AggregationBuilder> doCreateAggregation(String name, Pivot pivot, Count count, ESPivot searchTypeHandler, ESGeneratedQueryContext queryContext) {\n+        final String field = count.field();\n+        if (field == null) {\n+            // doc_count is always present in elasticsearch's bucket aggregations, no need to add it\n+            return Optional.empty();\n+        } else {\n+            // the request was for a field count, we have to add a value_count sub aggregation\n+            final ValueCountAggregationBuilder value = AggregationBuilders.count(name).field(field);\n+            record(queryContext, pivot, count, name, ValueCount.class);\n+            return Optional.of(value);\n+        }\n+    }\n+\n+    @Override\n+    public Stream<Value> doHandleResult(Pivot pivot,\n+                                        Count count,\n+                                        SearchResponse searchResult,\n+                                        ValueCount metricAggregation,", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODI4OA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968288", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg2MTEzNw=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java b/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java\ndeleted file mode 100644\nindex 068c3f6871..0000000000\n--- a/graylog-storage-elasticsearch7/src/main/java/org/graylog/storage/elasticsearch7/views/searchtypes/pivot/series/ESCountHandler.java\n+++ /dev/null\n\n@@ -1,140 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series;\n-\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.PivotSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Count;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilder;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.AggregationBuilders;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.HasAggregations;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.MultiBucketsAggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCount;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ValueCountAggregationBuilder;\n-import org.graylog.storage.elasticsearch7.views.ESGeneratedQueryContext;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.jooq.lambda.tuple.Tuple2;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nonnull;\n-import java.io.IOException;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.Stream;\n-\n-public class ESCountHandler extends ESPivotSeriesSpecHandler<Count, ValueCount> {\n-    private static final Logger LOG = LoggerFactory.getLogger(ESCountHandler.class);\n-\n-    @Nonnull\n-    @Override\n-    public Optional<AggregationBuilder> doCreateAggregation(String name, Pivot pivot, Count count, ESPivot searchTypeHandler, ESGeneratedQueryContext queryContext) {\n-        final String field = count.field();\n-        if (field == null) {\n-            // doc_count is always present in elasticsearch's bucket aggregations, no need to add it\n-            return Optional.empty();\n-        } else {\n-            // the request was for a field count, we have to add a value_count sub aggregation\n-            final ValueCountAggregationBuilder value = AggregationBuilders.count(name).field(field);\n-            record(queryContext, pivot, count, name, ValueCount.class);\n-            return Optional.of(value);\n-        }\n-    }\n-\n-    @Override\n-    public Stream<Value> doHandleResult(Pivot pivot,\n-                                        Count count,\n-                                        SearchResponse searchResult,\n-                                        ValueCount metricAggregation,\n-                                        ESPivot searchTypeHandler,\n-                                        ESGeneratedQueryContext esGeneratedQueryContext) {\n-        Object value = null;\n-        if (metricAggregation instanceof MultiBucketsAggregation.Bucket) {\n-            value = ((MultiBucketsAggregation.Bucket) metricAggregation).getDocCount();\n-        } else if (metricAggregation instanceof Aggregations) {\n-            value = searchResult.getHits().getTotalHits().value;\n-        } else if (metricAggregation != null) {\n-            value = metricAggregation.getValue();\n-        }\n-        if (value == null) {\n-            LOG.error(\"Unexpected aggregation type {}, returning 0 for the count. This is a bug.\", metricAggregation);\n-            value = 0;\n-        }\n-        return Stream.of(Value.create(count.id(), Count.NAME, value));\n-    }\n-\n-    @Override\n-    protected Aggregation extractAggregationFromResult(Pivot pivot, PivotSpec spec, HasAggregations aggregations, ESGeneratedQueryContext queryContext) {\n-        final Tuple2<String, Class<? extends Aggregation>> objects = aggTypes(queryContext, pivot).getTypes(spec);\n-        if (objects == null) {\n-            if (aggregations instanceof MultiBucketsAggregation.Bucket) {\n-                return createValueCount((MultiBucketsAggregation.Bucket) aggregations);\n-            }\n-        } else {\n-            // try to saved sub aggregation type. this might fail if we refer to the total result of the entire result instead of a specific\n-            // value_count aggregation. we'll handle that special case in doHandleResult above\n-            return aggregations.getAggregations().get(objects.v1);\n-        }\n-\n-        return null;\n-    }\n-\n-    private Aggregation createValueCount(MultiBucketsAggregation.Bucket aggregations) {\n-        final Long docCount = aggregations.getDocCount();\n-        return new ValueCount() {\n-            @Override\n-            public long getValue() {\n-                return docCount;\n-            }\n-\n-            @Override\n-            public double value() {\n-                return docCount;\n-            }\n-\n-            @Override\n-            public String getValueAsString() {\n-                return docCount.toString();\n-            }\n-\n-            @Override\n-            public String getName() {\n-                return null;\n-            }\n-\n-            @Override\n-            public String getType() {\n-                return null;\n-            }\n-\n-            @Override\n-            public Map<String, Object> getMetaData() {\n-                return null;\n-            }\n-\n-            @Override\n-            public XContentBuilder toXContent(XContentBuilder xContentBuilder, Params params) throws IOException {\n-                return null;\n-            }\n-        };\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NDUzNw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458884537", "bodyText": "Unused. Can be deleted.", "author": "alex-konn", "createdAt": "2020-07-22T15:34:32Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views;\n+\n+import com.google.common.collect.ImmutableSet;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.QueryResult;\n+import org.graylog.plugins.views.search.Search;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n+import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import javax.inject.Provider;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n+    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n+\n+    @Rule\n+    public MockitoRule rule = MockitoJUnit.rule();\n+\n+    ElasticsearchBackend elasticsearchBackend;\n+\n+    @Mock\n+    protected ElasticsearchClient client;\n+\n+    @Mock\n+    protected IndexLookup indexLookup;\n+\n+    @Mock\n+    protected FieldTypesLookup fieldTypesLookup;\n+\n+    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n+\n+    @Captor\n+    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n+\n+    @Before\n+    public void setUpSUT() {\n+        this.elasticSearchTypeHandlers = new HashMap<>();\n+        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n+        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n+        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n+        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n+        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n+\n+        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n+                queryStringParser,\n+                client,\n+                indexLookup,\n+                new QueryStringDecorators.Fake(),\n+                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n+                false);\n+    }\n+\n+    SearchJob searchJobForQuery(Query query) {\n+        final Search search = Search.builder()\n+                .id(\"search1\")\n+                .queries(ImmutableSet.of(query))\n+                .build();\n+        return new SearchJob(\"job1\", search, \"admin\");\n+    }\n+\n+    TimeRange timeRangeForTest() {\n+        try {\n+            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n+        } catch (InvalidRangeParametersException ignored) {\n+        }\n+        return null;\n+    }\n+\n+    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {\n+        this.elasticsearchBackend.doRun(searchJob, query, queryContext, predecessorResults);\n+\n+        verify(client, times(1)).msearch(clientRequestCaptor.capture(), any());\n+\n+        final List<SearchRequest> generatedSearch = clientRequestCaptor.getValue();\n+        return generatedSearch;\n+    }\n+\n+    String resourceFile(String filename) {", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODI2OQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968269", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NDUzNw=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\ndeleted file mode 100644\nindex debecc6d2a..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\n+++ /dev/null\n\n@@ -1,147 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views;\n-\n-import com.google.common.collect.ImmutableSet;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.QueryResult;\n-import org.graylog.plugins.views.search.Search;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n-import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Captor;\n-import org.mockito.Mock;\n-import org.mockito.junit.MockitoJUnit;\n-import org.mockito.junit.MockitoRule;\n-\n-import javax.inject.Provider;\n-import java.io.IOException;\n-import java.net.URISyntaxException;\n-import java.net.URL;\n-import java.nio.charset.StandardCharsets;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-\n-public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n-    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n-\n-    @Rule\n-    public MockitoRule rule = MockitoJUnit.rule();\n-\n-    ElasticsearchBackend elasticsearchBackend;\n-\n-    @Mock\n-    protected ElasticsearchClient client;\n-\n-    @Mock\n-    protected IndexLookup indexLookup;\n-\n-    @Mock\n-    protected FieldTypesLookup fieldTypesLookup;\n-\n-    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n-\n-    @Captor\n-    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n-\n-    @Before\n-    public void setUpSUT() {\n-        this.elasticSearchTypeHandlers = new HashMap<>();\n-        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n-        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n-        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n-        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n-        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n-\n-        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n-                queryStringParser,\n-                client,\n-                indexLookup,\n-                new QueryStringDecorators.Fake(),\n-                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n-                false);\n-    }\n-\n-    SearchJob searchJobForQuery(Query query) {\n-        final Search search = Search.builder()\n-                .id(\"search1\")\n-                .queries(ImmutableSet.of(query))\n-                .build();\n-        return new SearchJob(\"job1\", search, \"admin\");\n-    }\n-\n-    TimeRange timeRangeForTest() {\n-        try {\n-            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n-        } catch (InvalidRangeParametersException ignored) {\n-        }\n-        return null;\n-    }\n-\n-    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {\n-        this.elasticsearchBackend.doRun(searchJob, query, queryContext, predecessorResults);\n-\n-        verify(client, times(1)).msearch(clientRequestCaptor.capture(), any());\n-\n-        final List<SearchRequest> generatedSearch = clientRequestCaptor.getValue();\n-        return generatedSearch;\n-    }\n-\n-    String resourceFile(String filename) {\n-        try {\n-            final URL resource = this.getClass().getResource(filename);\n-            final Path path = Paths.get(resource.toURI());\n-            final byte[] bytes = Files.readAllBytes(path);\n-            return new String(bytes, StandardCharsets.UTF_8);\n-        } catch (IOException | URISyntaxException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NTI3NA==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458885274", "bodyText": "Variable is redundant. We can return clientRequestCaptor.getValue(); directly.", "author": "alex-konn", "createdAt": "2020-07-22T15:35:34Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views;\n+\n+import com.google.common.collect.ImmutableSet;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.QueryResult;\n+import org.graylog.plugins.views.search.Search;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n+import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import javax.inject.Provider;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n+    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n+\n+    @Rule\n+    public MockitoRule rule = MockitoJUnit.rule();\n+\n+    ElasticsearchBackend elasticsearchBackend;\n+\n+    @Mock\n+    protected ElasticsearchClient client;\n+\n+    @Mock\n+    protected IndexLookup indexLookup;\n+\n+    @Mock\n+    protected FieldTypesLookup fieldTypesLookup;\n+\n+    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n+\n+    @Captor\n+    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n+\n+    @Before\n+    public void setUpSUT() {\n+        this.elasticSearchTypeHandlers = new HashMap<>();\n+        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n+        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n+        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n+        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n+        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n+\n+        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n+                queryStringParser,\n+                client,\n+                indexLookup,\n+                new QueryStringDecorators.Fake(),\n+                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n+                false);\n+    }\n+\n+    SearchJob searchJobForQuery(Query query) {\n+        final Search search = Search.builder()\n+                .id(\"search1\")\n+                .queries(ImmutableSet.of(query))\n+                .build();\n+        return new SearchJob(\"job1\", search, \"admin\");\n+    }\n+\n+    TimeRange timeRangeForTest() {\n+        try {\n+            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n+        } catch (InvalidRangeParametersException ignored) {\n+        }\n+        return null;\n+    }\n+\n+    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {\n+        this.elasticsearchBackend.doRun(searchJob, query, queryContext, predecessorResults);\n+\n+        verify(client, times(1)).msearch(clientRequestCaptor.capture(), any());\n+\n+        final List<SearchRequest> generatedSearch = clientRequestCaptor.getValue();", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODI1Nw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968257", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NTI3NA=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\ndeleted file mode 100644\nindex debecc6d2a..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\n+++ /dev/null\n\n@@ -1,147 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views;\n-\n-import com.google.common.collect.ImmutableSet;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.QueryResult;\n-import org.graylog.plugins.views.search.Search;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n-import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Captor;\n-import org.mockito.Mock;\n-import org.mockito.junit.MockitoJUnit;\n-import org.mockito.junit.MockitoRule;\n-\n-import javax.inject.Provider;\n-import java.io.IOException;\n-import java.net.URISyntaxException;\n-import java.net.URL;\n-import java.nio.charset.StandardCharsets;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-\n-public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n-    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n-\n-    @Rule\n-    public MockitoRule rule = MockitoJUnit.rule();\n-\n-    ElasticsearchBackend elasticsearchBackend;\n-\n-    @Mock\n-    protected ElasticsearchClient client;\n-\n-    @Mock\n-    protected IndexLookup indexLookup;\n-\n-    @Mock\n-    protected FieldTypesLookup fieldTypesLookup;\n-\n-    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n-\n-    @Captor\n-    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n-\n-    @Before\n-    public void setUpSUT() {\n-        this.elasticSearchTypeHandlers = new HashMap<>();\n-        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n-        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n-        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n-        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n-        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n-\n-        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n-                queryStringParser,\n-                client,\n-                indexLookup,\n-                new QueryStringDecorators.Fake(),\n-                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n-                false);\n-    }\n-\n-    SearchJob searchJobForQuery(Query query) {\n-        final Search search = Search.builder()\n-                .id(\"search1\")\n-                .queries(ImmutableSet.of(query))\n-                .build();\n-        return new SearchJob(\"job1\", search, \"admin\");\n-    }\n-\n-    TimeRange timeRangeForTest() {\n-        try {\n-            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n-        } catch (InvalidRangeParametersException ignored) {\n-        }\n-        return null;\n-    }\n-\n-    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {\n-        this.elasticsearchBackend.doRun(searchJob, query, queryContext, predecessorResults);\n-\n-        verify(client, times(1)).msearch(clientRequestCaptor.capture(), any());\n-\n-        final List<SearchRequest> generatedSearch = clientRequestCaptor.getValue();\n-        return generatedSearch;\n-    }\n-\n-    String resourceFile(String filename) {\n-        try {\n-            final URL resource = this.getClass().getResource(filename);\n-            final Path path = Paths.get(resource.toURI());\n-            final byte[] bytes = Files.readAllBytes(path);\n-            return new String(bytes, StandardCharsets.UTF_8);\n-        } catch (IOException | URISyntaxException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NjYzMQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r458886631", "bodyText": "IOException is never thrown.", "author": "alex-konn", "createdAt": "2020-07-22T15:37:27Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views;\n+\n+import com.google.common.collect.ImmutableSet;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.QueryResult;\n+import org.graylog.plugins.views.search.Search;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n+import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n+import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n+import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n+import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import javax.inject.Provider;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n+    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n+\n+    @Rule\n+    public MockitoRule rule = MockitoJUnit.rule();\n+\n+    ElasticsearchBackend elasticsearchBackend;\n+\n+    @Mock\n+    protected ElasticsearchClient client;\n+\n+    @Mock\n+    protected IndexLookup indexLookup;\n+\n+    @Mock\n+    protected FieldTypesLookup fieldTypesLookup;\n+\n+    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n+\n+    @Captor\n+    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n+\n+    @Before\n+    public void setUpSUT() {\n+        this.elasticSearchTypeHandlers = new HashMap<>();\n+        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n+        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n+        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n+        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n+        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n+\n+        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n+                queryStringParser,\n+                client,\n+                indexLookup,\n+                new QueryStringDecorators.Fake(),\n+                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n+                false);\n+    }\n+\n+    SearchJob searchJobForQuery(Query query) {\n+        final Search search = Search.builder()\n+                .id(\"search1\")\n+                .queries(ImmutableSet.of(query))\n+                .build();\n+        return new SearchJob(\"job1\", search, \"admin\");\n+    }\n+\n+    TimeRange timeRangeForTest() {\n+        try {\n+            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n+        } catch (InvalidRangeParametersException ignored) {\n+        }\n+        return null;\n+    }\n+\n+    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {", "originalCommit": "353b51fc70dc7e8ae28c94ee641cbad0d6f543d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODI0NQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968245", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg4NjYzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\ndeleted file mode 100644\nindex debecc6d2a..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendGeneratedRequestTestBase.java\n+++ /dev/null\n\n@@ -1,147 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views;\n-\n-import com.google.common.collect.ImmutableSet;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.QueryResult;\n-import org.graylog.plugins.views.search.Search;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.FieldTypesLookup;\n-import org.graylog.plugins.views.search.elasticsearch.IndexLookup;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringDecorators;\n-import org.graylog.plugins.views.search.elasticsearch.QueryStringParser;\n-import org.graylog.plugins.views.search.searchtypes.pivot.BucketSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.SeriesSpec;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.storage.elasticsearch7.ElasticsearchClient;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.ESSearchTypeHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivot;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotBucketSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.ESPivotSeriesSpecHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESAverageHandler;\n-import org.graylog.storage.elasticsearch7.views.searchtypes.pivot.series.ESMaxHandler;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.mockito.ArgumentCaptor;\n-import org.mockito.Captor;\n-import org.mockito.Mock;\n-import org.mockito.junit.MockitoJUnit;\n-import org.mockito.junit.MockitoRule;\n-\n-import javax.inject.Provider;\n-import java.io.IOException;\n-import java.net.URISyntaxException;\n-import java.net.URL;\n-import java.nio.charset.StandardCharsets;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.times;\n-import static org.mockito.Mockito.verify;\n-\n-public class ElasticsearchBackendGeneratedRequestTestBase extends ElasticsearchBackendTestBase {\n-    protected static final QueryStringParser queryStringParser = new QueryStringParser();\n-\n-    @Rule\n-    public MockitoRule rule = MockitoJUnit.rule();\n-\n-    ElasticsearchBackend elasticsearchBackend;\n-\n-    @Mock\n-    protected ElasticsearchClient client;\n-\n-    @Mock\n-    protected IndexLookup indexLookup;\n-\n-    @Mock\n-    protected FieldTypesLookup fieldTypesLookup;\n-\n-    protected Map<String, Provider<ESSearchTypeHandler<? extends SearchType>>> elasticSearchTypeHandlers;\n-\n-    @Captor\n-    protected ArgumentCaptor<List<SearchRequest>> clientRequestCaptor;\n-\n-    @Before\n-    public void setUpSUT() {\n-        this.elasticSearchTypeHandlers = new HashMap<>();\n-        final Map<String, ESPivotBucketSpecHandler<? extends BucketSpec, ? extends Aggregation>> bucketHandlers = Collections.emptyMap();\n-        final Map<String, ESPivotSeriesSpecHandler<? extends SeriesSpec, ? extends Aggregation>> seriesHandlers = new HashMap<>();\n-        seriesHandlers.put(Average.NAME, new ESAverageHandler());\n-        seriesHandlers.put(Max.NAME, new ESMaxHandler());\n-        elasticSearchTypeHandlers.put(Pivot.NAME, () -> new ESPivot(bucketHandlers, seriesHandlers));\n-\n-        this.elasticsearchBackend = new ElasticsearchBackend(elasticSearchTypeHandlers,\n-                queryStringParser,\n-                client,\n-                indexLookup,\n-                new QueryStringDecorators.Fake(),\n-                (elasticsearchBackend, ssb, job, query, results) -> new ESGeneratedQueryContext(elasticsearchBackend, ssb, job, query, results, fieldTypesLookup),\n-                false);\n-    }\n-\n-    SearchJob searchJobForQuery(Query query) {\n-        final Search search = Search.builder()\n-                .id(\"search1\")\n-                .queries(ImmutableSet.of(query))\n-                .build();\n-        return new SearchJob(\"job1\", search, \"admin\");\n-    }\n-\n-    TimeRange timeRangeForTest() {\n-        try {\n-            return AbsoluteRange.create(\"2018-08-23T10:02:00.247+02:00\", \"2018-08-23T10:07:00.252+02:00\");\n-        } catch (InvalidRangeParametersException ignored) {\n-        }\n-        return null;\n-    }\n-\n-    List<SearchRequest> run(SearchJob searchJob, Query query, ESGeneratedQueryContext queryContext, Set<QueryResult> predecessorResults) throws IOException {\n-        this.elasticsearchBackend.doRun(searchJob, query, queryContext, predecessorResults);\n-\n-        verify(client, times(1)).msearch(clientRequestCaptor.capture(), any());\n-\n-        final List<SearchRequest> generatedSearch = clientRequestCaptor.getValue();\n-        return generatedSearch;\n-    }\n-\n-    String resourceFile(String filename) {\n-        try {\n-            final URL resource = this.getClass().getResource(filename);\n-            final Path path = Paths.get(resource.toURI());\n-            final byte[] bytes = Files.readAllBytes(path);\n-            return new String(bytes, StandardCharsets.UTF_8);\n-        } catch (IOException | URISyntaxException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM1Mzk5OQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459353999", "bodyText": "Unused", "author": "alex-konn", "createdAt": "2020-07-23T10:26:40Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendSearchTypeOverridesTest.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views;\n+\n+import com.google.common.collect.ImmutableSet;\n+import com.jayway.jsonpath.Configuration;\n+import com.jayway.jsonpath.DocumentContext;\n+import com.jayway.jsonpath.JsonPath;\n+import com.jayway.jsonpath.TypeRef;\n+import com.jayway.jsonpath.spi.mapper.JacksonMappingProvider;\n+import com.revinate.assertj.json.JsonPathAssert;\n+import org.graylog.plugins.views.search.Query;\n+import org.graylog.plugins.views.search.SearchJob;\n+import org.graylog.plugins.views.search.SearchType;\n+import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n+import org.graylog.plugins.views.search.filter.StreamFilter;\n+import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n+import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n+import org.graylog.plugins.views.search.timeranges.DerivedTimeRange;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.MultiSearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n+import org.graylog.storage.elasticsearch7.testing.TestMultisearchResponse;\n+import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n+import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n+import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.when;\n+\n+public class ElasticsearchBackendSearchTypeOverridesTest extends ElasticsearchBackendGeneratedRequestTestBase {\n+    @Rule\n+    public MockitoRule rule = MockitoJUnit.rule();\n+\n+    private SearchJob searchJob;\n+    private Query query;\n+\n+    @Before\n+    public void setUpFixtures() throws InvalidRangeParametersException {\n+        final Set<SearchType> searchTypes = new HashSet<SearchType>() {{\n+            add(\n+                    Pivot.builder()\n+                            .id(\"pivot1\")\n+                            .series(Collections.singletonList(Average.builder().field(\"field1\").build()))\n+                            .rollup(true)\n+                            .timerange(DerivedTimeRange.of(AbsoluteRange.create(\"2019-09-11T10:31:52.819Z\", \"2019-09-11T10:36:52.823Z\")))\n+                            .build()\n+            );\n+            add(\n+                    Pivot.builder()\n+                            .id(\"pivot2\")\n+                            .series(Collections.singletonList(Max.builder().field(\"field2\").build()))\n+                            .rollup(true)\n+                            .query(ElasticsearchQueryString.builder().queryString(\"source:babbage\").build())\n+                            .build()\n+            );\n+        }};\n+        this.query = Query.builder()\n+                .id(\"query1\")\n+                .searchTypes(searchTypes)\n+                .query(ElasticsearchQueryString.builder().queryString(\"production:true\").build())\n+                .filter(StreamFilter.ofId(\"stream1\"))\n+                .timerange(timeRangeForTest())\n+                .build();\n+\n+        this.searchJob = searchJobForQuery(this.query);\n+    }\n+\n+    @Test\n+    public void overridesInSearchTypeAreIncorporatedIntoGeneratedQueries() throws IOException {\n+        final ESGeneratedQueryContext queryContext = this.elasticsearchBackend.generate(searchJob, query, Collections.emptySet());\n+        final MultiSearchResponse response = TestMultisearchResponse.fromFixture(\"successfulMultiSearchResponse.json\");\n+        final List<MultiSearchResponse.Item> items = Arrays.stream(response.getResponses())\n+                .collect(Collectors.toList());\n+        when(client.msearch(any(), any())).thenReturn(items);\n+\n+        final List<SearchRequest> generatedRequest = run(searchJob, query, queryContext, Collections.emptySet());\n+\n+        final DocumentContext pivot1 = parse(generatedRequest.get(0).source().toString());\n+        final DocumentContext pivot2 = parse(generatedRequest.get(1).source().toString());\n+\n+        assertThat(queryStrings(pivot1)).containsExactly(\"production:true\");\n+        assertThat(timerangeFrom(pivot1)).containsExactly(\"2019-09-11 10:31:52.819\");\n+        assertThat(timerangeTo(pivot1)).containsExactly(\"2019-09-11 10:36:52.823\");\n+        assertThat(streams(pivot1)).containsExactly(Collections.singletonList(\"stream1\"));\n+\n+        assertThat(queryStrings(pivot2)).containsExactly(\"production:true\", \"source:babbage\");\n+        assertThat(timerangeFrom(pivot2)).containsExactly(\"2018-08-23 08:02:00.247\");\n+        assertThat(timerangeTo(pivot2)).containsExactly(\"2018-08-23 08:07:00.252\");\n+        assertThat(streams(pivot2)).containsExactly(Collections.singletonList(\"stream1\"));\n+    }\n+\n+    private DocumentContext parse(String json) {\n+        return JsonPath\n+                .using(Configuration.builder()\n+                        .mappingProvider(new JacksonMappingProvider())\n+                        .build())\n+                .parse(json);\n+    }\n+\n+    private List<String> queryStrings(DocumentContext pivot) {\n+        return pivot.read(\"$..query_string.query\", new TypeRef<List<String>>() {});\n+    }\n+\n+    private List<List<String>> streams(DocumentContext pivot) {\n+        return pivot.read(\"$..terms.streams\", new TypeRef<List<List<String>>>() {});\n+    }\n+\n+    private List<String> timerangeFrom(DocumentContext pivot) {\n+        return pivot.read(\"$..timestamp.from\", new TypeRef<List<String>>() {});\n+    }\n+\n+    private List<String> timerangeTo(DocumentContext pivot) {\n+        return pivot.read(\"$..timestamp.to\", new TypeRef<List<String>>() {});\n+    }\n+\n+    @Test\n+    public void timerangeOverridesAffectIndicesSelection() throws IOException, InvalidRangeParametersException {\n+        when(indexLookup.indexNamesForStreamsInTimeRange(ImmutableSet.of(\"stream1\"), timeRangeForTest()))\n+                .thenReturn(ImmutableSet.of(\"queryIndex\"));\n+\n+        TimeRange tr = AbsoluteRange.create(\"2019-09-11T10:31:52.819Z\", \"2019-09-11T10:36:52.823Z\");\n+        when(indexLookup.indexNamesForStreamsInTimeRange(ImmutableSet.of(\"stream1\"), tr))\n+                .thenReturn(ImmutableSet.of(\"searchTypeIndex\"));\n+\n+        final ESGeneratedQueryContext queryContext = this.elasticsearchBackend.generate(searchJob, query, Collections.emptySet());\n+        final MultiSearchResponse response = TestMultisearchResponse.fromFixture(\"successfulMultiSearchResponse.json\");\n+        final List<MultiSearchResponse.Item> items = Arrays.stream(response.getResponses())\n+                .collect(Collectors.toList());\n+        when(client.msearch(any(), any())).thenReturn(items);\n+\n+        final List<SearchRequest> generatedRequest = run(searchJob, query, queryContext, Collections.emptySet());\n+\n+        assertThat(indicesOf(generatedRequest))\n+                .hasSize(2)\n+                .containsExactly(\n+                        \"searchTypeIndex\",\n+                        \"queryIndex\"\n+                );\n+    }\n+\n+    private JsonPathAssert jsonAssertThat(DocumentContext ctx) {", "originalCommit": "e06354447723de4e186ca8fdea3318f49f15e835", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk2ODIzMg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459968232", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM1Mzk5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendSearchTypeOverridesTest.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendSearchTypeOverridesTest.java\ndeleted file mode 100644\nindex 86ca985af3..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendSearchTypeOverridesTest.java\n+++ /dev/null\n\n@@ -1,173 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views;\n-\n-import com.google.common.collect.ImmutableSet;\n-import com.jayway.jsonpath.Configuration;\n-import com.jayway.jsonpath.DocumentContext;\n-import com.jayway.jsonpath.JsonPath;\n-import com.jayway.jsonpath.TypeRef;\n-import com.jayway.jsonpath.spi.mapper.JacksonMappingProvider;\n-import com.revinate.assertj.json.JsonPathAssert;\n-import org.graylog.plugins.views.search.Query;\n-import org.graylog.plugins.views.search.SearchJob;\n-import org.graylog.plugins.views.search.SearchType;\n-import org.graylog.plugins.views.search.elasticsearch.ElasticsearchQueryString;\n-import org.graylog.plugins.views.search.filter.StreamFilter;\n-import org.graylog.plugins.views.search.searchtypes.pivot.Pivot;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Average;\n-import org.graylog.plugins.views.search.searchtypes.pivot.series.Max;\n-import org.graylog.plugins.views.search.timeranges.DerivedTimeRange;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.MultiSearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n-import org.graylog.storage.elasticsearch7.testing.TestMultisearchResponse;\n-import org.graylog2.plugin.indexer.searches.timeranges.AbsoluteRange;\n-import org.graylog2.plugin.indexer.searches.timeranges.InvalidRangeParametersException;\n-import org.graylog2.plugin.indexer.searches.timeranges.TimeRange;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.mockito.junit.MockitoJUnit;\n-import org.mockito.junit.MockitoRule;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Set;\n-import java.util.stream.Collectors;\n-\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.mockito.ArgumentMatchers.any;\n-import static org.mockito.Mockito.when;\n-\n-public class ElasticsearchBackendSearchTypeOverridesTest extends ElasticsearchBackendGeneratedRequestTestBase {\n-    @Rule\n-    public MockitoRule rule = MockitoJUnit.rule();\n-\n-    private SearchJob searchJob;\n-    private Query query;\n-\n-    @Before\n-    public void setUpFixtures() throws InvalidRangeParametersException {\n-        final Set<SearchType> searchTypes = new HashSet<SearchType>() {{\n-            add(\n-                    Pivot.builder()\n-                            .id(\"pivot1\")\n-                            .series(Collections.singletonList(Average.builder().field(\"field1\").build()))\n-                            .rollup(true)\n-                            .timerange(DerivedTimeRange.of(AbsoluteRange.create(\"2019-09-11T10:31:52.819Z\", \"2019-09-11T10:36:52.823Z\")))\n-                            .build()\n-            );\n-            add(\n-                    Pivot.builder()\n-                            .id(\"pivot2\")\n-                            .series(Collections.singletonList(Max.builder().field(\"field2\").build()))\n-                            .rollup(true)\n-                            .query(ElasticsearchQueryString.builder().queryString(\"source:babbage\").build())\n-                            .build()\n-            );\n-        }};\n-        this.query = Query.builder()\n-                .id(\"query1\")\n-                .searchTypes(searchTypes)\n-                .query(ElasticsearchQueryString.builder().queryString(\"production:true\").build())\n-                .filter(StreamFilter.ofId(\"stream1\"))\n-                .timerange(timeRangeForTest())\n-                .build();\n-\n-        this.searchJob = searchJobForQuery(this.query);\n-    }\n-\n-    @Test\n-    public void overridesInSearchTypeAreIncorporatedIntoGeneratedQueries() throws IOException {\n-        final ESGeneratedQueryContext queryContext = this.elasticsearchBackend.generate(searchJob, query, Collections.emptySet());\n-        final MultiSearchResponse response = TestMultisearchResponse.fromFixture(\"successfulMultiSearchResponse.json\");\n-        final List<MultiSearchResponse.Item> items = Arrays.stream(response.getResponses())\n-                .collect(Collectors.toList());\n-        when(client.msearch(any(), any())).thenReturn(items);\n-\n-        final List<SearchRequest> generatedRequest = run(searchJob, query, queryContext, Collections.emptySet());\n-\n-        final DocumentContext pivot1 = parse(generatedRequest.get(0).source().toString());\n-        final DocumentContext pivot2 = parse(generatedRequest.get(1).source().toString());\n-\n-        assertThat(queryStrings(pivot1)).containsExactly(\"production:true\");\n-        assertThat(timerangeFrom(pivot1)).containsExactly(\"2019-09-11 10:31:52.819\");\n-        assertThat(timerangeTo(pivot1)).containsExactly(\"2019-09-11 10:36:52.823\");\n-        assertThat(streams(pivot1)).containsExactly(Collections.singletonList(\"stream1\"));\n-\n-        assertThat(queryStrings(pivot2)).containsExactly(\"production:true\", \"source:babbage\");\n-        assertThat(timerangeFrom(pivot2)).containsExactly(\"2018-08-23 08:02:00.247\");\n-        assertThat(timerangeTo(pivot2)).containsExactly(\"2018-08-23 08:07:00.252\");\n-        assertThat(streams(pivot2)).containsExactly(Collections.singletonList(\"stream1\"));\n-    }\n-\n-    private DocumentContext parse(String json) {\n-        return JsonPath\n-                .using(Configuration.builder()\n-                        .mappingProvider(new JacksonMappingProvider())\n-                        .build())\n-                .parse(json);\n-    }\n-\n-    private List<String> queryStrings(DocumentContext pivot) {\n-        return pivot.read(\"$..query_string.query\", new TypeRef<List<String>>() {});\n-    }\n-\n-    private List<List<String>> streams(DocumentContext pivot) {\n-        return pivot.read(\"$..terms.streams\", new TypeRef<List<List<String>>>() {});\n-    }\n-\n-    private List<String> timerangeFrom(DocumentContext pivot) {\n-        return pivot.read(\"$..timestamp.from\", new TypeRef<List<String>>() {});\n-    }\n-\n-    private List<String> timerangeTo(DocumentContext pivot) {\n-        return pivot.read(\"$..timestamp.to\", new TypeRef<List<String>>() {});\n-    }\n-\n-    @Test\n-    public void timerangeOverridesAffectIndicesSelection() throws IOException, InvalidRangeParametersException {\n-        when(indexLookup.indexNamesForStreamsInTimeRange(ImmutableSet.of(\"stream1\"), timeRangeForTest()))\n-                .thenReturn(ImmutableSet.of(\"queryIndex\"));\n-\n-        TimeRange tr = AbsoluteRange.create(\"2019-09-11T10:31:52.819Z\", \"2019-09-11T10:36:52.823Z\");\n-        when(indexLookup.indexNamesForStreamsInTimeRange(ImmutableSet.of(\"stream1\"), tr))\n-                .thenReturn(ImmutableSet.of(\"searchTypeIndex\"));\n-\n-        final ESGeneratedQueryContext queryContext = this.elasticsearchBackend.generate(searchJob, query, Collections.emptySet());\n-        final MultiSearchResponse response = TestMultisearchResponse.fromFixture(\"successfulMultiSearchResponse.json\");\n-        final List<MultiSearchResponse.Item> items = Arrays.stream(response.getResponses())\n-                .collect(Collectors.toList());\n-        when(client.msearch(any(), any())).thenReturn(items);\n-\n-        final List<SearchRequest> generatedRequest = run(searchJob, query, queryContext, Collections.emptySet());\n-\n-        assertThat(indicesOf(generatedRequest))\n-                .hasSize(2)\n-                .containsExactly(\n-                        \"searchTypeIndex\",\n-                        \"queryIndex\"\n-                );\n-    }\n-\n-    private JsonPathAssert jsonAssertThat(DocumentContext ctx) {\n-        return JsonPathAssert.assertThat(ctx);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2MDAwOQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459360009", "bodyText": "I don't think it's worth having a base class for one method (objectMapperProvider is unused). At this point I'd prefer making indicesOf static and throw it into a utility class in org.graylog.storage.elasticsearch.testing", "author": "alex-konn", "createdAt": "2020-07-23T10:39:31Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendTestBase.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog.storage.elasticsearch7.views;\n+\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n+import org.graylog2.shared.bindings.providers.ObjectMapperProvider;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+abstract class ElasticsearchBackendTestBase {", "originalCommit": "e06354447723de4e186ca8fdea3318f49f15e835", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk4MzkxNQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459983915", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:55:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2MDAwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendTestBase.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendTestBase.java\ndeleted file mode 100644\nindex c055310592..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/views/ElasticsearchBackendTestBase.java\n+++ /dev/null\n\n@@ -1,34 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog.storage.elasticsearch7.views;\n-\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.SearchRequest;\n-import org.graylog2.shared.bindings.providers.ObjectMapperProvider;\n-\n-import java.io.IOException;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-abstract class ElasticsearchBackendTestBase {\n-    static final ObjectMapperProvider objectMapperProvider = new ObjectMapperProvider();\n-\n-    List<String> indicesOf(List<SearchRequest> clientRequest) throws IOException {\n-        return clientRequest.stream()\n-                .map(request -> String.join(\",\", request.indices()))\n-                .collect(Collectors.toList());\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkyOTQ5Ng==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459929496", "bodyText": "I don't think we should use a base class for a few utility methods. They could become static methods in a utility class instead.\nThey only one that is extensively used is map anyway. list is used once in each subclass, and set is completely unused.", "author": "alex-konn", "createdAt": "2020-07-24T08:51:30Z", "path": "graylog2-server/src/main/java/org/graylog2/indexer/EventsIndexMappingBase.java", "diffHunk": "@@ -0,0 +1,35 @@\n+/**\n+ * This file is part of Graylog.\n+ *\n+ * Graylog is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * Graylog is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU General Public License\n+ * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+package org.graylog2.indexer;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+abstract class EventsIndexMappingBase {", "originalCommit": "296206f46b7dc7957e00b46614440937670fa9e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk4NDgwMQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459984801", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkyOTQ5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog2-server/src/main/java/org/graylog2/indexer/EventsIndexMappingBase.java b/graylog2-server/src/main/java/org/graylog2/indexer/EventsIndexMappingBase.java\ndeleted file mode 100644\nindex 4c1883c054..0000000000\n--- a/graylog2-server/src/main/java/org/graylog2/indexer/EventsIndexMappingBase.java\n+++ /dev/null\n\n@@ -1,35 +0,0 @@\n-/**\n- * This file is part of Graylog.\n- *\n- * Graylog is free software: you can redistribute it and/or modify\n- * it under the terms of the GNU General Public License as published by\n- * the Free Software Foundation, either version 3 of the License, or\n- * (at your option) any later version.\n- *\n- * Graylog is distributed in the hope that it will be useful,\n- * but WITHOUT ANY WARRANTY; without even the implied warranty of\n- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n- * GNU General Public License for more details.\n- *\n- * You should have received a copy of the GNU General Public License\n- * along with Graylog.  If not, see <http://www.gnu.org/licenses/>.\n- */\n-package org.graylog2.indexer;\n-\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.ImmutableSet;\n-\n-abstract class EventsIndexMappingBase {\n-    ImmutableMap.Builder<String, Object> map() {\n-        return ImmutableMap.builder();\n-    }\n-\n-    ImmutableList.Builder<Object> list() {\n-        return ImmutableList.builder();\n-    }\n-\n-    ImmutableSet.Builder<Object> set() {\n-        return ImmutableSet.builder();\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk0NTE2Nw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459945167", "bodyText": "All methods except fromFixture can be private. fromFixture should consequently be moved to the top of the class.", "author": "alex-konn", "createdAt": "2020-07-24T09:23:05Z", "path": "graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/testing/TestMultisearchResponse.java", "diffHunk": "@@ -0,0 +1,128 @@\n+package org.graylog.storage.elasticsearch7.testing;\n+\n+import com.google.common.io.Resources;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.MultiSearchResponse;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.ParseField;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.ContextParser;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentParser;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.composite.ParsedComposite;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.filter.ParsedFilter;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.filter.ParsedFilters;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.global.ParsedGlobal;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedAutoDateHistogram;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedDateHistogram;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedHistogram;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.missing.ParsedMissing;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.nested.ParsedNested;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.nested.ParsedReverseNested;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.range.ParsedDateRange;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.range.ParsedRange;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.sampler.ParsedSampler;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedDoubleTerms;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedLongTerms;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedStringTerms;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedAvg;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedCardinality;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedExtendedStats;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMax;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMedianAbsoluteDeviation;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMin;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedStats;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedSum;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedTopHits;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedValueCount;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedWeightedAvg;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedBucketMetricValue;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedDerivative;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedExtendedStatsBucket;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedPercentilesBucket;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedSimpleValue;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedStatsBucket;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.Suggest;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.completion.CompletionSuggestion;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.phrase.PhraseSuggestion;\n+import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.term.TermSuggestion;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.UncheckedIOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public class TestMultisearchResponse {\n+    static List<NamedXContentRegistry.Entry> getDefaultNamedXContents() {", "originalCommit": "296206f46b7dc7957e00b46614440937670fa9e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk4NDgzMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8547#discussion_r459984833", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-07-24T10:57:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTk0NTE2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "chunk": "diff --git a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/testing/TestMultisearchResponse.java b/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/testing/TestMultisearchResponse.java\ndeleted file mode 100644\nindex 7a300f26e7..0000000000\n--- a/graylog-storage-elasticsearch7/src/test/java/org/graylog/storage/elasticsearch7/testing/TestMultisearchResponse.java\n+++ /dev/null\n\n@@ -1,128 +0,0 @@\n-package org.graylog.storage.elasticsearch7.testing;\n-\n-import com.google.common.io.Resources;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.action.search.MultiSearchResponse;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.ParseField;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.ContextParser;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.NamedXContentRegistry;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.XContentParser;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.common.xcontent.json.JsonXContent;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.Aggregation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.composite.ParsedComposite;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.filter.ParsedFilter;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.filter.ParsedFilters;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.global.ParsedGlobal;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedAutoDateHistogram;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedDateHistogram;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.histogram.ParsedHistogram;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.missing.ParsedMissing;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.nested.ParsedNested;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.nested.ParsedReverseNested;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.range.ParsedDateRange;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.range.ParsedRange;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.sampler.ParsedSampler;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedDoubleTerms;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedLongTerms;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.bucket.terms.ParsedStringTerms;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedAvg;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedCardinality;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedExtendedStats;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMax;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMedianAbsoluteDeviation;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedMin;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedStats;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedSum;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedTopHits;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedValueCount;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.metrics.ParsedWeightedAvg;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedBucketMetricValue;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedDerivative;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedExtendedStatsBucket;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedPercentilesBucket;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedSimpleValue;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.aggregations.pipeline.ParsedStatsBucket;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.Suggest;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.completion.CompletionSuggestion;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.phrase.PhraseSuggestion;\n-import org.graylog.shaded.elasticsearch7.org.elasticsearch.search.suggest.term.TermSuggestion;\n-\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.io.UncheckedIOException;\n-import java.net.URISyntaxException;\n-import java.net.URL;\n-import java.nio.file.Files;\n-import java.nio.file.Path;\n-import java.nio.file.Paths;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.stream.Collectors;\n-\n-public class TestMultisearchResponse {\n-    static List<NamedXContentRegistry.Entry> getDefaultNamedXContents() {\n-        Map<String, ContextParser<Object, ? extends Aggregation>> map = new HashMap<>();\n-        map.put(\"cardinality\", (p, c) -> ParsedCardinality.fromXContent(p, (String)c));\n-        map.put(\"percentiles_bucket\", (p, c) -> ParsedPercentilesBucket.fromXContent(p, (String)c));\n-        map.put(\"median_absolute_deviation\", (p, c) -> ParsedMedianAbsoluteDeviation.fromXContent(p, (String)c));\n-        map.put(\"min\", (p, c) -> ParsedMin.fromXContent(p, (String)c));\n-        map.put(\"max\", (p, c) -> ParsedMax.fromXContent(p, (String)c));\n-        map.put(\"sum\", (p, c) -> ParsedSum.fromXContent(p, (String)c));\n-        map.put(\"avg\", (p, c) -> ParsedAvg.fromXContent(p, (String)c));\n-        map.put(\"weighted_avg\", (p, c) -> ParsedWeightedAvg.fromXContent(p, (String)c));\n-        map.put(\"value_count\", (p, c) -> ParsedValueCount.fromXContent(p, (String)c));\n-        map.put(\"simple_value\", (p, c) -> ParsedSimpleValue.fromXContent(p, (String)c));\n-        map.put(\"derivative\", (p, c) -> ParsedDerivative.fromXContent(p, (String)c));\n-        map.put(\"bucket_metric_value\", (p, c) -> ParsedBucketMetricValue.fromXContent(p, (String)c));\n-        map.put(\"stats\", (p, c) -> ParsedStats.fromXContent(p, (String)c));\n-        map.put(\"stats_bucket\", (p, c) -> ParsedStatsBucket.fromXContent(p, (String)c));\n-        map.put(\"extended_stats\", (p, c) -> ParsedExtendedStats.fromXContent(p, (String)c));\n-        map.put(\"extended_stats_bucket\", (p, c) -> ParsedExtendedStatsBucket.fromXContent(p, (String)c));\n-        map.put(\"histogram\", (p, c) -> ParsedHistogram.fromXContent(p, (String)c));\n-        map.put(\"date_histogram\", (p, c) -> ParsedDateHistogram.fromXContent(p, (String)c));\n-        map.put(\"auto_date_histogram\", (p, c) -> ParsedAutoDateHistogram.fromXContent(p, (String)c));\n-        map.put(\"sterms\", (p, c) -> ParsedStringTerms.fromXContent(p, (String)c));\n-        map.put(\"lterms\", (p, c) -> ParsedLongTerms.fromXContent(p, (String)c));\n-        map.put(\"dterms\", (p, c) -> ParsedDoubleTerms.fromXContent(p, (String)c));\n-        map.put(\"missing\", (p, c) -> ParsedMissing.fromXContent(p, (String)c));\n-        map.put(\"nested\", (p, c) -> ParsedNested.fromXContent(p, (String)c));\n-        map.put(\"reverse_nested\", (p, c) -> ParsedReverseNested.fromXContent(p, (String)c));\n-        map.put(\"global\", (p, c) -> ParsedGlobal.fromXContent(p, (String)c));\n-        map.put(\"filter\", (p, c) -> ParsedFilter.fromXContent(p, (String)c));\n-        map.put(\"sampler\", (p, c) -> ParsedSampler.fromXContent(p, (String)c));\n-        map.put(\"range\", (p, c) -> ParsedRange.fromXContent(p, (String)c));\n-        map.put(\"date_range\", (p, c) -> ParsedDateRange.fromXContent(p, (String)c));\n-        map.put(\"filters\", (p, c) -> ParsedFilters.fromXContent(p, (String)c));\n-        map.put(\"top_hits\", (p, c) -> ParsedTopHits.fromXContent(p, (String)c));\n-        map.put(\"composite\", (p, c) -> ParsedComposite.fromXContent(p, (String)c));\n-\n-        List<NamedXContentRegistry.Entry> entries = map.entrySet().stream().map((entry) -> new NamedXContentRegistry.Entry(Aggregation.class, new ParseField(entry.getKey()), entry.getValue())).collect(Collectors.toList());\n-        entries.add(new NamedXContentRegistry.Entry(Suggest.Suggestion.class, new ParseField(\"term\"), (parser, context) -> TermSuggestion.fromXContent(parser, (String)context)));\n-        entries.add(new NamedXContentRegistry.Entry(Suggest.Suggestion.class, new ParseField(\"phrase\"), (parser, context) -> PhraseSuggestion.fromXContent(parser, (String)context)));\n-        entries.add(new NamedXContentRegistry.Entry(Suggest.Suggestion.class, new ParseField(\"completion\"), (parser, context) -> CompletionSuggestion.fromXContent(parser, (String)context)));\n-        return entries;\n-    }\n-    static MultiSearchResponse resultFor(InputStream result) throws IOException {\n-        final NamedXContentRegistry registry = new NamedXContentRegistry(getDefaultNamedXContents());\n-        final XContentParser parser = JsonXContent.jsonXContent.createParser(registry, LoggingDeprecationHandler.INSTANCE, result);\n-        return MultiSearchResponse.fromXContext(parser);\n-    }\n-\n-    static InputStream resourceFile(String filename) {\n-        try {\n-            @SuppressWarnings(\"UnstableApiUsage\")\n-            final URL resource = Resources.getResource(filename);\n-            final Path path = Paths.get(resource.toURI());\n-            return Files.newInputStream(path);\n-        } catch (IOException e) {\n-            throw new UncheckedIOException(e);\n-        } catch (URISyntaxException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-\n-    public static MultiSearchResponse fromFixture(String filename) throws IOException {\n-        return resultFor(resourceFile(filename));\n-    }\n-}\n"}}, {"oid": "6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "url": "https://github.com/Graylog2/graylog2-server/commit/6e17e40a9e1a28619700476b4aaaf9a6e0a04436", "message": "Removing method which is deprecated since 3.2.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "0519b894c6daa2057a09ba423fb24f43ac275bcb", "url": "https://github.com/Graylog2/graylog2-server/commit/0519b894c6daa2057a09ba423fb24f43ac275bcb", "message": "Provide initial implementation of views code for ES7.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "03e27e1180e9ed7bdd60c907426c50b46dafefa0", "url": "https://github.com/Graylog2/graylog2-server/commit/03e27e1180e9ed7bdd60c907426c50b46dafefa0", "message": "Properly include search source in request.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "980db38756deb0bc83157bdab66e57fd6dc77c99", "url": "https://github.com/Graylog2/graylog2-server/commit/980db38756deb0bc83157bdab66e57fd6dc77c99", "message": "Use correct types to differentiate between buckets and aggregations for ES7 pivot.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "a40232ba07319f3f5c584d4f57d1ebe97ff06a86", "url": "https://github.com/Graylog2/graylog2-server/commit/a40232ba07319f3f5c584d4f57d1ebe97ff06a86", "message": "Using `fixedInterval` instead of deprecated `dateHistogramInterval`.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "d78a9ed9a2b1f41881843c01036b522eb379fb3c", "url": "https://github.com/Graylog2/graylog2-server/commit/d78a9ed9a2b1f41881843c01036b522eb379fb3c", "message": "Adding/fixing tests for ES7 views.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "6875a6ad9952675badf627c7e1e6c4f9e2cf2058", "url": "https://github.com/Graylog2/graylog2-server/commit/6875a6ad9952675badf627c7e1e6c4f9e2cf2058", "message": "Adjusting tests to mocking our client wrapper.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "dc6fd52cd6675063ce7196b6bb4f61126889f442", "url": "https://github.com/Graylog2/graylog2-server/commit/dc6fd52cd6675063ce7196b6bb4f61126889f442", "message": "Fixing handling of all messages time range for effective time range.", "committedDate": "2020-07-24T10:57:00Z", "type": "commit"}, {"oid": "9cc72f66517a87aa792f18fa3058319d4d556384", "url": "https://github.com/Graylog2/graylog2-server/commit/9cc72f66517a87aa792f18fa3058319d4d556384", "message": "Adjusting exception format.", "committedDate": "2020-07-24T10:57:01Z", "type": "commit"}, {"oid": "0c780b940ebb8ff075711fbea4cdf99eb2d811a8", "url": "https://github.com/Graylog2/graylog2-server/commit/0c780b940ebb8ff075711fbea4cdf99eb2d811a8", "message": "Removing unused fixtures, making assertions more robust.", "committedDate": "2020-07-24T10:57:01Z", "type": "commit"}, {"oid": "8932ffc6091209334076b0e6d45ee065e885fd0e", "url": "https://github.com/Graylog2/graylog2-server/commit/8932ffc6091209334076b0e6d45ee065e885fd0e", "message": "Removing unadaptable test.", "committedDate": "2020-07-24T10:57:01Z", "type": "commit"}, {"oid": "4cf3ef3ccc63f2e578641a93de114d5c5b0abe96", "url": "https://github.com/Graylog2/graylog2-server/commit/4cf3ef3ccc63f2e578641a93de114d5c5b0abe96", "message": "Removing support for multiple query backends based on type.", "committedDate": "2020-07-24T10:57:01Z", "type": "commit"}, {"oid": "9c5375af67b6929df4c5a1f755a4b9f8d1283cff", "url": "https://github.com/Graylog2/graylog2-server/commit/9c5375af67b6929df4c5a1f755a4b9f8d1283cff", "message": "Adding backwards-compatible constructor.", "committedDate": "2020-07-24T10:57:01Z", "type": "commit"}, {"oid": "b9e93282c98703c03c4ce1d7317fa158da979181", "url": "https://github.com/Graylog2/graylog2-server/commit/b9e93282c98703c03c4ce1d7317fa158da979181", "message": "Adding events index mapping for ES7.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "67be7c2b52fd0fb292be148257e26f55c023bb48", "url": "https://github.com/Graylog2/graylog2-server/commit/67be7c2b52fd0fb292be148257e26f55c023bb48", "message": "Removing invalid assertion.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "85a8290b9ce8b817d3baac9aebd398e5a0e30cd5", "url": "https://github.com/Graylog2/graylog2-server/commit/85a8290b9ce8b817d3baac9aebd398e5a0e30cd5", "message": "Adjust test to `template` -> `index_patterns` change for index mapping templates.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "6f4d30ddb4a14cbfac2932eab64d6e517c179a5f", "url": "https://github.com/Graylog2/graylog2-server/commit/6f4d30ddb4a14cbfac2932eab64d6e517c179a5f", "message": "Simplifying condition in index mapping factory.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "68160a39db707ea4b6887b8a18a487c5dec9b532", "url": "https://github.com/Graylog2/graylog2-server/commit/68160a39db707ea4b6887b8a18a487c5dec9b532", "message": "Fixing extraction of document count from initial search result.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "e0b2036bc46625db5133569f44a20455537f2106", "url": "https://github.com/Graylog2/graylog2-server/commit/e0b2036bc46625db5133569f44a20455537f2106", "message": "A couple of cleanups.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "4f63f3b9e2ef05ce2844950ad0534aa1c5b913bb", "url": "https://github.com/Graylog2/graylog2-server/commit/4f63f3b9e2ef05ce2844950ad0534aa1c5b913bb", "message": "Some more cleanups.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "8a7ae8ec56f05e80e69de03a49ee793f0a4b99cd", "url": "https://github.com/Graylog2/graylog2-server/commit/8a7ae8ec56f05e80e69de03a49ee793f0a4b99cd", "message": "Getting rid of base class.", "committedDate": "2020-07-24T10:57:02Z", "type": "commit"}, {"oid": "f86ccb19cd163c802eca5fbe6c028b4f4a4f65cd", "url": "https://github.com/Graylog2/graylog2-server/commit/f86ccb19cd163c802eca5fbe6c028b4f4a4f65cd", "message": "Adapting to changes from ES 7.8.0", "committedDate": "2020-07-24T11:10:50Z", "type": "forcePushed"}, {"oid": "0557d61d985dcf4a45e43696767b3bb9b1a9240a", "url": "https://github.com/Graylog2/graylog2-server/commit/0557d61d985dcf4a45e43696767b3bb9b1a9240a", "message": "Adapting to changes from ES 7.8.0", "committedDate": "2020-07-24T11:12:25Z", "type": "commit"}, {"oid": "0557d61d985dcf4a45e43696767b3bb9b1a9240a", "url": "https://github.com/Graylog2/graylog2-server/commit/0557d61d985dcf4a45e43696767b3bb9b1a9240a", "message": "Adapting to changes from ES 7.8.0", "committedDate": "2020-07-24T11:12:25Z", "type": "forcePushed"}, {"oid": "ace707a366e0e420c033e89ce365863f8f5804af", "url": "https://github.com/Graylog2/graylog2-server/commit/ace707a366e0e420c033e89ce365863f8f5804af", "message": "Always return exact number of hits.", "committedDate": "2020-07-24T11:25:24Z", "type": "commit"}, {"oid": "ff10b71a61884174a0dd64e17def817e7b8f8fd7", "url": "https://github.com/Graylog2/graylog2-server/commit/ff10b71a61884174a0dd64e17def817e7b8f8fd7", "message": "Fixing accidental change.", "committedDate": "2020-07-24T12:29:21Z", "type": "commit"}]}