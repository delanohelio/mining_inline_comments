{"pr_number": 8310, "pr_title": "Extract interface from `MoreIndices`/`ElasticsearchProbe` classes to encapsulate ES-specifics", "pr_createdAt": "2020-06-09T15:25:24Z", "pr_url": "https://github.com/Graylog2/graylog2-server/pull/8310", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAxMzAxMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8310#discussion_r438013013", "bodyText": "I think it make sense to move this method into ClusterAdapter (or create a separate interface which ClusterAdapterES6 implements?) and get rid of ElasticsearchProbe completely. Right now ElasticsearchProbe#elasticsearchStats calls 4 different methods from ClusterAdapter, 3 of which are only used here. Those could become private, if the method were moved, thus reducing coupling.\nThe moved method should get the indices as a parameter to avoid a dependency on IndexSetRegistry, i.e. something like this: ClusterAdapter#statsForIndices(List<String> indices).\nIt would imply that org.graylog2.system.stats.ClusterStatsService would need the dependency on IndexSetRegistry, but that seems acceptable to me.", "author": "alex-konn", "createdAt": "2020-06-10T10:10:06Z", "path": "graylog2-server/src/main/java/org/graylog2/system/stats/elasticsearch/ElasticsearchProbe.java", "diffHunk": "@@ -16,107 +16,48 @@\n  */\n package org.graylog2.system.stats.elasticsearch;\n \n-import com.fasterxml.jackson.databind.JsonNode;\n-import com.fasterxml.jackson.databind.node.ArrayNode;\n-import com.fasterxml.jackson.databind.node.JsonNodeType;\n-import com.google.common.collect.Lists;\n import com.google.inject.Singleton;\n-import io.searchbox.client.JestClient;\n-import io.searchbox.client.JestResult;\n-import io.searchbox.cluster.Health;\n-import io.searchbox.cluster.PendingClusterTasks;\n-import io.searchbox.cluster.Stats;\n import org.graylog2.indexer.IndexSetRegistry;\n-import org.graylog2.indexer.cluster.jest.JestUtils;\n+import org.graylog2.indexer.cluster.ClusterAdapter;\n+import org.graylog2.indexer.cluster.PendingTasksStats;\n+import org.graylog2.indexer.indices.HealthStatus;\n \n import javax.inject.Inject;\n import java.util.Arrays;\n import java.util.List;\n-import java.util.Locale;\n \n @Singleton\n public class ElasticsearchProbe {\n-    private final JestClient jestClient;\n     private final IndexSetRegistry indexSetRegistry;\n+    private final ClusterAdapter clusterAdapter;\n \n     @Inject\n-    public ElasticsearchProbe(JestClient jestClient, IndexSetRegistry indexSetRegistry) {\n-        this.jestClient = jestClient;\n+    public ElasticsearchProbe(IndexSetRegistry indexSetRegistry, ClusterAdapter clusterAdapter) {\n         this.indexSetRegistry = indexSetRegistry;\n+        this.clusterAdapter = clusterAdapter;\n     }\n \n     public ElasticsearchStats elasticsearchStats() {", "originalCommit": "7eb8b632ac6d669f7f34b1add1907f513346a510", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA5MDAxMg==", "url": "https://github.com/Graylog2/graylog2-server/pull/8310#discussion_r438090012", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-06-10T12:41:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAxMzAxMw=="}], "type": "inlineReview", "revised_code": {"commit": "0cae9be45139e5e427d97d81ede87ef13beff81b", "chunk": "diff --git a/graylog2-server/src/main/java/org/graylog2/system/stats/elasticsearch/ElasticsearchProbe.java b/graylog2-server/src/main/java/org/graylog2/system/stats/elasticsearch/ElasticsearchProbe.java\nindex bae13c314b..b0ccf4070d 100644\n--- a/graylog2-server/src/main/java/org/graylog2/system/stats/elasticsearch/ElasticsearchProbe.java\n+++ b/graylog2-server/src/main/java/org/graylog2/system/stats/elasticsearch/ElasticsearchProbe.java\n\n@@ -16,48 +16,108 @@\n  */\n package org.graylog2.system.stats.elasticsearch;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.JsonNodeType;\n+import com.google.common.collect.Lists;\n import com.google.inject.Singleton;\n+import io.searchbox.client.JestClient;\n+import io.searchbox.client.JestResult;\n+import io.searchbox.cluster.Health;\n+import io.searchbox.cluster.PendingClusterTasks;\n+import io.searchbox.cluster.Stats;\n import org.graylog2.indexer.IndexSetRegistry;\n-import org.graylog2.indexer.cluster.ClusterAdapter;\n-import org.graylog2.indexer.cluster.PendingTasksStats;\n+import org.graylog2.indexer.cluster.jest.JestUtils;\n import org.graylog2.indexer.indices.HealthStatus;\n \n import javax.inject.Inject;\n import java.util.Arrays;\n import java.util.List;\n+import java.util.Locale;\n \n @Singleton\n public class ElasticsearchProbe {\n+    private final JestClient jestClient;\n     private final IndexSetRegistry indexSetRegistry;\n-    private final ClusterAdapter clusterAdapter;\n \n     @Inject\n-    public ElasticsearchProbe(IndexSetRegistry indexSetRegistry, ClusterAdapter clusterAdapter) {\n+    public ElasticsearchProbe(JestClient jestClient, IndexSetRegistry indexSetRegistry) {\n+        this.jestClient = jestClient;\n         this.indexSetRegistry = indexSetRegistry;\n-        this.clusterAdapter = clusterAdapter;\n     }\n \n     public ElasticsearchStats elasticsearchStats() {\n-        final ClusterStats clusterStats = clusterAdapter.clusterStats();\n+        final JestResult clusterStatsResponse = JestUtils.execute(jestClient, new Stats.Builder().build(), () -> \"Couldn't read Elasticsearch cluster stats\");\n+        final JsonNode clusterStatsResponseJson = clusterStatsResponse.getJsonObject();\n+        final String clusterName = clusterStatsResponseJson.path(\"cluster_name\").asText();\n \n-        final PendingTasksStats pendingTasksStats = clusterAdapter.pendingTasks();\n+        String clusterVersion = null;\n+        if (clusterStatsResponseJson.path(\"nodes\").path(\"versions\").isArray()) {\n+            final ArrayNode versions = (ArrayNode) clusterStatsResponseJson.path(\"nodes\").path(\"versions\");\n+            // We just use the first version in the \"versions\" array. This is not correct if there are different\n+            // versions running in the cluster, but that is not recommended anyway.\n+            final JsonNode versionNode = versions.path(0);\n+            if (versionNode.getNodeType() != JsonNodeType.MISSING) {\n+                clusterVersion = versionNode.asText();\n+            }\n+        }\n \n-        final List<String> indices = Arrays.asList(indexSetRegistry.getIndexWildcards());\n+        final JsonNode countStats = clusterStatsResponseJson.path(\"nodes\").path(\"count\");\n \n-        final ShardStats shardStats = clusterAdapter.shardStats(indices);\n-        final ClusterHealth clusterHealth = ClusterHealth.from(\n-                shardStats,\n-                pendingTasksStats\n+        final NodesStats nodesStats = NodesStats.create(\n+                countStats.path(\"total\").asInt(-1),\n+                countStats.path(\"master_only\").asInt(-1),\n+                countStats.path(\"data_only\").asInt(-1),\n+                countStats.path(\"master_data\").asInt(-1),\n+                countStats.path(\"client\").asInt(-1)\n         );\n-        final HealthStatus healthStatus = clusterAdapter.health(indices).orElseThrow(() -> new IllegalStateException(\"Unable to retrieve cluster health.\"));\n+\n+        final JsonNode clusterIndicesStats = clusterStatsResponseJson.path(\"indices\");\n+        final IndicesStats indicesStats = IndicesStats.create(\n+                clusterIndicesStats.path(\"count\").asInt(-1),\n+                clusterIndicesStats.path(\"store\").path(\"size_in_bytes\").asLong(-1L),\n+                clusterIndicesStats.path(\"fielddata\").path(\"memory_size_in_bytes\").asLong(-1L)\n+        );\n+\n+        final JestResult pendingClusterTasksResponse = JestUtils.execute(jestClient, new PendingClusterTasks.Builder().build(), () -> \"Couldn't read Elasticsearch pending cluster tasks\");\n+        final JsonNode pendingClusterTasks = pendingClusterTasksResponse.getJsonObject().path(\"tasks\");\n+        final int pendingTasksSize = pendingClusterTasks.size();\n+        final List<Long> pendingTasksTimeInQueue = Lists.newArrayListWithCapacity(pendingTasksSize);\n+        for (JsonNode jsonElement : pendingClusterTasks) {\n+            if (jsonElement.has(\"time_in_queue_millis\")) {\n+                pendingTasksTimeInQueue.add(jsonElement.get(\"time_in_queue_millis\").asLong());\n+            }\n+        }\n+\n+        final Health clusterHealthRequest = new Health.Builder()\n+                .addIndex(Arrays.asList(indexSetRegistry.getIndexWildcards()))\n+                .build();\n+        final JestResult clusterHealthResponse = JestUtils.execute(jestClient, clusterHealthRequest, () -> \"Couldn't read Elasticsearch cluster health\");\n+        final JsonNode clusterHealthJson = clusterHealthResponse.getJsonObject();\n+        final ClusterHealth clusterHealth = ClusterHealth.create(\n+                clusterHealthJson.path(\"number_of_nodes\").asInt(-1),\n+                clusterHealthJson.path(\"number_of_data_nodes\").asInt(-1),\n+                clusterHealthJson.path(\"active_shards\").asInt(-1),\n+                clusterHealthJson.path(\"relocating_shards\").asInt(-1),\n+                clusterHealthJson.path(\"active_primary_shards\").asInt(-1),\n+                clusterHealthJson.path(\"initializing_shards\").asInt(-1),\n+                clusterHealthJson.path(\"unassigned_shards\").asInt(-1),\n+                clusterHealthJson.path(\"timed_out\").asBoolean(),\n+                pendingTasksSize,\n+                pendingTasksTimeInQueue\n+        );\n+        final HealthStatus healthStatus = getHealthStatus(clusterHealthJson.path(\"status\").asText(\"RED\"));\n \n         return ElasticsearchStats.create(\n-                clusterStats.clusterName(),\n-                clusterStats.clusterVersion(),\n+                clusterName,\n+                clusterVersion,\n                 healthStatus,\n                 clusterHealth,\n-                clusterStats.nodesStats(),\n-                clusterStats.indicesStats()\n-        );\n+                nodesStats,\n+                indicesStats);\n+    }\n+\n+    private HealthStatus getHealthStatus(String status) {\n+        return HealthStatus.fromString(status.toUpperCase(Locale.ENGLISH));\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAyMTYwMw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8310#discussion_r438021603", "bodyText": "Wouldn't it make sense to rename this to EventIndices while we're at it? I find MoreIndices too vague for it's very specific purpose. EventWriter or EventIndexer would be even more specific. Same would go for MoreIndicesAdapter and MoreIndicesAdapterES6.\nThe method name bulkIndex on the other hand is unnecessarily specific. write would be a fine alternative imo.", "author": "alex-konn", "createdAt": "2020-06-10T10:26:34Z", "path": "graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java", "diffHunk": "@@ -16,50 +16,36 @@\n  */\n package org.graylog.events.indices;\n \n-import com.fasterxml.jackson.databind.ObjectMapper;\n-import io.searchbox.client.JestClient;\n-import io.searchbox.core.Bulk;\n-import io.searchbox.core.BulkResult;\n-import io.searchbox.core.Index;\n import org.graylog.events.event.Event;\n-import org.graylog.events.event.EventDto;\n import org.graylog.events.event.EventWithContext;\n-import org.graylog2.indexer.IndexMapping;\n-import org.graylog2.jackson.TypeReferences;\n import org.graylog2.plugin.database.Persisted;\n import org.graylog2.streams.StreamService;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import javax.inject.Inject;\n import javax.inject.Singleton;\n-import java.io.IOException;\n+import java.util.AbstractMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n import java.util.Set;\n import java.util.stream.Collectors;\n \n-import static java.util.Objects.requireNonNull;\n-import static org.graylog2.plugin.Tools.buildElasticSearchTimeFormat;\n-import static org.joda.time.DateTimeZone.UTC;\n-\n /**\n  * This class contains indices helper for the events system.\n  */\n @Singleton\n public class MoreIndices {", "originalCommit": "7eb8b632ac6d669f7f34b1add1907f513346a510", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA5MDc4Mw==", "url": "https://github.com/Graylog2/graylog2-server/pull/8310#discussion_r438090783", "bodyText": "\u2714\ufe0f", "author": "dennisoelkers", "createdAt": "2020-06-10T12:42:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAyMTYwMw=="}], "type": "inlineReview", "revised_code": {"commit": "0cae9be45139e5e427d97d81ede87ef13beff81b", "chunk": "diff --git a/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java b/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\nindex a2df5152a9..25553e98d4 100644\n--- a/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\n+++ b/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\n\n@@ -16,8 +16,16 @@\n  */\n package org.graylog.events.indices;\n \n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import io.searchbox.client.JestClient;\n+import io.searchbox.core.Bulk;\n+import io.searchbox.core.BulkResult;\n+import io.searchbox.core.Index;\n import org.graylog.events.event.Event;\n+import org.graylog.events.event.EventDto;\n import org.graylog.events.event.EventWithContext;\n+import org.graylog2.indexer.IndexMapping;\n+import org.graylog2.jackson.TypeReferences;\n import org.graylog2.plugin.database.Persisted;\n import org.graylog2.streams.StreamService;\n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAzMDk5NQ==", "url": "https://github.com/Graylog2/graylog2-server/pull/8310#discussion_r438030995", "bodyText": "I would love it, if you could unpack this by extracting lambda blocks to private methods. Ideally we'd only have one line lambdas, which are much easier to read than these nested blocks.", "author": "alex-konn", "createdAt": "2020-06-10T10:45:34Z", "path": "graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java", "diffHunk": "@@ -74,62 +60,26 @@ public void bulkIndex(List<EventWithContext> eventsWithContext) {\n             .collect(Collectors.toSet());\n         final Map<String, String> streamIndices = streamService.loadByIds(streamIds).stream()\n             .collect(Collectors.toMap(Persisted::getId, stream -> stream.getIndexSet().getWriteIndexAlias()));\n-\n-        final Bulk.Builder bulk = new Bulk.Builder();\n-        for (final EventWithContext eventWithContext : eventsWithContext) {\n-            final Event event = eventWithContext.event();\n-\n-            final Map<String, Object> source = objectMapper.convertValue(event.toDto(), TypeReferences.MAP_STRING_OBJECT);\n-\n-            // \"Fix\" timestamps to be in the correct format. Our message index mapping is using this format so we have\n-            // to use it for our events as well to make sure we can use the search without errors.\n-            source.put(EventDto.FIELD_EVENT_TIMESTAMP, buildElasticSearchTimeFormat(requireNonNull(event.getEventTimestamp()).withZone(UTC)));\n-            source.put(EventDto.FIELD_PROCESSING_TIMESTAMP, buildElasticSearchTimeFormat(requireNonNull(event.getProcessingTimestamp()).withZone(UTC)));\n-            if (event.getTimerangeStart() != null) {\n-                source.put(EventDto.FIELD_TIMERANGE_START, buildElasticSearchTimeFormat(event.getTimerangeStart().withZone(UTC)));\n-            }\n-            if (event.getTimerangeEnd() != null) {\n-                source.put(EventDto.FIELD_TIMERANGE_END, buildElasticSearchTimeFormat(event.getTimerangeEnd().withZone(UTC)));\n-            }\n-\n-            // We cannot index events that don't have any stream set\n-            if (event.getStreams().isEmpty()) {\n-                throw new IllegalStateException(\"Event streams cannot be empty\");\n-            }\n-\n-            // Collect a set of indices for the event to avoid writing to the same index set twice if\n-            // multiple streams use the same index set.\n-            final Set<String> indices = event.getStreams().stream()\n-                .map(streamId -> {\n-                    final String index = streamIndices.get(streamId);\n-                    if (index == null) {\n-                        LOG.warn(\"Couldn't find index set of stream <{}> for event <{}> (definition: {}/{})\", streamId,\n-                            event.getId(), event.getEventDefinitionType(), event.getEventDefinitionId());\n-                    }\n-                    return index;\n+        final List<Map.Entry<String, Event>> requests = eventsWithContext.stream()\n+                .flatMap(eventWithContext -> {\n+                    final Event event = eventWithContext.event();\n+                    // Collect a set of indices for the event to avoid writing to the same index set twice if\n+                    // multiple streams use the same index set.\n+                    final Set<String> indices = event.getStreams().stream()\n+                            .map(streamId -> {\n+                                final String index = streamIndices.get(streamId);\n+                                if (index == null) {\n+                                    LOG.warn(\"Couldn't find index set of stream <{}> for event <{}> (definition: {}/{})\", streamId,\n+                                            event.getId(), event.getEventDefinitionType(), event.getEventDefinitionId());\n+                                }\n+                                return index;\n+                            })\n+                            .filter(Objects::nonNull)\n+                            .collect(Collectors.toSet());\n+                    return indices.stream()\n+                            .map(index -> new AbstractMap.SimpleEntry<>(index, event));", "originalCommit": "7eb8b632ac6d669f7f34b1add1907f513346a510", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0cae9be45139e5e427d97d81ede87ef13beff81b", "chunk": "diff --git a/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java b/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\nindex a2df5152a9..25553e98d4 100644\n--- a/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\n+++ b/graylog2-server/src/main/java/org/graylog/events/indices/MoreIndices.java\n\n@@ -60,26 +74,62 @@ public class MoreIndices {\n             .collect(Collectors.toSet());\n         final Map<String, String> streamIndices = streamService.loadByIds(streamIds).stream()\n             .collect(Collectors.toMap(Persisted::getId, stream -> stream.getIndexSet().getWriteIndexAlias()));\n-        final List<Map.Entry<String, Event>> requests = eventsWithContext.stream()\n-                .flatMap(eventWithContext -> {\n-                    final Event event = eventWithContext.event();\n-                    // Collect a set of indices for the event to avoid writing to the same index set twice if\n-                    // multiple streams use the same index set.\n-                    final Set<String> indices = event.getStreams().stream()\n-                            .map(streamId -> {\n-                                final String index = streamIndices.get(streamId);\n-                                if (index == null) {\n-                                    LOG.warn(\"Couldn't find index set of stream <{}> for event <{}> (definition: {}/{})\", streamId,\n-                                            event.getId(), event.getEventDefinitionType(), event.getEventDefinitionId());\n-                                }\n-                                return index;\n-                            })\n-                            .filter(Objects::nonNull)\n-                            .collect(Collectors.toSet());\n-                    return indices.stream()\n-                            .map(index -> new AbstractMap.SimpleEntry<>(index, event));\n+\n+        final Bulk.Builder bulk = new Bulk.Builder();\n+        for (final EventWithContext eventWithContext : eventsWithContext) {\n+            final Event event = eventWithContext.event();\n+\n+            final Map<String, Object> source = objectMapper.convertValue(event.toDto(), TypeReferences.MAP_STRING_OBJECT);\n+\n+            // \"Fix\" timestamps to be in the correct format. Our message index mapping is using this format so we have\n+            // to use it for our events as well to make sure we can use the search without errors.\n+            source.put(EventDto.FIELD_EVENT_TIMESTAMP, buildElasticSearchTimeFormat(requireNonNull(event.getEventTimestamp()).withZone(UTC)));\n+            source.put(EventDto.FIELD_PROCESSING_TIMESTAMP, buildElasticSearchTimeFormat(requireNonNull(event.getProcessingTimestamp()).withZone(UTC)));\n+            if (event.getTimerangeStart() != null) {\n+                source.put(EventDto.FIELD_TIMERANGE_START, buildElasticSearchTimeFormat(event.getTimerangeStart().withZone(UTC)));\n+            }\n+            if (event.getTimerangeEnd() != null) {\n+                source.put(EventDto.FIELD_TIMERANGE_END, buildElasticSearchTimeFormat(event.getTimerangeEnd().withZone(UTC)));\n+            }\n+\n+            // We cannot index events that don't have any stream set\n+            if (event.getStreams().isEmpty()) {\n+                throw new IllegalStateException(\"Event streams cannot be empty\");\n+            }\n+\n+            // Collect a set of indices for the event to avoid writing to the same index set twice if\n+            // multiple streams use the same index set.\n+            final Set<String> indices = event.getStreams().stream()\n+                .map(streamId -> {\n+                    final String index = streamIndices.get(streamId);\n+                    if (index == null) {\n+                        LOG.warn(\"Couldn't find index set of stream <{}> for event <{}> (definition: {}/{})\", streamId,\n+                            event.getId(), event.getEventDefinitionType(), event.getEventDefinitionId());\n+                    }\n+                    return index;\n                 })\n-                .collect(Collectors.toList());\n-        moreIndicesAdapter.bulkIndex(requests);\n+                .filter(Objects::nonNull)\n+                .collect(Collectors.toSet());\n+\n+            for (final String index : indices) {\n+                bulk.addAction(new Index.Builder(source)\n+                    .index(index)\n+                    .type(IndexMapping.TYPE_MESSAGE)\n+                    .id(event.getId())\n+                    .build());\n+            }\n+        }\n+\n+        try {\n+            final BulkResult result = jestClient.execute(bulk.build());\n+            final List<BulkResult.BulkResultItem> failedItems = result.getFailedItems();\n+\n+            if (!failedItems.isEmpty()) {\n+                LOG.error(\"Failed to index {} events: {}\", eventsWithContext.size(), result.getErrorMessage());\n+            }\n+            LOG.debug(\"Index: Bulk indexed {} events, failures: {}\", result.getItems().size(), failedItems.size());\n+        } catch (IOException e) {\n+            LOG.error(\"Failed to index {} events\", eventsWithContext.size(), e);\n+        }\n     }\n }\n"}}, {"oid": "0cae9be45139e5e427d97d81ede87ef13beff81b", "url": "https://github.com/Graylog2/graylog2-server/commit/0cae9be45139e5e427d97d81ede87ef13beff81b", "message": "Reusing `HealthStatus`.", "committedDate": "2020-06-10T12:51:58Z", "type": "commit"}, {"oid": "b9c9a98c63430ac11597f351f9b92e5f987059f0", "url": "https://github.com/Graylog2/graylog2-server/commit/b9c9a98c63430ac11597f351f9b92e5f987059f0", "message": "Reusing fromString", "committedDate": "2020-06-10T12:51:58Z", "type": "commit"}, {"oid": "61cbe1507ecec3680396460d3b15aa36d5b7ab06", "url": "https://github.com/Graylog2/graylog2-server/commit/61cbe1507ecec3680396460d3b15aa36d5b7ab06", "message": "Extracting interface from `ElasticsearchProbe`.", "committedDate": "2020-06-10T12:51:58Z", "type": "commit"}, {"oid": "a172f7e6c01fc4470fc8afeb051175696501627b", "url": "https://github.com/Graylog2/graylog2-server/commit/a172f7e6c01fc4470fc8afeb051175696501627b", "message": "Extracting interface from `MoreIndices`.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "fbbbcc504e11cbc3cc3d6a17f368916f9d5d5202", "url": "https://github.com/Graylog2/graylog2-server/commit/fbbbcc504e11cbc3cc3d6a17f368916f9d5d5202", "message": "Adding license header.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "3822d8a9b42da5960b01a7380098e2d875fdcf6b", "url": "https://github.com/Graylog2/graylog2-server/commit/3822d8a9b42da5960b01a7380098e2d875fdcf6b", "message": "Consolidating ES stats fetching, cleaning up `CluterAdapter` interface.\n\nBy moving most of the logic from `ElasticsearchProbe` to the\n`ClusterAdapter` interface, we can get rid of the former.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "9349627630656b2a5d86b4a69095cc3f60a3e79a", "url": "https://github.com/Graylog2/graylog2-server/commit/9349627630656b2a5d86b4a69095cc3f60a3e79a", "message": "Renaming method to `statsForIndices`.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "e514f18f82f083bfea09bdff8faa85c71038e8df", "url": "https://github.com/Graylog2/graylog2-server/commit/e514f18f82f083bfea09bdff8faa85c71038e8df", "message": "Renaming `MoreIndices` to `EventIndexer`.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "e5137bac8f4391a5d89776fff9ba2f3f4d4e3fee", "url": "https://github.com/Graylog2/graylog2-server/commit/e5137bac8f4391a5d89776fff9ba2f3f4d4e3fee", "message": "Renaming overly specific `bulkIndex` method to `write`.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "67ab6448f3bf47ee8aec28d1737f4a3b10c9bba5", "url": "https://github.com/Graylog2/graylog2-server/commit/67ab6448f3bf47ee8aec28d1737f4a3b10c9bba5", "message": "Clean up stream pipeline by extracting helper methods.", "committedDate": "2020-06-10T12:53:48Z", "type": "commit"}, {"oid": "67ab6448f3bf47ee8aec28d1737f4a3b10c9bba5", "url": "https://github.com/Graylog2/graylog2-server/commit/67ab6448f3bf47ee8aec28d1737f4a3b10c9bba5", "message": "Clean up stream pipeline by extracting helper methods.", "committedDate": "2020-06-10T12:53:48Z", "type": "forcePushed"}, {"oid": "49e2746b6f83f5e75ee449e4e5e7cb07dfdf5a54", "url": "https://github.com/Graylog2/graylog2-server/commit/49e2746b6f83f5e75ee449e4e5e7cb07dfdf5a54", "message": "Renaming Adapter to .", "committedDate": "2020-06-10T12:55:04Z", "type": "commit"}, {"oid": "dae44005f4187172593c45e9caf0479cfc0184a9", "url": "https://github.com/Graylog2/graylog2-server/commit/dae44005f4187172593c45e9caf0479cfc0184a9", "message": "Renaming overly specific `bulkIndex` method to `write` in adapter too.", "committedDate": "2020-06-10T12:55:21Z", "type": "commit"}, {"oid": "04052d3b811d9981255656c2e5f095e94cd68be1", "url": "https://github.com/Graylog2/graylog2-server/commit/04052d3b811d9981255656c2e5f095e94cd68be1", "message": "Extracting helper methods for `EventIndexer#write`.", "committedDate": "2020-06-10T12:58:35Z", "type": "commit"}]}