{"pr_number": 6790, "pr_title": "6558 validate files on publish", "pr_createdAt": "2020-04-03T01:31:08Z", "pr_url": "https://github.com/IQSS/dataverse/pull/6790", "timeline": [{"oid": "f1f5285ac7a56d8f2705a4ba311e83ccb16ebe14", "url": "https://github.com/IQSS/dataverse/commit/f1f5285ac7a56d8f2705a4ba311e83ccb16ebe14", "message": "the framework for the physical file validations (#655)", "committedDate": "2020-03-27T13:03:19Z", "type": "commit"}, {"oid": "f149e121e42496f04cdc7d9190d6fe6e40d01ee6", "url": "https://github.com/IQSS/dataverse/commit/f149e121e42496f04cdc7d9190d6fe6e40d01ee6", "message": "Physical file validation framework, refined; (#6558)", "committedDate": "2020-03-31T02:48:35Z", "type": "commit"}, {"oid": "ad0960c1dc7c8c24aee8622e86d2b0446bcff791", "url": "https://github.com/IQSS/dataverse/commit/ad0960c1dc7c8c24aee8622e86d2b0446bcff791", "message": "one added TODO in the finalize command (#6558)", "committedDate": "2020-03-31T02:53:36Z", "type": "commit"}, {"oid": "92806657d2d92357e3885df9b6afd5dc59b2922a", "url": "https://github.com/IQSS/dataverse/commit/92806657d2d92357e3885df9b6afd5dc59b2922a", "message": "renamed DatasetLock.Reason.pidRegister DatasetLock.Reason.finalizePublication\n(#6558)", "committedDate": "2020-04-01T03:14:23Z", "type": "commit"}, {"oid": "58ac83b8341414d8732c8a91003b45ec328b37ff", "url": "https://github.com/IQSS/dataverse/commit/58ac83b8341414d8732c8a91003b45ec328b37ff", "message": "documentation for validate-files-on-publish. (#6558)", "committedDate": "2020-04-01T04:10:36Z", "type": "commit"}, {"oid": "790a5e548a3860b96a1578f3c9d761a75faf7d7f", "url": "https://github.com/IQSS/dataverse/commit/790a5e548a3860b96a1578f3c9d761a75faf7d7f", "message": "More changes/refinements, dedicated \"validation failed\" lock, etc. (#6558)", "committedDate": "2020-04-02T12:54:04Z", "type": "commit"}, {"oid": "fdfb7672245fabf1e30d219a7b16be496fd88bab", "url": "https://github.com/IQSS/dataverse/commit/fdfb7672245fabf1e30d219a7b16be496fd88bab", "message": "refresh the changed error/lock message after a file validation failure. (#6558)", "committedDate": "2020-04-02T13:13:18Z", "type": "commit"}, {"oid": "a3df9c534c37ef90060206ec738d81e49c72d7c3", "url": "https://github.com/IQSS/dataverse/commit/a3df9c534c37ef90060206ec738d81e49c72d7c3", "message": "cleaned up lock refresh and messaging. (#6558)", "committedDate": "2020-04-02T14:31:18Z", "type": "commit"}, {"oid": "d16bed59a6dd9e716495d15d912da748c602de40", "url": "https://github.com/IQSS/dataverse/commit/d16bed59a6dd9e716495d15d912da748c602de40", "message": "Merge branch 'develop' into 6558-validate-files-on-publish", "committedDate": "2020-04-02T18:02:31Z", "type": "commit"}, {"oid": "7dd277dc65449875495d3d7142f057ea49fe057f", "url": "https://github.com/IQSS/dataverse/commit/7dd277dc65449875495d3d7142f057ea49fe057f", "message": "a flyway script for purging any locks of type pidRegister.", "committedDate": "2020-04-02T19:34:26Z", "type": "commit"}, {"oid": "3d21e9dffdf675582aed9a9bc492188506da5e26", "url": "https://github.com/IQSS/dataverse/commit/3d21e9dffdf675582aed9a9bc492188506da5e26", "message": "another lock refresh tweak. (#6558)", "committedDate": "2020-04-02T19:48:49Z", "type": "commit"}, {"oid": "811ab0918570e6998e0f8f8de70b95c79a914bee", "url": "https://github.com/IQSS/dataverse/commit/811ab0918570e6998e0f8f8de70b95c79a914bee", "message": "A release note for #6558.", "committedDate": "2020-04-02T20:49:15Z", "type": "commit"}, {"oid": "2a6411a16c82249a117695322905d743d3113bf6", "url": "https://github.com/IQSS/dataverse/commit/2a6411a16c82249a117695322905d743d3113bf6", "message": "final (?) info messaging mechanism for the dataset page. (#6558)", "committedDate": "2020-04-02T21:45:29Z", "type": "commit"}, {"oid": "bc6e37fde1e10cfbf33bbddc1e3923f888f0ac6d", "url": "https://github.com/IQSS/dataverse/commit/bc6e37fde1e10cfbf33bbddc1e3923f888f0ac6d", "message": "rewrote/rearranged the troubleshooting guide for invalid files. (#6558)", "committedDate": "2020-04-03T01:09:58Z", "type": "commit"}, {"oid": "31f8df01438ea953dfaba4cf316b6e1806122859", "url": "https://github.com/IQSS/dataverse/commit/31f8df01438ea953dfaba4cf316b6e1806122859", "message": "extra lock checking in the publish command. (#6558)", "committedDate": "2020-04-03T01:13:56Z", "type": "commit"}, {"oid": "b102dafbd7e755326ff067c06462d5a9f3c82e2e", "url": "https://github.com/IQSS/dataverse/commit/b102dafbd7e755326ff067c06462d5a9f3c82e2e", "message": "a typo/dropped word in the release notes. (#6558)", "committedDate": "2020-04-03T01:21:05Z", "type": "commit"}, {"oid": "74badcbee4f92a7cd2930bbd750ce9a7e666d84e", "url": "https://github.com/IQSS/dataverse/commit/74badcbee4f92a7cd2930bbd750ce9a7e666d84e", "message": "typo", "committedDate": "2020-04-03T14:26:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTM5OA==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404265398", "bodyText": "Because we want the admin to intercede here we probably don't want to remove the lock, but should we update the  edit data button so that if there is a file validation failure the user cannot add files? We would still allow them to make other edits?", "author": "sekmiller", "createdAt": "2020-04-06T17:29:40Z", "path": "src/main/java/edu/harvard/iq/dataverse/DatasetPage.java", "diffHunk": "@@ -2011,48 +2037,42 @@ private String init(boolean initFull) {\n                 lockedDueToDcmUpload = true;\n             }\n             //This is a hack to remove dataset locks for File PID registration if \n-                //the dataset is released\n-                //in testing we had cases where datasets with 1000 files were remaining locked after being published successfully\n-                /*if(dataset.getLatestVersion().isReleased() && dataset.isLockedFor(DatasetLock.Reason.pidRegister)){\n-                    datasetService.removeDatasetLocks(dataset.getId(), DatasetLock.Reason.pidRegister);\n-                }*/\n-            if (dataset.isLockedFor(DatasetLock.Reason.pidRegister)) {\n+            //the dataset is released\n+            //in testing we had cases where datasets with 1000 files were remaining locked after being published successfully\n+            /*if(dataset.getLatestVersion().isReleased() && dataset.isLockedFor(DatasetLock.Reason.finalizePublication)){\n+                datasetService.removeDatasetLocks(dataset.getId(), DatasetLock.Reason.finalizePublication);\n+            }*/\n+            if (dataset.isLockedFor(DatasetLock.Reason.finalizePublication)) {\n+                // \"finalizePublication\" lock is used to lock the dataset while \n+                // the FinalizeDatasetPublicationCommand is running asynchronously. \n+                // the tasks currently performed by the command are the  pid registration \n+                // for files and (or) physical file validation (either or both \n+                // of these two can be disabled via database settings). More \n+                // such asynchronous processing tasks may be added in the future. \n                 JH.addMessage(FacesMessage.SEVERITY_WARN, BundleUtil.getStringFromBundle(\"dataset.publish.workflow.message\"),\n                         BundleUtil.getStringFromBundle(\"dataset.pidRegister.workflow.inprogress\"));\n             }\n+            if (dataset.isLockedFor(DatasetLock.Reason.FileValidationFailed)) {\n+                // the dataset is locked, because one or more datafiles in it \n+                // failed validation during an attempt to publish it. \n+                if (FacesContext.getCurrentInstance().getExternalContext().getFlash().get(\"errorMsg\") == null) {\n+                    JH.addMessage(FacesMessage.SEVERITY_ERROR, BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.message\"),\n+                            BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.contactSupport\"));\n+                }\n+                /* and now that we've shown the message to the user - remove the lock? */", "originalCommit": "74badcbee4f92a7cd2930bbd750ce9a7e666d84e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI3MDA2MA==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404270060", "bodyText": "Or maybe use the file validation failure lock to disable the publish button?", "author": "sekmiller", "createdAt": "2020-04-06T17:37:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMyMzc0Nw==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404323747", "bodyText": "No, we don't want to remove that lock automatically - that was an idea I was entertaining during the development. I should remove that comment.\nAs for the second comment - that's exactly what that \"failed validation\" lock does. It disables the publish button, and will prevent an execution of the publish command, if called via API. But it shouldn't prevent the contributor from making changes. But yes, this should be documented clearly.", "author": "landreev", "createdAt": "2020-04-06T19:08:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMyOTQ1NA==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404329454", "bodyText": "OK. I missed that the lock disables publish because it's if it's locked for any reason, not just file validation failure.", "author": "sekmiller", "createdAt": "2020-04-06T19:18:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEzODMxMg==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r405138312", "bodyText": "The way that page is dealing with/checking for various types of locks is a little scary.\nAdded a quick note to the \"dataset management\"/\"publish dataset\" section of the user guide.", "author": "landreev", "createdAt": "2020-04-07T21:58:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI2NTM5OA=="}], "type": "inlineReview", "revised_code": {"commit": "c3fbad2688ea8c9eaaeda5d0c33625da5f1ef91d", "chunk": "diff --git a/src/main/java/edu/harvard/iq/dataverse/DatasetPage.java b/src/main/java/edu/harvard/iq/dataverse/DatasetPage.java\nindex acc9245eb..7fcc1ae1f 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/DatasetPage.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/DatasetPage.java\n\n@@ -2059,7 +2059,6 @@ public class DatasetPage implements java.io.Serializable {\n                     JH.addMessage(FacesMessage.SEVERITY_ERROR, BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.message\"),\n                             BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.contactSupport\"));\n                 }\n-                /* and now that we've shown the message to the user - remove the lock? */\n             } \n             if (dataset.isLockedFor(DatasetLock.Reason.EditInProgress)) {\n                 String rootDataverseName = dataverseService.findRootDataverse().getName();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI5NjIyNQ==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404296225", "bodyText": "I think it would be desirable to attempt to validate all of the files before throwing an exception. It would make the admins job easier if they knew more than one file failed validation.", "author": "sekmiller", "createdAt": "2020-04-06T18:20:58Z", "path": "src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java", "diffHunk": "@@ -225,6 +240,98 @@ private void updateParentDataversesSubjectsField(Dataset savedDataset, CommandCo\n         }\n     }\n \n+    private void validateDataFiles(Dataset dataset, CommandContext ctxt) throws CommandException {\n+        try {\n+            for (DataFile dataFile : dataset.getFiles()) {\n+                // TODO: Should we validate all the files in the dataset, or only \n+                // the files that haven't been published previously?\n+                logger.log(Level.FINE, \"validating DataFile {0}\", dataFile.getId());", "originalCommit": "74badcbee4f92a7cd2930bbd750ce9a7e666d84e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMyNjE3MQ==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r404326171", "bodyText": "Thanks for the suggestion. I decided to quit on the first invalid file, so that it's faster. And then I tell the admin in the troubleshooting instruction that they need to verify all the files in the dataset.\nI just had this idea: I should probably leave the finalizePublication command as is, stopping on the first file that fails - but then I should provide a one step API for the admin, that will validate all the files in the dataset (using the existing code), and spell out to them which ones need to be fixed - ?", "author": "landreev", "createdAt": "2020-04-06T19:12:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI5NjIyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEzNzYxNw==", "url": "https://github.com/IQSS/dataverse/pull/6790#discussion_r405137617", "bodyText": "OK, this is done.", "author": "landreev", "createdAt": "2020-04-07T21:57:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDI5NjIyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "c3fbad2688ea8c9eaaeda5d0c33625da5f1ef91d", "chunk": "diff --git a/src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java b/src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java\nindex 61ab5b5a5..ebecf11da 100644\n--- a/src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java\n+++ b/src/main/java/edu/harvard/iq/dataverse/engine/command/impl/FinalizeDatasetPublicationCommand.java\n\n@@ -246,58 +246,7 @@ public class FinalizeDatasetPublicationCommand extends AbstractPublishDatasetCom\n                 // TODO: Should we validate all the files in the dataset, or only \n                 // the files that haven't been published previously?\n                 logger.log(Level.FINE, \"validating DataFile {0}\", dataFile.getId());\n-                \n-                DataFile.ChecksumType checksumType = dataFile.getChecksumType();\n-                if (checksumType == null) {\n-                    String info = BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.noChecksumType\", Arrays.asList(dataFile.getId().toString()));\n-                    logger.log(Level.INFO, info);\n-                    throw new Exception(info);\n-                }\n-                                \n-                StorageIO<DataFile> storage = dataFile.getStorageIO();\n-                storage.open(DataAccessOption.READ_ACCESS);\n-                InputStream in = null;\n-                \n-                if (!dataFile.isTabularData()) {\n-                    in = storage.getInputStream();\n-                } else {\n-                    // if this is a tabular file, read the preserved original \"auxiliary file\"\n-                    // instead:\n-                    in = storage.getAuxFileAsInputStream(FileUtil.SAVED_ORIGINAL_FILENAME_EXTENSION);\n-                }\n-                                \n-                if (in == null) {\n-                    String info = BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.failRead\", Arrays.asList(dataFile.getId().toString()));\n-                    logger.log(Level.INFO, info);\n-                    throw new Exception(info);\n-                }\n-                \n-                String recalculatedChecksum = null; \n-                try {\n-                    recalculatedChecksum = FileUtil.calculateChecksum(in, checksumType);\n-                } catch (RuntimeException rte) {\n-                    recalculatedChecksum = null; \n-                } finally {\n-                    IOUtils.closeQuietly(in);\n-                }\n-                \n-                if (recalculatedChecksum == null) {\n-                    String info = BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.failCalculateChecksum\", Arrays.asList(dataFile.getId().toString()));\n-                    logger.log(Level.INFO, info); \n-                    throw new Exception(info);\n-                }\n-                \n-                // TODO: What should we do if the datafile does not have a non-null checksum?\n-                // Should we fail, or should we assume that the recalculated checksum\n-                // is correct, and populate the checksumValue field with it?\n-                \n-                if (!recalculatedChecksum.equals(dataFile.getChecksumValue())) {\n-                    String info = BundleUtil.getStringFromBundle(\"dataset.publish.file.validation.error.wrongChecksumValue\", Arrays.asList(dataFile.getId().toString()));\n-                    logger.log(Level.INFO, info); \n-                    throw new Exception(info);\n-                }\n-                \n-                logger.log(Level.INFO, \"successfully validated DataFile {0}; checksum {1}\", new Object[]{dataFile.getId(), recalculatedChecksum});\n+                FileUtil.validateDataFileChecksum(dataFile);\n             }\n         } catch (Throwable e) {\n             \n"}}, {"oid": "d126a72a962582992ce83ef2c5b1b5c0f893b53a", "url": "https://github.com/IQSS/dataverse/commit/d126a72a962582992ce83ef2c5b1b5c0f893b53a", "message": "Merge branch 'develop' into 6558-validate-files-on-publish", "committedDate": "2020-04-07T02:38:25Z", "type": "commit"}, {"oid": "45cfa0f1679afc5b2d79496e7b0f67b18a01beb2", "url": "https://github.com/IQSS/dataverse/commit/45cfa0f1679afc5b2d79496e7b0f67b18a01beb2", "message": "Merge branch '6558-validate-files-on-publish' of https://github.com/IQSS/dataverse into 6558-validate-files-on-publish", "committedDate": "2020-04-07T02:39:00Z", "type": "commit"}, {"oid": "c3fbad2688ea8c9eaaeda5d0c33625da5f1ef91d", "url": "https://github.com/IQSS/dataverse/commit/c3fbad2688ea8c9eaaeda5d0c33625da5f1ef91d", "message": "Added /admin API call that an admin can use to find the files that have failed validation,\nthat need to be fixed or removed before the dataset can be published. (#6558)", "committedDate": "2020-04-07T04:01:58Z", "type": "commit"}, {"oid": "9ecb82c1a576d0fabcb349b0763443e9ac6fff1f", "url": "https://github.com/IQSS/dataverse/commit/9ecb82c1a576d0fabcb349b0763443e9ac6fff1f", "message": "Extra documentation entries for the validate files across dataset admin API (#6558)", "committedDate": "2020-04-07T19:39:42Z", "type": "commit"}, {"oid": "608228b03425fe0605e0a0dab650f771c923110d", "url": "https://github.com/IQSS/dataverse/commit/608228b03425fe0605e0a0dab650f771c923110d", "message": "Another documentation entry, the \"dataset management\" section of the user guide. (#6558)", "committedDate": "2020-04-07T21:55:51Z", "type": "commit"}, {"oid": "c0340c843d5dced0291d4c2f5ea3c397ee06f6e1", "url": "https://github.com/IQSS/dataverse/commit/c0340c843d5dced0291d4c2f5ea3c397ee06f6e1", "message": "removed the incorrect/confusing \"API\" reference\n\n... from the troubleshooting guide; also moved around the diag. API and the example sections.", "committedDate": "2020-04-09T20:02:25Z", "type": "commit"}, {"oid": "93160c9719bd9e54768fa60013dfa488fc77266f", "url": "https://github.com/IQSS/dataverse/commit/93160c9719bd9e54768fa60013dfa488fc77266f", "message": "cosmetic/style change", "committedDate": "2020-04-09T20:03:56Z", "type": "commit"}, {"oid": "840f389f50a6059d9e6c9dff0fcf0e6912e830f5", "url": "https://github.com/IQSS/dataverse/commit/840f389f50a6059d9e6c9dff0fcf0e6912e830f5", "message": "\"strongly recommened\"", "committedDate": "2020-04-09T20:15:48Z", "type": "commit"}, {"oid": "093ed6d6c908088e61f85bf29a90d787164bbd36", "url": "https://github.com/IQSS/dataverse/commit/093ed6d6c908088e61f85bf29a90d787164bbd36", "message": "rearranged the order of operations inside FinalizeDatasetPublicationCommand. #6558", "committedDate": "2020-04-13T22:14:17Z", "type": "commit"}, {"oid": "b055cadd632a07e090a6f587a7efb79b91b0f558", "url": "https://github.com/IQSS/dataverse/commit/b055cadd632a07e090a6f587a7efb79b91b0f558", "message": "one other rearrangment - changes where the dataset is merged, after it's modified during the first\nstage of the async publishing. #6558.", "committedDate": "2020-04-14T02:25:12Z", "type": "commit"}, {"oid": "402a6247e5e4d246cf2d0629a2ffb2e0af1ac43f", "url": "https://github.com/IQSS/dataverse/commit/402a6247e5e4d246cf2d0629a2ffb2e0af1ac43f", "message": "Cleaned up messaging; removed some commented out code. #6558", "committedDate": "2020-04-14T12:58:02Z", "type": "commit"}, {"oid": "bc389b3f2ff63422f6cf7000939e21da004a698e", "url": "https://github.com/IQSS/dataverse/commit/bc389b3f2ff63422f6cf7000939e21da004a698e", "message": "added an entry for the file number limit for async. handling. #6558", "committedDate": "2020-04-14T13:23:30Z", "type": "commit"}, {"oid": "a2079d2e379b498da2bd5567f28d85844d234fae", "url": "https://github.com/IQSS/dataverse/commit/a2079d2e379b498da2bd5567f28d85844d234fae", "message": "as discussed, skipping file validation for minor version releases (#6558)", "committedDate": "2020-04-14T15:25:45Z", "type": "commit"}]}