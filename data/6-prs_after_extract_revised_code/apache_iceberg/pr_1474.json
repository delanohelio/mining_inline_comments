{"pr_number": 1474, "pr_title": "FIX: fix reader not getting closed.", "pr_createdAt": "2020-09-17T23:13:31Z", "pr_url": "https://github.com/apache/iceberg/pull/1474", "timeline": [{"oid": "0c47ba83c089d16dabc6be6b22ff20252e0698ed", "url": "https://github.com/apache/iceberg/commit/0c47ba83c089d16dabc6be6b22ff20252e0698ed", "message": "FIX: fix reader not getting closed.\n\nthis lead to s3a connection pool timeout", "committedDate": "2020-09-17T23:12:25Z", "type": "commit"}, {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1", "url": "https://github.com/apache/iceberg/commit/a427eef4fcb8de7a6060be6ee2d49283200041a1", "message": "no need to create new reader just use row group from existing reader", "committedDate": "2020-09-17T23:17:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617018", "bodyText": "@sudssf This needs to initialize a new reader as we want to get row positions relative to the start of the file and not start of the split. I think the only change that is necessary in this PR is to close the reader.", "author": "shardulm94", "createdAt": "2020-09-17T23:30:27Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "originalCommit": "a427eef4fcb8de7a6060be6ee2d49283200041a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1Mg==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617552", "bodyText": "ok I will revert to previous commit thanks for reply", "author": "sudssf", "createdAt": "2020-09-17T23:32:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMTIyOQ==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490621229", "bodyText": "Can you remove the extra newline here?", "author": "rdblue", "createdAt": "2020-09-17T23:44:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA=="}], "type": "inlineReview", "revised_code": {"commit": "86d3dec8fc87b8545e476b550d7e9646724405e0", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\nindex 62045f23..b42c0fec 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n\n@@ -165,16 +165,20 @@ class ReadConf<T> {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos(List<BlockMetaData> rowGroups) {\n+  private Map<Long, Long> generateOffsetToStartPos() {\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n \n-    long curRowCount = 0;\n-    for (int i = 0; i < rowGroups.size(); i += 1) {\n-      BlockMetaData meta = rowGroups.get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {\n+      long curRowCount = 0;\n+      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+        BlockMetaData meta = fileReader.getRowGroups().get(i);\n+        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+        curRowCount += meta.getRowCount();\n+      }\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Failed to open Parquet file: %s\", file.location());\n     }\n-\n     return offsetToStartPos;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1OQ==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617559", "bodyText": "The reason for a new reader is to create one that doesn't have a filter pushed down through ParquetReadOptions.\nWhen building a reader, a file range can be added to ParquetReadOptions, which will filter Parquet row groups as they are read. Iceberg uses this to handle file split ranges, and Parquet avoids reading the row group metadata in case there are a lot of row groups in the file.\nThere are a couple options to fix this. We could stop pushing the file range to Parquet so that it reads all the row groups and use your implementation here. That would also require applying the range in ReadConf and setting shouldSkip appropriately.\nA second option is to properly close the file that is opened here, like this:\n  private Map<Long, Long> generateOffsetToStartPos() {\n    try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n      Map<Long, Long> offsetToStartPos = Maps.newHashMap();\n\n      long curRowCount = 0;\n      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n        BlockMetaData meta = fileReader.getRowGroups().get(i);\n        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n        curRowCount += meta.getRowCount();\n      }\n\n      return offsetToStartPos;\n\n    } catch (IOException e) {\n      throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n    }\n  }\nI think it's a good idea to go with the first option, but we might want to fix this with the second option in the mean time.", "author": "rdblue", "createdAt": "2020-09-17T23:32:16Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "originalCommit": "a427eef4fcb8de7a6060be6ee2d49283200041a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzgxNA==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617814", "bodyText": "thanks let me revert to option1", "author": "sudssf", "createdAt": "2020-09-17T23:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "86d3dec8fc87b8545e476b550d7e9646724405e0", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\nindex 62045f23..b42c0fec 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n\n@@ -165,16 +165,20 @@ class ReadConf<T> {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos(List<BlockMetaData> rowGroups) {\n+  private Map<Long, Long> generateOffsetToStartPos() {\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n \n-    long curRowCount = 0;\n-    for (int i = 0; i < rowGroups.size(); i += 1) {\n-      BlockMetaData meta = rowGroups.get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {\n+      long curRowCount = 0;\n+      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+        BlockMetaData meta = fileReader.getRowGroups().get(i);\n+        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+        curRowCount += meta.getRowCount();\n+      }\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Failed to open Parquet file: %s\", file.location());\n     }\n-\n     return offsetToStartPos;\n   }\n \n"}}, {"oid": "86d3dec8fc87b8545e476b550d7e9646724405e0", "url": "https://github.com/apache/iceberg/commit/86d3dec8fc87b8545e476b550d7e9646724405e0", "message": "Revert \"FIX: fix reader not getting closed.\"\n\nThis reverts commit 0c47ba83c089d16dabc6be6b22ff20252e0698ed.", "committedDate": "2020-09-17T23:35:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490620875", "bodyText": "Nit: missing space between try and (. This will probably fail validation.", "author": "rdblue", "createdAt": "2020-09-17T23:43:24Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,15 +167,19 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n \n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {", "originalCommit": "6b08ce32455b5cb830bcc396f93ab6b32fd0ced9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMTA2NQ==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490621065", "bodyText": "While you're changing this, can you remove this. from the variable reference? We use this. to distinguish setting instance fields, not getting instance fields.", "author": "rdblue", "createdAt": "2020-09-17T23:44:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMjY1OA==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490622658", "bodyText": "yup I will revert to code you posted above :)", "author": "sudssf", "createdAt": "2020-09-17T23:49:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\nindex a25102fd..02f849f6 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n\n@@ -167,21 +167,22 @@ class ReadConf<T> {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n+      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+        Map<Long, Long> offsetToStartPos = new HashMap<>();\n \n-    Map<Long, Long> offsetToStartPos = new HashMap<>();\n+        long curRowCount = 0;\n+        for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+          BlockMetaData meta = fileReader.getRowGroups().get(i);\n+          offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+          curRowCount += meta.getRowCount();\n+        }\n \n-    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {\n-      long curRowCount = 0;\n-      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-        BlockMetaData meta = fileReader.getRowGroups().get(i);\n-        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-        curRowCount += meta.getRowCount();\n+        return offsetToStartPos;\n+\n+      } catch (IOException e) {\n+        throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n       }\n-    } catch (IOException e) {\n-      throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n     }\n-    return offsetToStartPos;\n-  }\n \n   long[] startRowPositions() {\n     return startRowPositions;\n"}}, {"oid": "aa8f42aa56b23bfe332e1d0be0b1ac21ece21a3e", "url": "https://github.com/apache/iceberg/commit/aa8f42aa56b23bfe332e1d0be0b1ac21ece21a3e", "message": "throw UncheckedIOException", "committedDate": "2020-09-17T23:44:30Z", "type": "forcePushed"}, {"oid": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf", "url": "https://github.com/apache/iceberg/commit/2b257dba9dcc18596e10ae5aefd6e53eea950ebf", "message": "throw UncheckedIOException", "committedDate": "2020-09-17T23:53:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMzkxNA==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490623914", "bodyText": "Maps.newHashMap() was not auto resolved by imports so going to use default constructor", "author": "sudssf", "createdAt": "2020-09-17T23:54:15Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,17 +167,22 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n-    Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n+      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+        Map<Long, Long> offsetToStartPos = new HashMap<>();", "originalCommit": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\nindex 02f849f6..cb816da8 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n\n@@ -167,22 +167,22 @@ class ReadConf<T> {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n-        Map<Long, Long> offsetToStartPos = new HashMap<>();\n-\n-        long curRowCount = 0;\n-        for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-          BlockMetaData meta = fileReader.getRowGroups().get(i);\n-          offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-          curRowCount += meta.getRowCount();\n-        }\n+    try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+      Map<Long, Long> offsetToStartPos = new HashMap<>();\n+\n+      long curRowCount = 0;\n+      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+        BlockMetaData meta = fileReader.getRowGroups().get(i);\n+        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+        curRowCount += meta.getRowCount();\n+      }\n \n-        return offsetToStartPos;\n+      return offsetToStartPos;\n \n-      } catch (IOException e) {\n-        throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n-      }\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Failed to create/close reader for file: \" + file, e);\n     }\n+  }\n \n   long[] startRowPositions() {\n     return startRowPositions;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyODY1NQ==", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490628655", "bodyText": "The message may be \"failed to create reader\"?", "author": "chenjunjiedada", "createdAt": "2020-09-18T00:11:54Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,17 +167,22 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n-    Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n+      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+        Map<Long, Long> offsetToStartPos = new HashMap<>();\n \n-    return offsetToStartPos;\n-  }\n+        long curRowCount = 0;\n+        for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+          BlockMetaData meta = fileReader.getRowGroups().get(i);\n+          offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+          curRowCount += meta.getRowCount();\n+        }\n+\n+        return offsetToStartPos;\n+\n+      } catch (IOException e) {\n+        throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);", "originalCommit": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\nindex 02f849f6..cb816da8 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java\n\n@@ -167,22 +167,22 @@ class ReadConf<T> {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n-        Map<Long, Long> offsetToStartPos = new HashMap<>();\n-\n-        long curRowCount = 0;\n-        for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-          BlockMetaData meta = fileReader.getRowGroups().get(i);\n-          offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-          curRowCount += meta.getRowCount();\n-        }\n+    try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+      Map<Long, Long> offsetToStartPos = new HashMap<>();\n+\n+      long curRowCount = 0;\n+      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+        BlockMetaData meta = fileReader.getRowGroups().get(i);\n+        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+        curRowCount += meta.getRowCount();\n+      }\n \n-        return offsetToStartPos;\n+      return offsetToStartPos;\n \n-      } catch (IOException e) {\n-        throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n-      }\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(\"Failed to create/close reader for file: \" + file, e);\n     }\n+  }\n \n   long[] startRowPositions() {\n     return startRowPositions;\n"}}, {"oid": "0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "url": "https://github.com/apache/iceberg/commit/0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "message": "throw UncheckedIOException", "committedDate": "2020-09-18T00:16:32Z", "type": "commit"}, {"oid": "0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "url": "https://github.com/apache/iceberg/commit/0e7444ce62f3b2344d5f4c24991cec9eb9f4e548", "message": "throw UncheckedIOException", "committedDate": "2020-09-18T00:16:32Z", "type": "forcePushed"}]}