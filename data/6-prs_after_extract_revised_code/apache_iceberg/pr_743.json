{"pr_number": 743, "pr_title": "[spark-3] Bump Apache spark to 3.0.0-preview2", "pr_createdAt": "2020-01-21T09:41:45Z", "pr_url": "https://github.com/apache/iceberg/pull/743", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI3MzU3Mw==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r370273573", "bodyText": "How about throwing Exception? Keeping a list of which checked exceptions may be thrown isn't useful for test methods.", "author": "rdblue", "createdAt": "2020-01-23T18:08:01Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestStructuredStreaming.java", "diffHunk": "@@ -79,7 +80,7 @@ public static void stopSpark() {\n   }\n \n   @Test\n-  public void testStreamingWriteAppendMode() throws IOException {\n+  public void testStreamingWriteAppendMode() throws IOException, TimeoutException {", "originalCommit": "b7e03fc0cb79bdd8cb4f87d6c93367dfe0853775", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzgyNzQxNw==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373827417", "bodyText": "Yes, throwing \"Exception\" is better.", "author": "yujiantao", "createdAt": "2020-02-02T08:09:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI3MzU3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "99b814c301b0887112fcdbb34d6274de3701f9a1", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/spark/source/TestStructuredStreaming.java b/spark/src/test/java/org/apache/iceberg/spark/source/TestStructuredStreaming.java\nindex 03460c219..4d4fecbe8 100644\n--- a/spark/src/test/java/org/apache/iceberg/spark/source/TestStructuredStreaming.java\n+++ b/spark/src/test/java/org/apache/iceberg/spark/source/TestStructuredStreaming.java\n\n@@ -80,7 +78,7 @@ public class TestStructuredStreaming {\n   }\n \n   @Test\n-  public void testStreamingWriteAppendMode() throws IOException, TimeoutException {\n+  public void testStreamingWriteAppendMode() throws Exception {\n     File parent = temp.newFolder(\"parquet\");\n     File location = new File(parent, \"test-table\");\n     File checkpoint = new File(parent, \"checkpoint\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI3NDIzNA==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r370274234", "bodyText": "Can you add a comment to explain why this is empty? If I understand correctly, close is called after abort or commit is called. Both abort and commit will close the current data file so there is no more cleanup to do here.", "author": "rdblue", "createdAt": "2020-01-23T18:09:34Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java", "diffHunk": "@@ -493,6 +494,9 @@ protected void setCurrentKey(PartitionKey currentKey) {\n     public void write(InternalRow row) throws IOException {\n       writeInternal(row);\n     }\n+\n+    @Override\n+    public void close() {}", "originalCommit": "b7e03fc0cb79bdd8cb4f87d6c93367dfe0853775", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzgyNzQyOA==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373827428", "bodyText": "I will add this comment.", "author": "yujiantao", "createdAt": "2020-02-02T08:09:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI3NDIzNA=="}], "type": "inlineReview", "revised_code": {"commit": "99b814c301b0887112fcdbb34d6274de3701f9a1", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java b/spark/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\nindex 79f93b84f..b1e1fa585 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\n\n@@ -496,7 +496,10 @@ class SparkBatchWrite implements BatchWrite {\n     }\n \n     @Override\n-    public void close() {}\n+    public void close() {\n+      // close is called after abort or commit is called. Both abort and commit will close\n+      // the current data file so there is no more cleanup to do here.\n+    }\n   }\n \n   private static class PartitionedWriter extends BaseWriter {\n"}}, {"oid": "99b814c301b0887112fcdbb34d6274de3701f9a1", "url": "https://github.com/apache/iceberg/commit/99b814c301b0887112fcdbb34d6274de3701f9a1", "message": "Bump Apache spark to 3.0.0-preview2", "committedDate": "2020-02-02T07:50:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg3OTk1OQ==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373879959", "bodyText": "This should not be using Preconditions from Parquet. It should be the guava one. Can you update it to that one instead?", "author": "rdblue", "createdAt": "2020-02-02T22:17:53Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestTables.java", "diffHunk": "@@ -37,7 +37,7 @@\n import org.apache.iceberg.io.InputFile;\n import org.apache.iceberg.io.LocationProvider;\n import org.apache.iceberg.io.OutputFile;\n-import parquet.Preconditions;\n+import org.apache.parquet.Preconditions;", "originalCommit": "99b814c301b0887112fcdbb34d6274de3701f9a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5Nzc2MA==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373897760", "bodyText": "Yes.", "author": "yujiantao", "createdAt": "2020-02-03T01:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg3OTk1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "918f30e82bb76bee07dbab504599f921cb9536ea", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/spark/source/TestTables.java b/spark/src/test/java/org/apache/iceberg/spark/source/TestTables.java\nindex 62bcc3ae1..879aa16b1 100644\n--- a/spark/src/test/java/org/apache/iceberg/spark/source/TestTables.java\n+++ b/spark/src/test/java/org/apache/iceberg/spark/source/TestTables.java\n\n@@ -37,7 +38,6 @@ import org.apache.iceberg.io.FileIO;\n import org.apache.iceberg.io.InputFile;\n import org.apache.iceberg.io.LocationProvider;\n import org.apache.iceberg.io.OutputFile;\n-import org.apache.parquet.Preconditions;\n \n // TODO: Use the copy of this from core.\n class TestTables {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4MDAwMg==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373880002", "bodyText": "This should also be Exception.", "author": "rdblue", "createdAt": "2020-02-02T22:18:10Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestForwardCompatibility.java", "diffHunk": "@@ -125,7 +126,7 @@ public void testSparkWriteFailsUnknownTransform() throws IOException {\n   }\n \n   @Test\n-  public void testSparkStreamingWriteFailsUnknownTransform() throws IOException {\n+  public void testSparkStreamingWriteFailsUnknownTransform() throws IOException, TimeoutException {", "originalCommit": "99b814c301b0887112fcdbb34d6274de3701f9a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NzcwMQ==", "url": "https://github.com/apache/iceberg/pull/743#discussion_r373897701", "bodyText": "Ok.", "author": "yujiantao", "createdAt": "2020-02-03T01:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4MDAwMg=="}], "type": "inlineReview", "revised_code": {"commit": "918f30e82bb76bee07dbab504599f921cb9536ea", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/spark/source/TestForwardCompatibility.java b/spark/src/test/java/org/apache/iceberg/spark/source/TestForwardCompatibility.java\nindex a4b6bf611..d165b219d 100644\n--- a/spark/src/test/java/org/apache/iceberg/spark/source/TestForwardCompatibility.java\n+++ b/spark/src/test/java/org/apache/iceberg/spark/source/TestForwardCompatibility.java\n\n@@ -126,7 +126,7 @@ public class TestForwardCompatibility {\n   }\n \n   @Test\n-  public void testSparkStreamingWriteFailsUnknownTransform() throws IOException, TimeoutException {\n+  public void testSparkStreamingWriteFailsUnknownTransform() throws Exception {\n     File parent = temp.newFolder(\"avro\");\n     File location = new File(parent, \"test\");\n     File dataFolder = new File(location, \"data\");\n"}}, {"oid": "918f30e82bb76bee07dbab504599f921cb9536ea", "url": "https://github.com/apache/iceberg/commit/918f30e82bb76bee07dbab504599f921cb9536ea", "message": "Bump Apache spark to 3.0.0-preview2", "committedDate": "2020-02-03T01:58:15Z", "type": "forcePushed"}, {"oid": "cf7cc3f42d5b1bf1b0852de8bb59478a79ccab9d", "url": "https://github.com/apache/iceberg/commit/cf7cc3f42d5b1bf1b0852de8bb59478a79ccab9d", "message": "Bump Apache spark to 3.0.0-preview2", "committedDate": "2020-02-03T02:04:40Z", "type": "commit"}, {"oid": "cf7cc3f42d5b1bf1b0852de8bb59478a79ccab9d", "url": "https://github.com/apache/iceberg/commit/cf7cc3f42d5b1bf1b0852de8bb59478a79ccab9d", "message": "Bump Apache spark to 3.0.0-preview2", "committedDate": "2020-02-03T02:04:40Z", "type": "forcePushed"}]}