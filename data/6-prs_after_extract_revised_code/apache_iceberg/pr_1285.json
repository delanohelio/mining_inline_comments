{"pr_number": 1285, "pr_title": "Core: fix serialization issue in BaseCombinedScanTask with Kyro (No refactor)", "pr_createdAt": "2020-08-02T03:02:57Z", "pr_url": "https://github.com/apache/iceberg/pull/1285", "timeline": [{"oid": "2d282a8d1678642ad52ca7875adb214fb1072096", "url": "https://github.com/apache/iceberg/commit/2d282a8d1678642ad52ca7875adb214fb1072096", "message": "Core: fix serialization issue in BaseCombinedScanTask with Kyro (No refactor)", "committedDate": "2020-08-02T03:01:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MDUwNA==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r464550504", "bodyText": "What about a slightly different approach?\nRight now, the main problem is that List can't be easily serialized. But we know that tasks are FileScanTask and never changes, so we could use private final FileScanTask[] tasks instead, which has no problems with serialization.\nThen this would just need to copy into the array, tasks.stream().toArray(FileScanTask[]::new), and we could update files to return ImmutableList.copyOf(tasks).\nBy making those changes, we still end up with an immutable list returned by files, but take care of the serialization issue and don't need to add copyList.", "author": "rdblue", "createdAt": "2020-08-03T17:18:25Z", "path": "core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java", "diffHunk": "@@ -19,21 +19,22 @@\n \n package org.apache.iceberg;\n \n+import java.util.Arrays;\n import java.util.Collection;\n import java.util.List;\n import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n import org.apache.iceberg.relocated.com.google.common.base.MoreObjects;\n-import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n \n public class BaseCombinedScanTask implements CombinedScanTask {\n   private final List<FileScanTask> tasks;\n \n   public BaseCombinedScanTask(FileScanTask... tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    this.tasks = Arrays.asList(tasks);\n   }\n \n   public BaseCombinedScanTask(List<FileScanTask> tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    this.tasks = copyList(tasks);", "originalCommit": "2d282a8d1678642ad52ca7875adb214fb1072096", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NzIwOA==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r464757208", "bodyText": "Ah OK that also makes sense - I realized we'd probably want to make sure tasks cannot be modified but files() opens it for modification outside of this class.\nI simply thought about defining tasks as ArrayList<FileScanTask> which also ensures no problem with serialization, but the efforts would be similar (had to make change on constructors and files()) so either is fine for me. I'll go through changing it to array first. Thanks!", "author": "HeartSaVioR", "createdAt": "2020-08-04T02:09:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MDUwNA=="}], "type": "inlineReview", "revised_code": {"commit": "a2a2c768f74f11f1689932ad7cee66146a56f4d1", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\nindex 7cd6261a0..907d9832f 100644\n--- a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n+++ b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n\n@@ -19,27 +19,26 @@\n \n package org.apache.iceberg;\n \n-import java.util.Arrays;\n import java.util.Collection;\n import java.util.List;\n import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n import org.apache.iceberg.relocated.com.google.common.base.MoreObjects;\n-import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n \n public class BaseCombinedScanTask implements CombinedScanTask {\n-  private final List<FileScanTask> tasks;\n+  private final FileScanTask[] tasks;\n \n   public BaseCombinedScanTask(FileScanTask... tasks) {\n-    this.tasks = Arrays.asList(tasks);\n+    this.tasks = tasks;\n   }\n \n   public BaseCombinedScanTask(List<FileScanTask> tasks) {\n-    this.tasks = copyList(tasks);\n+    this.tasks = tasks.stream().toArray(FileScanTask[]::new);\n   }\n \n   @Override\n   public Collection<FileScanTask> files() {\n-    return tasks;\n+    return ImmutableList.copyOf(tasks);\n   }\n \n   @Override\n"}}, {"oid": "a2a2c768f74f11f1689932ad7cee66146a56f4d1", "url": "https://github.com/apache/iceberg/commit/a2a2c768f74f11f1689932ad7cee66146a56f4d1", "message": "Reflect review comment", "committedDate": "2020-08-04T02:22:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDg1MTMyNg==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r464851326", "bodyText": "In Guava, ImmutableList.copyOf() will throw on null input. That same behavior isn't mentioned here. Should we document it, either via a Preconditions check or via an annotation such as @ParametersAreNonNullByDefault which Guava uses.\nNote: I can't speak for all versions of Guava obviously (I doubt anybody could at this point), but I found this isue mentioning it google/guava#2470", "author": "kbendick", "createdAt": "2020-08-04T07:23:33Z", "path": "core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java", "diffHunk": "@@ -26,19 +26,19 @@\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n \n public class BaseCombinedScanTask implements CombinedScanTask {\n-  private final List<FileScanTask> tasks;\n+  private final FileScanTask[] tasks;\n \n   public BaseCombinedScanTask(FileScanTask... tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    this.tasks = tasks;\n   }\n \n   public BaseCombinedScanTask(List<FileScanTask> tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    this.tasks = tasks.stream().toArray(FileScanTask[]::new);", "originalCommit": "a2a2c768f74f11f1689932ad7cee66146a56f4d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDkwOTQ4Mg==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r464909482", "bodyText": "I guess the new code will also throw NPE in any way, but with different error message which is probably less helpful. Checking the null with Precondition sounds good to me, and I prefer defensive programming unless it's on critical path. :) Thanks!", "author": "HeartSaVioR", "createdAt": "2020-08-04T09:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDg1MTMyNg=="}], "type": "inlineReview", "revised_code": {"commit": "1357c223638a46d35780157d7f3d78b4d2680556", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\nindex 907d9832f..4ae02b564 100644\n--- a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n+++ b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n\n@@ -23,6 +23,7 @@ import java.util.Collection;\n import java.util.List;\n import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n import org.apache.iceberg.relocated.com.google.common.base.MoreObjects;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n \n public class BaseCombinedScanTask implements CombinedScanTask {\n"}}, {"oid": "1357c223638a46d35780157d7f3d78b4d2680556", "url": "https://github.com/apache/iceberg/commit/1357c223638a46d35780157d7f3d78b4d2680556", "message": "Reflect review comment", "committedDate": "2020-08-04T09:07:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIwMTgyOQ==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r465201829", "bodyText": "Why add these tests to TestRewriteDataFilesAction? These aren't specific to that action and the code change is in core. I think it would be more better to add these tests to TestDataFileSerialization, since that is quite similar. That, or create a new test suite, TestScanTaskSerialization. Either one is fine with me.", "author": "rdblue", "createdAt": "2020-08-04T17:09:31Z", "path": "spark/src/test/java/org/apache/iceberg/actions/TestRewriteDataFilesAction.java", "diffHunk": "@@ -311,6 +325,128 @@ public void testRewriteLargeTableHasResiduals() {\n     Assert.assertEquals(\"Rows must match\", records, actualRecords);\n   }\n \n+  @Test\n+  public void testBaseCombinedScanTaskKryoSerialization() throws Exception {", "originalCommit": "1357c223638a46d35780157d7f3d78b4d2680556", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMzNDAzOA==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r465334038", "bodyText": "I think I missed to migrate comments from the origin PR, my bad.\n\nI decided to add the serde tests of BaseCombinedScanTask here, because it seems to require non-trivial efforts to create BasedCombinedScanTask by hand. I can move out if we'd like to have separate suite with manually crafted test objects.\n\nSo that was the plan to reduce lots of manual lines by hand, but now I realized the new test cases would just duplicate small code in TestRewriteDataFilesAction even it becomes a new test suite. I'll add a new test suite. Thanks!", "author": "HeartSaVioR", "createdAt": "2020-08-04T21:14:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIwMTgyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "f80cfb9d729686dd2298d394494408a94dfc038c", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/actions/TestRewriteDataFilesAction.java b/spark/src/test/java/org/apache/iceberg/actions/TestRewriteDataFilesAction.java\nindex 9ec4fac40..5c6ae5949 100644\n--- a/spark/src/test/java/org/apache/iceberg/actions/TestRewriteDataFilesAction.java\n+++ b/spark/src/test/java/org/apache/iceberg/actions/TestRewriteDataFilesAction.java\n\n@@ -325,128 +311,6 @@ public abstract class TestRewriteDataFilesAction extends SparkTestBase {\n     Assert.assertEquals(\"Rows must match\", records, actualRecords);\n   }\n \n-  @Test\n-  public void testBaseCombinedScanTaskKryoSerialization() throws Exception {\n-    BaseCombinedScanTask scanTask = prepareBaseCombinedScanTaskForSerDeTest();\n-\n-    File data = temp.newFile();\n-    Assert.assertTrue(data.delete());\n-    Kryo kryo = new KryoSerializer(new SparkConf()).newKryo();\n-\n-    try (Output out = new Output(new FileOutputStream(data))) {\n-      kryo.writeClassAndObject(out, scanTask);\n-    }\n-\n-    try (Input in = new Input(new FileInputStream(data))) {\n-      Object obj = kryo.readClassAndObject(in);\n-      Assert.assertTrue(\"Should be a BaseCombinedScanTask\", obj instanceof BaseCombinedScanTask);\n-      checkBaseCombinedScanTask(scanTask, (BaseCombinedScanTask) obj);\n-    }\n-  }\n-\n-  @Test\n-  public void testBaseCombinedScanTaskJavaSerialization() throws Exception {\n-    BaseCombinedScanTask scanTask = prepareBaseCombinedScanTaskForSerDeTest();\n-\n-    ByteArrayOutputStream bytes = new ByteArrayOutputStream();\n-    try (ObjectOutputStream out = new ObjectOutputStream(bytes)) {\n-      out.writeObject(scanTask);\n-    }\n-\n-    try (ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bytes.toByteArray()))) {\n-      Object obj = in.readObject();\n-      Assert.assertTrue(\"Should be a BaseCombinedScanTask\", obj instanceof BaseCombinedScanTask);\n-      checkBaseCombinedScanTask(scanTask, (BaseCombinedScanTask) obj);\n-    }\n-  }\n-\n-  private BaseCombinedScanTask prepareBaseCombinedScanTaskForSerDeTest() {\n-    PartitionSpec spec = PartitionSpec.unpartitioned();\n-    Map<String, String> options = Maps.newHashMap();\n-    Table table = TABLES.create(SCHEMA, spec, options, tableLocation);\n-\n-    List<ThreeColumnRecord> records1 = Lists.newArrayList(\n-            new ThreeColumnRecord(1, null, \"AAAA\"),\n-            new ThreeColumnRecord(1, \"BBBBBBBBBB\", \"BBBB\")\n-    );\n-    writeRecords(records1);\n-\n-    List<ThreeColumnRecord> records2 = Lists.newArrayList(\n-            new ThreeColumnRecord(2, \"CCCCCCCCCC\", \"CCCC\"),\n-            new ThreeColumnRecord(2, \"DDDDDDDDDD\", \"DDDD\")\n-    );\n-    writeRecords(records2);\n-\n-    table.refresh();\n-\n-    CloseableIterable<FileScanTask> tasks = table.newScan().planFiles();\n-    return new BaseCombinedScanTask(Lists.newArrayList(tasks));\n-  }\n-\n-  private void checkBaseCombinedScanTask(BaseCombinedScanTask expected, BaseCombinedScanTask actual) {\n-    List<FileScanTask> expectedTasks = getFileScanTasksInFilePathOrder(expected);\n-    List<FileScanTask> actualTasks = getFileScanTasksInFilePathOrder(actual);\n-\n-    Assert.assertEquals(\"The number of file scan tasks should match\",\n-            expectedTasks.size(), actualTasks.size());\n-\n-    for (int i = 0; i < expectedTasks.size(); i++) {\n-      FileScanTask expectedTask = expectedTasks.get(i);\n-      FileScanTask actualTask = actualTasks.get(i);\n-      checkFileScanTask(expectedTask, actualTask);\n-    }\n-  }\n-\n-  private List<FileScanTask> getFileScanTasksInFilePathOrder(BaseCombinedScanTask task) {\n-    return task.files().stream()\n-            // use file path + start position to differentiate the tasks\n-            .sorted(Comparator.comparing(o -> o.file().path().toString() + \"##\" + o.start()))\n-            .collect(Collectors.toList());\n-  }\n-\n-  private void checkFileScanTask(FileScanTask expected, FileScanTask actual) {\n-    checkDataFile(expected.file(), actual.file());\n-\n-    // PartitionSpec implements its own equals method\n-    Assert.assertEquals(\"PartitionSpec doesn't match\", expected.spec(), actual.spec());\n-\n-    Assert.assertEquals(\"starting position doesn't match\", expected.start(), actual.start());\n-\n-    Assert.assertEquals(\"the number of bytes to scan doesn't match\", expected.start(), actual.start());\n-\n-    // simplify comparison on residual expression via comparing toString\n-    Assert.assertEquals(\"Residual expression doesn't match\",\n-            expected.residual().toString(), actual.residual().toString());\n-  }\n-\n-  // TODO: this is a copy of TestDataFileSerialization.checkDataFile, deduplicate\n-  private void checkDataFile(DataFile expected, DataFile actual) {\n-    Assert.assertEquals(\"Should match the serialized record path\",\n-            expected.path(), actual.path());\n-    Assert.assertEquals(\"Should match the serialized record format\",\n-            expected.format(), actual.format());\n-    Assert.assertEquals(\"Should match the serialized record partition\",\n-            expected.partition().get(0, Object.class), actual.partition().get(0, Object.class));\n-    Assert.assertEquals(\"Should match the serialized record count\",\n-            expected.recordCount(), actual.recordCount());\n-    Assert.assertEquals(\"Should match the serialized record size\",\n-            expected.fileSizeInBytes(), actual.fileSizeInBytes());\n-    Assert.assertEquals(\"Should match the serialized record value counts\",\n-            expected.valueCounts(), actual.valueCounts());\n-    Assert.assertEquals(\"Should match the serialized record null value counts\",\n-            expected.nullValueCounts(), actual.nullValueCounts());\n-    Assert.assertEquals(\"Should match the serialized record lower bounds\",\n-            expected.lowerBounds(), actual.lowerBounds());\n-    Assert.assertEquals(\"Should match the serialized record upper bounds\",\n-            expected.upperBounds(), actual.upperBounds());\n-    Assert.assertEquals(\"Should match the serialized record key metadata\",\n-            expected.keyMetadata(), actual.keyMetadata());\n-    Assert.assertEquals(\"Should match the serialized record offsets\",\n-            expected.splitOffsets(), actual.splitOffsets());\n-    Assert.assertEquals(\"Should match the serialized record offsets\",\n-            expected.keyMetadata(), actual.keyMetadata());\n-  }\n-\n   private void writeRecords(List<ThreeColumnRecord> records) {\n     Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class);\n     writeDF(df);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIwMjM4Mw==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r465202383", "bodyText": "Nit: We try to keep error messages small, so we avoid unnecessary punctuation and words. We can remove the . here.", "author": "rdblue", "createdAt": "2020-08-04T17:10:31Z", "path": "core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java", "diffHunk": "@@ -23,22 +23,24 @@\n import java.util.List;\n import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n import org.apache.iceberg.relocated.com.google.common.base.MoreObjects;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n \n public class BaseCombinedScanTask implements CombinedScanTask {\n-  private final List<FileScanTask> tasks;\n+  private final FileScanTask[] tasks;\n \n   public BaseCombinedScanTask(FileScanTask... tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    this.tasks = tasks;\n   }\n \n   public BaseCombinedScanTask(List<FileScanTask> tasks) {\n-    this.tasks = ImmutableList.copyOf(tasks);\n+    Preconditions.checkNotNull(tasks, \"tasks cannot be null.\");", "originalCommit": "1357c223638a46d35780157d7f3d78b4d2680556", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f80cfb9d729686dd2298d394494408a94dfc038c", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\nindex 4ae02b564..253ddfa76 100644\n--- a/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n+++ b/core/src/main/java/org/apache/iceberg/BaseCombinedScanTask.java\n\n@@ -34,7 +34,7 @@ public class BaseCombinedScanTask implements CombinedScanTask {\n   }\n \n   public BaseCombinedScanTask(List<FileScanTask> tasks) {\n-    Preconditions.checkNotNull(tasks, \"tasks cannot be null.\");\n+    Preconditions.checkNotNull(tasks, \"tasks cannot be null\");\n     this.tasks = tasks.stream().toArray(FileScanTask[]::new);\n   }\n \n"}}, {"oid": "f80cfb9d729686dd2298d394494408a94dfc038c", "url": "https://github.com/apache/iceberg/commit/f80cfb9d729686dd2298d394494408a94dfc038c", "message": "Reflect review comment", "committedDate": "2020-08-04T22:16:22Z", "type": "commit"}, {"oid": "f80cfb9d729686dd2298d394494408a94dfc038c", "url": "https://github.com/apache/iceberg/commit/f80cfb9d729686dd2298d394494408a94dfc038c", "message": "Reflect review comment", "committedDate": "2020-08-04T22:16:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQwODM3Nw==", "url": "https://github.com/apache/iceberg/pull/1285#discussion_r465408377", "bodyText": "This file needs the Apache license header, which you can copy from another file.", "author": "rdblue", "createdAt": "2020-08-05T00:49:16Z", "path": "spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java", "diffHunk": "@@ -0,0 +1,191 @@\n+package org.apache.iceberg;", "originalCommit": "f80cfb9d729686dd2298d394494408a94dfc038c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c42b59b05a251d5747510ac987fa4982e39e1fcc", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java b/spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java\nindex 00bce3cc5..e6220202a 100644\n--- a/spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java\n+++ b/spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java\n\n@@ -1,8 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n package org.apache.iceberg;\n \n import com.esotericsoftware.kryo.Kryo;\n import com.esotericsoftware.kryo.io.Input;\n import com.esotericsoftware.kryo.io.Output;\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.hadoop.HadoopTables;\n import org.apache.iceberg.io.CloseableIterable;\n"}}, {"oid": "c42b59b05a251d5747510ac987fa4982e39e1fcc", "url": "https://github.com/apache/iceberg/commit/c42b59b05a251d5747510ac987fa4982e39e1fcc", "message": "license header & checkstyle", "committedDate": "2020-08-05T01:10:07Z", "type": "commit"}, {"oid": "6ba1c96ba3c6eac611084701a4d71926ed2520f2", "url": "https://github.com/apache/iceberg/commit/6ba1c96ba3c6eac611084701a4d71926ed2520f2", "message": "Fixing...", "committedDate": "2020-08-05T02:24:03Z", "type": "commit"}]}