{"pr_number": 1514, "pr_title": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "pr_createdAt": "2020-09-26T01:00:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1514", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496251006", "bodyText": "There is no equals and hashCode implementation for CharSequence, so it can't be used reliably as a map key to deduplicate.\nAlso, the only thing you need from the file instance is the key metadata, so you could keep a map of string path to key metadata, like this:\n    Map<String, ByteBuffer> keyMetadata = Maps.newHashMap();\n    task.files().stream()\n        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n        .forEach(file -> keyMetadata.put(file.path().toString(), file.keyMetadata()));\n    Stream<EncryptedInputFile> encrypted = keyMetadata.entrySet().stream()\n        .map(entry -> EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));", "author": "rdblue", "createdAt": "2020-09-28T21:44:39Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java", "diffHunk": "@@ -58,9 +60,12 @@\n \n   BaseDataReader(CombinedScanTask task, FileIO io, EncryptionManager encryptionManager) {\n     this.tasks = task.files().iterator();\n-    Stream<EncryptedInputFile> encrypted = task.files().stream()\n-        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n-        .map(file -> EncryptedFiles.encryptedInput(io.newInputFile(file.path().toString()), file.keyMetadata()));\n+    Map<CharSequence, DeleteFile> uniqueDeleteFileMap = Maps.newHashMap();", "originalCommit": "e2fa9ac689d8776526a0d754a09878f5a0b668bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1OTg2NA==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496259864", "bodyText": "I actually started with deduping both DataFile and DeleteFile, but thought of keeping it just for DeleteFile, to not touch other workflows. will follow your recommendation. Thanks!", "author": "mehtaashish23", "createdAt": "2020-09-28T21:58:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg=="}], "type": "inlineReview", "revised_code": {"commit": "e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\nindex 42df13999..f2896db77 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n\n@@ -60,12 +59,12 @@ abstract class BaseDataReader<T> implements Closeable {\n \n   BaseDataReader(CombinedScanTask task, FileIO io, EncryptionManager encryptionManager) {\n     this.tasks = task.files().iterator();\n-    Map<CharSequence, DeleteFile> uniqueDeleteFileMap = Maps.newHashMap();\n-    task.files().forEach(files -> files.deletes()\n-        .forEach(deleteFile -> uniqueDeleteFileMap.put(deleteFile.path(), deleteFile)));\n-    Stream<EncryptedInputFile> encrypted = Stream.concat(task.files().stream()\n-        .map(fileScanTask -> fileScanTask.file()), uniqueDeleteFileMap.values().stream())\n-        .map(file ->  EncryptedFiles.encryptedInput(io.newInputFile(file.path().toString()), file.keyMetadata()));\n+    Map<String, ByteBuffer> keyMetadata = Maps.newHashMap();\n+    task.files().stream()\n+        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n+        .forEach(file -> keyMetadata.put(file.path().toString(), file.keyMetadata()));\n+    Stream<EncryptedInputFile> encrypted = keyMetadata.entrySet().stream()\n+        .map(entry -> EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));\n \n     // decrypt with the batch call to avoid multiple RPCs to a key server, if possible\n     Iterable<InputFile> decryptedFiles = encryptionManager.decrypt(encrypted::iterator);\n"}}, {"oid": "d89f92d11d1268bc180916d10d762221966c793d", "url": "https://github.com/apache/iceberg/commit/d89f92d11d1268bc180916d10d762221966c793d", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "committedDate": "2020-10-05T17:19:18Z", "type": "commit"}, {"oid": "e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "url": "https://github.com/apache/iceberg/commit/e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nReview Feedback", "committedDate": "2020-10-05T17:25:37Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "forcePushed"}]}