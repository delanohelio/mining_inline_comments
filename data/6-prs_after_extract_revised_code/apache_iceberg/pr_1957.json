{"pr_number": 1957, "pr_title": "Spark: Print file location in case of error during reads", "pr_createdAt": "2020-12-18T04:52:16Z", "pr_url": "https://github.com/apache/iceberg/pull/1957", "timeline": [{"oid": "5f37abf1ac17e0006926c73757b01f2d5311719b", "url": "https://github.com/apache/iceberg/commit/5f37abf1ac17e0006926c73757b01f2d5311719b", "message": "Spark: Print file location in case of error during reads", "committedDate": "2020-12-18T04:44:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMTYwMg==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546001602", "bodyText": "Did you intend to set this in the constructor?", "author": "rdblue", "createdAt": "2020-12-18T18:08:50Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java", "diffHunk": "@@ -56,6 +56,7 @@\n \n   private CloseableIterator<T> currentIterator;\n   private T current = null;\n+  private FileScanTask currentTask = null;", "originalCommit": "5f37abf1ac17e0006926c73757b01f2d5311719b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE3ODk5OA==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546178998", "bodyText": "Not really, does it matter if it is in the constructor? It is going to be set to null in the constructor anyway. Similar to the current variable above it.", "author": "shardulm94", "createdAt": "2020-12-19T02:38:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMTYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjI5MDU3NA==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546290574", "bodyText": "Sorry, I missed that this is getting set in next. I thought that change was just to indentation. Nevermind!", "author": "rdblue", "createdAt": "2020-12-19T22:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMTYwMg=="}], "type": "inlineReview", "revised_code": {"commit": "8114b9f25832061e442b3ea71cc1a90cd05c839b", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\nindex a07161e5b..566dcabd8 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n\n@@ -51,6 +53,8 @@ import org.apache.spark.unsafe.types.UTF8String;\n  * @param <T> is the Java class returned by this reader whose objects contain one or more rows.\n  */\n abstract class BaseDataReader<T> implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(BaseDataReader.class);\n+\n   private final Iterator<FileScanTask> tasks;\n   private final Map<String, InputFile> inputFiles;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMzg4MA==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546003880", "bodyText": "The main problem I have with this is that it alters the exception by discarding its type. Callers can no longer catch exceptions and handle errors. For example, a caller might catch a SocketException and retry, but let an EOFException propagate.\nIs there another way to attach the data? What about logging the file path and exception instead of modifying the exception?\nAnother option is to create a new exception and attach it as suppressed, then throw the original unmodified.", "author": "rdblue", "createdAt": "2020-12-18T18:13:23Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java", "diffHunk": "@@ -77,16 +78,30 @@\n   }\n \n   public boolean next() throws IOException {\n-    while (true) {\n-      if (currentIterator.hasNext()) {\n-        this.current = currentIterator.next();\n-        return true;\n-      } else if (tasks.hasNext()) {\n-        this.currentIterator.close();\n-        this.currentIterator = open(tasks.next());\n+    try {\n+      while (true) {\n+        if (currentIterator.hasNext()) {\n+          this.current = currentIterator.next();\n+          return true;\n+        } else if (tasks.hasNext()) {\n+          this.currentIterator.close();\n+          this.currentTask = tasks.next();\n+          this.currentIterator = open(currentTask);\n+        } else {\n+          this.currentIterator.close();\n+          return false;\n+        }\n+      }\n+    } catch (IOException | RuntimeException e) {\n+      if (currentTask == null || currentTask.isDataTask()) {\n+        throw e;\n       } else {\n-        this.currentIterator.close();\n-        return false;\n+        String message = String.format(\"Error reading file: %s\", getInputFile(currentTask).location());\n+        if (e instanceof IOException) {\n+          throw new IOException(message, e);\n+        } else {\n+          throw new RuntimeException(message, e);\n+        }", "originalCommit": "5f37abf1ac17e0006926c73757b01f2d5311719b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0ODQ3MQ==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546048471", "bodyText": "+1 To Logging an error", "author": "RussellSpitzer", "createdAt": "2020-12-18T19:29:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMzg4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA3NzU0Nw==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546077547", "bodyText": "Logging the error makes sense! Thanks for the suggestion.", "author": "shardulm94", "createdAt": "2020-12-18T20:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMzg4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE3OTAwNQ==", "url": "https://github.com/apache/iceberg/pull/1957#discussion_r546179005", "bodyText": "Done", "author": "shardulm94", "createdAt": "2020-12-19T02:38:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAwMzg4MA=="}], "type": "inlineReview", "revised_code": {"commit": "8114b9f25832061e442b3ea71cc1a90cd05c839b", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\nindex a07161e5b..566dcabd8 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java\n\n@@ -93,16 +97,10 @@ abstract class BaseDataReader<T> implements Closeable {\n         }\n       }\n     } catch (IOException | RuntimeException e) {\n-      if (currentTask == null || currentTask.isDataTask()) {\n-        throw e;\n-      } else {\n-        String message = String.format(\"Error reading file: %s\", getInputFile(currentTask).location());\n-        if (e instanceof IOException) {\n-          throw new IOException(message, e);\n-        } else {\n-          throw new RuntimeException(message, e);\n-        }\n+      if (currentTask != null && !currentTask.isDataTask()) {\n+        LOG.error(\"Error reading file: {}\", getInputFile(currentTask).location(), e);\n       }\n+      throw e;\n     }\n   }\n \n"}}, {"oid": "8114b9f25832061e442b3ea71cc1a90cd05c839b", "url": "https://github.com/apache/iceberg/commit/8114b9f25832061e442b3ea71cc1a90cd05c839b", "message": "Address PR comments", "committedDate": "2020-12-19T02:37:39Z", "type": "commit"}]}