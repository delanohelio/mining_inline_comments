{"pr_number": 1335, "pr_title": "Spark: Follow name mapping while importing Parquet tables", "pr_createdAt": "2020-08-13T15:23:04Z", "pr_url": "https://github.com/apache/iceberg/pull/1335", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNDcyNw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470034727", "bodyText": "I kept the initialization in place. It triggers validation. Otherwise, some tests fail.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:24:04Z", "path": "core/src/main/java/org/apache/iceberg/mapping/MappedFields.java", "diffHunk": "@@ -37,21 +38,21 @@ public static MappedFields of(List<MappedField> fields) {\n   }\n \n   private final List<MappedField> fields;\n-  private final Map<String, Integer> nameToId;\n-  private final Map<Integer, MappedField> idToField;\n+  private transient Map<String, Integer> nameToId;\n+  private transient Map<Integer, MappedField> idToField;\n \n   private MappedFields(List<MappedField> fields) {\n     this.fields = ImmutableList.copyOf(fields);\n-    this.nameToId = indexIds(fields);\n-    this.idToField = indexFields(fields);\n+    lazyNameToId();", "originalCommit": "1827e6ad3f9c8ce1265b0e47b5aad9480a3848d1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNTM0Mg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470035342", "bodyText": "Same here.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:24:55Z", "path": "core/src/main/java/org/apache/iceberg/mapping/NameMapping.java", "diffHunk": "@@ -43,31 +44,45 @@ public static NameMapping of(MappedFields fields) {\n   }\n \n   private final MappedFields mapping;\n-  private final Map<Integer, MappedField> fieldsById;\n-  private final Map<String, MappedField> fieldsByName;\n+  private transient Map<Integer, MappedField> fieldsById;\n+  private transient Map<String, MappedField> fieldsByName;\n \n   NameMapping(MappedFields mapping) {\n     this.mapping = mapping;\n-    this.fieldsById = MappingUtil.indexById(mapping);\n-    this.fieldsByName = MappingUtil.indexByName(mapping);\n+    lazyFieldsById();", "originalCommit": "1827e6ad3f9c8ce1265b0e47b5aad9480a3848d1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjE5Mw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470036193", "bodyText": "While we are using guava classes, I think it should be ok as Spark uses Java serialization for closures.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:26:10Z", "path": "core/src/main/java/org/apache/iceberg/mapping/NameMapping.java", "diffHunk": "@@ -27,7 +28,7 @@\n /**\n  * Represents a mapping from external schema names to Iceberg type IDs.\n  */\n-public class NameMapping {\n+public class NameMapping implements Serializable {", "originalCommit": "1827e6ad3f9c8ce1265b0e47b5aad9480a3848d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE4OTgzOA==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470189838", "bodyText": "Probably better to switch to using arrays. Some people still use Kryo for task serialization and we don't want that to fail.", "author": "rdblue", "createdAt": "2020-08-13T19:17:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE5NzQ1OQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470197459", "bodyText": "Yeah, we have a number of places like this to fix, including Schema.\nI've created #1337 to follow up on this.", "author": "aokolnychyi", "createdAt": "2020-08-13T19:30:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIwMTQyNA==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470201424", "bodyText": "Thanks! I don't think Schema needs to be updated, since it only uses Guava classes for transient fields that get re-initialized after serialization.\nLooks like that applies here as well. The change I was referring to is the list of fields in MappedFields.", "author": "rdblue", "createdAt": "2020-08-13T19:37:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI0NDU2Ng==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470244566", "bodyText": "Yeah, you are right, I overlooked.", "author": "aokolnychyi", "createdAt": "2020-08-13T20:58:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjE5Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470037828", "bodyText": "We have to prune columns without ids. Otherwise, ParquetSchemaUtil.convert will assign fallback ids to columns not present in the name mapping and they will most likely conflict with ids assigned by the name mapping.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:28:36Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -136,6 +154,19 @@ public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metr\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n+  private static MessageType getParquetType(ParquetMetadata metadata, Schema expectedSchema, NameMapping nameMapping) {\n+    MessageType type = metadata.getFileMetaData().getSchema();\n+    if (ParquetSchemaUtil.hasIds(type)) {\n+      return expectedSchema != null ? ParquetSchemaUtil.pruneColumns(type, expectedSchema) : type;\n+    } else if (nameMapping != null) {\n+      MessageType typeWithIds = ParquetSchemaUtil.applyNameMapping(type, nameMapping);", "originalCommit": "1827e6ad3f9c8ce1265b0e47b5aad9480a3848d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzOTM4OA==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470039388", "bodyText": "An alternative is to build a custom visitor and combine logic from ApplyNameMapping and PruneColumns.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:30:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDE5MzcxMw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470193713", "bodyText": "Do we need expectedSchema to do this?\nIt seems like it would be easier if we didn't need it. What we want is to use the IDs from the mapping without assigning new IDs for columns that don't have them during conversion. So why not make a version of convert that doesn't assign columns? That seems much easier than doing column pruning and it doesn't require a new schema -- which introduced new methods everywhere to pass that new schema.", "author": "rdblue", "createdAt": "2020-08-13T19:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI0NTI1Ng==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470245256", "bodyText": "Agree, let me update this.", "author": "aokolnychyi", "createdAt": "2020-08-13T20:59:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI1MDg3Mg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470250872", "bodyText": "Actually, I remember one point I forgot. We cannot have a version of convert that does not assign ids as we must have an id for every column in Iceberg schema. It seems what we want is a way to prune columns without ids.", "author": "aokolnychyi", "createdAt": "2020-08-13T21:11:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI1MjQyNg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470252426", "bodyText": "We can also add a flag to MessageTypeToType to throw an exception instead of assigning an id.", "author": "aokolnychyi", "createdAt": "2020-08-13T21:14:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI1NjU1OQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470256559", "bodyText": "What about a version of MessageTypeToType that removes columns without IDs rather than assigning new ones? That would be more flexible than failing if unassigned columns are present.", "author": "rdblue", "createdAt": "2020-08-13T21:22:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzgyOA=="}], "type": "inlineReview", "revised_code": {"commit": "ff54e7fd75e4d92795735bfb0ab8560c59d0c437", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\nindex dda8ada12..3811b4970 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n\n@@ -154,16 +152,14 @@ public class ParquetUtil {\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n-  private static MessageType getParquetType(ParquetMetadata metadata, Schema expectedSchema, NameMapping nameMapping) {\n+  private static MessageType getParquetTypeWithIds(ParquetMetadata metadata, NameMapping nameMapping) {\n     MessageType type = metadata.getFileMetaData().getSchema();\n     if (ParquetSchemaUtil.hasIds(type)) {\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumns(type, expectedSchema) : type;\n+      return type;\n     } else if (nameMapping != null) {\n-      MessageType typeWithIds = ParquetSchemaUtil.applyNameMapping(type, nameMapping);\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumns(typeWithIds, expectedSchema) : typeWithIds;\n+      return ParquetSchemaUtil.applyNameMapping(type, nameMapping);\n     } else {\n-      MessageType typeWithIds = ParquetSchemaUtil.addFallbackIds(type);\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumnsFallback(typeWithIds, expectedSchema) : typeWithIds;\n+      return ParquetSchemaUtil.addFallbackIds(type);\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzODY3Mg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470038672", "bodyText": "The idea here is that we should import metrics only for columns in the current schema.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:29:49Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -136,6 +154,19 @@ public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metr\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n+  private static MessageType getParquetType(ParquetMetadata metadata, Schema expectedSchema, NameMapping nameMapping) {", "originalCommit": "1827e6ad3f9c8ce1265b0e47b5aad9480a3848d1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ff54e7fd75e4d92795735bfb0ab8560c59d0c437", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\nindex dda8ada12..3811b4970 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n\n@@ -154,16 +152,14 @@ public class ParquetUtil {\n         toBufferMap(fileSchema, lowerBounds), toBufferMap(fileSchema, upperBounds));\n   }\n \n-  private static MessageType getParquetType(ParquetMetadata metadata, Schema expectedSchema, NameMapping nameMapping) {\n+  private static MessageType getParquetTypeWithIds(ParquetMetadata metadata, NameMapping nameMapping) {\n     MessageType type = metadata.getFileMetaData().getSchema();\n     if (ParquetSchemaUtil.hasIds(type)) {\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumns(type, expectedSchema) : type;\n+      return type;\n     } else if (nameMapping != null) {\n-      MessageType typeWithIds = ParquetSchemaUtil.applyNameMapping(type, nameMapping);\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumns(typeWithIds, expectedSchema) : typeWithIds;\n+      return ParquetSchemaUtil.applyNameMapping(type, nameMapping);\n     } else {\n-      MessageType typeWithIds = ParquetSchemaUtil.addFallbackIds(type);\n-      return expectedSchema != null ? ParquetSchemaUtil.pruneColumnsFallback(typeWithIds, expectedSchema) : typeWithIds;\n+      return ParquetSchemaUtil.addFallbackIds(type);\n     }\n   }\n \n"}}, {"oid": "2b90def1b7cd10984e0e436d3ac838305935a881", "url": "https://github.com/apache/iceberg/commit/2b90def1b7cd10984e0e436d3ac838305935a881", "message": "Spark: Respect name mapping while importing Parquet tables", "committedDate": "2020-08-13T15:33:09Z", "type": "commit"}, {"oid": "2b90def1b7cd10984e0e436d3ac838305935a881", "url": "https://github.com/apache/iceberg/commit/2b90def1b7cd10984e0e436d3ac838305935a881", "message": "Spark: Respect name mapping while importing Parquet tables", "committedDate": "2020-08-13T15:33:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MzM2Mw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470043363", "bodyText": "This would fail before the PR as the metrics were imported in the wrong way. The previous predicate did not trigger this issue, so I changed it.", "author": "aokolnychyi", "createdAt": "2020-08-13T15:36:57Z", "path": "spark2/src/test/java/org/apache/iceberg/spark/source/TestSparkTableUtil.java", "diffHunk": "@@ -239,18 +238,13 @@ public void testImportWithNameMapping() throws Exception {\n     List<String> actual = spark.read().format(\"iceberg\").load(DB_NAME + \".target_table\")\n         .select(\"data\")\n         .sort(\"data\")\n-        .filter(\"data<'c'\")\n-        .collectAsList()\n-        .stream()\n-        .map(r -> r.getString(0))\n-        .collect(Collectors.toList());\n+        .filter(\"data >= 'b'\")", "originalCommit": "2b90def1b7cd10984e0e436d3ac838305935a881", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "ff54e7fd75e4d92795735bfb0ab8560c59d0c437", "url": "https://github.com/apache/iceberg/commit/ff54e7fd75e4d92795735bfb0ab8560c59d0c437", "message": "Switch to using a separate visitor", "committedDate": "2020-08-14T17:42:24Z", "type": "commit"}, {"oid": "f1e4f54b1bf2fc1c887bc4a918f934680b4d6bc8", "url": "https://github.com/apache/iceberg/commit/f1e4f54b1bf2fc1c887bc4a918f934680b4d6bc8", "message": "Make package-private", "committedDate": "2020-08-14T17:45:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc2NzAwNQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470767005", "bodyText": "I've refactored the common logic in MessageTypeToType to a base class.", "author": "aokolnychyi", "createdAt": "2020-08-14T17:46:06Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/BaseMessageTypeToType.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.Optional;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.TimestampType;\n+import org.apache.parquet.schema.LogicalTypeAnnotation;\n+import org.apache.parquet.schema.PrimitiveType;\n+\n+abstract class BaseMessageTypeToType extends ParquetTypeVisitor<Type> {", "originalCommit": "f1e4f54b1bf2fc1c887bc4a918f934680b4d6bc8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "340b92ad0a2e183205b64ef11264760f85f7dbe3", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/BaseMessageTypeToType.java b/parquet/src/main/java/org/apache/iceberg/parquet/BaseMessageTypeToType.java\ndeleted file mode 100644\nindex 50fcf805b..000000000\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/BaseMessageTypeToType.java\n+++ /dev/null\n\n@@ -1,127 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.iceberg.parquet;\n-\n-import java.util.Optional;\n-import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n-import org.apache.iceberg.types.Type;\n-import org.apache.iceberg.types.Types;\n-import org.apache.iceberg.types.Types.TimestampType;\n-import org.apache.parquet.schema.LogicalTypeAnnotation;\n-import org.apache.parquet.schema.PrimitiveType;\n-\n-abstract class BaseMessageTypeToType extends ParquetTypeVisitor<Type> {\n-\n-  @Override\n-  public Type primitive(PrimitiveType primitive) {\n-    // first, use the logical type annotation, if present\n-    LogicalTypeAnnotation logicalType = primitive.getLogicalTypeAnnotation();\n-    if (logicalType != null) {\n-      Optional<Type> converted = logicalType.accept(ParquetLogicalTypeVisitor.get());\n-      if (converted.isPresent()) {\n-        return converted.get();\n-      }\n-    }\n-\n-    // last, use the primitive type\n-    switch (primitive.getPrimitiveTypeName()) {\n-      case BOOLEAN:\n-        return Types.BooleanType.get();\n-      case INT32:\n-        return Types.IntegerType.get();\n-      case INT64:\n-        return Types.LongType.get();\n-      case FLOAT:\n-        return Types.FloatType.get();\n-      case DOUBLE:\n-        return Types.DoubleType.get();\n-      case FIXED_LEN_BYTE_ARRAY:\n-        return Types.FixedType.ofLength(primitive.getTypeLength());\n-      case INT96:\n-        return Types.TimestampType.withZone();\n-      case BINARY:\n-        return Types.BinaryType.get();\n-    }\n-\n-    throw new UnsupportedOperationException(\n-        \"Cannot convert unknown primitive type: \" + primitive);\n-  }\n-\n-  private static class ParquetLogicalTypeVisitor implements LogicalTypeAnnotation.LogicalTypeAnnotationVisitor<Type> {\n-    private static final ParquetLogicalTypeVisitor INSTANCE = new ParquetLogicalTypeVisitor();\n-\n-    private static ParquetLogicalTypeVisitor get() {\n-      return INSTANCE;\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.StringLogicalTypeAnnotation stringType) {\n-      return Optional.of(Types.StringType.get());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.EnumLogicalTypeAnnotation enumType) {\n-      return Optional.of(Types.StringType.get());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.DecimalLogicalTypeAnnotation decimalType) {\n-      return Optional.of(Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale()));\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.DateLogicalTypeAnnotation dateType) {\n-      return Optional.of(Types.DateType.get());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.TimeLogicalTypeAnnotation timeType) {\n-      return Optional.of(Types.TimeType.get());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.TimestampLogicalTypeAnnotation timestampType) {\n-      return Optional.of(timestampType.isAdjustedToUTC() ? TimestampType.withZone() : TimestampType.withoutZone());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.IntLogicalTypeAnnotation intType) {\n-      Preconditions.checkArgument(intType.isSigned() || intType.getBitWidth() < 64,\n-          \"Cannot use uint64: not a supported Java type\");\n-      if (intType.getBitWidth() < 32) {\n-        return Optional.of(Types.IntegerType.get());\n-      } else if (intType.getBitWidth() == 32 && intType.isSigned()) {\n-        return Optional.of(Types.IntegerType.get());\n-      } else {\n-        return Optional.of(Types.LongType.get());\n-      }\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.JsonLogicalTypeAnnotation jsonType) {\n-      return Optional.of(Types.StringType.get());\n-    }\n-\n-    @Override\n-    public Optional<Type> visit(LogicalTypeAnnotation.BsonLogicalTypeAnnotation bsonType) {\n-      return Optional.of(Types.BinaryType.get());\n-    }\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc2NzY5MQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470767691", "bodyText": "This is the same in both visitors. Should it be moved into the base class?", "author": "rdblue", "createdAt": "2020-08-14T17:47:47Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToTypeWithoutAssigningIds.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.parquet;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Type.Repetition;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+/**\n+ * A visitor that converts a {@link MessageType} to a {@link Type} in Iceberg without assigning ids.\n+ * Columns without ids are pruned.\n+ */\n+public class MessageTypeToTypeWithoutAssigningIds extends BaseMessageTypeToType {\n+  private static final Joiner DOT = Joiner.on(\".\");\n+\n+  private final Map<String, Integer> aliasToId = Maps.newHashMap();\n+\n+  MessageTypeToTypeWithoutAssigningIds() {}\n+\n+  public Map<String, Integer> getAliases() {\n+    return aliasToId;\n+  }\n+\n+  @Override\n+  public Type message(MessageType message, List<Type> fields) {", "originalCommit": "ff54e7fd75e4d92795735bfb0ab8560c59d0c437", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDEwMw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470900103", "bodyText": "Updated MessageTypeToType instead.", "author": "aokolnychyi", "createdAt": "2020-08-14T23:09:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc2NzY5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "340b92ad0a2e183205b64ef11264760f85f7dbe3", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToTypeWithoutAssigningIds.java b/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToTypeWithoutAssigningIds.java\ndeleted file mode 100644\nindex 2b9a34915..000000000\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToTypeWithoutAssigningIds.java\n+++ /dev/null\n\n@@ -1,144 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.iceberg.parquet;\n-\n-import java.util.List;\n-import java.util.Map;\n-import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n-import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n-import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n-import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n-import org.apache.iceberg.types.Type;\n-import org.apache.iceberg.types.Types;\n-import org.apache.parquet.schema.GroupType;\n-import org.apache.parquet.schema.MessageType;\n-import org.apache.parquet.schema.Type.Repetition;\n-\n-import static org.apache.iceberg.types.Types.NestedField.optional;\n-import static org.apache.iceberg.types.Types.NestedField.required;\n-\n-/**\n- * A visitor that converts a {@link MessageType} to a {@link Type} in Iceberg without assigning ids.\n- * Columns without ids are pruned.\n- */\n-public class MessageTypeToTypeWithoutAssigningIds extends BaseMessageTypeToType {\n-  private static final Joiner DOT = Joiner.on(\".\");\n-\n-  private final Map<String, Integer> aliasToId = Maps.newHashMap();\n-\n-  MessageTypeToTypeWithoutAssigningIds() {}\n-\n-  public Map<String, Integer> getAliases() {\n-    return aliasToId;\n-  }\n-\n-  @Override\n-  public Type message(MessageType message, List<Type> fields) {\n-    return struct(message, fields);\n-  }\n-\n-  @Override\n-  public Type struct(GroupType parquetStruct, List<Type> fieldTypes) {\n-    List<org.apache.parquet.schema.Type> parquetFields = parquetStruct.getFields();\n-    List<Types.NestedField> fields = Lists.newArrayList();\n-\n-    for (int i = 0; i < parquetFields.size(); i += 1) {\n-      org.apache.parquet.schema.Type parquetField = parquetFields.get(i);\n-\n-      Preconditions.checkArgument(\n-          !parquetField.isRepetition(Repetition.REPEATED),\n-          \"Fields cannot have repetition REPEATED: %s\", parquetField);\n-\n-      Integer fieldId = getId(parquetField);\n-      Type fieldType = fieldTypes.get(i);\n-\n-      // keep the field if it has an id and it was not pruned (i.e. its type is not null)\n-      if (fieldId != null && fieldType != null) {\n-        addAlias(parquetField.getName(), fieldId);\n-\n-        if (parquetFields.get(i).isRepetition(Repetition.OPTIONAL)) {\n-          fields.add(optional(fieldId, parquetField.getName(), fieldType));\n-        } else {\n-          fields.add(required(fieldId, parquetField.getName(), fieldType));\n-        }\n-      }\n-    }\n-\n-    return fields.isEmpty() ? null : Types.StructType.of(fields);\n-  }\n-\n-  @Override\n-  public Type list(GroupType parquetList, Type elementType) {\n-    GroupType repeated = parquetList.getType(0).asGroupType();\n-    org.apache.parquet.schema.Type parquetElement = repeated.getType(0);\n-\n-    Preconditions.checkArgument(\n-        !parquetElement.isRepetition(Repetition.REPEATED),\n-        \"Elements cannot have repetition REPEATED: %s\", parquetElement);\n-\n-    Integer elementFieldId = getId(parquetElement);\n-\n-    // keep the list if its element has an id and it was not pruned (i.e. its type is not null)\n-    if (elementFieldId != null && elementType != null) {\n-      addAlias(parquetElement.getName(), elementFieldId);\n-\n-      if (parquetElement.isRepetition(Repetition.OPTIONAL)) {\n-        return Types.ListType.ofOptional(elementFieldId, elementType);\n-      } else {\n-        return Types.ListType.ofRequired(elementFieldId, elementType);\n-      }\n-    }\n-\n-    return null;\n-  }\n-\n-  @Override\n-  public Type map(GroupType map, Type keyType, Type valueType) {\n-    GroupType keyValue = map.getType(0).asGroupType();\n-    org.apache.parquet.schema.Type parquetKey = keyValue.getType(0);\n-    org.apache.parquet.schema.Type parquetValue = keyValue.getType(1);\n-\n-    Integer keyFieldId = getId(parquetKey);\n-    Integer valueFieldId = getId(parquetValue);\n-\n-    // keep the map if its key and values have ids and were not pruned (i.e. their types are not null)\n-    if (keyFieldId != null && valueFieldId != null && keyType != null && valueType != null) {\n-      addAlias(parquetKey.getName(), keyFieldId);\n-      addAlias(parquetValue.getName(), valueFieldId);\n-\n-      // check only values as keys are required by the spec\n-      if (parquetValue.isRepetition(Repetition.OPTIONAL)) {\n-        return Types.MapType.ofOptional(keyFieldId, valueFieldId, keyType, valueType);\n-      } else {\n-        return Types.MapType.ofRequired(keyFieldId, valueFieldId, keyType, valueType);\n-      }\n-    }\n-\n-    return null;\n-  }\n-\n-  private void addAlias(String name, int fieldId) {\n-    aliasToId.put(DOT.join(path(name)), fieldId);\n-  }\n-\n-  private Integer getId(org.apache.parquet.schema.Type type) {\n-    return type.getId() != null ? type.getId().intValue() : null;\n-  }\n-}\n"}}, {"oid": "340b92ad0a2e183205b64ef11264760f85f7dbe3", "url": "https://github.com/apache/iceberg/commit/340b92ad0a2e183205b64ef11264760f85f7dbe3", "message": "Squash logic into MessageTypeToType", "committedDate": "2020-08-14T23:00:49Z", "type": "commit"}, {"oid": "8a88f11d7fbcc5a0768b113b535fafe62bb2a06a", "url": "https://github.com/apache/iceberg/commit/8a88f11d7fbcc5a0768b113b535fafe62bb2a06a", "message": "Minor changes", "committedDate": "2020-08-14T23:07:46Z", "type": "commit"}, {"oid": "a4413d820f43bc89a889ce39bd3e888386d28b30", "url": "https://github.com/apache/iceberg/commit/a4413d820f43bc89a889ce39bd3e888386d28b30", "message": "Handle empty projections", "committedDate": "2020-08-15T00:23:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxMzUxMQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470913511", "bodyText": "This part requires attention. Tests for empty projections would fail otherwise.", "author": "aokolnychyi", "createdAt": "2020-08-15T00:24:13Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java", "diffHunk": "@@ -56,36 +60,38 @@\n \n   @Override\n   public Type message(MessageType message, List<Type> fields) {\n-    return struct(message, fields);\n+    Type struct = struct(message, fields);\n+    return struct != null ? struct : Types.StructType.of(Lists.newArrayList());", "originalCommit": "a4413d820f43bc89a889ce39bd3e888386d28b30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzQwOQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470917409", "bodyText": "Tests for empty projections?", "author": "rdblue", "createdAt": "2020-08-15T00:54:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxMzUxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMjkzMQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470922931", "bodyText": "For example, testEmptyProjection in TestReadProjection.", "author": "aokolnychyi", "createdAt": "2020-08-15T01:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxMzUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "093f69e1a6df124d8b1100d6d08829c360a9ed51", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java b/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\nindex 27f5e6ac5..6aee360fe 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\n\n@@ -67,7 +67,7 @@ class MessageTypeToType extends ParquetTypeVisitor<Type> {\n   @Override\n   public Type struct(GroupType struct, List<Type> fieldTypes) {\n     List<org.apache.parquet.schema.Type> parquetFields = struct.getFields();\n-    List<Types.NestedField> fields = Lists.newArrayList();\n+    List<Types.NestedField> fields = Lists.newArrayListWithExpectedSize(fieldTypes.size());\n \n     for (int i = 0; i < parquetFields.size(); i += 1) {\n       org.apache.parquet.schema.Type field = parquetFields.get(i);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzUwOQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470917509", "bodyText": "I think it would be fine to continue to use withExpectedSize because the size will actually be smaller.", "author": "rdblue", "createdAt": "2020-08-15T00:55:13Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java", "diffHunk": "@@ -56,36 +60,38 @@\n \n   @Override\n   public Type message(MessageType message, List<Type> fields) {\n-    return struct(message, fields);\n+    Type struct = struct(message, fields);\n+    return struct != null ? struct : Types.StructType.of(Lists.newArrayList());\n   }\n \n   @Override\n   public Type struct(GroupType struct, List<Type> fieldTypes) {\n-    if (struct == root) {\n-      nextId = 1; // use the reserved IDs for the root struct\n-    }\n-\n     List<org.apache.parquet.schema.Type> parquetFields = struct.getFields();\n-    List<Types.NestedField> fields = Lists.newArrayListWithExpectedSize(fieldTypes.size());\n+    List<Types.NestedField> fields = Lists.newArrayList();", "originalCommit": "a4413d820f43bc89a889ce39bd3e888386d28b30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzAwMg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470923002", "bodyText": "Agree", "author": "aokolnychyi", "createdAt": "2020-08-15T01:45:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzUwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "093f69e1a6df124d8b1100d6d08829c360a9ed51", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java b/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\nindex 27f5e6ac5..6aee360fe 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/MessageTypeToType.java\n\n@@ -67,7 +67,7 @@ class MessageTypeToType extends ParquetTypeVisitor<Type> {\n   @Override\n   public Type struct(GroupType struct, List<Type> fieldTypes) {\n     List<org.apache.parquet.schema.Type> parquetFields = struct.getFields();\n-    List<Types.NestedField> fields = Lists.newArrayList();\n+    List<Types.NestedField> fields = Lists.newArrayListWithExpectedSize(fieldTypes.size());\n \n     for (int i = 0; i < parquetFields.size(); i += 1) {\n       org.apache.parquet.schema.Type field = parquetFields.get(i);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzg1Mw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470917853", "bodyText": "Do we want to expose nameToIdFunc or do we want to have one that accepts a NameMapping?", "author": "rdblue", "createdAt": "2020-08-15T00:58:34Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java", "diffHunk": "@@ -41,8 +43,29 @@ public static MessageType convert(Schema schema, String name) {\n     return new TypeToMessageType().convert(schema, name);\n   }\n \n+  /**\n+   * Converts a Parquet schema to an Iceberg schema. Fields without IDs are kept and assigned fallback IDs.\n+   *\n+   * @param parquetSchema a Parquet schema\n+   * @return a matching Iceberg schema for the provided Parquet schema\n+   */\n   public static Schema convert(MessageType parquetSchema) {\n-    MessageTypeToType converter = new MessageTypeToType(parquetSchema);\n+    // if the Parquet schema does not contain ids, we assign fallback ids to top-level fields\n+    // all remaining fields will get ids >= 1000 to avoid pruning columns without ids\n+    MessageType parquetSchemaWithIds = hasIds(parquetSchema) ? parquetSchema : addFallbackIds(parquetSchema);\n+    AtomicInteger nextId = new AtomicInteger(1000);\n+    return convert(parquetSchemaWithIds, name -> nextId.getAndIncrement());\n+  }\n+\n+  /**\n+   * Converts a Parquet schema to an Iceberg schema. Fields without IDs are pruned.\n+   *\n+   * @param parquetSchema a Parquet schema\n+   * @param nameToIdFunc a name to field id mapping function\n+   * @return a matching Iceberg schema for the provided Parquet schema\n+   */\n+  public static Schema convert(MessageType parquetSchema, Function<String[], Integer> nameToIdFunc) {", "originalCommit": "a4413d820f43bc89a889ce39bd3e888386d28b30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzAyNg==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470923026", "bodyText": "Removed it from the public API.", "author": "aokolnychyi", "createdAt": "2020-08-15T01:45:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzg1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "093f69e1a6df124d8b1100d6d08829c360a9ed51", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java\nindex ed3539cf4..01dc261f7 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetSchemaUtil.java\n\n@@ -58,13 +58,16 @@ public class ParquetSchemaUtil {\n   }\n \n   /**\n-   * Converts a Parquet schema to an Iceberg schema. Fields without IDs are pruned.\n+   * Converts a Parquet schema to an Iceberg schema and prunes fields without IDs.\n    *\n    * @param parquetSchema a Parquet schema\n-   * @param nameToIdFunc a name to field id mapping function\n    * @return a matching Iceberg schema for the provided Parquet schema\n    */\n-  public static Schema convert(MessageType parquetSchema, Function<String[], Integer> nameToIdFunc) {\n+  public static Schema convertAndPrune(MessageType parquetSchema) {\n+    return convert(parquetSchema, name -> null);\n+  }\n+\n+  private static Schema convert(MessageType parquetSchema, Function<String[], Integer> nameToIdFunc) {\n     MessageTypeToType converter = new MessageTypeToType(nameToIdFunc);\n     return new Schema(\n         ParquetTypeVisitor.visit(parquetSchema, converter).asNestedType().fields(),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxODMzOQ==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470918339", "bodyText": "What about naming this convertAndPrune?", "author": "rdblue", "createdAt": "2020-08-15T01:02:39Z", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java", "diffHunk": "@@ -86,15 +95,23 @@ public static Metrics footerMetrics(ParquetMetadata metadata, MetricsConfig metr\n     Map<Integer, Literal<?>> upperBounds = Maps.newHashMap();\n     Set<Integer> missingStats = Sets.newHashSet();\n \n-    MessageType parquetType = metadata.getFileMetaData().getSchema();\n-    Schema fileSchema = ParquetSchemaUtil.convert(parquetType);\n+    // ignore metrics for fields we failed to determine reliable IDs\n+    MessageType parquetTypeWithIds = getParquetTypeWithIds(metadata, nameMapping);\n+    Schema fileSchema = ParquetSchemaUtil.convert(parquetTypeWithIds, name -> null);", "originalCommit": "a4413d820f43bc89a889ce39bd3e888386d28b30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzA0Nw==", "url": "https://github.com/apache/iceberg/pull/1335#discussion_r470923047", "bodyText": "Updated.", "author": "aokolnychyi", "createdAt": "2020-08-15T01:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxODMzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "093f69e1a6df124d8b1100d6d08829c360a9ed51", "chunk": "diff --git a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\nindex 01321b419..35fd6940a 100644\n--- a/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n+++ b/parquet/src/main/java/org/apache/iceberg/parquet/ParquetUtil.java\n\n@@ -97,7 +97,7 @@ public class ParquetUtil {\n \n     // ignore metrics for fields we failed to determine reliable IDs\n     MessageType parquetTypeWithIds = getParquetTypeWithIds(metadata, nameMapping);\n-    Schema fileSchema = ParquetSchemaUtil.convert(parquetTypeWithIds, name -> null);\n+    Schema fileSchema = ParquetSchemaUtil.convertAndPrune(parquetTypeWithIds);\n \n     List<BlockMetaData> blocks = metadata.getBlocks();\n     for (BlockMetaData block : blocks) {\n"}}, {"oid": "093f69e1a6df124d8b1100d6d08829c360a9ed51", "url": "https://github.com/apache/iceberg/commit/093f69e1a6df124d8b1100d6d08829c360a9ed51", "message": "Minor fixes", "committedDate": "2020-08-15T01:43:42Z", "type": "commit"}, {"oid": "07f684f0ab29706b8ba1a3d52da16413fcf8a12c", "url": "https://github.com/apache/iceberg/commit/07f684f0ab29706b8ba1a3d52da16413fcf8a12c", "message": "Fix checkstyle", "committedDate": "2020-08-15T06:15:43Z", "type": "commit"}]}