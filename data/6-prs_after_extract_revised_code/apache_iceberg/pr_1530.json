{"pr_number": 1530, "pr_title": "Spark: Implement equals and hashCode in SparkTable", "pr_createdAt": "2020-09-30T00:09:33Z", "pr_url": "https://github.com/apache/iceberg/pull/1530", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497733193", "bodyText": "Would it make sense to test that two tables with different properties but the same table identifier are not equal?", "author": "holdenk", "createdAt": "2020-09-30T18:58:54Z", "path": "core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java", "diffHunk": "@@ -525,6 +525,34 @@ public void testVersionHintFileMissingMetadata() throws Exception {\n         () -> TABLES.load(tableLocation));\n   }\n \n+  @Test\n+  public void testTableEquality() throws Exception {", "originalCommit": "6bd2628af7e06ecdb9ac56c8fd563df30ca8df79", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc2OTM4MQ==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497769381", "bodyText": "The main motivation to implement equals and hashCode was to refresh the cache in Spark. Therefore, I did not consider anything except the identifier so that if a table property was modified, we would still invalidate the cache as both entries point to the same table.\nAfter thinking about this more, modifying equals and hashCode in BaseTable may not be the best idea. Instead, we can simply compare icebergTable.toString() in SparkTable and limit this equality on table identifiers only to Spark.", "author": "aokolnychyi", "createdAt": "2020-09-30T20:06:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc2OTk5NA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497769994", "bodyText": "What do you think about this idea, @holdenk @RussellSpitzer @rdblue?", "author": "aokolnychyi", "createdAt": "2020-09-30T20:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc3MTcxMQ==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497771711", "bodyText": "We did a similar thing in #1512.", "author": "aokolnychyi", "createdAt": "2020-09-30T20:11:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc3ODA1OA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497778058", "bodyText": "Sounds like a good idea. I like to avoid implementing the method in places where \"equals\" has a fuzzy definition -- is it the \"same\" table or is it an equivalent instance?\nWe're also relying on Table.toString behavior a bit too much. It is probably time to add Table.name to the API and use that instead.", "author": "rdblue", "createdAt": "2020-09-30T20:23:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc3OTUwOA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497779508", "bodyText": "Sounds reasonable to me", "author": "RussellSpitzer", "createdAt": "2020-09-30T20:26:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzc5MjEzOA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497792138", "bodyText": "sgtm", "author": "holdenk", "createdAt": "2020-09-30T20:50:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgyMzU4NA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497823584", "bodyText": "It may be a good point in time to implement #658. Let me invest into that.", "author": "aokolnychyi", "createdAt": "2020-09-30T21:55:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg5ODkwNg==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r497898906", "bodyText": "I've created #1537.", "author": "aokolnychyi", "createdAt": "2020-10-01T01:02:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODAwNTAwMA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r498005000", "bodyText": "Throwing in my +1 for adding name to the API. But I'd hope that we can still leave a meaningful enough toString method in place.\nWithout it, we just wind up with your typical memory location etc, specifically when / if Table is used in a parameterized test (I just spent half my evening adding parameterized names to all of the tests that didn't have them).\nWhat is everybody's opinion on implementing toString when it's not strictly necessary? Would you say it's a good practice, or is it possibly just extra unused code that needs to be maintained over time? I know this is potentially more of a religious question than a hard and fast rule, but I'd love to hear your input.", "author": "kbendick", "createdAt": "2020-10-01T06:14:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM5MTYwOA==", "url": "https://github.com/apache/iceberg/pull/1530#discussion_r498391608", "bodyText": "I think implementing toString is a good practice. Spark uses it in query plans quite a bit.", "author": "rdblue", "createdAt": "2020-10-01T17:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzczMzE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d0be8b320860a927666ba5307298395c363f71d0", "chunk": "diff --git a/core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java b/core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java\nindex 1cddeefc..30060424 100644\n--- a/core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java\n+++ b/core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java\n\n@@ -526,31 +526,21 @@ public class TestHadoopCatalog extends HadoopTableTestBase {\n   }\n \n   @Test\n-  public void testTableEquality() throws Exception {\n+  public void testTableName() throws Exception {\n     Configuration conf = new Configuration();\n     String warehousePath = temp.newFolder().getAbsolutePath();\n     HadoopCatalog catalog = new HadoopCatalog(conf, warehousePath);\n     TableIdentifier tableIdent = TableIdentifier.of(\"db\", \"ns1\", \"ns2\", \"tbl\");\n     catalog.buildTable(tableIdent, SCHEMA)\n         .withPartitionSpec(SPEC)\n-        .withProperties(null)\n-        .withProperty(\"key1\", \"value1\")\n-        .withProperties(ImmutableMap.of(\"key2\", \"value2\"))\n         .create();\n \n-    Table catalogTable1 = catalog.loadTable(tableIdent);\n-    Table catalogTable2 = catalog.loadTable(tableIdent);\n-\n-    // different instances pointing to the same table must be equivalent\n-    Assert.assertNotSame(\"References must be different\", catalogTable1, catalogTable2);\n-    Assert.assertEquals(\"Tables must be equivalent\", catalogTable1, catalogTable2);\n-\n-    HadoopTables hadoopTables = new HadoopTables(conf);\n-    Table nonCatalogTable = hadoopTables.load(catalogTable1.location());\n+    Table table = catalog.loadTable(tableIdent);\n+    Assert.assertEquals(\"Name must match\", \"hadoop.db.ns1.ns2.tbl\", table.name());\n \n-    // tables loaded through catalog must not be equivalent to tables loaded through the Tables API\n-    Assert.assertNotSame(\"References must be different\", catalogTable1, nonCatalogTable);\n-    Assert.assertNotEquals(\"Tables must not be equivalent\", catalogTable1, nonCatalogTable);\n+    TableIdentifier snapshotsTableIdent = TableIdentifier.of(\"db\", \"ns1\", \"ns2\", \"tbl\", \"snapshots\");\n+    Table snapshotsTable = catalog.loadTable(snapshotsTableIdent);\n+    Assert.assertEquals(\"Name must match\", \"hadoop.db.ns1.ns2.tbl.snapshots\", snapshotsTable.name());\n   }\n \n   private static void addVersionsToTable(Table table) {\n"}}, {"oid": "d0be8b320860a927666ba5307298395c363f71d0", "url": "https://github.com/apache/iceberg/commit/d0be8b320860a927666ba5307298395c363f71d0", "message": "Spark: Implement equals and hashCode in SparkTable", "committedDate": "2020-10-01T21:58:59Z", "type": "commit"}, {"oid": "d0be8b320860a927666ba5307298395c363f71d0", "url": "https://github.com/apache/iceberg/commit/d0be8b320860a927666ba5307298395c363f71d0", "message": "Spark: Implement equals and hashCode in SparkTable", "committedDate": "2020-10-01T21:58:59Z", "type": "forcePushed"}]}