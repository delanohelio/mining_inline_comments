{"pr_number": 989, "pr_title": "ORC: Supported nested identity partition data ", "pr_createdAt": "2020-04-30T07:02:13Z", "pr_url": "https://github.com/apache/iceberg/pull/989", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzI4Ng==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417797286", "bodyText": "I want to rename this to OrcValueReader, but an interface with that name already exists. I can rename the other interface OrcRowReader instead. If folks are OK doing this as part of this RB, let me know.", "author": "rdsr", "createdAt": "2020-04-30T07:03:46Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+\n+\n+public interface OrcValReader<T> {", "originalCommit": "e415147e495c6230dcf7f478cc543652db777852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1MzcxMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421653711", "bodyText": "That works for me.", "author": "rdblue", "createdAt": "2020-05-07T16:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzI4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "cb684b7468710dbcaf22e6c25986ab0f8e5e2026", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java b/orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java\nsimilarity index 69%\nrename from orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java\nrename to orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java\nindex 565901852..36304acda 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java\n\n@@ -19,18 +19,16 @@\n \n package org.apache.iceberg.orc;\n \n-import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n+/**\n+ * Used for implementing ORC row readers.\n+ */\n+public interface OrcRowReader<T> {\n \n-public interface OrcValReader<T> {\n-  default T read(ColumnVector vector, int row) {\n-    int rowIndex = vector.isRepeating ? 0 : row;\n-    if (!vector.noNulls && vector.isNull[rowIndex]) {\n-      return null;\n-    } else {\n-      return nonNullRead(vector, rowIndex);\n-    }\n-  }\n+  /**\n+   * Reads a row.\n+   */\n+  T read(VectorizedRowBatch batch, int row);\n \n-  T nonNullRead(ColumnVector vector, int row);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzUwOQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417797509", "bodyText": "GenericOrcReader can share a lot of the code here.", "author": "rdsr", "createdAt": "2020-04-30T07:04:15Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {", "originalCommit": "e415147e495c6230dcf7f478cc543652db777852", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "96881f559d7fc9e52cba81c20ed4c94be383f335", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 4c8161b5d..4a71f8fcc 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -196,7 +196,9 @@ public class OrcValueReaders {\n       this.constants = constantList.toArray();\n     }\n \n-    protected abstract T createOrReuse();\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n \n     protected abstract void set(T struct, int pos, Object value);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417798193", "bodyText": "My guess would be this is what is tanking the perf. Spark[Avro|Parquet]Reader seem to reuse this object. Doing the same for ORC results in test failures", "author": "rdsr", "createdAt": "2020-04-30T07:05:45Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "originalCommit": "e415147e495c6230dcf7f478cc543652db777852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODU3ODI5MQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r418578291", "bodyText": "I reran the ORC jmh tests and do see any difference.", "author": "rdsr", "createdAt": "2020-05-01T14:57:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTAxNzU3MA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r419017570", "bodyText": "Do or do not?", "author": "rdblue", "createdAt": "2020-05-02T22:47:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTAyMjU1MA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r419022550", "bodyText": "do not see any difference :)", "author": "rdsr", "createdAt": "2020-05-02T23:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MjgyMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421672821", "bodyText": "The Spark/Parquet reader doesn't currently reuse containers.", "author": "rdblue", "createdAt": "2020-05-07T17:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI5ODcxNA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428298714", "bodyText": "@rdblue . Not sure I follow  this..\n\nThe Spark/Parquet reader doesn't currently reuse containers.\n\nI did the JMH testing for ORC before and after my patch", "author": "rdsr", "createdAt": "2020-05-20T20:49:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "96881f559d7fc9e52cba81c20ed4c94be383f335", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\nindex 26b4283ea..a4795a07f 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n\n@@ -121,19 +121,26 @@ class SparkOrcValueReaders {\n \n   static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n     private final int numFields;\n-    private final InternalRow internalRow;\n+    private InternalRow internalRow;\n \n     protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n       super(readers, struct, idToConstant);\n       this.numFields = readers.size();\n-      internalRow = createOrReuse();\n     }\n \n     @Override\n-    protected InternalRow createOrReuse() {\n+    protected InternalRow create() {\n       return new GenericInternalRow(numFields);\n     }\n \n+    @Override\n+    protected InternalRow reuseOrCreate() {\n+      if (internalRow == null) {\n+        internalRow = new GenericInternalRow(numFields);\n+      }\n+      return internalRow;\n+    }\n+\n     @Override\n     protected void set(InternalRow struct, int pos, Object value) {\n       if (value != null) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5ODEzOQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r418198139", "bodyText": "how about using UnsupportedOperationException instead?", "author": "abti", "createdAt": "2020-04-30T18:12:24Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);\n+\n+      case UNION:\n+        // We don't have an answer for union types.\n+        throw new IllegalArgumentException(\"Can't handle \" + schema);", "originalCommit": "e415147e495c6230dcf7f478cc543652db777852", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\nindex 477290974..44ce80346 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n\n@@ -35,27 +35,26 @@ public abstract class OrcSchemaWithTypeVisitor<T> {\n   public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n     switch (schema.getCategory()) {\n       case STRUCT:\n-        return visitRecord(iType.asStructType(), schema, visitor);\n+        return visitRecord(iType != null ? iType.asStructType() : null, schema, visitor);\n \n       case UNION:\n-        // We don't have an answer for union types.\n-        throw new IllegalArgumentException(\"Can't handle \" + schema);\n+        throw new UnsupportedOperationException(\"Cannot handle \" + schema);\n \n       case LIST:\n-        Types.ListType list = iType.asListType();\n-        return visitor.array(\n+        Types.ListType list = iType != null ? iType.asListType() : null;\n+        return visitor.list(\n             list, schema,\n             visit(list.elementType(), schema.getChildren().get(0), visitor));\n \n       case MAP:\n-        Types.MapType map = iType.asMapType();\n+        Types.MapType map = iType != null ? iType.asMapType() : null;\n         return visitor.map(\n             map, schema,\n-            visit(map.keyType(), schema.getChildren().get(0), visitor),\n-            visit(map.valueType(), schema.getChildren().get(1), visitor));\n+            visit(map != null ? map.keyType() : null, schema.getChildren().get(0), visitor),\n+            visit(map != null ? map.valueType() : null, schema.getChildren().get(1), visitor));\n \n       default:\n-        return visitor.primitive(iType.asPrimitiveType(), schema);\n+        return visitor.primitive(iType != null ? iType.asPrimitiveType() : null, schema);\n     }\n   }\n \n"}}, {"oid": "96881f559d7fc9e52cba81c20ed4c94be383f335", "url": "https://github.com/apache/iceberg/commit/96881f559d7fc9e52cba81c20ed4c94be383f335", "message": "Orc nested partition support", "committedDate": "2020-05-01T04:47:39Z", "type": "forcePushed"}, {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "url": "https://github.com/apache/iceberg/commit/8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "message": "Removed legacy code from Spark", "committedDate": "2020-05-01T15:09:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NjcxOA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r420996718", "bodyText": "I just noticed the logic here and it's a correctness bug. ORC should not assign column IDs when one is missing. Instead, it should ignore the field.", "author": "rdblue", "createdAt": "2020-05-06T18:18:00Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -214,6 +214,7 @@ public static Schema convert(TypeDescription orcSchema) {\n         \"Error in ORC file, children fields and names do not match.\");\n \n     List<Types.NestedField> icebergFields = Lists.newArrayListWithExpectedSize(children.size());\n+    // TODO how we get field ids from ORC schema", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI5OTI3OQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428299279", "bodyText": "Should we use another PR to fix this?", "author": "rdsr", "createdAt": "2020-05-20T20:50:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NjcxOA=="}], "type": "inlineReview", "revised_code": {"commit": "cb684b7468710dbcaf22e6c25986ab0f8e5e2026", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java b/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\nindex 19727a1bf..5449f0b64 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\n\n@@ -214,7 +214,6 @@ public final class ORCSchemaUtil {\n         \"Error in ORC file, children fields and names do not match.\");\n \n     List<Types.NestedField> icebergFields = Lists.newArrayListWithExpectedSize(children.size());\n-    // TODO how we get field ids from ORC schema\n     AtomicInteger lastColumnId = new AtomicInteger(getMaxIcebergId(orcSchema));\n     for (int i = 0; i < children.size(); i++) {\n       icebergFields.add(convertOrcToIceberg(children.get(i), childrenNames.get(i),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NzY3Nw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r420997677", "bodyText": "I don't see this used other than in the conversion logic to assign new IDs. Because that assignment is actually a correctness bug, we don't need this method at all. Also, since it isn't used anywhere else in this PR there is no need to make it package-private instead of private.", "author": "rdblue", "createdAt": "2020-05-06T18:19:35Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -496,7 +503,7 @@ private static boolean isRequired(TypeDescription orcType) {\n     }\n   }\n \n-  private static int getMaxIcebergId(TypeDescription originalOrcSchema) {\n+  static int getMaxIcebergId(TypeDescription originalOrcSchema) {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java b/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\nindex 19727a1bf..35e82c1b0 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java\n\n@@ -503,7 +503,7 @@ public final class ORCSchemaUtil {\n     }\n   }\n \n-  static int getMaxIcebergId(TypeDescription originalOrcSchema) {\n+  private static int getMaxIcebergId(TypeDescription originalOrcSchema) {\n     int maxId = icebergID(originalOrcSchema).orElse(0);\n     final List<TypeDescription> children = Optional.ofNullable(originalOrcSchema.getChildren())\n         .orElse(Collections.emptyList());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1MDUxMA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421650510", "bodyText": "In other visitors, we try to name the method after the type in the schema that is being visited. That's why Avro uses array but Iceberg uses list. Since the category for ORC is LIST, should the visitor method be named list?", "author": "rdblue", "createdAt": "2020-05-07T16:52:29Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);\n+\n+      case UNION:\n+        // We don't have an answer for union types.\n+        throw new IllegalArgumentException(\"Can't handle \" + schema);\n+\n+      case LIST:\n+        Types.ListType list = iType.asListType();\n+        return visitor.array(", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\nindex 477290974..44ce80346 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n\n@@ -35,27 +35,26 @@ public abstract class OrcSchemaWithTypeVisitor<T> {\n   public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n     switch (schema.getCategory()) {\n       case STRUCT:\n-        return visitRecord(iType.asStructType(), schema, visitor);\n+        return visitRecord(iType != null ? iType.asStructType() : null, schema, visitor);\n \n       case UNION:\n-        // We don't have an answer for union types.\n-        throw new IllegalArgumentException(\"Can't handle \" + schema);\n+        throw new UnsupportedOperationException(\"Cannot handle \" + schema);\n \n       case LIST:\n-        Types.ListType list = iType.asListType();\n-        return visitor.array(\n+        Types.ListType list = iType != null ? iType.asListType() : null;\n+        return visitor.list(\n             list, schema,\n             visit(list.elementType(), schema.getChildren().get(0), visitor));\n \n       case MAP:\n-        Types.MapType map = iType.asMapType();\n+        Types.MapType map = iType != null ? iType.asMapType() : null;\n         return visitor.map(\n             map, schema,\n-            visit(map.keyType(), schema.getChildren().get(0), visitor),\n-            visit(map.valueType(), schema.getChildren().get(1), visitor));\n+            visit(map != null ? map.keyType() : null, schema.getChildren().get(0), visitor),\n+            visit(map != null ? map.valueType() : null, schema.getChildren().get(1), visitor));\n \n       default:\n-        return visitor.primitive(iType.asPrimitiveType(), schema);\n+        return visitor.primitive(iType != null ? iType.asPrimitiveType() : null, schema);\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NDc4MA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421654780", "bodyText": "Do we need a short reader? Iceberg doesn't support short values in a table schema, so we shouldn't be expecting to ever return a short value.", "author": "rdblue", "createdAt": "2020-05-07T16:59:25Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODMwMjQxMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428302411", "bodyText": "Ohk. I can change this to ints", "author": "rdsr", "createdAt": "2020-05-20T20:56:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NDc4MA=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NTM1OA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421655358", "bodyText": "Similar to short, do we need this reader?", "author": "rdblue", "createdAt": "2020-05-07T17:00:20Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1Njc4NA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421656784", "bodyText": "Where is this used? It doesn't look like using 0-length arrays for positions and constants is correct.", "author": "rdblue", "createdAt": "2020-05-07T17:02:36Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MzI1MQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421663251", "bodyText": "Nevermind, I see what's happening.", "author": "rdblue", "createdAt": "2020-05-07T17:13:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1Njc4NA=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1ODEwMw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421658103", "bodyText": "Why not pass the possibly reused object in here?", "author": "rdblue", "createdAt": "2020-05-07T17:04:50Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421661929", "bodyText": "Instead of having an interface that uses VectorizedRowBatch, why not just have the top-level reader create a StructColumnVector and pass the batch's columns using that?\nYou can even make a reusable StructColumnVector to avoid needing to create a new one for every batch if you want:\n  class ReusableStructColumnVector extends StructColumnVector {\n    public ReusableStructColumnVector(int len, ColumnVector... fields) {\n      super(len, fields);\n    }\n\n    public ReusableStructColumnVector replaceVectors(ColumnVector[] fields) {\n      this.fields = fields;\n      return this;\n    }\n  }\nThen we'd only need one OrcValueReader interface.", "author": "rdblue", "createdAt": "2020-05-07T17:11:25Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTkyMTA2OQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421921069", "bodyText": "I think I did what you are suggesting before, but ran into issues. Let me try again to get the actual erorr.", "author": "rdsr", "createdAt": "2020-05-08T03:48:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjcwMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082701", "bodyText": "It worked this time.", "author": "rdsr", "createdAt": "2020-05-22T07:18:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MjY2MA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421662660", "bodyText": "These factory methods can declare the type they return, like OrcValueReader<byte[]>.", "author": "rdblue", "createdAt": "2020-05-07T17:12:44Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421665455", "bodyText": "You might consider a different approach. This currently mirrors what happens in Avro, where the constants are set after reading a record. That is done because Avro can't skip fields easily -- it needs to read through a value even if the value won't be used.\nBut columnar formats can easily skip. That's why in Parquet, we replace the column reader with a constant reader. So the struct reader behaves exactly like normal and reads a value from every child reader. But some of those children might ignore what's in the data file and return a constant. That should be more efficient because you're not materializing columns you don't need to.", "author": "rdblue", "createdAt": "2020-05-07T17:17:32Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {\n+      return readInternal(reuseOrCreate(), batch.cols, row);\n+    }\n+\n+    private T readInternal(T struct, ColumnVector[] columnVectors, int row) {\n+      for (int c = 0; c < readers.length; ++c) {\n+        set(struct, c, reader(c).read(columnVectors[c], row));", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjYwNg==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082606", "bodyText": "Is is ok if I tackle this in followup?", "author": "rdsr", "createdAt": "2020-05-22T07:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNzgyOA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429327828", "bodyText": "Yeah, that sounds good.", "author": "rdblue", "createdAt": "2020-05-22T15:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\nindex 90a857073..5b9c0c781 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java\n\n@@ -29,47 +29,38 @@ import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n-import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n \n public class OrcValueReaders {\n   private OrcValueReaders() {\n   }\n \n-  public static OrcValReader<?> booleans() {\n+  public static OrcValReader<Boolean> booleans() {\n     return BooleanReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> shorts() {\n-    return ShortReader.INSTANCE;\n-  }\n-\n-  public static OrcValReader<?> ints() {\n+  public static OrcValReader<Integer> ints() {\n     return IntegerReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> longs() {\n+  public static OrcValReader<Long> longs() {\n     return LongReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> floats() {\n+  public static OrcValReader<Float> floats() {\n     return FloatReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> doubles() {\n+  public static OrcValReader<Double> doubles() {\n     return DoubleReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> bytes() {\n+  public static OrcValReader<byte[]> bytes() {\n     return BytesReader.INSTANCE;\n   }\n \n-  public static OrcValReader<?> byteReader() {\n-    return ByteReader.INSTANCE;\n-  }\n-\n   private static class BooleanReader implements OrcValReader<Boolean> {\n-    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+    static final BooleanReader INSTANCE = new BooleanReader();\n \n     private BooleanReader() {\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTk0Nw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421665947", "bodyText": "Minor: we prefer to use this.reader = when assigning to instance fields so it's clear that it is setting a field.", "author": "rdblue", "createdAt": "2020-05-07T17:18:21Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "diffHunk": "@@ -53,425 +40,83 @@\n  * It minimizes allocations by reusing most of the objects in the implementation.\n  */\n public class SparkOrcReader implements OrcValueReader<InternalRow> {\n-  private static final int INITIAL_SIZE = 128 * 1024;\n-  private final List<TypeDescription> columns;\n-  private final Converter[] converters;\n-  private final UnsafeRowWriter rowWriter;\n+  private final SparkOrcValueReaders.StructReader reader;\n \n-  public SparkOrcReader(TypeDescription readOrcSchema) {\n-    columns = readOrcSchema.getChildren();\n-    converters = buildConverters();\n-    rowWriter = new UnsafeRowWriter(columns.size(), INITIAL_SIZE);\n+  public SparkOrcReader(org.apache.iceberg.Schema expectedSchema, TypeDescription readSchema) {\n+    this(expectedSchema, readSchema, ImmutableMap.of());\n   }\n \n-  private Converter[] buildConverters() {\n-    final Converter[] newConverters = new Converter[columns.size()];\n-    for (int c = 0; c < newConverters.length; ++c) {\n-      newConverters[c] = buildConverter(columns.get(c));\n-    }\n-    return newConverters;\n+  @SuppressWarnings(\"unchecked\")\n+  public SparkOrcReader(\n+      org.apache.iceberg.Schema expectedSchema, TypeDescription readOrcSchema, Map<Integer, ?> idToConstant) {\n+    reader = (SparkOrcValueReaders.StructReader) OrcSchemaWithTypeVisitor.visit(", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\nindex 6241eec49..8b6d1dcb8 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\n\n@@ -29,12 +29,13 @@ import org.apache.iceberg.orc.OrcValueReaders;\n import org.apache.iceberg.types.Type;\n import org.apache.iceberg.types.Types;\n import org.apache.orc.TypeDescription;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n import org.apache.spark.sql.catalyst.InternalRow;\n import org.apache.spark.sql.types.Decimal;\n \n /**\n- * Converts the OrcInterator, which returns ORC's VectorizedRowBatch to a\n+ * Converts the OrcIterator, which returns ORC's VectorizedRowBatch to a\n  * set of Spark's UnsafeRows.\n  *\n  * It minimizes allocations by reusing most of the objects in the implementation.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NjQ2Mg==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421666462", "bodyText": "This is where you could wrap the columns from VectorizedRowBatch in a StructColumnVector.", "author": "rdblue", "createdAt": "2020-05-07T17:19:12Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "diffHunk": "@@ -53,425 +40,83 @@\n  * It minimizes allocations by reusing most of the objects in the implementation.\n  */\n public class SparkOrcReader implements OrcValueReader<InternalRow> {\n-  private static final int INITIAL_SIZE = 128 * 1024;\n-  private final List<TypeDescription> columns;\n-  private final Converter[] converters;\n-  private final UnsafeRowWriter rowWriter;\n+  private final SparkOrcValueReaders.StructReader reader;\n \n-  public SparkOrcReader(TypeDescription readOrcSchema) {\n-    columns = readOrcSchema.getChildren();\n-    converters = buildConverters();\n-    rowWriter = new UnsafeRowWriter(columns.size(), INITIAL_SIZE);\n+  public SparkOrcReader(org.apache.iceberg.Schema expectedSchema, TypeDescription readSchema) {\n+    this(expectedSchema, readSchema, ImmutableMap.of());\n   }\n \n-  private Converter[] buildConverters() {\n-    final Converter[] newConverters = new Converter[columns.size()];\n-    for (int c = 0; c < newConverters.length; ++c) {\n-      newConverters[c] = buildConverter(columns.get(c));\n-    }\n-    return newConverters;\n+  @SuppressWarnings(\"unchecked\")\n+  public SparkOrcReader(\n+      org.apache.iceberg.Schema expectedSchema, TypeDescription readOrcSchema, Map<Integer, ?> idToConstant) {\n+    reader = (SparkOrcValueReaders.StructReader) OrcSchemaWithTypeVisitor.visit(\n+        expectedSchema, readOrcSchema, new ReadBuilder(idToConstant));\n   }\n \n   @Override\n   public InternalRow read(VectorizedRowBatch batch, int row) {\n-    rowWriter.reset();\n-    rowWriter.zeroOutNullBytes();\n-    for (int c = 0; c < batch.cols.length; ++c) {\n-      converters[c].convert(rowWriter, c, batch.cols[c], row);\n-    }\n-    return rowWriter.getRow();\n+    return reader.read(batch, row);", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjQ2NQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082465", "bodyText": "It worked!", "author": "rdsr", "createdAt": "2020-05-22T07:17:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NjQ2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\nindex 6241eec49..8b6d1dcb8 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java\n\n@@ -29,12 +29,13 @@ import org.apache.iceberg.orc.OrcValueReaders;\n import org.apache.iceberg.types.Type;\n import org.apache.iceberg.types.Types;\n import org.apache.orc.TypeDescription;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n import org.apache.spark.sql.catalyst.InternalRow;\n import org.apache.spark.sql.types.Decimal;\n \n /**\n- * Converts the OrcInterator, which returns ORC's VectorizedRowBatch to a\n+ * Converts the OrcIterator, which returns ORC's VectorizedRowBatch to a\n  * set of Spark's UnsafeRows.\n  *\n  * It minimizes allocations by reusing most of the objects in the implementation.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2ODgyMg==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421668822", "bodyText": "Consider renaming this to something that makes it more obvious that it is returning UTF8String. Avro has a factory method named utf8s to distinguish between strings and its custom Utf8 class.", "author": "rdblue", "createdAt": "2020-05-07T17:23:16Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\nindex a4795a07f..3a25a2fb1 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n\n@@ -47,7 +47,7 @@ class SparkOrcValueReaders {\n   private SparkOrcValueReaders() {\n   }\n \n-  static OrcValReader<UTF8String> strings() {\n+  static OrcValReader<UTF8String> utf8String() {\n     return StringReader.INSTANCE;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MTk4OQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421671989", "bodyText": "Container reuse requires passing objects into the read method for correctness.\nThe contract for container reuse is that the caller will consume the record before asking for the next one. For example, Spark might copy the entire row into an UnsafeRow.\nThe problem with keeping a reused list or struct in the reader itself is that the reader might be called more than once to produce a value before the row is consumed. For example, a list of structs locations list<struct<lat:double,long:double>> will call the inner reader for each location struct in the list before returning the record. If the reader reuses the struct, then the same struct will be added to the list multiple times and all of them will have the last values set in the reused struct.", "author": "rdblue", "createdAt": "2020-05-07T17:28:30Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\nindex a4795a07f..3a25a2fb1 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n\n@@ -47,7 +47,7 @@ class SparkOrcValueReaders {\n   private SparkOrcValueReaders() {\n   }\n \n-  static OrcValReader<UTF8String> strings() {\n+  static OrcValReader<UTF8String> utf8String() {\n     return StringReader.INSTANCE;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421673301", "bodyText": "As I noted above, the reader can't keep track of a row like this.", "author": "rdblue", "createdAt": "2020-05-07T17:30:32Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private InternalRow internalRow;", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MTc3Nw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429051777", "bodyText": "In this case the reuse is only being done for the top level row and not for any internal row. Do u still see this as an issue?", "author": "rdsr", "createdAt": "2020-05-22T05:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjM5OA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082398", "bodyText": "I ended up removing this for now.", "author": "rdsr", "createdAt": "2020-05-22T07:17:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\nindex a4795a07f..3a25a2fb1 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java\n\n@@ -47,7 +47,7 @@ class SparkOrcValueReaders {\n   private SparkOrcValueReaders() {\n   }\n \n-  static OrcValReader<UTF8String> strings() {\n+  static OrcValReader<UTF8String> utf8String() {\n     return StringReader.INSTANCE;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NDU3MQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421674571", "bodyText": "Once this and #1004 are in, we can remove the Spark projection!", "author": "rdblue", "createdAt": "2020-05-07T17:32:45Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -109,23 +104,8 @@\n     Iterator<InternalRow> iter;\n \n     if (hasJoinedPartitionColumns) {\n-      if (SUPPORTS_CONSTANTS.contains(file.format())) {\n-        iterSchema = requiredSchema;\n-        iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));\n-      } else {\n-        // schema used to read data files\n-        Schema readSchema = TypeUtil.selectNot(requiredSchema, idColumns);\n-        Schema partitionSchema = TypeUtil.select(requiredSchema, idColumns);\n-        PartitionRowConverter convertToRow = new PartitionRowConverter(partitionSchema, spec);\n-        JoinedRow joined = new JoinedRow();\n-\n-        InternalRow partition = convertToRow.apply(file.partition());\n-        joined.withRight(partition);\n-\n-        // create joined rows and project from the joined schema to the final schema\n-        iterSchema = TypeUtil.join(readSchema, partitionSchema);\n-        iter = Iterators.transform(open(task, readSchema, ImmutableMap.of()), joined::withLeft);\n-      }\n+      iterSchema = requiredSchema;\n+      iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyODgyMQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429328821", "bodyText": "#1004 is in. That might be why this has conflicts.", "author": "rdblue", "createdAt": "2020-05-22T15:56:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NDU3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "efd91f65f00edff4edb0f8037b8465669f24eb08", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java b/spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java\nindex 424b86048..05802ff2c 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java\n\n@@ -83,46 +88,45 @@ class RowDataReader extends BaseDataReader<InternalRow> {\n   }\n \n   @Override\n-  Iterator<InternalRow> open(FileScanTask task) {\n+  CloseableIterator<InternalRow> open(FileScanTask task) {\n     DataFile file = task.file();\n \n     // update the current file for Spark's filename() function\n     InputFileBlockHolder.set(file.path().toString(), task.start(), task.length());\n \n     // schema or rows returned by readers\n-    Schema finalSchema = expectedSchema;\n     PartitionSpec spec = task.spec();\n     Set<Integer> idColumns = spec.identitySourceIds();\n+    Schema partitionSchema = TypeUtil.select(expectedSchema, idColumns);\n+    boolean projectsIdentityPartitionColumns = !partitionSchema.columns().isEmpty();\n \n-    // schema needed for the projection and filtering\n-    StructType sparkType = SparkSchemaUtil.convert(finalSchema);\n-    Schema requiredSchema = SparkSchemaUtil.prune(tableSchema, sparkType, task.residual(), caseSensitive);\n-    boolean hasJoinedPartitionColumns = !idColumns.isEmpty();\n-    boolean hasExtraFilterColumns = requiredSchema.columns().size() != finalSchema.columns().size();\n-\n-    Schema iterSchema;\n-    Iterator<InternalRow> iter;\n-\n-    if (hasJoinedPartitionColumns) {\n-      iterSchema = requiredSchema;\n-      iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));\n-    } else if (hasExtraFilterColumns) {\n-      // add projection to the final schema\n-      iterSchema = requiredSchema;\n-      iter = open(task, requiredSchema, ImmutableMap.of());\n-    } else {\n-      // return the base iterator\n-      iterSchema = finalSchema;\n-      iter = open(task, finalSchema, ImmutableMap.of());\n+    if (projectsIdentityPartitionColumns) {\n+      if (SUPPORTS_CONSTANTS.contains(file.format())) {\n+        return open(task, expectedSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant))\n+            .iterator();\n+      }\n+\n+      // schema used to read data files\n+      Schema readSchema = TypeUtil.selectNot(expectedSchema, idColumns);\n+      PartitionRowConverter convertToRow = new PartitionRowConverter(partitionSchema, spec);\n+      JoinedRow joined = new JoinedRow();\n+\n+      // create joined rows and project from the joined schema to the final schema\n+      Schema joinedSchema = TypeUtil.join(readSchema, partitionSchema);\n+      InternalRow partition = convertToRow.apply(file.partition());\n+      joined.withRight(partition);\n+\n+      CloseableIterable<InternalRow> transformedIterable = CloseableIterable.transform(\n+          CloseableIterable.transform(open(task, readSchema, ImmutableMap.of()), joined::withLeft),\n+          APPLY_PROJECTION.bind(projection(expectedSchema, joinedSchema))::invoke);\n+      return transformedIterable.iterator();\n     }\n \n-    // TODO: remove the projection by reporting the iterator's schema back to Spark\n-    return Iterators.transform(\n-        iter,\n-        APPLY_PROJECTION.bind(projection(finalSchema, iterSchema))::invoke);\n+    // return the base iterator\n+    return open(task, expectedSchema, ImmutableMap.of()).iterator();\n   }\n \n-  private Iterator<InternalRow> open(FileScanTask task, Schema readSchema, Map<Integer, ?> idToConstant) {\n+  private CloseableIterable<InternalRow> open(FileScanTask task, Schema readSchema, Map<Integer, ?> idToConstant) {\n     CloseableIterable<InternalRow> iter;\n     if (task.isDataTask()) {\n       iter = newDataIterable(task.asDataTask(), readSchema);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NjUwMA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421676500", "bodyText": "I think this should test with and without container reuse if that is implemented in this PR. Probably just make this test parameterized.", "author": "rdblue", "createdAt": "2020-05-07T17:36:04Z", "path": "spark/src/test/java/org/apache/iceberg/spark/data/TestSparkOrcReader.java", "diffHunk": "@@ -71,7 +71,7 @@ private void writeAndValidateRecords(Schema schema, Iterable<InternalRow> expect\n \n     try (CloseableIterable<InternalRow> reader = ORC.read(Files.localInput(testFile))\n         .project(schema)\n-        .createReaderFunc(SparkOrcReader::new)", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA5MDU2MQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429090561", "bodyText": "For now I've removed the reuse code. We can tackle than in followup", "author": "rdsr", "createdAt": "2020-05-22T07:37:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NjUwMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421384789", "bodyText": "For completeness sake, also set ICEBERG_REQUIRED_ATTRIBUTE?", "author": "shardulm94", "createdAt": "2020-05-07T09:56:52Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -308,7 +309,7 @@ private static TypeDescription buildOrcProjection(Integer fieldId, Type type, bo\n           orcType = convert(fieldId, type, false);\n         }\n     }\n-\n+    orcType.setAttribute(ICEBERG_ID_ATTRIBUTE, fieldId.toString());", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzUyOA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429083528", "bodyText": "Adding this is actually causing failures\norg.apache.iceberg.data.orc.TestGenericReadProjection > testRenamedAddedField FAILED\n    java.lang.IllegalArgumentException: No conversion of type LONG to self needed\n        at org.apache.orc.impl.ConvertTreeReaderFactory.createAnyIntegerConvertTreeReader(ConvertTreeReaderFactory.java:1671)\n        at org.apache.orc.impl.ConvertTreeReaderFactory.createConvertTreeReader(ConvertTreeReaderFactory.java:2124)\n        at org.apache.orc.impl.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2331)\n        at org.apache.orc.impl.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:1961)\n        at org.apache.orc.impl.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2371)\n        at org.apache.orc.impl.RecordReaderImpl.<init>(RecordReaderImpl.java:227)\n        at org.apache.orc.impl.ReaderImpl.rows(ReaderImpl.java:752)\n        at org.apache.iceberg.orc.OrcIterable.newOrcIterator(OrcIterable.java:80)\n        at org.apache.iceberg.orc.OrcIterable.iterator(OrcIterable.java:65)\n        at com.google.common.collect.Iterables.getOnlyElement(Iterables.java:254)\n        at org.apache.iceberg.data.orc.TestGenericReadProjection.writeAndRead(TestGenericReadProjection.java:53)\n\nAnd I vaguely remember we fixed a similar bug before in ORC", "author": "rdsr", "createdAt": "2020-05-22T07:20:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNjAzMw==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429326033", "bodyText": "It would be great to know what's going on here. Since this is just a projection schema and the reader is built with the Iceberg schema (that has required/optional), I don't think it is really a blocker. But setting a property here shouldn't cause ORC to fail, right?", "author": "rdblue", "createdAt": "2020-05-22T15:50:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzOTY1Ng==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429339656", "bodyText": "I'll file the necessary followups.", "author": "rdsr", "createdAt": "2020-05-22T16:23:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQzMjg4MA==", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428432880", "bodyText": "iType can be null if a corresponding field is not found in the Iceberg schema for the current field in the ORC schema. So we should put a null check here and in other places where Type.asXXX() is being done", "author": "shardulm94", "createdAt": "2020-05-21T04:02:21Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);", "originalCommit": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "chunk": "diff --git a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\nindex 477290974..44ce80346 100644\n--- a/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n+++ b/orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java\n\n@@ -35,27 +35,26 @@ public abstract class OrcSchemaWithTypeVisitor<T> {\n   public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n     switch (schema.getCategory()) {\n       case STRUCT:\n-        return visitRecord(iType.asStructType(), schema, visitor);\n+        return visitRecord(iType != null ? iType.asStructType() : null, schema, visitor);\n \n       case UNION:\n-        // We don't have an answer for union types.\n-        throw new IllegalArgumentException(\"Can't handle \" + schema);\n+        throw new UnsupportedOperationException(\"Cannot handle \" + schema);\n \n       case LIST:\n-        Types.ListType list = iType.asListType();\n-        return visitor.array(\n+        Types.ListType list = iType != null ? iType.asListType() : null;\n+        return visitor.list(\n             list, schema,\n             visit(list.elementType(), schema.getChildren().get(0), visitor));\n \n       case MAP:\n-        Types.MapType map = iType.asMapType();\n+        Types.MapType map = iType != null ? iType.asMapType() : null;\n         return visitor.map(\n             map, schema,\n-            visit(map.keyType(), schema.getChildren().get(0), visitor),\n-            visit(map.valueType(), schema.getChildren().get(1), visitor));\n+            visit(map != null ? map.keyType() : null, schema.getChildren().get(0), visitor),\n+            visit(map != null ? map.valueType() : null, schema.getChildren().get(1), visitor));\n \n       default:\n-        return visitor.primitive(iType.asPrimitiveType(), schema);\n+        return visitor.primitive(iType != null ? iType.asPrimitiveType() : null, schema);\n     }\n   }\n \n"}}, {"oid": "efd91f65f00edff4edb0f8037b8465669f24eb08", "url": "https://github.com/apache/iceberg/commit/efd91f65f00edff4edb0f8037b8465669f24eb08", "message": "Orc nested partition support", "committedDate": "2020-05-22T16:21:18Z", "type": "commit"}, {"oid": "66edd0350cf0d6b13cfb92d54cf4de342955aec5", "url": "https://github.com/apache/iceberg/commit/66edd0350cf0d6b13cfb92d54cf4de342955aec5", "message": "Removed legacy code from Spark", "committedDate": "2020-05-22T16:21:18Z", "type": "commit"}, {"oid": "4e7df0f3b9ebb9261bc161095d99ece434064ced", "url": "https://github.com/apache/iceberg/commit/4e7df0f3b9ebb9261bc161095d99ece434064ced", "message": "address comments", "committedDate": "2020-05-22T16:21:18Z", "type": "commit"}, {"oid": "cb684b7468710dbcaf22e6c25986ab0f8e5e2026", "url": "https://github.com/apache/iceberg/commit/cb684b7468710dbcaf22e6c25986ab0f8e5e2026", "message": "Rename OrcValReader to OrcValueReader", "committedDate": "2020-05-22T16:21:18Z", "type": "commit"}, {"oid": "b973d4b5e1a08ca6a9feed36cc6402eee71a30f5", "url": "https://github.com/apache/iceberg/commit/b973d4b5e1a08ca6a9feed36cc6402eee71a30f5", "message": "Resolve conflicts", "committedDate": "2020-05-22T16:21:18Z", "type": "commit"}, {"oid": "b973d4b5e1a08ca6a9feed36cc6402eee71a30f5", "url": "https://github.com/apache/iceberg/commit/b973d4b5e1a08ca6a9feed36cc6402eee71a30f5", "message": "Resolve conflicts", "committedDate": "2020-05-22T16:21:18Z", "type": "forcePushed"}]}