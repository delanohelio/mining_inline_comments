{"pr_number": 1228, "pr_title": "Fix Handling of SparkPartitions with Whitepsace in Location", "pr_createdAt": "2020-07-22T14:25:35Z", "pr_url": "https://github.com/apache/iceberg/pull/1228", "timeline": [{"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d", "url": "https://github.com/apache/iceberg/commit/6401f6e342f8bc4eb2571f807a18305206bc032d", "message": "Fix Handling of SparkPartitions with Whitepsace in Location\n\nPreviously the listPartition method would use a string representation\nof the Partition's URI when creating the Hadoop Path. This constructor would\nhandle the string as the literal input for the path and ignore any encoded\ncharacters. This casues an issue if the directory or filename has whitespace\nor some other special character being reported as it's encoded version\n resulting in FNF exceptions. By switching to passing a URI as\nthe SparkPartition's location uri, the escaped characters are correctly handled\nby the Hadoop Path class..", "committedDate": "2020-07-21T21:41:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458916359", "bodyText": "Looks like the main problem is that new Path(locationUri.get()) is not the same as new Path(locationUri.get().toString())?", "author": "rdblue", "createdAt": "2020-07-22T16:20:28Z", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "originalCommit": "6401f6e342f8bc4eb2571f807a18305206bc032d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxODg3MA==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458918870", "bodyText": "Yes, Like I wrote on the issue. The constructor of Path(string) assumes the string is decoded. The constructor of Path(Uri) has a URI so it knows it's encoded. That's why we can also fix this by reconverting back to a URI at the last moment (basically re asserting the encoding)", "author": "RussellSpitzer", "createdAt": "2020-07-22T16:23:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxOTcxNA==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458919714", "bodyText": "scala> import java.net.URI\nimport java.net.URI\n\nscala> import org.apache.hadoop.fs.Path\nimport org.apache.hadoop.fs.Path\n\nscala> val uri = new URI(\"file:///has%20spaces\")\nuri: java.net.URI = file:///has%20spaces\n\nscala> new Path(uri).toString\nres4: String = file:/has spaces\n\nscala> new Path(uri.toString).toString\nres5: String = file:/has%20spaces", "author": "RussellSpitzer", "createdAt": "2020-07-22T16:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyODU0Mw==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458928543", "bodyText": "Here what Spark does:\n  /**\n   * Convert URI to String.\n   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n   * to decode the uri\n   * @param uri the URI of the path\n   * @return the String of the path\n   */\n  def URIToString(uri: URI): String = {\n    new Path(uri).toString\n  }\n\n  /**\n   * Convert String to URI.\n   * Since new URI(string) does not encode string, e.g. change '%' to '%25'.\n   * Here we create a hadoop Path with the given String, and rely on Path.toUri\n   * to encode the string\n   * @param str the String of the path\n   * @return the URI of the path\n   */\n  def stringToURI(str: String): URI = {\n    new Path(str).toUri\n  }", "author": "aokolnychyi", "createdAt": "2020-07-22T16:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyODYxMw==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458928613", "bodyText": "Okay, it sounds like we can keep this fix scoped to just these classes where we need to preserve the original URI instead of modifying it. That's a good rule for us to follow: if we have a URI, then use the URI constructor. If we have a String, use the String constructor.", "author": "rdblue", "createdAt": "2020-07-22T16:34:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTk1Ng==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458929956", "bodyText": "+1 for using the approach that @aokolnychyi pasted.", "author": "rdblue", "createdAt": "2020-07-22T16:36:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMTMzMQ==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458931331", "bodyText": "Sounds good to me. I'd rather we didn't have 3 classes involved :) but If Spark does it this way at least we will be broken in similar ways if something doesn't work ;)", "author": "RussellSpitzer", "createdAt": "2020-07-22T16:38:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMzE3Mw==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458933173", "bodyText": "Works at least for my little example\nuri: java.net.URI = file:///has%20spaces\n\nscala> new Path(uri).toString\nres0: String = file:/has spaces\n\nscala> new Path(new Path(uri).toString)\nres1: org.apache.hadoop.fs.Path = file:/has spaces", "author": "RussellSpitzer", "createdAt": "2020-07-22T16:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\nindex 4b55a8e6a..a5d6974e3 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n\n@@ -386,7 +400,7 @@ public class SparkTableUtil {\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    URI uri = locationUri.get();\n+    String uri = uriToString(locationUri.get());\n     String format = serde.nonEmpty() ? serde.get() : table.provider().get();\n \n     Map<String, String> partitionSpec = JavaConverters.mapAsJavaMapConverter(partition.spec()).asJava();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyNDc0OQ==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458924749", "bodyText": "The alternate fix is on the line below (an all other times we make a Path from a string), where instead of just passing through the string we pass back through the URI version of the string, or possibly just decode the string before passing it through. I think it's probably safest to use URI the whole time, second safest to change back to URI at the last moment, third safest to attempt to decode and hope Hadoop parses the string like we want it too.", "author": "RussellSpitzer", "createdAt": "2020-07-22T16:29:51Z", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -313,7 +313,7 @@ private SparkTableUtil() {\n     }\n   }\n \n-  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, String partitionUri,\n+  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, URI partitionUri,\n                                                      PartitionSpec spec, Configuration conf,\n                                                      MetricsConfig metricsSpec) {\n     try {", "originalCommit": "6401f6e342f8bc4eb2571f807a18305206bc032d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\nindex 4b55a8e6a..a5d6974e3 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n\n@@ -313,7 +327,7 @@ public class SparkTableUtil {\n     }\n   }\n \n-  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, URI partitionUri,\n+  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, String partitionUri,\n                                                      PartitionSpec spec, Configuration conf,\n                                                      MetricsConfig metricsSpec) {\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTA5Ng==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458929096", "bodyText": "I'd like to avoid changing this method since it is public and using a URI will probably change behavior for users passing strings (String -> URI -> Path instead of String -> Path).", "author": "rdblue", "createdAt": "2020-07-22T16:34:54Z", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -271,7 +271,7 @@ private SparkTableUtil() {\n    * @param metricsConfig a metrics conf\n    * @return a List of DataFile\n    */\n-  public static List<DataFile> listPartition(Map<String, String> partition, String uri, String format,\n+  public static List<DataFile> listPartition(Map<String, String> partition, URI uri, String format,", "originalCommit": "6401f6e342f8bc4eb2571f807a18305206bc032d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\nindex 4b55a8e6a..a5d6974e3 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n\n@@ -271,7 +285,7 @@ public class SparkTableUtil {\n    * @param metricsConfig a metrics conf\n    * @return a List of DataFile\n    */\n-  public static List<DataFile> listPartition(Map<String, String> partition, URI uri, String format,\n+  public static List<DataFile> listPartition(Map<String, String> partition, String uri, String format,\n                                              PartitionSpec spec, Configuration conf, MetricsConfig metricsConfig) {\n     if (format.contains(\"avro\")) {\n       return listAvroPartition(partition, uri, spec, conf);\n"}}, {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "url": "https://github.com/apache/iceberg/commit/25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "message": "Address Reviewer Comments\n\nIn order to avoid changing the API and SparkSQL compatible types we will fix the whitespace issue by\ninstead replacing the encoded string representation with a decoded string representation. We use a\nmethod identical to Apache Spark, taking the Hadoop Path representation of the URI and getting the\nstring representation from that.", "committedDate": "2020-07-22T17:57:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MTIzMQ==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458991231", "bodyText": "If this is going to be public, I'd rather find a better place than in SparkTableUtil, like org.apache.iceberg.hadoop.Util. I'm also fine with this being a private method here.", "author": "rdblue", "createdAt": "2020-07-22T18:17:46Z", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -105,6 +105,20 @@\n   private SparkTableUtil() {\n   }\n \n+  /**\n+   * From Apache Spark\n+   *\n+   * Convert URI to String.\n+   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n+   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n+   * to decode the uri\n+   * @param uri the URI of the path\n+   * @return the String of the path\n+   */\n+  public static String uriToString(URI uri) {", "originalCommit": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5ODIwMQ==", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458998201", "bodyText": "I'll move it to Util, since this will probably come up again in the future and possibly in a non Spark Context (pretty sure all HadoopFS interactions will run into this if we ever implement methods for another system)", "author": "RussellSpitzer", "createdAt": "2020-07-22T18:30:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MTIzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "b389a7a7e5758447c20124d2c24d0f8b565f881e", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\nindex a5d6974e3..828ec4ffe 100644\n--- a/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n+++ b/spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java\n\n@@ -105,20 +106,6 @@ public class SparkTableUtil {\n   private SparkTableUtil() {\n   }\n \n-  /**\n-   * From Apache Spark\n-   *\n-   * Convert URI to String.\n-   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n-   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n-   * to decode the uri\n-   * @param uri the URI of the path\n-   * @return the String of the path\n-   */\n-  public static String uriToString(URI uri) {\n-    return new Path(uri).toString();\n-  }\n-\n   /**\n    * Returns a DataFrame with a row for each partition in the table.\n    *\n"}}, {"oid": "b389a7a7e5758447c20124d2c24d0f8b565f881e", "url": "https://github.com/apache/iceberg/commit/b389a7a7e5758447c20124d2c24d0f8b565f881e", "message": "Move uriToString to Hadoop Util Class\n\nFor any future integrations which need to change URI's to strings.", "committedDate": "2020-07-22T18:40:15Z", "type": "commit"}]}