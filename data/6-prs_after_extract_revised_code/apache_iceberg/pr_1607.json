{"pr_number": 1607, "pr_title": "Test out complex stuctures: MAP/LIST/STRUCT", "pr_createdAt": "2020-10-13T12:29:37Z", "pr_url": "https://github.com/apache/iceberg/pull/1607", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEwNzk2NQ==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r504107965", "bodyText": "Style:\n\nWe don't use final for local variables because Java does a good job of inferring it and it is debatable whether it actually helps the compiler make better decisions.\nThe indentation is off. It should be 4 spaces (2 indents) for a continuing indent.", "author": "rdblue", "createdAt": "2020-10-13T16:46:28Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -230,6 +276,250 @@ public void testJoinTables(FileFormat format) throws IOException {\n     Assert.assertArrayEquals(new Object[] {1L, \"Bob\", 102L, 33.33d}, rows.get(2));\n   }\n \n+  private void testArrayTypeInTable(FileFormat format) throws IOException {\n+    final Schema schema = new Schema(\n+            required(1, \"arrayofprimitives\", Types.ListType.ofRequired(", "originalCommit": "6e1228fd085822b7784ca862370cfabd505a1fc5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "157fbcca552b073c49de3030dabbec69f136a28e", "chunk": "diff --git a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\nindex beec003a4..9b417773f 100644\n--- a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n+++ b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n\n@@ -276,29 +290,300 @@ public abstract class HiveIcebergStorageHandlerBaseTest {\n     Assert.assertArrayEquals(new Object[] {1L, \"Bob\", 102L, 33.33d}, rows.get(2));\n   }\n \n-  private void testArrayTypeInTable(FileFormat format) throws IOException {\n-    final Schema schema = new Schema(\n-            required(1, \"arrayofprimitives\", Types.ListType.ofRequired(\n-                    2, Types.IntegerType.get()\n-            )),\n-            required(3, \"arrayofarrays\", Types.ListType.ofRequired(\n-                    4, Types.ListType.ofRequired(\n-                            5, Types.DateType.get()\n-                    )\n-            )),\n-            required(6, \"arrayofmaps\", Types.ListType.ofRequired(\n-                    7, Types.MapType.ofRequired(\n-                            8, 9, Types.StringType.get(), Types.BooleanType.get()\n-                    )\n-            )),\n-            required(10, \"arrayofstructs\", Types.ListType.ofRequired(\n-                    11, Types.StructType.of(\n-                            required(12, \"something\", Types.DoubleType.get()),\n-                            required(13, \"someone\", Types.LongType.get()),\n-                            required(14, \"somewhere\", Types.StringType.get())\n-                    )\n-            ))\n+  @Test\n+  public void testCreateDropTable() throws TException, IOException, InterruptedException {\n+    // We need the location for HadoopTable based tests only\n+    String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n+        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+        (location != null ? \"LOCATION '\" + location + \"' \" : \"\") +\n+        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" + SchemaParser.toJson(CUSTOMER_SCHEMA) + \"', \" +\n+        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" + PartitionSpecParser.toJson(IDENTITY_SPEC) + \"', \" +\n+        \"'dummy'='test')\");\n+\n+    Properties properties = new Properties();\n+    properties.put(Catalogs.NAME, TableIdentifier.of(\"default\", \"customers\").toString());\n+    if (location != null) {\n+      properties.put(Catalogs.LOCATION, location);\n+    }\n+\n+    // Check the Iceberg table data\n+    org.apache.iceberg.Table icebergTable = Catalogs.loadTable(shell.getHiveConf(), properties);\n+    Assert.assertEquals(CUSTOMER_SCHEMA.asStruct(), icebergTable.schema().asStruct());\n+    Assert.assertEquals(IDENTITY_SPEC, icebergTable.spec());\n+\n+    // Check the HMS table parameters\n+    org.apache.hadoop.hive.metastore.api.Table hmsTable =\n+        metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+\n+    Map<String, String> hmsParams = hmsTable.getParameters();\n+    IGNORED_PARAMS.forEach(hmsParams::remove);\n+\n+    // This is only set for HiveCatalog based tables. Check the value, then remove it so the other checks can be general\n+    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n+      Assert.assertTrue(hmsParams.get(BaseMetastoreTableOperations.METADATA_LOCATION_PROP)\n+          .startsWith(icebergTable.location()));\n+      hmsParams.remove(BaseMetastoreTableOperations.METADATA_LOCATION_PROP);\n+    }\n+\n+    // General metadata checks\n+    Assert.assertEquals(6, hmsParams.size());\n+    Assert.assertEquals(\"test\", hmsParams.get(\"dummy\"));\n+    Assert.assertEquals(\"TRUE\", hmsParams.get(InputFormatConfig.EXTERNAL_TABLE_PURGE));\n+    Assert.assertEquals(\"TRUE\", hmsParams.get(\"EXTERNAL\"));\n+    Assert.assertNotNull(hmsParams.get(hive_metastoreConstants.DDL_TIME));\n+    Assert.assertEquals(HiveIcebergStorageHandler.class.getName(),\n+        hmsTable.getParameters().get(hive_metastoreConstants.META_TABLE_STORAGE));\n+    Assert.assertEquals(BaseMetastoreTableOperations.ICEBERG_TABLE_TYPE_VALUE.toUpperCase(),\n+        hmsTable.getParameters().get(BaseMetastoreTableOperations.TABLE_TYPE_PROP));\n+\n+    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n+      Assert.assertEquals(Collections.singletonMap(\"dummy\", \"test\"), icebergTable.properties());\n+\n+      shell.executeStatement(\"DROP TABLE customers\");\n+\n+      // Check if the table was really dropped even from the Catalog\n+      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n+          \"Table does not exist\", () -> {\n+            Catalogs.loadTable(shell.getHiveConf(), properties);\n+          }\n+      );\n+    } else {\n+      Map<String, String> expectedIcebergProperties = new HashMap<>(2);\n+      expectedIcebergProperties.put(\"dummy\", \"test\");\n+      expectedIcebergProperties.put(TableProperties.ENGINE_HIVE_ENABLED, \"true\");\n+      Assert.assertEquals(expectedIcebergProperties, icebergTable.properties());\n+\n+      // Check the HMS table parameters\n+      hmsTable = metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n+\n+      // Drop the table\n+      shell.executeStatement(\"DROP TABLE customers\");\n+\n+      // Check if we drop an exception when trying to load the table\n+      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n+          \"Table does not exist\", () -> {\n+            Catalogs.loadTable(shell.getHiveConf(), properties);\n+          }\n+      );\n+\n+      // Check if the files are removed\n+      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n+      Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n+      Assert.assertEquals(0, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateTableWithoutSpec() throws TException, InterruptedException {\n+    // We need the location for HadoopTable based tests only\n+    String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n+        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+        (location != null ? \"LOCATION '\" + location + \"' \" : \"\") +\n+        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" + SchemaParser.toJson(CUSTOMER_SCHEMA) + \"')\");\n+\n+    Properties properties = new Properties();\n+    properties.put(Catalogs.NAME, TableIdentifier.of(\"default\", \"customers\").toString());\n+    if (location != null) {\n+      properties.put(Catalogs.LOCATION, location);\n+    }\n+\n+    // Check the Iceberg table partition data\n+    org.apache.iceberg.Table icebergTable = Catalogs.loadTable(shell.getHiveConf(), properties);\n+    Assert.assertEquals(SPEC, icebergTable.spec());\n+\n+    // Check the HMS table parameters\n+    org.apache.hadoop.hive.metastore.api.Table hmsTable =\n+        metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+\n+    Map<String, String> hmsParams = hmsTable.getParameters();\n+    IGNORED_PARAMS.forEach(hmsParams::remove);\n+\n+    // Just check that the PartitionSpec is not set in the metadata\n+    Assert.assertNull(hmsParams.get(InputFormatConfig.PARTITION_SPEC));\n+\n+    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n+      Assert.assertEquals(6, hmsParams.size());\n+    } else {\n+      Assert.assertEquals(5, hmsParams.size());\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateTableWithUnpartitionedSpec() throws TException, InterruptedException {\n+    // We need the location for HadoopTable based tests only\n+    String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n+        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+        (location != null ? \"LOCATION '\" + location + \"' \" : \"\") +\n+        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" + SchemaParser.toJson(CUSTOMER_SCHEMA) + \"', \" +\n+        \"'\" + InputFormatConfig.PARTITION_SPEC + \"'='\" + PartitionSpecParser.toJson(SPEC) + \"')\");\n+\n+    Properties properties = new Properties();\n+    properties.put(Catalogs.NAME, TableIdentifier.of(\"default\", \"customers\").toString());\n+    if (location != null) {\n+      properties.put(Catalogs.LOCATION, location);\n+    }\n+\n+    // Check the Iceberg table partition data\n+    org.apache.iceberg.Table icebergTable = Catalogs.loadTable(shell.getHiveConf(), properties);\n+    Assert.assertEquals(SPEC, icebergTable.spec());\n+\n+    // Check the HMS table parameters\n+    org.apache.hadoop.hive.metastore.api.Table hmsTable =\n+        metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+\n+    Map<String, String> hmsParams = hmsTable.getParameters();\n+    IGNORED_PARAMS.forEach(hmsParams::remove);\n+\n+    // Just check that the PartitionSpec is not set in the metadata\n+    Assert.assertNull(hmsParams.get(InputFormatConfig.PARTITION_SPEC));\n+    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n+      Assert.assertEquals(6, hmsParams.size());\n+    } else {\n+      Assert.assertEquals(5, hmsParams.size());\n+    }\n+  }\n+\n+  @Test\n+  public void testDeleteBackingTable() throws TException, IOException, InterruptedException {\n+    // We need the location for HadoopTable based tests only\n+    String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+    shell.executeStatement(\"CREATE EXTERNAL TABLE customers \" +\n+        \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+        (location != null ? \"LOCATION '\" + location + \"' \" : \"\") +\n+        \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" + SchemaParser.toJson(CUSTOMER_SCHEMA) + \"', \" +\n+        \"'\" + InputFormatConfig.EXTERNAL_TABLE_PURGE + \"'='FALSE')\");\n+\n+    Properties properties = new Properties();\n+    properties.put(Catalogs.NAME, TableIdentifier.of(\"default\", \"customers\").toString());\n+    if (location != null) {\n+      properties.put(Catalogs.LOCATION, location);\n+    }\n+\n+    if (!Catalogs.hiveCatalog(shell.getHiveConf())) {\n+      shell.executeStatement(\"DROP TABLE customers\");\n+\n+      // Check if the table remains\n+      Catalogs.loadTable(shell.getHiveConf(), properties);\n+    } else {\n+      // Check the HMS table parameters\n+      org.apache.hadoop.hive.metastore.api.Table hmsTable =\n+          metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+      Path hmsTableLocation = new Path(hmsTable.getSd().getLocation());\n+\n+      // Drop the table\n+      shell.executeStatement(\"DROP TABLE customers\");\n+\n+      // Check if we drop an exception when trying to drop the table\n+      AssertHelpers.assertThrows(\"should throw exception\", NoSuchTableException.class,\n+          \"Table does not exist\", () -> {\n+            Catalogs.loadTable(shell.getHiveConf(), properties);\n+          }\n+      );\n+\n+      // Check if the files are kept\n+      FileSystem fs = Util.getFs(hmsTableLocation, shell.getHiveConf());\n+      Assert.assertEquals(1, fs.listStatus(hmsTableLocation).length);\n+      Assert.assertEquals(1, fs.listStatus(new Path(hmsTableLocation, \"metadata\")).length);\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateTableError() {\n+    String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+\n+    // Wrong schema\n+    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n+        \"Unrecognized token 'WrongSchema'\", () -> {\n+          shell.executeQuery(\"CREATE EXTERNAL TABLE withShell2 \" +\n+              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+              (location != null ? \"LOCATION '\" + location + \"' \" : \"\") +\n+              \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='WrongSchema')\");\n+        }\n+    );\n+\n+    // Missing schema, we try to get the schema from the table and fail\n+    AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n+        \"Please provide an existing table or a valid schema\", () -> {\n+          shell.executeQuery(\"CREATE EXTERNAL TABLE withShell2 \" +\n+              \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+              (location != null ? \"LOCATION '\" + location + \"' \" : \"\"));\n+        }\n     );\n+\n+    if (location != null) {\n+      // Missing location\n+      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class,\n+          \"Table location not set\", () -> {\n+            shell.executeQuery(\"CREATE EXTERNAL TABLE withShell2 \" +\n+                \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+                \"TBLPROPERTIES ('\" + InputFormatConfig.TABLE_SCHEMA + \"'='\" +\n+                SchemaParser.toJson(CUSTOMER_SCHEMA) + \"')\");\n+          }\n+      );\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateTableAboveExistingTable() throws TException, IOException, InterruptedException {\n+    // Create the Iceberg table\n+    createIcebergTable(\"customers\", CUSTOMER_SCHEMA, FileFormat.PARQUET, Collections.emptyList());\n+\n+    if (Catalogs.hiveCatalog(shell.getHiveConf())) {\n+\n+      // In HiveCatalog we just expect an exception since the table is already exists\n+      AssertHelpers.assertThrows(\"should throw exception\", IllegalArgumentException.class, \"customers already exists\",\n+          () -> {\n+            shell.executeQuery(\n+                \"CREATE EXTERNAL TABLE customers \" + \"STORED BY \" +\n+                    \"'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' TBLPROPERTIES ('\" +\n+                    InputFormatConfig.TABLE_SCHEMA + \"'='\" + SchemaParser.toJson(CUSTOMER_SCHEMA) +\n+                    \"')\");\n+          });\n+    } else {\n+      // We need the location for HadoopTable based tests only\n+      String location = locationForCreateTable(temp.getRoot().getPath(), \"customers\");\n+\n+      shell.executeStatement(\n+          \"CREATE EXTERNAL TABLE customers \" + \"STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \" +\n+              (location != null ? \"LOCATION '\" + location + \"'\" : \"\"));\n+\n+      Properties properties = new Properties();\n+      properties.put(Catalogs.NAME, TableIdentifier.of(\"default\", \"customers\").toString());\n+      if (location != null) {\n+        properties.put(Catalogs.LOCATION, location);\n+      }\n+\n+      // Check the HMS table parameters\n+      org.apache.hadoop.hive.metastore.api.Table hmsTable =\n+          metastore.clientPool().run(client -> client.getTable(\"default\", \"customers\"));\n+\n+      Map<String, String> hmsParams = hmsTable.getParameters();\n+      IGNORED_PARAMS.forEach(hmsParams::remove);\n+\n+      Assert.assertEquals(4, hmsParams.size());\n+      Assert.assertEquals(\"TRUE\", hmsParams.get(\"EXTERNAL\"));\n+      Assert.assertNotNull(hmsParams.get(hive_metastoreConstants.DDL_TIME));\n+      Assert.assertEquals(HiveIcebergStorageHandler.class.getName(),\n+          hmsTable.getParameters().get(hive_metastoreConstants.META_TABLE_STORAGE));\n+      Assert.assertEquals(BaseMetastoreTableOperations.ICEBERG_TABLE_TYPE_VALUE.toUpperCase(),\n+          hmsTable.getParameters().get(BaseMetastoreTableOperations.TABLE_TYPE_PROP));\n+    }\n+  }\n+\n+  private void testArrayTypeInTable(FileFormat format) throws IOException {\n+    final Schema schema =\n+        new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())),\n+            required(3, \"arrayofarrays\",\n+                Types.ListType.ofRequired(4, Types.ListType.ofRequired(5, Types.DateType.get()))),\n+            required(6, \"arrayofmaps\", Types.ListType\n+                .ofRequired(7, Types.MapType.ofRequired(8, 9, Types.StringType.get(), Types.BooleanType.get()))),\n+            required(10, \"arrayofstructs\", Types.ListType.ofRequired(11, Types.StructType\n+                .of(required(12, \"something\", Types.DoubleType.get()), required(13, \"someone\", Types.LongType.get()),\n+                    required(14, \"somewhere\", Types.StringType.get())))));\n     List<Record> records = TestHelper.generateRandomRecords(schema, 1, 0L);\n     createTable(\"arraytable\", schema, format, records);\n     // sanity check, fetch all rows\n"}}, {"oid": "157fbcca552b073c49de3030dabbec69f136a28e", "url": "https://github.com/apache/iceberg/commit/157fbcca552b073c49de3030dabbec69f136a28e", "message": "Lowercase table names in queries", "committedDate": "2020-10-14T12:22:24Z", "type": "forcePushed"}, {"oid": "f39573db44877eb1b8a8ce986422fd3728b5a5ac", "url": "https://github.com/apache/iceberg/commit/f39573db44877eb1b8a8ce986422fd3728b5a5ac", "message": "Test out complex stuctures: MAP/LIST/STRUCT", "committedDate": "2020-10-29T12:24:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQyOTI1Ng==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r514429256", "bodyText": "you can remove these drop statements, since the @ After should clean up all the tables", "author": "marton-bod", "createdAt": "2020-10-29T17:14:09Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -481,6 +482,287 @@ public void testCreateTableAboveExistingTable() throws TException, IOException,\n     }\n   }\n \n+  @Test\n+  public void testArrayOfPrimitivesInTable() throws IOException {\n+    Schema schema =\n+            new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access a single element from the array\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofprimitives\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(\n+                String.format(\"SELECT arrayofprimitives[%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\", j, i));\n+        Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n+      }\n+    }\n+    // drop test table\n+    shell.executeStatement(\"DROP TABLE default.arraytable\");", "originalCommit": "1abc954a1a93f139044c54db564e1931fefd7548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU4Ng==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r514444586", "bodyText": "@marton-bod Thanks for the review. I've removed all the drop statements.", "author": "lcspinter", "createdAt": "2020-10-29T17:36:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQyOTI1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f378684d7ea42370178f4d65de0908c72ba8a0c6", "chunk": "diff --git a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\nindex a4145a5de..39a78a459 100644\n--- a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n+++ b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n\n@@ -496,8 +496,6 @@ public abstract class HiveIcebergStorageHandlerBaseTest {\n         Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n       }\n     }\n-    // drop test table\n-    shell.executeStatement(\"DROP TABLE default.arraytable\");\n   }\n \n   @Test\n"}}, {"oid": "f378684d7ea42370178f4d65de0908c72ba8a0c6", "url": "https://github.com/apache/iceberg/commit/f378684d7ea42370178f4d65de0908c72ba8a0c6", "message": "Remove drop statement", "committedDate": "2020-10-29T17:35:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjA5Nw==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528672097", "bodyText": "Do we need this test? This adds an extra sql statement which could be costly when run 24 times. I think that if the number of rows are not correct when preparing the table, then the tests will fail anyway.\nOr did I miss something?", "author": "pvary", "createdAt": "2020-11-23T12:35:35Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -512,4 +770,14 @@ protected void createHiveTable(String tableName, String location) {\n   protected String locationForCreateTable(String tempDirName, String tableName) {\n     return null;\n   }\n+\n+  private List<Record> createTableWithGeneratedRecords(Schema schema, int numRecords, long seed, String tableName)\n+          throws IOException {\n+    List<Record> records = TestHelper.generateRandomRecords(schema, numRecords, seed);\n+    createTable(tableName, schema, records);\n+    // sanity check, fetch all rows\n+    List<Object[]> allRows = shell.executeStatement(\"SELECT * from default.\" + tableName);\n+    Assert.assertEquals(\"Number of rows doesn't match expected.\", records.size(), allRows.size());", "originalCommit": "f378684d7ea42370178f4d65de0908c72ba8a0c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc1NDE4Mg==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528754182", "bodyText": "You are right, removed the unnecessary query/assert,", "author": "lcspinter", "createdAt": "2020-11-23T14:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjA5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkzMTY4MQ==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528931681", "bodyText": "@pvary, do you think that we should move some of these Hive tests to an integration test suite? Then we could update the CI action to run Hive integration tests separately and hopefully avoid triggering it for changes to Spark or Flink.", "author": "rdblue", "createdAt": "2020-11-23T19:04:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjA5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQzNjM1NA==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r529436354", "bodyText": "@rdblue: Sounds like a good idea. Do we have anything like this already set-up for any of the subprojects, or we should invent/find the path?\nThanks, Peter", "author": "pvary", "createdAt": "2020-11-24T10:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjA5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc3NTY5OQ==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r529775699", "bodyText": "@pvary, Jack created integration tests for the Glue catalog, so you can look at what he did in iceberg-glue. Thanks!", "author": "rdblue", "createdAt": "2020-11-24T18:03:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjA5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "32ff2f2a4dfd29e8c73d1ea387ad1fc107bc8269", "chunk": "diff --git a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\nindex 39a78a459..6303ade84 100644\n--- a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n+++ b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n\n@@ -770,14 +828,4 @@ public abstract class HiveIcebergStorageHandlerBaseTest {\n   protected String locationForCreateTable(String tempDirName, String tableName) {\n     return null;\n   }\n-\n-  private List<Record> createTableWithGeneratedRecords(Schema schema, int numRecords, long seed, String tableName)\n-          throws IOException {\n-    List<Record> records = TestHelper.generateRandomRecords(schema, numRecords, seed);\n-    createTable(tableName, schema, records);\n-    // sanity check, fetch all rows\n-    List<Object[]> allRows = shell.executeStatement(\"SELECT * from default.\" + tableName);\n-    Assert.assertEquals(\"Number of rows doesn't match expected.\", records.size(), allRows.size());\n-    return records;\n-  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjI4OQ==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528672289", "bodyText": "nit: would you mind removing this line?", "author": "pvary", "createdAt": "2020-11-23T12:35:58Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -481,6 +482,263 @@ public void testCreateTableAboveExistingTable() throws TException, IOException,\n     }\n   }\n \n+  @Test\n+  public void testArrayOfPrimitivesInTable() throws IOException {\n+    Schema schema =\n+            new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access a single element from the array\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofprimitives\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(\n+                String.format(\"SELECT arrayofprimitives[%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\", j, i));\n+        Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testArrayOfArraysInTable() throws IOException {\n+    Schema schema =\n+            new Schema(\n+                    required(1, \"arrayofarrays\",\n+                            Types.ListType.ofRequired(2, Types.ListType.ofRequired(3, Types.DateType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access an element from a matrix\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofarrays\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<?> expectedInnerList = (List<?>) expectedList.get(j);\n+        for (int k = 0; k < expectedInnerList.size(); k++) {\n+          List<Object[]> queryResult = shell.executeStatement(\n+                  String.format(\"SELECT arrayofarrays[%d][%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\",\n+                          j, k, i));\n+          Assert.assertEquals(expectedInnerList.get(k).toString(), queryResult.get(0)[0]);\n+        }\n+", "originalCommit": "f378684d7ea42370178f4d65de0908c72ba8a0c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc1NDI3MQ==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528754271", "bodyText": "Fixed it.", "author": "lcspinter", "createdAt": "2020-11-23T14:46:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3MjI4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "32ff2f2a4dfd29e8c73d1ea387ad1fc107bc8269", "chunk": "diff --git a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\nindex 39a78a459..6303ade84 100644\n--- a/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n+++ b/mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java\n\n@@ -483,35 +583,39 @@ public abstract class HiveIcebergStorageHandlerBaseTest {\n   }\n \n   @Test\n-  public void testArrayOfPrimitivesInTable() throws IOException {\n+  public void testArrayTypeInTable() throws IOException {\n     Schema schema =\n-            new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())));\n-    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+            new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())),\n+                    required(3, \"arrayofarrays\",\n+                            Types.ListType.ofRequired(4, Types.ListType.ofRequired(5, Types.DateType.get()))),\n+                    required(6, \"arrayofmaps\", Types.ListType\n+                            .ofRequired(7, Types.MapType.ofRequired(8, 9, Types.StringType.get(),\n+                                    Types.BooleanType.get()))),\n+                    required(10, \"arrayofstructs\", Types.ListType.ofRequired(11, Types.StructType\n+                            .of(required(12, \"something\", Types.DoubleType.get()), required(13, \"someone\",\n+                                    Types.LongType.get()), required(14, \"somewhere\", Types.StringType.get())))));\n+    List<Record> records = TestHelper.generateRandomRecords(schema, 1, 0L);\n+    createTable(\"arraytable\", schema, records);\n+    // sanity check, fetch all rows\n+    List<Object[]> allRows = shell.executeStatement(\"SELECT * FROM default.arraytable\");\n+    Assert.assertTrue(\"Number of rows doesn't match expected.\", records.size() == allRows.size());\n     // access a single element from the array\n+    List<Object[]> queryResult;\n     for (int i = 0; i < records.size(); i++) {\n       List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofprimitives\");\n       for (int j = 0; j < expectedList.size(); j++) {\n-        List<Object[]> queryResult = shell.executeStatement(\n+        queryResult = shell.executeStatement(\n                 String.format(\"SELECT arrayofprimitives[%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\", j, i));\n         Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n       }\n     }\n-  }\n-\n-  @Test\n-  public void testArrayOfArraysInTable() throws IOException {\n-    Schema schema =\n-            new Schema(\n-                    required(1, \"arrayofarrays\",\n-                            Types.ListType.ofRequired(2, Types.ListType.ofRequired(3, Types.DateType.get()))));\n-    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n     // access an element from a matrix\n     for (int i = 0; i < records.size(); i++) {\n       List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofarrays\");\n       for (int j = 0; j < expectedList.size(); j++) {\n         List<?> expectedInnerList = (List<?>) expectedList.get(j);\n         for (int k = 0; k < expectedInnerList.size(); k++) {\n-          List<Object[]> queryResult = shell.executeStatement(\n+          queryResult = shell.executeStatement(\n                   String.format(\"SELECT arrayofarrays[%d][%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\",\n                           j, k, i));\n           Assert.assertEquals(expectedInnerList.get(k).toString(), queryResult.get(0)[0]);\n"}}, {"oid": "32ff2f2a4dfd29e8c73d1ea387ad1fc107bc8269", "url": "https://github.com/apache/iceberg/commit/32ff2f2a4dfd29e8c73d1ea387ad1fc107bc8269", "message": "Test out complex stuctures: MAP/LIST/STRUCT", "committedDate": "2020-11-23T14:40:52Z", "type": "commit"}, {"oid": "00e7a43d45a2b42a2a84fd63c677ea581b281e14", "url": "https://github.com/apache/iceberg/commit/00e7a43d45a2b42a2a84fd63c677ea581b281e14", "message": "Split complex types tests", "committedDate": "2020-11-23T14:40:53Z", "type": "commit"}, {"oid": "3574abaa4bb16cd143998bfe6a4aff7433090bd8", "url": "https://github.com/apache/iceberg/commit/3574abaa4bb16cd143998bfe6a4aff7433090bd8", "message": "Remove drop statement", "committedDate": "2020-11-23T14:40:53Z", "type": "commit"}, {"oid": "eb5f31bcc5d0433413a80b1e9a36a590ae6f5e08", "url": "https://github.com/apache/iceberg/commit/eb5f31bcc5d0433413a80b1e9a36a590ae6f5e08", "message": "Review changes.", "committedDate": "2020-11-23T14:45:14Z", "type": "commit"}, {"oid": "eb5f31bcc5d0433413a80b1e9a36a590ae6f5e08", "url": "https://github.com/apache/iceberg/commit/eb5f31bcc5d0433413a80b1e9a36a590ae6f5e08", "message": "Review changes.", "committedDate": "2020-11-23T14:45:14Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkzMDEwOA==", "url": "https://github.com/apache/iceberg/pull/1607#discussion_r528930108", "bodyText": "I think these tests may be quite a bit cleaner if this had a method to check the result given a schema and the expected record. It would require less code in each test case. That's what we do with other tests. Spark, for example, has helpers that can check the contents of a generic record against the contents of an InternalRow or a public Row. Probably good as a follow-up to this.", "author": "rdblue", "createdAt": "2020-11-23T19:02:06Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -581,6 +582,262 @@ public void testCreateTableAboveExistingTable() throws TException, IOException,\n     }\n   }\n \n+  @Test\n+  public void testArrayOfPrimitivesInTable() throws IOException {\n+    Schema schema =\n+            new Schema(required(1, \"arrayofprimitives\", Types.ListType.ofRequired(2, Types.IntegerType.get())));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access a single element from the array\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofprimitives\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(\n+                String.format(\"SELECT arrayofprimitives[%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\", j, i));\n+        Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testArrayOfArraysInTable() throws IOException {\n+    Schema schema =\n+            new Schema(\n+                    required(1, \"arrayofarrays\",\n+                            Types.ListType.ofRequired(2, Types.ListType.ofRequired(3, Types.DateType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access an element from a matrix\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofarrays\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<?> expectedInnerList = (List<?>) expectedList.get(j);\n+        for (int k = 0; k < expectedInnerList.size(); k++) {\n+          List<Object[]> queryResult = shell.executeStatement(\n+                  String.format(\"SELECT arrayofarrays[%d][%d] FROM default.arraytable \" + \"LIMIT 1 OFFSET %d\",\n+                          j, k, i));\n+          Assert.assertEquals(expectedInnerList.get(k).toString(), queryResult.get(0)[0]);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testArrayOfMapsInTable() throws IOException {\n+    Schema schema =\n+            new Schema(required(1, \"arrayofmaps\", Types.ListType\n+                    .ofRequired(2, Types.MapType.ofRequired(3, 4, Types.StringType.get(),\n+                            Types.BooleanType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access an element from a map in an array\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofmaps\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        Map<?, ?> expectedMap = (Map<?, ?>) expectedList.get(j);\n+        for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+          List<Object[]> queryResult = shell.executeStatement(String\n+                  .format(\"SELECT arrayofmaps[%d][\\\"%s\\\"] FROM default.arraytable LIMIT 1 OFFSET %d\", j,\n+                          entry.getKey(), i));\n+          Assert.assertEquals(entry.getValue(), queryResult.get(0)[0]);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testArrayOfStructsInTable() throws IOException {\n+    Schema schema =\n+            new Schema(\n+                    required(1, \"arrayofstructs\", Types.ListType.ofRequired(2, Types.StructType\n+                            .of(required(3, \"something\", Types.DoubleType.get()), required(4, \"someone\",\n+                                    Types.LongType.get()), required(5, \"somewhere\", Types.StringType.get())))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"arraytable\");\n+    // access an element from a struct in an array\n+    for (int i = 0; i < records.size(); i++) {\n+      List<?> expectedList = (List<?>) records.get(i).getField(\"arrayofstructs\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(String.format(\"SELECT arrayofstructs[%d].something, \" +\n+                \"arrayofstructs[%d].someone, arrayofstructs[%d].somewhere FROM default.arraytable LIMIT 1 \" +\n+                \"OFFSET %d\", j, j, j, i));\n+        GenericRecord genericRecord = (GenericRecord) expectedList.get(j);\n+        Assert.assertEquals(genericRecord.getField(\"something\"), queryResult.get(0)[0]);\n+        Assert.assertEquals(genericRecord.getField(\"someone\"), queryResult.get(0)[1]);\n+        Assert.assertEquals(genericRecord.getField(\"somewhere\"), queryResult.get(0)[2]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testMapOfPrimitivesInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"mapofprimitives\", Types.MapType.ofRequired(2, 3, Types.StringType.get(),\n+                    Types.IntegerType.get())));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"maptable\");\n+    // access a single value from the map\n+    for (int i = 0; i < records.size(); i++) {\n+      Map<?, ?> expectedMap = (Map<?, ?>) records.get(i).getField(\"mapofprimitives\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        List<Object[]> queryResult = shell.executeStatement(String\n+                .format(\"SELECT mapofprimitives[\\\"%s\\\"] \" + \"FROM default.maptable LIMIT 1 OFFSET %d\", entry.getKey(),\n+                        i));\n+        Assert.assertEquals(entry.getValue(), queryResult.get(0)[0]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testMapOfArraysInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"mapofarrays\",\n+                    Types.MapType.ofRequired(2, 3, Types.StringType.get(), Types.ListType.ofRequired(4,\n+                            Types.DateType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"maptable\");\n+    // access a single element from a list in a map\n+    for (int i = 0; i < records.size(); i++) {\n+      Map<?, ?> expectedMap = (Map<?, ?>) records.get(i).getField(\"mapofarrays\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        List<?> expectedList = (List<?>) entry.getValue();\n+        for (int j = 0; j < expectedList.size(); j++) {\n+          List<Object[]> queryResult = shell.executeStatement(String\n+                  .format(\"SELECT mapofarrays[\\\"%s\\\"]\" + \"[%d] FROM maptable LIMIT 1 OFFSET %d\", entry.getKey(), j, i));\n+          Assert.assertEquals(expectedList.get(j).toString(), queryResult.get(0)[0]);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testMapOfMapsInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"mapofmaps\", Types.MapType.ofRequired(2, 3, Types.StringType.get(),\n+                    Types.MapType.ofRequired(4, 5, Types.StringType.get(), Types.StringType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"maptable\");\n+    // access a single element from a map in a map\n+    for (int i = 0; i < records.size(); i++) {\n+      Map<?, ?> expectedMap = (Map<?, ?>) records.get(i).getField(\"mapofmaps\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        Map<?, ?> expectedInnerMap = (Map<?, ?>) entry.getValue();\n+        for (Map.Entry<?, ?> innerEntry : expectedInnerMap.entrySet()) {\n+          List<Object[]> queryResult = shell.executeStatement(String\n+                  .format(\"SELECT mapofmaps[\\\"%s\\\"]\" + \"[\\\"%s\\\"] FROM maptable LIMIT 1 OFFSET %d\", entry.getKey(),\n+                          innerEntry.getKey(), i));\n+          Assert.assertEquals(innerEntry.getValue(), queryResult.get(0)[0]);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testMapOfStructsInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"mapofstructs\", Types.MapType.ofRequired(2, 3, Types.StringType.get(),\n+                    Types.StructType.of(required(4, \"something\", Types.DoubleType.get()),\n+                            required(5, \"someone\", Types.LongType.get()),\n+                            required(6, \"somewhere\", Types.StringType.get())))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"maptable\");\n+    // access a single element from a struct in a map\n+    for (int i = 0; i < records.size(); i++) {\n+      Map<?, ?> expectedMap = (Map<?, ?>) records.get(i).getField(\"mapofstructs\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        List<Object[]> queryResult = shell.executeStatement(String.format(\"SELECT mapofstructs[\\\"%s\\\"].something, \" +\n+                \"mapofstructs[\\\"%s\\\"].someone, mapofstructs[\\\"%s\\\"].somewhere FROM default.maptable LIMIT 1 \" +\n+                \"OFFSET %d\", entry.getKey(), entry.getKey(), entry.getKey(), i));\n+        GenericRecord genericRecord = (GenericRecord) entry.getValue();\n+        Assert.assertEquals(genericRecord.getField(\"something\"), queryResult.get(0)[0]);\n+        Assert.assertEquals(genericRecord.getField(\"someone\"), queryResult.get(0)[1]);\n+        Assert.assertEquals(genericRecord.getField(\"somewhere\"), queryResult.get(0)[2]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testStructOfPrimitivesInTable() throws IOException {\n+    Schema schema = new Schema(required(1, \"structofprimitives\",\n+            Types.StructType.of(required(2, \"key\", Types.StringType.get()), required(3, \"value\",\n+                    Types.IntegerType.get()))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"structtable\");\n+    // access a single value in a struct\n+    for (int i = 0; i < records.size(); i++) {\n+      GenericRecord expectedStruct = (GenericRecord) records.get(i).getField(\"structofprimitives\");\n+      List<Object[]> queryResult = shell.executeStatement(String.format(\n+              \"SELECT structofprimitives.key, structofprimitives.value FROM default.structtable LIMIT 1 OFFSET %d\", i));\n+      Assert.assertEquals(expectedStruct.getField(\"key\"), queryResult.get(0)[0]);\n+      Assert.assertEquals(expectedStruct.getField(\"value\"), queryResult.get(0)[1]);\n+    }\n+  }\n+\n+  @Test\n+  public void testStructOfArraysInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"structofarrays\", Types.StructType\n+                    .of(required(2, \"names\", Types.ListType.ofRequired(3, Types.StringType.get())),\n+                            required(4, \"birthdays\", Types.ListType.ofRequired(5,\n+                                    Types.DateType.get())))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"structtable\");\n+    // access an element of an array inside a struct\n+    for (int i = 0; i < records.size(); i++) {\n+      GenericRecord expectedStruct = (GenericRecord) records.get(i).getField(\"structofarrays\");\n+      List<?> expectedList = (List<?>) expectedStruct.getField(\"names\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(\n+                String.format(\"SELECT structofarrays.names[%d] FROM default.structtable LIMIT 1 OFFSET %d\", j, i));\n+        Assert.assertEquals(expectedList.get(j), queryResult.get(0)[0]);\n+      }\n+      expectedList = (List<?>) expectedStruct.getField(\"birthdays\");\n+      for (int j = 0; j < expectedList.size(); j++) {\n+        List<Object[]> queryResult = shell.executeStatement(\n+                String.format(\"SELECT structofarrays.birthdays[%d] FROM default.structtable LIMIT 1 OFFSET %d\", j, i));\n+        Assert.assertEquals(expectedList.get(j).toString(), queryResult.get(0)[0]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testStructOfMapsInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"structofmaps\", Types.StructType\n+                    .of(required(2, \"map1\", Types.MapType.ofRequired(3, 4,\n+                            Types.StringType.get(), Types.StringType.get())), required(5, \"map2\",\n+                            Types.MapType.ofRequired(6, 7, Types.StringType.get(),\n+                                    Types.IntegerType.get())))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"structtable\");\n+    // access a map entry inside a struct\n+    for (int i = 0; i < records.size(); i++) {\n+      GenericRecord expectedStruct = (GenericRecord) records.get(i).getField(\"structofmaps\");\n+      Map<?, ?> expectedMap = (Map<?, ?>) expectedStruct.getField(\"map1\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        List<Object[]> queryResult = shell.executeStatement(String\n+                .format(\"SELECT structofmaps.map1[\\\"%s\\\"] from default.structtable LIMIT 1 OFFSET %d\", entry.getKey(),\n+                        i));\n+        Assert.assertEquals(entry.getValue(), queryResult.get(0)[0]);\n+      }\n+      expectedMap = (Map<?, ?>) expectedStruct.getField(\"map2\");\n+      for (Map.Entry<?, ?> entry : expectedMap.entrySet()) {\n+        List<Object[]> queryResult = shell.executeStatement(String\n+                .format(\"SELECT structofmaps.map2[\\\"%s\\\"] from default.structtable LIMIT 1 OFFSET %d\", entry.getKey(),\n+                        i));\n+        Assert.assertEquals(entry.getValue(), queryResult.get(0)[0]);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testStructOfStructsInTable() throws IOException {\n+    Schema schema = new Schema(\n+            required(1, \"structofstructs\", Types.StructType.of(required(2, \"struct1\", Types.StructType\n+                    .of(required(3, \"key\", Types.StringType.get()), required(4, \"value\",\n+                            Types.IntegerType.get()))))));\n+    List<Record> records = createTableWithGeneratedRecords(schema, 1, 0L, \"structtable\");\n+    // access a struct element inside a struct\n+    for (int i = 0; i < records.size(); i++) {\n+      GenericRecord expectedStruct = (GenericRecord) records.get(i).getField(\"structofstructs\");\n+      GenericRecord expectedInnerStruct = (GenericRecord) expectedStruct.getField(\"struct1\");\n+      List<Object[]> queryResult = shell.executeStatement(String.format(\n+              \"SELECT structofstructs.struct1.key, structofstructs.struct1.value FROM default.structtable \" +\n+                      \"LIMIT 1 OFFSET %d\", i));\n+      Assert.assertEquals(expectedInnerStruct.getField(\"key\"), queryResult.get(0)[0]);\n+      Assert.assertEquals(expectedInnerStruct.getField(\"value\"), queryResult.get(0)[1]);", "originalCommit": "eb5f31bcc5d0433413a80b1e9a36a590ae6f5e08", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}