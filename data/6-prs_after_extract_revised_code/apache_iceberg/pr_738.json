{"pr_number": 738, "pr_title": "Collect row stats while writing manifests", "pr_createdAt": "2020-01-16T10:24:48Z", "pr_url": "https://github.com/apache/iceberg/pull/738", "timeline": [{"oid": "9e18ddc084ca1bcee7e2267ef08df85ea82f86c7", "url": "https://github.com/apache/iceberg/commit/9e18ddc084ca1bcee7e2267ef08df85ea82f86c7", "message": "Collect row stats while writing manifests", "committedDate": "2020-01-16T10:29:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzM0MzczOQ==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r367343739", "bodyText": "Technically, this doesn't have to extend TableTestBase but we need writeManifest. I think we can refactor a bit and introduce a separate parent test class with the logic for writing/checking manifests/snapshots.", "author": "aokolnychyi", "createdAt": "2020-01-16T10:33:28Z", "path": "core/src/test/java/org/apache/iceberg/TestManifestWriter.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+import org.apache.iceberg.ManifestEntry.Status;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestManifestWriter extends TableTestBase {", "originalCommit": "9e18ddc084ca1bcee7e2267ef08df85ea82f86c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzg2NTgyNA==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r367865824", "bodyText": "+1 to extract out base classes for just manifest and snapshots.", "author": "chenjunjiedada", "createdAt": "2020-01-17T10:26:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzM0MzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MzA1Mw==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368043053", "bodyText": "Either way is fine with me. I usually prefer to keep things simple.", "author": "rdblue", "createdAt": "2020-01-17T17:08:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzM0MzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg2MDU2NQ==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368860565", "bodyText": "I wanted to refactor but it looks the changes won't be worth the effort after a closer look. For example, we will need to pass a partition spec and FileIO to write manifests that we can simply take from table in TableTestBase. Let's keep it as is for now.", "author": "aokolnychyi", "createdAt": "2020-01-21T08:20:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzM0MzczOQ=="}], "type": "inlineReview", "revised_code": {"commit": "4185fe021e10a4e6c489dde7d0db9a95c5b003de", "chunk": "diff --git a/core/src/test/java/org/apache/iceberg/TestManifestWriter.java b/core/src/test/java/org/apache/iceberg/TestManifestWriter.java\nindex 99b539a01..9a67ac7b4 100644\n--- a/core/src/test/java/org/apache/iceberg/TestManifestWriter.java\n+++ b/core/src/test/java/org/apache/iceberg/TestManifestWriter.java\n\n@@ -56,9 +56,9 @@ public class TestManifestWriter extends TableTestBase {\n \n   private DataFile newFile(long recordCount) {\n     String fileName = UUID.randomUUID().toString();\n-    return DataFiles.builder()\n-        .withPath(fileName + \".parquet\")\n-        .withFileSizeInBytes(0)\n+    return DataFiles.builder(SPEC)\n+        .withPath(\"data_bucket=0/\" + fileName + \".parquet\")\n+        .withFileSizeInBytes(1024)\n         .withRecordCount(recordCount)\n         .build();\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368042226", "bodyText": "Can we add these up by the data files counts?", "author": "rdblue", "createdAt": "2020-01-17T17:06:39Z", "path": "api/src/main/java/org/apache/iceberg/ManifestFile.java", "diffHunk": "@@ -42,7 +42,10 @@\n           required(509, \"contains_null\", Types.BooleanType.get()),\n           optional(510, \"lower_bound\", Types.BinaryType.get()), // null if no non-null values\n           optional(511, \"upper_bound\", Types.BinaryType.get())\n-      ))));\n+      ))),\n+      optional(512, \"added_rows_count\", Types.LongType.get()),\n+      optional(513, \"existing_rows_count\", Types.LongType.get()),\n+      optional(514, \"deleted_rows_count\", Types.LongType.get()));", "originalCommit": "9e18ddc084ca1bcee7e2267ef08df85ea82f86c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2Mjg4NA==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368062884", "bodyText": "@rdblue, not sure I got. Do you mean whether we can avoid storing these and add them up?", "author": "aokolnychyi", "createdAt": "2020-01-17T17:58:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NTA0OQ==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368065049", "bodyText": "No, I meant that we don't need to add these at the end of the schema. We can add them up by the file count columns, like you do with all of the accessor methods.", "author": "rdblue", "createdAt": "2020-01-17T18:03:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NTc3OA==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368065778", "bodyText": "Yes, let me update this.", "author": "aokolnychyi", "createdAt": "2020-01-17T18:05:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg2MDc3Mw==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r368860773", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-01-21T08:21:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwMTA4OQ==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r369201089", "bodyText": "Hm, reordering actually led to failures while writing manifest lists as GenericAvroWriter doesn't take into account field ids.", "author": "aokolnychyi", "createdAt": "2020-01-21T19:34:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMjI2MQ==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r369222261", "bodyText": "@rdblue, do we want to build something as ProjectionDatumReader for the write side?", "author": "aokolnychyi", "createdAt": "2020-01-21T20:19:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk5MjEwMw==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r369992103", "bodyText": "@rdblue, I reverted this change. I propose to merge this PR as is and create a follow-up issue to implement writers that take into account field ids.", "author": "aokolnychyi", "createdAt": "2020-01-23T08:50:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2NTEzNw==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r370265137", "bodyText": "Writers don't use field IDs?", "author": "rdblue", "createdAt": "2020-01-23T17:50:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUwNjY2Mw==", "url": "https://github.com/apache/iceberg/pull/738#discussion_r370506663", "bodyText": "@rdblue, yes, GenericAvroWriter doesn't. I think SparkAvroWriter does respect field ids.", "author": "aokolnychyi", "createdAt": "2020-01-24T07:51:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA0MjIyNg=="}], "type": "inlineReview", "revised_code": {"commit": "873ae9147f423a5aef9726c5947927a110cd1682", "chunk": "diff --git a/api/src/main/java/org/apache/iceberg/ManifestFile.java b/api/src/main/java/org/apache/iceberg/ManifestFile.java\nindex 176bbbd32..bdb6f2141 100644\n--- a/api/src/main/java/org/apache/iceberg/ManifestFile.java\n+++ b/api/src/main/java/org/apache/iceberg/ManifestFile.java\n\n@@ -36,16 +36,16 @@ public interface ManifestFile {\n       required(502, \"partition_spec_id\", Types.IntegerType.get()),\n       optional(503, \"added_snapshot_id\", Types.LongType.get()),\n       optional(504, \"added_data_files_count\", Types.IntegerType.get()),\n+      optional(512, \"added_rows_count\", Types.LongType.get()),\n       optional(505, \"existing_data_files_count\", Types.IntegerType.get()),\n+      optional(513, \"existing_rows_count\", Types.LongType.get()),\n       optional(506, \"deleted_data_files_count\", Types.IntegerType.get()),\n+      optional(514, \"deleted_rows_count\", Types.LongType.get()),\n       optional(507, \"partitions\", Types.ListType.ofRequired(508, Types.StructType.of(\n           required(509, \"contains_null\", Types.BooleanType.get()),\n           optional(510, \"lower_bound\", Types.BinaryType.get()), // null if no non-null values\n           optional(511, \"upper_bound\", Types.BinaryType.get())\n-      ))),\n-      optional(512, \"added_rows_count\", Types.LongType.get()),\n-      optional(513, \"existing_rows_count\", Types.LongType.get()),\n-      optional(514, \"deleted_rows_count\", Types.LongType.get()));\n+      ))));\n \n   static Schema schema() {\n     return SCHEMA;\n"}}, {"oid": "d5c01089b5839ee38bbbd4e8935edb1b9550e7ee", "url": "https://github.com/apache/iceberg/commit/d5c01089b5839ee38bbbd4e8935edb1b9550e7ee", "message": "Collect row stats while writing manifests", "committedDate": "2020-01-21T08:12:08Z", "type": "commit"}, {"oid": "873ae9147f423a5aef9726c5947927a110cd1682", "url": "https://github.com/apache/iceberg/commit/873ae9147f423a5aef9726c5947927a110cd1682", "message": "Reorder fields", "committedDate": "2020-01-21T08:12:08Z", "type": "commit"}, {"oid": "4185fe021e10a4e6c489dde7d0db9a95c5b003de", "url": "https://github.com/apache/iceberg/commit/4185fe021e10a4e6c489dde7d0db9a95c5b003de", "message": "Use SPEC to build files", "committedDate": "2020-01-21T08:12:08Z", "type": "commit"}, {"oid": "4185fe021e10a4e6c489dde7d0db9a95c5b003de", "url": "https://github.com/apache/iceberg/commit/4185fe021e10a4e6c489dde7d0db9a95c5b003de", "message": "Use SPEC to build files", "committedDate": "2020-01-21T08:12:08Z", "type": "forcePushed"}, {"oid": "8d72cc6644624507b1b7369f5933097b09be6b1d", "url": "https://github.com/apache/iceberg/commit/8d72cc6644624507b1b7369f5933097b09be6b1d", "message": "Revert \"Reorder fields\"\n\nThis reverts commit 873ae914", "committedDate": "2020-01-23T06:34:07Z", "type": "commit"}]}