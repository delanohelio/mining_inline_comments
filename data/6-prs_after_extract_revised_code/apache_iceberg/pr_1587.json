{"pr_number": 1587, "pr_title": "Nessie support for core ", "pr_createdAt": "2020-10-12T15:25:48Z", "pr_url": "https://github.com/apache/iceberg/pull/1587", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNTkwMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528905901", "bodyText": "Nit: static final constants should use upper case names, like LOGGER. I'm not sure why style checks didn't catch this.\n(Not a blocker)", "author": "rdblue", "createdAt": "2020-11-23T18:18:32Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDQ2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914465", "bodyText": "fixed. I was just arguing w/ @jacques-n on this point on Fri ;-) He sided with you.", "author": "rymurr", "createdAt": "2020-11-23T18:33:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNTkwMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNjg2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528906862", "bodyText": "Nit: threw is no longer needed so this could be simply return true. That simplifies the logic at the end of the method to just return false.\nUp to you whether to change this or not. I know some people strongly prefer only one exit point from a method.", "author": "rdblue", "createdAt": "2020-11-23T18:20:14Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.reference() != null) {\n+      newReference = loadReference(pti.reference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.tableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    boolean threw = true;\n+    try {\n+      Tasks.foreach(identifier)\n+           .retry(5)\n+           .stopRetryOn(NessieNotFoundException.class)\n+           .throwFailureWhenFinished()\n+           .run(this::dropTableInner, BaseNessieClientServerException.class);\n+      threw = false;", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDkxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914919", "bodyText": "fixed. I like your way better too..just a hangover from the refactor", "author": "rymurr", "createdAt": "2020-11-23T18:34:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNjg2Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528910205", "bodyText": "Did you intend to change this to \"ref\"? Your reply seemed to imply that: #1587 (comment)", "author": "rdblue", "createdAt": "2020-11-23T18:26:05Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkyOTY1Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528929656", "bodyText": "It is just ref now, the removePrefix method strips the nessie.from the constant in the nessie class. Didn't want to duplicate the constants already in NessieClient", "author": "rymurr", "createdAt": "2020-11-23T19:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkzODkwMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528938903", "bodyText": "I missed the removePrefix call. Thanks!", "author": "rdblue", "createdAt": "2020-11-23T19:17:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503393453", "bodyText": "not sure if this is the best way to get hold of a directory to write tables into. Anyone have any suggestions?", "author": "rymurr", "createdAt": "2020-10-12T16:03:59Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  public static final String CONF_NESSIE_URL = \"nessie.url\";\n+  public static final String CONF_NESSIE_USERNAME = \"nessie.username\";\n+  public static final String CONF_NESSIE_PASSWORD = \"nessie.password\";\n+  public static final String CONF_NESSIE_AUTH_TYPE = \"nessie.auth_type\";\n+  public static final String NESSIE_AUTH_TYPE_DEFAULT = \"BASIC\";\n+  public static final String CONF_NESSIE_REF = \"nessie.ref\";\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+    String path = url == null ? config.get(CONF_NESSIE_URL) : url;\n+    String username = config.get(CONF_NESSIE_USERNAME);\n+    String password = config.get(CONF_NESSIE_PASSWORD);\n+    String authTypeStr = config.get(CONF_NESSIE_AUTH_TYPE, NESSIE_AUTH_TYPE_DEFAULT);\n+    AuthType authType = AuthType.valueOf(authTypeStr);\n+    this.client = new NessieClient(authType, path, username, password);\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NTQ5NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511175494", "bodyText": "In general, I would discourage depending so heavily on Hadoop Configuration. Spark and Flink have a way to pass catalog-specific options, which is the best way to configure catalogs.\nThere is some discussion about this in #1640. I think that catalogs should primarily depend on config passed in a string map, and should only use Hadoop Configuration when dependencies (like HadoopFileIO or HiveClient) require it.", "author": "rdblue", "createdAt": "2020-10-23T22:05:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NTE5MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512165191", "bodyText": "I have cleaned this up a bit and tried to follow the pattern you suggested in #1640", "author": "rymurr", "createdAt": "2020-10-26T18:04:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 2a4f4cc74..66a3000ce 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,7 +21,6 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n-import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NDkzNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503394937", "bodyText": "The nessie specific tests all modify spark settings and reset the settings at the end. This is to interfere as little as possible w/ the 'normal' iceberg path.", "author": "rymurr", "createdAt": "2020-10-12T16:06:38Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.nessie.NessieCatalog;\n+import org.apache.iceberg.spark.SparkTestBase;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+public abstract class TestIcebergSourceNessieTables extends TestIcebergSourceTablesBase {\n+\n+  private static TableIdentifier currentIdentifier;\n+\n+  private NessieClient client;\n+  private String branch;\n+\n+  private Configuration getConfig() throws IOException {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java b/spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java\ndeleted file mode 100644\nindex f1bda41fd..000000000\n--- a/spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java\n+++ /dev/null\n\n@@ -1,120 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.iceberg.spark.source;\n-\n-import com.dremio.nessie.client.NessieClient;\n-import com.dremio.nessie.error.NessieConflictException;\n-import java.io.IOException;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.iceberg.PartitionSpec;\n-import org.apache.iceberg.Schema;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.nessie.NessieCatalog;\n-import org.apache.iceberg.spark.SparkTestBase;\n-import org.junit.After;\n-import org.junit.Before;\n-\n-public abstract class TestIcebergSourceNessieTables extends TestIcebergSourceTablesBase {\n-\n-  private static TableIdentifier currentIdentifier;\n-\n-  private NessieClient client;\n-  private String branch;\n-\n-  private Configuration getConfig() throws IOException {\n-    String defaultFs = temp.newFolder().toURI().toString();\n-    String fsImpl = org.apache.hadoop.fs.LocalFileSystem.class.getName();\n-    String path = \"http://localhost:19121/api/v1\";\n-    branch = \"test-\" + TestIcebergSourceNessieTables.class.getName();\n-\n-    Configuration conf =  spark.sessionState().newHadoopConf();\n-    conf.set(\"fs.defaultFS\", defaultFs);\n-    conf.set(\"fs.file.impl\", fsImpl);\n-    conf.set(\"nessie.ref\", branch);\n-    conf.set(\"nessie.url\", path);\n-    setHadoopConfig(path, branch);\n-    this.client = new NessieClient(NessieClient.AuthType.NONE, path, null, null);\n-\n-    try {\n-      this.client.getTreeApi().createEmptyBranch(branch);\n-    } catch (NessieConflictException e) {\n-      this.client.getTreeApi().deleteBranch(branch, this.client.getTreeApi().getReferenceByName(branch).getHash());\n-      this.client.getTreeApi().createEmptyBranch(branch);\n-    }\n-    return conf;\n-  }\n-\n-  @Before\n-  public void start() throws IOException {\n-    SparkTestBase.nessie = new NessieCatalog(\"nessie\", getConfig());\n-\n-  }\n-\n-  @After\n-  public void dropTable() throws IOException {\n-    Table table = nessie.loadTable(currentIdentifier);\n-    Path tablePath = new Path(table.location());\n-    FileSystem fs = tablePath.getFileSystem(getConfig());\n-    fs.delete(tablePath, true);\n-    nessie.refresh();\n-    nessie.dropTable(currentIdentifier, false);\n-\n-    this.client.getTreeApi().deleteBranch(branch, this.client.getTreeApi().getReferenceByName(branch).getHash());\n-    this.client.close();\n-    unsetHadoopConfig();\n-  }\n-\n-  @SuppressWarnings(\"RegexpSingleLine\")\n-  private void setHadoopConfig(String path, String newBranch) {\n-    spark.sparkContext().hadoopConfiguration().set(\"nessie.url\", path);\n-    spark.sparkContext().hadoopConfiguration().set(\"nessie.ref\", newBranch);\n-  }\n-\n-  @SuppressWarnings(\"RegexpSingleLine\")\n-  private void unsetHadoopConfig() {\n-    spark.sparkContext().hadoopConfiguration().unset(\"nessie.url\");\n-    spark.sparkContext().hadoopConfiguration().unset(\"nessie.ref\");\n-  }\n-\n-  @Override\n-  public Table createTable(TableIdentifier ident, Schema schema, PartitionSpec spec) {\n-    TestIcebergSourceNessieTables.currentIdentifier = ident;\n-    return TestIcebergSourceNessieTables.nessie.createTable(ident, schema, spec);\n-  }\n-\n-  @Override\n-  public Table loadTable(TableIdentifier ident, String entriesSuffix) {\n-    TableIdentifier identifier = TableIdentifier.of(ident.namespace().level(0), ident.name(), entriesSuffix);\n-    return TestIcebergSourceNessieTables.nessie.loadTable(identifier);\n-  }\n-\n-  @Override\n-  public String loadLocation(TableIdentifier ident, String entriesSuffix) {\n-    return String.format(\"%s.%s\", loadLocation(ident), entriesSuffix);\n-  }\n-\n-  @Override\n-  public String loadLocation(TableIdentifier ident) {\n-    return ident.toString();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTU5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395596", "bodyText": "We identify Nessie as the core catalog/source when there are specific parameters available on the classpath or hadoop config. The idea here is to be fully backwards compatible w/ Hive and Hadoop catalogs.", "author": "rymurr", "createdAt": "2020-10-12T16:07:50Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -133,16 +135,29 @@ protected Table findTable(DataSourceOptions options, Configuration conf) {\n     Optional<String> path = options.get(\"path\");\n     Preconditions.checkArgument(path.isPresent(), \"Cannot open table: path is not set\");\n \n-    if (path.get().contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path.get());\n+    if (nessie(options.asMap(), conf)) {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTIxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181217", "bodyText": "This is probably an area to revisit. Right now, this is written to have minimal changes between 2.4.x and 3.0.x, but I think we will probably want to route all loading from here through a catalog. That will allow us to delegate all of this to Nessie or Hive the same way.", "author": "rdblue", "createdAt": "2020-10-23T22:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTU5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java b/spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java\nindex b2e376927..589bbad22 100644\n--- a/spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java\n+++ b/spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java\n\n@@ -135,29 +133,16 @@ public class IcebergSource implements DataSourceV2, ReadSupport, WriteSupport, D\n     Optional<String> path = options.get(\"path\");\n     Preconditions.checkArgument(path.isPresent(), \"Cannot open table: path is not set\");\n \n-    if (nessie(options.asMap(), conf)) {\n-      ParsedTableIdentifier identifier = ParsedTableIdentifier.getParsedTableIdentifier(path.get(), options.asMap());\n-      NessieCatalog catalog = new NessieCatalog(conf, identifier.getReference());\n-      return catalog.loadTable(identifier.getTableIdentifier());\n+    if (path.get().contains(\"/\")) {\n+      HadoopTables tables = new HadoopTables(conf);\n+      return tables.load(path.get());\n     } else {\n-      if (path.get().contains(\"/\")) {\n-        HadoopTables tables = new HadoopTables(conf);\n-        return tables.load(path.get());\n-      } else {\n-        HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n-        TableIdentifier tableIdentifier = TableIdentifier.parse(path.get());\n-        return hiveCatalog.loadTable(tableIdentifier);\n-      }\n+      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n+      TableIdentifier tableIdentifier = TableIdentifier.parse(path.get());\n+      return hiveCatalog.loadTable(tableIdentifier);\n     }\n   }\n \n-  private boolean nessie(Map<String, String> options, Configuration conf) {\n-    return options.containsKey(\"nessie.ref\") ||\n-        options.containsKey(\"nessie.url\") ||\n-        conf.get(\"nessie.url\") != null ||\n-        conf.get(\"nessie.ref\") != null;\n-  }\n-\n   private SparkSession lazySparkSession() {\n     if (lazySpark == null) {\n       this.lazySpark = SparkSession.builder().getOrCreate();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTkyMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395922", "bodyText": "All Nessie tests are run in their own branch to not interfere with parallel test execution", "author": "rymurr", "createdAt": "2020-10-12T16:08:31Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java", "diffHunk": "@@ -83,12 +90,40 @@ public static void dropWarehouse() {\n   protected final SupportsNamespaces validationNamespaceCatalog;\n   protected final TableIdentifier tableIdent = TableIdentifier.of(Namespace.of(\"default\"), \"table\");\n   protected final String tableName;\n+  protected NessieClient client;\n+  protected String branch;\n \n   public SparkCatalogTestBase(String catalogName, String implementation, Map<String, String> config) {\n     this.catalogName = catalogName;\n-    this.validationCatalog = catalogName.equals(\"testhadoop\") ?\n-        new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse) :\n-        catalog;\n+    switch (catalogName) {\n+      case \"testhadoop\":\n+        this.validationCatalog = new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse);\n+        break;\n+      case \"testnessie\":\n+        String path = \"http://localhost:19121/api/v1\";\n+        branch = config.get(\"nessie_ref\");\n+        setHadoopConfig(path, branch);\n+\n+        this.client = new NessieClient(NessieClient.AuthType.NONE, path, null, null);\n+        try {\n+          try {\n+            this.client.getTreeApi().createEmptyBranch(branch);", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java b/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java\nindex 243c2d33c..106ba122d 100644\n--- a/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java\n+++ b/spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java\n\n@@ -90,40 +83,12 @@ public abstract class SparkCatalogTestBase extends SparkTestBase {\n   protected final SupportsNamespaces validationNamespaceCatalog;\n   protected final TableIdentifier tableIdent = TableIdentifier.of(Namespace.of(\"default\"), \"table\");\n   protected final String tableName;\n-  protected NessieClient client;\n-  protected String branch;\n \n   public SparkCatalogTestBase(String catalogName, String implementation, Map<String, String> config) {\n     this.catalogName = catalogName;\n-    switch (catalogName) {\n-      case \"testhadoop\":\n-        this.validationCatalog = new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse);\n-        break;\n-      case \"testnessie\":\n-        String path = \"http://localhost:19121/api/v1\";\n-        branch = config.get(\"nessie_ref\");\n-        setHadoopConfig(path, branch);\n-\n-        this.client = new NessieClient(NessieClient.AuthType.NONE, path, null, null);\n-        try {\n-          try {\n-            this.client.getTreeApi().createEmptyBranch(branch);\n-          } catch (NessieConflictException e) {\n-            this.client.getTreeApi().deleteBranch(branch,\n-                this.client.getTreeApi().getReferenceByName(branch).getHash());\n-            this.client.getTreeApi().createEmptyBranch(branch);\n-          }\n-        } catch (Exception e) {\n-          throw new RuntimeException(e);\n-        }\n-        nessie = new NessieCatalog(\"nessie\", spark.sessionState().newHadoopConf(), branch, path);\n-        this.validationCatalog = nessie;\n-        break;\n-      case \"testhive\":\n-      default:\n-        this.validationCatalog = catalog;\n-    }\n-\n+    this.validationCatalog = catalogName.equals(\"testhadoop\") ?\n+        new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse) :\n+        catalog;\n     this.validationNamespaceCatalog = (SupportsNamespaces) validationCatalog;\n \n     spark.conf().set(\"spark.sql.catalog.\" + catalogName, implementation);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397068", "bodyText": "The concept of a namespace is implicit in Nessie and are therefore not managed through the normal SupportsNamespaces interface. We skip tests of this interface when the catalog is a NessieCatalog.", "author": "rymurr", "createdAt": "2020-10-12T16:10:38Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java", "diffHunk": "@@ -56,6 +56,8 @@ public void cleanNamespaces() {\n \n   @Test\n   public void testCreateNamespace() {\n+    // Nessie namespaces are explicit and do not need to be explicitly managed\n+    Assume.assumeFalse(catalogName.endsWith(\"testnessie\"));", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MjE5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511182190", "bodyText": "There are a lot of tests that need this. Should we separate the test cases into different suites?", "author": "rdblue", "createdAt": "2020-10-23T22:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0Njk4OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512046988", "bodyText": "Sure, the hadoop catalog is also skipped for most of these. Makes sense to have separate tests", "author": "rymurr", "createdAt": "2020-10-26T15:24:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java b/spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java\nindex a01f3e167..d1eac3126 100644\n--- a/spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java\n+++ b/spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java\n\n@@ -56,8 +56,6 @@ public class TestNamespaceSQL extends SparkCatalogTestBase {\n \n   @Test\n   public void testCreateNamespace() {\n-    // Nessie namespaces are explicit and do not need to be explicitly managed\n-    Assume.assumeFalse(catalogName.endsWith(\"testnessie\"));\n     Assert.assertFalse(\"Namespace should not already exist\", validationNamespaceCatalog.namespaceExists(NS));\n \n     sql(\"CREATE NAMESPACE %s\", fullNamespace);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397814", "bodyText": "We do not extend SupportsNamespaces as a Nessie object store supports the concept of namespaces implicitly. A Nessie namespace can be arbitrarily deep but is not explicitly created or stored. Similar to empty folders in git.", "author": "rymurr", "createdAt": "2020-10-12T16:11:58Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3MzcxNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511173716", "bodyText": "Should be fine, but I think the trade-off is that you won't be able to list namespaces in a namespace. It will be harder to find the namespaces themselves.", "author": "rdblue", "createdAt": "2020-10-23T21:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NDc2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511994761", "bodyText": "I will take another pass at this today, I can see totally valid reasons to support listing namespaces if they have tables in them. The problem as I see it comes from creating or deleting namespaces, and storing namespace metadata.\n\n\ncreate/delete: in Nessie (similar to git) a namespace would be created implicitly with the first table in that namespace tree and deleted with the last table in that namespace tree. Separate crerate/delete options in nessie are either no-ops or require a dummy to be placed in that namespace. Both of which are odd operations. eg if its a no-op then creating namespace foo.bar then asking if foo.bar exists will return false.\n\n\nnamespace metadata: What is the use case envisioned for those operations? I think for Nessie we would start with the same behaviour as the hdfs catalog but am curious to know the benefit of supporting those apis.", "author": "rymurr", "createdAt": "2020-10-26T14:18:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NzkyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512167927", "bodyText": "Having another look we could add valid impls for namespaceExists and listNamespaces and do no-op or throw for the others. Then the clients can still navigate namespaces. Thoughts?", "author": "rymurr", "createdAt": "2020-10-26T18:08:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 2a4f4cc74..66a3000ce 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,7 +21,6 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n-import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176255", "bodyText": "Looks like this will return all tables underneath the given namespace, even if they are nested in other namespaces?\nI haven't tested this in spark, does it work as expected?", "author": "rdblue", "createdAt": "2020-10-23T22:07:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwMDI3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512000270", "bodyText": "You are correct, it will return everythiing in and below namespace. What is the contract supposed to be? Only tables in this namespace?", "author": "rymurr", "createdAt": "2020-10-26T14:25:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NjIxMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512166211", "bodyText": "Just checked and the contract is Return all the identifiers under this namespace. I took this to mean everything under this and all sub namespaces. If that was not the intention of the method I will fix the predicate.", "author": "rymurr", "createdAt": "2020-10-26T18:06:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex f902c2d6c..66a3000ce 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -36,6 +36,7 @@ import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjM5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176395", "bodyText": "Probably shouldn't use RuntimeException here. How about NoSuchNamespaceException?", "author": "rdblue", "createdAt": "2020-10-23T22:08:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(\"Unable to list tables due to missing ref.\", ex);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwMDg2OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512000869", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-10-26T14:26:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjM5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex f902c2d6c..66a3000ce 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -36,6 +36,7 @@ import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NzY3Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511177676", "bodyText": "Style: Most Iceberg error messages use the form Cannot <some action>: <reason> (<workaround>). Consistency here tends to make at least Iceberg errors more readable and easy to consume.", "author": "rdblue", "createdAt": "2020-10-23T22:13:03Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwNjM0NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512006345", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-10-26T14:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NzY3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex eb5cea10a..8e88207aa 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,11 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.lang.reflect.Method;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODcxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178717", "bodyText": "I think this should throw NoSuchTableException if the existing metadata is not null because the table was deleted under the reference. You'll probably want to follow the same behavior as the Hive catalog.", "author": "rdblue", "createdAt": "2020-10-23T22:16:53Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex eb5cea10a..8e88207aa 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,11 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.lang.reflect.Method;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODkyMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178920", "bodyText": "Doesn't look like the format here is quite correct. Missing a space?", "author": "rdblue", "createdAt": "2020-10-23T22:17:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxMzc5MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512013791", "bodyText": "good eye, the first char of the applicationId is a newline. I've put no space between commit and %s to not have extra trailing whitespace in message.\nAlso note that the handling of commit messages in nessie is still fairly primitive. This should get replaced by a structured object in the near future.", "author": "rymurr", "createdAt": "2020-10-26T14:42:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODkyMA=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex eb5cea10a..8e88207aa 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,11 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.lang.reflect.Method;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTA2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179065", "bodyText": "Is this right for NotFoundException? Iceberg will retry failed commits.", "author": "rdblue", "createdAt": "2020-10-23T22:18:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxOTY2MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512019660", "bodyText": "good eye, cleaned up exception message and handled throwing better", "author": "rymurr", "createdAt": "2020-10-26T14:49:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTA2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex eb5cea10a..8e88207aa 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,11 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.lang.reflect.Method;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTIzNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179235", "bodyText": "You can use the DynFields helpers to do this a bit more easily.", "author": "rdblue", "createdAt": "2020-10-23T22:18:52Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new CommitFailedException(ex, \"failed\");\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {\n+    try {\n+      if (sparkConfMethod == null) {\n+        Class sparkEnvClazz = Class.forName(\"org.apache.spark.SparkEnv\");\n+        sparkEnvMethod = sparkEnvClazz.getMethod(\"get\");\n+        Class sparkConfClazz = Class.forName(\"org.apache.spark.SparkConf\");\n+        sparkConfMethod = sparkEnvClazz.getMethod(\"conf\");\n+        appIdMethod = sparkConfClazz.getMethod(\"getAppId\");", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAyODUyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512028521", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-10-26T15:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTIzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex eb5cea10a..8e88207aa 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,11 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.lang.reflect.Method;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MDI0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511180243", "bodyText": "We prefer using AssertHelpers.assertThrows so that state after the exception was thrown can be validated. For example, testing catalog.createTable(invalid) would not only check ValidationException but also verify that the table was not created.", "author": "rdblue", "createdAt": "2020-10-23T22:22:45Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestParsedTableIdentifier {\n+\n+\n+  @Test\n+  public void noMarkings() {\n+    String path = \"foo\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(path, pti.getTableIdentifier().name());\n+    Assert.assertNull(pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test\n+  public void branchOnly() {\n+    String path = \"foo@bar\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(\"foo\", pti.getTableIdentifier().name());\n+    Assert.assertEquals(\"bar\", pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void timestampOnly() {\n+    String path = \"foo#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void branchAndTimestamp() {\n+    String path = \"foo@bar#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAzMzY5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512033695", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-10-26T15:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MDI0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java\nindex 05ecb4715..d05ae4b8d 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java\n\n@@ -22,6 +22,7 @@ package org.apache.iceberg.nessie;\n import com.dremio.nessie.client.NessieClient;\n import java.util.HashMap;\n import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n import org.junit.Assert;\n import org.junit.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTYxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181610", "bodyText": "Please have a look at #1640, I'd like to standardize how we do this. I do like using type = nessie, so we may want to have a lookup that points to the NessieCatalog implementation.", "author": "rdblue", "createdAt": "2020-10-23T22:27:29Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -103,6 +106,10 @@ protected Catalog buildIcebergCatalog(String name, CaseInsensitiveStringMap opti\n         String warehouseLocation = options.get(\"warehouse\");\n         return new HadoopCatalog(name, conf, warehouseLocation);\n \n+      case \"nessie\":\n+        String defaultBranch = options.getOrDefault(\"nessie_ref\", \"main\");\n+        String nessieUrl = options.get(\"nessie_url\");\n+        return new NessieCatalog(name, conf, defaultBranch, nessieUrl);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java b/spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java\nindex c01410944..e6887a14b 100644\n--- a/spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java\n+++ b/spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java\n\n@@ -106,10 +104,6 @@ public class SparkCatalog implements StagingTableCatalog, org.apache.spark.sql.c\n         String warehouseLocation = options.get(\"warehouse\");\n         return new HadoopCatalog(name, conf, warehouseLocation);\n \n-      case \"nessie\":\n-        String defaultBranch = options.getOrDefault(\"nessie_ref\", \"main\");\n-        String nessieUrl = options.get(\"nessie_url\");\n-        return new NessieCatalog(name, conf, defaultBranch, nessieUrl);\n       default:\n         throw new UnsupportedOperationException(\"Unknown catalog type: \" + catalogType);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTkwOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181909", "bodyText": "Why was this needed?", "author": "rdblue", "createdAt": "2020-10-23T22:28:37Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java", "diffHunk": "@@ -50,6 +50,7 @@ public TestCreateTableAsSelect(String catalogName, String implementation, Map<St\n   @After\n   public void removeTables() {\n     sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0NTYyOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512045629", "bodyText": "The way I was running in the test made it get deleted on the backend nessie server but not in the cached spark context I will clean this up as part of the Spark rework", "author": "rymurr", "createdAt": "2020-10-26T15:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTkwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "da33d558c0f1a283f8315dbea9fba82824dfa600", "chunk": "diff --git a/spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java b/spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java\nindex c66486cca..3ca8c890d 100644\n--- a/spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java\n+++ b/spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java\n\n@@ -50,7 +50,6 @@ public class TestCreateTableAsSelect extends SparkCatalogTestBase {\n   @After\n   public void removeTables() {\n     sql(\"DROP TABLE IF EXISTS %s\", tableName);\n-    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n   }\n \n   @Test\n"}}, {"oid": "da33d558c0f1a283f8315dbea9fba82824dfa600", "url": "https://github.com/apache/iceberg/commit/da33d558c0f1a283f8315dbea9fba82824dfa600", "message": "some more updates for code review", "committedDate": "2020-10-26T18:09:38Z", "type": "forcePushed"}, {"oid": "4ac611f4b827b2216be431c2c28a1e80349b9b60", "url": "https://github.com/apache/iceberg/commit/4ac611f4b827b2216be431c2c28a1e80349b9b60", "message": "fix tests and bump plugin version", "committedDate": "2020-10-30T23:44:33Z", "type": "forcePushed"}, {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372", "url": "https://github.com/apache/iceberg/commit/31ddd6b77be8814008663d1aafdf01e373e1b372", "message": "update to support #1640", "committedDate": "2020-11-05T14:21:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTUwOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r519081508", "bodyText": "For Spark writes, we pass the application ID in through snapshot.summary(): \n  \n    \n      iceberg/spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\n    \n    \n         Line 153\n      in\n      9af545e\n    \n    \n    \n    \n\n        \n          \n           operation.set(\"spark.app.id\", applicationId);", "author": "rdblue", "createdAt": "2020-11-07T02:05:00Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {", "originalCommit": "31ddd6b77be8814008663d1aafdf01e373e1b372", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTc3OTMyMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r519779322", "bodyText": "Ahh, thanks for that. Much cleaner this way.", "author": "rymurr", "createdAt": "2020-11-09T12:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 4d1d98351..5e4181c31 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,8 +26,10 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n"}}, {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58", "url": "https://github.com/apache/iceberg/commit/6eba2838dd053690f7f0e66ed0f3095147465a58", "message": "simpler way to get spark app id", "committedDate": "2020-11-09T12:44:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520813255", "bodyText": "#1640 is in. It uses a no-arg constructor and adds an initialize(String name, Map<String, String> config) method to initialize and configure the catalog. I think you should be able to update this now.\nI'm hoping that this removes the need to make Spark and Flink depend on the new Nessie and Glue modules. We should make sure we have a test suite we can include here that uses Flink and Spark.", "author": "rdblue", "createdAt": "2020-11-10T19:16:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxODQwMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520818403", "bodyText": "This is fixed now, apologies. I fixed the constructor but didn't remove the comment.\nI agree that the Catalog portion of Spark3 should work fine now w/o explicitly adding Nessie (or Glue etc). I believe we still need to update the IcebergSource to handle custom (Iceberg) catalogs right?\nIs the intention to add the new catalogs to the Iceberg shaded jar?", "author": "rymurr", "createdAt": "2020-11-10T19:25:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNDkzNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521614936", "bodyText": "Is the intention to add the new catalogs to the Iceberg shaded jar?\n\nI think it depends. If a catalog pulls in a ton of dependencies and requires updating a lot of the shaded Jar's documentation, then it comes at a high cost. On the other hand, if it uses existing bundled libraries or libraries that can be pulled from the Spark runtime, then it would be easier.\n\nI believe we still need to update the IcebergSource to handle custom (Iceberg) catalogs right?\n\nYes, we will need to come up with a way for IcebergSource to work with custom catalogs. Spark has a way for the source to return a catalog and identifier that is used instead of the source directly. That's a much better model, but the problem is that we don't necessarily know what the catalog should be. And, if we redirect to a catalog, we will need to also have a catalog that can load Hadoop tables from a URI. I think this is more of a follow-up.", "author": "rdblue", "createdAt": "2020-11-11T20:19:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI5ODA1OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526298059", "bodyText": "Which mechanism were you thinking for this? Was it LookupCatalog? That is rather scala-y but it works. I have something basic working along the lines of LookupCatalog but I have some concerns about it. Shall I post a PR as a straw man?", "author": "rymurr", "createdAt": "2020-11-18T17:48:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520814377", "bodyText": "I don't think that any configuration should come from the Hadoop Configuration unless it is used for a Hadoop component, like HadoopFileIO. Can you initialize this from the catalog config passed to initialize?", "author": "rdblue", "createdAt": "2020-11-10T19:18:09Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjU3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822572", "bodyText": "Hey @rdblue these parameters are initialised in the initialize method (I have moved the method up to near the constructor as it was hidden at teh bottom of the class). The initialisation uses the passed options where possible and falls back to Configuration if not found. This is to make it compatible with Spark2/3 IcebergSource. However I am happy to remove this once IcebergSource supports custom catalogs (which I hope to tackle next if its not already being worked on)", "author": "rymurr", "createdAt": "2020-11-10T19:32:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTU2NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521615564", "bodyText": "We support the Hive warehouse property because that's how to set it up in Hive. Since we are introducing new configuration for Nessie, I'd really rather not make it so people can depend on using the Hadoop config. Then we will never be able to get rid of it.", "author": "rdblue", "createdAt": "2020-11-11T20:20:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2ODczMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526068733", "bodyText": "Ok, removed. The consequence of this is the custom catalog work for IcebergSource has to be done before the next release if we want a valid/usable nessie in the release", "author": "rymurr", "createdAt": "2020-11-18T13:02:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNTM2Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520815363", "bodyText": "This error message could easily be incorrect because it doesn't use CONF_NESSIE_REF directly. It assumes the caller did.", "author": "rdblue", "createdAt": "2020-11-10T19:19:45Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816050", "bodyText": "Here as well, I don't think this should pull config from Configuration.", "author": "rdblue", "createdAt": "2020-11-10T19:20:57Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNzk2Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520827966", "bodyText": "re-jigged this and above a little bit to make it clear that the hadoop config is only used as a fallback. Hopefully that is more clear. As stated before I hope to remove Configuration for anything but IO in a further PR.", "author": "rymurr", "createdAt": "2020-11-10T19:41:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTkxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521615910", "bodyText": "Why remove it in a follow-up? I'd be concerned about not remembering and then needing to break behavior later.", "author": "rdblue", "createdAt": "2020-11-11T20:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2OTA3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526069072", "bodyText": "removed later as stated above", "author": "rymurr", "createdAt": "2020-11-18T13:03:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjM2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816362", "bodyText": "Looks like reference must never be null, correct?", "author": "rdblue", "createdAt": "2020-11-10T19:21:32Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyOTA1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520829057", "bodyText": "correct. The only way to return from get is with a valid reference, otherwise an exception would be thrown. Would you prefer an explicit null check here?", "author": "rymurr", "createdAt": "2020-11-10T19:43:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjM2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzE0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817143", "bodyText": "I think it would be helpful for get to have a better name for uses like this. What about findReference or loadReference?", "author": "rdblue", "createdAt": "2020-11-10T19:22:54Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyOTM0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520829341", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T19:43:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzE0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzg2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817861", "bodyText": "How about passing ImmutableMap.of() instead of new HashMap<>()? That avoids unnecessary object creation. Better yet, what about a version of this that doesn't need to pass a map if there isn't one?", "author": "rdblue", "createdAt": "2020-11-10T19:24:13Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzMDU0Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520830542", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T19:45:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzg2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819559", "bodyText": "Is this assuming that the NessieNotFoundException is referring to the ref because the table was loaded just above? Or is that always used for a ref?", "author": "rdblue", "createdAt": "2020-11-10T19:27:11Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNjI0OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520836248", "bodyText": "You are correct NessieNotFoundException  refers to the ref. If the table were deleted it would be a conflict exception. This is similar to comparing the error modes of git if you committed to a non-existent ref compared to a merge conflict in the case of changing files in the repo", "author": "rymurr", "createdAt": "2020-11-10T19:55:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNzEyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520837127", "bodyText": "I am not 100% certain that RuntimeException is the best avenue here, its definitely an unexpected error and in a sense unrecoverable. There are no exceptions referenced in the javadoc so perhaps a log line and returning false is more appropriate?", "author": "rymurr", "createdAt": "2020-11-10T19:57:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNjY1MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521616651", "bodyText": "Yeah, I like logging and returning false.", "author": "rdblue", "createdAt": "2020-11-11T20:22:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA3MDg1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526070852", "bodyText": "done", "author": "rymurr", "createdAt": "2020-11-18T13:06:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTk0Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819942", "bodyText": "Can't this refresh and complete the operation?", "author": "rdblue", "createdAt": "2020-11-10T19:27:49Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0MjcyNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520842724", "bodyText": "correct, now refreshes and tries again", "author": "rymurr", "createdAt": "2020-11-10T20:07:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTk0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDMyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820327", "bodyText": "In this case, just remove the purge. We do that in our catalog as well because we never delete data as a result of a user action. We garbage collect it later.", "author": "rdblue", "createdAt": "2020-11-10T19:28:28Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNzg4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520837887", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-11-10T19:58:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDMyNw=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDQ1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820455", "bodyText": "What is this referring to?", "author": "rdblue", "createdAt": "2020-11-10T19:28:42Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0NDM5OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520844399", "bodyText": "We don't strictly need to refresh immediately after an operation. This generates an extra call to the backend which typically isn't required. We have to do it because tests do require it. Tests tend to switch branches, perform multiple actions and make several conflicting changes in short order in the same jvm so need explicit refresh. Since the api call isn't expensive we have left the refresh in until a better strategy (or better tests) are devised", "author": "rymurr", "createdAt": "2020-11-10T20:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDQ1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjM1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822354", "bodyText": "Util methods seem to be mixed in. I think it may help readability if these were at the bottom, or were static methods in a NessieUtil class.", "author": "rdblue", "createdAt": "2020-11-10T19:31:57Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0NzcxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520847714", "bodyText": "good idea, fixed. Static methods have been moved to a util class and private methods have been moved to the bottom with Override methods grouped above", "author": "rymurr", "createdAt": "2020-11-10T20:16:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjM1NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjc3NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822774", "bodyText": "Is there a more specific name for this? It isn't clear what catalog.getHash() should be.\nAlso, style nit: we avoid using get where a more specific verb would add value.", "author": "rdblue", "createdAt": "2020-11-10T19:32:49Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0ODQ1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520848457", "bodyText": "changed to currentHash. Thoughts? The method returns the current hash as teh catalog understands it.", "author": "rymurr", "createdAt": "2020-11-10T20:17:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjc3NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823402", "bodyText": "Should we create a trait just for listing namespaces that are implicit?", "author": "rdblue", "createdAt": "2020-11-10T19:33:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTA4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520849087", "bodyText": "How do you mean? A new interface that no-ops create, load, drop from SupportsNamespaces?", "author": "rymurr", "createdAt": "2020-11-10T20:19:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMTM3OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520901378", "bodyText": "Just an interface that omits those. All this needs is to list namespaces, not do anything else.\nI guess we can take a closer look if anything else needs this.", "author": "rdblue", "createdAt": "2020-11-10T22:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzczNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823736", "bodyText": "Ignore my comments above, since it looks like you've already added this. Can you merge this with init and the constructors?", "author": "rdblue", "createdAt": "2020-11-10T19:34:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNDM3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520834377", "bodyText": "done :-)", "author": "rymurr", "createdAt": "2020-11-10T19:52:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzczNg=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDA4NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824084", "bodyText": "Nessie URL? In other places, we configure the connection using uri.", "author": "rdblue", "createdAt": "2020-11-10T19:34:56Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTY4Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520849682", "bodyText": "removed the builder and any URL refs I found", "author": "rymurr", "createdAt": "2020-11-10T20:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDA4NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDU5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824595", "bodyText": "This is the default ref, right? Tables can override it. I think that would be a better name if you can use this catalog to load other refs.", "author": "rdblue", "createdAt": "2020-11-10T19:35:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {\n+      this.url = url;\n+      return this;\n+    }\n+\n+    public Builder setRef(String ref) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzMzc3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520833770", "bodyText": "I've deleted the builder as its superfluous after #1640", "author": "rymurr", "createdAt": "2020-11-10T19:51:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDU5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex 7d9b75480..9a67b7588 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -24,27 +24,20 @@ import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n-import com.dremio.nessie.model.ContentsKey;\n-import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n import com.dremio.nessie.model.ImmutableOperations;\n import com.dremio.nessie.model.ImmutablePut;\n import com.dremio.nessie.model.Operations;\n import com.dremio.nessie.model.Reference;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.function.Predicate;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520825564", "bodyText": "If an update doesn't create a snapshot, then this method will return the app ID that committed the last snapshot. That may not be correct. Should we create a class in core to hold this information instead? Then we could set it somewhere in Spark and Flink so you'd always have identifiers without needing to resort to reflection?", "author": "rdblue", "createdAt": "2020-11-10T19:37:21Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private String applicationId() {\n+    String appId = null;\n+    TableMetadata current = current();\n+    if (current != null) {\n+      Snapshot snapshot = current.currentSnapshot();\n+      if (snapshot != null) {\n+        Map<String, String> summary = snapshot.summary();\n+        appId = summary.get(\"spark.app.id\");", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1MjM5OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520852398", "bodyText": "Ahh, good point. Do you mean setting some static state somewhere which holds the current app id? I don't love setting static state, is there a way to tell if the snapshot is the 'correct' snapshot we are looking for?\nWe were just talking today about how to better handle Nessie commit info, perhaps somethign we could discuss tomorrow on the sync call? cc @jacques-n", "author": "rymurr", "createdAt": "2020-11-10T20:25:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMTk5Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520901997", "bodyText": "Maybe we should pass this in through catalog properties?", "author": "rdblue", "createdAt": "2020-11-10T22:02:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzg2OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521617869", "bodyText": "I think we should update our SparkCatalog to pass information into catalogs.", "author": "rdblue", "createdAt": "2020-11-11T20:25:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA3NTczNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526075735", "bodyText": "cool, we can add it to the CaseInsensitiveStrngMap when SparkCatalog is initialised? I am not sure of the effect of changing this map from inside SparkCatalog though, perhaps passing a copy w/ the extra params?", "author": "rymurr", "createdAt": "2020-11-18T13:13:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTE1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539150", "bodyText": "Yeah, we should copy and add it. Let's go forward with this for now and we can fix it in a follow-up.", "author": "rdblue", "createdAt": "2020-11-19T01:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NDE0MTkxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r644141910", "bodyText": "I opened #2664 to address that", "author": "nastra", "createdAt": "2021-06-02T16:39:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 5e4181c31..2db4bbed9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -68,10 +68,6 @@ public class NessieTableOperations extends BaseMetastoreTableOperations {\n \n   @Override\n   protected void doRefresh() {\n-    // break reference with parent (to avoid cross-over refresh)\n-    // TODO, confirm this is correct behavior.\n-    // reference = reference.copy();\n-\n     reference.refresh();\n     String metadataLocation = null;\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNjQ4OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520826489", "bodyText": "What about doing this delete in a finally block if threw is false? That's usually a better way than catching Throwable and wrapping it in a RuntimeException.", "author": "rdblue", "createdAt": "2020-11-10T19:39:03Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1NDIxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520854219", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T20:29:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNjQ4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 5e4181c31..2db4bbed9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -68,10 +68,6 @@ public class NessieTableOperations extends BaseMetastoreTableOperations {\n \n   @Override\n   protected void doRefresh() {\n-    // break reference with parent (to avoid cross-over refresh)\n-    // TODO, confirm this is correct behavior.\n-    // reference = reference.copy();\n-\n     reference.refresh();\n     String metadataLocation = null;\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520828053", "bodyText": "This doesn't seem correct to me. I try to maintain single-table state by catalog, so that all uses of a table stay in sync. I think it would make sense to do the same with refs. If you update a branch by refreshing or committing any table, it should also refresh everything that is related to stay in sync. Otherwise, you're left with the problem of not knowing whether two tables with the same ref are in sync.", "author": "rdblue", "createdAt": "2020-11-10T19:41:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1NTUyNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520855525", "bodyText": "Cool, that makes sense to me. Have removed the comment.", "author": "rymurr", "createdAt": "2020-11-10T20:31:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxODM5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521618396", "bodyText": "@rymurr, do we need to request a refresh for all other tables that use this ref?", "author": "rdblue", "createdAt": "2020-11-11T20:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA5ODcxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526098717", "bodyText": "Yes and no, but the option should at least be there. However I think doing this properly is a bigger question. Whether to refresh depends on the isolation level and the use case.\nCurrently if two tables were modified by a different process on the same branch and an iceberg client, who had both those tables cached, committed to only one then the two tables would be out of sync on that iceberg client. But I think that would be true if they were using Hive or Hadoop also, correct? I think rather than addressing this use case in here it would be better to have a wider discussion on how to handle consistency across iceberg catalogs. Thoughts?", "author": "rymurr", "createdAt": "2020-11-18T13:46:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "e3748801b817a76dc1c71f76904271222c7a5f99", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 5e4181c31..2db4bbed9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -68,10 +68,6 @@ public class NessieTableOperations extends BaseMetastoreTableOperations {\n \n   @Override\n   protected void doRefresh() {\n-    // break reference with parent (to avoid cross-over refresh)\n-    // TODO, confirm this is correct behavior.\n-    // reference = reference.copy();\n-\n     reference.refresh();\n     String metadataLocation = null;\n     try {\n"}}, {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99", "url": "https://github.com/apache/iceberg/commit/e3748801b817a76dc1c71f76904271222c7a5f99", "message": "address code review", "committedDate": "2020-11-10T20:54:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTEzMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899130", "bodyText": "We try to use simpler error messages and avoid referring to specific people, like \"we\" or \"you\". A good rule of thumb is \"Cannot [some action]: [problem[ [(suggestion to fix)]\" or \"Invalid [something]: [problem]\". How about \"Invalid table name: # is not allowed (reference by timestamp is not supported)\"?", "author": "rdblue", "createdAt": "2020-11-10T21:56:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MjQ1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521362452", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-11T13:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTEzMA=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nsimilarity index 60%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nindex 06ba28d0b..780d8944f 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n\n@@ -19,22 +19,19 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import java.time.Instant;\n-import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n \n-public class ParsedTableIdentifier {\n+public class TableReference {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * container class to hold all options in a Nessie table name.\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n    */\n-  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTIxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899217", "bodyText": "Can we use a simpler verb, like parse or parseTableIdentifier? It's wordy to use \"get\" and then a past tense verb.", "author": "rdblue", "createdAt": "2020-11-10T21:56:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    TableIdentifier identifier = TableIdentifier.parse(path);\n+    String reference = properties.get(NessieClient.CONF_NESSIE_REF);\n+    return new ParsedTableIdentifier(identifier, null, reference);\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path, Map<String, String> properties) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2NjM3Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521366373", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-11-11T13:43:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTIxNw=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nsimilarity index 60%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nindex 06ba28d0b..780d8944f 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n\n@@ -19,22 +19,19 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import java.time.Instant;\n-import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n \n-public class ParsedTableIdentifier {\n+public class TableReference {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * container class to hold all options in a Nessie table name.\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n    */\n-  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDQ4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520900487", "bodyText": "I'm wondering if there is a more specific name for this class. Maybe something like TableReference because it has both an identifier and a ref? Or maybe NessieIdentifier? ParsedTableIdentifier doesn't really tell me what is different about this as opposed to TableIdentifier.", "author": "rdblue", "createdAt": "2020-11-10T21:59:10Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2Nzk3OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521367979", "bodyText": "I chose TableReference in the end. I don't love it but its way better than ParsedTableIdentifier. I don't know how to concisely state that its a TableIdentifier tied to a specific Reference. I have updated the javadoc which I hope clarifies it", "author": "rymurr", "createdAt": "2020-11-11T13:45:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDQ4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nsimilarity index 60%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nindex 06ba28d0b..780d8944f 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n\n@@ -19,22 +19,19 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import java.time.Instant;\n-import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n \n-public class ParsedTableIdentifier {\n+public class TableReference {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * container class to hold all options in a Nessie table name.\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n    */\n-  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjcwOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520902708", "bodyText": "Table no longer exists? Or the ref no longer exists?\nAlso, NotFoundException is for files that don't exist. Tables should use NoSuchTableException", "author": "rdblue", "createdAt": "2020-11-10T22:03:39Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Hash;\n+import com.dremio.nessie.model.Reference;\n+import org.apache.iceberg.exceptions.NotFoundException;\n+\n+class UpdateableReference {\n+\n+  private Reference reference;\n+  private final TreeApi client;\n+\n+  UpdateableReference(Reference reference, TreeApi client) {\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  public boolean refresh() {\n+    if (reference instanceof Hash) {\n+      return false;\n+    }\n+    Reference oldReference = reference;\n+    try {\n+      reference = client.getReferenceByName(reference.getName());\n+    } catch (NessieNotFoundException e) {\n+      throw new NotFoundException(e, \"Failure refreshing data, table no longer exists.\");", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NzI2Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521377267", "bodyText": "fixed the comment and simplified the exception handling", "author": "rymurr", "createdAt": "2020-11-11T14:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjcwOA=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java b/nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java\nindex 13177d4e3..133f787fb 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java\n\n@@ -24,7 +24,6 @@ import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Branch;\n import com.dremio.nessie.model.Hash;\n import com.dremio.nessie.model.Reference;\n-import org.apache.iceberg.exceptions.NotFoundException;\n \n class UpdateableReference {\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMzc1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520903750", "bodyText": "Most tests use @Rule TemporaryFolder temp so that JUnit handles temp lifecycle. I'd recommend doing that here, too.", "author": "rdblue", "createdAt": "2020-11-10T22:05:48Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3Nzk0OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521377949", "bodyText": "agreed! Bizarre that wasn't used in the first place :-)", "author": "rymurr", "createdAt": "2020-11-11T14:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMzc1MA=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\nindex 9f4e6cb79..24e50cd67 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n\n@@ -26,8 +26,7 @@ import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Branch;\n import com.dremio.nessie.model.Reference;\n-import java.io.File;\n-import java.nio.file.attribute.PosixFilePermissions;\n+import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNDY2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520904662", "bodyText": "This looks like it should have a more specific name because it returns the metadata location for a table.", "author": "rdblue", "createdAt": "2020-11-10T22:07:45Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    catalog.close();\n+    client.close();\n+    catalog = null;\n+    client = null;\n+    hadoopConfig = null;\n+  }\n+\n+  @AfterClass\n+  public static void destroy() throws Exception {\n+    tempDir.delete();\n+  }\n+\n+  static String getContent(NessieCatalog catalog, TableIdentifier tableIdentifier) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3ODkyNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521378924", "bodyText": "fixed, contents is an internal nessie name for the objects stored in the Nessie object database. Changed it to content held for iceberg", "author": "rymurr", "createdAt": "2020-11-11T14:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNDY2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\nindex 9f4e6cb79..24e50cd67 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n\n@@ -26,8 +26,7 @@ import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Branch;\n import com.dremio.nessie.model.Reference;\n-import java.io.File;\n-import java.nio.file.attribute.PosixFilePermissions;\n+import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNTA2Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520905063", "bodyText": "Looks like this could just always pass hash.", "author": "rdblue", "createdAt": "2020-11-10T22:08:31Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3OTU4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521379587", "bodyText": ":-) i think you are correct", "author": "rymurr", "createdAt": "2020-11-11T14:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNTA2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\nindex 9f4e6cb79..24e50cd67 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java\n\n@@ -26,8 +26,7 @@ import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Branch;\n import com.dremio.nessie.model.Reference;\n-import java.io.File;\n-import java.nio.file.attribute.PosixFilePermissions;\n+import java.io.IOException;\n import java.util.ArrayList;\n import java.util.List;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520906352", "bodyText": "I prefer to separate tests into distinct cases. It looks like this combines testRename with testListTables. Combining test cases into a single method causes failures to prevent other tests from running, which makes the whole suite harder to work with.\nIt is also a lot easier to spot missing test cases and add new ones when tests are separate. I'd recommend taking a look at most of these test suites.\nThat said, I think that you'll be the primary reviewers here so in the end it is mostly up to you what conventions you want to maintain.", "author": "rdblue", "createdAt": "2020-11-10T22:11:02Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.util.List;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalog extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-catalog-branch\";\n+\n+  public TestCatalog() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void test() {\n+    createTable(TableIdentifier.of(\"foo\", \"bar\"));\n+    List<TableIdentifier> tables = catalog.listTables(Namespace.of(\"foo\"));\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"bar\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.renameTable(TableIdentifier.of(\"foo\", \"bar\"), TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(null);\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"baz\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.dropTable(TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(Namespace.empty());\n+    Assert.assertTrue(tables.isEmpty());", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4NTcyNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521385726", "bodyText": "I prefer splitting as well. I have split into 3 tests, its a little more cluttered this way but let me know what you think, happy to go either way.", "author": "rymurr", "createdAt": "2020-11-11T14:13:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTE5Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526541193", "bodyText": "Looks good.", "author": "rdblue", "createdAt": "2020-11-19T01:56:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java\nindex 403d318de..d68a95d64 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java\n\n@@ -34,19 +34,29 @@ public class TestCatalog extends BaseTestIceberg {\n   }\n \n   @Test\n-  public void test() {\n+  public void testList() {\n     createTable(TableIdentifier.of(\"foo\", \"bar\"));\n     List<TableIdentifier> tables = catalog.listTables(Namespace.of(\"foo\"));\n     Assert.assertEquals(1, tables.size());\n     Assert.assertEquals(\"bar\", tables.get(0).name());\n     Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    createTable(TableIdentifier.of(\"foo\", \"bar\"));\n     catalog.renameTable(TableIdentifier.of(\"foo\", \"bar\"), TableIdentifier.of(\"foo\", \"baz\"));\n-    tables = catalog.listTables(null);\n+    List<TableIdentifier> tables = catalog.listTables(null);\n     Assert.assertEquals(1, tables.size());\n     Assert.assertEquals(\"baz\", tables.get(0).name());\n     Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+  }\n+\n+  @Test\n+  public void testDelete() {\n+    createTable(TableIdentifier.of(\"foo\", \"baz\"));\n     catalog.dropTable(TableIdentifier.of(\"foo\", \"baz\"));\n-    tables = catalog.listTables(Namespace.empty());\n+    List<TableIdentifier> tables = catalog.listTables(Namespace.empty());\n     Assert.assertTrue(tables.isEmpty());\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzg3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520907870", "bodyText": "What is this suppressing?", "author": "rdblue", "createdAt": "2020-11-10T22:14:01Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4NjY4MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521386680", "bodyText": "absolutely nothing! It got carried over from the nessie repo (which has militant checkstyle rules) and I forgot to remove it. Gone now.", "author": "rymurr", "createdAt": "2020-11-11T14:15:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzg3MA=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\nindex 04d414069..f95b6b352 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n\n@@ -35,6 +35,7 @@ import java.util.stream.Collectors;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecordBuilder;\n import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DataFiles;\n import org.apache.iceberg.Files;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwODUxOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520908518", "bodyText": "Can you use AssertHelpers.assertThrows instead? That way, you can add assertions after the exception to check other things, like that the table has not been modified.", "author": "rdblue", "createdAt": "2020-11-10T22:15:19Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location1)\n+                              .withFileSizeInBytes(Files.localInput(location2).getLength())\n+                              .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location2)\n+                              .withFileSizeInBytes(Files.localInput(location1).getLength())\n+                              .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+                                  .current()\n+                                  .metadataFileLocation()\n+                                  .replace(\"file:\", \"\"))\n+                             .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test(expected = CommitFailedException.class)", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4ODE2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521388161", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-11T14:17:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwODUxOA=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\nindex 04d414069..f95b6b352 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n\n@@ -35,6 +35,7 @@ import java.util.stream.Collectors;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecordBuilder;\n import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DataFiles;\n import org.apache.iceberg.Files;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTExMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909112", "bodyText": "We've moved the other implementations to create a FileIO at the catalog level and pass it into TableOperations. You may want to do the same. Also, you'll probably want to update to use the same logic so that the implementation can be overridden dynamically.", "author": "rdblue", "createdAt": "2020-11-10T22:16:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } finally {\n+      if (threw) {\n+        io().deleteFile(newMetadataLocation);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5MTUzMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521391533", "bodyText": "thanks for the pointer, copied the Hive Catalog now.", "author": "rymurr", "createdAt": "2020-11-11T14:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTExMg=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 2db4bbed9..278a74117 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -27,14 +27,11 @@ import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.TableMetadata;\n-import org.apache.iceberg.common.DynFields;\n import org.apache.iceberg.exceptions.CommitFailedException;\n import org.apache.iceberg.exceptions.NoSuchTableException;\n-import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTg0Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909846", "bodyText": "Does this need properties? The only thing that is used is an optional ref. That could be passed by itself rather than as a map.", "author": "rdblue", "createdAt": "2020-11-10T22:18:10Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5ODE2Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521398167", "bodyText": "correct, even further the ref isn't really needed. Thanks for pointing that out, much cleaner now.", "author": "rymurr", "createdAt": "2020-11-11T14:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTg0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nsimilarity index 60%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nindex 06ba28d0b..780d8944f 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n\n@@ -19,22 +19,19 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import java.time.Instant;\n-import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n \n-public class ParsedTableIdentifier {\n+public class TableReference {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * container class to hold all options in a Nessie table name.\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n    */\n-  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxMDIwNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520910207", "bodyText": "We typically use a continuation indent of 2 indents / 4 spaces, rather than aligning with the previous method call.", "author": "rdblue", "createdAt": "2020-11-10T22:19:00Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5ODYzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521398634", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-11T14:32:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxMDIwNw=="}], "type": "inlineReview", "revised_code": {"commit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\nindex 04d414069..f95b6b352 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n\n@@ -35,6 +35,7 @@ import java.util.stream.Collectors;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecordBuilder;\n import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DataFiles;\n import org.apache.iceberg.Files;\n"}}, {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "url": "https://github.com/apache/iceberg/commit/b46dbf7a2599e7bd8cea384cd968366ce4767382", "message": "respond to code review comments", "committedDate": "2020-11-18T13:52:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526529343", "bodyText": "Minor: It seems strange to me to default this in the catalog rather than in the tests. I would probably use a precondition to validate it isn't null instead.", "author": "rdblue", "createdAt": "2020-11-19T01:19:41Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTU3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527671572", "bodyText": "Just to make sure I am looking at the right line of the diff: you mean the name right? I have updated the test to set the catalog name to nessie but I was following the other Catalog impls which set the name to eg 'hive' or 'hadoop' if name is unset.", "author": "rymurr", "createdAt": "2020-11-20T12:53:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyMjc0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527822741", "bodyText": "If that's what the other catalogs do, then that seems reasonable. I think we eventually want to guarantee that there is always a name, but there are probably cases where we didn't have one. We can look into that separately.", "author": "rdblue", "createdAt": "2020-11-20T16:50:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526530130", "bodyText": "Other catalogs use \"warehouse\" instead of a catalog-specific property. It would be slightly better for consistency to do the same, although it is fine this way. If the NessieClient is expecting config like this, it may well be more consistent for Nessie users to always use the full namespaced names.\nJust be aware that this will require properties like spark.sql.catalog.some_name.nessie.warehouse.dir=...", "author": "rdblue", "createdAt": "2020-11-19T01:22:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3NTMyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527675321", "bodyText": "I am not sure I understand what you mean by 'warehouse' here. The original version of this patch used the same as the hadoop catalog (conf.get(\"fs.defaultFS\") + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE) but I believe a change was suggested/requested. I personally would much prefer a standard approach than the custom nessie directory. Do you prefer using the Hadoop style one above or the CatalogProperties.WAREHOUSE_LOCATION one?\nI have switched in the most recent patch to using WAREHOUSE_LOCATION", "author": "rymurr", "createdAt": "2020-11-20T13:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyMzgzMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527823831", "bodyText": "Yeah, I meant using CatalogProperties.WAREHOUSE_LOCATION. That's what the other catalogs use for a config property.", "author": "rdblue", "createdAt": "2020-11-20T16:52:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTIxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526531219", "bodyText": "Similar, it may be easier to configure using just \"ref\".", "author": "rdblue", "createdAt": "2020-11-19T01:25:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3NjkyNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527676926", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T13:03:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTIxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMzU2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526533562", "bodyText": "You can replace this with Tasks:\nTasks.foreach(identifier)\n    .retry(5)\n    .stopRetryOn(NessieNotFoundException.class)\n    .throwFailureWhenFinished()\n    .run(this::dropTableInner)\nTasks is pretty flexible and allows you to configure exponential backoff, whether to retry on all exceptions but a known list (stopRetryOn), whether to retry on specific exceptions (onlyRetryOn), and set up callbacks (onFailure).\nIt helps us avoid logic like this everywhere.", "author": "rdblue", "createdAt": "2020-11-19T01:32:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3OTkxMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527679913", "bodyText": "\ud83d\udc4d I have updated to use Tasks. Fun class :-)", "author": "rymurr", "createdAt": "2020-11-20T13:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMzU2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534372", "bodyText": "I'd prefer an error message with more context, like Failed to rename X to Y. There's no guarantee that the error message from Nessie has that information. It probably has information about the state of the ref, rather than what was being attempted.", "author": "rdblue", "createdAt": "2020-11-19T01:35:28Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY5NzQxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527697410", "bodyText": "yup. Not sure why I was being lazy. Fixed now", "author": "rymurr", "createdAt": "2020-11-20T13:41:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDc5NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534794", "bodyText": "This can't happen if the to table has already been dropped? Seems like this assumes that the NessieNotFoundException refers to the ref.\nMaybe we're guaranteed that the ref hasn't changed because this isn't a NessieConflictException? If so, a comment would help.", "author": "rdblue", "createdAt": "2020-11-19T01:36:56Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcwODM0OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527708348", "bodyText": "If to table has already been dropped and our ref wasn't up to date we would get a conflict exception. This is similar to a merge conflict in git: the table has been changed by someone else so there is a conflict exception. The fact that the change is a delete is irrelevant nessie, same error would be thrown if the table had been appended to or the schema were to be changed.\nI have opened projectnessie/nessie#477 to track the lack of documentation on the exception classes. In the meantime I have added a comment here", "author": "rymurr", "createdAt": "2020-11-20T13:59:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDc5NA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNTEwNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526535107", "bodyText": "Why is this public?\nNot a blocker, just normal code lint.", "author": "rdblue", "createdAt": "2020-11-19T01:37:43Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcwOTgyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527709821", "bodyText": "\ud83e\udd14 I expect there was a reason at some point. It is only used by tests so I have made it package private for now. The original intention was likely to expose CRUD ops on branches/tags to the user but I think a more structured interface would be better for that", "author": "rymurr", "createdAt": "2020-11-20T14:02:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNTEwNw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjI3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536270", "bodyText": "We may want to let the original exception propagate instead of throwing a RuntimeException so that people working with the table can take action if the ref is gone. I'm not really sure what the right thing is here.", "author": "rdblue", "createdAt": "2020-11-19T01:41:18Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxMzUwNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527713506", "bodyText": "I would normally agree but NessieNotFoundException is a checked exception and I don't want to add that throws clause to the interface. Is there a more specialised unchecked exception that you think would suit?\nIf it helps the likelihood of this throwing should be very low in real life. Typically a user/service would own their branches and deleting a branch when someone else is actively working on it would be an organisational issue rather than something that should be handled in code. An analogy in git would be someone deleting your branch which is an active PR (without closing the PR).", "author": "rymurr", "createdAt": "2020-11-20T14:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjI3MA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 278a74117..eb5cea10a 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,12 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.util.Map;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n-import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.exceptions.CommitFailedException;\n-import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjY5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536690", "bodyText": "NessieTableOperations calls unwrap instead of using instanceof.", "author": "rdblue", "createdAt": "2020-11-19T01:42:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() throws NessieNotFoundException {\n+    reference.refresh();\n+  }\n+\n+  public String currentHash() {\n+    return reference.getHash();\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(NessieUtil.toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxNDgzNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527714837", "bodyText": "nice catch", "author": "rymurr", "createdAt": "2020-11-20T14:10:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjY5MA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\nindex c63d22ec5..6f296c2b9 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java\n\n@@ -21,25 +21,31 @@ package org.apache.iceberg.nessie;\n \n import com.dremio.nessie.api.TreeApi;\n import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableDelete;\n-import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n import com.dremio.nessie.model.ImmutablePut;\n-import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.MultiContents;\n import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n+import java.util.function.Predicate;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n-import org.apache.hadoop.conf.Configurable;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreCatalog;\n-import org.apache.iceberg.CatalogProperties;\n-import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.SupportsNamespaces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzODY5Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526538697", "bodyText": "CommitFailedException is used to trigger a table refresh and a retry. Throwing it for NessieConflictException seems correct to me, but reading the error messages makes me less sure.\nIf the ref is a tag, then we don't want to retry because it can't be updated, right? In that case, this should throw some other exception because the table is read-only.\nIf the ref is a branch, then the ref should be refreshed using the normal retry logic so everything looks good. doRefresh will update the ref and then update the table content.", "author": "rdblue", "createdAt": "2020-11-19T01:48:53Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxNjc2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527716765", "bodyText": "Yep! exactly! On line 87 we do reference.checkMutable() which will throw IllegalArgumentException if its a tag. So by the time we commit we know its a branch. I have cleaned up the erroneous error msg.", "author": "rymurr", "createdAt": "2020-11-20T14:13:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzODY5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 278a74117..eb5cea10a 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,12 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.util.Map;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n-import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.exceptions.CommitFailedException;\n-import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTAwMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539000", "bodyText": "Like above, do we know this is the ref because the current ref already loaded the table?", "author": "rdblue", "createdAt": "2020-11-19T01:49:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMDg2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527720861", "bodyText": "I think my comment above covers this as well. The only sensible way this could ever throw is if someone deleted your branch between when you loaded the table and when you tried to commit.\nI have made that a bit more explicit in the comment", "author": "rymurr", "createdAt": "2020-11-20T14:17:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTAwMA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\nindex 278a74117..eb5cea10a 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java\n\n@@ -26,12 +26,12 @@ import com.dremio.nessie.model.Contents;\n import com.dremio.nessie.model.ContentsKey;\n import com.dremio.nessie.model.IcebergTable;\n import com.dremio.nessie.model.ImmutableIcebergTable;\n-import java.util.Map;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n import org.apache.iceberg.BaseMetastoreTableOperations;\n-import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.exceptions.CommitFailedException;\n-import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTcwNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539705", "bodyText": "Nit: We usually omit get from getter method names because it doesn't add value and looks weird in other languages (like Scala and Kotlin).", "author": "rdblue", "createdAt": "2020-11-19T01:51:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMTY0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527721641", "bodyText": "fixed. The pythonista in me doesn't like get either :-)", "author": "rymurr", "createdAt": "2020-11-20T14:18:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTcwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java b/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nsimilarity index 65%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nindex 780d8944f..0b53be048 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n\n@@ -20,18 +20,19 @@\n package org.apache.iceberg.nessie;\n \n import java.time.Instant;\n+import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n \n-public class TableReference {\n+public class ParsedTableIdentifier {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   * container class to hold all options in a Nessie table name.\n    */\n-  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526540334", "bodyText": "Looks like this check is the only one needed for #. It doesn't matter if the identifier also contains @ and it also doesn't matter if there is more than one #.", "author": "rdblue", "createdAt": "2020-11-19T01:53:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(TableIdentifier path) {\n+    TableReference pti = parse(path.name());\n+    return new TableReference(TableIdentifier.of(path.namespace(), pti.getTableIdentifier().name()),\n+        pti.getTimestamp(),\n+        pti.getReference());\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(String path) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new TableReference(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMjYyOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527722629", "bodyText": "If it doesn't matter much to you I would like to leave it in. I will be adding timestamp support here very soon.\nHappy to remove it till then if you prefer too.", "author": "rymurr", "createdAt": "2020-11-20T14:20:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyNjU0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527826541", "bodyText": "Sounds fine to me if you're going to update this soon. I just wanted to make sure we didn't have an unnecessarily long method.", "author": "rdblue", "createdAt": "2020-11-20T16:55:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java b/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nsimilarity index 65%\nrename from nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\nrename to nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\nindex 780d8944f..0b53be048 100644\n--- a/nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java\n+++ b/nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java\n\n@@ -20,18 +20,19 @@\n package org.apache.iceberg.nessie;\n \n import java.time.Instant;\n+import java.util.Map;\n import org.apache.iceberg.catalog.TableIdentifier;\n \n-public class TableReference {\n+public class ParsedTableIdentifier {\n \n   private final TableIdentifier tableIdentifier;\n   private final Instant timestamp;\n   private final String reference;\n \n   /**\n-   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   * container class to hold all options in a Nessie table name.\n    */\n-  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n     this.tableIdentifier = tableIdentifier;\n     this.timestamp = timestamp;\n     this.reference = reference;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526541498", "bodyText": "Isn't it automatically refreshed because it is shared with the NessieTableOperations?", "author": "rdblue", "createdAt": "2020-11-19T01:57:15Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NTM3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527755370", "bodyText": "References aren't refreshed on commits. So while the ref is shared its out of date everywhere.\nThis normally isn't a problem but since in this test we are creating a branch off the current state of the 'test-branch-hash' branch we explicitly need the up to date hash. Note: in the TableOperations the metadata would be up to date so querying the data would work fine. In normal practice the ref being out of date will only mean we don't get any updates from other users (not the recommended usage pattern) or we would get a merge conflict if we updated the table after someone else has.", "author": "rymurr", "createdAt": "2020-11-20T15:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyOTIzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527829234", "bodyText": "Hm. The commit is going to trigger a refresh on the table the next time its metadata is accessed. That is usually right away because operations will read the latest metadata to clean up unused files. For Nessie, doRefresh is going to update the shared ref. That's why I thought this was redundant. I guess there could be cases where the metadata isn't accessed yet and you do need the refresh.\nNot a big deal, so let's not worry about it.", "author": "rdblue", "createdAt": "2020-11-20T16:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nsimilarity index 61%\nrename from nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\nrename to nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nindex 93dedbdf3..0d7298c61 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\n\n@@ -19,7 +19,6 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import org.apache.iceberg.Table;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjI5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542290", "bodyText": "Using the table name \"foo.bar\" is fine, but using foobar as a variable name makes the test harder to read because it isn't obvious what metadataLocation(catalog, foobar) does exactly. If foobar is a Namespace, then it would be the default location for a table, for example. It would be easier to read if this were something more descriptive, like tableIdent.", "author": "rdblue", "createdAt": "2020-11-19T01:59:42Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NjM3Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527756373", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-20T15:11:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjI5MA=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nsimilarity index 61%\nrename from nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\nrename to nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nindex 93dedbdf3..0d7298c61 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\n\n@@ -19,7 +19,6 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import org.apache.iceberg.Table;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjQ5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542496", "bodyText": "Similar, it would be good to name this table for clarity later on in this long test method.", "author": "rdblue", "createdAt": "2020-11-19T02:00:18Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NjUwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527756502", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T15:11:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjQ5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nsimilarity index 61%\nrename from nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\nrename to nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nindex 93dedbdf3..0d7298c61 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\n\n@@ -19,7 +19,6 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import org.apache.iceberg.Table;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzAwMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543001", "bodyText": "This is another test I think could be broken into distinct cases with a @Before to set up the default branch and table.", "author": "rdblue", "createdAt": "2020-11-19T02:01:46Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+\n+    bar.updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+\n+    // metadata location changed no longer matches\n+    Assert.assertNotEquals(metadataLocation(catalog, foobar), metadataLocation(newCatalog, foobar));\n+\n+    // points to the previous metadata location\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(newCatalog, foobar));\n+\n+\n+    String mainHash = tree.getReferenceByName(BRANCH).getHash();\n+    // catalog created with ref and no hash points to same catalog as above\n+    NessieCatalog refCatalog = initCatalog(\"test\");\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar), metadataLocation(refCatalog, foobar));\n+    // catalog created with ref and hash points to\n+    NessieCatalog refHashCatalog = initCatalog(mainHash);\n+    Assert.assertEquals(metadataLocation(catalog, foobar), metadataLocation(refHashCatalog, foobar));\n+\n+    // asking for table@branch gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@test\")));\n+    // asking for table@branch#hash gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(catalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@\" + mainHash)));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MDMxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527760314", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T15:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzAwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nsimilarity index 61%\nrename from nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\nrename to nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\nindex 93dedbdf3..0d7298c61 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestTestBranchHash.java\n\n@@ -19,7 +19,6 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n import org.apache.iceberg.Table;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543532", "bodyText": "Context helpers would make this test more readable and would be helpful if it ever fails.", "author": "rdblue", "createdAt": "2020-11-19T02:03:23Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    Table bar = createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(newCatalog, foobaz), metadataLocation(catalog, foobaz));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTYyOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849628", "bodyText": "ive re-worked this test class. Let me know if thats easier to read", "author": "rymurr", "createdAt": "2020-11-20T17:28:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDAwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914002", "bodyText": "Looks a lot better!", "author": "rdblue", "createdAt": "2020-11-23T18:33:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\nindex fe0a62adb..b58ccbe2d 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n\n@@ -19,10 +19,8 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n-import com.dremio.nessie.model.Branch;\n import org.apache.iceberg.Table;\n import org.apache.iceberg.catalog.TableIdentifier;\n import org.apache.iceberg.types.Types;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0Mzc0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543743", "bodyText": "What does this suppress?", "author": "rdblue", "createdAt": "2020-11-19T02:04:05Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTc4OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849789", "bodyText": "leftover from strict checkstyle checks, removed", "author": "rymurr", "createdAt": "2020-11-20T17:28:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0Mzc0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\nindex fe0a62adb..b58ccbe2d 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n\n@@ -19,10 +19,8 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n-import com.dremio.nessie.model.Branch;\n import org.apache.iceberg.Table;\n import org.apache.iceberg.catalog.TableIdentifier;\n import org.apache.iceberg.types.Types;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDAxNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544015", "bodyText": "What is the main difference between this suite and the branch suite above? Seems very similar to me, so I think I've missed the point. Smaller test cases that are well named would help.", "author": "rdblue", "createdAt": "2020-11-19T02:04:50Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTkyMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849920", "bodyText": "effectively none, removed", "author": "rymurr", "createdAt": "2020-11-20T17:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDAxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\nindex fe0a62adb..b58ccbe2d 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java\n\n@@ -19,10 +19,8 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n-import com.dremio.nessie.model.Branch;\n import org.apache.iceberg.Table;\n import org.apache.iceberg.catalog.TableIdentifier;\n import org.apache.iceberg.types.Types;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDI4Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544282", "bodyText": "Nit: println usage.", "author": "rdblue", "createdAt": "2020-11-19T02:05:35Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg1MDA0Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527850047", "bodyText": "removed", "author": "rymurr", "createdAt": "2020-11-20T17:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDI4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\nindex a831d952a..46ba31a02 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\n\n@@ -19,10 +19,8 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n-import com.dremio.nessie.model.Branch;\n import org.apache.iceberg.catalog.TableIdentifier;\n import org.apache.iceberg.types.Types;\n import org.junit.Assert;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDQ3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544477", "bodyText": "This is another test that doesn't seem very different from the others. Can these be combined into a single suite with good test case names that calls out what is unique about each test?", "author": "rdblue", "createdAt": "2020-11-19T02:06:22Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    forwardCatalog.refresh();\n+    tree.assignBranch(\"main\",\n+        tree.getReferenceByName(\"main\").getHash(),\n+        Branch.of(\"main\", forwardCatalog.currentHash()));\n+\n+    catalog.refresh();\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobar),\n+                            metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobaz),\n+                            metadataLocation(catalog, foobaz));\n+\n+    catalog.dropTable(foobar);\n+    catalog.dropTable(foobaz);\n+    tree.deleteBranch(\"FORWARD\", tree.getReferenceByName(\"FORWARD\").getHash());", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg1MDE0NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527850145", "bodyText": "agreed, deleted", "author": "rymurr", "createdAt": "2020-11-20T17:29:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDQ3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\nindex a831d952a..46ba31a02 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java\n\n@@ -19,10 +19,8 @@\n \n package org.apache.iceberg.nessie;\n \n-import com.dremio.nessie.client.NessieClient;\n import com.dremio.nessie.error.NessieConflictException;\n import com.dremio.nessie.error.NessieNotFoundException;\n-import com.dremio.nessie.model.Branch;\n import org.apache.iceberg.catalog.TableIdentifier;\n import org.apache.iceberg.types.Types;\n import org.junit.Assert;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526545279", "bodyText": "Could this be refactored to be smaller and use a couple of util functions? Something like addFile(table, filename) could help.", "author": "rdblue", "createdAt": "2020-11-19T02:08:46Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg4NTg1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527885857", "bodyText": "Can do, I original copied this from one of the catalog tests. I believe those are all package private static methods. Do you know of any test class that has these utils available publicly?", "author": "rymurr", "createdAt": "2020-11-20T18:11:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNTM1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528915354", "bodyText": "I think there's something in Flink, but this is an area where we can generally improve tests.", "author": "rdblue", "createdAt": "2020-11-23T18:35:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\nindex f95b6b352..0772709da 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n\n@@ -35,7 +35,6 @@ import java.util.stream.Collectors;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecordBuilder;\n import org.apache.hadoop.fs.Path;\n-import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DataFiles;\n import org.apache.iceberg.Files;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526546123", "bodyText": "Do you have a test for concurrent writes to the same table from multiple catalogs? That would be good with two cases: two tables that share the same ref (loaded by the same catalog) and two tables that were loaded by different catalogs and have separate refs.", "author": "rdblue", "createdAt": "2020-11-19T02:11:22Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location1)\n+        .withFileSizeInBytes(Files.localInput(location2).getLength())\n+        .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location2)\n+        .withFileSizeInBytes(Files.localInput(location1).getLength())\n+        .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+            .current()\n+            .metadataFileLocation()\n+            .replace(\"file:\", \"\"))\n+        .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test\n+  public void testFailure() throws NessieNotFoundException, NessieConflictException {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    Branch branch = (Branch) client.getTreeApi().getReferenceByName(BRANCH);\n+\n+    IcebergTable table = client.getContentsApi().getContents(KEY, BRANCH).unwrap(IcebergTable.class).get();\n+\n+    client.getContentsApi().setContents(KEY, branch.getName(), branch.getHash(), \"\",\n+        IcebergTable.of(\"dummytable.metadata.json\"));\n+\n+    AssertHelpers.assertThrows(\"Update schema fails with conflict exception, ref not up to date\",\n+        CommitFailedException.class,\n+        () -> icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit());", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg4NDk1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527884954", "bodyText": "TestCatalogBranch does this for the positive case (ie concurrent changes that succeed) and internal nessie for teh negative case. I have added a negative case to TestCatalogBranch also. (and renamed the class)", "author": "rymurr", "createdAt": "2020-11-20T18:09:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkxOTUzOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527919539", "bodyText": "Cleaned this up a bit more. We do both tests you suggested, thought it may not be clear its happening. Let me know if the extra comments aren't enough.", "author": "rymurr", "createdAt": "2020-11-20T19:16:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw=="}], "type": "inlineReview", "revised_code": {"commit": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "chunk": "diff --git a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\nindex f95b6b352..0772709da 100644\n--- a/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n+++ b/nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java\n\n@@ -35,7 +35,6 @@ import java.util.stream.Collectors;\n import org.apache.avro.generic.GenericData;\n import org.apache.avro.generic.GenericRecordBuilder;\n import org.apache.hadoop.fs.Path;\n-import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DataFiles;\n import org.apache.iceberg.Files;\n"}}, {"oid": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "url": "https://github.com/apache/iceberg/commit/52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "message": "initial commit of nessie:\n\n* nessie catalog/table ops\n* modifications to catalog/source for spark\n* add nessie to tests\n\nleft to do:\n* support namespaces\n* start/stop nessie as part of gradle build", "committedDate": "2020-11-20T12:57:08Z", "type": "commit"}, {"oid": "dd7278d84c2d2c01c15192420f8b50410374308c", "url": "https://github.com/apache/iceberg/commit/dd7278d84c2d2c01c15192420f8b50410374308c", "message": "working nessie\n\n* remove namespace for nessie, handled implicitly\n* add gradle plugin", "committedDate": "2020-11-20T12:57:09Z", "type": "commit"}, {"oid": "a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "url": "https://github.com/apache/iceberg/commit/a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "message": "fix versions", "committedDate": "2020-11-20T12:57:10Z", "type": "commit"}, {"oid": "a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "url": "https://github.com/apache/iceberg/commit/a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "message": "tidy up", "committedDate": "2020-11-20T12:57:11Z", "type": "commit"}, {"oid": "0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "url": "https://github.com/apache/iceberg/commit/0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "message": "fix up quarkus plugin", "committedDate": "2020-11-20T12:57:12Z", "type": "commit"}, {"oid": "491e7c2018385169a388e582c6625936ffd82de6", "url": "https://github.com/apache/iceberg/commit/491e7c2018385169a388e582c6625936ffd82de6", "message": "code review comments", "committedDate": "2020-11-20T12:57:13Z", "type": "commit"}, {"oid": "c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "url": "https://github.com/apache/iceberg/commit/c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "message": "revert spark changes", "committedDate": "2020-11-20T12:57:14Z", "type": "commit"}, {"oid": "a52e751fae2f126d0d86a5e2be29111ac219b45f", "url": "https://github.com/apache/iceberg/commit/a52e751fae2f126d0d86a5e2be29111ac219b45f", "message": "some more updates for code review", "committedDate": "2020-11-20T12:57:15Z", "type": "commit"}, {"oid": "823e5bca690dde951ead0f7a6cd96f385d28f41e", "url": "https://github.com/apache/iceberg/commit/823e5bca690dde951ead0f7a6cd96f385d28f41e", "message": "basic support for Namespaces", "committedDate": "2020-11-20T12:57:16Z", "type": "commit"}, {"oid": "4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "url": "https://github.com/apache/iceberg/commit/4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "message": "fix tests and bump plugin version", "committedDate": "2020-11-20T12:57:16Z", "type": "commit"}, {"oid": "6fa22bb3967de6918f39ac45e688dfe94ffe7306", "url": "https://github.com/apache/iceberg/commit/6fa22bb3967de6918f39ac45e688dfe94ffe7306", "message": "update to support #1640", "committedDate": "2020-11-20T12:57:17Z", "type": "commit"}, {"oid": "b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "url": "https://github.com/apache/iceberg/commit/b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "message": "simpler way to get spark app id", "committedDate": "2020-11-20T12:57:18Z", "type": "commit"}, {"oid": "8a9009b06ba78c3ff62c22f13ec8908156dd5151", "url": "https://github.com/apache/iceberg/commit/8a9009b06ba78c3ff62c22f13ec8908156dd5151", "message": "address code review", "committedDate": "2020-11-20T12:57:19Z", "type": "commit"}, {"oid": "bf52afa2053150ff079ba6918518b78b95e8d86e", "url": "https://github.com/apache/iceberg/commit/bf52afa2053150ff079ba6918518b78b95e8d86e", "message": "another round of code review", "committedDate": "2020-11-20T12:57:20Z", "type": "commit"}, {"oid": "5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "url": "https://github.com/apache/iceberg/commit/5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "message": "respond to code review comments", "committedDate": "2020-11-20T12:57:21Z", "type": "commit"}, {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "message": "next round of code review", "committedDate": "2020-11-20T19:17:59Z", "type": "commit"}, {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "message": "next round of code review", "committedDate": "2020-11-20T19:17:59Z", "type": "forcePushed"}, {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "url": "https://github.com/apache/iceberg/commit/fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "message": "clarify branch/table visibility tests", "committedDate": "2020-11-23T17:48:13Z", "type": "commit"}]}