{"pr_number": 1125, "pr_title": "Implement the parquet value reader & writer for apache flink", "pr_createdAt": "2020-06-18T11:33:57Z", "pr_url": "https://github.com/apache/iceberg/pull/1125", "timeline": [{"oid": "ab0c7e4ca6906c5c187707ea50cd41d9c0478281", "url": "https://github.com/apache/iceberg/commit/ab0c7e4ca6906c5c187707ea50cd41d9c0478281", "message": "Implement the parquet value reader & writer for apache flink", "committedDate": "2020-06-18T11:29:38Z", "type": "commit"}, {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "url": "https://github.com/apache/iceberg/commit/e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "message": "Fix the failure unit tests.", "committedDate": "2020-06-18T11:53:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NTUyMw==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444575523", "bodyText": "How high have you tested? I usually test locally with ~1m rows.\nCould you also add tests with the new generation methods that @samarthjain added for Parquet vectorization? Those allow you to generate data that will be dictionary encoded and that will fall back to non-dictionary after a few dictionary pages. \n  \n    \n      iceberg/spark/src/test/java/org/apache/iceberg/spark/data/RandomData.java\n    \n    \n        Lines 99 to 106\n      in\n      705da1b\n    \n    \n    \n    \n\n        \n          \n           public static Iterable<Record> generateFallbackData(Schema schema, int numRecords, long seed, long numDictRecords) { \n        \n\n        \n          \n             return newIterable(() -> new FallbackDataGenerator(schema, seed, numDictRecords), schema, numRecords); \n        \n\n        \n          \n           } \n        \n\n        \n          \n            \n        \n\n        \n          \n           public static Iterable<GenericData.Record> generateDictionaryEncodableData( \n        \n\n        \n          \n               Schema schema, int numRecords, long seed, float nullPercentage) { \n        \n\n        \n          \n             return newIterable(() -> new DictionaryEncodedDataGenerator(schema, seed, nullPercentage), schema, numRecords); \n        \n\n        \n          \n           }", "author": "rdblue", "createdAt": "2020-06-24T00:14:33Z", "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static final Schema COMPLEX_SCHEMA = new Schema(\n+      required(1, \"roots\", Types.LongType.get()),\n+      optional(3, \"lime\", Types.ListType.ofRequired(4, Types.DoubleType.get())),\n+      required(5, \"strict\", Types.StructType.of(\n+          required(9, \"tangerine\", Types.StringType.get()),\n+          optional(6, \"hopeful\", Types.StructType.of(\n+              required(7, \"steel\", Types.FloatType.get()),\n+              required(8, \"lantern\", Types.DateType.get())\n+          )),\n+          optional(10, \"vehement\", Types.LongType.get())\n+      )),\n+      optional(11, \"metamorphosis\", Types.MapType.ofRequired(12, 13,\n+          Types.StringType.get(), Types.TimestampType.withZone())),\n+      required(14, \"winter\", Types.ListType.ofOptional(15, Types.StructType.of(\n+          optional(16, \"beet\", Types.DoubleType.get()),\n+          required(17, \"stamp\", Types.FloatType.get()),\n+          optional(18, \"wheeze\", Types.StringType.get())\n+      ))),\n+      optional(19, \"renovate\", Types.MapType.ofRequired(20, 21,\n+          Types.StringType.get(), Types.StructType.of(\n+              optional(22, \"jumpy\", Types.DoubleType.get()),\n+              required(23, \"koala\", Types.IntegerType.get()),\n+              required(24, \"couch rope\", Types.IntegerType.get())\n+          ))),\n+      optional(2, \"slide\", Types.StringType.get())\n+  );\n+\n+  @Test\n+  public void testCorrectness() throws IOException {\n+    int numRows = 2500;", "originalCommit": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYzMzg5NQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444633895", "bodyText": "OK, let me think about how to add those unit tests. Thanks.", "author": "openinx", "createdAt": "2020-06-24T04:11:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NTUyMw=="}], "type": "inlineReview", "revised_code": {"commit": "0350b9b9ce9c717bccbae03256b0ab792bbb710e", "chunk": "diff --git a/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java b/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\nindex 0a1918a06..31b419f27 100644\n--- a/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\n+++ b/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\n\n@@ -38,6 +38,7 @@ import static org.apache.iceberg.types.Types.NestedField.optional;\n import static org.apache.iceberg.types.Types.NestedField.required;\n \n public class TestFlinkParquetReaderWriter {\n+  private static final int NUM_RECORDS = 1_000_000;\n \n   @Rule\n   public TemporaryFolder temp = new TemporaryFolder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NjEwMw==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444576103", "bodyText": "Should this inherit from the one for Iceberg generics to avoid duplicating the list and map methods? Primitive and struct will need to be implemented, but this could reuse a lot there as well.", "author": "rdblue", "createdAt": "2020-06-24T00:16:51Z", "path": "flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.RandomUtil;\n+\n+import static java.time.temporal.ChronoUnit.MICROS;\n+\n+public class RandomData {\n+  private RandomData() {\n+  }\n+\n+  public static List<Row> generate(Schema schema, int numRecords, long seed) {\n+    RandomDataGenerator generator = new RandomDataGenerator(seed);\n+    List<Row> rows = Lists.newArrayListWithExpectedSize(numRecords);\n+    for (int i = 0; i < numRecords; i += 1) {\n+      rows.add((Row) TypeUtil.visit(schema, generator));\n+    }\n+\n+    return rows;\n+  }\n+\n+  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {", "originalCommit": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1c37f6def03ed67d4b717f5347909ca4b8763897", "chunk": "diff --git a/flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java b/flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java\nindex 8b6612608..5d300ce2f 100644\n--- a/flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java\n+++ b/flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java\n\n@@ -19,49 +19,32 @@\n \n package org.apache.iceberg.flink.data;\n \n-import java.nio.ByteBuffer;\n-import java.time.Instant;\n-import java.time.LocalDate;\n-import java.time.LocalTime;\n-import java.time.OffsetDateTime;\n-import java.time.ZoneOffset;\n import java.util.List;\n-import java.util.Map;\n-import java.util.Random;\n-import java.util.Set;\n-import java.util.UUID;\n import java.util.function.Supplier;\n import org.apache.flink.types.Row;\n import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.RandomGenericData;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n-import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n-import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n-import org.apache.iceberg.types.Type;\n import org.apache.iceberg.types.TypeUtil;\n import org.apache.iceberg.types.Types;\n-import org.apache.iceberg.util.RandomUtil;\n \n-import static java.time.temporal.ChronoUnit.MICROS;\n-\n-public class RandomData {\n+class RandomData {\n   private RandomData() {\n   }\n \n-  public static List<Row> generate(Schema schema, int numRecords, long seed) {\n-    RandomDataGenerator generator = new RandomDataGenerator(seed);\n+  static List<Row> generate(Schema schema, int numRecords, long seed) {\n+    RandomRowDataGenerator generator = new RandomRowDataGenerator(seed);\n     List<Row> rows = Lists.newArrayListWithExpectedSize(numRecords);\n     for (int i = 0; i < numRecords; i += 1) {\n       rows.add((Row) TypeUtil.visit(schema, generator));\n     }\n-\n     return rows;\n   }\n \n-  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {\n-    private final Random random;\n+  private static class RandomRowDataGenerator extends RandomGenericData.RandomDataGenerator<Row> {\n \n-    private RandomDataGenerator(long seed) {\n-      this.random = new Random(seed);\n+    private RandomRowDataGenerator(long seed) {\n+      super(seed);\n     }\n \n     @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578082", "bodyText": "Instead of adding this interface, what about adding WriteBuilder.createStructWriter to do this? That way, the Flink builder could just inherit from the generic builder and override that one method.\nI think that would be cleaner because adding this interface requires also adding public methods to pass the factory. I'd rather not add those public methods if we can avoid it by adding a protected method and change the builder to a protected class.", "author": "rdblue", "createdAt": "2020-06-24T00:24:35Z", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "originalCommit": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNzIwNg==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444617206", "bodyText": "I guess we will also need to mark the WriteBuilder from private to public because it will be accessed by flink classes from outside package.", "author": "openinx", "createdAt": "2020-06-24T02:58:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTAzMzE0MQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445033141", "bodyText": "It could be protected, right?", "author": "rdblue", "createdAt": "2020-06-24T16:48:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIyNjY4MA==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445226680", "bodyText": "protected is not enough for the outside flink package, the WriterBuilder is a static class in org.apache.iceberg.data.parquet , it must be public so that other packages could inherit it.", "author": "openinx", "createdAt": "2020-06-24T23:30:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIzOTg5Nw==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445239897", "bodyText": "You're right. The class should be public, but the method that will be overridden should be protected.", "author": "rdblue", "createdAt": "2020-06-25T00:16:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NzE2MA==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445257160", "bodyText": "Em, I've implemented two versions. the first version provides a  public  interfaces with protected StructureWriterFactory and StructReaderFactory, the second version use the inherit WriterBuilder  & ReaderBuilder #1125. For me , seems the first version looks much more concise. I plan to change to version#1 (with the  public interface and protected methods ). Thanks.", "author": "openinx", "createdAt": "2020-06-25T01:23:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTcwNjgyNQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445706825", "bodyText": "Could you post the branch with the inheritance version? I'd like to see it to compare. I don't like the extra public classes and methods, and I think that inheritance would be a cleaner public API. I'm curious why you think the other approach looks more concise, though.", "author": "rdblue", "createdAt": "2020-06-25T17:02:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE4MTMyNQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446181325", "bodyText": "The inheritance version is here.\n\nI'm curious why you think the other approach looks more concise, though.\n\nBecause the inheritance version will need to expose the buildReader and buildWriter logic , for example this. If we change those logic, will also need to change in flink reader/writers. seems the same logic with the GenericParquetReader.", "author": "openinx", "createdAt": "2020-06-26T13:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNDI4Ng==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446304286", "bodyText": "Okay, how about inheriting from the outer class, then? That way, the interface and the method that accepts the factory could be protected. Mainly, I don't think these should be public.", "author": "rdblue", "createdAt": "2020-06-26T17:03:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "1c37f6def03ed67d4b717f5347909ca4b8763897", "chunk": "diff --git a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\nindex fe016b49e..e8c36fb76 100644\n--- a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\n+++ b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\n\n@@ -291,11 +288,6 @@ public class GenericParquetWriter {\n     }\n   }\n \n-  public interface StructWriterFactory {\n-\n-    StructWriter<?> create(List<ParquetValueWriter<?>> writers);\n-  }\n-\n   private static class RecordWriter extends StructWriter<Record> {\n     private RecordWriter(List<ParquetValueWriter<?>> writers) {\n       super(writers);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODc3Ng==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578776", "bodyText": "Why change this to use the GenericRecord instance rather than the Record interface?\nI don't see much value in this change. We will just need to change it back if we want to add implementations of Record that are not generic, like we do with our internal classes that extend Avro's IndexedRecord. Ideally, I'd like to change those over to use our generics readers eventually.", "author": "rdblue", "createdAt": "2020-06-24T00:27:22Z", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {\n+\n+    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n+  }\n+\n+  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {", "originalCommit": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYyOTE0MQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445629141", "bodyText": "I changed this because the buildReader method return the GenericRecord ParquetValueReader. Seems better to change the ParquetValueReader to be Record reader.", "author": "openinx", "createdAt": "2020-06-25T15:05:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODc3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "1c37f6def03ed67d4b717f5347909ca4b8763897", "chunk": "diff --git a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\nindex b9da8ddb0..0900c7027 100644\n--- a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\n+++ b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\n\n@@ -409,12 +403,7 @@ public class GenericParquetReaders {\n     }\n   }\n \n-  public interface StructReaderFactory<T> {\n-\n-    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n-  }\n-\n-  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {\n+  static class RecordReader extends StructReader<Record, Record> {\n     private final StructType structType;\n \n     RecordReader(List<Type> types,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3OTM4OQ==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444579389", "bodyText": "Similar to the write path, I think it would be nice to refactor this to avoid exposing new public methods and interfaces.", "author": "rdblue", "createdAt": "2020-06-24T00:29:46Z", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {", "originalCommit": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1c37f6def03ed67d4b717f5347909ca4b8763897", "chunk": "diff --git a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\nindex b9da8ddb0..0900c7027 100644\n--- a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\n+++ b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java\n\n@@ -409,12 +403,7 @@ public class GenericParquetReaders {\n     }\n   }\n \n-  public interface StructReaderFactory<T> {\n-\n-    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n-  }\n-\n-  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {\n+  static class RecordReader extends StructReader<Record, Record> {\n     private final StructType structType;\n \n     RecordReader(List<Type> types,\n"}}, {"oid": "1c37f6def03ed67d4b717f5347909ca4b8763897", "url": "https://github.com/apache/iceberg/commit/1c37f6def03ed67d4b717f5347909ca4b8763897", "message": "Remove the StructWriterFactory & StructReaderFactory.", "committedDate": "2020-06-24T03:46:07Z", "type": "commit"}, {"oid": "f4799a0000639f662c3df823240c2e27d0734b10", "url": "https://github.com/apache/iceberg/commit/f4799a0000639f662c3df823240c2e27d0734b10", "message": "Revert the generic type in GenericParquetReaders#buildReader", "committedDate": "2020-06-24T03:56:44Z", "type": "commit"}, {"oid": "0350b9b9ce9c717bccbae03256b0ab792bbb710e", "url": "https://github.com/apache/iceberg/commit/0350b9b9ce9c717bccbae03256b0ab792bbb710e", "message": "Add test suits for DictionaryEncodedData and FallbackData", "committedDate": "2020-06-24T09:40:50Z", "type": "commit"}, {"oid": "17845b17870ae19d260ba93410206748fc8c6eb7", "url": "https://github.com/apache/iceberg/commit/17845b17870ae19d260ba93410206748fc8c6eb7", "message": "Revert to user the StructWriterFactory & StructReaderFactory", "committedDate": "2020-06-25T14:46:37Z", "type": "commit"}, {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6", "url": "https://github.com/apache/iceberg/commit/95e197a8544dd32597da0f4bd0b84fa41f6664c6", "message": "Use the Record instead of GenericRecord", "committedDate": "2020-06-25T14:56:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYzMzgzNA==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445633834", "bodyText": "I tried to mark this method to be protected but seems java8 don't allow to do that....", "author": "openinx", "createdAt": "2020-06-25T15:12:07Z", "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +290,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {\n+\n+    StructWriter<?> create(List<ParquetValueWriter<?>> writers);", "originalCommit": "95e197a8544dd32597da0f4bd0b84fa41f6664c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg5MDM0Mg==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445890342", "bodyText": "Interface methods are always public.", "author": "rdblue", "createdAt": "2020-06-25T23:22:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYzMzgzNA=="}], "type": "inlineReview", "revised_code": {"commit": "5bffceda9758076f67236011d4ba4e560b92590c", "chunk": "diff --git a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\nindex 9a3e5b43c..4cdb2dee1 100644\n--- a/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\n+++ b/data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java\n\n@@ -290,11 +288,6 @@ public class GenericParquetWriter {\n     }\n   }\n \n-  public interface StructWriterFactory {\n-\n-    StructWriter<?> create(List<ParquetValueWriter<?>> writers);\n-  }\n-\n   private static class RecordWriter extends StructWriter<Record> {\n     private RecordWriter(List<ParquetValueWriter<?>> writers) {\n       super(writers);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNTE5OA==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446305198", "bodyText": "How about RandomRecordGenerator instead of RandomRecordDataGenerator? I think that's more descriptive since it returns random records.", "author": "rdblue", "createdAt": "2020-06-26T17:05:07Z", "path": "data/src/test/java/org/apache/iceberg/data/RandomGenericData.java", "diffHunk": "@@ -55,11 +55,9 @@ private RandomGenericData() {}\n     return records;\n   }\n \n-  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {\n-    private final Random random;\n-\n-    private RandomDataGenerator(long seed) {\n-      this.random = new Random(seed);\n+  private static class RandomRecordDataGenerator extends RandomDataGenerator<Record> {", "originalCommit": "95e197a8544dd32597da0f4bd0b84fa41f6664c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bffceda9758076f67236011d4ba4e560b92590c", "chunk": "diff --git a/data/src/test/java/org/apache/iceberg/data/RandomGenericData.java b/data/src/test/java/org/apache/iceberg/data/RandomGenericData.java\nindex 095e0c204..19179c0b1 100644\n--- a/data/src/test/java/org/apache/iceberg/data/RandomGenericData.java\n+++ b/data/src/test/java/org/apache/iceberg/data/RandomGenericData.java\n\n@@ -55,8 +55,8 @@ public class RandomGenericData {\n     return records;\n   }\n \n-  private static class RandomRecordDataGenerator extends RandomDataGenerator<Record> {\n-    private RandomRecordDataGenerator(long seed) {\n+  private static class RandomRecordGenerator extends RandomDataGenerator<Record> {\n+    private RandomRecordGenerator(long seed) {\n       super(seed);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNjkxNg==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446306916", "bodyText": "Good to know that this passes, but I don't think we need to run with this high of a record count every time in CI. Could you reduce this to 20_000?", "author": "rdblue", "createdAt": "2020-06-26T17:08:50Z", "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+  private static final int NUM_RECORDS = 1_000_000;", "originalCommit": "95e197a8544dd32597da0f4bd0b84fa41f6664c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bffceda9758076f67236011d4ba4e560b92590c", "chunk": "diff --git a/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java b/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\nindex 31b419f27..f8bf6a53e 100644\n--- a/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\n+++ b/flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java\n\n@@ -38,7 +38,7 @@ import static org.apache.iceberg.types.Types.NestedField.optional;\n import static org.apache.iceberg.types.Types.NestedField.required;\n \n public class TestFlinkParquetReaderWriter {\n-  private static final int NUM_RECORDS = 1_000_000;\n+  private static final int NUM_RECORDS = 20_000;\n \n   @Rule\n   public TemporaryFolder temp = new TemporaryFolder();\n"}}, {"oid": "5bffceda9758076f67236011d4ba4e560b92590c", "url": "https://github.com/apache/iceberg/commit/5bffceda9758076f67236011d4ba4e560b92590c", "message": "Make the flink parquet reader/write inherit the generic parquet reader writer.", "committedDate": "2020-06-27T02:45:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU5MjAxMA==", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446592010", "bodyText": "I changed the buildReader to buildRowReader  because the parent buildReader will return with a ParquetValueReader <Record> data type, which clashes with this FlinkParquetReaders 's buildReader returned ParquetValueReader <Row>.", "author": "openinx", "createdAt": "2020-06-28T02:46:06Z", "path": "flink/src/main/java/org/apache/iceberg/flink/data/FlinkParquetReaders.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.parquet.GenericParquetReaders;\n+import org.apache.iceberg.parquet.ParquetSchemaUtil;\n+import org.apache.iceberg.parquet.ParquetValueReader;\n+import org.apache.iceberg.parquet.ParquetValueReaders;\n+import org.apache.iceberg.parquet.TypeWithSchemaVisitor;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Type;\n+\n+public class FlinkParquetReaders extends GenericParquetReaders {\n+  private FlinkParquetReaders() {\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  public static ParquetValueReader<Row> buildRowReader(Schema expectedSchema,", "originalCommit": "5bffceda9758076f67236011d4ba4e560b92590c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}