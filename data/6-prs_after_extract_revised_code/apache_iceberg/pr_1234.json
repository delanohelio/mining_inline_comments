{"pr_number": 1234, "pr_title": "avro: Extract DecoderResolver to provide cached ResolvingDecoder for resolving avro decoder", "pr_createdAt": "2020-07-23T04:08:43Z", "pr_url": "https://github.com/apache/iceberg/pull/1234", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMxNTI2MQ==", "url": "https://github.com/apache/iceberg/pull/1234#discussion_r459315261", "bodyText": "This newResolver could also be removed ?", "author": "openinx", "createdAt": "2020-07-23T09:11:56Z", "path": "core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java", "diffHunk": "@@ -66,28 +61,12 @@ public void setClassLoader(ClassLoader newClassLoader) {\n \n   @Override\n   public T read(T reuse, Decoder decoder) throws IOException {\n-    ResolvingDecoder resolver = resolve(decoder);\n+    ResolvingDecoder resolver = DecoderResolver.resolve(decoder, readSchema, fileSchema);\n     T value = reader.read(resolver, reuse);\n     resolver.drain();\n     return value;\n   }\n \n-  private ResolvingDecoder resolve(Decoder decoder) throws IOException {\n-    Map<Schema, Map<Schema, ResolvingDecoder>> cache = DECODER_CACHES.get();\n-    Map<Schema, ResolvingDecoder> fileSchemaToResolver = cache\n-        .computeIfAbsent(readSchema, k -> new HashMap<>());\n-\n-    ResolvingDecoder resolver = fileSchemaToResolver.get(fileSchema);\n-    if (resolver == null) {\n-      resolver = newResolver();\n-      fileSchemaToResolver.put(fileSchema, resolver);\n-    }\n-\n-    resolver.configure(decoder);\n-\n-    return resolver;\n-  }\n-\n   private ResolvingDecoder newResolver() {", "originalCommit": "13bc1ec98d0cb5448dbd14b1141ec50113e8244d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6bf3856b42a6a1e117940990c9f87289db382903", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java b/core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java\nindex d9523cb16..a1b5a587f 100644\n--- a/core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java\n+++ b/core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java\n\n@@ -61,18 +58,7 @@ class GenericAvroReader<T> implements DatumReader<T> {\n \n   @Override\n   public T read(T reuse, Decoder decoder) throws IOException {\n-    ResolvingDecoder resolver = DecoderResolver.resolve(decoder, readSchema, fileSchema);\n-    T value = reader.read(resolver, reuse);\n-    resolver.drain();\n-    return value;\n-  }\n-\n-  private ResolvingDecoder newResolver() {\n-    try {\n-      return DecoderFactory.get().resolvingDecoder(fileSchema, readSchema, null);\n-    } catch (IOException e) {\n-      throw new RuntimeIOException(e);\n-    }\n+    return DecoderResolver.resolveAndRead(reader, reuse, decoder, readSchema, fileSchema);\n   }\n \n   private static class ReadBuilder extends AvroSchemaVisitor<ValueReader<?>> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMxNzM0MQ==", "url": "https://github.com/apache/iceberg/pull/1234#discussion_r459317341", "bodyText": "Could simplify those lines as fileSchemaToResolver.computeIfAbsent  ?", "author": "openinx", "createdAt": "2020-07-23T09:15:56Z", "path": "core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data.avro;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.avro.Schema;\n+import org.apache.avro.io.Decoder;\n+import org.apache.avro.io.DecoderFactory;\n+import org.apache.avro.io.ResolvingDecoder;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.relocated.com.google.common.collect.MapMaker;\n+\n+/**\n+ * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}.\n+ * This class uses a {@link ThreadLocal} for caching {@link ResolvingDecoder}.\n+ */\n+public class DecoderResolver {\n+\n+  private DecoderResolver() {}\n+\n+  private static final ThreadLocal<Map<Schema, Map<Schema, ResolvingDecoder>>> DECODER_CACHES =\n+      ThreadLocal.withInitial(() -> new MapMaker().weakKeys().makeMap());\n+\n+  public static ResolvingDecoder resolve(Decoder decoder, Schema readSchema, Schema fileSchema) throws IOException {\n+    Map<Schema, Map<Schema, ResolvingDecoder>> cache = DECODER_CACHES.get();\n+    Map<Schema, ResolvingDecoder> fileSchemaToResolver = cache\n+        .computeIfAbsent(readSchema, k -> new HashMap<>());\n+\n+    ResolvingDecoder resolver = fileSchemaToResolver.get(fileSchema);\n+    if (resolver == null) {\n+      resolver = newResolver(readSchema, fileSchema);\n+      fileSchemaToResolver.put(fileSchema, resolver);\n+    }", "originalCommit": "13bc1ec98d0cb5448dbd14b1141ec50113e8244d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6bf3856b42a6a1e117940990c9f87289db382903", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java b/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\nindex 18de310ba..c026bb69d 100644\n--- a/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\n+++ b/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\n\n@@ -26,30 +26,37 @@ import org.apache.avro.Schema;\n import org.apache.avro.io.Decoder;\n import org.apache.avro.io.DecoderFactory;\n import org.apache.avro.io.ResolvingDecoder;\n+import org.apache.iceberg.avro.ValueReader;\n import org.apache.iceberg.exceptions.RuntimeIOException;\n import org.apache.iceberg.relocated.com.google.common.collect.MapMaker;\n \n /**\n- * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}.\n- * This class uses a {@link ThreadLocal} for caching {@link ResolvingDecoder}.\n+ * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}. This class uses a {@link ThreadLocal} for caching\n+ * {@link ResolvingDecoder}.\n  */\n public class DecoderResolver {\n \n-  private DecoderResolver() {}\n-\n   private static final ThreadLocal<Map<Schema, Map<Schema, ResolvingDecoder>>> DECODER_CACHES =\n       ThreadLocal.withInitial(() -> new MapMaker().weakKeys().makeMap());\n \n-  public static ResolvingDecoder resolve(Decoder decoder, Schema readSchema, Schema fileSchema) throws IOException {\n+  private DecoderResolver() {}\n+\n+  public static <T> T resolveAndRead(ValueReader<T> reader, T reuse, Decoder decoder, Schema readSchema,\n+      Schema fileSchema) throws IOException {\n+    ResolvingDecoder resolver = DecoderResolver.resolve(decoder, readSchema, fileSchema);\n+    T value = reader.read(resolver, reuse);\n+    resolver.drain();\n+    return value;\n+  }\n+\n+  private static ResolvingDecoder resolve(Decoder decoder, Schema readSchema, Schema fileSchema) throws IOException {\n     Map<Schema, Map<Schema, ResolvingDecoder>> cache = DECODER_CACHES.get();\n     Map<Schema, ResolvingDecoder> fileSchemaToResolver = cache\n         .computeIfAbsent(readSchema, k -> new HashMap<>());\n \n-    ResolvingDecoder resolver = fileSchemaToResolver.get(fileSchema);\n-    if (resolver == null) {\n-      resolver = newResolver(readSchema, fileSchema);\n-      fileSchemaToResolver.put(fileSchema, resolver);\n-    }\n+    ResolvingDecoder resolver = fileSchemaToResolver.computeIfAbsent(\n+        fileSchema,\n+        schema -> newResolver(readSchema, schema));\n \n     resolver.configure(decoder);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMxOTUwOA==", "url": "https://github.com/apache/iceberg/pull/1234#discussion_r459319508", "bodyText": "Q: Will it have problem when the  GenericAvroReader , DataReader, SparkAvroReader  share the same  cache ?", "author": "openinx", "createdAt": "2020-07-23T09:20:11Z", "path": "core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data.avro;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.avro.Schema;\n+import org.apache.avro.io.Decoder;\n+import org.apache.avro.io.DecoderFactory;\n+import org.apache.avro.io.ResolvingDecoder;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.relocated.com.google.common.collect.MapMaker;\n+\n+/**\n+ * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}.\n+ * This class uses a {@link ThreadLocal} for caching {@link ResolvingDecoder}.\n+ */\n+public class DecoderResolver {\n+\n+  private DecoderResolver() {}\n+\n+  private static final ThreadLocal<Map<Schema, Map<Schema, ResolvingDecoder>>> DECODER_CACHES =", "originalCommit": "13bc1ec98d0cb5448dbd14b1141ec50113e8244d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMzNzU1Nw==", "url": "https://github.com/apache/iceberg/pull/1234#discussion_r459337557", "bodyText": "ResolvingDecoder is used by per record:\nresolver.configure(decoder);\nreader.read(resolver, reuse);\nresolver.drain();\n\nI think this pattern should be thread safe and can be shared.", "author": "JingsongLi", "createdAt": "2020-07-23T09:54:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMxOTUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "6bf3856b42a6a1e117940990c9f87289db382903", "chunk": "diff --git a/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java b/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\nindex 18de310ba..c026bb69d 100644\n--- a/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\n+++ b/core/src/main/java/org/apache/iceberg/data/avro/DecoderResolver.java\n\n@@ -26,30 +26,37 @@ import org.apache.avro.Schema;\n import org.apache.avro.io.Decoder;\n import org.apache.avro.io.DecoderFactory;\n import org.apache.avro.io.ResolvingDecoder;\n+import org.apache.iceberg.avro.ValueReader;\n import org.apache.iceberg.exceptions.RuntimeIOException;\n import org.apache.iceberg.relocated.com.google.common.collect.MapMaker;\n \n /**\n- * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}.\n- * This class uses a {@link ThreadLocal} for caching {@link ResolvingDecoder}.\n+ * Resolver to resolve {@link Decoder} to a {@link ResolvingDecoder}. This class uses a {@link ThreadLocal} for caching\n+ * {@link ResolvingDecoder}.\n  */\n public class DecoderResolver {\n \n-  private DecoderResolver() {}\n-\n   private static final ThreadLocal<Map<Schema, Map<Schema, ResolvingDecoder>>> DECODER_CACHES =\n       ThreadLocal.withInitial(() -> new MapMaker().weakKeys().makeMap());\n \n-  public static ResolvingDecoder resolve(Decoder decoder, Schema readSchema, Schema fileSchema) throws IOException {\n+  private DecoderResolver() {}\n+\n+  public static <T> T resolveAndRead(ValueReader<T> reader, T reuse, Decoder decoder, Schema readSchema,\n+      Schema fileSchema) throws IOException {\n+    ResolvingDecoder resolver = DecoderResolver.resolve(decoder, readSchema, fileSchema);\n+    T value = reader.read(resolver, reuse);\n+    resolver.drain();\n+    return value;\n+  }\n+\n+  private static ResolvingDecoder resolve(Decoder decoder, Schema readSchema, Schema fileSchema) throws IOException {\n     Map<Schema, Map<Schema, ResolvingDecoder>> cache = DECODER_CACHES.get();\n     Map<Schema, ResolvingDecoder> fileSchemaToResolver = cache\n         .computeIfAbsent(readSchema, k -> new HashMap<>());\n \n-    ResolvingDecoder resolver = fileSchemaToResolver.get(fileSchema);\n-    if (resolver == null) {\n-      resolver = newResolver(readSchema, fileSchema);\n-      fileSchemaToResolver.put(fileSchema, resolver);\n-    }\n+    ResolvingDecoder resolver = fileSchemaToResolver.computeIfAbsent(\n+        fileSchema,\n+        schema -> newResolver(readSchema, schema));\n \n     resolver.configure(decoder);\n \n"}}, {"oid": "6dc524da297035fe12b0fdd5c2a7cfcc07ea02fe", "url": "https://github.com/apache/iceberg/commit/6dc524da297035fe12b0fdd5c2a7cfcc07ea02fe", "message": "avro: Extract DecoderResolver to provide cached ResolvingDecoder for resolving avro decoder", "committedDate": "2020-07-24T05:43:37Z", "type": "commit"}, {"oid": "6bf3856b42a6a1e117940990c9f87289db382903", "url": "https://github.com/apache/iceberg/commit/6bf3856b42a6a1e117940990c9f87289db382903", "message": "Fix comments", "committedDate": "2020-07-24T05:43:37Z", "type": "commit"}, {"oid": "b79bd908c5695b2c00fe23d6da6ce5b1a2c03f4d", "url": "https://github.com/apache/iceberg/commit/b79bd908c5695b2c00fe23d6da6ce5b1a2c03f4d", "message": "Rebase", "committedDate": "2020-07-24T05:47:33Z", "type": "commit"}, {"oid": "b79bd908c5695b2c00fe23d6da6ce5b1a2c03f4d", "url": "https://github.com/apache/iceberg/commit/b79bd908c5695b2c00fe23d6da6ce5b1a2c03f4d", "message": "Rebase", "committedDate": "2020-07-24T05:47:33Z", "type": "forcePushed"}]}