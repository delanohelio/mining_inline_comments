{"pr_number": 1395, "pr_title": "Changes default collect behavior of ExpireSnapshotActions", "pr_createdAt": "2020-08-27T19:32:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1395", "timeline": [{"oid": "67176fe5dc103ac785c9aa5530662696f95fc00a", "url": "https://github.com/apache/iceberg/commit/67176fe5dc103ac785c9aa5530662696f95fc00a", "message": "Changes default collect behavior of ExpireSnapshotActions\n\nPreviously ExpireSnapshotAction would always use toLocalIterator which\nends up costing significantly more time on smaller data sets. Since even\nthe largest lists of files are expected to fit in memory we are changing\nthe default to Collect. Collect will bring back the results more quickly\nat the cost of additional memory. An option to streamDeleteResults will still\nbe available for extremely large expire operations.", "committedDate": "2020-08-27T19:02:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MDc1Ng==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478660756", "bodyText": "nit: I think it should be 4 spaces for continued indentation. Applies to the whole test.", "author": "aokolnychyi", "createdAt": "2020-08-27T19:56:24Z", "path": "spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java", "diffHunk": "@@ -1008,4 +1008,37 @@ public void testExpireAction() {\n     Assert.assertSame(\"Multiple calls to expire should return the same deleted files\",\n         pendingDeletes, action.expire());\n   }\n+\n+  @Test\n+  public void testUseLocalIterator() {\n+    table.newFastAppend()\n+            .appendFile(FILE_A)", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDc4OA==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664788", "bodyText": "Got it!", "author": "RussellSpitzer", "createdAt": "2020-08-27T20:04:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MDc1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "chunk": "diff --git a/spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java b/spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java\nindex 9fe42fbe6..5887a04fa 100644\n--- a/spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java\n+++ b/spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java\n\n@@ -1012,24 +1012,24 @@ public abstract class TestExpireSnapshotsAction extends SparkTestBase {\n   @Test\n   public void testUseLocalIterator() {\n     table.newFastAppend()\n-            .appendFile(FILE_A)\n-            .commit();\n+        .appendFile(FILE_A)\n+        .commit();\n \n     table.newOverwrite()\n-            .deleteFile(FILE_A)\n-            .addFile(FILE_B)\n-            .commit();\n+        .deleteFile(FILE_A)\n+        .addFile(FILE_B)\n+        .commit();\n \n     table.newFastAppend()\n-            .appendFile(FILE_C)\n-            .commit();\n+        .appendFile(FILE_C)\n+        .commit();\n \n     long end = rightAfterSnapshot();\n \n     int jobsBefore = spark.sparkContext().dagScheduler().nextJobId().get();\n \n     ExpireSnapshotsActionResult results =\n-            Actions.forTable(table).expireSnapshots().expireOlderThan(end).streamDeleteResults(true).execute();\n+        Actions.forTable(table).expireSnapshots().expireOlderThan(end).streamDeleteResults(true).execute();\n \n     Assert.assertEquals(\"Table does not have 1 snapshot after expiration\", 1, Iterables.size(table.snapshots()));\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MTEzMA==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478661130", "bodyText": "nit: to use stream -> to stream", "author": "aokolnychyi", "createdAt": "2020-08-27T19:57:10Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -90,6 +91,19 @@ protected Table table() {\n     return table;\n   }\n \n+  /**\n+   * Whether or not to use stream the expired file list to the driver. The default (false) will use", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\nindex 736ed845d..5f6402db0 100644\n--- a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n+++ b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n\n@@ -92,11 +92,10 @@ public class ExpireSnapshotsAction extends BaseAction<ExpireSnapshotsActionResul\n   }\n \n   /**\n-   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n-   * collect to bring back all results to the driver at once which may be an issue with very long file lists.\n-   * Set this to true to use toLocalIterator if you are running into memory issues when collecting the list of files\n-   * to be deleted.\n-   * @param stream whether to use toLocalIterator to stream results instead of collect.\n+   * By default, all files to delete are brought to the driver at once which may be an issue with very long file lists.\n+   * Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting\n+   * the list of files to be deleted.\n+   * @param stream whether to use {@link Dataset#toLocalIterator} to stream results instead of {@link Dataset#collect}.\n    * @return this for method chaining\n    */\n   public ExpireSnapshotsAction streamDeleteResults(boolean stream) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478662813", "bodyText": "What about this? By default, all files to delete are brought to the driver at once which may be an issue with very long file lists. Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting the list of files to be deleted.", "author": "aokolnychyi", "createdAt": "2020-08-27T20:00:34Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -90,6 +91,19 @@ protected Table table() {\n     return table;\n   }\n \n+  /**\n+   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n+   * collect to bring back all results to the driver at once which may be an issue with very long file lists.", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDg3OQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664879", "bodyText": "Sgtm", "author": "RussellSpitzer", "createdAt": "2020-08-27T20:04:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDkzMQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664931", "bodyText": "Sounds good to me, except that it creates a dead link because Dataset#toLocalIterator is not in Iceberg Javadoc.", "author": "rdblue", "createdAt": "2020-08-27T20:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw=="}], "type": "inlineReview", "revised_code": {"commit": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\nindex 736ed845d..5f6402db0 100644\n--- a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n+++ b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n\n@@ -92,11 +92,10 @@ public class ExpireSnapshotsAction extends BaseAction<ExpireSnapshotsActionResul\n   }\n \n   /**\n-   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n-   * collect to bring back all results to the driver at once which may be an issue with very long file lists.\n-   * Set this to true to use toLocalIterator if you are running into memory issues when collecting the list of files\n-   * to be deleted.\n-   * @param stream whether to use toLocalIterator to stream results instead of collect.\n+   * By default, all files to delete are brought to the driver at once which may be an issue with very long file lists.\n+   * Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting\n+   * the list of files to be deleted.\n+   * @param stream whether to use {@link Dataset#toLocalIterator} to stream results instead of {@link Dataset#collect}.\n    * @return this for method chaining\n    */\n   public ExpireSnapshotsAction streamDeleteResults(boolean stream) {\n"}}, {"oid": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "url": "https://github.com/apache/iceberg/commit/764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "message": "Reviewer Comments", "committedDate": "2020-08-27T20:24:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY3ODY0Ng==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478678646", "bodyText": "These are broken links because we don't have Spark's API in our Javadoc, right?", "author": "rdblue", "createdAt": "2020-08-27T20:31:58Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -92,11 +92,10 @@ protected Table table() {\n   }\n \n   /**\n-   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n-   * collect to bring back all results to the driver at once which may be an issue with very long file lists.\n-   * Set this to true to use toLocalIterator if you are running into memory issues when collecting the list of files\n-   * to be deleted.\n-   * @param stream whether to use toLocalIterator to stream results instead of collect.\n+   * By default, all files to delete are brought to the driver at once which may be an issue with very long file lists.\n+   * Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting\n+   * the list of files to be deleted.\n+   * @param stream whether to use {@link Dataset#toLocalIterator} to stream results instead of {@link Dataset#collect}.", "originalCommit": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY4MTg5NQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478681895", "bodyText": "You are right, my bad.", "author": "aokolnychyi", "createdAt": "2020-08-27T20:38:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY3ODY0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "ea2dff674bb2019e7bdcde1aa6c342ce26317fdd", "chunk": "diff --git a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\nindex 5f6402db0..e0c67954e 100644\n--- a/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n+++ b/spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java\n\n@@ -93,9 +93,9 @@ public class ExpireSnapshotsAction extends BaseAction<ExpireSnapshotsActionResul\n \n   /**\n    * By default, all files to delete are brought to the driver at once which may be an issue with very long file lists.\n-   * Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting\n+   * Set this to true to use toLocalIterator if you are running into memory issues when collecting\n    * the list of files to be deleted.\n-   * @param stream whether to use {@link Dataset#toLocalIterator} to stream results instead of {@link Dataset#collect}.\n+   * @param stream whether to use toLocalIterator to stream results instead of collect.\n    * @return this for method chaining\n    */\n   public ExpireSnapshotsAction streamDeleteResults(boolean stream) {\n"}}, {"oid": "ea2dff674bb2019e7bdcde1aa6c342ce26317fdd", "url": "https://github.com/apache/iceberg/commit/ea2dff674bb2019e7bdcde1aa6c342ce26317fdd", "message": "Fix Tests and Doc Links\n\nUnfortunately we can't predicate accurately the exact number of jobs that will be\nproduced because of test run-order and caching (I think). So instead we will just make\nsure that we have more jobs run than we had Shuffle Partitions.", "committedDate": "2020-08-27T22:11:59Z", "type": "commit"}]}