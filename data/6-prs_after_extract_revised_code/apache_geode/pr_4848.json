{"pr_number": 4848, "pr_title": "GEODE-7670: Add Tests for PR clear", "pr_createdAt": "2020-03-25T17:01:42Z", "pr_url": "https://github.com/apache/geode/pull/4848", "timeline": [{"oid": "1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "url": "https://github.com/apache/geode/commit/1d16fb2e4bf6e480d41d12a3ed4c7ba3ab43a276", "message": "GEODE-7670: Fixed and added tests", "committedDate": "2020-03-26T12:28:04Z", "type": "forcePushed"}, {"oid": "267897885f9ee57967de5266ce3f6cdd96c4a90e", "url": "https://github.com/apache/geode/commit/267897885f9ee57967de5266ce3f6cdd96c4a90e", "message": "GEODE-7670: Fixed and added tests", "committedDate": "2020-03-26T13:10:45Z", "type": "forcePushed"}, {"oid": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "url": "https://github.com/apache/geode/commit/65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "message": "GEODE-7670: Fixed and added tests", "committedDate": "2020-03-26T13:22:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgwODQxOQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398808419", "bodyText": "can you add more shortcuts?", "author": "gesterzhou", "createdAt": "2020-03-26T18:43:15Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5MDc1Mg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399290752", "bodyText": "There are other tickets aimed at testing concurrent operations with overflow, persistence, etc. Adding more region types should be done as part of the other tickets (that's why I set the RegionShortcut to be configurable through parameters), not this one.", "author": "jujoramos", "createdAt": "2020-03-27T14:09:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgwODQxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg0OTY0NQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398849645", "bodyText": "after the first clear, all other gets() will not really do anything. You should re-populateRegion again before next clear.", "author": "gesterzhou", "createdAt": "2020-03-26T19:51:07Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5MTkwOA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399291908", "bodyText": "The test is still valid, though, we aim to verify that there are no issues with concurrent gets and concurrent clears, doesn't matter how many entries (if any) the region has. There is another method within the class that tests concurrent gets + puts + clears.", "author": "jujoramos", "createdAt": "2020-03-27T14:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg0OTY0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4NzI3MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398887271", "bodyText": "you need to measure how long a clear() took. If it's more than 5 seconds, something must be wrong.", "author": "gesterzhou", "createdAt": "2020-03-26T20:58:20Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5MzUxMQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399293511", "bodyText": "I'm not following you on this one... why only 5 seconds?, and why should the test verify how long the operation actually took?. The method basically executes the clear operation for a specific period of time to be able to interleave this operation with other concurrent ones in the cache. Measuring how long the operation took should be part of another ticket (a performance one, probably).", "author": "jujoramos", "createdAt": "2020-03-27T14:13:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4NzI3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3ODU5OQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r400378599", "bodyText": "5 seconds is rvv domination timeout. If clear operation took more than 5 seconds, something must be wrong. No need to measure other operations' time.", "author": "gesterzhou", "createdAt": "2020-03-30T17:46:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4NzI3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTcxNzYyMw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r401717623", "bodyText": "@gesterzhou : I still don't understand what these tests have to do with the fact that a clear operation should take less than 5 seconds. The ticket is to purely verify that clear can be executed while other cache operations are being executed at the same time on the same region, shouldn't we create an extra ticket to test the scenario you're talking about?.", "author": "jujoramos", "createdAt": "2020-04-01T15:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4NzI3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4ODIwMg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398888202", "bodyText": "it's better to change the continuous put into continuous putAll.", "author": "gesterzhou", "createdAt": "2020-03-26T21:00:15Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5NDA5Mw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399294093", "bodyText": "Any reason for that?. I can certainly do it, just wondering what's the actual reasoning behind the request.", "author": "jujoramos", "createdAt": "2020-03-27T14:13:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4ODIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3OTA0Ng==", "url": "https://github.com/apache/geode/pull/4848#discussion_r400379046", "bodyText": "putAll will have longer window to reproduce synchronization issues", "author": "gesterzhou", "createdAt": "2020-03-30T17:47:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4ODIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTcxODA3Mg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r401718072", "bodyText": "Cool, will add another test to execute multiple putAll instead of regular put opertations.", "author": "jujoramos", "createdAt": "2020-04-01T15:46:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4ODIwMg=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398852703", "bodyText": "Shortening the test name :)\nWe have PRConcurrentMapOpsJUnitTest - similar to this?", "author": "agingade", "createdAt": "2020-03-26T19:56:39Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1ODc3Mg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398958772", "bodyText": "This is a good start; other cache ops that can be added in mix are Region ops (destroyRegion, invalidateRegion), querying; Region with index, rebalance, etc.", "author": "agingade", "createdAt": "2020-03-26T23:51:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5Njk2MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399296961", "bodyText": "I'm in favour of having clear names in tests and classes, that's why I prefer to use long ones :-). Regarding the second comment, strongly agreed!.\nThis PR is to specifically address GEODE-7670, that's why it only addresses gets and puts, we can certainly improve the test and add extra operations (or region types) as part of other tickets.", "author": "jujoramos", "createdAt": "2020-03-27T14:18:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1MTQ1Ng==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399451456", "bodyText": "@jujoramos name change and adding new ops I will leave it to you. The acceptance criteria and ticket heading doesn't match; anyways we could add additional tickets to try out other ops.", "author": "agingade", "createdAt": "2020-03-27T18:09:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg1MjcwMw=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTMwOA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398945308", "bodyText": "2 secs may be long pauses...Since there is continuous cache operation, how about sleeping for few mili secs (say 50)", "author": "agingade", "createdAt": "2020-03-26T23:10:05Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5ODkzMA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399298930", "bodyText": "Changed.", "author": "jujoramos", "createdAt": "2020-03-27T14:20:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTMwOA=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTM5Ng==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398945396", "bodyText": "3 secs long sleep.", "author": "agingade", "createdAt": "2020-03-26T23:10:21Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI5OTUxOA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399299518", "bodyText": "Changed.", "author": "jujoramos", "createdAt": "2020-03-27T14:21:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0NTM5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUyMg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398949522", "bodyText": "This waits for message pertaining to region creation or status change. There is DistributionMessageObserver that can be used to see if any messages are still in progress.", "author": "agingade", "createdAt": "2020-03-26T23:22:39Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMwMTkwNQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399301905", "bodyText": "Agreed, the DistributionMessageObserver can be used but it's a test hook and I've heard we want to get rid of that eventually, that's why I chose to use another approach (which seems to work fine, so I'm not sure I should to apply the requested change here).", "author": "jujoramos", "createdAt": "2020-03-27T14:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1MzczNw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399453737", "bodyText": "I won't foresee removal of observers; again there are multiple ways to do it; it is your choice :)", "author": "agingade", "createdAt": "2020-03-27T18:13:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTUyMg=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398952027", "bodyText": "This is going over the PRs entry/key set getting all the values. This will be consistent where-ever this is called.\nAre we trying to see if the data in one vm is same as in another vm. Or are we trying to see data in primary buckets are same as in secondary buckets.\nFetching the local PR data-set and iterating over it will give the data stored in that vm.\nOr just to see an op could be executed successfully after clear?", "author": "agingade", "createdAt": "2020-03-26T23:29:57Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMwMzUxMQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399303511", "bodyText": "The method asserts that the data is consistent across VMs by tacking a snapshot of the region per VM and comparing it against the other running VMs, it doesn't check primaries vs secondaries.\n    vms.forEach(vm -> vm.invoke(() -> {\n      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n    }));", "author": "jujoramos", "createdAt": "2020-03-27T14:27:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1NTY1MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399455651", "bodyText": "What I am trying to says is, since you are iterating over the PR region; it will get the data from all the nodes. Thats remains same across all the nodes.", "author": "agingade", "createdAt": "2020-03-27T18:16:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTcxOTg0NA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r401719844", "bodyText": "@agingade : got your point, thanks for catching this. Will change the method to verify that the data both on the primary and secondary buckets are in sync.", "author": "jujoramos", "createdAt": "2020-04-01T15:48:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjAyNw=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1Mjg3NQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398952875", "bodyText": "No need to specify time; if someone changes the time and doesn't update it, this will become incorrect.", "author": "agingade", "createdAt": "2020-03-26T23:32:32Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches threads to continuously execute puts and gets for 60 seconds.\n+   * - Clears the Partition Region continuously (once every 10 seconds for 60 seconds).", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMwMzY2MA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399303660", "bodyText": "Done!.", "author": "jujoramos", "createdAt": "2020-03-27T14:27:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1Mjg3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1NzY4Mg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r398957682", "bodyText": "Instead of CacheWriter, you can use DistributionMessageObserver. And can use VM.bounce* to kill vms. No need to wait for CacheWriter messaging implementation.", "author": "agingade", "createdAt": "2020-03-26T23:47:45Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} can be executed multiple times on\n+ * the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME = \"[{index}] {method}(Coordinator:{0}, Region:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  /**\n+   * Waits until there are not PR messages in flight for the given region.\n+   */\n+  private void waitForSilence() {\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+    await().untilAsserted(() -> {\n+      PartitionedRegionStats prStats = region.getPrStats();\n+      assertThat(prStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(prStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(prStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionData(int entryCount, List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.isEmpty()).isTrue();\n+    }));\n+  }\n+\n+  /**\n+   * Waits until there are no partition messages in flight and gets a snapshot of the region.\n+   */\n+  private Map<String, String> waitForSilenceAndGetRegionSnapshot() {\n+    waitForSilence();\n+    Map<String, String> regionSnapshot = new HashMap<>();\n+    Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+    region.forEach(regionSnapshot::put);\n+\n+    return regionSnapshot;\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent on requested VMs.\n+   */\n+  private void assertRegionDataConsistency(List<VM> vms) {\n+    // Get first snapshot to compare with the rest.\n+    final Map<String, String> vm0Snapshot =\n+        vms.get(0).invoke(this::waitForSilenceAndGetRegionSnapshot);\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n+      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n+      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n+    }));\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    assertRegionData(entryCount, vms);\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInSeconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInSeconds * 1000);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets for 10 seconds.\n+   * - Clears the Partition Region continuously (once every 2 seconds for 10 seconds).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 10000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs continuously execute gets for 10 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 10)),\n+        server2.invokeAsync(() -> executeGets(entries, 10)),\n+        accessor.invokeAsync(() -> executeGets(entries, 10)));\n+\n+    // Clear the region every 2 seconds for 10 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 2));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server1));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches one thread per VM to continuously execute puts for 15 seconds.\n+   * - Clears the Partition Region continuously (once every 3 seconds for 15 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 5000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 15)),\n+        server2.invokeAsync(() -> executePuts(entries, 15)),\n+        accessor.invokeAsync(() -> executePuts(entries, 15)));\n+\n+    // Clear the region every 3 seconds for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 3));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Launches threads to continuously execute puts and gets for 60 seconds.\n+   * - Clears the Partition Region continuously (once every 10 seconds for 60 seconds).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsAndGetsShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut)\n+      throws InterruptedException {\n+    final int entries = 15000;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts and gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        server2.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region every 10 seconds for 60 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(60, 10));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following:\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n+   * clear is in progress.\n+   * - Clears the Partition Region (at this point the coordinator is restarted).\n+   * - Asserts that, after the member joins again, entries have not been deleted.\n+   */\n+  @Test\n+  @TestCaseName(\"[{index}] {method}(Region:{0})\")\n+  @Parameters(method = \"regionTypes\")\n+  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n+    final int entries = 1000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n+\n+    // Clear the region.\n+    server1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      assertThatThrownBy(region::clear)\n+          .isInstanceOf(DistributedSystemDisconnectedException.class)\n+          .hasCauseInstanceOf(ForcedDisconnectException.class);\n+    });\n+\n+    // Wait for member to get back online.\n+    server1.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute gets for 60 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentGetsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7500;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, 60)),\n+        accessor.invokeAsync(() -> executeGets(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region is empty across VMs.\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * The test does the following (the clear coordinator is chosen through parameters):\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches one thread per VM to continuously execute puts for 30 seconds.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clears are finished, the Region data is consistent across members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"vmAndRegionTypes\")\n+  public void clearWithConcurrentPutsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM, RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 7000;\n+    parametrizedSetup(regionShortcut);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, 60)),\n+        accessor.invokeAsync(() -> executePuts(entries, 60)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Data is consistent across members.\n+    assertRegionDataConsistency(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * Shutdowns a member while the clear operation is in progress.\n+   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n+   * it's the clear coordinator or another member holding primary buckets.\n+   *\n+   * TODO: Review once GEODE-7678 / GEODE-7912 are merged (CacheWriter lifecycle might change).\n+   */\n+  public static class MemberKiller extends CacheWriterAdapter<String, String> {", "originalCommit": "65275b6a5fa3bdf344b5dbf3042705ee5b19e2a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMwNDkxNA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399304914", "bodyText": "Same as above, I'm still inclined to use the CacheWriter for now instead of the DistributionMessageObserver hook. If the lifecycle of the listener changes, I'll be more than happy to use another approach :-). If you think this should block the PR from being merged, though, I'll explore using the DistributionMessageObserver.", "author": "jujoramos", "createdAt": "2020-03-27T14:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1NzY4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ1NzA3MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r399457071", "bodyText": "I don't think lifecycle of listeners changing. Its your choice.", "author": "agingade", "createdAt": "2020-03-27T18:19:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1NzY4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "725e652cb1804300394de294ae5f61d61a9c3a22", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 104063f22c..abc06971c1 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -48,8 +48,10 @@ import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n import org.apache.geode.cache.util.CacheWriterAdapter;\n import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n import org.apache.geode.distributed.internal.InternalDistributedSystem;\n import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n import org.apache.geode.test.dunit.AsyncInvocation;\n"}}, {"oid": "725e652cb1804300394de294ae5f61d61a9c3a22", "url": "https://github.com/apache/geode/commit/725e652cb1804300394de294ae5f61d61a9c3a22", "message": "More tests for troubleshooting purposes.", "committedDate": "2020-04-02T16:54:47Z", "type": "forcePushed"}, {"oid": "80f14caedc1605c6e689af62aa3a3bded678d406", "url": "https://github.com/apache/geode/commit/80f14caedc1605c6e689af62aa3a3bded678d406", "message": "- Rebase against latest changes from feature/GEODE-7665.", "committedDate": "2020-04-15T10:35:18Z", "type": "forcePushed"}, {"oid": "9aea509566690a717892f352a65619a5dfdffff2", "url": "https://github.com/apache/geode/commit/9aea509566690a717892f352a65619a5dfdffff2", "message": "- Rebase against latest changes from feature/GEODE-7665.", "committedDate": "2020-05-13T10:04:10Z", "type": "forcePushed"}, {"oid": "bc4956d19c87fff0300c7008ae8db1c1759d0825", "url": "https://github.com/apache/geode/commit/bc4956d19c87fff0300c7008ae8db1c1759d0825", "message": "- Rebase against latest changes from feature/GEODE-7665.", "committedDate": "2020-05-13T10:16:27Z", "type": "forcePushed"}, {"oid": "bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "url": "https://github.com/apache/geode/commit/bd830f8b9c544f18e666d9b0815ca1c6e06e60e1", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed).", "committedDate": "2020-05-21T10:46:07Z", "type": "forcePushed"}, {"oid": "c5a4a76a471858274b345622a71004025bd1c14f", "url": "https://github.com/apache/geode/commit/c5a4a76a471858274b345622a71004025bd1c14f", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed).", "committedDate": "2020-06-02T15:55:24Z", "type": "forcePushed"}, {"oid": "e03690916dd18a0a7c40962f120d1df6c716e864", "url": "https://github.com/apache/geode/commit/e03690916dd18a0a7c40962f120d1df6c716e864", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (puts, gets, members\nadded and members removed).", "committedDate": "2020-06-04T13:26:38Z", "type": "forcePushed"}, {"oid": "bfc40f4eff22ae338c429549040bde08f43dceba", "url": "https://github.com/apache/geode/commit/bfc40f4eff22ae338c429549040bde08f43dceba", "message": "- Handle PartitionedRegionPartialClearException.", "committedDate": "2020-06-18T14:26:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwODQyMw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r447308423", "bodyText": "This validation needs to be changed....The RVV's are maintained as local-rvv (local to the node/member) and array of remote-rvvs (all other members). The RVVs has to be taken for corresponding member from both dumps and compared.", "author": "agingade", "createdAt": "2020-06-29T23:05:16Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,680 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION,\n+        RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] vms() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region is empty on requested VMs.\n+   */\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bucketId = 0; bucketId < BUCKETS; bucketId++) {\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+\n+          assertThat(otherDump.getRvv())", "originalCommit": "bfc40f4eff22ae338c429549040bde08f43dceba", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27b13e2967e627df529725b3ccd028b1a87a6e4c", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\ndeleted file mode 100644\nindex ad757ac5c2..0000000000\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ /dev/null\n\n@@ -1,680 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n- * agreements. See the NOTICE file distributed with this work for additional information regarding\n- * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n- * copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software distributed under the License\n- * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n- * or implied. See the License for the specific language governing permissions and limitations under\n- * the License.\n- */\n-package org.apache.geode.internal.cache;\n-\n-import static org.apache.geode.internal.util.ArrayUtils.asList;\n-import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n-import static org.apache.geode.test.dunit.VM.getVM;\n-import static org.assertj.core.api.Assertions.assertThat;\n-import static org.assertj.core.api.Assertions.assertThatThrownBy;\n-\n-import java.io.Serializable;\n-import java.time.Instant;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.stream.IntStream;\n-\n-import junitparams.JUnitParamsRunner;\n-import junitparams.Parameters;\n-import junitparams.naming.TestCaseName;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.runner.RunWith;\n-\n-import org.apache.geode.ForcedDisconnectException;\n-import org.apache.geode.cache.Cache;\n-import org.apache.geode.cache.CacheWriter;\n-import org.apache.geode.cache.CacheWriterException;\n-import org.apache.geode.cache.PartitionAttributes;\n-import org.apache.geode.cache.PartitionAttributesFactory;\n-import org.apache.geode.cache.PartitionedRegionPartialClearException;\n-import org.apache.geode.cache.Region;\n-import org.apache.geode.cache.RegionEvent;\n-import org.apache.geode.cache.RegionShortcut;\n-import org.apache.geode.cache.partition.PartitionRegionHelper;\n-import org.apache.geode.cache.util.CacheWriterAdapter;\n-import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n-import org.apache.geode.distributed.internal.DMStats;\n-import org.apache.geode.distributed.internal.InternalDistributedSystem;\n-import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n-import org.apache.geode.test.dunit.AsyncInvocation;\n-import org.apache.geode.test.dunit.VM;\n-import org.apache.geode.test.dunit.rules.CacheRule;\n-import org.apache.geode.test.dunit.rules.DistributedRule;\n-\n-/**\n- * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n- * on the same region while other cache operations are being executed concurrently and members are\n- * added or removed.\n- */\n-@RunWith(JUnitParamsRunner.class)\n-public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n-  private static final Integer BUCKETS = 13;\n-  private static final String REGION_NAME = \"PartitionedRegion\";\n-  private static final String TEST_CASE_NAME =\n-      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n-\n-  @Rule\n-  public DistributedRule distributedRule = new DistributedRule(3);\n-\n-  @Rule\n-  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n-\n-  private VM accessor, server1, server2;\n-\n-  private enum TestVM {\n-    ACCESSOR(0), SERVER1(1), SERVER2(2);\n-\n-    final int vmNumber;\n-\n-    TestVM(int vmNumber) {\n-      this.vmNumber = vmNumber;\n-    }\n-  }\n-\n-  @SuppressWarnings(\"unused\")\n-  static RegionShortcut[] regionTypes() {\n-    return new RegionShortcut[] {\n-        RegionShortcut.PARTITION,\n-        RegionShortcut.PARTITION_REDUNDANT\n-    };\n-  }\n-\n-  @SuppressWarnings(\"unused\")\n-  static TestVM[] vms() {\n-    return new TestVM[] {\n-        TestVM.SERVER1, TestVM.ACCESSOR\n-    };\n-  }\n-\n-  @SuppressWarnings(\"unused\")\n-  static Object[] vmAndRegionTypes() {\n-    ArrayList<Object[]> parameters = new ArrayList<>();\n-    RegionShortcut[] regionShortcuts = regionTypes();\n-\n-    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n-      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n-      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n-    });\n-\n-    return parameters.toArray();\n-  }\n-\n-  @Before\n-  public void setUp() throws Exception {\n-    server1 = getVM(TestVM.SERVER1.vmNumber);\n-    server2 = getVM(TestVM.SERVER2.vmNumber);\n-    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n-  }\n-\n-  private void initAccessor(RegionShortcut regionShortcut) {\n-    @SuppressWarnings(\"rawtypes\")\n-    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n-        .setTotalNumBuckets(BUCKETS)\n-        .setLocalMaxMemory(0)\n-        .create();\n-\n-    cacheRule.getCache().createRegionFactory(regionShortcut)\n-        .setPartitionAttributes(attributes)\n-        .create(REGION_NAME);\n-\n-  }\n-\n-  private void initDataStore(RegionShortcut regionShortcut) {\n-    @SuppressWarnings(\"rawtypes\")\n-    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n-        .setTotalNumBuckets(BUCKETS)\n-        .create();\n-\n-    cacheRule.getCache().createRegionFactory(regionShortcut)\n-        .setPartitionAttributes(attributes)\n-        .create(REGION_NAME);\n-  }\n-\n-  private void parametrizedSetup(RegionShortcut regionShortcut) {\n-    server1.invoke(() -> initDataStore(regionShortcut));\n-    server2.invoke(() -> initDataStore(regionShortcut));\n-    accessor.invoke(() -> initAccessor(regionShortcut));\n-  }\n-\n-  private void waitForSilence() {\n-    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n-    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n-    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n-\n-    await().untilAsserted(() -> {\n-      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n-      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n-      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n-      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n-      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n-      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n-    });\n-  }\n-\n-  /**\n-   * Populates the region and verifies the data on the selected VMs.\n-   */\n-  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n-    feeder.invoke(() -> {\n-      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n-      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n-    });\n-\n-    vms.forEach(vm -> vm.invoke(() -> {\n-      waitForSilence();\n-      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n-\n-      IntStream.range(0, entryCount)\n-          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n-    }));\n-  }\n-\n-  /**\n-   * Asserts that the region is empty on requested VMs.\n-   */\n-  private void assertRegionIsEmpty(List<VM> vms) {\n-    vms.forEach(vm -> vm.invoke(() -> {\n-      waitForSilence();\n-      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n-\n-      assertThat(region.getLocalSize()).isEqualTo(0);\n-    }));\n-  }\n-\n-  /**\n-   * Asserts that the region data is consistent across buckets.\n-   */\n-  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n-    List<BucketDump> bucketDumps;\n-    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n-    // Redundant copies + 1 primary.\n-    int expectedCopies = region.getRedundantCopies() + 1;\n-\n-    for (int bucketId = 0; bucketId < BUCKETS; bucketId++) {\n-      bucketDumps = region.getAllBucketEntries(bucketId);\n-      assertThat(bucketDumps.size())\n-          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n-              + bucketDumps.size())\n-          .isEqualTo(expectedCopies);\n-\n-      // Check that all copies of the bucket have the same data.\n-      if (bucketDumps.size() > 1) {\n-        BucketDump firstDump = bucketDumps.get(0);\n-\n-        for (int j = 1; j < bucketDumps.size(); j++) {\n-          BucketDump otherDump = bucketDumps.get(j);\n-\n-          assertThat(otherDump.getRvv())\n-              .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \"\n-                  + otherDump.getMember()\n-                  + \" is not consistent with member \" + firstDump.getMember())\n-              .isEqualTo(firstDump.getRvv());\n-\n-          assertThat(otherDump.getValues())\n-              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n-                  + \" are not consistent with member \" + firstDump.getMember())\n-              .isEqualTo(firstDump.getValues());\n-\n-          assertThat(otherDump.getVersions())\n-              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n-                  + \" are not consistent with member \" + firstDump.getMember())\n-              .isEqualTo(firstDump.getVersions());\n-        }\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n-   */\n-  private void executeGets(final int numEntries, final long durationInSeconds) {\n-    Cache cache = cacheRule.getCache();\n-    Region<String, String> region = cache.getRegion(REGION_NAME);\n-    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n-\n-    while (Instant.now().isBefore(finishTime)) {\n-      // Region might have been cleared in between, that's why we check for null.\n-      IntStream.range(0, numEntries).forEach(i -> {\n-        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n-        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n-      });\n-    }\n-  }\n-\n-  /**\n-   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n-   */\n-  private void executePuts(final int numEntries, final long durationInSeconds) {\n-    Cache cache = cacheRule.getCache();\n-    Region<String, String> region = cache.getRegion(REGION_NAME);\n-    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n-\n-    while (Instant.now().isBefore(finishTime)) {\n-      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n-    }\n-  }\n-\n-  /**\n-   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n-   */\n-  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n-    Cache cache = cacheRule.getCache();\n-    Map<String, String> valuesToInsert = new HashMap<>();\n-    Region<String, String> region = cache.getRegion(REGION_NAME);\n-    IntStream.range(start, finish)\n-        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n-\n-    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n-\n-    while (Instant.now().isBefore(finishTime)) {\n-      region.putAll(valuesToInsert);\n-    }\n-  }\n-\n-  /**\n-   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n-   */\n-  private void executeClears(final long durationInSeconds, final long waitTimeInMilliseconds)\n-      throws InterruptedException {\n-    Cache cache = cacheRule.getCache();\n-    Region<String, String> region = cache.getRegion(REGION_NAME);\n-    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n-\n-    while (Instant.now().isBefore(finishTime)) {\n-      region.clear();\n-      Thread.sleep(waitTimeInMilliseconds);\n-    }\n-  }\n-\n-  /**\n-   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n-   */\n-  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n-    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n-      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n-      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n-    }));\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Populates the Partition Region.\n-   * - Verifies that the entries are synchronized on all members.\n-   * - Launches one thread per VM to continuously execute gets for a given time.\n-   * - Clears the Partition Region continuously every X milliseconds for a given time.\n-   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n-   */\n-  @Test\n-  @TestCaseName(TEST_CASE_NAME)\n-  @Parameters(method = \"vmAndRegionTypes\")\n-  public void clearWithConcurrentGetsShouldWorkCorrectly(TestVM coordinatorVM,\n-      RegionShortcut regionShortcut) throws InterruptedException {\n-    final int entries = 10000;\n-    parametrizedSetup(regionShortcut);\n-    populateRegion(accessor, entries, asList(accessor, server1, server2));\n-\n-    // Let all VMs continuously execute gets for 10 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executeGets(entries, 10)),\n-        server2.invokeAsync(() -> executeGets(entries, 10)),\n-        accessor.invokeAsync(() -> executeGets(entries, 10)));\n-\n-    // Clear the region every half second seconds for 10 seconds.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(10, 500));\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region is empty across VMs.\n-    assertRegionIsEmpty(asList(accessor, server1, server1));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Launches one thread per VM to continuously execute puts for a given time.\n-   * - Clears the Partition Region continuously every X milliseconds for a given time.\n-   * - Asserts that, after the clears are finished, the Region Buckets are consistent.\n-   */\n-  @Test\n-  @TestCaseName(TEST_CASE_NAME)\n-  @Parameters(method = \"vmAndRegionTypes\")\n-  public void clearWithConcurrentPutsShouldWorkCorrectly(TestVM coordinatorVM,\n-      RegionShortcut regionShortcut) throws InterruptedException {\n-    final int entries = 5000;\n-    parametrizedSetup(regionShortcut);\n-\n-    // Let all VMs continuously execute puts for 15 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executePuts(entries, 15)),\n-        server2.invokeAsync(() -> executePuts(entries, 15)),\n-        accessor.invokeAsync(() -> executePuts(entries, 15)));\n-\n-    // Clear the region every half second for 15 seconds.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 500));\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region Buckets are consistent.\n-    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Launches one thread per VM to continuously execute putAll for a given time.\n-   * - Clears the Partition Region continuously every X milliseconds for a given time.\n-   * - Asserts that, after the clears are finished, the Region Buckets are consistent.\n-   */\n-  @Test\n-  @TestCaseName(TEST_CASE_NAME)\n-  @Parameters(method = \"vmAndRegionTypes\")\n-  public void clearWithConcurrentPutAllShouldWorkCorrectly(TestVM coordinatorVM,\n-      RegionShortcut regionShortcut) throws InterruptedException {\n-    parametrizedSetup(regionShortcut);\n-\n-    // Let all VMs continuously execute putAll for 15 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executePutAlls(0, 2000, 15)),\n-        server2.invokeAsync(() -> executePutAlls(2000, 4000, 15)),\n-        accessor.invokeAsync(() -> executePutAlls(4000, 6000, 15)));\n-\n-    // Clear the region every half second for 15 seconds.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(15, 500));\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region Buckets are consistent.\n-    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Launches threads to continuously execute put, get and putAll for a given time.\n-   * - Clears the Partition Region continuously every X milliseconds for a given time.\n-   * - Asserts that, after the clears are finished, the Region Buckets are consistent.\n-   */\n-  @Test\n-  @TestCaseName(TEST_CASE_NAME)\n-  @Parameters(method = \"vmAndRegionTypes\")\n-  public void clearWithConcurrentPutsAndGetsShouldWorkCorrectly(TestVM coordinatorVM,\n-      RegionShortcut regionShortcut)\n-      throws InterruptedException {\n-    final int entries = 15000;\n-    parametrizedSetup(regionShortcut);\n-\n-    // Let all VMs continuously execute puts and gets for 60 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executePuts(entries, 60)),\n-        server2.invokeAsync(() -> executeGets(entries, 60)),\n-        accessor.invokeAsync(() -> executePutAlls(0, entries, 60)));\n-\n-    // Clear the region every second for 60 seconds.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(60, 1000));\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region Buckets are consistent.\n-    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following:\n-   * - Populates the Partition Region.\n-   * - Verifies that the entries are synchronized on all members.\n-   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n-   * clear is in progress.\n-   * - Clears the Partition Region (at this point the coordinator is restarted).\n-   * - Asserts that, after the member joins again, the Region Buckets are consistent.\n-   */\n-  @Test\n-  @TestCaseName(\"[{index}] {method}(RegionType:{0})\")\n-  @Parameters(method = \"regionTypes\")\n-  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n-    final int entries = 1000;\n-    parametrizedSetup(regionShortcut);\n-    populateRegion(accessor, entries, asList(accessor, server1, server2));\n-    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n-\n-    // Clear the region.\n-    server1.invoke(() -> {\n-      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n-      assertThatThrownBy(region::clear)\n-          .isInstanceOf(DistributedSystemDisconnectedException.class)\n-          .hasCauseInstanceOf(ForcedDisconnectException.class);\n-    });\n-\n-    // Wait for member to get back online and assign all buckets.\n-    server1.invoke(() -> {\n-      cacheRule.createCache();\n-      initDataStore(regionShortcut);\n-      await().untilAsserted(\n-          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n-      PartitionRegionHelper.assignBucketsToPartitions(cacheRule.getCache().getRegion(REGION_NAME));\n-    });\n-\n-    // Assert Region Buckets are consistent.\n-    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Populates the Partition Region.\n-   * - Verifies that the entries are synchronized on all members.\n-   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n-   * clear is in progress (the member has primary buckets, though, so participates on\n-   * the clear operation).\n-   * - Launches one thread per VM to continuously execute gets for a given time.\n-   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n-   * - Asserts that, after the clears are finished, the Partition Region is empty on all members.\n-   */\n-  @Test\n-  @Parameters(method = \"vms\")\n-  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n-  public void clearOnRedundantPartitionRegionWithConcurrentGetsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n-      TestVM coordinatorVM) throws InterruptedException {\n-    final int entries = 7500;\n-    parametrizedSetup(RegionShortcut.PARTITION_REDUNDANT);\n-    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n-    populateRegion(accessor, entries, asList(accessor, server1, server2));\n-\n-    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executeGets(entries, 60)),\n-        accessor.invokeAsync(() -> executeGets(entries, 60)));\n-\n-    // Clear the region.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n-\n-    // Wait for member to get back online.\n-    server2.invoke(() -> {\n-      cacheRule.createCache();\n-      initDataStore(RegionShortcut.PARTITION_REDUNDANT);\n-      await().untilAsserted(\n-          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n-    });\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region is empty across VMs.\n-    assertRegionIsEmpty(asList(accessor, server1, server2));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Populates the Partition Region.\n-   * - Verifies that the entries are synchronized on all members.\n-   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n-   * clear is in progress (the member has primary buckets, though, so participates on\n-   * the clear operation).\n-   * - Launches one thread per VM to continuously execute gets for a given time.\n-   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n-   * - Asserts that the clear operation failed with PartitionedRegionPartialClearException (primary\n-   * buckets on the the restarted members are not available).\n-   */\n-  @Test\n-  @Parameters(method = \"vms\")\n-  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n-  public void clearOnNonRedundantPartitionRegionWithConcurrentGetsShouldFailWhenNonCoordinatorMembersAreBounced(\n-      TestVM coordinatorVM) throws InterruptedException {\n-    final int entries = 7500;\n-    parametrizedSetup(RegionShortcut.PARTITION);\n-    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n-    populateRegion(accessor, entries, asList(accessor, server1, server2));\n-\n-    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executeGets(entries, 60)),\n-        accessor.invokeAsync(() -> executeGets(entries, 60)));\n-\n-    // Clear the region.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> {\n-      assertThatThrownBy(() -> cacheRule.getCache().getRegion(REGION_NAME).clear())\n-          .isInstanceOf(PartitionedRegionPartialClearException.class)\n-          .hasMessage(\"Unable to clear all the buckets from the partitioned region \" + REGION_NAME\n-              + \", either data (buckets) moved or member departed.\");\n-    });\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n-   * clear is in progress (the member has primary buckets, though, so participates on\n-   * the clear operation).\n-   * - Launches one thread per VM to continuously execute puts for a given time.\n-   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n-   * - Asserts that, after the clears are finished, the Region Buckets are consistent.\n-   */\n-  @Test\n-  @Parameters(method = \"vms\")\n-  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n-  public void clearOnRedundantPartitionRegionWithConcurrentPutsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n-      TestVM coordinatorVM) throws InterruptedException {\n-    final int entries = 7000;\n-    parametrizedSetup(RegionShortcut.PARTITION_REDUNDANT);\n-    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n-\n-    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executePuts(entries, 60)),\n-        accessor.invokeAsync(() -> executePuts(entries, 60)));\n-\n-    // Clear the region.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> cacheRule.getCache().getRegion(REGION_NAME).clear());\n-\n-    // Wait for member to get back online.\n-    server2.invoke(() -> {\n-      cacheRule.createCache();\n-      initDataStore(RegionShortcut.PARTITION_REDUNDANT);\n-      await().untilAsserted(\n-          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n-    });\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-\n-    // Assert Region Buckets are consistent.\n-    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n-    accessor.invoke(this::assertRegionBucketsConsistency);\n-  }\n-\n-  /**\n-   * The test does the following (the clear coordinator is chosen through parameters):\n-   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n-   * clear is in progress (the member has primary buckets, though, so participates on\n-   * the clear operation).\n-   * - Launches one thread per VM to continuously execute puts for a given time.\n-   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n-   * - Asserts that the clear operation failed with PartitionedRegionPartialClearException (primary\n-   * buckets on the the restarted members are not available).\n-   */\n-  @Test\n-  @Parameters(method = \"vms\")\n-  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n-  public void clearOnNonRedundantPartitionRegionWithConcurrentPutsShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n-      TestVM coordinatorVM) throws InterruptedException {\n-    final int entries = 7000;\n-    parametrizedSetup(RegionShortcut.PARTITION);\n-    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n-\n-    // Let all VMs (except the one to kill) continuously execute gets for 60 seconds.\n-    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n-        server1.invokeAsync(() -> executePuts(entries, 60)),\n-        accessor.invokeAsync(() -> executePuts(entries, 60)));\n-\n-    // Clear the region.\n-    getVM(coordinatorVM.vmNumber).invoke(() -> {\n-      assertThatThrownBy(() -> cacheRule.getCache().getRegion(REGION_NAME).clear())\n-          .isInstanceOf(PartitionedRegionPartialClearException.class)\n-          .hasMessage(\"Unable to clear all the buckets from the partitioned region \" + REGION_NAME\n-              + \", either data (buckets) moved or member departed.\");\n-    });\n-\n-    // Let asyncInvocations finish.\n-    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n-      asyncInvocation.await();\n-    }\n-  }\n-\n-  /**\n-   * Shutdowns a member while the clear operation is in progress.\n-   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n-   * it's the clear coordinator or another member holding primary buckets.\n-   */\n-  public static class MemberKiller extends CacheWriterAdapter<String, String> {\n-\n-    @Override\n-    public synchronized void beforeRegionClear(RegionEvent<String, String> event)\n-        throws CacheWriterException {\n-      InternalDistributedSystem.getConnectedInstance().stopReconnectingNoDisconnect();\n-      MembershipManagerHelper.crashDistributedSystem(\n-          InternalDistributedSystem.getConnectedInstance());\n-      await().untilAsserted(\n-          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNull());\n-    }\n-  }\n-}\n"}}, {"oid": "27b13e2967e627df529725b3ccd028b1a87a6e4c", "url": "https://github.com/apache/geode/commit/27b13e2967e627df529725b3ccd028b1a87a6e4c", "message": "GEODE-7682: add PR.clear  API (#4755)\n\n* GEODE-7683: introduce BR.cmnClearRegion\n\nCo-authored-by: Xiaojian Zhou <gzhou@pivotal.io>", "committedDate": "2020-07-13T11:40:47Z", "type": "commit"}, {"oid": "e863e842e5a57ac505cf5d4f9a957283c0fd124e", "url": "https://github.com/apache/geode/commit/e863e842e5a57ac505cf5d4f9a957283c0fd124e", "message": "PR.clear's event id should be created and used in BR (#4805)\n\n* GEODE-7857: PR.clear's event id should be created and used in BR", "committedDate": "2020-07-13T11:40:48Z", "type": "commit"}, {"oid": "a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440", "url": "https://github.com/apache/geode/commit/a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-13T15:02:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r453976769", "bodyText": "The PartialClearException could happen here but not 100% will happen. Your assertion could fail here.", "author": "gesterzhou", "createdAt": "2020-07-13T22:22:09Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,715 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.CacheWriter;\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    List<String> keysToRemove = new ArrayList<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish).forEach(i -> keysToRemove.add(String.valueOf(i)));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.removeAll(keysToRemove);\n+    }\n+  }\n+\n+  /**\n+   * Execute the clear operation and retry until success.\n+   */\n+  private void executeClearWithRetry(VM coordinator) {\n+    coordinator.invoke(() -> {\n+      boolean retry;\n+\n+      do {\n+        retry = false;\n+\n+        try {\n+          cacheRule.getCache().getRegion(REGION_NAME).clear();\n+        } catch (PartitionedRegionPartialClearException pce) {\n+          retry = true;\n+        }\n+      } while (retry);\n+    });\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInMilliseconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInMilliseconds);\n+    }\n+  }\n+\n+  /**\n+   * Register the MemberKiller CacheWriter on the given vms and cancel auto-reconnects.\n+   */\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator and regionType are parametrized):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Launches one thread per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region continuously every X milliseconds for a given time.\n+   * - Asserts that, after the clears have finished, the Region Buckets are consistent across\n+   * members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"coordinatorsAndRegionTypes\")\n+  public void clearWithConcurrentPutGetRemoveShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int entries = 15000;\n+    final int workSeconds = 60;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute puts and gets for 60 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        server2.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Clear the region every second for 60 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(workSeconds, 1000));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator and regionType are parametrized):\n+   * - Launches two threads per VM to continuously execute putAll and removeAll for a given time.\n+   * - Clears the Partition Region continuously every X milliseconds for a given time.\n+   * - Asserts that, after the clears have finished, the Region Buckets are consistent across\n+   * members.\n+   */\n+  @Test\n+  @TestCaseName(TEST_CASE_NAME)\n+  @Parameters(method = \"coordinatorsAndRegionTypes\")\n+  public void clearWithConcurrentPutAllRemoveAllShouldWorkCorrectly(TestVM coordinatorVM,\n+      RegionShortcut regionShortcut) throws InterruptedException {\n+    final int workSeconds = 15;\n+    parametrizedSetup(regionShortcut);\n+\n+    // Let all VMs continuously execute putAll for 15 seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executePutAlls(0, 2000, workSeconds)),\n+        server1.invokeAsync(() -> executeRemoveAlls(0, 2000, workSeconds)),\n+        server2.invokeAsync(() -> executePutAlls(2000, 4000, workSeconds)),\n+        server2.invokeAsync(() -> executeRemoveAlls(2000, 4000, workSeconds)),\n+        accessor.invokeAsync(() -> executePutAlls(4000, 6000, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoveAlls(4000, 6000, workSeconds)));\n+\n+    // Clear the region every half second for 15 seconds.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> executeClears(workSeconds, 500));\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (regionType is parametrized):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop the coordinator VM while the\n+   * clear is in progress.\n+   * - Clears the Partition Region (at this point the coordinator is restarted).\n+   * - Asserts that, after the member joins again, the Region Buckets are consistent.\n+   */\n+  @Test\n+  @TestCaseName(\"[{index}] {method}(RegionType:{0})\")\n+  @Parameters(method = \"regionTypes\")\n+  public void clearShouldFailWhenCoordinatorMemberIsBounced(RegionShortcut regionShortcut) {\n+    final int entries = 1000;\n+    parametrizedSetup(regionShortcut);\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server1));\n+\n+    // Clear the region.\n+    server1.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      assertThatThrownBy(region::clear)\n+          .isInstanceOf(DistributedSystemDisconnectedException.class)\n+          .hasCauseInstanceOf(ForcedDisconnectException.class);\n+    });\n+\n+    // Wait for member to get back online and assign all buckets.\n+    server1.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionShortcut);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+      PartitionRegionHelper.assignBucketsToPartitions(cacheRule.getCache().getRegion(REGION_NAME));\n+    });\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches two threads per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that, after the clear has finished, the Region Buckets are consistent across members.\n+   */\n+  @Test\n+  @Parameters(method = \"coordinators\")\n+  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n+  public void clearOnRedundantPartitionRegionWithConcurrentPutGetRemoveShouldWorkCorrectlyWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM) throws InterruptedException {\n+    final int entries = 7500;\n+    final int workSeconds = 60;\n+    parametrizedSetup(RegionShortcut.PARTITION_REDUNDANT);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets, put and removes for 60\n+    // seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Retry the clear operation on the region until success (server2 will go down, but other\n+    // members will become primary for those buckets previously hosted by server2).\n+    executeClearWithRetry(getVM(coordinatorVM.vmNumber));\n+\n+    // Wait for member to get back online.\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(RegionShortcut.PARTITION_REDUNDANT);\n+      await().untilAsserted(\n+          () -> assertThat(InternalDistributedSystem.getConnectedInstance()).isNotNull());\n+    });\n+\n+    // Let asyncInvocations finish.\n+    for (AsyncInvocation<Void> asyncInvocation : asyncInvocationList) {\n+      asyncInvocation.await();\n+    }\n+\n+    // Assert Region Buckets are consistent.\n+    asList(accessor, server1, server2).forEach(vm -> vm.invoke(this::waitForSilence));\n+    accessor.invoke(this::assertRegionBucketsConsistency);\n+  }\n+\n+  /**\n+   * The test does the following (clear coordinator is chosen through parameters):\n+   * - Populates the Partition Region.\n+   * - Verifies that the entries are synchronized on all members.\n+   * - Sets the {@link MemberKiller} as a {@link CacheWriter} to stop a non-coordinator VM while the\n+   * clear is in progress (the member has primary buckets, though, so participates on\n+   * the clear operation).\n+   * - Launches two threads per VM to continuously execute gets, puts and removes for a given time.\n+   * - Clears the Partition Region (at this point the non-coordinator is restarted).\n+   * - Asserts that the clear operation failed with PartitionedRegionPartialClearException (primary\n+   * buckets on the the restarted members are not available).\n+   */\n+  @Test\n+  @Parameters(method = \"coordinators\")\n+  @TestCaseName(\"[{index}] {method}(Coordinator:{0})\")\n+  public void clearOnNonRedundantPartitionRegionWithConcurrentPutGetRemoveShouldFailWhenNonCoordinatorMembersAreBounced(\n+      TestVM coordinatorVM) throws InterruptedException {\n+    final int entries = 7500;\n+    final int workSeconds = 45;\n+    parametrizedSetup(RegionShortcut.PARTITION);\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+    populateRegion(accessor, entries, asList(accessor, server1, server2));\n+\n+    // Let all VMs (except the one to kill) continuously execute gets, put and removes for 45\n+    // seconds.\n+    List<AsyncInvocation<Void>> asyncInvocationList = Arrays.asList(\n+        server1.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        server1.invokeAsync(() -> executePuts(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeGets(entries, workSeconds)),\n+        accessor.invokeAsync(() -> executeRemoves(entries, workSeconds)));\n+\n+    // Clear the region.\n+    getVM(coordinatorVM.vmNumber).invoke(() -> {\n+      assertThatThrownBy(() -> cacheRule.getCache().getRegion(REGION_NAME).clear())", "originalCommit": "a24ace73cfaa3fc20ddfb9dcee4b67a22d9cd440", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDIxOTE4OA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r454219188", "bodyText": "@gesterzhou\nThere are three members in this test: ACCESSOR, SERVER1 and SERVER2, both servers host primary buckets locally for the region. The clear operation is executed either from the ACCESSOR or SERVER1, and SERVER2 is always killed through the MemberKiller class (CacheWriter.beforeRegionClear()) before the clear is locally executed.\nAccording to what I understand, the PartitionedRegionPartialClearException should always be thrown as SERVER2 doesn't get started (after the initial shutdown) until the clear \"finishes\", meaning that the clear coordinator will never be able to get the lock for all the primary buckets (the region is configured as PARTITION, not as PARTITION_REDUNDANT, so there are no secondary buckets that can become primary while SERVER2 is down).\nAm I missing something here?, shouldn't the exception be thrown no matter what, given the above conditions?.\n\nAs a side note, the test clearOnNonRedundantPartitionRegionWithConcurrentPutGetRemoveShouldFailWhenNonCoordinatorMembersAreBounced failed 4 times out of 100 executions, the actual failure depends on whether the clear is executed on the ACCESSOR or SERVER1 vm.\nThe two failures seen when the clear is executed on the the ACCESSOR node are basically assertion errors, caused by the fact the the PartitionedRegionPartialClearException is not thrown (discussed above).\nThe two failures seen when the clear is executed on SERVER1, on the other hand, are caused by the fact that the exception message is different from the one expected by the test (I'll change this and update the PR).", "author": "jujoramos", "createdAt": "2020-07-14T09:16:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM5NDkxMQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r454394911", "bodyText": "@gesterzhou\nI've modified the test assertion to always expect the PartitionedRegionPartialClearException but don't check the actual message, all the related failures are gone now.\nThe question still remains, though, the PartitionedRegionPartialClearException is always thrown under the conditions set by the test (that's what I would expect), why do you think the mentioned exception shouldn't be thrown 100% of time under these conditions?.", "author": "jujoramos", "createdAt": "2020-07-14T14:24:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUyODE1MA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r454528150", "bodyText": "Only when the primary holder cannot be found any where, the PartitionedRegionPartialClearException will be throw.\nIn your case, only killing server2. There're chances and races that the primary buckets are recreated quick enough on server1. So PartitionedRegionPartialClearException is not 100%.", "author": "gesterzhou", "createdAt": "2020-07-14T17:37:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1MDA1Ng==", "url": "https://github.com/apache/geode/pull/4848#discussion_r454950056", "bodyText": "Maybe I'm missing something here, but there's no activity on the cluster at the time server2 is killed, so the primaries previously hosted by that server shouldn't be recreated anywhere (and there are no secondaries to promote as the region is just PARTITION, not REDUNDANT_PARTITION). Moreover, and since server2 is abruptly shutdown, no other members can re-create the primaries as they don't have any of the data that was hosted by server2 at the time it was brought down.", "author": "jujoramos", "createdAt": "2020-07-15T10:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njc2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "8d913c51b9f24933fc1efb1370ebb24cf66eeb94", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 7f8822af05..b8d63adce3 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -400,9 +400,7 @@ public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements\n \n   /**\n    * The test does the following (clear coordinator and regionType are parametrized):\n-   * - Populates the Partition Region.\n-   * - Verifies that the entries are synchronized on all members.\n-   * - Launches one thread per VM to continuously execute gets, puts and removes for a given time.\n+   * - Launches one thread per VM to continuously execute removes, puts and gets for a given time.\n    * - Clears the Partition Region continuously every X milliseconds for a given time.\n    * - Asserts that, after the clears have finished, the Region Buckets are consistent across\n    * members.\n"}}, {"oid": "8d913c51b9f24933fc1efb1370ebb24cf66eeb94", "url": "https://github.com/apache/geode/commit/8d913c51b9f24933fc1efb1370ebb24cf66eeb94", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-14T13:14:10Z", "type": "forcePushed"}, {"oid": "57223db057da98ad76be13bb6d0933907b3e0f5c", "url": "https://github.com/apache/geode/commit/57223db057da98ad76be13bb6d0933907b3e0f5c", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-14T14:47:32Z", "type": "forcePushed"}, {"oid": "6ddee4249c54644c19b10d4ae307e4c3e78c912f", "url": "https://github.com/apache/geode/commit/6ddee4249c54644c19b10d4ae307e4c3e78c912f", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-14T15:19:56Z", "type": "forcePushed"}, {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "url": "https://github.com/apache/geode/commit/e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-16T13:03:05Z", "type": "commit"}, {"oid": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "url": "https://github.com/apache/geode/commit/e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "message": "GEODE-7670: Add Tests for PR clear\n\nAdded distributed tests to verify that the clear operation on\nPartitioned Regions works as expected when there are other\nconcurrent operations happening on the cache (put, putAll, get,\nremove, removeAll, members added and members removed).", "committedDate": "2020-07-16T13:03:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ2OTcwMA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457469700", "bodyText": "It's recommended not to declare multiple variables inline, so this should ideally be split into three separate lines.", "author": "DonalEvans", "createdAt": "2020-07-20T15:02:09Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3MTg0Nw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457471847", "bodyText": "This warning suppression is not necessary, as the method is used in coordinatorsAndRegionTypes() below.", "author": "DonalEvans", "createdAt": "2020-07-20T15:04:28Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3NTEwMQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457475101", "bodyText": "This warning suppression can be removed if the below line is changed to PartitionAttributes<String, String> attributes = new PartitionAttributesFactory<String, String>()", "author": "DonalEvans", "createdAt": "2020-07-20T15:08:07Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3NTM0Nw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457475347", "bodyText": "This warning suppression can be removed if the below line is changed to PartitionAttributes<String, String> attributes = new PartitionAttributesFactory<String, String>()", "author": "DonalEvans", "createdAt": "2020-07-20T15:08:26Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4MTY4MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457481681", "bodyText": "These warning suppressions can be safely removed if some changes are made in this method, as described below.", "author": "DonalEvans", "createdAt": "2020-07-20T15:14:53Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4MzA0MQ==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457483041", "bodyText": "These can be changed to RegionVersionVector<?> to prevent \"rawtypes\" warnings.", "author": "DonalEvans", "createdAt": "2020-07-20T15:16:10Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ4Njk0NA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457486944", "bodyText": "The following change set will remove the need for suppressed \"unchecked\" and \"rawtypes\" warnings in this method:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Map<VersionSource, RegionVersionHolder> rvv2Members =\n          \n          \n            \n                    new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n          \n          \n            \n                Map<VersionSource, RegionVersionHolder> rvv1Members =\n          \n          \n            \n                    new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n          \n          \n            \n                for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n          \n          \n            \n                  VersionSource memberId = entry.getKey();\n          \n          \n            \n                  RegionVersionHolder versionHolder1 = entry.getValue();\n          \n          \n            \n                  RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n          \n          \n            \n                Map<VersionSource<?>, RegionVersionHolder<?>> rvv2Members =\n          \n          \n            \n                    new HashMap<>(rvv1.getMemberToVersion());\n          \n          \n            \n                Map<VersionSource<?>, RegionVersionHolder<?>> rvv1Members =\n          \n          \n            \n                    new HashMap<>(rvv1.getMemberToVersion());\n          \n          \n            \n                for (Map.Entry<VersionSource<?>, RegionVersionHolder<?>> entry : rvv1Members.entrySet()) {\n          \n          \n            \n                  VersionSource<?> memberId = entry.getKey();\n          \n          \n            \n                  RegionVersionHolder<?> versionHolder1 = entry.getValue();\n          \n          \n            \n                  RegionVersionHolder<?> versionHolder2 = rvv2Members.remove(memberId);", "author": "DonalEvans", "createdAt": "2020-07-20T15:20:12Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5MjYyMA==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457492620", "bodyText": "The arguments \"start\" and \"finish\" here might be better named as \"startKey\" and \"endKey\" or something similar, to make it clear that they are not related to time.", "author": "DonalEvans", "createdAt": "2020-07-20T15:26:17Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5MzM0Mw==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457493343", "bodyText": "The arguments \"start\" and \"finish\" here might be better named as \"startKey\" and \"endKey\" or something similar, to make it clear that they are not related to time.", "author": "DonalEvans", "createdAt": "2020-07-20T15:27:04Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ5OTIyMg==", "url": "https://github.com/apache/geode/pull/4848#discussion_r457499222", "bodyText": "Instead of a while loop with a Thread.sleep(), it might be better to use the Timer and TimerTask classes to execute clears (specifically the scheduleAtFixedRate() method.) Entirely personal preference, but I do know that in general we try not to use Thread.sleep() directly in tests.", "author": "DonalEvans", "createdAt": "2020-07-20T15:33:32Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java", "diffHunk": "@@ -0,0 +1,733 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import java.io.Serializable;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.ForcedDisconnectException;\n+import org.apache.geode.cache.Cache;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.PartitionedRegionPartialClearException;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.distributed.DistributedSystemDisconnectedException;\n+import org.apache.geode.distributed.internal.ClusterDistributionManager;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.DistributionMessage;\n+import org.apache.geode.distributed.internal.DistributionMessageObserver;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.internal.cache.versions.RegionVersionHolder;\n+import org.apache.geode.internal.cache.versions.RegionVersionVector;\n+import org.apache.geode.internal.cache.versions.VersionSource;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+/**\n+ * Tests to verify that {@link PartitionedRegion#clear()} operation can be executed multiple times\n+ * on the same region while other cache operations are being executed concurrently and members are\n+ * added or removed.\n+ */\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithConcurrentOperationsDUnitTest implements Serializable {\n+  private static final Integer BUCKETS = 13;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  private static final String TEST_CASE_NAME =\n+      \"[{index}] {method}(Coordinator:{0}, RegionType:{1})\";\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  private VM accessor, server1, server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        RegionShortcut.PARTITION, RegionShortcut.PARTITION_REDUNDANT\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static TestVM[] coordinators() {\n+    return new TestVM[] {\n+        TestVM.SERVER1, TestVM.ACCESSOR\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] coordinatorsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      parameters.add(new Object[] {TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .setLocalMaxMemory(0)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    @SuppressWarnings(\"rawtypes\")\n+    PartitionAttributes attributes = new PartitionAttributesFactory<String, String>()\n+        .setTotalNumBuckets(BUCKETS)\n+        .create();\n+\n+    cacheRule.getCache().createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    server1.invoke(() -> initDataStore(regionShortcut));\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress()).isEqualTo(0);\n+      assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress()).isEqualTo(0);\n+    });\n+  }\n+\n+  /**\n+   * Populates the region and verifies the data on the selected VMs.\n+   */\n+  private void populateRegion(VM feeder, int entryCount, List<VM> vms) {\n+    feeder.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, entryCount).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    });\n+\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      IntStream.range(0, entryCount)\n+          .forEach(i -> assertThat(region.get(String.valueOf(i))).isEqualTo(\"Value_\" + i));\n+    }));\n+  }\n+\n+  /**\n+   * Asserts that the RegionVersionVectors for both buckets are consistent.\n+   *\n+   * @param bucketId Id of the bucket to compare.\n+   * @param bucketDump1 First bucketDump.\n+   * @param bucketDump2 Second bucketDump.\n+   */\n+  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+  private void assertRegionVersionVectorsConsistency(int bucketId, BucketDump bucketDump1,\n+      BucketDump bucketDump2) {\n+    RegionVersionVector rvv1 = bucketDump1.getRvv();\n+    RegionVersionVector rvv2 = bucketDump2.getRvv();\n+\n+    if (rvv1 == null) {\n+      assertThat(rvv2)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump2.getMember()\n+              + \", but does not on member \" + bucketDump1.getMember())\n+          .isNull();\n+    }\n+\n+    if (rvv2 == null) {\n+      assertThat(rvv1)\n+          .as(\"Bucket \" + bucketId + \" has an RVV on member \" + bucketDump1.getMember()\n+              + \", but does not on member \" + bucketDump2.getMember())\n+          .isNull();\n+    }\n+\n+    assertThat(rvv1).isNotNull();\n+    assertThat(rvv2).isNotNull();\n+    Map<VersionSource, RegionVersionHolder> rvv2Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    Map<VersionSource, RegionVersionHolder> rvv1Members =\n+        new HashMap<VersionSource, RegionVersionHolder>(rvv1.getMemberToVersion());\n+    for (Map.Entry<VersionSource, RegionVersionHolder> entry : rvv1Members.entrySet()) {\n+      VersionSource memberId = entry.getKey();\n+      RegionVersionHolder versionHolder1 = entry.getValue();\n+      RegionVersionHolder versionHolder2 = rvv2Members.remove(memberId);\n+      assertThat(versionHolder1)\n+          .as(\"RegionVersionVector for bucket \" + bucketId + \" on member \" + bucketDump1.getMember()\n+              + \" is not consistent with member \" + bucketDump2.getMember())\n+          .isEqualTo(versionHolder2);\n+    }\n+  }\n+\n+  /**\n+   * Asserts that the region data is consistent across buckets.\n+   */\n+  private void assertRegionBucketsConsistency() throws ForceReattemptException {\n+    List<BucketDump> bucketDumps;\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    // Redundant copies + 1 primary.\n+    int expectedCopies = region.getRedundantCopies() + 1;\n+\n+    for (int bId = 0; bId < BUCKETS; bId++) {\n+      final int bucketId = bId;\n+      bucketDumps = region.getAllBucketEntries(bucketId);\n+      assertThat(bucketDumps.size())\n+          .as(\"Bucket \" + bucketId + \" should have \" + expectedCopies + \" copies, but has \"\n+              + bucketDumps.size())\n+          .isEqualTo(expectedCopies);\n+\n+      // Check that all copies of the bucket have the same data.\n+      if (bucketDumps.size() > 1) {\n+        BucketDump firstDump = bucketDumps.get(0);\n+\n+        for (int j = 1; j < bucketDumps.size(); j++) {\n+          BucketDump otherDump = bucketDumps.get(j);\n+          assertRegionVersionVectorsConsistency(bucketId, firstDump, otherDump);\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getValues())\n+              .as(\"Values for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getValues()));\n+\n+          await().untilAsserted(() -> assertThat(otherDump.getVersions())\n+              .as(\"Versions for bucket \" + bucketId + \" on member \" + otherDump.getMember()\n+                  + \" are not consistent with member \" + firstDump.getMember())\n+              .isEqualTo(firstDump.getVersions()));\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute get operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeGets(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.get(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute put operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executePuts(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      IntStream.range(0, numEntries).forEach(i -> region.put(String.valueOf(i), \"Value_\" + i));\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute putAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executePutAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Map<String, String> valuesToInsert = new HashMap<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish)\n+        .forEach(i -> valuesToInsert.put(String.valueOf(i), \"Value_\" + i));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.putAll(valuesToInsert);\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute remove operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoves(final int numEntries, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      // Region might have been cleared in between, that's why we check for null.\n+      IntStream.range(0, numEntries).forEach(i -> {\n+        Optional<String> nullableValue = Optional.ofNullable(region.remove(String.valueOf(i)));\n+        nullableValue.ifPresent(value -> assertThat(value).isEqualTo(\"Value_\" + i));\n+      });\n+    }\n+  }\n+\n+  /**\n+   * Continuously execute removeAll operations on the PartitionedRegion for the given\n+   * durationInSeconds.\n+   */\n+  private void executeRemoveAlls(final int start, final int finish, final long durationInSeconds) {\n+    Cache cache = cacheRule.getCache();\n+    List<String> keysToRemove = new ArrayList<>();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    IntStream.range(start, finish).forEach(i -> keysToRemove.add(String.valueOf(i)));\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.removeAll(keysToRemove);\n+    }\n+  }\n+\n+  /**\n+   * Execute the clear operation and retry until success.\n+   */\n+  private void executeClearWithRetry(VM coordinator) {\n+    coordinator.invoke(() -> {\n+      boolean retry;\n+\n+      do {\n+        retry = false;\n+\n+        try {\n+          cacheRule.getCache().getRegion(REGION_NAME).clear();\n+        } catch (PartitionedRegionPartialClearException pce) {\n+          retry = true;\n+        }\n+\n+      } while (retry);\n+    });\n+  }\n+\n+  /**\n+   * Continuously execute clear operations on the PartitionedRegion for the given durationInSeconds.\n+   */\n+  private void executeClears(final long durationInSeconds, final long waitTimeInMilliseconds)\n+      throws InterruptedException {\n+    Cache cache = cacheRule.getCache();\n+    Region<String, String> region = cache.getRegion(REGION_NAME);\n+    Instant finishTime = Instant.now().plusSeconds(durationInSeconds);\n+\n+    while (Instant.now().isBefore(finishTime)) {\n+      region.clear();\n+      Thread.sleep(waitTimeInMilliseconds);", "originalCommit": "e0f6aa05dfcc4bd2d72ca14f21c553c717802565", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e2471e8ea2aff1f53781690bb5d107818f656c39", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\nindex 51780db0ed..fdb91c7005 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithConcurrentOperationsDUnitTest.java\n\n@@ -28,6 +28,11 @@ import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n import java.util.stream.IntStream;\n \n import junitparams.JUnitParamsRunner;\n"}}, {"oid": "e2471e8ea2aff1f53781690bb5d107818f656c39", "url": "https://github.com/apache/geode/commit/e2471e8ea2aff1f53781690bb5d107818f656c39", "message": "- Changes requested by reviewers.\n- Standardized time unit used through the test.", "committedDate": "2020-07-21T08:53:09Z", "type": "commit"}]}