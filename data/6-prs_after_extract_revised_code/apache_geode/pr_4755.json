{"pr_number": 4755, "pr_title": "GEODE-7682: add PR.clear  API", "pr_createdAt": "2020-03-02T21:39:00Z", "pr_url": "https://github.com/apache/geode/pull/4755", "timeline": [{"oid": "15c800304a507855cd04a9948d24d61b5da54211", "url": "https://github.com/apache/geode/commit/15c800304a507855cd04a9948d24d61b5da54211", "message": "GEODE-7683: introduce BR.cmnClearRegion\n\nCo-authored-by: Xiaojian Zhou <gzhou@pivotal.io>\n\nGEODE-7684: Create messaging class for PR Clear (#4689)\n\n* Added new message class and test\n\nCo-authored-by: Benjamin Ross <bross@pivotal.io>\nCo-authored-by: Donal Evans <doevans@pivotal.io>", "committedDate": "2020-02-28T23:20:42Z", "type": "commit"}, {"oid": "25177d3968f6140df3521d844769006da6fb795e", "url": "https://github.com/apache/geode/commit/25177d3968f6140df3521d844769006da6fb795e", "message": "GEODE-7682: add PR.clear API", "committedDate": "2020-03-02T07:45:31Z", "type": "commit"}, {"oid": "38c4c45a243aeaae074e2b531bac4dc4bb924f00", "url": "https://github.com/apache/geode/commit/38c4c45a243aeaae074e2b531bac4dc4bb924f00", "message": "fix warnings", "committedDate": "2020-03-02T17:27:30Z", "type": "commit"}, {"oid": "2912becea43acc49971338cb8ef7ec4053203f2f", "url": "https://github.com/apache/geode/commit/2912becea43acc49971338cb8ef7ec4053203f2f", "message": "add dunit test case", "committedDate": "2020-03-02T23:30:23Z", "type": "commit"}, {"oid": "4465d95e6b07c3e0328c8d6932615393d53782e8", "url": "https://github.com/apache/geode/commit/4465d95e6b07c3e0328c8d6932615393d53782e8", "message": "add dunit test", "committedDate": "2020-03-03T02:16:02Z", "type": "commit"}, {"oid": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "url": "https://github.com/apache/geode/commit/cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "message": "add test case for client/server", "committedDate": "2020-03-03T22:37:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NTY1MQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387345651", "bodyText": "Would it make sense to just remove this as part of unsupported?\nIt looks like putAll was once unsupported and now it just falls through, but we don't verify anything... we can probably just remove clear from this unsupported test", "author": "jhuynh1", "createdAt": "2020-03-03T22:57:35Z", "path": "geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java", "diffHunk": "@@ -1309,12 +1309,7 @@ public void test023UnsupportedOps() throws Exception {\n       pr.put(new Integer(3), \"three\");\n       pr.getEntry(\"key\");\n \n-      try {\n-        pr.clear();\n-        fail(\n-            \"PartitionedRegionSingleNodeOperationTest:testUnSupportedOps() operation failed on a blank PartitionedRegion\");\n-      } catch (UnsupportedOperationException expected) {\n-      }\n+      pr.clear();", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1OTUxOA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387359518", "bodyText": "OK, I will remove it.", "author": "gesterzhou", "createdAt": "2020-03-03T23:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NTY1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java b/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java\nindex efda321c23..e311ad4f0b 100644\n--- a/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java\n+++ b/geode-core/src/integrationTest/java/org/apache/geode/internal/cache/PartitionedRegionSingleNodeOperationsJUnitTest.java\n\n@@ -1297,66 +1296,6 @@ public class PartitionedRegionSingleNodeOperationsJUnitTest {\n     }\n   }\n \n-  @Test\n-  public void test023UnsupportedOps() throws Exception {\n-    Region pr = null;\n-    try {\n-      pr = PartitionedRegionTestHelper.createPartitionedRegion(\"testUnsupportedOps\",\n-          String.valueOf(200), 0);\n-\n-      pr.put(new Integer(1), \"one\");\n-      pr.put(new Integer(2), \"two\");\n-      pr.put(new Integer(3), \"three\");\n-      pr.getEntry(\"key\");\n-\n-      pr.clear();\n-\n-      // try {\n-      // pr.entries(true);\n-      // fail();\n-      // }\n-      // catch (UnsupportedOperationException expected) {\n-      // }\n-\n-      // try {\n-      // pr.entrySet(true);\n-      // fail();\n-      // }\n-      // catch (UnsupportedOperationException expected) {\n-      // }\n-\n-      try {\n-        HashMap data = new HashMap();\n-        data.put(\"foo\", \"bar\");\n-        data.put(\"bing\", \"bam\");\n-        data.put(\"supper\", \"hero\");\n-        pr.putAll(data);\n-        // fail(\"testPutAll() does NOT throw UnsupportedOperationException\");\n-      } catch (UnsupportedOperationException onse) {\n-      }\n-\n-\n-      // try {\n-      // pr.values();\n-      // fail(\"testValues() does NOT throw UnsupportedOperationException\");\n-      // }\n-      // catch (UnsupportedOperationException expected) {\n-      // }\n-\n-\n-      try {\n-        pr.containsValue(\"foo\");\n-      } catch (UnsupportedOperationException ex) {\n-        fail(\"PartitionedRegionSingleNodeOperationTest:testContainsValue() operation failed\");\n-      }\n-\n-    } finally {\n-      if (pr != null) {\n-        pr.destroyRegion();\n-      }\n-    }\n-  }\n-\n   /**\n    * This method validates size operations. It verifies that it returns correct size of the\n    * PartitionedRegion.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NjQ4NA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387346484", "bodyText": "we can possibly not get the lock, throw an illegal state exception and then just continue as if we have the lock?", "author": "jhuynh1", "createdAt": "2020-03-03T22:59:45Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4NzQ5OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387487498", "bodyText": "fixed.", "author": "gesterzhou", "createdAt": "2020-03-04T07:26:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NjQ4NA=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex acd2bb1636..c61ed00a58 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2153,6 +2153,7 @@ public class PartitionedRegion extends LocalRegion\n         lockService.lock(\"_clearOperation\", -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n+        throw e;\n       }\n       try {\n         if (cache.isCacheAtShutdownAll()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0NzQ1Ng==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387347456", "bodyText": "with comment from before, there is a chance we didn't acquire the lock (due to illegal state exception.. this might see a problem in that case.", "author": "jhuynh1", "createdAt": "2020-03-03T23:02:07Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (logger.isDebugEnabled()) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex acd2bb1636..c61ed00a58 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2153,6 +2153,7 @@ public class PartitionedRegion extends LocalRegion\n         lockService.lock(\"_clearOperation\", -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n+        throw e;\n       }\n       try {\n         if (cache.isCacheAtShutdownAll()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODI5MQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348291", "bodyText": "Is this new code?  If so, this is a fairly long method, any chance we can break it into smaller helper methods?  I would assume unit testing this method would be a lot easier at that point as we could unit test the individual smaller methods instead", "author": "jhuynh1", "createdAt": "2020-03-03T23:04:23Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,197 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (logger.isDebugEnabled()) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4ODc4OQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387488789", "bodyText": "It's old code, copied from RemoveAll.", "author": "gesterzhou", "createdAt": "2020-03-04T07:29:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODI5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex acd2bb1636..c61ed00a58 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2153,6 +2153,7 @@ public class PartitionedRegion extends LocalRegion\n         lockService.lock(\"_clearOperation\", -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n+        throw e;\n       }\n       try {\n         if (cache.isCacheAtShutdownAll()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODg1OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348858", "bodyText": "Any reason why we removed the type?", "author": "jhuynh1", "createdAt": "2020-03-03T23:06:01Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -109,14 +106,9 @@ public boolean isSevereAlertCompatible() {\n     return true;\n   }\n \n-  public RegionEventImpl getRegionEvent() {\n-    return regionEvent;\n-  }\n-\n   public ClearResponse send(DistributedMember recipient, PartitionedRegion region)\n       throws ForceReattemptException {\n-    Set<InternalDistributedMember> recipients =\n-        Collections.singleton((InternalDistributedMember) recipient);\n+    Set recipients = Collections.singleton(recipient);", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ4OTkyNA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387489924", "bodyText": "fix.", "author": "gesterzhou", "createdAt": "2020-03-04T07:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODg1OA=="}], "type": "inlineReview", "revised_code": {"commit": "b7e11f681cd658d5cf3253369be93dd165f6661c", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 15b281bd5c..29a7fc0c89 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -108,7 +108,8 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n \n   public ClearResponse send(DistributedMember recipient, PartitionedRegion region)\n       throws ForceReattemptException {\n-    Set recipients = Collections.singleton(recipient);\n+    Set<InternalDistributedMember> recipients =\n+        Collections.singleton((InternalDistributedMember) recipient);\n     ClearResponse clearResponse = new ClearResponse(region.getSystem(), recipients);\n     initMessage(region, recipients, clearResponse);\n     if (logger.isDebugEnabled()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODkzNA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387348934", "bodyText": "why is this null now?", "author": "jhuynh1", "createdAt": "2020-03-03T23:06:16Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -143,20 +135,18 @@ public void toData(DataOutput out, SerializationContext context) throws IOExcept\n     } else {\n       InternalDataSerializer.writeSignedVL(bucketId, out);\n     }\n-    DataSerializer.writeObject(regionEvent, out);\n   }\n \n   @Override\n   public void fromData(DataInput in, DeserializationContext context)\n       throws IOException, ClassNotFoundException {\n     super.fromData(in, context);\n     this.bucketId = (int) InternalDataSerializer.readSignedVL(in);\n-    this.regionEvent = DataSerializer.readObject(in);\n   }\n \n   @Override\n   public EventID getEventID() {\n-    return regionEvent.getEventId();\n+    return null;", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MDA3NQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387490075", "bodyText": "It's not used.", "author": "gesterzhou", "createdAt": "2020-03-04T07:33:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM0ODkzNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDA0Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387350043", "bodyText": "Should this now be changed to say //Check if we obtained primary lock...", "author": "jhuynh1", "createdAt": "2020-03-03T23:09:10Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +169,31 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region, int bucketId)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n     // Check if we are primary, throw exception if not", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MTI5NQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387491295", "bodyText": "Done", "author": "gesterzhou", "createdAt": "2020-03-04T07:36:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDA0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 15b281bd5c..e0c815e7c8 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -173,14 +173,14 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n     return this.bucketId;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region, int bucketId)\n+  public boolean doLocalClear(PartitionedRegion region)\n       throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n     BucketRegion bucketRegion =\n         region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n     boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n-    // Check if we are primary, throw exception if not\n+    // Check if we obtained primary lock, throw exception if not\n     if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDUyNQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387350525", "bodyText": "remove?", "author": "jhuynh1", "createdAt": "2020-03-03T23:10:37Z", "path": "geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java", "diffHunk": "@@ -61,64 +60,43 @@\n   @Before\n   public void setup() throws ForceReattemptException {\n     message = spy(new ClearPRMessage());\n+    InternalDistributedMember member = mock(InternalDistributedMember.class);\n     region = mock(PartitionedRegion.class, RETURNS_DEEP_STUBS);\n     dataStore = mock(PartitionedRegionDataStore.class);\n     when(region.getDataStore()).thenReturn(dataStore);\n+    when(region.getFullPath()).thenReturn(\"/test\");\n     bucketRegion = mock(BucketRegion.class);\n     when(dataStore.getInitializedBucketForId(any(), any())).thenReturn(bucketRegion);\n+    RegionEventImpl bucketRegionEventImpl = mock(RegionEventImpl.class);\n+    // RegionEventImpl(bucketRegion, Operation.REGION_CLEAR, null, false, member, true);", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MTI1MA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387491250", "bodyText": "Done.", "author": "gesterzhou", "createdAt": "2020-03-04T07:36:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM1MDUyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java b/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java\nindex 3568ff047c..15056cc185 100644\n--- a/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java\n+++ b/geode-core/src/test/java/org/apache/geode/internal/cache/partitioned/ClearPRMessageTest.java\n\n@@ -68,14 +68,13 @@ public class ClearPRMessageTest {\n     bucketRegion = mock(BucketRegion.class);\n     when(dataStore.getInitializedBucketForId(any(), any())).thenReturn(bucketRegion);\n     RegionEventImpl bucketRegionEventImpl = mock(RegionEventImpl.class);\n-    // RegionEventImpl(bucketRegion, Operation.REGION_CLEAR, null, false, member, true);\n   }\n \n   @Test\n   public void doLocalClearThrowsExceptionWhenBucketIsNotPrimaryAtFirstCheck() {\n     when(bucketRegion.isPrimary()).thenReturn(false);\n \n-    assertThatThrownBy(() -> message.doLocalClear(region, 0))\n+    assertThatThrownBy(() -> message.doLocalClear(region))\n         .isInstanceOf(ForceReattemptException.class)\n         .hasMessageContaining(ClearPRMessage.BUCKET_NON_PRIMARY_MESSAGE);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NzAwOA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387367008", "bodyText": "The int bucketId in the parameter list is never used.", "author": "jchen21", "createdAt": "2020-03-04T00:00:29Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +169,31 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region, int bucketId)", "originalCommit": "cc8577d6a8c7c81495cd4fb7431d57dc9041bb04", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ5MjU0MA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387492540", "bodyText": "Fixed.", "author": "gesterzhou", "createdAt": "2020-03-04T07:40:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NzAwOA=="}], "type": "inlineReview", "revised_code": {"commit": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 15b281bd5c..e0c815e7c8 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -173,14 +173,14 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n     return this.bucketId;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region, int bucketId)\n+  public boolean doLocalClear(PartitionedRegion region)\n       throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n     BucketRegion bucketRegion =\n         region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n     boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n-    // Check if we are primary, throw exception if not\n+    // Check if we obtained primary lock, throw exception if not\n     if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n"}}, {"oid": "605f37ae56a6b01489595afa30cbfcf9ab81f704", "url": "https://github.com/apache/geode/commit/605f37ae56a6b01489595afa30cbfcf9ab81f704", "message": "fix based on jason's comments", "committedDate": "2020-03-04T07:43:01Z", "type": "commit"}, {"oid": "5e1847b1e8b306038eb1d87080fba8983af9c868", "url": "https://github.com/apache/geode/commit/5e1847b1e8b306038eb1d87080fba8983af9c868", "message": "fix test", "committedDate": "2020-03-04T17:05:10Z", "type": "commit"}, {"oid": "b7e11f681cd658d5cf3253369be93dd165f6661c", "url": "https://github.com/apache/geode/commit/b7e11f681cd658d5cf3253369be93dd165f6661c", "message": "fix based on comments", "committedDate": "2020-03-04T17:18:29Z", "type": "commit"}, {"oid": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "url": "https://github.com/apache/geode/commit/2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "message": "fix based on review comments, and POE handling", "committedDate": "2020-03-04T17:25:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg0MDUyNw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387840527", "bodyText": "typo", "author": "gesterzhou", "createdAt": "2020-03-04T18:06:32Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +171,35 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();\n+      regionEvent.setOperation(Operation.REGION_CLEAR);\n+      regionEvent.setRegion(bucketRegion);\n+      bucketRegion.cmnClearRegion(regionEvent, true, true);\n+    } catch (PartitionOfflineException poe) {\n+      logger.info(\"There is no member to hold bukcet {}, not to retry any more\", this.bucketId,", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "47c0f5c690a36878507008aa366ecc0d82580789", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex cb20faade3..b6cfdd6d53 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -192,7 +192,7 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n       regionEvent.setRegion(bucketRegion);\n       bucketRegion.cmnClearRegion(regionEvent, true, true);\n     } catch (PartitionOfflineException poe) {\n-      logger.info(\"There is no member to hold bukcet {}, not to retry any more\", this.bucketId,\n+      logger.info(\"There is no member to hold bucket {}, not to retry any more\", this.bucketId,\n           poe);\n       throw poe;\n     } catch (Exception ex) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4MDE0Mg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387880142", "bodyText": "Based on the API doc, ALL_KEYS behavior is now deprecated, please use an alternative.", "author": "jchen21", "createdAt": "2020-03-04T19:20:04Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.stream.IntStream;\n+\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, accessor;\n+  protected ClientVM client1, client2;\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    locator = cluster.startLocatorVM(0);\n+    locatorPort = locator.getPort();\n+    dataStore1 = cluster.startServerVM(1, locatorPort);\n+    dataStore2 = cluster.startServerVM(2, locatorPort);\n+    accessor = cluster.startServerVM(3, locatorPort);\n+    client1 = cluster.startClientVM(4,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    client2 = cluster.startClientVM(5,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    dataStore1.invoke(this::initDataStore);\n+    dataStore2.invoke(this::initDataStore);\n+    accessor.invoke(this::initAccessor);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+  }\n+\n+  protected RegionShortcut getRegionShortCut() {\n+    return RegionShortcut.PARTITION_REDUNDANT;\n+  }\n+\n+  private Region getRegion(boolean isClient) {\n+    if (isClient) {\n+      return getClientCache().getRegion(REGION_NAME);\n+    } else {\n+      return getCache().getRegion(REGION_NAME);\n+    }\n+  }\n+\n+  private void verifyRegionSize(boolean isClient, int expectedNum) {\n+    assertThat(getRegion(isClient).size()).isEqualTo(expectedNum);\n+  }\n+\n+  private void initClientCache() {\n+    Region region = getClientCache().createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)\n+        .create(REGION_NAME);\n+    region.registerInterest(\"ALL_KEYS\");", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3Mzc3MQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387973771", "bodyText": "fixed. changed to registerInterestForAllKeys(InterestResultPolicy.KEYS)", "author": "gesterzhou", "createdAt": "2020-03-04T22:30:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4MDE0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "47c0f5c690a36878507008aa366ecc0d82580789", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\nindex b312861a9d..009289c52c 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n\n@@ -21,14 +21,18 @@ import static org.assertj.core.api.Assertions.assertThat;\n import java.io.Serializable;\n import java.util.stream.IntStream;\n \n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n \n import org.apache.geode.cache.PartitionAttributesFactory;\n import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n import org.apache.geode.cache.RegionShortcut;\n import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.util.CacheListenerAdapter;\n import org.apache.geode.test.dunit.rules.ClientVM;\n import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n import org.apache.geode.test.dunit.rules.MemberVM;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5ODIwOQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387898209", "bodyText": "clearPRMessage.doLocalClear never returns false. It either returns true or throws exception. Is it expected?", "author": "jchen21", "createdAt": "2020-03-04T19:52:29Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3OTA4Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387979083", "bodyText": "yes, we need to wait for something from the response (which is a reply processor). a boolean is a minimum.", "author": "gesterzhou", "createdAt": "2020-03-04T22:43:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5ODIwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2289,21 +2289,17 @@ public class PartitionedRegion extends LocalRegion\n         if (result) {\n           return;\n         }\n-      } catch (ForceReattemptException prce) {\n+      } catch (ForceReattemptException fre) {\n         checkReadiness();\n         InternalDistributedMember lastTarget = currentTarget;\n         if (retryTime == null) {\n           retryTime = new RetryTimeKeeper(this.retryTimeout);\n         }\n         currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n-        if (logger.isDebugEnabled()) {\n-          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n-              currentTarget);\n-        }\n         if (lastTarget.equals(currentTarget)) {\n           if (logger.isDebugEnabled()) {\n             logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n-                currentTarget, prce.getMessage());\n+                currentTarget, fre.getMessage());\n           }\n           if (retryTime.overMaximum()) {\n             PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMjg2Ng==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387902866", "bodyText": "Why this variable is called prce?", "author": "jchen21", "createdAt": "2020-03-04T20:01:01Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3NDc4Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387974783", "bodyText": "It's copied from old code. But I have fixed it here to fre.", "author": "gesterzhou", "createdAt": "2020-03-04T22:32:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMjg2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2289,21 +2289,17 @@ public class PartitionedRegion extends LocalRegion\n         if (result) {\n           return;\n         }\n-      } catch (ForceReattemptException prce) {\n+      } catch (ForceReattemptException fre) {\n         checkReadiness();\n         InternalDistributedMember lastTarget = currentTarget;\n         if (retryTime == null) {\n           retryTime = new RetryTimeKeeper(this.retryTimeout);\n         }\n         currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n-        if (logger.isDebugEnabled()) {\n-          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n-              currentTarget);\n-        }\n         if (lastTarget.equals(currentTarget)) {\n           if (logger.isDebugEnabled()) {\n             logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n-                currentTarget, prce.getMessage());\n+                currentTarget, fre.getMessage());\n           }\n           if (retryTime.overMaximum()) {\n             PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMzYzMQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387903631", "bodyText": "If  lastTarget is the same as currentTarget, we have two debug messages: line 2305 and line 2300. This is a little bit duplicate.", "author": "jchen21", "createdAt": "2020-03-04T20:02:32Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3NzE5MQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387977191", "bodyText": "move one of it into else. Again it's copied from old code.", "author": "gesterzhou", "createdAt": "2020-03-04T22:38:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwMzYzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2289,21 +2289,17 @@ public class PartitionedRegion extends LocalRegion\n         if (result) {\n           return;\n         }\n-      } catch (ForceReattemptException prce) {\n+      } catch (ForceReattemptException fre) {\n         checkReadiness();\n         InternalDistributedMember lastTarget = currentTarget;\n         if (retryTime == null) {\n           retryTime = new RetryTimeKeeper(this.retryTimeout);\n         }\n         currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n-        if (logger.isDebugEnabled()) {\n-          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n-              currentTarget);\n-        }\n         if (lastTarget.equals(currentTarget)) {\n           if (logger.isDebugEnabled()) {\n             logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n-                currentTarget, prce.getMessage());\n+                currentTarget, fre.getMessage());\n           }\n           if (retryTime.overMaximum()) {\n             PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwNDcxOQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387904719", "bodyText": "Should this code block be executed even when lastTarget is not equal to currentTarget?", "author": "jchen21", "createdAt": "2020-03-04T20:04:48Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, prce.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3Nzk1OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387977958", "bodyText": "this is copied from existing code. I will leave it as is.", "author": "gesterzhou", "createdAt": "2020-03-04T22:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkwNDcxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2289,21 +2289,17 @@ public class PartitionedRegion extends LocalRegion\n         if (result) {\n           return;\n         }\n-      } catch (ForceReattemptException prce) {\n+      } catch (ForceReattemptException fre) {\n         checkReadiness();\n         InternalDistributedMember lastTarget = currentTarget;\n         if (retryTime == null) {\n           retryTime = new RetryTimeKeeper(this.retryTimeout);\n         }\n         currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n-        if (logger.isDebugEnabled()) {\n-          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n-              currentTarget);\n-        }\n         if (lastTarget.equals(currentTarget)) {\n           if (logger.isDebugEnabled()) {\n             logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n-                currentTarget, prce.getMessage());\n+                currentTarget, fre.getMessage());\n           }\n           if (retryTime.overMaximum()) {\n             PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyMTk5NQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387921995", "bodyText": "Do we need to make any change for this function?", "author": "jchen21", "createdAt": "2020-03-04T20:41:37Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,202 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException prce) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (logger.isDebugEnabled()) {\n+          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n+              currentTarget);\n+        }\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, prce.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();\n+        }\n+      }\n+\n+      // It's possible this is a GemFire thread e.g. ServerConnection\n+      // which got to this point because of a distributed system shutdown or\n+      // region closure which uses interrupt to break any sleep() or wait()\n+      // calls\n+      // e.g. waitForPrimary or waitForBucketRecovery in which case throw\n+      // exception\n+      checkShutdown();\n+\n+      // If we get here, the attempt failed...\n+      if (count == 1) {\n+        // TODO prStats add ClearPRMsg retried\n+        this.prStats.incPutAllMsgsRetried();\n+      }\n+    }\n+  }\n+\n+  List<ClearPRMessage> createClearPRMessages() {\n+    if (cache.isCacheAtShutdownAll()) {\n+      throw cache.getCacheClosedException(\"Cache is shutting down\");\n+    }\n+\n+    ArrayList<ClearPRMessage> clearMsgList = new ArrayList<>();\n+    for (int bucketId = 0; bucketId < this.totalNumberOfBuckets; bucketId++) {\n+      ClearPRMessage clearPRMessage = new ClearPRMessage(bucketId);\n+      clearMsgList.add(clearPRMessage);\n+    }\n+    return clearMsgList;\n   }\n \n   @Override", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk4MTU2Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387981563", "bodyText": "No. I confirmed.", "author": "gesterzhou", "createdAt": "2020-03-04T22:49:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyMTk5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2289,21 +2289,17 @@ public class PartitionedRegion extends LocalRegion\n         if (result) {\n           return;\n         }\n-      } catch (ForceReattemptException prce) {\n+      } catch (ForceReattemptException fre) {\n         checkReadiness();\n         InternalDistributedMember lastTarget = currentTarget;\n         if (retryTime == null) {\n           retryTime = new RetryTimeKeeper(this.retryTimeout);\n         }\n         currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n-        if (logger.isDebugEnabled()) {\n-          logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,\n-              currentTarget);\n-        }\n         if (lastTarget.equals(currentTarget)) {\n           if (logger.isDebugEnabled()) {\n             logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n-                currentTarget, prce.getMessage());\n+                currentTarget, fre.getMessage());\n           }\n           if (retryTime.overMaximum()) {\n             PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyNTkyOA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387925928", "bodyText": "Better update the Javadoc, a new parameter is introduced.", "author": "jchen21", "createdAt": "2020-03-04T20:49:39Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -3122,7 +3307,7 @@ private boolean putInBucket(final InternalDistributedMember targetNode, final In\n    * @return a Node which contains the bucket, potentially null\n    */\n   private InternalDistributedMember waitForNodeOrCreateBucket(RetryTimeKeeper retryTime,\n-      EntryEventImpl event, Integer bucketId) {\n+      EntryEventImpl event, Integer bucketId, boolean createIfNotExist) {", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk3OTkxMw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387979913", "bodyText": "Done", "author": "gesterzhou", "createdAt": "2020-03-04T22:45:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkyNTkyOA=="}], "type": "inlineReview", "revised_code": {"commit": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 37647419ab..507708688d 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -3304,6 +3305,7 @@ public class PartitionedRegion extends LocalRegion\n    * @param retryTime the RetryTimeKeeper to track retry times\n    * @param event the event used to get the entry size in the event a new bucket should be created\n    * @param bucketId the identity of the bucket should it be created\n+   * @param createIfNotExist boolean to indicate if to create a bucket if found not exist\n    * @return a Node which contains the bucket, potentially null\n    */\n   private InternalDistributedMember waitForNodeOrCreateBucket(RetryTimeKeeper retryTime,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkzMjgwMQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387932801", "bodyText": "Why not use the other non-zero-argument constructor of RegionEventImpl? Then we don't have to the setters in the next two lines. Is there any concern of side effect?", "author": "jchen21", "createdAt": "2020-03-04T21:03:32Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,39 +171,35 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public int getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();", "originalCommit": "2ab9beb4cc1d49e61c8eaa125815c925b99ccfbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk4MTEyMg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r387981122", "bodyText": "If use existing constructor, I will have to specify a few NULLs in the parameters. This will confuse people. Using 2 setters will emphasize that I only care the 2 attributes.", "author": "gesterzhou", "createdAt": "2020-03-04T22:48:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzkzMjgwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "47c0f5c690a36878507008aa366ecc0d82580789", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex cb20faade3..b6cfdd6d53 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -192,7 +192,7 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n       regionEvent.setRegion(bucketRegion);\n       bucketRegion.cmnClearRegion(regionEvent, true, true);\n     } catch (PartitionOfflineException poe) {\n-      logger.info(\"There is no member to hold bukcet {}, not to retry any more\", this.bucketId,\n+      logger.info(\"There is no member to hold bucket {}, not to retry any more\", this.bucketId,\n           poe);\n       throw poe;\n     } catch (Exception ex) {\n"}}, {"oid": "47c0f5c690a36878507008aa366ecc0d82580789", "url": "https://github.com/apache/geode/commit/47c0f5c690a36878507008aa366ecc0d82580789", "message": "add more datastore members and listener in test", "committedDate": "2020-03-04T22:27:13Z", "type": "commit"}, {"oid": "5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "url": "https://github.com/apache/geode/commit/5cd5c6ee3a09d057454f8edf0979d265e6384ca1", "message": "fix based on jianxia's comments", "committedDate": "2020-03-04T22:52:42Z", "type": "commit"}, {"oid": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "url": "https://github.com/apache/geode/commit/08550c037c9c36ec9d677d70be67a0c7eaf282a0", "message": "fix based on jianxia's comments on mesg", "committedDate": "2020-03-05T07:56:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5NzIyNA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388497224", "bodyText": "Could this lock name be extracted to a constant, since it's used multiple times in a couple of different classes.", "author": "DonalEvans", "createdAt": "2020-03-05T19:00:24Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzNzA0NQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388537045", "bodyText": "I noticed this too. DR.clear is using it. I will change it to be \"_clearOperation\" + regionName.", "author": "gesterzhou", "createdAt": "2020-03-05T20:12:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5NzIyNA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5OTY5OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388499698", "bodyText": "We make this same check as soon as we get inside the createClearPRMessages() method. Is it needed in both places?", "author": "DonalEvans", "createdAt": "2020-03-05T19:04:57Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwNzA4OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388607088", "bodyText": "I removed the one in createClearPRMessages()", "author": "gesterzhou", "createdAt": "2020-03-05T22:35:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5OTY5OA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMDk3Nw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388500977", "bodyText": "A more descriptive name for this might be \"sendMessagesStartTime\" or something along those lines.", "author": "DonalEvans", "createdAt": "2020-03-05T19:07:09Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwNzcxMw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388607713", "bodyText": "fixed.", "author": "gesterzhou", "createdAt": "2020-03-05T22:37:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMDk3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMjI4OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388502288", "bodyText": "Why do we only log this message if the time taken was more than 10 seconds? Would it be acceptable to just always log it if debug is enabled?", "author": "DonalEvans", "createdAt": "2020-03-05T19:09:27Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzODQ3Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388538473", "bodyText": "I agree. It in inherited from putAll. A putAll should take longer time than clear. 10 seconds is too long for clear. I will fix.", "author": "gesterzhou", "createdAt": "2020-03-05T20:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwMjI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwNDQ4Mw==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388504483", "bodyText": "while(true) might be better here, just personal preference.", "author": "DonalEvans", "createdAt": "2020-03-05T19:13:04Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwODI2MA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388608260", "bodyText": "fixed", "author": "gesterzhou", "createdAt": "2020-03-05T22:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUwNDQ4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxNjgyMA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388516820", "bodyText": "Looking at this code, it seems possible that we can enter the loop with currentTarget == null, then attempt to find a target using waitForNodeOrCreateBucket() and get a non-null target. However, we don't try to use that target immediately, but rather return to the start of the loop with count now equal to 1, even though we haven't actually failed, and there is no true retry happening. This means that when we get to the if (count == 1) check at the bottom of the loop on the next iteration, count will have been incremented to 2, and we never increment the stats. Should the continue here be removed, to allow us to attempt to send the message to the target we just got?", "author": "DonalEvans", "createdAt": "2020-03-05T19:34:58Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwOTE2Mg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388609162", "bodyText": "this is from old code. It worked for years. I have created a story to enhance it. But I will leave it as is for the time being.", "author": "gesterzhou", "createdAt": "2020-03-05T22:41:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxNjgyMA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxODkwOQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388518909", "bodyText": "The op string should be \"clear a bucket\"", "author": "DonalEvans", "createdAt": "2020-03-05T19:38:48Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException fre) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, fre.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzOTE4Mg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388539182", "bodyText": "fixed", "author": "gesterzhou", "createdAt": "2020-03-05T20:16:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxODkwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxOTMzOA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388519338", "bodyText": "This should be \"PR.sendClearMsgByBucket\"", "author": "DonalEvans", "createdAt": "2020-03-05T19:39:32Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2144,18 +2145,203 @@ public void writeToDisk() {\n     throw new UnsupportedOperationException();\n   }\n \n-  /**\n-   * @since GemFire 5.0\n-   * @throws UnsupportedOperationException OVERRIDES\n-   */\n   @Override\n-  public void clear() {\n-    throw new UnsupportedOperationException();\n+  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n+    final boolean isDebugEnabled = logger.isDebugEnabled();\n+    synchronized (clearLock) {\n+      final DistributedLockService lockService = getPartitionedRegionLockService();\n+      try {\n+        lockService.lock(\"_clearOperation\", -1, -1);\n+      } catch (IllegalStateException e) {\n+        lockCheckReadiness();\n+        throw e;\n+      }\n+      try {\n+        if (cache.isCacheAtShutdownAll()) {\n+          throw cache.getCacheClosedException(\"Cache is shutting down\");\n+        }\n+\n+        // create ClearPRMessage per bucket\n+        List<ClearPRMessage> clearMsgList = createClearPRMessages();\n+        for (ClearPRMessage clearPRMessage : clearMsgList) {\n+          int bucketId = clearPRMessage.getBucketId();\n+          checkReadiness();\n+          long then = 0;\n+          if (isDebugEnabled) {\n+            then = System.currentTimeMillis();\n+          }\n+          try {\n+            sendClearMsgByBucket(bucketId, clearPRMessage);\n+          } catch (PartitionOfflineException poe) {\n+            // TODO add a PartialResultException\n+            logger.info(\"PR.sendClearMsgByBucket encountered PartitionOfflineException at bucket \"\n+                + bucketId, poe);\n+          } catch (Exception e) {\n+            logger.info(\"PR.sendClearMsgByBucket encountered exception at bucket \" + bucketId, e);\n+          }\n+\n+          if (isDebugEnabled) {\n+            long now = System.currentTimeMillis();\n+            if (now - then > 10000) {\n+              logger.debug(\"PR.sendClearMsgByBucket for bucket {} took {} ms\", bucketId,\n+                  (now - then));\n+            }\n+          }\n+          // TODO add psStats\n+        }\n+      } finally {\n+        try {\n+          lockService.unlock(\"_clearOperation\");\n+        } catch (IllegalStateException e) {\n+          lockCheckReadiness();\n+        }\n+      }\n+\n+      // notify bridge clients at PR level\n+      regionEvent.setEventType(EnumListenerEvent.AFTER_REGION_CLEAR);\n+      notifyBridgeClients(regionEvent);\n+    }\n   }\n \n-  @Override\n-  void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n-    throw new UnsupportedOperationException();\n+  void sendClearMsgByBucket(final Integer bucketId, ClearPRMessage clearPRMessage) {\n+    RetryTimeKeeper retryTime = null;\n+    InternalDistributedMember currentTarget = getNodeForBucketWrite(bucketId, null);\n+    if (logger.isDebugEnabled()) {\n+      logger.debug(\"PR.sendClearMsgByBucket:bucket {}'s currentTarget is {}\", bucketId,\n+          currentTarget);\n+    }\n+\n+    long timeOut = 0;\n+    int count = 0;\n+    for (;;) {\n+      switch (count) {\n+        case 0:\n+          // Note we don't check for DM cancellation in common case.\n+          // First time. Assume success, keep going.\n+          break;\n+        case 1:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // Second time (first failure). Calculate timeout and keep going.\n+          timeOut = System.currentTimeMillis() + this.retryTimeout;\n+          break;\n+        default:\n+          this.cache.getCancelCriterion().checkCancelInProgress(null);\n+          // test for timeout\n+          long timeLeft = timeOut - System.currentTimeMillis();\n+          if (timeLeft < 0) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"clear a bucket\" + bucketId,\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+\n+          // Didn't time out. Sleep a bit and then continue\n+          boolean interrupted = Thread.interrupted();\n+          try {\n+            Thread.sleep(PartitionedRegionHelper.DEFAULT_WAIT_PER_RETRY_ITERATION);\n+          } catch (InterruptedException ignore) {\n+            interrupted = true;\n+          } finally {\n+            if (interrupted) {\n+              Thread.currentThread().interrupt();\n+            }\n+          }\n+          break;\n+      } // switch\n+      count++;\n+\n+      if (currentTarget == null) { // pick target\n+        checkReadiness();\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+\n+        currentTarget = waitForNodeOrCreateBucket(retryTime, null, bucketId, false);\n+        if (currentTarget == null) {\n+          // the bucket does not exist, no need to clear\n+          logger.info(\"Bucket \" + bucketId + \" does not contain data, no need to clear\");\n+          return;\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: new currentTarget is {}\", currentTarget);\n+          }\n+        }\n+\n+        // It's possible this is a GemFire thread e.g. ServerConnection\n+        // which got to this point because of a distributed system shutdown or\n+        // region closure which uses interrupt to break any sleep() or wait() calls\n+        // e.g. waitForPrimary or waitForBucketRecovery in which case throw exception\n+        checkShutdown();\n+        continue;\n+      } // pick target\n+\n+      boolean result = false;\n+      try {\n+        final boolean isLocal = (this.localMaxMemory > 0) && currentTarget.equals(getMyId());\n+        if (isLocal) {\n+          result = clearPRMessage.doLocalClear(this);\n+        } else {\n+          ClearPRMessage.ClearResponse response = clearPRMessage.send(currentTarget, this);\n+          if (response != null) {\n+            this.prStats.incPartitionMessagesSent();\n+            result = response.waitForResult();\n+          }\n+        }\n+        if (result) {\n+          return;\n+        }\n+      } catch (ForceReattemptException fre) {\n+        checkReadiness();\n+        InternalDistributedMember lastTarget = currentTarget;\n+        if (retryTime == null) {\n+          retryTime = new RetryTimeKeeper(this.retryTimeout);\n+        }\n+        currentTarget = getNodeForBucketWrite(bucketId, retryTime);\n+        if (lastTarget.equals(currentTarget)) {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendClearMsgByBucket: Retrying at the same node:{} due to {}\",\n+                currentTarget, fre.getMessage());\n+          }\n+          if (retryTime.overMaximum()) {\n+            PRHARedundancyProvider.timedOut(this, null, null, \"update an entry\",\n+                this.retryTimeout);\n+            // NOTREACHED\n+          }\n+          retryTime.waitToRetryNode();\n+        } else {\n+          if (logger.isDebugEnabled()) {\n+            logger.debug(\"PR.sendMsgByBucket: Old target was {}, Retrying {}\", lastTarget,", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwOTQ3OQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388609479", "bodyText": "fixed.", "author": "gesterzhou", "createdAt": "2020-03-05T22:42:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUxOTMzOA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\nindex 507708688d..1cf9c97f65 100755\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java\n\n@@ -2151,7 +2151,7 @@ public class PartitionedRegion extends LocalRegion\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);\n       } catch (IllegalStateException e) {\n         lockCheckReadiness();\n         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyMzk0MA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388523940", "bodyText": "This might be better as \"All members holding data for bucket {} are offline, no more retries will be attempted\"", "author": "DonalEvans", "createdAt": "2020-03-05T19:47:39Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -179,50 +153,40 @@ protected boolean operateOnPartitionedRegion(ClusterDistributionManager distribu\n     return false;\n   }\n \n-  public boolean doLocalClear(PartitionedRegion region) throws ForceReattemptException {\n+  public Integer getBucketId() {\n+    return this.bucketId;\n+  }\n+\n+  public boolean doLocalClear(PartitionedRegion region)\n+      throws ForceReattemptException {\n     // Retrieve local bucket region which matches target bucketId\n-    BucketRegion bucketRegion = region.getDataStore().getInitializedBucketForId(null, bucketId);\n+    BucketRegion bucketRegion =\n+        region.getDataStore().getInitializedBucketForId(null, this.bucketId);\n \n-    // Check if we are primary, throw exception if not\n-    if (!bucketRegion.isPrimary()) {\n+    boolean lockedForPrimary = bucketRegion.doLockForPrimary(false);\n+    // Check if we obtained primary lock, throw exception if not\n+    if (!lockedForPrimary) {\n       throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n     }\n-\n-    DistributedLockService lockService = getPartitionRegionLockService();\n-    String lockName = bucketRegion.getFullPath();\n     try {\n-      boolean locked = lockService.lock(lockName, LOCK_WAIT_TIMEOUT_MS, -1);\n-\n-      if (!locked) {\n-        throw new ForceReattemptException(BUCKET_REGION_LOCK_UNAVAILABLE_MESSAGE);\n-      }\n-\n-      // Double check if we are still primary, as this could have changed between our first check\n-      // and obtaining the lock\n-      if (!bucketRegion.isPrimary()) {\n-        throw new ForceReattemptException(BUCKET_NON_PRIMARY_MESSAGE);\n-      }\n-\n-      try {\n-        bucketRegion.cmnClearRegion(regionEvent, true, true);\n-      } catch (Exception ex) {\n-        throw new ForceReattemptException(\n-            EXCEPTION_THROWN_DURING_CLEAR_OPERATION + ex.getClass().getName(), ex);\n-      }\n-\n+      RegionEventImpl regionEvent = new RegionEventImpl();\n+      regionEvent.setOperation(Operation.REGION_CLEAR);\n+      regionEvent.setRegion(bucketRegion);\n+      bucketRegion.cmnClearRegion(regionEvent, true, true);\n+    } catch (PartitionOfflineException poe) {\n+      logger.info(\"There is no member to hold bucket {}, not to retry any more\", this.bucketId,", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYwOTc5NA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388609794", "bodyText": "fixed.", "author": "gesterzhou", "createdAt": "2020-03-05T22:43:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyMzk0MA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 9596f95d85..7e1865b04e 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -149,8 +149,7 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n           startTime);\n       return false;\n     }\n-    sendReply(getSender(), getProcessorId(), distributionManager, null, region, startTime);\n-    return false;\n+    return this.result;\n   }\n \n   public Integer getBucketId() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMTA2OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388531068", "bodyText": "There is an Assert.assertNotNull() that would be better here than assertTrue().\nAlso, it might be clearer with a message of \"ClearReplyMessage recipient was NULL.\"", "author": "DonalEvans", "createdAt": "2020-03-05T20:00:43Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -293,16 +225,21 @@ public ClearReplyMessage() {}\n \n     private ClearReplyMessage(int processorId, boolean result, ReplyException ex) {\n       super();\n-      this.result = result;\n       setProcessorId(processorId);\n-      setException(ex);\n+      if (ex != null) {\n+        setException(ex);\n+      } else {\n+        setReturnValue(result);\n+      }\n     }\n \n-    /** Send an ack */\n+    /**\n+     * Send an ack\n+     */\n     public static void send(InternalDistributedMember recipient, int processorId,\n         ReplySender replySender,\n         boolean result, ReplyException ex) {\n-      Assert.assertTrue(recipient != null, \"ClearReplyMessage NULL reply message\");\n+      Assert.assertTrue(recipient != null, \"ClearReplyMessage NULL recipient.\");", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYxMDc1NQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388610755", "bodyText": "fixed", "author": "gesterzhou", "createdAt": "2020-03-05T22:45:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMTA2OA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 9596f95d85..7e1865b04e 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -239,7 +240,7 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n     public static void send(InternalDistributedMember recipient, int processorId,\n         ReplySender replySender,\n         boolean result, ReplyException ex) {\n-      Assert.assertTrue(recipient != null, \"ClearReplyMessage NULL recipient.\");\n+      Assert.assertNotNull(recipient, \"ClearReplyMessage recipient was NULL.\");\n       ClearReplyMessage message = new ClearReplyMessage(processorId, result, ex);\n       message.setRecipient(recipient);\n       replySender.putOutgoing(message);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMzUxOA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388533518", "bodyText": "These verifications of region size on the data stores are called multiple times in multiple tests. Could they be extracted to helper methods to reduce code duplication?", "author": "DonalEvans", "createdAt": "2020-03-05T20:05:50Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.stream.IntStream;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.InterestResultPolicy;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.util.CacheListenerAdapter;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, dataStore3, accessor;\n+  protected ClientVM client1, client2;\n+\n+  private static final Logger logger = LogManager.getLogger();\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    locator = cluster.startLocatorVM(0);\n+    locatorPort = locator.getPort();\n+    dataStore1 = cluster.startServerVM(1, locatorPort);\n+    dataStore2 = cluster.startServerVM(2, locatorPort);\n+    dataStore3 = cluster.startServerVM(3, locatorPort);\n+    accessor = cluster.startServerVM(4, locatorPort);\n+    client1 = cluster.startClientVM(5,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    client2 = cluster.startClientVM(6,\n+        c -> c.withPoolSubscription(true).withLocatorConnection((locatorPort)));\n+    dataStore1.invoke(this::initDataStore);\n+    dataStore2.invoke(this::initDataStore);\n+    dataStore3.invoke(this::initDataStore);\n+    accessor.invoke(this::initAccessor);\n+    client1.invoke(this::initClientCache);\n+    client2.invoke(this::initClientCache);\n+  }\n+\n+  protected RegionShortcut getRegionShortCut() {\n+    return RegionShortcut.PARTITION_REDUNDANT;\n+  }\n+\n+  private Region getRegion(boolean isClient) {\n+    if (isClient) {\n+      return getClientCache().getRegion(REGION_NAME);\n+    } else {\n+      return getCache().getRegion(REGION_NAME);\n+    }\n+  }\n+\n+  private void verifyRegionSize(boolean isClient, int expectedNum) {\n+    assertThat(getRegion(isClient).size()).isEqualTo(expectedNum);\n+  }\n+\n+  private void initClientCache() {\n+    Region region = getClientCache().createClientRegionFactory(ClientRegionShortcut.CACHING_PROXY)\n+        .create(REGION_NAME);\n+    region.registerInterestForAllKeys(InterestResultPolicy.KEYS);\n+  }\n+\n+  private void initDataStore() {\n+    getCache().createRegionFactory(getRegionShortCut())\n+        .setPartitionAttributes(new PartitionAttributesFactory().setTotalNumBuckets(10).create())\n+        .addCacheListener(new CacheListenerAdapter() {\n+          @Override\n+          public void afterRegionDestroy(RegionEvent event) {\n+            Region region = event.getRegion();\n+            logger.info(\"Region \" + region.getFullPath() + \" is destroyed.\");\n+          }\n+\n+          @Override\n+          public void afterRegionClear(RegionEvent event) {\n+            Region region = event.getRegion();\n+            logger.info(\"Region \" + region.getFullPath() + \" is cleared.\");\n+          }\n+        })\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initAccessor() {\n+    getCache().createRegionFactory(getRegionShortCut())\n+        .setPartitionAttributes(\n+            new PartitionAttributesFactory().setTotalNumBuckets(10).setLocalMaxMemory(0).create())\n+        .create(REGION_NAME);\n+  }\n+\n+  private void feed(boolean isClient) {\n+    Region region = getRegion(isClient);\n+    IntStream.range(0, NUM_ENTRIES).forEach(i -> region.put(i, \"value\" + i));\n+  }\n+\n+  @Test\n+  public void normalClearFromDataStore() {\n+    accessor.invoke(() -> feed(false));\n+    dataStore1.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+    dataStore2.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+    dataStore3.invoke(() -> verifyRegionSize(false, NUM_ENTRIES));\n+\n+    dataStore1.invoke(() -> getRegion(false).clear());\n+    dataStore1.invoke(() -> verifyRegionSize(false, 0));\n+    dataStore2.invoke(() -> verifyRegionSize(false, 0));\n+    dataStore3.invoke(() -> verifyRegionSize(false, 0));", "originalCommit": "08550c037c9c36ec9d677d70be67a0c7eaf282a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyMjQyNA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388622424", "bodyText": "fixed.", "author": "gesterzhou", "createdAt": "2020-03-05T23:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzMzUxOA=="}], "type": "inlineReview", "revised_code": {"commit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\nindex e409859158..eb9c31fec9 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n\n@@ -19,6 +19,8 @@ import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCach\n import static org.assertj.core.api.Assertions.assertThat;\n \n import java.io.Serializable;\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.IntStream;\n \n import org.apache.logging.log4j.LogManager;\n"}}, {"oid": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "url": "https://github.com/apache/geode/commit/1dfc0a0e82930d442ce3d5db93c624d228a97856", "message": "fix based on donal's comments and add listener check", "committedDate": "2020-03-05T23:18:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyODMwMg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388628302", "bodyText": "You need to also update the lock name in lockService.unlock() on line 2192.", "author": "DonalEvans", "createdAt": "2020-03-05T23:39:04Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/PartitionedRegion.java", "diffHunk": "@@ -2151,7 +2151,7 @@ void basicClear(RegionEventImpl regionEvent, boolean cacheWrite) {\n     synchronized (clearLock) {\n       final DistributedLockService lockService = getPartitionedRegionLockService();\n       try {\n-        lockService.lock(\"_clearOperation\", -1, -1);\n+        lockService.lock(\"_clearOperation\" + this.getFullPath().replace('/', '_'), -1, -1);", "originalCommit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMTM1OQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388631359", "bodyText": "fixed", "author": "gesterzhou", "createdAt": "2020-03-05T23:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYyODMwMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMDYxOQ==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388630619", "bodyText": "Why is this being cast to Boolean? The returnValue field is primitive and the waitForResult() method returns a primitive as well. It feels like they should all agree on what the type is.", "author": "DonalEvans", "createdAt": "2020-03-05T23:47:24Z", "path": "geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java", "diffHunk": "@@ -298,7 +299,7 @@ public ClearResponse(InternalDistributedSystem distributedSystem,\n \n     public void setResponse(ClearReplyMessage response) {\n       if (response.getException() == null) {\n-        this.returnValue = (boolean) response.getReturnValue();\n+        this.returnValue = (Boolean) response.getReturnValue();", "originalCommit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMTU3OA==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388631578", "bodyText": "fixed", "author": "gesterzhou", "createdAt": "2020-03-05T23:50:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzMDYxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "6fd4819c1fbd62ee1bd5ffcff530de33518cf85a", "chunk": "diff --git a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\nindex 7e1865b04e..9fa80575bc 100644\n--- a/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n+++ b/geode-core/src/main/java/org/apache/geode/internal/cache/partitioned/ClearPRMessage.java\n\n@@ -299,7 +299,7 @@ public class ClearPRMessage extends PartitionMessageWithDirectReply {\n \n     public void setResponse(ClearReplyMessage response) {\n       if (response.getException() == null) {\n-        this.returnValue = (Boolean) response.getReturnValue();\n+        this.returnValue = (boolean) response.getReturnValue();\n       }\n     }\n \n"}}, {"oid": "803e8b112a59faca3f562c6a9e176eebaabb0ddb", "url": "https://github.com/apache/geode/commit/803e8b112a59faca3f562c6a9e176eebaabb0ddb", "message": "add a new dunit test to try", "committedDate": "2020-03-05T23:48:22Z", "type": "commit"}, {"oid": "6fd4819c1fbd62ee1bd5ffcff530de33518cf85a", "url": "https://github.com/apache/geode/commit/6fd4819c1fbd62ee1bd5ffcff530de33518cf85a", "message": "fix", "committedDate": "2020-03-05T23:51:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0NTEyMg==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388645122", "bodyText": "The number of VMs should be 7.", "author": "jchen21", "createdAt": "2020-03-06T00:33:27Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java", "diffHunk": "@@ -0,0 +1,203 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n+import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.IntStream;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+import org.apache.geode.cache.InterestResultPolicy;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.client.ClientRegionShortcut;\n+import org.apache.geode.cache.util.CacheListenerAdapter;\n+import org.apache.geode.test.dunit.SerializableCallableIF;\n+import org.apache.geode.test.dunit.rules.ClientVM;\n+import org.apache.geode.test.dunit.rules.ClusterStartupRule;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+\n+public class PartitionedRegionClearDUnitTest implements Serializable {\n+  protected static final String REGION_NAME = \"testPR\";\n+  protected static final int NUM_ENTRIES = 1000;\n+\n+  protected int locatorPort;\n+  protected MemberVM locator;\n+  protected MemberVM dataStore1, dataStore2, dataStore3, accessor;\n+  protected ClientVM client1, client2;\n+\n+  private static final Logger logger = LogManager.getLogger();\n+\n+  @Rule\n+  public ClusterStartupRule cluster = new ClusterStartupRule(6);", "originalCommit": "1dfc0a0e82930d442ce3d5db93c624d228a97856", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0NjI4Ng==", "url": "https://github.com/apache/geode/pull/4755#discussion_r388646286", "bodyText": "interesting. it did not fail. I fixed. Thank you.", "author": "gesterzhou", "createdAt": "2020-03-06T00:36:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY0NTEyMg=="}], "type": "inlineReview", "revised_code": {"commit": "945a898d3115d5d86fa6aa1387ce1ba85b874802", "chunk": "diff --git a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\nindex eb9c31fec9..fb2a81bdb3 100644\n--- a/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n+++ b/geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearDUnitTest.java\n\n@@ -14,6 +14,7 @@\n  */\n package org.apache.geode.internal.cache;\n \n+import static org.apache.geode.internal.Assert.fail;\n import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getCache;\n import static org.apache.geode.test.dunit.rules.ClusterStartupRule.getClientCache;\n import static org.assertj.core.api.Assertions.assertThat;\n"}}, {"oid": "945a898d3115d5d86fa6aa1387ce1ba85b874802", "url": "https://github.com/apache/geode/commit/945a898d3115d5d86fa6aa1387ce1ba85b874802", "message": "fix junit test", "committedDate": "2020-03-06T00:45:03Z", "type": "commit"}, {"oid": "4c99aa105a1e4a791caed869daaa40ff7d179e1c", "url": "https://github.com/apache/geode/commit/4c99aa105a1e4a791caed869daaa40ff7d179e1c", "message": "Merge branch 'feature/GEODE-7665' into feature/GEODE-7682-2", "committedDate": "2020-03-06T04:20:54Z", "type": "commit"}]}