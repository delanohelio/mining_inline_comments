{"pr_number": 594, "pr_title": "issue #108 #618 bulkdata export for group members and instruction for exports", "pr_createdAt": "2020-01-15T19:56:15Z", "pr_url": "https://github.com/IBM/FHIR/pull/594", "timeline": [{"oid": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "url": "https://github.com/IBM/FHIR/commit/a8c8b576f187809f0ec72fc7d0290c7b453644c2", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:33:21Z", "type": "commit"}, {"oid": "fd5d848eb4bda4a6c0dd04740c6df46bfe1a5337", "url": "https://github.com/IBM/FHIR/commit/fd5d848eb4bda4a6c0dd04740c6df46bfe1a5337", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:33:43Z", "type": "commit"}, {"oid": "3cd91fb12e7c4d0f437203a193773ddd3f32f95f", "url": "https://github.com/IBM/FHIR/commit/3cd91fb12e7c4d0f437203a193773ddd3f32f95f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:05Z", "type": "commit"}, {"oid": "b6a060142056769ba7f49b79281389b3c3af8aeb", "url": "https://github.com/IBM/FHIR/commit/b6a060142056769ba7f49b79281389b3c3af8aeb", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:21Z", "type": "commit"}, {"oid": "82c49e6403e51899ce8afea8947d728fb086112a", "url": "https://github.com/IBM/FHIR/commit/82c49e6403e51899ce8afea8947d728fb086112a", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:39Z", "type": "commit"}, {"oid": "f0b7845ac77ed7b7d913cc3f9d44011fbe310e03", "url": "https://github.com/IBM/FHIR/commit/f0b7845ac77ed7b7d913cc3f9d44011fbe310e03", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:08Z", "type": "commit"}, {"oid": "b300473427c7e7550e8aca6a15004fafbb900f6a", "url": "https://github.com/IBM/FHIR/commit/b300473427c7e7550e8aca6a15004fafbb900f6a", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:31Z", "type": "commit"}, {"oid": "2b5f305451a3a2ef065b00f9f55996d0a61827d2", "url": "https://github.com/IBM/FHIR/commit/2b5f305451a3a2ef065b00f9f55996d0a61827d2", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:43Z", "type": "commit"}, {"oid": "d80dd887c13ef9589b92a39bafb144ddc7d0f952", "url": "https://github.com/IBM/FHIR/commit/d80dd887c13ef9589b92a39bafb144ddc7d0f952", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:36:08Z", "type": "commit"}, {"oid": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "url": "https://github.com/IBM/FHIR/commit/b4aa4f9ba945dd6665688265e2170641c5d97fc0", "message": "Update fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:57:26Z", "type": "commit"}, {"oid": "a50e91deb919bf5c15ef5710bfb1eb1640556ba2", "url": "https://github.com/IBM/FHIR/commit/a50e91deb919bf5c15ef5710bfb1eb1640556ba2", "message": "issue #108 changes per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T15:10:03Z", "type": "commit"}, {"oid": "8aeb5c9941d7e38073086cd1446341840c7ae0be", "url": "https://github.com/IBM/FHIR/commit/8aeb5c9941d7e38073086cd1446341840c7ae0be", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-23T17:23:03Z", "type": "commit"}, {"oid": "b8bef36bbee277673e25908308c6b0762bffaa4a", "url": "https://github.com/IBM/FHIR/commit/b8bef36bbee277673e25908308c6b0762bffaa4a", "message": "issue #108 bulkdata export for group members initial code drop\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-15T19:55:38Z", "type": "commit"}, {"oid": "cb069a19f62a88115d8126d0aef936707281e07e", "url": "https://github.com/IBM/FHIR/commit/cb069a19f62a88115d8126d0aef936707281e07e", "message": "issue #108 add support for nested group\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T15:17:15Z", "type": "commit"}, {"oid": "ed52a92c0352c56f4f97cf317d43a1385b62d835", "url": "https://github.com/IBM/FHIR/commit/ed52a92c0352c56f4f97cf317d43a1385b62d835", "message": "issue #108 fix for exit status\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T16:25:49Z", "type": "commit"}, {"oid": "3ff78cbc8e56ea11e4ee63f8edda9ca387d73a9d", "url": "https://github.com/IBM/FHIR/commit/3ff78cbc8e56ea11e4ee63f8edda9ca387d73a9d", "message": "issue #108 changes to survive circle reference of groups\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T18:58:55Z", "type": "commit"}, {"oid": "6434c62a97873e1b6cf977201e8e98fb55a89c36", "url": "https://github.com/IBM/FHIR/commit/6434c62a97873e1b6cf977201e8e98fb55a89c36", "message": "issue #108 adjust log level to fine for some locations\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T19:36:15Z", "type": "commit"}, {"oid": "34dd7262b0ab58f432964898676c370c63df8b20", "url": "https://github.com/IBM/FHIR/commit/34dd7262b0ab58f432964898676c370c63df8b20", "message": "issue #108 add integration tests for export operations\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-17T14:13:50Z", "type": "commit"}, {"oid": "411dfae242931e3c85c0ae79e2edcbc4a0acd7f5", "url": "https://github.com/IBM/FHIR/commit/411dfae242931e3c85c0ae79e2edcbc4a0acd7f5", "message": "issue #108 instruction for bulkdata export\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-20T22:03:52Z", "type": "commit"}, {"oid": "4247b9102386532ab7e481ca0989dc5659031c72", "url": "https://github.com/IBM/FHIR/commit/4247b9102386532ab7e481ca0989dc5659031c72", "message": "issue #108 added description for the new integration tests\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-20T22:38:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzI3Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767273", "bodyText": "just a note to Albert... I'll change this in my PR.  so we don't just force DEFAULT_TENANT_ID", "author": "prb112", "createdAt": "2020-01-21T00:34:14Z", "path": "fhir-operation-bulkdata/src/main/java/com/ibm/fhir/operation/bulkdata/processor/impl/CosExportImpl.java", "diffHunk": "@@ -161,13 +163,48 @@ public Parameters exportPatient(String logicalId, MediaType outputFormat, Instan\n         }\n     }\n \n-    // not implemented yet\n     @Override\n     public Parameters exportGroup(String logicalId, MediaType outputFormat, Instant since,\n         List<String> types, List<String> typeFilters, FHIRRequestContext ctx,\n         FHIRResourceHelpers resourceHelper, FHIROperationContext operationContext,\n         BulkDataTenantSpecificCache cache) throws FHIROperationException {\n-        throw new FHIROperationException(\"No $export group operation right now\");\n+\n+        try {\n+            log.fine(\"Using the COS Implementation\");\n+\n+            Map<String, String> properties =", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyMzE0MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369023140", "bodyText": "sounds great!! thanks!", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzI3Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzQxMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767410", "bodyText": "on line 121, can you remove the printstacktrace", "author": "prb112", "createdAt": "2020-01-21T00:35:18Z", "path": "fhir-operation-bulkdata/src/main/java/com/ibm/fhir/operation/bulkdata/processor/impl/CosExportImpl.java", "diffHunk": "@@ -161,13 +163,48 @@ public Parameters exportPatient(String logicalId, MediaType outputFormat, Instan\n         }\n     }\n \n-    // not implemented yet\n     @Override", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyNDA5NA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369024094", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:15:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzQxMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2Nzg2Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767866", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-01-21T00:38:25Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2Nzk3Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767977", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-01-21T00:39:14Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODAwOA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768008", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n          \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "author": "prb112", "createdAt": "2020-01-21T00:39:27Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODAzMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768030", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n          \n          \n            \n                private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{", "author": "prb112", "createdAt": "2020-01-21T00:39:37Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODIxMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768211", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n          \n          \n            \n                    Group group = findGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);", "author": "prb112", "createdAt": "2020-01-21T00:40:45Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODI1Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768252", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n          \n          \n            \n                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);", "author": "prb112", "createdAt": "2020-01-21T00:40:55Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+        // List for the patients\n+        List<Member> patientMembers = new ArrayList<>();\n+        // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+        HashSet<String> groupsInPath = new HashSet<>();\n+        ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768312", "bodyText": "what does setPageNum 2 mean?", "author": "prb112", "createdAt": "2020-01-21T00:41:20Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+        // List for the patients\n+        List<Member> patientMembers = new ArrayList<>();\n+        // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+        HashSet<String> groupsInPath = new HashSet<>();\n+        ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n+\n+        if (chunkData == null) {\n+            chunkData = new TransientUserData(0, null, new ArrayList<PartETag>(), 1);\n+            chunkData.setIndexOfCurrentResourceType(0);\n+            jobContext.setTransientUserData(chunkData);\n+        } else {\n+            chunkData.setIndexOfCurrentResourceType(indexOfCurrentResourceType);\n+        }\n+        // The fhir resources of one resource type for all the patients will be exported into one COS object.\n+        // Here we simply set the lastPageNum to be smaller than the next PageNum to ask the common ChunkWriter\n+        // to close the writing for current resource type.\n+        chunkData.setPageNum(2);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzMTk3Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369031976", "bodyText": "paging is used for the common implementation. e.g, for patient export, the codes read page of patients, and then write these patients' resources of current to-be-exported resource type to COS, and then move to the next page of patients.\nBut for group export, we don't really use paging for patients, we get all patient in one batch, so just as mentioned in the comments, we simply set current page number to be 2 and the lastpagenum to be 1 to simply sign the CheckPoint and ChunkWriter to finish writing for current resource type.", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:28:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjU5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369206593", "bodyText": "OK - I got it now.  Thanks.", "author": "prb112", "createdAt": "2020-01-21T19:46:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg=="}], "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex 271f1c21d5..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODU1Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768553", "bodyText": "? gets replaced?", "author": "prb112", "createdAt": "2020-01-21T00:42:38Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyNjEzMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369026131", "bodyText": "yes, ? will be replace with the group id", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODU1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\nindex f256285c95..7f12630023 100644\n--- a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n+++ b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n\n@@ -56,7 +56,7 @@ public class ExportOperationTest extends FHIRServerTestBase {\n     public static final boolean ON = true;\n \n     public static final boolean DEBUG = false;\n-    String ExportStatusUrl;\n+    private String exportStatusUrl;\n     private String savedPatientId, savedPatientId2;\n     private String savedGroupId, savedGroupId2;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODYwNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768607", "bodyText": "camelcase and visibility modifier?", "author": "prb112", "createdAt": "2020-01-21T00:42:54Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";\n     public static final String BASE_VALID_URL = \"/$export\";\n-\n     public static final String BASE_VALID_STATUS_URL = \"/$export-status\";\n-\n     public static final String FORMAT = \"application/fhir+ndjson\";\n+    public static final boolean ON = true;\n \n-    public static final boolean ON = false;\n-    \n-    @Test(groups = { TEST_GROUP_NAME }, enabled = ON)\n-    public void testBaseExport() throws FHIRGeneratorException, IOException {\n-        Response response =\n-            doPost(BASE_VALID_URL, FHIRMediaType.APPLICATION_FHIR_JSON, FORMAT, Instant.of(\"2019-01-01T08:21:26.94-04:00\"), Arrays.asList(\"Patient\"), null);\n-        assertEquals(response.getStatus(), 202);\n-\n-        // Debug the content-location that's returned. \n-        String contentLocation = response.getHeaderString(\"Content-Location\");\n-        System.out.println(\"Content Location: \" + contentLocation);\n-        \n-        assertEquals(contentLocation, \"/fhir-server/api/v4/$export-status?job=1\");\n-\n-    }\n+    public static final boolean DEBUG = false;\n+    String ExportStatusUrl;", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzMzcyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369033725", "bodyText": "good catch.", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:31:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODYwNw=="}], "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\nindex f256285c95..7f12630023 100644\n--- a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n+++ b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n\n@@ -56,7 +56,7 @@ public class ExportOperationTest extends FHIRServerTestBase {\n     public static final boolean ON = true;\n \n     public static final boolean DEBUG = false;\n-    String ExportStatusUrl;\n+    private String exportStatusUrl;\n     private String savedPatientId, savedPatientId2;\n     private String savedGroupId, savedGroupId2;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768693", "bodyText": "we run these on each Integration test?", "author": "prb112", "createdAt": "2020-01-21T00:43:24Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";\n     public static final String BASE_VALID_URL = \"/$export\";\n-\n     public static final String BASE_VALID_STATUS_URL = \"/$export-status\";\n-\n     public static final String FORMAT = \"application/fhir+ndjson\";\n+    public static final boolean ON = true;", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzODYyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369038625", "bodyText": "I didn't add ExportOperationTest to server integration test testng.xml, so it doesn't run in the pipeline now.  I prefer to run this in local integration test at present.  but let me add it to the pipeline, because seems the deployment/configurations are ready in the pipeline, so, let me try to enable it now and let's see what we can get...", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:39:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTA2MTM3OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369061378", "bodyText": "en, it failed in the pipeline, because there is unfinished db2 javabatch config in server.xml, let me remove it from server.xml.", "author": "albertwang-ibm", "createdAt": "2020-01-21T15:16:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTA4ODY0OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369088648", "bodyText": "interesting, got ClassNotFound error, seems cause by the removing of databaseutil in the dependency. let me sync with master and test in my local to find out if I can reproduce this...\njava.lang.NoClassDefFoundError: com/ibm/fhir/database/utils/api/IDatabaseTarget com.ibm.jbatch.container.controller.impl.ChunkStepControllerImpl", "author": "albertwang-ibm", "createdAt": "2020-01-21T15:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEwNzcxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369107717", "bodyText": "en... does reproduced in my local the same error ... trying to figure out how this can happen ...", "author": "albertwang-ibm", "createdAt": "2020-01-21T16:30:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5ODEzNA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369198134", "bodyText": "fixed the error by adding databaseUtil to bulkdata webapp war, and removed the export test from testng.xml of integration test because it needs COS key and service id to be configured correctly.", "author": "albertwang-ibm", "createdAt": "2020-01-21T19:28:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\nindex f256285c95..7f12630023 100644\n--- a/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n+++ b/fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java\n\n@@ -56,7 +56,7 @@ public class ExportOperationTest extends FHIRServerTestBase {\n     public static final boolean ON = true;\n \n     public static final boolean DEBUG = false;\n-    String ExportStatusUrl;\n+    private String exportStatusUrl;\n     private String savedPatientId, savedPatientId2;\n     private String savedGroupId, savedGroupId2;\n \n"}}, {"oid": "184fbe33b9aefcf02e944fa0f40f0812cccf8010", "url": "https://github.com/IBM/FHIR/commit/184fbe33b9aefcf02e944fa0f40f0812cccf8010", "message": "issue #618 document updates per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T13:18:30Z", "type": "commit"}, {"oid": "45f4cb78555d4e1bf53ed9f2a5b43cbb447b2922", "url": "https://github.com/IBM/FHIR/commit/45f4cb78555d4e1bf53ed9f2a5b43cbb447b2922", "message": "issue #108 #618 updates per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T14:19:42Z", "type": "commit"}, {"oid": "6965fc97e2967ece4f3f8fe0d1d087fce3bbe020", "url": "https://github.com/IBM/FHIR/commit/6965fc97e2967ece4f3f8fe0d1d087fce3bbe020", "message": "issue #108 enable export test in pipeline\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T14:42:31Z", "type": "commit"}, {"oid": "f9df819f42512da12a3c910cea2e571887d8a097", "url": "https://github.com/IBM/FHIR/commit/f9df819f42512da12a3c910cea2e571887d8a097", "message": "issue #108 remove db2 config for JavaBatch\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T15:31:32Z", "type": "commit"}, {"oid": "4e22edf066d7a58943d54b68b9d35f07d217eed4", "url": "https://github.com/IBM/FHIR/commit/4e22edf066d7a58943d54b68b9d35f07d217eed4", "message": "Merge pull request #622 from IBM/master\n\nfetch most current master", "committedDate": "2020-01-21T15:55:43Z", "type": "commit"}, {"oid": "d3bba30aad14547373aaaaf954baa2ec70f3c4d1", "url": "https://github.com/IBM/FHIR/commit/d3bba30aad14547373aaaaf954baa2ec70f3c4d1", "message": "issue #108 fix config issues\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T18:43:56Z", "type": "commit"}, {"oid": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "url": "https://github.com/IBM/FHIR/commit/6f2466f7cb0177e0b74f27b9afba812caec290d1", "message": "issue #108 remove export test from testng to allow pipeline pass\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T19:25:12Z", "type": "commit"}, {"oid": "154e61301388bdecc5313d6b7415383e6c41c209", "url": "https://github.com/IBM/FHIR/commit/154e61301388bdecc5313d6b7415383e6c41c209", "message": "issue #618 updated document per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:07:54Z", "type": "commit"}, {"oid": "1616ff4967c5d1430a53a5e53cb6f1b44d2fc702", "url": "https://github.com/IBM/FHIR/commit/1616ff4967c5d1430a53a5e53cb6f1b44d2fc702", "message": "issue #108 use optional included config for javabatch db\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:29:08Z", "type": "commit"}, {"oid": "94d170953ff21bce3925e5d564778cffadb097f7", "url": "https://github.com/IBM/FHIR/commit/94d170953ff21bce3925e5d564778cffadb097f7", "message": "issue #618 add more comments for job parameters\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:55:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3Njc4Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369776782", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *", "author": "lmsurpre", "createdAt": "2020-01-22T20:07:34Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,323 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex b394cd8e69..cbb6fa7d8a 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -46,9 +46,11 @@ import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient group export Chunk implementation - the Reader.\n- *\n  */\n public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each page.\n"}}, {"oid": "9cfad480ccd71ea1cacaa36f0618e5a3a8d05129", "url": "https://github.com/IBM/FHIR/commit/9cfad480ccd71ea1cacaa36f0618e5a3a8d05129", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:08:43Z", "type": "commit"}, {"oid": "e2205ebcb971600b4ef48a31dafca5f5d28d7768", "url": "https://github.com/IBM/FHIR/commit/e2205ebcb971600b4ef48a31dafca5f5d28d7768", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:11:09Z", "type": "commit"}, {"oid": "abd471ae28b1dfb80024941d9f44242c88fe034f", "url": "https://github.com/IBM/FHIR/commit/abd471ae28b1dfb80024941d9f44242c88fe034f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:11:28Z", "type": "commit"}, {"oid": "9893c32fbfd42697a192bb9ea2ddfbe94d3724d0", "url": "https://github.com/IBM/FHIR/commit/9893c32fbfd42697a192bb9ea2ddfbe94d3724d0", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:06Z", "type": "commit"}, {"oid": "fcb855bd23804549796909a1977190458f5ed86c", "url": "https://github.com/IBM/FHIR/commit/fcb855bd23804549796909a1977190458f5ed86c", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:31Z", "type": "commit"}, {"oid": "666b17823ce47ba3a93f6c2b35faae72922aaa23", "url": "https://github.com/IBM/FHIR/commit/666b17823ce47ba3a93f6c2b35faae72922aaa23", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:54Z", "type": "commit"}, {"oid": "2cb6259a12b83e750e37e00fde69aaeae6102d9e", "url": "https://github.com/IBM/FHIR/commit/2cb6259a12b83e750e37e00fde69aaeae6102d9e", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:13:13Z", "type": "commit"}, {"oid": "a4abcf9e42921c975378a9d3bfe9280a0f80f4cd", "url": "https://github.com/IBM/FHIR/commit/a4abcf9e42921c975378a9d3bfe9280a0f80f4cd", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:13:45Z", "type": "commit"}, {"oid": "b2521ee541f65036241189df925208ef51ca4d23", "url": "https://github.com/IBM/FHIR/commit/b2521ee541f65036241189df925208ef51ca4d23", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:14:24Z", "type": "commit"}, {"oid": "4ea77cf94259eff32d85395f97501af3ae5e46c4", "url": "https://github.com/IBM/FHIR/commit/4ea77cf94259eff32d85395f97501af3ae5e46c4", "message": "Update fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:14:47Z", "type": "commit"}, {"oid": "2383da13041b59d74156c0c4306729dd54b63d47", "url": "https://github.com/IBM/FHIR/commit/2383da13041b59d74156c0c4306729dd54b63d47", "message": "issue #108 added paging support for the group members\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T03:45:03Z", "type": "commit"}, {"oid": "380d727f9a68588844e74d86a84a29ae5766b049", "url": "https://github.com/IBM/FHIR/commit/380d727f9a68588844e74d86a84a29ae5766b049", "message": "Merge branch 'Albert-Master-New' of git@github.com:IBM/FHIR.git into Albert-Master-New", "committedDate": "2020-01-23T03:52:23Z", "type": "commit"}, {"oid": "3f7248a159d479d2f59db706924fd31293a809bd", "url": "https://github.com/IBM/FHIR/commit/3f7248a159d479d2f59db706924fd31293a809bd", "message": "issue #108 one minor fix\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T13:07:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370140764", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n          \n          \n            \n                                        chunkData.getBufferStream().write(Constants.NDJSON_LINESEPARATOR.getBytes());\n          \n      \n    \n    \n  \n\nWhy not make the NDJSON_LINESEPARATOR bytes anyway?", "author": "prb112", "createdAt": "2020-01-23T14:15:03Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDk2MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370140961", "bodyText": "avoiding getBytes each time?", "author": "prb112", "createdAt": "2020-01-23T14:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2NDc4Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370164787", "bodyText": "I didn't because I thought the cost is very minor, but make sense for me to make the change.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:54:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MTM4MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370141381", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            List<String> searchCreterial = new ArrayList<String>();\n          \n          \n            \n                            List<String> searchCriteria = new ArrayList<String>();", "author": "prb112", "createdAt": "2020-01-23T14:16:07Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2MTU1MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370161550", "bodyText": "this is a refactor, will change in eclipse and commit.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:49:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MTM4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0Mjk2Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370142963", "bodyText": "shouldn't this throw a more specific exception?  more easily differentiating in code downstream?", "author": "prb112", "createdAt": "2020-01-23T14:18:48Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NDc4OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370154788", "bodyText": "not needed, the job always exit when this rare error happens, exception info in log is enough", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:38:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0Mjk2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MzI5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370143293", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n          \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, Set<String> groupsInPath)", "author": "prb112", "createdAt": "2020-01-23T14:19:20Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NTkwMw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370155903", "bodyText": "I used HashSet on purpose here, didn't want this to be generic, it's for internally used only.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:40:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MzI5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDc0NQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370144745", "bodyText": "I think we should throw an exception.  This could lead to unintended consequences.  if a tenant is not passed in, it should be treated as invalid.", "author": "prb112", "createdAt": "2020-01-23T14:21:48Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NzE3Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370157176", "bodyText": "the control should be in the operation side, the javabatch itself allows non tenant id to make the javabatch Job test itself easier.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:42:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDc0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTQxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370145417", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n          \n          \n            \n                            logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n          \n      \n    \n    \n  \n\ngeneral pattern", "author": "prb112", "createdAt": "2020-01-23T14:22:57Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2NjU0OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370166548", "bodyText": "Signed-off-by: Albert Wang xuwang@us.ibm.com", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:57:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTQxNw=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370145979", "bodyText": "maybe add a logger.fine for debug purposes?", "author": "prb112", "createdAt": "2020-01-23T14:23:56Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        if (patientMembers == null) {\n+            Group group = findGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+            patientMembers = new ArrayList<>();\n+            // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+            HashSet<String> groupsInPath = new HashSet<>();\n+            expandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n+        }\n+        List<Member> patientPageMembers = patientMembers.subList((pageNum - 1) * pageSize,\n+                pageNum * pageSize <= patientMembers.size() ? pageNum * pageSize : patientMembers.size());\n+        pageNum++;\n+\n+        if (chunkData == null) {\n+            chunkData = new TransientUserData(pageNum, null, new ArrayList<PartETag>(), 1);\n+            chunkData.setIndexOfCurrentResourceType(0);\n+            jobContext.setTransientUserData(chunkData);\n+        } else {\n+            chunkData.setIndexOfCurrentResourceType(indexOfCurrentResourceType);\n+            chunkData.setPageNum(pageNum);\n+        }\n+        chunkData.setLastPageNum((patientMembers.size() + pageSize -1)/pageSize );\n+\n+        if (!patientPageMembers.isEmpty()) {\n+            logger.fine(\"readItem: loaded patients number - \" + patientMembers.size());\n+            fillChunkDataBuffer(patientPageMembers);\n+        } else {\n+            logger.fine(\"readItem: End of reading!\");\n+        }\n+\n+        return patientPageMembers;\n+    }\n+\n+    @Override\n+    public void open(Serializable checkpoint) throws Exception {\n+        if (checkpoint != null) {\n+            CheckPointUserData checkPointData = (CheckPointUserData) checkpoint;\n+            pageNum = checkPointData.getPageNum();\n+            indexOfCurrentResourceType = checkPointData.getIndexOfCurrentResourceType();\n+            jobContext.setTransientUserData(TransientUserData.fromCheckPointUserData(checkPointData));\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NjQyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370146425", "bodyText": "also chunkData.getBufferStream() <-- who is response to close this?", "author": "prb112", "createdAt": "2020-01-23T14:24:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3ODY5OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370178699", "bodyText": "haha, good question. Actually Closing a ByteArrayOutputStream has no effect per java document, actually the function is empty in codes. it's handled by garbage collector after no reference to it.  and the same ByteArrayOutputStream is used the whole life circle of the batch job.", "author": "albertwang-ibm", "createdAt": "2020-01-23T15:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE4NTcxMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370185711", "bodyText": "OK, I think adding a comment to that effect is good thing in the code.", "author": "prb112", "createdAt": "2020-01-23T15:27:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "chunk": "diff --git a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\nindex cbb6fa7d8a..7f017d09b4 100644\n--- a/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n+++ b/fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\n\n@@ -270,7 +270,7 @@ public class ChunkReader extends AbstractItemReader {\n                 pageSize = Integer.parseInt(fhirSearchPageSize);\n                 logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n             } catch (Exception e) {\n-                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+                logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n             }\n         }\n \n"}}, {"oid": "ac5d50b24ed03d9841411aef2fb395891fea31c4", "url": "https://github.com/IBM/FHIR/commit/ac5d50b24ed03d9841411aef2fb395891fea31c4", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:28:25Z", "type": "commit"}, {"oid": "cf2fabcbf2c87159f81316a936c9a7e14411889f", "url": "https://github.com/IBM/FHIR/commit/cf2fabcbf2c87159f81316a936c9a7e14411889f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:29:25Z", "type": "commit"}, {"oid": "4fa6b3223bb7bfb14048beffebd9ddc09aa0f2fa", "url": "https://github.com/IBM/FHIR/commit/4fa6b3223bb7bfb14048beffebd9ddc09aa0f2fa", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:32:59Z", "type": "commit"}]}