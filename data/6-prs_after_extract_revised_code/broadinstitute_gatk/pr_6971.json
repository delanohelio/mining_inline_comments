{"pr_number": 6971, "pr_title": "Add filtering to ExtractCohort", "pr_createdAt": "2020-11-19T18:18:07Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6971", "timeline": [{"oid": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "url": "https://github.com/broadinstitute/gatk/commit/947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "message": "adding filtering to extractCohort", "committedDate": "2020-11-19T18:08:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEzNTgyNA==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527135824", "bodyText": "This is awesome!", "author": "kcibul", "createdAt": "2020-11-19T19:16:36Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java", "diffHunk": "@@ -46,6 +55,17 @@ protected void onStartup() {\n \n         VCFHeader header = CommonCode.generateVcfHeader(sampleNames, reference.getSequenceDictionary());\n \n+        if (minLocation == null && maxLocation == null && hasUserSuppliedIntervals()) {", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEzNjMxNg==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527136316", "bodyText": "perhaps filterSetName instead", "author": "kcibul", "createdAt": "2020-11-19T19:17:24Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java", "diffHunk": "@@ -37,6 +40,12 @@\n     )\n     private String cohortTable = null;\n \n+    @Argument(\n+            fullName = \"filter-set-name\",\n+            doc = \"Name in filter_set_name column of filtering table to use. Which training set should be applied in extract.\"\n+    )\n+    private String nameOfFilterSet = null;", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java\nindex 3b41fc895..fc62cb0a2 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohort.java\n\n@@ -44,7 +44,7 @@ public class ExtractCohort extends ExtractTool {\n             fullName = \"filter-set-name\",\n             doc = \"Name in filter_set_name column of filtering table to use. Which training set should be applied in extract.\"\n     )\n-    private String nameOfFilterSet = null;\n+    private String filterSetName = null;\n \n     @Override\n     protected void onStartup() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEzNjQ1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527136455", "bodyText": "perhaps filterSetName instead", "author": "kcibul", "createdAt": "2020-11-19T19:17:41Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java", "diffHunk": "@@ -85,7 +86,8 @@ public ExtractCohortEngine(final String projectID,\n                                final double vqsLodSNPThreshold,\n                                final double vqsLodINDELThreshold,\n                                final ProgressMeter progressMeter,\n-                               final ExtractCohort.QueryMode queryMode) {\n+                               final ExtractCohort.QueryMode queryMode,\n+                               final String nameOfFilterSet) {", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\nindex d9ceecd0d..0b92ff74c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n\n@@ -87,7 +87,7 @@ public class ExtractCohortEngine {\n                                final double vqsLodINDELThreshold,\n                                final ProgressMeter progressMeter,\n                                final ExtractCohort.QueryMode queryMode,\n-                               final String nameOfFilterSet) {\n+                               final String filterSetName) {\n         this.localSortMaxRecordsInRam = localSortMaxRecordsInRam;\n \n         this.projectID = projectID;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEzODg5Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527138893", "bodyText": "might be good to have a comment about what each of these alleles are?  is the first allele reference and the second is the alternate?", "author": "kcibul", "createdAt": "2020-11-19T19:21:41Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java", "diffHunk": "@@ -113,19 +117,42 @@ public ExtractCohortEngine(final String projectID,\n     int getTotalNumberOfSites() { return totalNumberOfSites; }\n \n     public void traverse() {\n+\n+        String rowRestriction = null;\n+        if (minLocation != null && maxLocation != null) {\n+            rowRestriction = \"location >= \" + minLocation + \" AND location <= \" + maxLocation;\n+        }\n+        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + nameOfFilterSet + \"'\";\n+\n+        final StorageAPIAvroReader filteringTableAvroReader = new StorageAPIAvroReader(filteringTableRef, rowRestrictionWithFilterSetName, projectID);\n+        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\nindex d9ceecd0d..0b92ff74c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n\n@@ -122,27 +122,25 @@ public class ExtractCohortEngine {\n         if (minLocation != null && maxLocation != null) {\n             rowRestriction = \"location >= \" + minLocation + \" AND location <= \" + maxLocation;\n         }\n-        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + nameOfFilterSet + \"'\";\n+        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + filterSetName + \"'\";\n \n         final StorageAPIAvroReader filteringTableAvroReader = new StorageAPIAvroReader(filteringTableRef, rowRestrictionWithFilterSetName, projectID);\n-        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();\n-        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, String>>> fullYngMap = new HashMap<>();\n+        //First allele here is the ref, followed by the alts associated with that ref. We need this because at this point the alleles haven't been joined and remapped to one reference allele.\n+        final HashMap<Long, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();\n+        final HashMap<Long, HashMap<Allele, HashMap<Allele, String>>> fullYngMap = new HashMap<>();\n \n         for ( final GenericRecord queryRow : filteringTableAvroReader ) {\n             final long location = Long.parseLong(queryRow.get(SchemaUtils.LOCATION_FIELD_NAME).toString());\n-            final int currentPosition = SchemaUtils.decodePosition(location);\n-            final String contig = SchemaUtils.decodeContig(location);\n             final Double vqslod = Double.parseDouble(queryRow.get(\"vqslod\").toString());\n             final String yng = queryRow.get(\"yng_status\").toString();\n             final Allele ref = Allele.create(queryRow.get(\"ref\").toString(), true);\n             final Allele alt = Allele.create(queryRow.get(\"alt\").toString(), false);\n-            final Locatable locatable = new SimpleInterval(contig, currentPosition, currentPosition);\n-            fullVqsLodMap.putIfAbsent(locatable, new HashMap<>());\n-            fullVqsLodMap.get(locatable).putIfAbsent(ref, new HashMap<>());\n-            fullVqsLodMap.get(locatable).get(ref).put(alt, vqslod);\n-            fullYngMap.putIfAbsent(locatable, new HashMap<>());\n-            fullYngMap.get(locatable).putIfAbsent(ref, new HashMap<>());\n-            fullYngMap.get(locatable).get(ref).put(alt, yng);\n+            fullVqsLodMap.putIfAbsent(location, new HashMap<>());\n+            fullVqsLodMap.get(location).putIfAbsent(ref, new HashMap<>());\n+            fullVqsLodMap.get(location).get(ref).put(alt, vqslod);\n+            fullYngMap.putIfAbsent(location, new HashMap<>());\n+            fullYngMap.get(location).putIfAbsent(ref, new HashMap<>());\n+            fullYngMap.get(location).get(ref).put(alt, yng);\n         }\n \n         switch (queryMode) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0MTEyNw==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527141127", "bodyText": "instead of locatable, could we just leave it as location since we'll have that when we try to lookup in this table? (ie coming out of the extract BQ?)", "author": "kcibul", "createdAt": "2020-11-19T19:25:14Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java", "diffHunk": "@@ -113,19 +117,42 @@ public ExtractCohortEngine(final String projectID,\n     int getTotalNumberOfSites() { return totalNumberOfSites; }\n \n     public void traverse() {\n+\n+        String rowRestriction = null;\n+        if (minLocation != null && maxLocation != null) {\n+            rowRestriction = \"location >= \" + minLocation + \" AND location <= \" + maxLocation;\n+        }\n+        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + nameOfFilterSet + \"'\";\n+\n+        final StorageAPIAvroReader filteringTableAvroReader = new StorageAPIAvroReader(filteringTableRef, rowRestrictionWithFilterSetName, projectID);\n+        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();\n+        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, String>>> fullYngMap = new HashMap<>();\n+\n+        for ( final GenericRecord queryRow : filteringTableAvroReader ) {\n+            final long location = Long.parseLong(queryRow.get(SchemaUtils.LOCATION_FIELD_NAME).toString());\n+            final int currentPosition = SchemaUtils.decodePosition(location);\n+            final String contig = SchemaUtils.decodeContig(location);\n+            final Double vqslod = Double.parseDouble(queryRow.get(\"vqslod\").toString());\n+            final String yng = queryRow.get(\"yng_status\").toString();\n+            final Allele ref = Allele.create(queryRow.get(\"ref\").toString(), true);\n+            final Allele alt = Allele.create(queryRow.get(\"alt\").toString(), false);\n+            final Locatable locatable = new SimpleInterval(contig, currentPosition, currentPosition);", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\nindex d9ceecd0d..0b92ff74c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n\n@@ -122,27 +122,25 @@ public class ExtractCohortEngine {\n         if (minLocation != null && maxLocation != null) {\n             rowRestriction = \"location >= \" + minLocation + \" AND location <= \" + maxLocation;\n         }\n-        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + nameOfFilterSet + \"'\";\n+        final String rowRestrictionWithFilterSetName = rowRestriction + \" AND \" + SchemaUtils.FILTER_SET_NAME + \" = '\" + filterSetName + \"'\";\n \n         final StorageAPIAvroReader filteringTableAvroReader = new StorageAPIAvroReader(filteringTableRef, rowRestrictionWithFilterSetName, projectID);\n-        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();\n-        final HashMap<Locatable, HashMap<Allele, HashMap<Allele, String>>> fullYngMap = new HashMap<>();\n+        //First allele here is the ref, followed by the alts associated with that ref. We need this because at this point the alleles haven't been joined and remapped to one reference allele.\n+        final HashMap<Long, HashMap<Allele, HashMap<Allele, Double>>> fullVqsLodMap = new HashMap<>();\n+        final HashMap<Long, HashMap<Allele, HashMap<Allele, String>>> fullYngMap = new HashMap<>();\n \n         for ( final GenericRecord queryRow : filteringTableAvroReader ) {\n             final long location = Long.parseLong(queryRow.get(SchemaUtils.LOCATION_FIELD_NAME).toString());\n-            final int currentPosition = SchemaUtils.decodePosition(location);\n-            final String contig = SchemaUtils.decodeContig(location);\n             final Double vqslod = Double.parseDouble(queryRow.get(\"vqslod\").toString());\n             final String yng = queryRow.get(\"yng_status\").toString();\n             final Allele ref = Allele.create(queryRow.get(\"ref\").toString(), true);\n             final Allele alt = Allele.create(queryRow.get(\"alt\").toString(), false);\n-            final Locatable locatable = new SimpleInterval(contig, currentPosition, currentPosition);\n-            fullVqsLodMap.putIfAbsent(locatable, new HashMap<>());\n-            fullVqsLodMap.get(locatable).putIfAbsent(ref, new HashMap<>());\n-            fullVqsLodMap.get(locatable).get(ref).put(alt, vqslod);\n-            fullYngMap.putIfAbsent(locatable, new HashMap<>());\n-            fullYngMap.get(locatable).putIfAbsent(ref, new HashMap<>());\n-            fullYngMap.get(locatable).get(ref).put(alt, yng);\n+            fullVqsLodMap.putIfAbsent(location, new HashMap<>());\n+            fullVqsLodMap.get(location).putIfAbsent(ref, new HashMap<>());\n+            fullVqsLodMap.get(location).get(ref).put(alt, vqslod);\n+            fullYngMap.putIfAbsent(location, new HashMap<>());\n+            fullYngMap.get(location).putIfAbsent(ref, new HashMap<>());\n+            fullYngMap.get(location).get(ref).put(alt, yng);\n         }\n \n         switch (queryMode) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0NDcxOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6971#discussion_r527144719", "bodyText": "A comment for what this does would be great, since even reading it... I'm not sure!", "author": "kcibul", "createdAt": "2020-11-19T19:30:50Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java", "diffHunk": "@@ -352,45 +389,54 @@ private void finalizeCurrentVariant(final List<VariantContext> unmergedCalls, fi\n         }\n     }\n \n-    private VariantContext filterVariants(VariantContext mergedVC) {\n-        return mergedVC;\n-        //TODO not needed for arrays\n-//            LinkedHashMap<Allele, Double> remappedVqsLodMap = remapAllelesInMap(mergedVC, vqsLodMap, Double.NaN);\n-//            LinkedHashMap<Allele, String> remappedYngMap = remapAllelesInMap(mergedVC, yngMap, VCFConstants.EMPTY_INFO_FIELD);\n-//\n-//            final VariantContextBuilder builder = new VariantContextBuilder(mergedVC);\n-//\n-//            builder.attribute(GATKVCFConstants.AS_VQS_LOD_KEY, remappedVqsLodMap.values().stream().map(val -> val.equals(Double.NaN) ? VCFConstants.EMPTY_INFO_FIELD : val.toString()).collect(Collectors.toList()));\n-//            builder.attribute(GATKVCFConstants.AS_YNG_STATUS_KEY, remappedYngMap.values());\n-//\n-//            int refLength = mergedVC.getReference().length();\n-//\n-//            // if there are any Yays, the site is PASS\n-//            if (remappedYngMap.values().contains(\"Y\")) {\n-//                builder.filter(\"PASS\");\n-//            } else if (remappedYngMap.values().contains(\"N\")) {\n-//                // TODO: do we want to remove this variant?\n-//                builder.filter(\"NAY\");\n-//            } else {\n-//                if (remappedYngMap.values().contains(\"G\")) {\n-//                    // TODO change the initial query to include the filtername from the tranches tables\n-//                    Optional<Double> snpMax = remappedVqsLodMap.entrySet().stream().filter(entry -> entry.getKey().length() == refLength).map(entry -> entry.getValue().equals(Double.NaN) ? 0.0 : entry.getValue()).max(Double::compareTo);\n-//                    if (snpMax.isPresent() && snpMax.get() < vqsLodSNPThreshold) {\n-//                        // TODO: add in sensitivities\n-//                        builder.filter(\"VQSRTrancheSNP\");\n-//                    }\n-//                    Optional<Double> indelMax = remappedVqsLodMap.entrySet().stream().filter(entry -> entry.getKey().length() != refLength).map(entry -> entry.getValue().equals(Double.NaN) ? 0.0 : entry.getValue()).max(Double::compareTo);\n-//                    if (indelMax.isPresent() && indelMax.get() < vqsLodINDELThreshold) {\n-//                        // TODO: add in sensitivities\n-//                        builder.filter(\"VQSRTrancheINDEL\");\n-//                    }\n-//                }\n-//                // TODO: what if there is nothing in the YNG table?\n-//                // this shouldn't happen\n-//            }\n-//\n-//            final VariantContext filteredVC = builder.make();\n+    private VariantContext filterVariants(VariantContext mergedVC, HashMap<Allele, HashMap<Allele, Double>> vqsLodMap, HashMap<Allele, HashMap<Allele, String>> yngMap) {\n+        LinkedHashMap<Allele, Double> remappedVqsLodMap = remapAllelesInMap(mergedVC, vqsLodMap, Double.NaN);\n+        LinkedHashMap<Allele, String> remappedYngMap = remapAllelesInMap(mergedVC, yngMap, VCFConstants.EMPTY_INFO_FIELD);\n+\n+        final VariantContextBuilder builder = new VariantContextBuilder(mergedVC);\n+\n+        builder.attribute(GATKVCFConstants.AS_VQS_LOD_KEY, mergedVC.getAlternateAlleles()\n+                .stream()\n+                .map(a -> remappedVqsLodMap.get(a))\n+                .filter(Objects::nonNull)\n+                .map(val -> val.equals(Double.NaN) ? VCFConstants.EMPTY_INFO_FIELD : val.toString())\n+                .collect(Collectors.toList()));\n+        builder.attribute(GATKVCFConstants.AS_YNG_STATUS_KEY, mergedVC.getAlternateAlleles()\n+                .stream()\n+                .map(a -> remappedYngMap.get(a))\n+                .filter(Objects::nonNull)\n+                .collect(Collectors.toList()));\n+\n+        int refLength = mergedVC.getReference().length();\n+\n+        // if there are any Yays, the site is PASS\n+        if (remappedYngMap.values().contains(\"Y\")) {\n+            builder.passFilters();\n+        } else if (remappedYngMap.values().contains(\"N\")) {\n+            builder.filter(GATKVCFConstants.NAY_FROM_YNG);\n+        } else {\n+            // if it doesn't trigger any of the filters below, we assume it passes.\n+            builder.passFilters();\n+            if (remappedYngMap.values().contains(\"G\")) {\n+            // TODO change the initial query to include the filtername from the tranches tables\n+            Optional<Double> snpMax = remappedVqsLodMap.entrySet().stream().filter(entry -> entry.getKey().length() == refLength).map(entry -> entry.getValue().equals(Double.NaN) ? 0.0 : entry.getValue()).max(Double::compareTo);\n+            if (snpMax.isPresent() && snpMax.get() < vqsLodSNPThreshold) {\n+                // TODO: add in sensitivities\n+                builder.filter(GATKVCFConstants.VQSR_TRANCHE_SNP);\n+            }\n+            Optional<Double> indelMax = remappedVqsLodMap.entrySet().stream().filter(entry -> entry.getKey().length() != refLength).map(entry -> entry.getValue().equals(Double.NaN) ? 0.0 : entry.getValue()).max(Double::compareTo);\n+            if (indelMax.isPresent() && indelMax.get() < vqsLodINDELThreshold) {\n+                // TODO: add in sensitivities\n+                builder.filter(GATKVCFConstants.VQSR_TRANCHE_INDEL);\n+                }\n+            } else {\n+                // If VQSR dropped this site (there's no YNG or VQSLOD) then we'll filter it as a NAY.\n+                builder.filter(GATKVCFConstants.NAY_FROM_YNG);\n+            }\n         }\n+        final VariantContext filteredVC = builder.make();\n+        return filteredVC;\n+    }\n \n     private <T> LinkedHashMap<Allele, T> remapAllelesInMap(VariantContext vc, HashMap<Allele, HashMap<Allele, T>> datamap, T emptyVal) {", "originalCommit": "947313a881a0efcf9f37d9c8ce10f06e3aa87d88", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\nindex d9ceecd0d..0b92ff74c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/variantdb/nextgen/ExtractCohortEngine.java\n\n@@ -438,6 +436,10 @@ public class ExtractCohortEngine {\n         return filteredVC;\n     }\n \n+    /*\n+     * Alleles from the filtering table need to be remapped to use the same ref allele that the will exist in the joined variant context.\n+     * This method changes the alleles in the datamap to match the representation that's in the vc.\n+     */\n     private <T> LinkedHashMap<Allele, T> remapAllelesInMap(VariantContext vc, HashMap<Allele, HashMap<Allele, T>> datamap, T emptyVal) {\n         // get the extended reference\n         Allele ref = vc.getReference();\n"}}, {"oid": "4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "url": "https://github.com/broadinstitute/gatk/commit/4f5b8c74ac4ec559a12e1596a4aaececaa3fd34f", "message": "addressing comments", "committedDate": "2020-11-19T21:29:30Z", "type": "commit"}]}