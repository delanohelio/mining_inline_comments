{"pr_number": 6394, "pr_title": "Consolidated branch with JunctionTreeImprovements.", "pr_createdAt": "2020-01-20T00:33:48Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6394", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNzc0Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369917746", "bodyText": "haplotypeList might not be the best name for a Set<Haplotype>", "author": "davidbenjamin", "createdAt": "2020-01-23T03:28:55Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java", "diffHunk": "@@ -11,6 +15,8 @@\n     private final Status status;\n     private final AbstractReadThreadingGraph threadingGraph;\n     private final SeqGraph graph;\n+    private Set<Haplotype> haplotypeList;", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\nindex 9e5351ad3..1138c11cd 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\n\n@@ -15,8 +11,6 @@ public final class AssemblyResult {\n     private final Status status;\n     private final AbstractReadThreadingGraph threadingGraph;\n     private final SeqGraph graph;\n-    private Set<Haplotype> haplotypeList;\n-    private boolean containsSuspectHaplotypes;\n \n     /**\n      * Create a new assembly result\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNzg4Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369917882", "bodyText": "I would let good grammar override the desire to start boolean getters with is.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:29:50Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java", "diffHunk": "@@ -42,6 +48,22 @@ public int getKmerSize() {\n         return graph == null? threadingGraph.getKmerSize() : graph.getKmerSize();\n     }\n \n+    public Set<Haplotype> getHaplotypeList() {\n+        return haplotypeList;\n+    }\n+\n+    public void setHaplotypeList(Set<Haplotype> haplotypeList) {\n+        this.haplotypeList = haplotypeList;\n+    }\n+\n+    public boolean isContainsSuspectHaplotypes() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\nindex 9e5351ad3..1138c11cd 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java\n\n@@ -48,22 +42,6 @@ public final class AssemblyResult {\n         return graph == null? threadingGraph.getKmerSize() : graph.getKmerSize();\n     }\n \n-    public Set<Haplotype> getHaplotypeList() {\n-        return haplotypeList;\n-    }\n-\n-    public void setHaplotypeList(Set<Haplotype> haplotypeList) {\n-        this.haplotypeList = haplotypeList;\n-    }\n-\n-    public boolean isContainsSuspectHaplotypes() {\n-        return containsSuspectHaplotypes;\n-    }\n-\n-    public void setContainsSuspectHaplotypes(boolean containsSuspectHaplotypes) {\n-        this.containsSuspectHaplotypes = containsSuspectHaplotypes;\n-    }\n-\n     /**\n      * Status of the assembly result\n      */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODIxNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918214", "bodyText": "omit the space before 10", "author": "davidbenjamin", "createdAt": "2020-01-23T03:32:10Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -61,7 +61,7 @@\n      */\n     @Advanced\n     @Argument(fullName= KMER_SIZE_LONG_NAME, doc=\"Kmer size to use in the read threading assembler\", optional = true)\n-    public List<Integer> kmerSizes = Lists.newArrayList(10,25);\n+    public List<Integer> kmerSizes = Lists.newArrayList( 10, 25);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\nindex 741207b9c..a26578a5c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n\n@@ -61,7 +34,7 @@ public abstract class ReadThreadingAssemblerArgumentCollection implements Serial\n      */\n     @Advanced\n     @Argument(fullName= KMER_SIZE_LONG_NAME, doc=\"Kmer size to use in the read threading assembler\", optional = true)\n-    public List<Integer> kmerSizes = Lists.newArrayList( 10, 25);\n+    public List<Integer> kmerSizes = Lists.newArrayList(10,25);\n \n     /**\n      * When graph cycles are detected, the normal behavior is to increase kmer sizes iteratively until the cycles are\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODMyNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918324", "bodyText": "Rewrite the doc string to avoid the double negative", "author": "davidbenjamin", "createdAt": "2020-01-23T03:32:54Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -161,6 +161,13 @@\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n+    /**\n+     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder\n+     */\n+    @Hidden\n+    @Argument(fullName=\"disable-artificial-haplotype-recovery\", doc = \"If disabled, linked de bruijn graph will not attempt to recover variant haplotypes that are not supported by junction trees\", optional = true)", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\nindex 741207b9c..a26578a5c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n\n@@ -161,13 +134,6 @@ public abstract class ReadThreadingAssemblerArgumentCollection implements Serial\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n-    /**\n-     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder\n-     */\n-    @Hidden\n-    @Argument(fullName=\"disable-artificial-haplotype-recovery\", doc = \"If disabled, linked de bruijn graph will not attempt to recover variant haplotypes that are not supported by junction trees\", optional = true)\n-    public boolean disableArtificialHaplotypeRecovery = false;\n-\n     @Advanced\n     @Argument(fullName=\"debug-assembly\", shortName=\"debug\", doc=\"Print out verbose debug information about each assembly region\", optional = true)\n     public boolean debugAssembly;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODM1OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918358", "bodyText": "This javadoc was copied and not modified", "author": "davidbenjamin", "createdAt": "2020-01-23T03:33:07Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -161,6 +161,13 @@\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n+    /**\n+     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\nindex 741207b9c..a26578a5c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n\n@@ -161,13 +134,6 @@ public abstract class ReadThreadingAssemblerArgumentCollection implements Serial\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n-    /**\n-     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder\n-     */\n-    @Hidden\n-    @Argument(fullName=\"disable-artificial-haplotype-recovery\", doc = \"If disabled, linked de bruijn graph will not attempt to recover variant haplotypes that are not supported by junction trees\", optional = true)\n-    public boolean disableArtificialHaplotypeRecovery = false;\n-\n     @Advanced\n     @Argument(fullName=\"debug-assembly\", shortName=\"debug\", doc=\"Print out verbose debug information about each assembly region\", optional = true)\n     public boolean debugAssembly;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODYzNQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918635", "bodyText": "setWasPoorlyRecovered", "author": "davidbenjamin", "createdAt": "2020-01-23T03:35:15Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java", "diffHunk": "@@ -167,6 +184,14 @@ public void addJunctionTree(final JunctionTreeLinkedDeBruinGraph.ThreadingTree j\n         }\n     }\n \n+    /**\n+     * Add a flag of graph that based on this haplotype we think we should expand the kmer size\n+     * @param b\n+     */\n+    public void setIsWonky(final boolean b) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1NzY1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374257659", "bodyText": "What, you think the isWonky() is not a reasonable method in the gatk?", "author": "jamesemery", "createdAt": "2020-02-03T18:12:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODYzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java\nindex 5db3ec7f6..ca9f99f93 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java\n\n@@ -184,14 +167,6 @@ public class JTBestHaplotype<V extends BaseVertex, E extends BaseEdge> extends K\n         }\n     }\n \n-    /**\n-     * Add a flag of graph that based on this haplotype we think we should expand the kmer size\n-     * @param b\n-     */\n-    public void setIsWonky(final boolean b) {\n-        this.wasPoorlyRecovered = b;\n-    }\n-\n     /**\n      * A helper class for managing the various junction tree operations that need to be done by JTBestHaplotypeFinder\n      *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTY0OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921648", "bodyText": "There's a runMutect2 method at the bottom of this class that you should use.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:55:08Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test\n+    public void testWhySiteFails() {\n+        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTkxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921918", "bodyText": "And does the test still work without all the non-default arguments?", "author": "davidbenjamin", "createdAt": "2020-01-23T03:56:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTY0OA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\nindex b55adb88e..33455747a 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n\n@@ -197,23 +196,6 @@ public class Mutect2IntegrationTest extends CommandLineProgramTest {\n         };\n     }\n \n-    @Test\n-    public void testWhySiteFails() {\n-        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +\n-                \" gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly19.fasta\" +\n-                \" -normal synthetic.challenge.set1.normal -bamout bamout.bam -O calls.vcf -L 15:33482411-33484411 --debug-graph-transformations\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n-    @Test\n-    public void testInfiniteLoop() {\n-        String[] args = (\"-R gs://gatk-best-practices/somatic-b37/Homo_sapiens_assembly19.fasta -I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -tumor synthetic.challenge.set1.tumor \" +\n-                \"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -normal synthetic.challenge.set1.normal \" +\n-                \"--germline-resource gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf -pon gs://fc-8803b178-2553-4f68-9560-caf1d3d37997/pon/wgs_125_plus_targeted_dream.vcf \" +\n-                \"-L 1:2616022-3015494 -O output.vcf --bam-output bamout.bam --max-mnp-distance 0 --downsampling-stride 20 --max-reads-per-alignment-start 6 --max-suspicious-reads-per-alignment-start 6\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n     @Test(dataProvider = \"twoTumorData\")\n     public void testTwoDreamTumorSamples(final List<File> tumors, final List<File> normals,\n                                          final File truth, final File mask, final double requiredSensitivity) throws Exception {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTcxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921718", "bodyText": "What is this testing?", "author": "davidbenjamin", "createdAt": "2020-01-23T03:55:31Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0ODYwNw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374348607", "bodyText": "same as the other error. I apologize i thought I had deleted all of these debugger test sites from development.", "author": "jamesemery", "createdAt": "2020-02-03T21:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTcxOA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\nindex b55adb88e..33455747a 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n\n@@ -197,23 +196,6 @@ public class Mutect2IntegrationTest extends CommandLineProgramTest {\n         };\n     }\n \n-    @Test\n-    public void testWhySiteFails() {\n-        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +\n-                \" gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly19.fasta\" +\n-                \" -normal synthetic.challenge.set1.normal -bamout bamout.bam -O calls.vcf -L 15:33482411-33484411 --debug-graph-transformations\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n-    @Test\n-    public void testInfiniteLoop() {\n-        String[] args = (\"-R gs://gatk-best-practices/somatic-b37/Homo_sapiens_assembly19.fasta -I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -tumor synthetic.challenge.set1.tumor \" +\n-                \"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -normal synthetic.challenge.set1.normal \" +\n-                \"--germline-resource gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf -pon gs://fc-8803b178-2553-4f68-9560-caf1d3d37997/pon/wgs_125_plus_targeted_dream.vcf \" +\n-                \"-L 1:2616022-3015494 -O output.vcf --bam-output bamout.bam --max-mnp-distance 0 --downsampling-stride 20 --max-reads-per-alignment-start 6 --max-suspicious-reads-per-alignment-start 6\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n     @Test(dataProvider = \"twoTumorData\")\n     public void testTwoDreamTumorSamples(final List<File> tumors, final List<File> normals,\n                                          final File truth, final File mask, final double requiredSensitivity) throws Exception {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTgzNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921834", "bodyText": "Same as above -- what is it testing and use the runMutect2 method.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:56:14Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test\n+    public void testWhySiteFails() {\n+        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +\n+                \" gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly19.fasta\" +\n+                \" -normal synthetic.challenge.set1.normal -bamout bamout.bam -O calls.vcf -L 15:33482411-33484411 --debug-graph-transformations\").split(\" \");\n+        runCommandLine(args);\n+    }\n+\n+    @Test\n+    public void testInfiniteLoop() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\nindex b55adb88e..33455747a 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java\n\n@@ -197,23 +196,6 @@ public class Mutect2IntegrationTest extends CommandLineProgramTest {\n         };\n     }\n \n-    @Test\n-    public void testWhySiteFails() {\n-        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +\n-                \" gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly19.fasta\" +\n-                \" -normal synthetic.challenge.set1.normal -bamout bamout.bam -O calls.vcf -L 15:33482411-33484411 --debug-graph-transformations\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n-    @Test\n-    public void testInfiniteLoop() {\n-        String[] args = (\"-R gs://gatk-best-practices/somatic-b37/Homo_sapiens_assembly19.fasta -I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -tumor synthetic.challenge.set1.tumor \" +\n-                \"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -normal synthetic.challenge.set1.normal \" +\n-                \"--germline-resource gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf -pon gs://fc-8803b178-2553-4f68-9560-caf1d3d37997/pon/wgs_125_plus_targeted_dream.vcf \" +\n-                \"-L 1:2616022-3015494 -O output.vcf --bam-output bamout.bam --max-mnp-distance 0 --downsampling-stride 20 --max-reads-per-alignment-start 6 --max-suspicious-reads-per-alignment-start 6\").split(\" \");\n-        runCommandLine(args);\n-    }\n-\n     @Test(dataProvider = \"twoTumorData\")\n     public void testTwoDreamTumorSamples(final List<File> tumors, final List<File> normals,\n                                          final File truth, final File mask, final double requiredSensitivity) throws Exception {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjA1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369922059", "bodyText": "Use an ArgumentsBuilder and explain what this is testing.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:57:44Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java", "diffHunk": "@@ -126,6 +129,12 @@ public void testVCFModeWithExperimentalAssemblyEngineCode(final String inputFile\n         }\n     }\n \n+    @Test\n+    public void testThisSiteThatEludesMe() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0NzgwMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374347801", "bodyText": "whoops, this was leftover from trying to debug some issue or other in the code during development. I'll just remove this test so as not to cause problems.", "author": "jamesemery", "createdAt": "2020-02-03T21:22:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjA1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\nindex dff9dadbd..d418936b7 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\n\n@@ -129,12 +126,6 @@ public class HaplotypeCallerIntegrationTest extends CommandLineProgramTest {\n         }\n     }\n \n-    @Test\n-    public void testThisSiteThatEludesMe() {\n-        String[] args = \"-I /Users/emeryj/hellbender/AssemblyEngineEvaluationWork/results/reads.overlapping.discordance.bam -O output.for.debugging.vcf -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly38.fasta -ip 1000 -L chr1:10742920\".split(\" \");\n-        runCommandLine(args);\n-    }\n-\n     /*\n      * Test that in VCF mode we're consistent with past GATK4 results\n      *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjE3Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369922176", "bodyText": "Use the variable, not the string literal.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:58:16Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java", "diffHunk": "@@ -114,7 +117,7 @@ public void testVCFModeWithExperimentalAssemblyEngineCode(final String inputFile\n                 \"-L\", \"20:10000000-10100000\",\n                 \"-O\", outputPath,\n                 \"-pairHMM\", \"AVX_LOGLESS_CACHING\",\n-                \"--disable-sequence-graph-simplification\",\n+                \"--linked-de-bruijn-graph\",", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\nindex dff9dadbd..d418936b7 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java\n\n@@ -117,7 +114,7 @@ public class HaplotypeCallerIntegrationTest extends CommandLineProgramTest {\n                 \"-L\", \"20:10000000-10100000\",\n                 \"-O\", outputPath,\n                 \"-pairHMM\", \"AVX_LOGLESS_CACHING\",\n-                \"--linked-de-bruijn-graph\",\n+                \"--disable-sequence-graph-simplification\",\n                 \"--\" + StandardArgumentDefinitions.ADD_OUTPUT_VCF_COMMANDLINE, \"false\"\n         };\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzgzOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369923838", "bodyText": "Is the idea that this has to be a List and not, say, an OptionalInt, because of cycles in the reference?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:09:12Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java", "diffHunk": "@@ -30,6 +32,8 @@\n     private final int singleSampleCapacity;\n     private final PriorityQueue<Integer> singleSampleMultiplicities;\n \n+    private final List<Integer> referencePathIndexes = new ArrayList<>(2);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMzNjUxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374336513", "bodyText": "Correct", "author": "jamesemery", "createdAt": "2020-02-03T20:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzgzOA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java\nindex 974e7ab3c..f6dea8217 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java\n\n@@ -32,8 +30,6 @@ public final class MultiSampleEdge extends BaseEdge {\n     private final int singleSampleCapacity;\n     private final PriorityQueue<Integer> singleSampleMultiplicities;\n \n-    private final List<Integer> referencePathIndexes = new ArrayList<>(2);\n-\n     /**\n      * Create a new MultiSampleEdge with weight multiplicity and, if isRef == true, indicates a path through the reference\n      *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzk2NA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369923964", "bodyText": "While you're at it, the line above can use Utils.validate()", "author": "davidbenjamin", "createdAt": "2020-01-23T04:10:00Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java", "diffHunk": "@@ -93,7 +93,8 @@ public Path(final Path<V,E> p, final List<E> edges) {\n         for (int i = 0; i < edges.size(); i++) {\n             if ( ! p.graph.getEdgeSource(edges.get(i)).equals(tmpVertex) ) {\n                 throw new IllegalStateException(\"Edges added to path must be contiguous.\");\n-            } tmpVertex = p.graph.getEdgeTarget(edges.get(i));\n+            }", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java\nindex 961736425..81f26526e 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java\n\n@@ -93,8 +93,7 @@ public class Path<V extends BaseVertex, E extends BaseEdge> {\n         for (int i = 0; i < edges.size(); i++) {\n             if ( ! p.graph.getEdgeSource(edges.get(i)).equals(tmpVertex) ) {\n                 throw new IllegalStateException(\"Edges added to path must be contiguous.\");\n-            }\n-            tmpVertex = p.graph.getEdgeTarget(edges.get(i));\n+            } tmpVertex = p.graph.getEdgeTarget(edges.get(i));\n         }\n \n         graph = p.graph;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDE0Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924143", "bodyText": "typo: should be Indices (or Indexes -- both are correct)", "author": "davidbenjamin", "createdAt": "2020-01-23T04:11:14Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -404,6 +405,20 @@ public void postProcessForHaplotypeFinding(final File debugGraphOutputPath, fina\n         }\n     }\n \n+    //TODO this should really be easy enough to write a test for\n+    @VisibleForTesting\n+    private void annotateEdgesWithReferenceIndecies() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\nindex d2ca73320..8088a485d 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n\n@@ -405,20 +404,6 @@ public class JunctionTreeLinkedDeBruinGraph extends AbstractReadThreadingGraph {\n         }\n     }\n \n-    //TODO this should really be easy enough to write a test for\n-    @VisibleForTesting\n-    private void annotateEdgesWithReferenceIndecies() {\n-        final List<MultiDeBruijnVertex> referencePath = getReferencePath(TraversalDirection.downwards);\n-        MultiDeBruijnVertex lastVert = null;\n-        int refIndex = 0;\n-        for (MultiDeBruijnVertex nextVert : referencePath) {\n-            if (lastVert != null) {\n-                getEdge(lastVert, nextVert).addReferenceIndex(refIndex++);\n-            }\n-            lastVert = nextVert;\n-        }\n-    }\n-\n \n     // Generate threading trees\n     public void generateJunctionTrees() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDE5MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924191", "bodyText": "This method is both private and VisibleForTesting?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:11:33Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -404,6 +405,20 @@ public void postProcessForHaplotypeFinding(final File debugGraphOutputPath, fina\n         }\n     }\n \n+    //TODO this should really be easy enough to write a test for\n+    @VisibleForTesting\n+    private void annotateEdgesWithReferenceIndecies() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\nindex d2ca73320..8088a485d 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n\n@@ -405,20 +404,6 @@ public class JunctionTreeLinkedDeBruinGraph extends AbstractReadThreadingGraph {\n         }\n     }\n \n-    //TODO this should really be easy enough to write a test for\n-    @VisibleForTesting\n-    private void annotateEdgesWithReferenceIndecies() {\n-        final List<MultiDeBruijnVertex> referencePath = getReferencePath(TraversalDirection.downwards);\n-        MultiDeBruijnVertex lastVert = null;\n-        int refIndex = 0;\n-        for (MultiDeBruijnVertex nextVert : referencePath) {\n-            if (lastVert != null) {\n-                getEdge(lastVert, nextVert).addReferenceIndex(refIndex++);\n-            }\n-            lastVert = nextVert;\n-        }\n-    }\n-\n \n     // Generate threading trees\n     public void generateJunctionTrees() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDYzOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924639", "bodyText": "final", "author": "davidbenjamin", "createdAt": "2020-01-23T04:14:33Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -452,25 +467,43 @@ private void threadSequenceForJuncitonTree(final SequenceForKmers seqForKmers) {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        int kmersPastSinceLast = 0;\n+        boolean hasToRediscoverKmer = false;\n+        int kmersPastSinceLastNullVertex = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            final MultiDeBruijnVertex vertex;\n-            if (kmersPastSinceLast == 0) {\n+            MultiDeBruijnVertex vertex;\n+            if (!hasToRediscoverKmer) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-                // TODO this might cause problems\n-                if (vertex != null) {\n-                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n+            }\n+            // we found a null path in the grpah\n+            if (vertex == null) {\n+                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n+                if (kmersPastSinceLastNullVertex == 0) {\n+                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\nindex d2ca73320..8088a485d 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n\n@@ -467,43 +452,25 @@ public class JunctionTreeLinkedDeBruinGraph extends AbstractReadThreadingGraph {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        boolean hasToRediscoverKmer = false;\n-        int kmersPastSinceLastNullVertex = 0;\n+        int kmersPastSinceLast = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            MultiDeBruijnVertex vertex;\n-            if (!hasToRediscoverKmer) {\n+            final MultiDeBruijnVertex vertex;\n+            if (kmersPastSinceLast == 0) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-            }\n-            // we found a null path in the grpah\n-            if (vertex == null) {\n-                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n-                if (kmersPastSinceLastNullVertex == 0) {\n-                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);\n-                    if (outgoingEdges.size()==1) {\n-                        vertex = getEdgeTarget(outgoingEdges.stream().findFirst().get());\n-                        kmersPastSinceLastNullVertex = 1;\n-                    }\n-                // if we dropped multiple bases from the read following an already missing path from the reference then we throw it away and try to catch the trail from kmers again\n-                } else {\n-                    hasToRediscoverKmer = true;\n-                    nodeHelper.clear();\n+                // TODO this might cause problems\n+                if (vertex != null) {\n+                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n                 }\n             }\n-\n             // If for whatever reason vertex = null, then we have fallen off the corrected graph so we don't update anything\n             if (vertex != null) {\n                 lastVertex = vertex;\n-\n-                // If we aren't in an error state do nothing, otherwise we increment the count of bases, if we are over kmersize then revert to a safety state\n-                if (kmersPastSinceLastNullVertex > 0) {\n-                    kmersPastSinceLastNullVertex++;\n-                    if (kmersPastSinceLastNullVertex > kmerSize) {\n-                        kmersPastSinceLastNullVertex = 0;\n-                    }\n-                }\n+                kmersPastSinceLast = 0;\n+            } else {\n+                kmersPastSinceLast++;\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369925448", "bodyText": "Could you explain what this does?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:19:50Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -452,25 +467,43 @@ private void threadSequenceForJuncitonTree(final SequenceForKmers seqForKmers) {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        int kmersPastSinceLast = 0;\n+        boolean hasToRediscoverKmer = false;\n+        int kmersPastSinceLastNullVertex = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            final MultiDeBruijnVertex vertex;\n-            if (kmersPastSinceLast == 0) {\n+            MultiDeBruijnVertex vertex;\n+            if (!hasToRediscoverKmer) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-                // TODO this might cause problems\n-                if (vertex != null) {\n-                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n+            }\n+            // we found a null path in the grpah\n+            if (vertex == null) {\n+                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n+                if (kmersPastSinceLastNullVertex == 0) {\n+                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);\n+                    if (outgoingEdges.size()==1) {\n+                        vertex = getEdgeTarget(outgoingEdges.stream().findFirst().get());\n+                        kmersPastSinceLastNullVertex = 1;\n+                    }\n+                // if we dropped multiple bases from the read following an already missing path from the reference then we throw it away and try to catch the trail from kmers again\n+                } else {\n+                    hasToRediscoverKmer = true;\n+                    nodeHelper.clear();\n                 }\n             }\n+\n             // If for whatever reason vertex = null, then we have fallen off the corrected graph so we don't update anything\n             if (vertex != null) {\n                 lastVertex = vertex;\n-                kmersPastSinceLast = 0;\n-            } else {\n-                kmersPastSinceLast++;\n+\n+                // If we aren't in an error state do nothing, otherwise we increment the count of bases, if we are over kmersize then revert to a safety state\n+                if (kmersPastSinceLastNullVertex > 0) {\n+                    kmersPastSinceLastNullVertex++;\n+                    if (kmersPastSinceLastNullVertex > kmerSize) {\n+                        kmersPastSinceLastNullVertex = 0;", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0NzA5Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374347097", "bodyText": "Yes. I will try to clean up the comments to this effect:\nWe want to \"skip\" over single base incongruities if we can since they mean some path was pruned from the graph. In order to do that we have a \"unsafe state\" mode and the normal mode. If we are missing our next edge then we attempt to skip one edge past in both and flip into the unsafe state. The idea is that if there was a pruned SNP error we want to try to walk over the next kmer size bases and if we find k. If we find k exact matching bases between the read and the graph then we have walked over an entire kmer. There is a potential issue with this code that we discussed. I will refactor this to check ahead of time for validity without touching the trees at all.", "author": "jamesemery", "createdAt": "2020-02-03T21:20:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4ODY1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374388655", "bodyText": "I have refactored it to do this step \"tentatively\" ahead of time. I will ask you to take a look afterwards.", "author": "jamesemery", "createdAt": "2020-02-03T22:55:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\nindex d2ca73320..8088a485d 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java\n\n@@ -467,43 +452,25 @@ public class JunctionTreeLinkedDeBruinGraph extends AbstractReadThreadingGraph {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        boolean hasToRediscoverKmer = false;\n-        int kmersPastSinceLastNullVertex = 0;\n+        int kmersPastSinceLast = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            MultiDeBruijnVertex vertex;\n-            if (!hasToRediscoverKmer) {\n+            final MultiDeBruijnVertex vertex;\n+            if (kmersPastSinceLast == 0) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-            }\n-            // we found a null path in the grpah\n-            if (vertex == null) {\n-                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n-                if (kmersPastSinceLastNullVertex == 0) {\n-                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);\n-                    if (outgoingEdges.size()==1) {\n-                        vertex = getEdgeTarget(outgoingEdges.stream().findFirst().get());\n-                        kmersPastSinceLastNullVertex = 1;\n-                    }\n-                // if we dropped multiple bases from the read following an already missing path from the reference then we throw it away and try to catch the trail from kmers again\n-                } else {\n-                    hasToRediscoverKmer = true;\n-                    nodeHelper.clear();\n+                // TODO this might cause problems\n+                if (vertex != null) {\n+                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n                 }\n             }\n-\n             // If for whatever reason vertex = null, then we have fallen off the corrected graph so we don't update anything\n             if (vertex != null) {\n                 lastVertex = vertex;\n-\n-                // If we aren't in an error state do nothing, otherwise we increment the count of bases, if we are over kmersize then revert to a safety state\n-                if (kmersPastSinceLastNullVertex > 0) {\n-                    kmersPastSinceLastNullVertex++;\n-                    if (kmersPastSinceLastNullVertex > kmerSize) {\n-                        kmersPastSinceLastNullVertex = 0;\n-                    }\n-                }\n+                kmersPastSinceLast = 0;\n+            } else {\n+                kmersPastSinceLast++;\n             }\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTgxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369925813", "bodyText": "SNP", "author": "davidbenjamin", "createdAt": "2020-01-23T04:21:44Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\nindex bee660813..35752dac2 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n\n@@ -96,105 +96,6 @@ public class JunctionTreeKBestHaplotypeFinderUnitTest extends GATKBaseTest {\n \n     }\n \n-    @Test\n-    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 2);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-        Assert.assertEquals(bestPaths.get(1), \"AAAACAC\"+\"T\"+\"C\" + read2); //asserting that the front of read 1 was appended to read 2 for haplotype construction\n-    }\n-\n-    @Test\n-    // This test documents one of the known edge cases in the pivotal edge recovery code where sometimes an edge might be\n-    // dropped if there doesn't happen to be any result path that connects to the root vertex of this dorpped path\n-    public void testRecoveryOfAPathDroppedByJunctionTreeFailureDueToStillBeingUnreachable() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"TTTAGAGAG\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph is interestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                    \"TAGAGTG\"+\"GGGTT\"; // creates a branch off of the uncovered reference path\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 1);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-    }\n-\n-    // TODO this test is disabled because currently we have NOT implemented, so now we are simply using the score of the output path as the\n-    // TODO heurisitic for stapling the front onto this path. this might be addressed in the future.\n-    @Test (enabled = false)\n-    public void testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n-        String ref =            \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"C\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        String completePath1 =  \"AAAACAC\"+\"T\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"T\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\";\n-        String completePath2 =  \"AAAACAC\"+\"G\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\";\n-        String incompletePath =                \"TGTGCGG\"+\"C\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\"; // njote that this point is a copy of path 2 after its first C variant\n-\n-        // Ensure that completePath1 will have the highest score by weighting it heavily\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-\n-        // followed by lower weight complete path 2\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-\n-        // And the incomplete path\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-\n-        Assert.assertEquals(bestPaths.size(), 3);\n-        Assert.assertEquals(bestPaths.get(0), completePath1);\n-        Assert.assertEquals(bestPaths.get(1), completePath2);\n-        Assert.assertEquals(bestPaths.get(2), \"AAAACAC\"+\"G\"+\"A\" + incompletePath); // asserting that path 2 (the most similar path) was used for the head of incomplete path\n-    }\n-\n     @Test\n     // This test demonstrates a potential source of infinite looping, specifically the chain extension\n     public void testDegernerateLoopingDanglingEndInChainGatheringCode() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjUxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369926518", "bodyText": "Is there an overloaded version of addSequence with a multiplicity argument so you don't have to repeat lines?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:26:17Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het\n+        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n+        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n+\n+        assembler.addSequence(\"reference\", getBytes(ref), true);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4MTYxMA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374381610", "bodyText": "There is one but it has the feature of adding multiplicty to the graph which doesn't get accounted for in the junction trees. Maybe it should be refactored to work that way?", "author": "jamesemery", "createdAt": "2020-02-03T22:37:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjUxOA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\nindex bee660813..35752dac2 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n\n@@ -96,105 +96,6 @@ public class JunctionTreeKBestHaplotypeFinderUnitTest extends GATKBaseTest {\n \n     }\n \n-    @Test\n-    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 2);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-        Assert.assertEquals(bestPaths.get(1), \"AAAACAC\"+\"T\"+\"C\" + read2); //asserting that the front of read 1 was appended to read 2 for haplotype construction\n-    }\n-\n-    @Test\n-    // This test documents one of the known edge cases in the pivotal edge recovery code where sometimes an edge might be\n-    // dropped if there doesn't happen to be any result path that connects to the root vertex of this dorpped path\n-    public void testRecoveryOfAPathDroppedByJunctionTreeFailureDueToStillBeingUnreachable() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"TTTAGAGAG\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph is interestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                    \"TAGAGTG\"+\"GGGTT\"; // creates a branch off of the uncovered reference path\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 1);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-    }\n-\n-    // TODO this test is disabled because currently we have NOT implemented, so now we are simply using the score of the output path as the\n-    // TODO heurisitic for stapling the front onto this path. this might be addressed in the future.\n-    @Test (enabled = false)\n-    public void testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n-        String ref =            \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"C\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        String completePath1 =  \"AAAACAC\"+\"T\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"T\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\";\n-        String completePath2 =  \"AAAACAC\"+\"G\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\";\n-        String incompletePath =                \"TGTGCGG\"+\"C\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\"; // njote that this point is a copy of path 2 after its first C variant\n-\n-        // Ensure that completePath1 will have the highest score by weighting it heavily\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-\n-        // followed by lower weight complete path 2\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-\n-        // And the incomplete path\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-\n-        Assert.assertEquals(bestPaths.size(), 3);\n-        Assert.assertEquals(bestPaths.get(0), completePath1);\n-        Assert.assertEquals(bestPaths.get(1), completePath2);\n-        Assert.assertEquals(bestPaths.get(2), \"AAAACAC\"+\"G\"+\"A\" + incompletePath); // asserting that path 2 (the most similar path) was used for the head of incomplete path\n-    }\n-\n     @Test\n     // This test demonstrates a potential source of infinite looping, specifically the chain extension\n     public void testDegernerateLoopingDanglingEndInChainGatheringCode() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjYwNw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369926607", "bodyText": "Typo: dorpped", "author": "davidbenjamin", "createdAt": "2020-01-23T04:26:56Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het\n+        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n+        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n+\n+        assembler.addSequence(\"reference\", getBytes(ref), true);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n+\n+        assembler.buildGraphIfNecessary();\n+        assembler.generateJunctionTrees();\n+\n+        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n+                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n+\n+        Assert.assertEquals(bestPaths.size(), 2);\n+        Assert.assertEquals(bestPaths.get(0), read1);\n+        Assert.assertEquals(bestPaths.get(1), \"AAAACAC\"+\"T\"+\"C\" + read2); //asserting that the front of read 1 was appended to read 2 for haplotype construction\n+    }\n+\n+    @Test\n+    // This test documents one of the known edge cases in the pivotal edge recovery code where sometimes an edge might be\n+    // dropped if there doesn't happen to be any result path that connects to the root vertex of this dorpped path", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\nindex bee660813..35752dac2 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n\n@@ -96,105 +96,6 @@ public class JunctionTreeKBestHaplotypeFinderUnitTest extends GATKBaseTest {\n \n     }\n \n-    @Test\n-    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 2);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-        Assert.assertEquals(bestPaths.get(1), \"AAAACAC\"+\"T\"+\"C\" + read2); //asserting that the front of read 1 was appended to read 2 for haplotype construction\n-    }\n-\n-    @Test\n-    // This test documents one of the known edge cases in the pivotal edge recovery code where sometimes an edge might be\n-    // dropped if there doesn't happen to be any result path that connects to the root vertex of this dorpped path\n-    public void testRecoveryOfAPathDroppedByJunctionTreeFailureDueToStillBeingUnreachable() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n-        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"TTTAGAGAG\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph is interestingg\n-\n-        // A simple snip het\n-        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n-        String read2 =                    \"TAGAGTG\"+\"GGGTT\"; // creates a branch off of the uncovered reference path\n-\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-        Assert.assertEquals(bestPaths.size(), 1);\n-        Assert.assertEquals(bestPaths.get(0), read1);\n-    }\n-\n-    // TODO this test is disabled because currently we have NOT implemented, so now we are simply using the score of the output path as the\n-    // TODO heurisitic for stapling the front onto this path. this might be addressed in the future.\n-    @Test (enabled = false)\n-    public void testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n-        String ref =            \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"C\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n-\n-        String completePath1 =  \"AAAACAC\"+\"T\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"T\"+\"GAGAGATATA\"+\"C\"+\"GAGTTTTGTTT\";\n-        String completePath2 =  \"AAAACAC\"+\"G\"+\"ATGTGCGG\"+\"A\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\";\n-        String incompletePath =                \"TGTGCGG\"+\"C\"+\"TTTAGAGAG\"+\"A\"+\"GGGTTCC\"+\"A\"+\"GAGAGATATA\"+\"G\"+\"GAGTTTTGTTT\"; // njote that this point is a copy of path 2 after its first C variant\n-\n-        // Ensure that completePath1 will have the highest score by weighting it heavily\n-        assembler.addSequence(\"reference\", getBytes(ref), true);\n-\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath1), false);\n-\n-        // followed by lower weight complete path 2\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-        assembler.addSequence(\"anonymous\", getBytes(completePath2), false);\n-\n-        // And the incomplete path\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-        assembler.addSequence(\"anonymous\", getBytes(incompletePath), false);\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n-                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n-\n-\n-        Assert.assertEquals(bestPaths.size(), 3);\n-        Assert.assertEquals(bestPaths.get(0), completePath1);\n-        Assert.assertEquals(bestPaths.get(1), completePath2);\n-        Assert.assertEquals(bestPaths.get(2), \"AAAACAC\"+\"G\"+\"A\" + incompletePath); // asserting that path 2 (the most similar path) was used for the head of incomplete path\n-    }\n-\n     @Test\n     // This test demonstrates a potential source of infinite looping, specifically the chain extension\n     public void testDegernerateLoopingDanglingEndInChainGatheringCode() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNzEzMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369927133", "bodyText": "This is a very nice test.", "author": "davidbenjamin", "createdAt": "2020-01-23T04:30:26Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -1099,4 +1198,80 @@ public void testKmerGraphSimpleReferenceRecoveryWithSNP() {\n         }\n         return path;\n     }\n+\n+\n+    @Test\n+    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderBasicExample() {\n+        int readlength = 20;\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n+        String ref = \"TAAACAAG\"+\"G\"+\"TTGGGTTCG\"+\"A\"+\"GCGGGGTTC\"+\"T\"+\"CTCGAAGT\"+\"T\"+\"CTTGGTAATAT\"+\"A\"+\"GGGGGCCCC\"; // Reference with 5 sites all separated by at least kmer size\n+        String alt1 = \"TAAACAAG\"+\"T\"+\"TTGGGTTCG\"+\"G\"+\"GCGGGGTTC\"+\"A\"+\"CTCGAAGT\"+\"C\"+\"CTTGGTAATAT\"+\"G\"+\"GGGGGCCCC\"; // Alt with different values for all sites\n+\n+        // Generate some reads that do not span the entire active region\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        for (int i = 0; i + readlength < ref.length(); i++) {\n+            assembler.addSequence(\"anonymous\", getBytes(alt1.substring(i, i + readlength)), false);\n+        }\n+\n+        assembler.buildGraphIfNecessary();\n+        assembler.generateJunctionTrees();\n+\n+        final JunctionTreeKBestHaplotypeFinder<MultiDeBruijnVertex, MultiSampleEdge> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1);\n+\n+        LinkedHashSet<MultiSampleEdge> pivotalEdges = bestPaths.createMapOfPivotalEdgesInTopologicalOrder();\n+        Iterator<MultiSampleEdge> edgesInOrder = pivotalEdges.iterator();\n+        ListIterator<String> expectedEdgeKmerTargetsFOrPivotalEdges = Arrays.asList(new String[]{\"AACAAGT\",\"GGTTCGG\",\"GGGTTCA\",\"CGAAGTC\",\"TAATATG\"}).listIterator();\n+\n+        // Asserting that the order of edges is as expected\n+        Assert.assertEquals(pivotalEdges.size(), 5);\n+        while (edgesInOrder.hasNext()) {\n+            MultiSampleEdge nextEdge = edgesInOrder.next();\n+            String expectedKmerEdge = expectedEdgeKmerTargetsFOrPivotalEdges.next();\n+            String nextTarget = assembler.getEdgeTarget(nextEdge).getSequenceString();\n+            Assert.assertEquals(nextTarget, expectedKmerEdge);\n+        }\n+\n+    }\n+\n+    @Test\n+    // this test asserts that included in pivotal edges are edges that are only reachable by following uncovered reference path\n+    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderHiddenReferenceSequence() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\nindex bee660813..35752dac2 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java\n\n@@ -1198,80 +1099,4 @@ public class JunctionTreeKBestHaplotypeFinderUnitTest extends GATKBaseTest {\n         }\n         return path;\n     }\n-\n-\n-    @Test\n-    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderBasicExample() {\n-        int readlength = 20;\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n-        String ref = \"TAAACAAG\"+\"G\"+\"TTGGGTTCG\"+\"A\"+\"GCGGGGTTC\"+\"T\"+\"CTCGAAGT\"+\"T\"+\"CTTGGTAATAT\"+\"A\"+\"GGGGGCCCC\"; // Reference with 5 sites all separated by at least kmer size\n-        String alt1 = \"TAAACAAG\"+\"T\"+\"TTGGGTTCG\"+\"G\"+\"GCGGGGTTC\"+\"A\"+\"CTCGAAGT\"+\"C\"+\"CTTGGTAATAT\"+\"G\"+\"GGGGGCCCC\"; // Alt with different values for all sites\n-\n-        // Generate some reads that do not span the entire active region\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        for (int i = 0; i + readlength < ref.length(); i++) {\n-            assembler.addSequence(\"anonymous\", getBytes(alt1.substring(i, i + readlength)), false);\n-        }\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final JunctionTreeKBestHaplotypeFinder<MultiDeBruijnVertex, MultiSampleEdge> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1);\n-\n-        LinkedHashSet<MultiSampleEdge> pivotalEdges = bestPaths.createMapOfPivotalEdgesInTopologicalOrder();\n-        Iterator<MultiSampleEdge> edgesInOrder = pivotalEdges.iterator();\n-        ListIterator<String> expectedEdgeKmerTargetsFOrPivotalEdges = Arrays.asList(new String[]{\"AACAAGT\",\"GGTTCGG\",\"GGGTTCA\",\"CGAAGTC\",\"TAATATG\"}).listIterator();\n-\n-        // Asserting that the order of edges is as expected\n-        Assert.assertEquals(pivotalEdges.size(), 5);\n-        while (edgesInOrder.hasNext()) {\n-            MultiSampleEdge nextEdge = edgesInOrder.next();\n-            String expectedKmerEdge = expectedEdgeKmerTargetsFOrPivotalEdges.next();\n-            String nextTarget = assembler.getEdgeTarget(nextEdge).getSequenceString();\n-            Assert.assertEquals(nextTarget, expectedKmerEdge);\n-        }\n-\n-    }\n-\n-    @Test\n-    // this test asserts that included in pivotal edges are edges that are only reachable by following uncovered reference path\n-    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderHiddenReferenceSequence() {\n-        int readlength = 20;\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n-        String ref =  \"TAAACAAG\"+\"G\"+\"TTGGGTTCG\"+\"AGCGGT\"+\"CTCGAAGT\"+\"T\"+\"CTTGGTAATAT\"+\"A\"+\"GGGGGCCCC\"; // Reference with 5 sites all separated by at least kmer size\n-        String alt1 = \"TAAACAAG\"+\"T\"+\"TTGGGTTCG\"+\"GGCGGA\"+\"CTCGAAGT\"+\"C\"+\"CTTGGTAATAT\"+\"G\"+\"GGGGGCCCC\"; // Alt with different values for all sites\n-        String alt2 =                        \"AGCGGTCT\"+\"G\"+\"CGAAGT\"+\"T\"+\"CTTGGTAATAT\"+\"A\"+\"GGGGGCCCC\"; // A snippet of reference sequence starting after an uncovered reference edge\n-\n-        // Generate some reads that do not span the entire active region\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        for (int i = 0; i + readlength < ref.length(); i++) {\n-            assembler.addSequence(\"anonymous\", getBytes(alt1.substring(i, i + readlength)), false);\n-        }\n-\n-        for (int i = 0; i + readlength < alt2.length(); i++) {\n-            assembler.addSequence(\"anonymous\", getBytes(alt2.substring(i, i + readlength)), false);\n-        }\n-\n-        assembler.buildGraphIfNecessary();\n-        assembler.generateJunctionTrees();\n-\n-        final JunctionTreeKBestHaplotypeFinder<MultiDeBruijnVertex, MultiSampleEdge> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1);\n-\n-        LinkedHashSet<MultiSampleEdge> pivotalEdges = bestPaths.createMapOfPivotalEdgesInTopologicalOrder();\n-        Iterator<MultiSampleEdge> edgesInOrder = pivotalEdges.iterator();\n-        ListIterator<String> expectedEdgeKmerTargetsFOrPivotalEdges = Arrays.asList(new String[]{\"AACAAGT\",\"GGTTCGG\", // edges corresoinding to the start of alt1 path\n-                \"CGGTCTG\", // Edge corresponding to the G insertion (This would be dropped if we didn't include reference edges with no support in this calculation)\n-                \"CGAAGTC\",\n-                \"TAATATA\",\"TAATATG\" // Edges correspoindg to the ref and alt respectively, the order is arbitrary because the shortest path is what is taken to determine distance\n-        }).listIterator();\n-\n-        // Asserting that the order of edges is as expected\n-        Assert.assertEquals(pivotalEdges.size(), 6);\n-        while (edgesInOrder.hasNext()) {\n-            MultiSampleEdge nextEdge = edgesInOrder.next();\n-            String expectedKmerEdge = expectedEdgeKmerTargetsFOrPivotalEdges.next();\n-            String nextTarget = assembler.getEdgeTarget(nextEdge).getSequenceString();\n-            Assert.assertEquals(nextTarget, expectedKmerEdge);\n-        }\n-    }\n }\n\\ No newline at end of file\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxMzkyMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370313922", "bodyText": "Having a ternary where all operands are boolean is just too boolean.  How about:\nif (queue.size() > (result.isEmpty() ? DEFAULT_MAX_PATHS_TO_CONSIDER_WITHOUT_RESULT : DEFAULT_MAX_PATHS_TO_EVER_CONSIDER)", "author": "davidbenjamin", "createdAt": "2020-01-23T19:34:03Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -86,33 +97,49 @@ public boolean keepCycles() {\n     @Override\n     @SuppressWarnings({\"unchecked\"})\n     public List<KBestHaplotype<V, E>> findBestHaplotypes(final int maxNumberOfHaplotypes) {\n+        //pre-process step: find pivotal edges so they can be marked off as visited (if we want to recover edges uncovered in the graph).\n+        final LinkedHashSet<E> unvisitedPivotalEdges = experimentalEndRecoveryMode ? createMapOfPivotalEdgesInTopologicalOrder() : new LinkedHashSet<>();\n+\n         final List<JTBestHaplotype<V, E>> result = new ArrayList<>();\n         final PriorityQueue<JTBestHaplotype<V, E>> queue = new PriorityQueue<>(Comparator.comparingDouble(KBestHaplotype<V, E>::score).reversed());\n         sources.forEach(source -> queue.add(new JTBestHaplotype<>(source, graph)));\n \n         // Iterate over paths in the queue, unless we are out of paths of maxHaplotypes to find\n-        while (!queue.isEmpty() && result.size() < maxNumberOfHaplotypes) {\n+        while (result.size() < maxNumberOfHaplotypes && (!queue.isEmpty() || !unvisitedPivotalEdges.isEmpty())) {\n+            // check that we aren't caught in a hopelessly complicated graph for which we can't hope to recover\n+            if (result.isEmpty() ?", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -97,28 +86,12 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n     @Override\n     @SuppressWarnings({\"unchecked\"})\n     public List<KBestHaplotype<V, E>> findBestHaplotypes(final int maxNumberOfHaplotypes) {\n-        //pre-process step: find pivotal edges so they can be marked off as visited (if we want to recover edges uncovered in the graph).\n-        final LinkedHashSet<E> unvisitedPivotalEdges = experimentalEndRecoveryMode ? createMapOfPivotalEdgesInTopologicalOrder() : new LinkedHashSet<>();\n-\n         final List<JTBestHaplotype<V, E>> result = new ArrayList<>();\n         final PriorityQueue<JTBestHaplotype<V, E>> queue = new PriorityQueue<>(Comparator.comparingDouble(KBestHaplotype<V, E>::score).reversed());\n         sources.forEach(source -> queue.add(new JTBestHaplotype<>(source, graph)));\n \n         // Iterate over paths in the queue, unless we are out of paths of maxHaplotypes to find\n-        while (result.size() < maxNumberOfHaplotypes && (!queue.isEmpty() || !unvisitedPivotalEdges.isEmpty())) {\n-            // check that we aren't caught in a hopelessly complicated graph for which we can't hope to recover\n-            if (result.isEmpty() ?\n-                    queue.size() > DEFAULT_MAX_PATHS_TO_CONSIDER_WITHOUT_RESULT : // restrict the number of branching paths examined\n-                    queue.size() > DEFAULT_MAX_PATHS_TO_EVER_CONSIDER) {\n-                break;\n-            }\n-\n-            // breakout condition, pop a new path onto the tree from unvisited pivotal edges if\n-            if ( queue.isEmpty() ) {\n-                enqueueNextPivotalEdge(unvisitedPivotalEdges, result, queue);\n-                continue;\n-            }\n-\n+        while (!queue.isEmpty() && result.size() < maxNumberOfHaplotypes) {\n             final JTBestHaplotype<V, E> pathToExtend = queue.poll();\n \n             // This safeguards against infinite loops and degenerate excessively long paths, only allow 4 decisions without junction tree guidance\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNDgxMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370314811", "bodyText": "Do you have a plan for this TODO?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:36:05Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA4MTY5Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r373081693", "bodyText": "This was intended as a question for you the reviewer. Specifically I mean the path annotation based on the graph which is used to mark haplotypes that are \"bad\" so we may filter or kmer expand them. Its disabled now because as it was implemented it didn't change the results on that CHM dataset I was looking at.", "author": "jamesemery", "createdAt": "2020-01-30T17:15:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNDgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -171,15 +144,11 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n-                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n-                // check that we were able to recover the missing path\n-                if (newPath != null) {\n-                    //TODO this might be removed, this is where we evaluate\n-                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n-                    result.add(newPath);\n+                if (chain.isEmpty()) {\n+                    result.add(pathToExtend);\n+                } else {\n+                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n                 }\n-                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTQ4MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315481", "bodyText": "Write this as something like \"Filter out paths that involve the same kmer too many times without permission from a junction tree\"", "author": "davidbenjamin", "createdAt": "2020-01-23T19:37:25Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -171,15 +144,11 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n-                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n-                // check that we were able to recover the missing path\n-                if (newPath != null) {\n-                    //TODO this might be removed, this is where we evaluate\n-                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n-                    result.add(newPath);\n+                if (chain.isEmpty()) {\n+                    result.add(pathToExtend);\n+                } else {\n+                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n                 }\n-                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTY2OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315669", "bodyText": "typo: laset", "author": "davidbenjamin", "createdAt": "2020-01-23T19:37:47Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)\n+                List<JTBestHaplotype<V, E>> filteredPaths = jTPaths.stream()\n+                        .filter(path -> path.hasJunctionTreeEvidence() || path.wasLastEdgeFollowedBasedOnJTEvidence() ||\n+                                // Count the number of occurances of the laset vertex, if there are more than DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH throw away the path", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -171,15 +144,11 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n-                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n-                // check that we were able to recover the missing path\n-                if (newPath != null) {\n-                    //TODO this might be removed, this is where we evaluate\n-                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n-                    result.add(newPath);\n+                if (chain.isEmpty()) {\n+                    result.add(pathToExtend);\n+                } else {\n+                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n                 }\n-                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTk2NA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315964", "bodyText": "I liked the previous indentation better.   What does IntelliJ say?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:38:22Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)\n+                List<JTBestHaplotype<V, E>> filteredPaths = jTPaths.stream()\n+                        .filter(path -> path.hasJunctionTreeEvidence() || path.wasLastEdgeFollowedBasedOnJTEvidence() ||\n+                                // Count the number of occurances of the laset vertex, if there are more than DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH throw away the path\n+                                path.getVertices().stream().filter(v -> v.equals(path.getLastVertex())).count() <= DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH)\n+                        .collect(Collectors.toList());\n+                if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n+                    logger.debug(\"A path was filtered because it was looping without junction tree support\");\n+                }\n+\n+                queue.addAll(filteredPaths);\n \n-            // Otherwise just take the next node forward\n+                // Otherwise just take the next node forward", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDUwNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374314504", "bodyText": "whoops, some of these are casualties to the intellij automatic formatting.", "author": "jamesemery", "createdAt": "2020-02-03T20:08:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTk2NA=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -171,15 +144,11 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n-                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n-                // check that we were able to recover the missing path\n-                if (newPath != null) {\n-                    //TODO this might be removed, this is where we evaluate\n-                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n-                    result.add(newPath);\n+                if (chain.isEmpty()) {\n+                    result.add(pathToExtend);\n+                } else {\n+                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n                 }\n-                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjI1MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370316250", "bodyText": "This would be a good place to remind people of the definition of a pivotal edge.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:39:00Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjkyMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370316922", "bodyText": "Status of this TODO?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:40:22Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM5MTYwMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374391601", "bodyText": "It did show up as a non-zero fraction on the profiler. It should be optimized. That and \"is this vertex a junction tree vertex\" (which is not cached and thus gets called by every read at every vertex which should be fixed) are both newly taking up runtime and could save a few percent in runtime. I would opt to push optimization into another PR the fix for this so as not to get bogged down in this review.", "author": "jamesemery", "createdAt": "2020-02-03T23:03:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjkyMg=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNzM2Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370317367", "bodyText": "typo: piviotal", "author": "davidbenjamin", "createdAt": "2020-01-23T19:41:21Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNzc3MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370317771", "bodyText": "typo: occurrences", "author": "davidbenjamin", "createdAt": "2020-01-23T19:42:14Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODI1MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318250", "bodyText": "This exception is not very informative", "author": "davidbenjamin", "createdAt": "2020-01-23T19:43:16Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318372", "bodyText": "Status of this commented-out code?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:43:32Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMyMDUyOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374320528", "bodyText": "This was the old attempt to reconcile path heads after the fact. Something akin to this will be necessary in the future if we want to base head pasting on the similarity between ptaths. For now i think its okay to just remove it.", "author": "jamesemery", "createdAt": "2020-02-03T20:21:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMyOTY4Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375329686", "bodyText": "Remove is good for now.", "author": "davidbenjamin", "createdAt": "2020-02-05T15:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODcxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318713", "bodyText": "capitalize tiny", "author": "davidbenjamin", "createdAt": "2020-01-23T19:44:19Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n+     *\n+     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n+     * or might not be considered by the KBestHaplotypeFinder.\n+     *\n+     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n+     *       a breadth first search.\n+     *\n+     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n+     */\n+    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n+    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n+    @VisibleForTesting\n+    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n+        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n+        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n+        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n+\n+        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n+        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n+\n+        // Initialize the graph with the start\n+        edgesToVisit.addAll(sources.stream()\n+                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n+                .map(e -> new tinyEdgeHelper(e, 0))\n+                .collect(Collectors.toList()));\n+\n+        while (!edgesToVisit.isEmpty()) {\n+            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n+            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n+\n+            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n+            if (outgoingEdges.size() > 1) {\n+                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n+                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n+            }\n+\n+            // visit the unvisited edges and add any edges not already found to the output linked hash map\n+            outgoingEdges.stream()\n+                    .filter(e -> !visitedEdges.contains(e))\n+                    .forEach(e -> {\n+                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n+                        visitedEdges.add(e);\n+                    });\n+        }\n+\n+        return outputEdgesInOrder;\n+    }\n+\n+\n+    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n+    private class tinyEdgeHelper {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxOTUxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370319513", "bodyText": "topography. . . topographical", "author": "davidbenjamin", "createdAt": "2020-01-23T19:45:57Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n+     *\n+     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n+     * or might not be considered by the KBestHaplotypeFinder.\n+     *\n+     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n+     *       a breadth first search.\n+     *\n+     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n+     */\n+    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n+    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n+    @VisibleForTesting\n+    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n+        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n+        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n+        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n+\n+        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n+        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxOTc5Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370319796", "bodyText": "Remind the reader about the definition of pivotal edge here", "author": "davidbenjamin", "createdAt": "2020-01-23T19:46:31Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\nindex a32377325..d6a064fe7 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java\n\n@@ -228,201 +188,4 @@ public class JunctionTreeKBestHaplotypeFinder<V extends BaseVertex, E extends Ba\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n-    /**\n-     * Helper method that controls the logic for pivotal edges.\n-     *\n-     * The logic for pivotal edges currently is this:\n-     *  1: pop the next pivotal edge in our tree\n-     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n-     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n-     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n-     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n-     *\n-     *\n-     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n-     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n-     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n-     *       for an illustration of this problem.\n-     *\n-     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n-     * @param result                completed paths in the graph to use for construction\n-     * @param queue                 path priority queue to deposit new edges into\n-     */\n-    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n-        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n-        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n-        unvisitedPivotalEdges.remove(firstEdge);\n-\n-        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n-        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n-        if (bestMatchingHaplotype.isPresent()) {\n-            // Now we try to construct a reference covering haplotype from the one we just discovered\n-            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n-            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-            if (edgesIncomingToSplitPoint.isEmpty()) {\n-                return;\n-            }\n-\n-            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n-            // TODO maybe this will matter some day, simply select the last edge\n-            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-            edgesBeforeSplit.add(firstEdge);\n-\n-            // create a new path with the beginging of the best edge stapled to the front\n-            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n-            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n-                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n-                    .filter(Optional::isPresent)\n-                    .map(Optional::get)\n-                    .collect(Collectors.toList());\n-            pathToAdd.markTreesAsVisited(treesPassed);\n-            queue.add(pathToAdd);\n-        }\n-    }\n-\n-    //TODO this probably needs to be more testing...\n-    //TODO thiss might be best computed in the paths as they are being expanded\n-    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n-        int farthestReferenceEdgeReached = 0;\n-        int numUpstreamRefEdgesEncountered = 0;\n-        int lastReferenceEdgeVisited = 0;\n-        for (E edge : newPath.getEdges()) {\n-            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n-\n-            // if we are not on a reference edge don't worry\n-            if (!refOccurances.isEmpty()) {\n-                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n-                int refIndex = 0;\n-                for (Integer index : refOccurances) {\n-                    refIndex = index;\n-                    if (refIndex > lastReferenceEdgeVisited) {\n-                        break;\n-                    }\n-                }\n-\n-                // check if we are too far upstream\n-                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n-                    numUpstreamRefEdgesEncountered++;\n-                } else if (refIndex > farthestReferenceEdgeReached) {\n-                    farthestReferenceEdgeReached = refIndex;\n-                }\n-                lastReferenceEdgeVisited = refIndex;\n-            }\n-        }\n-\n-        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n-        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n-            newPath.setIsWonky(true);\n-        }\n-    }\n-\n-\n-    /**\n-     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n-     *\n-     * @return true if a valid reference-starting path was able to be constructed.\n-     */\n-    // TODO maybe if this fails to find we should include the reference path explicitly\n-    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n-        // check that the path is valid, if so don't modify it\n-        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n-            return pathToReconcile;\n-        }\n-\n-        throw new RuntimeException(\"e\");\n-//\n-//        V pivotalVerex = pathToReconcile.getFirstVertex();\n-//        //TODO this can be MUCH faster than a simple contains search here\n-//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n-//\n-//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n-//        if (candidatePaths.isEmpty()) {\n-//            // this is a failure state for now\n-//            return null;\n-//        }\n-//\n-//        //TODO this is totally simple for right now, will choose a better approach soon.\n-//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n-//\n-//        // Now we try to construct a reference covering haplotype from the one we just discovered\n-//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n-//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n-//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n-//        if (edgesIncomingToSplitPoint.isEmpty()) {\n-//            return null;\n-//        }\n-//\n-//        // TODO maybe this will matter some day, simply select the last edge\n-//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n-//        outputEdges.addAll(pathToReconcile.getEdges());\n-//\n-//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n-    }\n-\n-    /**\n-     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n-     *\n-     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n-     * or might not be considered by the KBestHaplotypeFinder.\n-     *\n-     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n-     *       a breadth first search.\n-     *\n-     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n-     */\n-    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n-    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n-    @VisibleForTesting\n-    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n-        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n-        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n-        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n-\n-        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n-        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n-\n-        // Initialize the graph with the start\n-        edgesToVisit.addAll(sources.stream()\n-                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n-                .map(e -> new tinyEdgeHelper(e, 0))\n-                .collect(Collectors.toList()));\n-\n-        while (!edgesToVisit.isEmpty()) {\n-            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n-            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n-\n-            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n-            if (outgoingEdges.size() > 1) {\n-                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n-                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n-            }\n-\n-            // visit the unvisited edges and add any edges not already found to the output linked hash map\n-            outgoingEdges.stream()\n-                    .filter(e -> !visitedEdges.contains(e))\n-                    .forEach(e -> {\n-                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n-                        visitedEdges.add(e);\n-                    });\n-        }\n-\n-        return outputEdgesInOrder;\n-    }\n-\n-\n-    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n-    private class tinyEdgeHelper {\n-        E edge;\n-        int score;\n-\n-        private tinyEdgeHelper(E e, int i) {\n-            edge = e;\n-            score = score();\n-        }\n-\n-        private int score() {\n-            return score;\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMDI3Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370320273", "bodyText": "typo: Correciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:47:35Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 7ec7d16f4..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -485,106 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorreciton() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMTI0Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370321242", "bodyText": "typo: Correciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:49:43Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 7ec7d16f4..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -485,106 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorreciton() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMTg1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370321855", "bodyText": "These are great tests but you need to extract the shared code.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:51:12Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 7ec7d16f4..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -485,106 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorreciton() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjQ3Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322476", "bodyText": "typo: Junciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:52:22Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        // We only see the supported alt path because the unsupported alt path is never recovered\n+        Assert.assertEquals(bestPaths.size(),1);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 7ec7d16f4..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -485,106 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorreciton() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjY2NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322665", "bodyText": "If possible, it would be nice for this test too to fall within the extracted method of the above two tests.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:52:50Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        // We only see the supported alt path because the unsupported alt path is never recovered\n+        Assert.assertEquals(bestPaths.size(),1);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 7ec7d16f4..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -485,106 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorreciton() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjg5OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322899", "bodyText": "Comment not needed", "author": "davidbenjamin", "createdAt": "2020-01-23T19:53:18Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -74,12 +75,17 @@ public ReadThreadingAssembler(final int maxAllowedPathsForReadThreadingAssembler\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = kmerSizes;\n+        this.kmerSizes = new ArrayList<>(kmerSizes);\n+        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\nindex a0f4aba58..83a8d59d1 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n\n@@ -75,17 +75,12 @@ public final class ReadThreadingAssembler {\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = new ArrayList<>(kmerSizes);\n-        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes\n+        this.kmerSizes = kmerSizes;\n         this.dontIncreaseKmerSizesForCycles = dontIncreaseKmerSizesForCycles;\n         this.allowNonUniqueKmersInRef = allowNonUniqueKmersInRef;\n         this.numPruningSamples = numPruningSamples;\n         this.pruneFactor = pruneFactor;\n         this.generateSeqGraph = !useLinkedDebrujinGraphs;\n-        if (!generateSeqGraph) {\n-            logger.error(\"JunctionTreeLinkedDeBruinGraph is enabled.\\n This is an exeperimental assembly graph mode that has not been fully validated\\n\\n\");\n-        }\n-\n         chainPruner = useAdaptivePruning ? new AdaptiveChainPruner<>(initialErrorRateForPruning, pruningLogOddsThreshold, maxUnprunedVariants) :\n                 new LowWeightChainPruner<>(pruneFactor);\n         numBestHaplotypesPerGraph = maxAllowedPathsForReadThreadingAssembler;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMzE2MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370323160", "bodyText": "typo: exeperimental", "author": "davidbenjamin", "createdAt": "2020-01-23T19:53:53Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -74,12 +75,17 @@ public ReadThreadingAssembler(final int maxAllowedPathsForReadThreadingAssembler\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = kmerSizes;\n+        this.kmerSizes = new ArrayList<>(kmerSizes);\n+        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes\n         this.dontIncreaseKmerSizesForCycles = dontIncreaseKmerSizesForCycles;\n         this.allowNonUniqueKmersInRef = allowNonUniqueKmersInRef;\n         this.numPruningSamples = numPruningSamples;\n         this.pruneFactor = pruneFactor;\n         this.generateSeqGraph = !useLinkedDebrujinGraphs;\n+        if (!generateSeqGraph) {\n+            logger.error(\"JunctionTreeLinkedDeBruinGraph is enabled.\\n This is an exeperimental assembly graph mode that has not been fully validated\\n\\n\");", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\nindex a0f4aba58..83a8d59d1 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n\n@@ -75,17 +75,12 @@ public final class ReadThreadingAssembler {\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = new ArrayList<>(kmerSizes);\n-        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes\n+        this.kmerSizes = kmerSizes;\n         this.dontIncreaseKmerSizesForCycles = dontIncreaseKmerSizesForCycles;\n         this.allowNonUniqueKmersInRef = allowNonUniqueKmersInRef;\n         this.numPruningSamples = numPruningSamples;\n         this.pruneFactor = pruneFactor;\n         this.generateSeqGraph = !useLinkedDebrujinGraphs;\n-        if (!generateSeqGraph) {\n-            logger.error(\"JunctionTreeLinkedDeBruinGraph is enabled.\\n This is an exeperimental assembly graph mode that has not been fully validated\\n\\n\");\n-        }\n-\n         chainPruner = useAdaptivePruning ? new AdaptiveChainPruner<>(initialErrorRateForPruning, pruningLogOddsThreshold, maxUnprunedVariants) :\n                 new LowWeightChainPruner<>(pruneFactor);\n         numBestHaplotypesPerGraph = maxAllowedPathsForReadThreadingAssembler;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMzU1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370323559", "bodyText": "put stuff on separate lines", "author": "davidbenjamin", "createdAt": "2020-01-23T19:54:45Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -142,24 +148,44 @@ public AssemblyResultSet runLocalAssembly(final AssemblyRegion assemblyRegion,\n         final SimpleInterval activeRegionExtendedLocation = assemblyRegion.getExtendedSpan();\n         refHaplotype.setGenomeLocation(activeRegionExtendedLocation);\n         resultSet.add(refHaplotype);\n-        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n+        // either follow the old method for building graphs and then assembling or assemble and haplotype call before expanding kmers\n+        if (generateSeqGraph) {\n+            assembleKmerGraphsAndHaplotypeCall(refHaplotype, refLoc, header, aligner,\n+                    correctedReads, nonRefSeqGraphs, resultSet, activeRegionExtendedLocation);\n+        } else {\n+            assembleGraphsAndExpandKmersGivenHaplotypes(refHaplotype, refLoc, header, aligner,\n+                    correctedReads, nonRefRTGraphs, resultSet, activeRegionExtendedLocation);\n+        }\n+\n+        // If we get to this point then no graph worked... thats bad and indicates something horrible happened, in this case we just return a reference haplotype\n+        if (resultSet.getHaplotypeList().isEmpty()) {\n+            logger.debug(\"Graph at position \"+resultSet.getPaddedReferenceLoc()+\" failed to assemble anything informative; emitting just the reference here\" );\n+        }\n+\n+        // print the graphs if the appropriate debug option has been turned on\n+        if ( graphOutputPath != null ) { if (generateSeqGraph) { printGraphs(nonRefSeqGraphs); } else { printGraphs(nonRefRTGraphs); } }", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\nindex a0f4aba58..83a8d59d1 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n\n@@ -145,47 +140,27 @@ public final class ReadThreadingAssembler {\n         resultSet.setRegionForGenotyping(assemblyRegion);\n         resultSet.setFullReferenceWithPadding(fullReferenceWithPadding);\n         resultSet.setPaddedReferenceLoc(refLoc);\n-        final SimpleInterval activeRegionExtendedLocation = assemblyRegion.getExtendedSpan();\n+        final SimpleInterval activeRegionExtendedLocation = assemblyRegion.getPaddedSpan();\n         refHaplotype.setGenomeLocation(activeRegionExtendedLocation);\n         resultSet.add(refHaplotype);\n-        // either follow the old method for building graphs and then assembling or assemble and haplotype call before expanding kmers\n-        if (generateSeqGraph) {\n-            assembleKmerGraphsAndHaplotypeCall(refHaplotype, refLoc, header, aligner,\n-                    correctedReads, nonRefSeqGraphs, resultSet, activeRegionExtendedLocation);\n-        } else {\n-            assembleGraphsAndExpandKmersGivenHaplotypes(refHaplotype, refLoc, header, aligner,\n-                    correctedReads, nonRefRTGraphs, resultSet, activeRegionExtendedLocation);\n-        }\n-\n-        // If we get to this point then no graph worked... thats bad and indicates something horrible happened, in this case we just return a reference haplotype\n-        if (resultSet.getHaplotypeList().isEmpty()) {\n-            logger.debug(\"Graph at position \"+resultSet.getPaddedReferenceLoc()+\" failed to assemble anything informative; emitting just the reference here\" );\n-        }\n-\n-        // print the graphs if the appropriate debug option has been turned on\n-        if ( graphOutputPath != null ) { if (generateSeqGraph) { printGraphs(nonRefSeqGraphs); } else { printGraphs(nonRefRTGraphs); } }\n-        if ( graphHaplotypeHistogramPath != null ) { haplotypeHistogram.add((double)resultSet.getHaplotypeCount()); }\n-\n-        return resultSet;\n-    }\n-\n-    /**\n-     * Follow the old behavior, call into {@link #assemble(List, Haplotype, SAMFileHeader, SmithWatermanAligner)} to decide if a graph\n-     * is acceptable for haplotype discovery then detect haplotypes.\n-     */\n-    private void assembleKmerGraphsAndHaplotypeCall(final Haplotype refHaplotype, final SimpleInterval refLoc, final SAMFileHeader header,\n-                                                    final SmithWatermanAligner aligner, final List<GATKRead> correctedReads,\n-                                                    final List<SeqGraph> nonRefSeqGraphs, final AssemblyResultSet resultSet,\n-                                                    final SimpleInterval activeRegionExtendedLocation) {\n+        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n         final Map<SeqGraph,AssemblyResult> assemblyResultBySeqGraph = new HashMap<>();\n         // create the graphs by calling our subclass assemble method\n         for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, header, aligner) ) {\n             if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {\n                 // do some QC on the graph\n-                sanityCheckGraph(result.getSeqGraph(), refHaplotype);\n-                // add it to graphs with meaningful non-reference features\n-                assemblyResultBySeqGraph.put(result.getSeqGraph(),result);\n-                nonRefSeqGraphs.add(result.getSeqGraph());\n+                if (generateSeqGraph) {\n+                    sanityCheckGraph(result.getSeqGraph(), refHaplotype);\n+                    // add it to graphs with meaningful non-reference features\n+                    assemblyResultBySeqGraph.put(result.getSeqGraph(),result);\n+                    nonRefSeqGraphs.add(result.getSeqGraph());\n+                } else {\n+                    sanityCheckGraph(result.getThreadingGraph(), refHaplotype);\n+                    result.getThreadingGraph().postProcessForHaplotypeFinding(debugGraphOutputPath, refHaplotype.getLocation());\n+                    // add it to graphs with meaningful non-reference features\n+                    assemblyResultByRTGraph.put(result.getThreadingGraph(),result);\n+                    nonRefRTGraphs.add(result.getThreadingGraph());\n+                }\n \n                 if (graphHaplotypeHistogramPath != null) {\n                     kmersUsedHistogram.add((double)result.getKmerSize());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM1MDQwMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370350402", "bodyText": "How about for savedAssemblyResult : Lists.reverse(savedAssemblyResults), which iterates over a reversing wrapper of the list?", "author": "davidbenjamin", "createdAt": "2020-01-23T20:57:48Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -168,56 +194,147 @@ public AssemblyResultSet runLocalAssembly(final AssemblyRegion assemblyRegion,\n         }\n \n         // add assembled alt haplotypes to the {@code resultSet}\n-        if (generateSeqGraph) {\n-            findBestPaths(nonRefSeqGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultBySeqGraph, resultSet, aligner);\n-        } else {\n-            findBestPaths(nonRefRTGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByRTGraph, resultSet, aligner);\n+        findBestPaths(nonRefSeqGraphs, assemblyResultBySeqGraph, refHaplotype, refLoc, activeRegionExtendedLocation, resultSet, aligner);\n+    }\n+\n+    /**\n+     * Follow the kmer expansion heurisics as {@link #assemble(List, Haplotype, SAMFileHeader, SmithWatermanAligner)}, but in this case\n+     * attempt to recover haplotypes from the kmer graph and use them to assess whether to expand the kmer size.\n+     */\n+    private void assembleGraphsAndExpandKmersGivenHaplotypes(final Haplotype refHaplotype, final SimpleInterval refLoc, final SAMFileHeader header,\n+                                                             final SmithWatermanAligner aligner, final List<GATKRead> correctedReads,\n+                                                             final List<AbstractReadThreadingGraph> nonRefRTGraphs, final AssemblyResultSet resultSet,\n+                                                             final SimpleInterval activeRegionExtendedLocation) {\n+        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n+        // create the graphs by calling our subclass assemble method\n+\n+        final List<AssemblyResult> savedAssemblyResults = new ArrayList<>();\n+\n+        boolean hasAdequatelyAssembledGraph = false;\n+        List<Integer> kmersToTry = getExpandedKmerList();\n+        // first, try using the requested kmer sizes\n+        for ( int i = 0; i < kmersToTry.size(); i++ ) {\n+            final int kmerSize = kmersToTry.get(i);\n+            final boolean isLastCycle = i == kmersToTry.size() - 1;\n+            if (!hasAdequatelyAssembledGraph) {\n+                AssemblyResult assembledResult = createGraph(correctedReads, refHaplotype, kmerSize, isLastCycle || dontIncreaseKmerSizesForCycles, isLastCycle || allowNonUniqueKmersInRef, header, aligner);\n+                if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION) {\n+                    // do some QC on the graph\n+                    sanityCheckGraph(assembledResult.getThreadingGraph(), refHaplotype);\n+                    assembledResult.getThreadingGraph().postProcessForHaplotypeFinding(debugGraphOutputPath, refHaplotype.getLocation());\n+                    // add it to graphs with meaningful non-reference features\n+                    assemblyResultByRTGraph.put(assembledResult.getThreadingGraph(), assembledResult);\n+                    nonRefRTGraphs.add(assembledResult.getThreadingGraph());\n+\n+                    if (graphHaplotypeHistogramPath != null) {\n+                        kmersUsedHistogram.add((double) assembledResult.getKmerSize());\n+                    }\n+\n+                    AbstractReadThreadingGraph graph = assembledResult.getThreadingGraph();\n+                    findBestPaths(Collections.singletonList(graph), Collections.singletonMap(graph, assembledResult),\n+                            refHaplotype, refLoc, activeRegionExtendedLocation, null, aligner);\n+\n+                    savedAssemblyResults.add(assembledResult);\n+\n+                    //TODO LOGIC PLAN HERE - we want to check if we have a trustworthy graph (i.e. no badly assembled haplotypes) if we do, emit it.\n+                    //TODO                 - but if we failed to assemble due to excessive looping or did have badly assembled haplotypes then we expand kmer size.\n+                    //TODO                 - If we get no variation\n+\n+                    // if asssembly didn't fail ( which is a degenerate case that occurs for some subset of graphs with difficult loops)\n+                    if (! savedAssemblyResults.get(savedAssemblyResults.size() - 1).getHaplotypeList().isEmpty()) {\n+                        // we have found our workable kmer size so lets add the results and finish\n+                        if (!assembledResult.isContainsSuspectHaplotypes()) {\n+                            for (Haplotype h : assembledResult.getHaplotypeList()) {\n+                                resultSet.add(h, assembledResult);\n+                            }\n+                            hasAdequatelyAssembledGraph = true;\n+                        }\n+                    }\n+\n+                // if no variation is discoverd in the graph don't bother expanding the kmer size.\n+                } else if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.JUST_ASSEMBLED_REFERENCE) {\n+                    hasAdequatelyAssembledGraph = true;\n+                }\n+            }\n         }\n \n-        // print the graphs if the appropriate debug option has been turned on\n-        if ( graphOutputPath != null ) { printGraphs(nonRefSeqGraphs); }\n-        if ( graphHaplotypeHistogramPath != null ) { haplotypeHistogram.add((double)resultSet.getHaplotypeCount()); }\n \n-        return resultSet;\n+        // This indicates that we have thrown everything away... we should go back and check that we weren't too conservative about assembly results that might otherwise be good\n+        if (!hasAdequatelyAssembledGraph) {\n+            // search for the last haplotype set that had any results, if none are found just return me\n+            // In this case we prefer the last meaningful kmer size if possible\n+            for (int i = savedAssemblyResults.size() - 1; i > 0; i --) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\nindex a0f4aba58..83a8d59d1 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java\n\n@@ -194,147 +169,56 @@ public final class ReadThreadingAssembler {\n         }\n \n         // add assembled alt haplotypes to the {@code resultSet}\n-        findBestPaths(nonRefSeqGraphs, assemblyResultBySeqGraph, refHaplotype, refLoc, activeRegionExtendedLocation, resultSet, aligner);\n-    }\n-\n-    /**\n-     * Follow the kmer expansion heurisics as {@link #assemble(List, Haplotype, SAMFileHeader, SmithWatermanAligner)}, but in this case\n-     * attempt to recover haplotypes from the kmer graph and use them to assess whether to expand the kmer size.\n-     */\n-    private void assembleGraphsAndExpandKmersGivenHaplotypes(final Haplotype refHaplotype, final SimpleInterval refLoc, final SAMFileHeader header,\n-                                                             final SmithWatermanAligner aligner, final List<GATKRead> correctedReads,\n-                                                             final List<AbstractReadThreadingGraph> nonRefRTGraphs, final AssemblyResultSet resultSet,\n-                                                             final SimpleInterval activeRegionExtendedLocation) {\n-        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n-        // create the graphs by calling our subclass assemble method\n-\n-        final List<AssemblyResult> savedAssemblyResults = new ArrayList<>();\n-\n-        boolean hasAdequatelyAssembledGraph = false;\n-        List<Integer> kmersToTry = getExpandedKmerList();\n-        // first, try using the requested kmer sizes\n-        for ( int i = 0; i < kmersToTry.size(); i++ ) {\n-            final int kmerSize = kmersToTry.get(i);\n-            final boolean isLastCycle = i == kmersToTry.size() - 1;\n-            if (!hasAdequatelyAssembledGraph) {\n-                AssemblyResult assembledResult = createGraph(correctedReads, refHaplotype, kmerSize, isLastCycle || dontIncreaseKmerSizesForCycles, isLastCycle || allowNonUniqueKmersInRef, header, aligner);\n-                if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION) {\n-                    // do some QC on the graph\n-                    sanityCheckGraph(assembledResult.getThreadingGraph(), refHaplotype);\n-                    assembledResult.getThreadingGraph().postProcessForHaplotypeFinding(debugGraphOutputPath, refHaplotype.getLocation());\n-                    // add it to graphs with meaningful non-reference features\n-                    assemblyResultByRTGraph.put(assembledResult.getThreadingGraph(), assembledResult);\n-                    nonRefRTGraphs.add(assembledResult.getThreadingGraph());\n-\n-                    if (graphHaplotypeHistogramPath != null) {\n-                        kmersUsedHistogram.add((double) assembledResult.getKmerSize());\n-                    }\n-\n-                    AbstractReadThreadingGraph graph = assembledResult.getThreadingGraph();\n-                    findBestPaths(Collections.singletonList(graph), Collections.singletonMap(graph, assembledResult),\n-                            refHaplotype, refLoc, activeRegionExtendedLocation, null, aligner);\n-\n-                    savedAssemblyResults.add(assembledResult);\n-\n-                    //TODO LOGIC PLAN HERE - we want to check if we have a trustworthy graph (i.e. no badly assembled haplotypes) if we do, emit it.\n-                    //TODO                 - but if we failed to assemble due to excessive looping or did have badly assembled haplotypes then we expand kmer size.\n-                    //TODO                 - If we get no variation\n-\n-                    // if asssembly didn't fail ( which is a degenerate case that occurs for some subset of graphs with difficult loops)\n-                    if (! savedAssemblyResults.get(savedAssemblyResults.size() - 1).getHaplotypeList().isEmpty()) {\n-                        // we have found our workable kmer size so lets add the results and finish\n-                        if (!assembledResult.isContainsSuspectHaplotypes()) {\n-                            for (Haplotype h : assembledResult.getHaplotypeList()) {\n-                                resultSet.add(h, assembledResult);\n-                            }\n-                            hasAdequatelyAssembledGraph = true;\n-                        }\n-                    }\n-\n-                // if no variation is discoverd in the graph don't bother expanding the kmer size.\n-                } else if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.JUST_ASSEMBLED_REFERENCE) {\n-                    hasAdequatelyAssembledGraph = true;\n-                }\n-            }\n+        if (generateSeqGraph) {\n+            findBestPaths(nonRefSeqGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultBySeqGraph, resultSet, aligner);\n+        } else {\n+            findBestPaths(nonRefRTGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByRTGraph, resultSet, aligner);\n         }\n \n+        // print the graphs if the appropriate debug option has been turned on\n+        if ( graphOutputPath != null ) { printGraphs(nonRefSeqGraphs); }\n+        if ( graphHaplotypeHistogramPath != null ) { haplotypeHistogram.add((double)resultSet.getHaplotypeCount()); }\n \n-        // This indicates that we have thrown everything away... we should go back and check that we weren't too conservative about assembly results that might otherwise be good\n-        if (!hasAdequatelyAssembledGraph) {\n-            // search for the last haplotype set that had any results, if none are found just return me\n-            // In this case we prefer the last meaningful kmer size if possible\n-            for (int i = savedAssemblyResults.size() - 1; i > 0; i --) {\n-                if (savedAssemblyResults.get(i).getHaplotypeList().size() > 1) {\n-                    for (Haplotype h : savedAssemblyResults.get(i).getHaplotypeList()) {\n-                        resultSet.add(h, savedAssemblyResults.get(i));\n-                    }\n-                    break;\n-                }\n-            }\n-        }\n+        return resultSet;\n     }\n \n-    /**\n-     * Find discover paths by using KBestHaplotypeFinder over each graph.\n-     *\n-     * This method has the side effect that it will annotate all of the AssemblyResults objects with the derived haplotypes\n-     * which can be used for basing kmer graph pruning on the discovered haplotypes.\n-     *\n-     * @param graphs                graphs to be used for kmer detection\n-     * @param assemblyResultByGraph assembly results objects keyed by graphs used to construct them\n-     * @param refHaplotype          reference haplotype\n-     * @param refLoc                location of reference haplotype\n-     * @param activeRegionWindow    window of the active region (without padding)\n-     * @param resultSet             (can be null) the results set into which to deposit discovered haplotypes\n-     * @param aligner               SmithWaterman aligner to use for aligning the discovered haplotype to the reference haplotype\n-     * @return A list of discovered haplotyes (note that this is not currently used for anything)\n-     */\n-    @SuppressWarnings({\"unchecked\"})\n     private <V extends  BaseVertex, E extends BaseEdge, T extends BaseGraph<V, E>>\n-    List<Haplotype> findBestPaths(final Collection<T> graphs, final Map<T, AssemblyResult> assemblyResultByGraph,\n-                                  final Haplotype refHaplotype, final SimpleInterval refLoc, final SimpleInterval activeRegionWindow,\n-                                  final AssemblyResultSet resultSet, final SmithWatermanAligner aligner) {\n+    List<Haplotype> findBestPaths(final Collection<T> graphs, final Haplotype refHaplotype, final SimpleInterval refLoc, final SimpleInterval activeRegionWindow,\n+                                          final Map<T, AssemblyResult> assemblyResultByGraph, final AssemblyResultSet assemblyResultSet, final SmithWatermanAligner aligner) {\n         // add the reference haplotype separately from all the others to ensure that it is present in the list of haplotypes\n         final Set<Haplotype> returnHaplotypes = new LinkedHashSet<>();\n \n         final int activeRegionStart = refHaplotype.getAlignmentStartHapwrtRef();\n         int failedCigars = 0;\n \n-        // Validate that the graph is valid with extant source and sink before operating\n         for( final BaseGraph<V, E> graph : graphs ) {\n-            final AssemblyResult assemblyResult = assemblyResultByGraph.get(graph);\n             final V source = graph.getReferenceSourceVertex();\n             final V sink = graph.getReferenceSinkVertex();\n-            Utils.validateArg(source != null && sink != null, () -> \"Both source and sink cannot be null but got \" + source + \" and sink \" + sink + \" for graph \" + graph);\n+            Utils.validateArg( source != null && sink != null, () -> \"Both source and sink cannot be null but got \" + source + \" and sink \" + sink + \" for graph \" + graph);\n \n             for (final KBestHaplotype<V, E> kBestHaplotype :\n                     (generateSeqGraph ?\n-                            new GraphBasedKBestHaplotypeFinder<>(graph, source, sink) :\n-                            new JunctionTreeKBestHaplotypeFinder<>(graph, source, sink, JunctionTreeKBestHaplotypeFinder.DEFAULT_OUTGOING_JT_EVIDENCE_THRESHOLD_TO_BELEIVE, recoverHaplotypesFromEdgesNotCoveredInJunctionTrees))\n+                            new GraphBasedKBestHaplotypeFinder<>(graph,source,sink) :\n+                            new JunctionTreeKBestHaplotypeFinder<>(graph,source,sink, JunctionTreeKBestHaplotypeFinder.DEFAULT_OUTGOING_JT_EVIDENCE_THRESHOLD_TO_BELEIVE))\n                             .findBestHaplotypes(numBestHaplotypesPerGraph)) {\n-                // TODO for now this seems like the solution, perhaps in the future it will be to excise the haplotype completely)\n-                if (kBestHaplotype instanceof JTBestHaplotype && ((JTBestHaplotype<V, E>) kBestHaplotype).isWasPoorlyRecovered()) {\n-                    assemblyResult.setContainsSuspectHaplotypes(true);\n-                }\n                 final Haplotype h = kBestHaplotype.haplotype();\n-\n-                if (!returnHaplotypes.contains(h)) {\n+                if( !returnHaplotypes.contains(h) ) {\n                     // TODO this score seems to be irrelevant at this point...\n                     if (kBestHaplotype.isReference()) {\n                         refHaplotype.setScore(kBestHaplotype.score());\n                     }\n                     final Cigar cigar = CigarUtils.calculateCigar(refHaplotype.getBases(), h.getBases(), aligner, SWOverhangStrategy.SOFTCLIP);\n \n-                    if (cigar == null) {\n+                    if ( cigar == null ) {\n                         failedCigars++; // couldn't produce a meaningful alignment of haplotype to reference, fail quietly\n                         continue;\n-                    } else if (cigar.isEmpty()) {\n+                    } else if( cigar.isEmpty() ) {\n                         throw new IllegalStateException(\"Smith-Waterman alignment failure. Cigar = \" + cigar + \" with reference length \" + cigar.getReferenceLength() +\n                                 \" but expecting reference length of \" + refHaplotype.getCigar().getReferenceLength());\n-                    } else if (pathIsTooDivergentFromReference(cigar) || cigar.getReferenceLength() < MIN_HAPLOTYPE_REFERENCE_LENGTH) {\n+                    } else if ( pathIsTooDivergentFromReference(cigar) || cigar.getReferenceLength() < MIN_HAPLOTYPE_REFERENCE_LENGTH ) {\n                         // N cigar elements means that a bubble was too divergent from the reference so skip over this path\n                         continue;\n-                    } else if (cigar.getReferenceLength() != refHaplotype.getCigar().getReferenceLength()) { // SW failure\n+                    } else if( cigar.getReferenceLength() != refHaplotype.getCigar().getReferenceLength() ) { // SW failure\n                         throw new IllegalStateException(\"Smith-Waterman alignment failure. Cigar = \" + cigar + \" with reference length \"\n                                 + cigar.getReferenceLength() + \" but expecting reference length of \" + refHaplotype.getCigar().getReferenceLength()\n                                 + \" ref = \" + refHaplotype + \" path \" + new String(h.getBases()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMzMDk2Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375330967", "bodyText": "For consistency this should be LINKED_DE_BRUJN_GRAPH_LONG_NAME", "author": "davidbenjamin", "createdAt": "2020-02-05T15:36:48Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -23,6 +23,7 @@\n     public static final String CAPTURE_ASSEMBLY_FAILURE_BAM_LONG_NAME = \"capture-assembly-failure-bam\";\n     public static final String KMER_SIZE_LONG_NAME = \"kmer-size\";\n     public static final String DONT_INCREASE_KMER_SIZE_LONG_NAME = \"dont-increase-kmer-sizes-for-cycles\";\n+    public static final String LINKED_DE_BRUIJN_GRAPH_ARGUMENT = \"linked-de-bruijn-graph\";", "originalCommit": "9d2497935fc8251c8ba864dbd64ec010d77ce6fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\nindex c3acd2337..a26578a5c 100644\n--- a/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n+++ b/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java\n\n@@ -23,35 +24,6 @@ public abstract class ReadThreadingAssemblerArgumentCollection implements Serial\n     public static final String CAPTURE_ASSEMBLY_FAILURE_BAM_LONG_NAME = \"capture-assembly-failure-bam\";\n     public static final String KMER_SIZE_LONG_NAME = \"kmer-size\";\n     public static final String DONT_INCREASE_KMER_SIZE_LONG_NAME = \"dont-increase-kmer-sizes-for-cycles\";\n-    public static final String LINKED_DE_BRUIJN_GRAPH_ARGUMENT = \"linked-de-bruijn-graph\";\n-\n-\n-    //---------------------------------------------------------------------------------------------------------------\n-    //\n-    // Assembly Region Trimming Parameters\n-    //\n-    // ---------------------------------------------------------------------------------------------------------------\n-    @Advanced\n-    @Argument(fullName=\"dont-trim-active-regions\", doc=\"If specified, we will not trim down the active region from the full region (active + extension) to just the active interval for genotyping\", optional = true)\n-    protected boolean dontTrimActiveRegions = false;\n-\n-    /**\n-     * the maximum extent into the full active region extension that we're willing to go in genotyping our events\n-     */\n-    @Hidden\n-    @Argument(fullName=\"max-extension\", doc = \"the maximum extent into the full active region extension that we're willing to go in genotyping\", optional = true)\n-    protected int extension = 25;\n-\n-    /**\n-     * Include at least this many bases around an event for calling it\n-     */\n-    @Hidden\n-    @Argument(fullName=\"padding-around-indels\", doc = \"Include at least this many bases around an event for calling indels\", optional = true)\n-    public int indelPadding = 150;\n-\n-    @Hidden\n-    @Argument(fullName=\"padding-around-snps\", doc = \"Include at least this many bases around an event for calling snps\", optional = true)\n-    public int snpPadding = 20;\n \n     // -----------------------------------------------------------------------------------------------\n     // arguments to control internal behavior of the read threading assembler\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMzNDQ1Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375334452", "bodyText": "typo: Junciton", "author": "davidbenjamin", "createdAt": "2020-02-05T15:42:08Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -585,6 +584,35 @@ public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistency\n         Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n     }\n \n+    @Test\n+    // test asserting that we don't make spurious edges when we are trying to recover error bases\n+    public void testJuncitonTreeErrorCorrectionNotAddingTreesWhenOverTentativeBases() {", "originalCommit": "9d2497935fc8251c8ba864dbd64ec010d77ce6fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dac52340c334a2feab53a1ab7d13148aea88fb05", "chunk": "diff --git a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\nindex 2000497cb..8abb30eca 100644\n--- a/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n+++ b/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java\n\n@@ -484,135 +485,6 @@ public class JunctionTreeLinkedDeBruinGraphUnitTest extends BaseTest {\n         Assert.assertNotNull(startAlt);\n     }\n \n-    @Test\n-    public void testJunctionTreeErrorCorrection() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrectionUnrecoverableWithInsertion() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    public void testJunctionTreeErrorCorrectionKmerSizeDistanceAllowance() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n-    }\n-\n-    @Test\n-    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-        // This path has two unsupported edges which should be pruned, however they are less than a kmer size apart and should result in the path being unable to find\n-        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n-        // Only provide a single instance of the path so that its middle C variant gets pruned\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        Assert.assertEquals(bestPaths.size(),1);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n-    }\n-\n-    @Test\n-    // test asserting that we don't make spurious edges when we are trying to recover error bases\n-    public void testJuncitonTreeErrorCorrectionNotAddingTreesWhenOverTentativeBases() {\n-        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n-        final String ref             = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTGG\"+\"A\"+\"GGG\"+\"C\"+\"GTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTGG\"+\"C\"+\"GGG\"+\"C\"+\"GTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n-\n-        // This path shold be pruned, but if we aren't careful might end up pairing the first SNP with the middle SNP at this site\n-        final String unSupportedAltWithError = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"C\"+\"TTGG\"+\"C\"+\"GGG\"+\"A\"+\"GTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n-        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n-        assembler.addSequence(\"anonymous\", getBytes(ref), false);\n-        assembler.addSequence(\"anonymous\", getBytes(ref), false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt),  false);\n-        assembler.addSequence(\"anonymous\", getBytes(supportedAlt),  false);\n-        assembler.addSequence(\"anonymous\", getBytes(unSupportedAltWithError), 1, false);\n-        assembler.buildGraphIfNecessary();\n-        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n-        assembler.generateJunctionTrees();\n-\n-        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n-                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).setJunctionTreeEvidenceWeightThreshold(1).findBestHaplotypes(10);\n-\n-        // We only see the supported alt path because the unsupported alt path is never recovered\n-        // If we saw 3 that means the undersupported pruned path ended up in the junciton trees and created a path that shouldn't be there\n-        Assert.assertEquals(bestPaths.size(),2);\n-        Assert.assertEquals(new String(bestPaths.get(0).getBases()), ref);\n-        Assert.assertEquals(new String(bestPaths.get(1).getBases()), supportedAlt);\n-    }\n-\n     @Test(enabled = ! DEBUG)\n     public void testNonUniqueMiddle() {\n         final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(3);\n"}}, {"oid": "dac52340c334a2feab53a1ab7d13148aea88fb05", "url": "https://github.com/broadinstitute/gatk/commit/dac52340c334a2feab53a1ab7d13148aea88fb05", "message": "resolved conflicts between old and new branches", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "814d7da49dfa0d7dfb2b90e62d91477ae1b47402", "url": "https://github.com/broadinstitute/gatk/commit/814d7da49dfa0d7dfb2b90e62d91477ae1b47402", "message": "First attempt at recovering paths that have been dropped by the graphing code based on painting covered edges and recovering them later", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "4908314e8b24b8d9c3deda2ce3b7313c8536306c", "url": "https://github.com/broadinstitute/gatk/commit/4908314e8b24b8d9c3deda2ce3b7313c8536306c", "message": "removed pruning and removed 10mer for arguments sake", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "923366894ed052eaa5513c97cc2a0a75523579d2", "url": "https://github.com/broadinstitute/gatk/commit/923366894ed052eaa5513c97cc2a0a75523579d2", "message": "tmp", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "cc04b5f0f80f66ec2079a254c79dabf43a59008c", "url": "https://github.com/broadinstitute/gatk/commit/cc04b5f0f80f66ec2079a254c79dabf43a59008c", "message": "still an inadequate ammount of stuff done, how to filter out sites?", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "1f0ae1125c905ed45f37cf71350b298774c4807a", "url": "https://github.com/broadinstitute/gatk/commit/1f0ae1125c905ed45f37cf71350b298774c4807a", "message": "working on implementaiotn", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "23fe827463ae863e282e59440a0c54180a8948fd", "url": "https://github.com/broadinstitute/gatk/commit/23fe827463ae863e282e59440a0c54180a8948fd", "message": "lets see where this wild ride takes us, now the graphs are expanded based on the haplotype recovered result", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "aeb4bd23e10e2fcdb47e030b9a146a66739976bb", "url": "https://github.com/broadinstitute/gatk/commit/aeb4bd23e10e2fcdb47e030b9a146a66739976bb", "message": "merged the two branches so hopefully both the expansion heuristics and the front pasting are accounted for", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "196e531bf4eec58e38d9cdf725f8c833a631041b", "url": "https://github.com/broadinstitute/gatk/commit/196e531bf4eec58e38d9cdf725f8c833a631041b", "message": "attempt at synthesis where the old restriction rules have been done away with", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "3ab244c4d5480d0a2ed973f03ce0c64675faa7a6", "url": "https://github.com/broadinstitute/gatk/commit/3ab244c4d5480d0a2ed973f03ce0c64675faa7a6", "message": "fixed a horrible issue that would cause null pointers on real data", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "7b02e46c936882c7a1ce5bd9e95269fd86506912", "url": "https://github.com/broadinstitute/gatk/commit/7b02e46c936882c7a1ce5bd9e95269fd86506912", "message": "some cleanup and the first steps towrads disqualifying potentially badly looping paths", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "360157f56f99217296be1d3c9739ddb9a59619cd", "url": "https://github.com/broadinstitute/gatk/commit/360157f56f99217296be1d3c9739ddb9a59619cd", "message": "apparently working but possibly not who knows", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "655227c372a743f3bb6fe9a5ffd5f81fe287fd1f", "url": "https://github.com/broadinstitute/gatk/commit/655227c372a743f3bb6fe9a5ffd5f81fe287fd1f", "message": "added ErrorAcceptingTHreadingWork", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "1103ff101120b859891b6f214066796e57c42ceb", "url": "https://github.com/broadinstitute/gatk/commit/1103ff101120b859891b6f214066796e57c42ceb", "message": "removing 10mers", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "05266ec2cf882bb1388da6081a081626dd91e7a0", "url": "https://github.com/broadinstitute/gatk/commit/05266ec2cf882bb1388da6081a081626dd91e7a0", "message": "fixed the jt error correciton code and added tests", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "bf3cfaf5a13ec4de814c30524e3394b1e61d610d", "url": "https://github.com/broadinstitute/gatk/commit/bf3cfaf5a13ec4de814c30524e3394b1e61d610d", "message": "Fixxed the issue with 85mers not being properly treated if there was reference variance out to that size", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "02e6aa7fa981c88746a50685fd01fa00720f6455", "url": "https://github.com/broadinstitute/gatk/commit/02e6aa7fa981c88746a50685fd01fa00720f6455", "message": "Refactored ReadThreadingAssembler to handle both JunctionTrees and SeqGraphs without reusing too much code", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "b9a323e6c1577347092bcdc43fb8096ddc97292f", "url": "https://github.com/broadinstitute/gatk/commit/b9a323e6c1577347092bcdc43fb8096ddc97292f", "message": "turning back off the regeneration code", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "b8f2941668b8d1105c95518c185573f93d1284cf", "url": "https://github.com/broadinstitute/gatk/commit/b8f2941668b8d1105c95518c185573f93d1284cf", "message": "refactored and cleaned up the threading code. There could probably be a few more tests of the haplotype recovery but lets kick this to the reviewer", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "756522bea219e2d79cd25e9d6e18db47c3e7dc9b", "url": "https://github.com/broadinstitute/gatk/commit/756522bea219e2d79cd25e9d6e18db47c3e7dc9b", "message": "responded to the first round of comments", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "6999063a12a07648b971fe3d49ffdc6c28805e0d", "url": "https://github.com/broadinstitute/gatk/commit/6999063a12a07648b971fe3d49ffdc6c28805e0d", "message": "defensive OBOB", "committedDate": "2020-02-05T18:48:43Z", "type": "commit"}, {"oid": "f266f2e23e6091fec684af75ed9985002afde3da", "url": "https://github.com/broadinstitute/gatk/commit/f266f2e23e6091fec684af75ed9985002afde3da", "message": "responding to revdiew comments again", "committedDate": "2020-02-05T18:48:43Z", "type": "commit"}, {"oid": "55ca10377437cc488465c88481edad8c7191b6fc", "url": "https://github.com/broadinstitute/gatk/commit/55ca10377437cc488465c88481edad8c7191b6fc", "message": "updating the expected output to reflect the changes from the rebase", "committedDate": "2020-02-05T19:04:44Z", "type": "commit"}, {"oid": "55ca10377437cc488465c88481edad8c7191b6fc", "url": "https://github.com/broadinstitute/gatk/commit/55ca10377437cc488465c88481edad8c7191b6fc", "message": "updating the expected output to reflect the changes from the rebase", "committedDate": "2020-02-05T19:04:44Z", "type": "forcePushed"}]}