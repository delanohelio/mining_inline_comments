{"pr_number": 2168, "pr_title": "HBASE-24695 FSHLog - close the current WAL file in a background thread.", "pr_createdAt": "2020-07-29T07:27:04Z", "pr_url": "https://github.com/apache/hbase/pull/2168", "timeline": [{"oid": "5b6517641c048dfc93fbf6de6b86a34981aed1a6", "url": "https://github.com/apache/hbase/commit/5b6517641c048dfc93fbf6de6b86a34981aed1a6", "message": "HBASE-24695 FSHLog - close the current WAL file in a background thread.", "committedDate": "2020-07-29T07:26:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MTA2Ng==", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462191066", "bodyText": "May be we can replace with that {} method of logging where we have the placeholders?", "author": "ramkrish86", "createdAt": "2020-07-29T10:13:13Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -436,6 +464,19 @@ protected void doShutdown() throws IOException {\n       this.writer.close();\n       this.writer = null;\n     }\n+    closeExecutor.shutdown();\n+    try {\n+      if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {\n+        LOG.error(\"We have waited \" + waitOnShutdownInSeconds + \" seconds but\"", "originalCommit": "5b6517641c048dfc93fbf6de6b86a34981aed1a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIzMTQzNw==", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462231437", "bodyText": "done", "author": "anoopsjohn", "createdAt": "2020-07-29T11:33:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MTA2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "a050b4877a33351f63ab567b2a9918da6ddfa2b5", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex 58931122a7..276902e4de 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n\n@@ -467,11 +468,10 @@ public class FSHLog extends AbstractFSWAL<Writer> {\n     closeExecutor.shutdown();\n     try {\n       if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {\n-        LOG.error(\"We have waited \" + waitOnShutdownInSeconds + \" seconds but\"\n-            + \" the close of writer(s) doesn't complete.\"\n+        LOG.error(\"We have waited {} seconds but the close of writer(s) doesn't complete.\"\n             + \"Please check the status of underlying filesystem\"\n-            + \" or increase the wait time by the config \\\"\" + FSHLOG_WAIT_ON_SHUTDOWN_IN_SECONDS\n-            + \"\\\"\");\n+            + \" or increase the wait time by the config \\\"{}\\\"\", this.waitOnShutdownInSeconds,\n+            FSHLOG_WAIT_ON_SHUTDOWN_IN_SECONDS);\n       }\n     } catch (InterruptedException e) {\n       LOG.error(\"The wait for termination of FSHLog writer(s) is interrupted\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA==", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462192010", "bodyText": "confirming once again with hasFlushedEntries when syncCloseCall is it mandatory or just to be on the safe side? Because even if hasUnFlushedEntries is false here i think errors would have crossed the limit anyway because we increment and then check it.\nRest LGTM. Can check the QA once. May be you may have to change some cluster based test to run with FSHLog as the default may be AsyncWAL.", "author": "ramkrish86", "createdAt": "2020-07-29T10:15:01Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "diffHunk": "@@ -412,6 +422,24 @@ protected void doReplaceWriter(Path oldPath, Path newPath, Writer nextWriter) th\n     }\n   }\n \n+  private void closeWriter(Path path, boolean syncCloseCall) throws IOException {\n+    try {\n+      TraceUtil.addTimelineAnnotation(\"closing writer\");\n+      writer.close();\n+      TraceUtil.addTimelineAnnotation(\"writer closed\");\n+    } catch (IOException ioe) {\n+      int errors = closeErrorCount.incrementAndGet();\n+      boolean hasUnflushedEntries = isUnflushedEntries();\n+      if (syncCloseCall && (hasUnflushedEntries || (errors > this.closeErrorsTolerated))) {", "originalCommit": "5b6517641c048dfc93fbf6de6b86a34981aed1a6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjIxNTI1Mg==", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462215252", "bodyText": "Ideally when we writer close, there wont be any unflushed entries. We have synced all writes happend to this wal writer.  But as the code was having it and to be on safe side, continue to use that.  Ya in that case will go with sync way of call so that we can act against and IOE in close call.  Same with that errors count. If consecutively those many failures, we will have to throw IOE and RS will abort.  But here one catch is there.  This #errors based abort wont be that strict from now on.  Say if the errors tolerated is 1, we need to throw back IOE if errors count is 2.  But it is possible that one close req came and given to a thread and before that is done another close req and given to another thread and then a 3rd close req came by then 1st thread is done and it was failed. So the 3rd req will be tried in sync way of close. By the time it finishes, the 2nd close thread also failed to close. So the errors already became 2 and 3d  (sync way call) also failed which makes the count to 3.  So instead of throw back IOE at errors=2, it will do now on errors=3.  But we are sure all edits are synced and no data loss. So I believe this is ok.. Asycn wal is not having any such logic at all.", "author": "anoopsjohn", "createdAt": "2020-07-29T11:00:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjcyMDczNw==", "url": "https://github.com/apache/hbase/pull/2168#discussion_r462720737", "bodyText": "That is right. It is not a harm to check again. Am just saying that since the first sync based close was checking for >= it means either it has already reached the max count or already greater. And next time when we do throw the IOE we check it  after increment. Reg AsyncWAL i just said if tests are running with AsyncWAL this code path may never get executed. So should you go and change the WAL type for test cases to execute this flow?", "author": "ramkrish86", "createdAt": "2020-07-30T04:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjE5MjAxMA=="}], "type": "inlineReview", "revised_code": {"commit": "44e11fb58d2cb608b04699da176ba3c66f1907f2", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex 58931122a7..5efc002853 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n\n@@ -422,7 +423,7 @@ public class FSHLog extends AbstractFSWAL<Writer> {\n     }\n   }\n \n-  private void closeWriter(Path path, boolean syncCloseCall) throws IOException {\n+  private void closeWriter(Writer writer, Path path, boolean syncCloseCall) throws IOException {\n     try {\n       TraceUtil.addTimelineAnnotation(\"closing writer\");\n       writer.close();\n"}}, {"oid": "44e11fb58d2cb608b04699da176ba3c66f1907f2", "url": "https://github.com/apache/hbase/commit/44e11fb58d2cb608b04699da176ba3c66f1907f2", "message": "HBASE-24695 FSHLog - close the current WAL file in a background thread.", "committedDate": "2020-07-29T11:15:24Z", "type": "commit"}, {"oid": "a050b4877a33351f63ab567b2a9918da6ddfa2b5", "url": "https://github.com/apache/hbase/commit/a050b4877a33351f63ab567b2a9918da6ddfa2b5", "message": "HBASE-24695 FSHLog - close the current WAL file in a background thread.", "committedDate": "2020-07-29T11:32:23Z", "type": "commit"}]}