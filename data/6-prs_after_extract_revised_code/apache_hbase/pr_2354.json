{"pr_number": 2354, "pr_title": "HBASE-24986 Move ReplicationBarrier related methods to a separated class", "pr_createdAt": "2020-09-07T03:59:18Z", "pr_url": "https://github.com/apache/hbase/pull/2354", "timeline": [{"oid": "d1c1e6c173d7b8270deea84f503d03a418651749", "url": "https://github.com/apache/hbase/commit/d1c1e6c173d7b8270deea84f503d03a418651749", "message": "HBASE-24986 Move ReplicationBarrier related methods to a separated class", "committedDate": "2020-09-07T03:57:48Z", "type": "commit"}, {"oid": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a", "url": "https://github.com/apache/hbase/commit/7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a", "message": "fix checkstyle issues", "committedDate": "2020-09-07T06:06:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzNzM1MQ==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484237351", "bodyText": "Minor suggestion. Can reduce one line code. :-)\nfor (Cell cell : cells) {\nif (isMergeQualifierPrefix(cell)) {\nreturn true;\n}\n}\nreturn false;", "author": "infraio", "createdAt": "2020-09-07T07:36:37Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java", "diffHunk": "@@ -346,4 +347,64 @@ public static TableState getTableState(Result r) throws IOException {\n       throw new IOException(e);\n     }\n   }\n+\n+  /**\n+   * @return Deserialized values of &lt;qualifier,regioninfo&gt; pairs taken from column values that\n+   *         match the regex 'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static Map<String, RegionInfo> getMergeRegionsWithName(Cell[] cells) {\n+    if (cells == null) {\n+      return null;\n+    }\n+    Map<String, RegionInfo> regionsToMerge = null;\n+    for (Cell cell : cells) {\n+      if (!isMergeQualifierPrefix(cell)) {\n+        continue;\n+      }\n+      // Ok. This cell is that of a info:merge* column.\n+      RegionInfo ri = RegionInfo.parseFromOrNull(cell.getValueArray(), cell.getValueOffset(),\n+        cell.getValueLength());\n+      if (ri != null) {\n+        if (regionsToMerge == null) {\n+          regionsToMerge = new LinkedHashMap<>();\n+        }\n+        regionsToMerge.put(Bytes.toString(CellUtil.cloneQualifier(cell)), ri);\n+      }\n+    }\n+    return regionsToMerge;\n+  }\n+\n+  /**\n+   * @return Deserialized regioninfo values taken from column values that match the regex\n+   *         'info:merge.*' in array of <code>cells</code>.\n+   */\n+  @Nullable\n+  public static List<RegionInfo> getMergeRegions(Cell[] cells) {\n+    Map<String, RegionInfo> mergeRegionsWithName = getMergeRegionsWithName(cells);\n+    return (mergeRegionsWithName == null) ? null : new ArrayList<>(mergeRegionsWithName.values());\n+  }\n+\n+  /**\n+   * @return True if any merge regions present in <code>cells</code>; i.e. the column in\n+   *         <code>cell</code> matches the regex 'info:merge.*'.\n+   */\n+  public static boolean hasMergeRegions(Cell[] cells) {", "originalCommit": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2NDQ4MA==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484264480", "bodyText": "Just copy-paste. Let me change the code.", "author": "Apache9", "createdAt": "2020-09-07T08:12:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDIzNzM1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "8542c7debbd92ee723b61133221af361aa52ea73", "chunk": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java\nindex 40d28f3f9e..a2297b66ab 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/CatalogFamilyFormat.java\n\n@@ -391,10 +391,9 @@ public class CatalogFamilyFormat {\n    */\n   public static boolean hasMergeRegions(Cell[] cells) {\n     for (Cell cell : cells) {\n-      if (!isMergeQualifierPrefix(cell)) {\n-        continue;\n+      if (isMergeQualifierPrefix(cell)) {\n+        return true;\n       }\n-      return true;\n     }\n     return false;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI0MDU4Mg==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484240582", "bodyText": "Is it possible NPE in this long call chain?", "author": "infraio", "createdAt": "2020-09-07T07:42:37Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java", "diffHunk": "@@ -88,7 +87,7 @@ protected Flow executeFromState(MasterProcedureEnv env, GCMergedRegionsState sta\n         setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);\n         break;\n       case GC_REGION_EDIT_METADATA:\n-        MetaTableAccessor.deleteMergeQualifiers(env.getMasterServices().getConnection(), mergedChild);\n+        env.getAssignmentManager().getRegionStateStore().deleteMergeQualifiers(mergedChild);", "originalCommit": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2Mzk0OA==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484263948", "bodyText": "In real deploy, no. In tests we could have null assignmentmanager or regionstatestore, but as the above pre commit is fine so I do not think it is a problem here.", "author": "Apache9", "createdAt": "2020-09-07T08:11:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI0MDU4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "85be881629f2b8fade0e324af2297cfe94632939", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java\nindex 352a3c8ec0..5a21e6cacb 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/GCMergedRegionsProcedure.java\n\n@@ -72,30 +72,30 @@ extends AbstractStateMachineTableProcedure<GCMergedRegionsState> {\n \n   @Override\n   protected Flow executeFromState(MasterProcedureEnv env, GCMergedRegionsState state)\n-  throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {\n+    throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(this + \" execute state=\" + state);\n     }\n     try {\n       switch (state) {\n-      case GC_MERGED_REGIONS_PREPARE:\n-        // Nothing to do to prepare.\n-        setNextState(GCMergedRegionsState.GC_MERGED_REGIONS_PURGE);\n-        break;\n-      case GC_MERGED_REGIONS_PURGE:\n-        addChildProcedure(createGCRegionProcedures(env));\n-        setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);\n-        break;\n-      case GC_REGION_EDIT_METADATA:\n-        env.getAssignmentManager().getRegionStateStore().deleteMergeQualifiers(mergedChild);\n-        return Flow.NO_MORE_STATE;\n-      default:\n-        throw new UnsupportedOperationException(this + \" unhandled state=\" + state);\n+        case GC_MERGED_REGIONS_PREPARE:\n+          // Nothing to do to prepare.\n+          setNextState(GCMergedRegionsState.GC_MERGED_REGIONS_PURGE);\n+          break;\n+        case GC_MERGED_REGIONS_PURGE:\n+          addChildProcedure(createGCRegionProcedures(env));\n+          setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);\n+          break;\n+        case GC_REGION_EDIT_METADATA:\n+          env.getAssignmentManager().getRegionStateStore().deleteMergeQualifiers(mergedChild);\n+          return Flow.NO_MORE_STATE;\n+        default:\n+          throw new UnsupportedOperationException(this + \" unhandled state=\" + state);\n       }\n     } catch (IOException ioe) {\n       // TODO: This is going to spew log?\n-      LOG.warn(\"Error trying to GC merged regions \" + this.father.getShortNameToLog() +\n-          \" & \" + this.mother.getShortNameToLog() + \"; retrying...\", ioe);\n+      LOG.warn(\"Error trying to GC merged regions \" + this.father.getShortNameToLog() + \" & \" +\n+        this.mother.getShortNameToLog() + \"; retrying...\", ioe);\n     }\n     return Flow.HAS_MORE_STATE;\n   }\n"}}, {"oid": "85be881629f2b8fade0e324af2297cfe94632939", "url": "https://github.com/apache/hbase/commit/85be881629f2b8fade0e324af2297cfe94632939", "message": "fix checkstyle issue", "committedDate": "2020-09-07T07:44:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI1Nzg5Mg==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484257892", "bodyText": "getReplicationBarrier => getReplicationBarriers? As this method return a arrary too.", "author": "infraio", "createdAt": "2020-09-07T08:00:39Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.replication;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.Cell.Type;\n+import org.apache.hadoop.hbase.CellBuilderFactory;\n+import org.apache.hadoop.hbase.CellBuilderType;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor;\n+import org.apache.hadoop.hbase.ClientMetaTableAccessor.QueryType;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.MetaTableAccessor;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.Table;\n+import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;\n+import org.apache.hadoop.hbase.master.RegionState;\n+import org.apache.hadoop.hbase.master.RegionState.State;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.Pair;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Helper class for storing replication barriers in family 'rep_barrier' of meta table.\n+ * <p/>\n+ * See SerialReplicationChecker on how to make use of the barriers.\n+ */\n+@InterfaceAudience.Private\n+public final class ReplicationBarrierFamilyFormat {\n+\n+  @VisibleForTesting\n+  public static final byte[] REPLICATION_PARENT_QUALIFIER = Bytes.toBytes(\"parent\");\n+\n+  private static final byte ESCAPE_BYTE = (byte) 0xFF;\n+\n+  private static final byte SEPARATED_BYTE = 0x00;\n+\n+  private ReplicationBarrierFamilyFormat() {\n+  }\n+\n+  public static void addReplicationBarrier(Put put, long openSeqNum) throws IOException {\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(HConstants.SEQNUM_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(Bytes.toBytes(openSeqNum))\n+      .build());\n+  }\n+\n+  private static void writeRegionName(ByteArrayOutputStream out, byte[] regionName) {\n+    for (byte b : regionName) {\n+      if (b == ESCAPE_BYTE) {\n+        out.write(ESCAPE_BYTE);\n+      }\n+      out.write(b);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public static byte[] getParentsBytes(List<RegionInfo> parents) {\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    Iterator<RegionInfo> iter = parents.iterator();\n+    writeRegionName(bos, iter.next().getRegionName());\n+    while (iter.hasNext()) {\n+      bos.write(ESCAPE_BYTE);\n+      bos.write(SEPARATED_BYTE);\n+      writeRegionName(bos, iter.next().getRegionName());\n+    }\n+    return bos.toByteArray();\n+  }\n+\n+  private static List<byte[]> parseParentsBytes(byte[] bytes) {\n+    List<byte[]> parents = new ArrayList<>();\n+    ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+    for (int i = 0; i < bytes.length; i++) {\n+      if (bytes[i] == ESCAPE_BYTE) {\n+        i++;\n+        if (bytes[i] == SEPARATED_BYTE) {\n+          parents.add(bos.toByteArray());\n+          bos.reset();\n+          continue;\n+        }\n+        // fall through to append the byte\n+      }\n+      bos.write(bytes[i]);\n+    }\n+    if (bos.size() > 0) {\n+      parents.add(bos.toByteArray());\n+    }\n+    return parents;\n+  }\n+\n+  public static void addReplicationParent(Put put, List<RegionInfo> parents) throws IOException {\n+    byte[] value = getParentsBytes(parents);\n+    put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(put.getRow())\n+      .setFamily(HConstants.REPLICATION_BARRIER_FAMILY).setQualifier(REPLICATION_PARENT_QUALIFIER)\n+      .setTimestamp(put.getTimestamp()).setType(Type.Put).setValue(value).build());\n+  }\n+\n+  public static Put makePutForReplicationBarrier(RegionInfo regionInfo, long openSeqNum, long ts)\n+    throws IOException {\n+    Put put = new Put(regionInfo.getRegionName(), ts);\n+    addReplicationBarrier(put, openSeqNum);\n+    return put;\n+  }\n+\n+  public static final class ReplicationBarrierResult {\n+    private final long[] barriers;\n+    private final RegionState.State state;\n+    private final List<byte[]> parentRegionNames;\n+\n+    ReplicationBarrierResult(long[] barriers, State state, List<byte[]> parentRegionNames) {\n+      this.barriers = barriers;\n+      this.state = state;\n+      this.parentRegionNames = parentRegionNames;\n+    }\n+\n+    public long[] getBarriers() {\n+      return barriers;\n+    }\n+\n+    public RegionState.State getState() {\n+      return state;\n+    }\n+\n+    public List<byte[]> getParentRegionNames() {\n+      return parentRegionNames;\n+    }\n+\n+    @Override\n+    public String toString() {\n+      return \"ReplicationBarrierResult [barriers=\" + Arrays.toString(barriers) + \", state=\" +\n+        state + \", parentRegionNames=\" +\n+        parentRegionNames.stream().map(Bytes::toStringBinary).collect(Collectors.joining(\", \")) +\n+        \"]\";\n+    }\n+  }\n+\n+  private static long getReplicationBarrier(Cell c) {\n+    return Bytes.toLong(c.getValueArray(), c.getValueOffset(), c.getValueLength());\n+  }\n+\n+  public static long[] getReplicationBarriers(Result result) {\n+    return result.getColumnCells(HConstants.REPLICATION_BARRIER_FAMILY, HConstants.SEQNUM_QUALIFIER)\n+      .stream().mapToLong(ReplicationBarrierFamilyFormat::getReplicationBarrier).sorted().distinct()\n+      .toArray();\n+  }\n+\n+  private static ReplicationBarrierResult getReplicationBarrierResult(Result result) {\n+    long[] barriers = getReplicationBarriers(result);\n+    byte[] stateBytes = result.getValue(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER);\n+    RegionState.State state =\n+      stateBytes != null ? RegionState.State.valueOf(Bytes.toString(stateBytes)) : null;\n+    byte[] parentRegionsBytes =\n+      result.getValue(HConstants.REPLICATION_BARRIER_FAMILY, REPLICATION_PARENT_QUALIFIER);\n+    List<byte[]> parentRegionNames =\n+      parentRegionsBytes != null ? parseParentsBytes(parentRegionsBytes) : Collections.emptyList();\n+    return new ReplicationBarrierResult(barriers, state, parentRegionNames);\n+  }\n+\n+  public static ReplicationBarrierResult getReplicationBarrierResult(Connection conn,\n+    TableName tableName, byte[] row, byte[] encodedRegionName) throws IOException {\n+    byte[] metaStartKey = RegionInfo.createRegionName(tableName, row, HConstants.NINES, false);\n+    byte[] metaStopKey =\n+      RegionInfo.createRegionName(tableName, HConstants.EMPTY_START_ROW, \"\", false);\n+    Scan scan = new Scan().withStartRow(metaStartKey).withStopRow(metaStopKey)\n+      .addColumn(HConstants.CATALOG_FAMILY, HConstants.STATE_QUALIFIER)\n+      .addFamily(HConstants.REPLICATION_BARRIER_FAMILY).readAllVersions().setReversed(true)\n+      .setCaching(10);\n+    try (Table table = conn.getTable(TableName.META_TABLE_NAME);\n+      ResultScanner scanner = table.getScanner(scan)) {\n+      for (Result result;;) {\n+        result = scanner.next();\n+        if (result == null) {\n+          return new ReplicationBarrierResult(new long[0], null, Collections.emptyList());\n+        }\n+        byte[] regionName = result.getRow();\n+        // TODO: we may look up a region which has already been split or merged so we need to check\n+        // whether the encoded name matches. Need to find a way to quit earlier when there is no\n+        // record for the given region, for now it will scan to the end of the table.\n+        if (!Bytes.equals(encodedRegionName,\n+          Bytes.toBytes(RegionInfo.encodeRegionName(regionName)))) {\n+          continue;\n+        }\n+        return getReplicationBarrierResult(result);\n+      }\n+    }\n+  }\n+\n+  public static long[] getReplicationBarrier(Connection conn, byte[] regionName)", "originalCommit": "7644720fcaacd63587e08fc2b4c5c1dd2a3ef14a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI2ODEzNQ==", "url": "https://github.com/apache/hbase/pull/2354#discussion_r484268135", "bodyText": "Done.", "author": "Apache9", "createdAt": "2020-09-07T08:18:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDI1Nzg5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "8542c7debbd92ee723b61133221af361aa52ea73", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java\nindex 608d02b8e6..123a036ca0 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationBarrierFamilyFormat.java\n\n@@ -216,7 +216,7 @@ public final class ReplicationBarrierFamilyFormat {\n     }\n   }\n \n-  public static long[] getReplicationBarrier(Connection conn, byte[] regionName)\n+  public static long[] getReplicationBarriers(Connection conn, byte[] regionName)\n     throws IOException {\n     try (Table table = conn.getTable(TableName.META_TABLE_NAME)) {\n       Result result = table.get(new Get(regionName)\n"}}, {"oid": "8542c7debbd92ee723b61133221af361aa52ea73", "url": "https://github.com/apache/hbase/commit/8542c7debbd92ee723b61133221af361aa52ea73", "message": "address review comments", "committedDate": "2020-09-07T08:13:44Z", "type": "commit"}]}