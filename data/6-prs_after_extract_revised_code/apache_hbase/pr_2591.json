{"pr_number": 2591, "pr_title": "HBASE-24859: Optimize in-memory representation of HBase map reduce table splits", "pr_createdAt": "2020-10-28T00:04:30Z", "pr_url": "https://github.com/apache/hbase/pull/2591", "timeline": [{"oid": "38c3384902fda42e486931db6bb2338a27128efe", "url": "https://github.com/apache/hbase/commit/38c3384902fda42e486931db6bb2338a27128efe", "message": "HBASE-24859: Improve the storage cost for HBase map reduce table splits", "committedDate": "2020-10-28T00:13:30Z", "type": "forcePushed"}, {"oid": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "url": "https://github.com/apache/hbase/commit/688aaa58d14ad61b2a2a54d90f35f508686c9324", "message": "HBASE-24859: Improve the storage cost for HBase map reduce table splits", "committedDate": "2020-10-28T03:55:24Z", "type": "commit"}, {"oid": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "url": "https://github.com/apache/hbase/commit/688aaa58d14ad61b2a2a54d90f35f508686c9324", "message": "HBASE-24859: Improve the storage cost for HBase map reduce table splits", "committedDate": "2020-10-28T03:55:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE3OTg4Ng==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513179886", "bodyText": "So, we do not pass the scan object and then we save a bunch of memory? The TableSplit doesn't carry around the heavy scan instance anymore? Is that it? Thanks.", "author": "saintstack", "createdAt": "2020-10-28T04:53:33Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java", "diffHunk": "@@ -323,7 +323,7 @@ public boolean nextKeyValue() throws IOException, InterruptedException {\n       }\n       List<InputSplit> splits = new ArrayList<>(1);\n       long regionSize = sizeCalculator.getRegionSize(regLoc.getRegionInfo().getRegionName());\n-      TableSplit split = new TableSplit(tableName, scan,\n+      TableSplit split = new TableSplit(tableName,", "originalCommit": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzU5OTE3OA==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513599178", "bodyText": "@saintstack that is correct! If you see the jira for description, there is a heap dump screenshots which shows the scan object may occupy much memory in case of tables with large number of regions. This patch just fix the TableInputFormat for single table where we don\u2019t use the scan object from TableSplit since we use it from MR Job conf directly. There should be another patch to fix the similar fix with more code changes  for MultiTableInputFormat. I will try to fix that in a separate patch.", "author": "sandeepvinayak", "createdAt": "2020-10-28T16:44:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE3OTg4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "732e0dddf789099bca9abe7188f812090ff0217e", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\nindex c06e0e37fc..0f49af571f 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n\n@@ -323,7 +323,7 @@ extends InputFormat<ImmutableBytesWritable, Result> {\n       }\n       List<InputSplit> splits = new ArrayList<>(1);\n       long regionSize = sizeCalculator.getRegionSize(regLoc.getRegionInfo().getRegionName());\n-      TableSplit split = new TableSplit(tableName,\n+      TableSplit split = new TableSplit(tableName, null,\n           HConstants.EMPTY_BYTE_ARRAY, HConstants.EMPTY_BYTE_ARRAY, regLoc\n           .getHostnamePort().split(Addressing.HOSTNAME_PORT_SEPARATOR)[0], regionSize);\n       splits.add(split);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513757980", "bodyText": "Why do we need a new constructor? Just pass null wherever it is not needed?", "author": "bharathv", "createdAt": "2020-10-28T21:02:19Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java", "diffHunk": "@@ -184,9 +184,24 @@ public TableSplit(final byte [] tableName, byte[] startRow, byte[] endRow,\n    * @param startRow The start row of the split.\n    * @param endRow The end row of the split.\n    * @param location The location of the region.\n+   * @param encodedRegionName The region ID.\n+   * @param length Size of region in bytes\n    */\n   public TableSplit(TableName tableName, byte[] startRow, byte[] endRow,\n-      final String location) {\n+    final String location, final String encodedRegionName, long length) {\n+    this(tableName, null, startRow, endRow, location, encodedRegionName, length);", "originalCommit": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc5NTc2Mw==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513795763", "bodyText": "@bharathv I think the separate constructor is more intuitive that it is okay to not have scan object? What do you think?", "author": "sandeepvinayak", "createdAt": "2020-10-28T22:19:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA5MjczOQ==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514092739", "bodyText": "can't we ignore the scan assignment, just using this.scan = \"\" anyway, instead of the following:\n    try {\n      this.scan =\n        (null == scan) ? \"\" : TableMapReduceUtil.convertScanToString(scan);\n    } catch (IOException e) {\n      LOG.warn(\"Failed to convert Scan to String\", e);\n    }\n\nI also prefer not to add a new constructor.", "author": "Reidddddd", "createdAt": "2020-10-29T08:49:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA5NTM1Mg==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514095352", "bodyText": "iff we make sure the scan is useless here", "author": "Reidddddd", "createdAt": "2020-10-29T08:53:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM5NjEwNw==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514396107", "bodyText": "I think the separate constructor is more intuitive that it is okay to not have scan object? What do you think?\n\nIMHO more constructors is less readability. In this case we have 8 constructors for TableSplit. If I were to use it, I'd confused unless I see the usages of each of these. Either we should have a fluent interface or fewer constructors is what I think. Subjective of course.", "author": "bharathv", "createdAt": "2020-10-29T16:27:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUyODQxOA==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514528418", "bodyText": "@Reidddddd Scan is not useless for all the input formats of map-reduce, it is for the TableInputFormat.\nWe do need the scan object for MultiTableInputFormat", "author": "sandeepvinayak", "createdAt": "2020-10-29T19:58:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc1Nzk4MA=="}], "type": "inlineReview", "revised_code": {"commit": "7fef633035b3105a7ffe99f70577cbd45247234c", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\nindex 9627be27ab..1b1eac658b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n\n@@ -193,7 +193,11 @@ implements Writable, Comparable<TableSplit> {\n   }\n \n   /**\n-   * Creates a new instance without a scanner.\n+   * Creates a new instance without a scanner. Having no scanner in TableSplit doesn't necessarily\n+   * mean there is not scanner for map reduce job, it just means that we do not need to set\n+   * it for each split. For example, it is not required to have a scan object for\n+   * {@link org.apache.hadoop.hbase.mapred.TableInputFormatBase} since we use\n+   * the scan from the job conf and scanner is supposed to be same for all the splits of table.\n    *\n    * @param tableName The name of the current table.\n    * @param startRow The start row of the split.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2ODgxNw==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513768817", "bodyText": "nit: I think these checks are not tight enough since they don't differentiate between a full table scan object and a no scan object, instead I think it should be something like\nassertTrue(tableSplit.getScanAsString().isEmpty()) or some such...", "author": "bharathv", "createdAt": "2020-10-28T21:21:49Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java", "diffHunk": "@@ -271,6 +272,11 @@ public void testNumOfSplits(int splitsPerRegion, int expectedNumOfSplits) throws\n     TableInputFormat tif = new TableInputFormat();\n     tif.setConf(job.getConfiguration());\n     List<InputSplit> splits = tif.getSplits(job);\n+    for (InputSplit split : splits) {\n+      TableSplit tableSplit = (TableSplit) split;\n+      Assert.assertEquals(tableSplit.getScan().getStartRow(), HConstants.EMPTY_START_ROW);", "originalCommit": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzgzMDMzNQ==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513830335", "bodyText": "@bharathv The reason I am asserting on this is when we serialize null scan object, we set the default object. That's why we don't get the empty string back but with the defaut values. I am asserting here on default values.\nhttps://github.com/apache/hbase/blob/branch-1/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java#L1126", "author": "sandeepvinayak", "createdAt": "2020-10-28T23:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2ODgxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQyNjczNg==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514426736", "bodyText": "Ya my point is, that is a weak check. You wouldn't know if that scan is an empty scan or a default scan. Change the code to something like this and you can see there is a bug ...\nfor (InputSplit split : splits) {\n     TableSplit tableSplit = (TableSplit) split;\n     assertTrue(tableSplit.getScanAsString().isEmpty());\n }\n\nIn table split code, add this...\n\npublic String getScanAsString() {\n   return scan;\n }\n\nRun this test\n  @Test\n  public void testGetSplits() throws IOException, InterruptedException, ClassNotFoundException {\n    testNumOfSplits(1, 26);\n    testNumOfSplits(3, 78);  <====\n  }\n\nIf number of splits per region is > 1, your patch didn't handle the TableSplit constructor in this call createNInputSplitsUniform(). Your test still passes because you are asserting on a default Scan object and not the fact that it shouldn't be set in the first place.", "author": "bharathv", "createdAt": "2020-10-29T17:10:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2ODgxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUyNTYxMw==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514525613", "bodyText": "I see your point, thanks !", "author": "sandeepvinayak", "createdAt": "2020-10-29T19:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2ODgxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU5MDY4Ng==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514590686", "bodyText": "Remove the other two asserts? They are implied if the scan is \"\" ?", "author": "bharathv", "createdAt": "2020-10-29T21:55:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2ODgxNw=="}], "type": "inlineReview", "revised_code": {"commit": "7fef633035b3105a7ffe99f70577cbd45247234c", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java\nindex 965ba11d70..2618a10edd 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableInputFormatScanBase.java\n\n@@ -274,6 +274,9 @@ public abstract class TestTableInputFormatScanBase {\n     List<InputSplit> splits = tif.getSplits(job);\n     for (InputSplit split : splits) {\n       TableSplit tableSplit = (TableSplit) split;\n+      // We should have the null scan object in the TableSplit, but when we serialize\n+      // null scan in the TableSplit, we put the default values instead.\n+      // So, asserting here for default values.\n       Assert.assertEquals(tableSplit.getScan().getStartRow(), HConstants.EMPTY_START_ROW);\n       Assert.assertEquals(tableSplit.getScan().getStopRow(), HConstants.EMPTY_END_ROW);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2OTYxNg==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r513769616", "bodyText": "Mind adding a javadoc for \"scan\" object? What it means to be null..", "author": "bharathv", "createdAt": "2020-10-28T21:23:32Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java", "diffHunk": "@@ -184,9 +184,24 @@ public TableSplit(final byte [] tableName, byte[] startRow, byte[] endRow,\n    * @param startRow The start row of the split.\n    * @param endRow The end row of the split.\n    * @param location The location of the region.\n+   * @param encodedRegionName The region ID.\n+   * @param length Size of region in bytes\n    */\n   public TableSplit(TableName tableName, byte[] startRow, byte[] endRow,\n-      final String location) {\n+    final String location, final String encodedRegionName, long length) {\n+    this(tableName, null, startRow, endRow, location, encodedRegionName, length);\n+  }\n+\n+  /**\n+   * Creates a new instance without a scanner.", "originalCommit": "688aaa58d14ad61b2a2a54d90f35f508686c9324", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7fef633035b3105a7ffe99f70577cbd45247234c", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\nindex 9627be27ab..1b1eac658b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n\n@@ -193,7 +193,11 @@ implements Writable, Comparable<TableSplit> {\n   }\n \n   /**\n-   * Creates a new instance without a scanner.\n+   * Creates a new instance without a scanner. Having no scanner in TableSplit doesn't necessarily\n+   * mean there is not scanner for map reduce job, it just means that we do not need to set\n+   * it for each split. For example, it is not required to have a scan object for\n+   * {@link org.apache.hadoop.hbase.mapred.TableInputFormatBase} since we use\n+   * the scan from the job conf and scanner is supposed to be same for all the splits of table.\n    *\n    * @param tableName The name of the current table.\n    * @param startRow The start row of the split.\n"}}, {"oid": "7fef633035b3105a7ffe99f70577cbd45247234c", "url": "https://github.com/apache/hbase/commit/7fef633035b3105a7ffe99f70577cbd45247234c", "message": "Adding javadoc for scan object and comment on asserts\n\na", "committedDate": "2020-10-29T00:01:07Z", "type": "commit"}, {"oid": "7fef633035b3105a7ffe99f70577cbd45247234c", "url": "https://github.com/apache/hbase/commit/7fef633035b3105a7ffe99f70577cbd45247234c", "message": "Adding javadoc for scan object and comment on asserts\n\na", "committedDate": "2020-10-29T00:01:07Z", "type": "forcePushed"}, {"oid": "732e0dddf789099bca9abe7188f812090ff0217e", "url": "https://github.com/apache/hbase/commit/732e0dddf789099bca9abe7188f812090ff0217e", "message": "Removing the constructor and testing on the scan string rather than scan object", "committedDate": "2020-10-29T19:59:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU5MDE0OA==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514590148", "bodyText": "Mark this InterfaceAudience.Private? This is a test helper method..", "author": "bharathv", "createdAt": "2020-10-29T21:54:11Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java", "diffHunk": "@@ -214,6 +223,14 @@ public Scan getScan() throws IOException {\n     return TableMapReduceUtil.convertStringToScan(this.scan);\n   }\n \n+  /**\n+   * Returns a scan object in the serialized form\n+   * @return a serialized scan object\n+   */\n+  public String getScanAsString() {", "originalCommit": "732e0dddf789099bca9abe7188f812090ff0217e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45147463f6d14f3a9de7df1398b943be24959cba", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\nindex 1fb0c094e7..bc33feac3b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n\n@@ -217,16 +219,19 @@ implements Writable, Comparable<TableSplit> {\n    * Returns a Scan object from the stored string representation.\n    *\n    * @return Returns a Scan object based on the stored scanner.\n-   * @throws IOException\n+   * @throws IOException throws IOException if deserialization fails\n    */\n   public Scan getScan() throws IOException {\n     return TableMapReduceUtil.convertStringToScan(this.scan);\n   }\n \n   /**\n-   * Returns a scan object in the serialized form\n-   * @return a serialized scan object\n+   * Returns a scan string\n+   * @return scan as string. Should be noted that this is not same as getScan().toString()\n+   *    because Scan object will have the default values when empty scan string is\n+   *    deserialized. Thus getScan().toString() can never be empty\n    */\n+  @InterfaceAudience.Private\n   public String getScanAsString() {\n     return this.scan;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwMjM1Nw==", "url": "https://github.com/apache/hbase/pull/2591#discussion_r514602357", "bodyText": "nit: new lines missing\n/**\n * .....\n */", "author": "bharathv", "createdAt": "2020-10-29T22:24:45Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java", "diffHunk": "@@ -86,7 +86,16 @@ static Version fromCode(int code) {\n   private byte [] endRow;\n   private String regionLocation;\n   private String encodedRegionName = \"\";\n+\n+  /** The scan object may be null but the serialized form of scan is never null", "originalCommit": "732e0dddf789099bca9abe7188f812090ff0217e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45147463f6d14f3a9de7df1398b943be24959cba", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\nindex 1fb0c094e7..bc33feac3b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java\n\n@@ -87,13 +87,15 @@ implements Writable, Comparable<TableSplit> {\n   private String regionLocation;\n   private String encodedRegionName = \"\";\n \n-  /** The scan object may be null but the serialized form of scan is never null\n+  /**\n+   * The scan object may be null but the serialized form of scan is never null\n    * or empty since we serialize the scan object with default values then.\n-   * Having no scanner in TableSplit doesn't necessarily mean there is not scanner\n+   * Having no scanner in TableSplit doesn't necessarily mean there is no scanner\n    * for mapreduce job, it just means that we do not need to set it for each split.\n    * For example, it is not required to have a scan object for\n    * {@link org.apache.hadoop.hbase.mapred.TableInputFormatBase} since we use the scan from the\n-   * job conf and scanner is supposed to be same for all the splits of table.*/\n+   * job conf and scanner is supposed to be same for all the splits of table.\n+   */\n   private String scan = \"\"; // stores the serialized form of the Scan\n \n   private long length; // Contains estimation of region size in bytes\n"}}, {"oid": "45147463f6d14f3a9de7df1398b943be24959cba", "url": "https://github.com/apache/hbase/commit/45147463f6d14f3a9de7df1398b943be24959cba", "message": "Addressing comments and fixing come checkstyles", "committedDate": "2020-10-30T00:31:40Z", "type": "forcePushed"}, {"oid": "ff3474472d6aa06670576b7e1ccb7bf4ebbf89e3", "url": "https://github.com/apache/hbase/commit/ff3474472d6aa06670576b7e1ccb7bf4ebbf89e3", "message": "Addressing comments and fixing come checkstyles", "committedDate": "2020-10-30T00:37:20Z", "type": "forcePushed"}, {"oid": "244e482a5dd663258cec4cfe515ec5dcd97902c3", "url": "https://github.com/apache/hbase/commit/244e482a5dd663258cec4cfe515ec5dcd97902c3", "message": "Addressing comments and fixing come checkstyles", "committedDate": "2020-10-30T00:39:12Z", "type": "commit"}, {"oid": "244e482a5dd663258cec4cfe515ec5dcd97902c3", "url": "https://github.com/apache/hbase/commit/244e482a5dd663258cec4cfe515ec5dcd97902c3", "message": "Addressing comments and fixing come checkstyles", "committedDate": "2020-10-30T00:39:12Z", "type": "forcePushed"}]}