{"pr_number": 1062, "pr_title": "HBASE-23705 Add CellComparator to HFileContext", "pr_createdAt": "2020-01-17T21:51:21Z", "pr_url": "https://github.com/apache/hbase/pull/1062", "timeline": [{"oid": "4fc55067006f9946f52547561d5a383b55f2dd42", "url": "https://github.com/apache/hbase/commit/4fc55067006f9946f52547561d5a383b55f2dd42", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-18T05:48:30Z", "type": "forcePushed"}, {"oid": "e8a42ce12911ff76559f7f9c40b80efbc5bd35c3", "url": "https://github.com/apache/hbase/commit/e8a42ce12911ff76559f7f9c40b80efbc5bd35c3", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-18T15:12:18Z", "type": "forcePushed"}, {"oid": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "url": "https://github.com/apache/hbase/commit/f45287b27aae2cece0959ba69b9e2ba02dc19982", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-18T15:35:14Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTg0NQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368309845", "bodyText": "Is there already a Jira for this?", "author": "HorizonNet", "createdAt": "2020-01-19T17:37:06Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java", "diffHunk": "@@ -377,6 +378,27 @@ private static int compareRows(byte[] left, int loffset, int llength, byte[] rig\n       return result;\n     }\n \n+    @Override\n+    public int compareRows(ByteBuffer row, Cell cell) {\n+      byte [] array;\n+      int offset;\n+      int len = row.remaining();\n+      if (row.hasArray()) {\n+        array = row.array();\n+        offset = row.position() + row.arrayOffset();\n+      } else {\n+        // This is awful, we copy the row array if offheap just so we can do a compare.\n+        // We do this elsewhere too when Cell is backed by an offheap ByteBuffer.\n+        // Needs fixing. TODO.", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMzkxNw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368323917", "bodyText": "No.\nSince making this comment, I see that we do this whenever the BB is offheap.  Let me make an issue. This issue adds a method to CellComparator that takes a row held in a ByteBuffer. We need more of this with methods in Comparator that can stride through a BB by index so we don't have to copy on heap to compare. The hard part is an implementation that does not insist on two compare methods -- one for array and another for BB.   Would be good if could have one compare only.", "author": "saintstack", "createdAt": "2020-01-19T21:23:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ0NTIwNA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368445204", "bodyText": "Are you sure on this STack. All the impl of the BB vs Array (vice versa) or BB vs BB all happens inside the BBUtils method. There we are clearly ensuring that we either call getXXxOffset() or getXXXPosition() so that we avoide copying onheap. Only when a user tries to do getRowArray on a BB backed cell we try to copy the row part and then do the comparsion. In that case he should also be using getRowOfset() only which would be 0/.", "author": "ramkrish86", "createdAt": "2020-01-20T09:32:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxODI1OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368618259", "bodyText": "Only when a user tries to do getRowArray on a BB backed cell we try to copy the row part and then do the comparsion. In that case he should also be using getRowOfset() only which would be\n\nI should have been more specific. Lets make it so no need to copy-to-compare ever.", "author": "saintstack", "createdAt": "2020-01-20T15:53:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1MDExMw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369150113", "bodyText": "Made the comment more mild. Added pointer to BBUtils, that we do here what it does. Added note to fix ever having to copy on heap.", "author": "saintstack", "createdAt": "2020-01-21T17:49:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTg0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\nindex 5da45594ef..e6c8e3ded6 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n\n@@ -387,9 +385,8 @@ public class CellComparatorImpl implements CellComparator {\n         array = row.array();\n         offset = row.position() + row.arrayOffset();\n       } else {\n-        // This is awful, we copy the row array if offheap just so we can do a compare.\n-        // We do this elsewhere too when Cell is backed by an offheap ByteBuffer.\n-        // Needs fixing. TODO.\n+        // We copy the row array if offheap just so we can do a compare. We do this elsewhere too\n+        // in BBUtils when Cell is backed by an offheap ByteBuffer. Needs fixing so no copy. TODO.\n         array = new byte[len];\n         offset = 0;\n         ByteBufferUtils.copyFromBufferToArray(array, row, row.position(),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTkzMQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368309931", "bodyText": "NIT: Use {@code tableName} instead.", "author": "HorizonNet", "createdAt": "2020-01-19T17:38:27Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java", "diffHunk": "@@ -387,4 +409,23 @@ public Comparator getSimpleComparator() {\n   public Comparator getSimpleComparator() {\n     return new BBKVComparator(this);\n   }\n+\n+  /**\n+   * Utility method that makes a guess at comparator to use based off passed tableName.\n+   * Use in extreme when no comparator specified.\n+   * @return CellComparator to use going off the <code>tableName</code> passed.", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1MDE4Nw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369150187", "bodyText": "Done", "author": "saintstack", "createdAt": "2020-01-21T17:50:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTkzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\nindex 5da45594ef..e6c8e3ded6 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n\n@@ -413,7 +410,7 @@ public class CellComparatorImpl implements CellComparator {\n   /**\n    * Utility method that makes a guess at comparator to use based off passed tableName.\n    * Use in extreme when no comparator specified.\n-   * @return CellComparator to use going off the <code>tableName</code> passed.\n+   * @return CellComparator to use going off the {@code tableName} passed.\n    */\n   public static CellComparator getCellComparator(TableName tableName) {\n     return getCellComparator(tableName.toBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTk4Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368309982", "bodyText": "NIT: Use {@code tableName} instead.", "author": "HorizonNet", "createdAt": "2020-01-19T17:38:53Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java", "diffHunk": "@@ -387,4 +409,23 @@ public Comparator getSimpleComparator() {\n   public Comparator getSimpleComparator() {\n     return new BBKVComparator(this);\n   }\n+\n+  /**\n+   * Utility method that makes a guess at comparator to use based off passed tableName.\n+   * Use in extreme when no comparator specified.\n+   * @return CellComparator to use going off the <code>tableName</code> passed.\n+   */\n+  public static CellComparator getCellComparator(TableName tableName) {\n+    return getCellComparator(tableName.toBytes());\n+  }\n+\n+  /**\n+   * Utility method that makes a guess at comparator to use based off passed tableName.\n+   * Use in extreme when no comparator specified.\n+   * @return CellComparator to use going off the <code>tableName</code> passed.", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMzcyOA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368323728", "bodyText": "Will do.", "author": "saintstack", "createdAt": "2020-01-19T21:20:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMwOTk4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\nindex 5da45594ef..e6c8e3ded6 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n\n@@ -413,7 +410,7 @@ public class CellComparatorImpl implements CellComparator {\n   /**\n    * Utility method that makes a guess at comparator to use based off passed tableName.\n    * Use in extreme when no comparator specified.\n-   * @return CellComparator to use going off the <code>tableName</code> passed.\n+   * @return CellComparator to use going off the {@code tableName} passed.\n    */\n   public static CellComparator getCellComparator(TableName tableName) {\n     return getCellComparator(tableName.toBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDIwOQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310209", "bodyText": "NIT: Whitespace before ? and :.", "author": "HorizonNet", "createdAt": "2020-01-19T17:43:06Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java", "diffHunk": "@@ -114,6 +118,11 @@ public HFileContext(HFileContext context) {\n     this.hfileName = hfileName;\n     this.columnFamily = columnFamily;\n     this.tableName = tableName;\n+    // If no cellComparator specified, make a guess based off tablename. If hbase:meta, then should\n+    // be the meta table comparator. Comparators are per table.\n+    this.cellComparator = cellComparator != null? cellComparator:", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1MDc1Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369150752", "bodyText": "Implemented.", "author": "saintstack", "createdAt": "2020-01-21T17:51:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDIwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\nindex 17e8a44f16..ea4782d035 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n\n@@ -120,14 +120,12 @@ public class HFileContext implements HeapSize, Cloneable {\n     this.tableName = tableName;\n     // If no cellComparator specified, make a guess based off tablename. If hbase:meta, then should\n     // be the meta table comparator. Comparators are per table.\n-    this.cellComparator = cellComparator != null? cellComparator:\n-      this.tableName != null? CellComparatorImpl.getCellComparator(this.tableName):\n-        CellComparator.getInstance();\n+    this.cellComparator = cellComparator != null ? cellComparator : this.tableName != null ?\n+      CellComparatorImpl.getCellComparator(this.tableName) : CellComparator.getInstance();\n   }\n \n   /**\n-   * @return true when on-disk blocks from this file are compressed, and/or encrypted;\n-   * false otherwise.\n+   * @return true when on-disk blocks are compressed, and/or encrypted; false otherwise.\n    */\n   public boolean isCompressedOrEncrypted() {\n     Compression.Algorithm compressAlgo = getCompression();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDI3MA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310270", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:44:18Z", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -424,15 +423,14 @@ private WriterLength getNewWriter(byte[] tableName, byte[] family, Configuration\n         HFileContext hFileContext = contextBuilder.build();\n         if (null == favoredNodes) {\n           wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs)\n-                  .withOutputDir(familydir).withBloomType(bloomType)\n-                  .withComparator(CellComparator.getInstance()).withFileContext(hFileContext).build();\n+              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs).\n+                withOutputDir(familydir).withBloomType(bloomType).", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java b/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nindex d855edb305..ab1ede6ba1 100644\n--- a/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\n+++ b/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\n\n@@ -422,15 +386,13 @@ public class HFileOutputFormat2\n         contextBuilder.withDataBlockEncoding(encoding);\n         HFileContext hFileContext = contextBuilder.build();\n         if (null == favoredNodes) {\n-          wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs).\n-                withOutputDir(familydir).withBloomType(bloomType).\n-                withFileContext(hFileContext).build();\n+          wl.writer = new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs)\n+            .withOutputDir(familydir).withBloomType(bloomType)\n+            .withFileContext(hFileContext).build();\n         } else {\n-          wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs)).\n-                withOutputDir(familydir).withBloomType(bloomType).\n-                withFileContext(hFileContext).withFavoredNodes(favoredNodes).build();\n+          wl.writer = new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs))\n+            .withOutputDir(familydir).withBloomType(bloomType)\n+            .withFileContext(hFileContext).withFavoredNodes(favoredNodes).build();\n         }\n \n         this.writers.put(tableAndFamily, wl);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDI3Ng==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310276", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:44:24Z", "path": "hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java", "diffHunk": "@@ -424,15 +423,14 @@ private WriterLength getNewWriter(byte[] tableName, byte[] family, Configuration\n         HFileContext hFileContext = contextBuilder.build();\n         if (null == favoredNodes) {\n           wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs)\n-                  .withOutputDir(familydir).withBloomType(bloomType)\n-                  .withComparator(CellComparator.getInstance()).withFileContext(hFileContext).build();\n+              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs).\n+                withOutputDir(familydir).withBloomType(bloomType).\n+                withFileContext(hFileContext).build();\n         } else {\n           wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs))\n-                  .withOutputDir(familydir).withBloomType(bloomType)\n-                  .withComparator(CellComparator.getInstance()).withFileContext(hFileContext)\n-                  .withFavoredNodes(favoredNodes).build();\n+              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs)).\n+                withOutputDir(familydir).withBloomType(bloomType).", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java b/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nindex d855edb305..ab1ede6ba1 100644\n--- a/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\n+++ b/hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\n\n@@ -422,15 +386,13 @@ public class HFileOutputFormat2\n         contextBuilder.withDataBlockEncoding(encoding);\n         HFileContext hFileContext = contextBuilder.build();\n         if (null == favoredNodes) {\n-          wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs).\n-                withOutputDir(familydir).withBloomType(bloomType).\n-                withFileContext(hFileContext).build();\n+          wl.writer = new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, fs)\n+            .withOutputDir(familydir).withBloomType(bloomType)\n+            .withFileContext(hFileContext).build();\n         } else {\n-          wl.writer =\n-              new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs)).\n-                withOutputDir(familydir).withBloomType(bloomType).\n-                withFileContext(hFileContext).withFavoredNodes(favoredNodes).build();\n+          wl.writer = new StoreFileWriter.Builder(conf, CacheConfig.DISABLED, new HFileSystem(fs))\n+            .withOutputDir(familydir).withBloomType(bloomType)\n+            .withFileContext(hFileContext).withFavoredNodes(favoredNodes).build();\n         }\n \n         this.writers.put(tableAndFamily, wl);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDY5NA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310694", "bodyText": "NIT: Usually there should be a whitespace before the :. Thought it is already part of the Checkstyle ruleset.", "author": "HorizonNet", "createdAt": "2020-01-19T17:52:31Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java", "diffHunk": "@@ -361,7 +361,7 @@ static HFileBlock createFromBuff(ByteBuff buf, boolean usesHBaseChecksum, final\n     // This constructor is called when we deserialize a block from cache and when we read a block in\n     // from the fs. fileCache is null when deserialized from cache so need to make up one.\n     HFileContextBuilder fileContextBuilder =\n-        fileContext != null ? new HFileContextBuilder(fileContext) : new HFileContextBuilder();\n+        fileContext != null ? new HFileContextBuilder(fileContext): new HFileContextBuilder();", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMzcwNQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368323705", "bodyText": "I can set these back.", "author": "saintstack", "createdAt": "2020-01-19T21:20:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NDk5OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369154999", "bodyText": "Done", "author": "saintstack", "createdAt": "2020-01-21T17:59:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\nindex 504cc5d31e..ec317e6f8e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\n\n@@ -360,8 +357,8 @@ public class HFileBlock implements Cacheable {\n     final long prevBlockOffset = buf.getLong(Header.PREV_BLOCK_OFFSET_INDEX);\n     // This constructor is called when we deserialize a block from cache and when we read a block in\n     // from the fs. fileCache is null when deserialized from cache so need to make up one.\n-    HFileContextBuilder fileContextBuilder =\n-        fileContext != null ? new HFileContextBuilder(fileContext): new HFileContextBuilder();\n+    HFileContextBuilder fileContextBuilder = fileContext != null ?\n+      new HFileContextBuilder(fileContext) : new HFileContextBuilder();\n     fileContextBuilder.withHBaseCheckSum(usesHBaseChecksum);\n     int onDiskDataSizeWithHeader;\n     if (usesHBaseChecksum) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDc1NA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310754", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:53:47Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java", "diffHunk": "@@ -1827,7 +1827,8 @@ protected HFileBlock readBlockDataInternal(FSDataInputStream is, long offset,\n \n     @Override\n     public void setIncludesMemStoreTS(boolean includesMemstoreTS) {\n-      this.fileContext.setIncludesMvcc(includesMemstoreTS);\n+      this.fileContext = new HFileContextBuilder(this.fileContext).\n+        withIncludesMvcc(includesMemstoreTS).build();", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxNTE1Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368415152", "bodyText": "Do we really need to build new HFileContextBuilder and HFileContext to set?", "author": "anoopsjohn", "createdAt": "2020-01-20T08:21:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDc1NA=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\nindex 504cc5d31e..ec317e6f8e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java\n\n@@ -1827,8 +1810,8 @@ public class HFileBlock implements Cacheable {\n \n     @Override\n     public void setIncludesMemStoreTS(boolean includesMemstoreTS) {\n-      this.fileContext = new HFileContextBuilder(this.fileContext).\n-        withIncludesMvcc(includesMemstoreTS).build();\n+      this.fileContext = new HFileContextBuilder(this.fileContext)\n+        .withIncludesMvcc(includesMemstoreTS).build();\n     }\n \n     @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDkyMg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310922", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:57:03Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java", "diffHunk": "@@ -276,8 +275,8 @@ private Path writeStoreFile() throws IOException {\n     Path storeFileParentDir = new Path(TEST_UTIL.getDataTestDir(), \"TestHFile\");\n     HFileContext meta = new HFileContextBuilder().withBlockSize(64 * 1024).build();\n     StoreFileWriter sfw =\n-        new StoreFileWriter.Builder(conf, fs).withOutputDir(storeFileParentDir)\n-            .withComparator(CellComparatorImpl.COMPARATOR).withFileContext(meta).build();\n+        new StoreFileWriter.Builder(conf, fs).withOutputDir(storeFileParentDir).\n+          withFileContext(meta).build();", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1OTc5MQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369159791", "bodyText": "Done", "author": "saintstack", "createdAt": "2020-01-21T18:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDkyMg=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java\nindex 2d0a23b366..b3010edf3f 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFile.java\n\n@@ -275,8 +275,8 @@ public class TestHFile  {\n     Path storeFileParentDir = new Path(TEST_UTIL.getDataTestDir(), \"TestHFile\");\n     HFileContext meta = new HFileContextBuilder().withBlockSize(64 * 1024).build();\n     StoreFileWriter sfw =\n-        new StoreFileWriter.Builder(conf, fs).withOutputDir(storeFileParentDir).\n-          withFileContext(meta).build();\n+        new StoreFileWriter.Builder(conf, fs).withOutputDir(storeFileParentDir)\n+          .withFileContext(meta).build();\n \n     final int rowLen = 32;\n     Random RNG = new Random();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDkzNA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310934", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:57:16Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderImpl.java", "diffHunk": "@@ -66,9 +65,8 @@ Path makeNewFile() throws IOException {\n     HFileContext context =\n         new HFileContextBuilder().withBlockSize(blocksize).withIncludesTags(true).build();\n     Configuration conf = TEST_UTIL.getConfiguration();\n-    HFile.Writer writer =\n-        HFile.getWriterFactoryNoCache(conf).withOutputStream(fout).withFileContext(context)\n-            .withComparator(CellComparatorImpl.COMPARATOR).create();\n+    HFile.Writer writer = HFile.getWriterFactoryNoCache(conf).\n+      withOutputStream(fout).withFileContext(context).create();", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2MjI5MA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369162290", "bodyText": "I went through the patch and I made all align w/ your suggestions. Thanks @HorizonNet .", "author": "saintstack", "createdAt": "2020-01-21T18:15:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDkzNA=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderImpl.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderImpl.java\nindex 595389e02f..8c3a6329fa 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderImpl.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/io/hfile/TestHFileReaderImpl.java\n\n@@ -65,8 +65,8 @@ public class TestHFileReaderImpl {\n     HFileContext context =\n         new HFileContextBuilder().withBlockSize(blocksize).withIncludesTags(true).build();\n     Configuration conf = TEST_UTIL.getConfiguration();\n-    HFile.Writer writer = HFile.getWriterFactoryNoCache(conf).\n-      withOutputStream(fout).withFileContext(context).create();\n+    HFile.Writer writer = HFile.getWriterFactoryNoCache(conf)\n+      .withOutputStream(fout).withFileContext(context).create();\n     // 4 bytes * 3 * 2 for each key/value +\n     // 3 for keys, 15 for values = 42 (woot)\n     writer.append(toKV(\"c\"));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDk5MQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368310991", "bodyText": "NIT: Most of the time we use a leading ..", "author": "HorizonNet", "createdAt": "2020-01-19T17:58:28Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java", "diffHunk": "@@ -85,36 +89,37 @@\n \n   @Test\n   public void testUsingMetaAndBinary() throws IOException {\n-    FileSystem filesystem = FileSystem.get(conf);\n     Path rootdir = UTIL.getDataTestDirOnTestFS();\n     // Up flush size else we bind up when we use default catalog flush of 16k.\n-    TableDescriptorBuilder metaBuilder = UTIL.getMetaTableDescriptorBuilder()\n-            .setMemStoreFlushSize(64 * 1024 * 1024);\n-\n+    TableDescriptors tds = new FSTableDescriptors(UTIL.getConfiguration());\n+    TableDescriptorBuilder metaBuilder = TableDescriptorBuilder.\n+      newBuilder(tds.get(TableName.META_TABLE_NAME)).setMemStoreFlushSize(64 * 1024 * 1024);\n+    TableDescriptor td = metaBuilder.build();\n     HRegion mr = HBaseTestingUtility.createRegionAndWAL(HRegionInfo.FIRST_META_REGIONINFO,\n-        rootdir, this.conf, metaBuilder.build());\n+        rootdir, this.conf, td);\n     try {\n       // Write rows for three tables 'A', 'B', and 'C'.\n       for (char c = 'A'; c < 'D'; c++) {\n         HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(\"\" + c));\n         final int last = 128;\n         final int interval = 2;\n         for (int i = 0; i <= last; i += interval) {\n-          HRegionInfo hri = new HRegionInfo(htd.getTableName(),\n-            i == 0 ? HConstants.EMPTY_BYTE_ARRAY : Bytes.toBytes((byte) i),\n-            i == last ? HConstants.EMPTY_BYTE_ARRAY : Bytes.toBytes((byte) i + interval));\n-\n+          RegionInfo hri = RegionInfoBuilder.newBuilder(htd.getTableName()).\n+            setStartKey(i == 0? HConstants.EMPTY_BYTE_ARRAY: Bytes.toBytes((byte)i)).", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMzY2MA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368323660", "bodyText": "Smile. I like the trailing '.'. Makes you keep reading to see what is next. IIRC, I got it from the effective java book. I should see what is in our coding template.", "author": "saintstack", "createdAt": "2020-01-19T21:19:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY0Mzg3Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368643872", "bodyText": "Back again...\nLet me do as you suggest both here and above where you state 'Most of the time we use a ...'. Onus is on me to put in place checkstyle rules if I want to go against precedent ('Most of the time...'). Thanks for reviews.", "author": "saintstack", "createdAt": "2020-01-20T16:45:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2MDg1OA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369160858", "bodyText": "Implemented.", "author": "saintstack", "createdAt": "2020-01-21T18:12:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMDk5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java\nindex 316cd35b9a..f7eb397a2f 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestGetClosestAtOrBefore.java\n\n@@ -104,10 +104,10 @@ public class TestGetClosestAtOrBefore  {\n         final int last = 128;\n         final int interval = 2;\n         for (int i = 0; i <= last; i += interval) {\n-          RegionInfo hri = RegionInfoBuilder.newBuilder(htd.getTableName()).\n-            setStartKey(i == 0? HConstants.EMPTY_BYTE_ARRAY: Bytes.toBytes((byte)i)).\n-            setEndKey(i == last? HConstants.EMPTY_BYTE_ARRAY: Bytes.toBytes((byte)i + interval)).\n-            build();\n+          RegionInfo hri = RegionInfoBuilder.newBuilder(htd.getTableName())\n+            .setStartKey(i == 0 ? HConstants.EMPTY_BYTE_ARRAY : Bytes.toBytes((byte)i))\n+            .setEndKey(i == last ? HConstants.EMPTY_BYTE_ARRAY :\n+              Bytes.toBytes((byte)i + interval)).build();\n           Put put =\n             MetaTableAccessor.makePutFromRegionInfo(hri, EnvironmentEdgeManager.currentTime());\n           put.setDurability(Durability.SKIP_WAL);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwNTE5Ng==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368405196", "bodyText": "The BB passed here contain only the row bytes? The BB is sliced for row alone?", "author": "anoopsjohn", "createdAt": "2020-01-20T07:50:45Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java", "diffHunk": "@@ -80,6 +83,24 @@ static CellComparator getInstance() {\n    */\n   int compareRows(Cell cell, byte[] bytes, int offset, int length);\n \n+  /**\n+   * @param row ByteBuffer that wraps a row; will read from current position and will reading all\n+   *            remaining; will not disturb the ByteBuffer internal state.\n+   * @return greater than 0 if leftCell is bigger, less than 0 if rightCell is bigger, 0 if both\n+   *         cells are equal\n+   */\n+  default int compareRows(ByteBuffer row, Cell cell) {", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYwNDk5OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368604999", "bodyText": "Yes.\nJavadoc tries to make this explicit. Should I add more?\n\"    * @param row ByteBuffer that wraps a row; will read from current position and will reading all\n*            remaining; will not disturb the ByteBuffer internal state.\"", "author": "saintstack", "createdAt": "2020-01-20T15:27:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwNTE5Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwOTYxNQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368409615", "bodyText": "I see. This method is moved to CellComparator. Is that required? This impl here correctly handle things. Within the BBUtils we are handling HBB/DBB. But in this patch, it is trying to handle in CellComparator which is not good IMHO.\nAlso within this context we know the passed row BB is sliced for the rk bytes alone. Within CellComparator we can not have such assumption. So its better to keep it here only.  I believe only this class is having such need for compares. Any other place?", "author": "anoopsjohn", "createdAt": "2020-01-20T08:05:49Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java", "diffHunk": "@@ -154,19 +153,6 @@ private int binarySearch(Cell seekCell, boolean seekBefore) {\n     }\n   }\n \n-  private int compareRows(ByteBuffer row, Cell seekCell) {", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxMDU2Nw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368610567", "bodyText": "We can't have encoders doing their own logic figuring Cell Compare else the issue this patch fixes will perpetually haunt us as encoding implementors make the same mistake of around comparators over and over again; i.e. presuming only one comparator in the system or knowing there are two at least but defaulting to user-space comparator since that is what is used 99.9% of the time.\nCellComparator already has methods that do row compare. This is just adding one that hosts the row in ByteBuffer instead of an array... an override.\nCellComparators need to do more ByteBuffering, not less. CellComparator needs to learn how to do compares w/o making copies of the ByteBuffer content as it currently does in BBUtills if the BB doesn't have an array because  comparators don't know how to stride through a ByteBuffer.\nbq. Also within this context we know the passed row BB is sliced for the rk bytes alone. Within CellComparator we can not have such assumption.\nCellComparator has one method that does this already taking an array.", "author": "saintstack", "createdAt": "2020-01-20T15:38:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwOTYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1MzQ1MA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368653450", "bodyText": "I understood ur arg now.  Make sense...  The MetaCellComparator was doing on heap copy. So ur impl there is ok as of now. May be we can see whether we can avoid some of those. But can be another jira.  +1 for doing this way boss.", "author": "anoopsjohn", "createdAt": "2020-01-20T17:06:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwOTYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1NzE3Mw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368657173", "bodyText": "Thanks @anoopsjohn\nWill put up new patch that implements your suggestions and those of @HorizonNet", "author": "saintstack", "createdAt": "2020-01-20T17:16:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQwOTYxNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMDM0MQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368410341", "bodyText": "This I like :-)  Our best effort to make things work.", "author": "anoopsjohn", "createdAt": "2020-01-20T08:07:59Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java", "diffHunk": "@@ -114,6 +118,11 @@ public HFileContext(HFileContext context) {\n     this.hfileName = hfileName;\n     this.columnFamily = columnFamily;\n     this.tableName = tableName;\n+    // If no cellComparator specified, make a guess based off tablename. If hbase:meta, then should\n+    // be the meta table comparator. Comparators are per table.\n+    this.cellComparator = cellComparator != null? cellComparator:\n+      this.tableName != null? CellComparatorImpl.getCellComparator(this.tableName):", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\nindex 17e8a44f16..ea4782d035 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n\n@@ -120,14 +120,12 @@ public class HFileContext implements HeapSize, Cloneable {\n     this.tableName = tableName;\n     // If no cellComparator specified, make a guess based off tablename. If hbase:meta, then should\n     // be the meta table comparator. Comparators are per table.\n-    this.cellComparator = cellComparator != null? cellComparator:\n-      this.tableName != null? CellComparatorImpl.getCellComparator(this.tableName):\n-        CellComparator.getInstance();\n+    this.cellComparator = cellComparator != null ? cellComparator : this.tableName != null ?\n+      CellComparatorImpl.getCellComparator(this.tableName) : CellComparator.getInstance();\n   }\n \n   /**\n-   * @return true when on-disk blocks from this file are compressed, and/or encrypted;\n-   * false otherwise.\n+   * @return true when on-disk blocks are compressed, and/or encrypted; false otherwise.\n    */\n   public boolean isCompressedOrEncrypted() {\n     Compression.Algorithm compressAlgo = getCompression();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMTAxOQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368411019", "bodyText": "Can we just use TableName.isMetaTableName(TableName) here?  Why to have the indirection of toBytes and then compare bytes?", "author": "anoopsjohn", "createdAt": "2020-01-20T08:09:44Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java", "diffHunk": "@@ -387,4 +409,23 @@ public Comparator getSimpleComparator() {\n   public Comparator getSimpleComparator() {\n     return new BBKVComparator(this);\n   }\n+\n+  /**\n+   * Utility method that makes a guess at comparator to use based off passed tableName.\n+   * Use in extreme when no comparator specified.\n+   * @return CellComparator to use going off the <code>tableName</code> passed.\n+   */\n+  public static CellComparator getCellComparator(TableName tableName) {\n+    return getCellComparator(tableName.toBytes());", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxMTU4Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368611582", "bodyText": "Need both. In actual filecontext, it hosts tablename as bytes only -- not as a TableName object. The TableName.toBytes doesn't actually make bytes. TN itself hosts the name in bytes.\nMaybe I should be clearer in a comment that no new arrays are being made in this code?", "author": "saintstack", "createdAt": "2020-01-20T15:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMTAxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\nindex 5da45594ef..e6c8e3ded6 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n\n@@ -413,7 +410,7 @@ public class CellComparatorImpl implements CellComparator {\n   /**\n    * Utility method that makes a guess at comparator to use based off passed tableName.\n    * Use in extreme when no comparator specified.\n-   * @return CellComparator to use going off the <code>tableName</code> passed.\n+   * @return CellComparator to use going off the {@code tableName} passed.\n    */\n   public static CellComparator getCellComparator(TableName tableName) {\n     return getCellComparator(tableName.toBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMzE3OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368413179", "bodyText": "With out this also (with below way of get class based on the name) it will work? U just added a short circuit here? Or u fixing some issue here with below getComparatorClass(comparatorClassName)?", "author": "anoopsjohn", "createdAt": "2020-01-20T08:16:26Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java", "diffHunk": "@@ -624,19 +624,22 @@ private String getHBase1CompatibleName(final String comparator) {\n     return comparatorKlass;\n   }\n \n-  public static CellComparator createComparator(\n-      String comparatorClassName) throws IOException {\n+  static CellComparator createComparator(String comparatorClassName) throws IOException {\n+    if (comparatorClassName.equals(CellComparatorImpl.COMPARATOR.getClass().getName())) {\n+      return CellComparatorImpl.COMPARATOR;\n+    } else if (comparatorClassName.equals(\n+        CellComparatorImpl.META_COMPARATOR.getClass().getName())) {\n+      return CellComparatorImpl.META_COMPARATOR;\n+    }", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ0MDU0OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368440549", "bodyText": "I think it is to avoid the reflections call if possible", "author": "ramkrish86", "createdAt": "2020-01-20T09:23:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMzE3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxMjIzMg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368612232", "bodyText": "Just to avoid the reflection in near all cases.", "author": "saintstack", "createdAt": "2020-01-20T15:41:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMzE3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "4ffef9839fae0fd1c41f16515af67b73ca1d6d52", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\nindex d75dc9c1f2..35fb2818e6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n\n@@ -628,7 +636,7 @@ public class FixedFileTrailer {\n     if (comparatorClassName.equals(CellComparatorImpl.COMPARATOR.getClass().getName())) {\n       return CellComparatorImpl.COMPARATOR;\n     } else if (comparatorClassName.equals(\n-        CellComparatorImpl.META_COMPARATOR.getClass().getName())) {\n+      CellComparatorImpl.META_COMPARATOR.getClass().getName())) {\n       return CellComparatorImpl.META_COMPARATOR;\n     }\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMzU0Mw==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368413543", "bodyText": "So here the comparator class name will be passed within the fileContext from upper layers. Good.", "author": "anoopsjohn", "createdAt": "2020-01-20T08:17:31Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java", "diffHunk": "@@ -319,7 +312,7 @@ public Writer create() throws IOException {\n           LOG.debug(\"Unable to set drop behind on {}\", path.getName());\n         }\n       }\n-      return new HFileWriterImpl(conf, cacheConf, path, ostream, comparator, fileContext);\n+      return new HFileWriterImpl(conf, cacheConf, path, ostream, fileContext);", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxMzM2OQ==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368613369", "bodyText": "Yes sir. Idea is that there is one place to get comparator to use. Before this patch, comparator was passed down most of the time but in encoder context and elsewhere in a few locations, comparator was hardcoded because not passed from above.", "author": "saintstack", "createdAt": "2020-01-20T15:44:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxMzU0Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxNTc2NA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368415764", "bodyText": "Better to have a trailer.getComparator() which internally do this create?", "author": "anoopsjohn", "createdAt": "2020-01-20T08:23:42Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java", "diffHunk": "@@ -380,7 +386,8 @@ private HFileContext createHFileContext(Path path,\n     HFileContextBuilder builder = new HFileContextBuilder()\n       .withHBaseCheckSum(true)\n       .withHFileName(path.getName())\n-      .withCompression(trailer.getCompressionCodec());\n+      .withCompression(trailer.getCompressionCodec())\n+      .withCellComparator(trailer.createComparator(trailer.getComparatorClassName()));", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxNTU2NA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368615564", "bodyText": "I want to keep context immutable so it is safe to use in any context. It is why I removed the setter methods. I think it fine building a new one here rather than reuse. Its once per file reader open. Seems fine.\nLet me add your getCellComparator suggestion.", "author": "saintstack", "createdAt": "2020-01-20T15:48:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxNTc2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1ODUxOA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r369158518", "bodyText": "Hmm... Its a static. createComparator is probably right name here...", "author": "saintstack", "createdAt": "2020-01-21T18:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQxNTc2NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQzOTk4Mg==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368439982", "bodyText": "I too agree to @anoopsjohn . Seems we deliberately left this compareRows() here. Is there a similar compareRows in every encoder?", "author": "ramkrish86", "createdAt": "2020-01-20T09:21:56Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java", "diffHunk": "@@ -131,8 +131,7 @@ private int binarySearch(Cell seekCell, boolean seekBefore) {\n     int comp = 0;\n     while (low <= high) {\n       mid = low + ((high - low) >> 1);\n-      ByteBuffer row = getRow(mid);\n-      comp = compareRows(row, seekCell);\n+      comp = this.cellComparator.compareRows(getRow(mid), seekCell);", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxNTExOA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368615118", "bodyText": "There is a similar array-based compare rows in CellComparator.\nSee above for my argument that encoders should not each have to do their own figuring of cell compare.\nNotice how much cleaner the code in here is now?", "author": "saintstack", "createdAt": "2020-01-20T15:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQzOTk4Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ0MzE2NA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368443164", "bodyText": "So every where it comes from the context only including for the blooms", "author": "ramkrish86", "createdAt": "2020-01-20T09:28:21Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java", "diffHunk": "@@ -135,14 +132,16 @@ private StoreFileWriter(FileSystem fs, Path path, final Configuration conf, Cach\n       // init bloom context\n       switch (bloomType) {\n         case ROW:\n-          bloomContext = new RowBloomContext(generalBloomFilterWriter, comparator);\n+          bloomContext =\n+            new RowBloomContext(generalBloomFilterWriter, fileContext.getCellComparator());\n           break;\n         case ROWCOL:\n-          bloomContext = new RowColBloomContext(generalBloomFilterWriter, comparator);\n+          bloomContext =\n+            new RowColBloomContext(generalBloomFilterWriter, fileContext.getCellComparator());", "originalCommit": "f45287b27aae2cece0959ba69b9e2ba02dc19982", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYxNTM1MA==", "url": "https://github.com/apache/hbase/pull/1062#discussion_r368615350", "bodyText": "Yes sir. One place only instead of hardcodings and guesses at which to use.", "author": "saintstack", "createdAt": "2020-01-20T15:48:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ0MzE2NA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "cc691c7b79f1fcc9b7945a0e784abddd72432e98", "url": "https://github.com/apache/hbase/commit/cc691c7b79f1fcc9b7945a0e784abddd72432e98", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-21T21:01:55Z", "type": "forcePushed"}, {"oid": "3f229b18dbceb5a6688e1067305477e96368dcdd", "url": "https://github.com/apache/hbase/commit/3f229b18dbceb5a6688e1067305477e96368dcdd", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-21T23:23:52Z", "type": "forcePushed"}, {"oid": "4ffef9839fae0fd1c41f16515af67b73ca1d6d52", "url": "https://github.com/apache/hbase/commit/4ffef9839fae0fd1c41f16515af67b73ca1d6d52", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-22T07:15:17Z", "type": "commit"}, {"oid": "4ffef9839fae0fd1c41f16515af67b73ca1d6d52", "url": "https://github.com/apache/hbase/commit/4ffef9839fae0fd1c41f16515af67b73ca1d6d52", "message": "HBASE-23705 Add CellComparator to HFileContext\n\nCodecs don't have access to what CellComparator to use.  Backfill.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n Adds a new compareRows with default implementation that takes a ByteBuffer.\n Needed by the index in a block encoder implementation.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparatorImpl.java\n Adds implementation for meta of new compareRows method. Adds utility\n method for figuring comparator based off tablename.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/AbstractDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexCodecV1.java\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexSeekerV1.java\n Comparator is in context. Remove redundant handling.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java\n Comparator is in context. Remove redundant handling. Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\n Clean javadoc.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/RowIndexEncoderV1.java\n Cache context so can use it to get comparator to use later.\n\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n Cache cellcomparator to use. Javdoc on diff between HFileContext and\n HFileInfo.\nM hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java\n Add CellComparator\n\nM hbase-mapreduce/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterImpl.java\nM hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java\n Remove comparator caching. Get from context instead.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java\n Skip a reflection if we can.\n\nM hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\n Javadoc. Removed unused filed.", "committedDate": "2020-01-22T07:15:17Z", "type": "forcePushed"}]}