{"pr_number": 2614, "pr_title": "HBASE-25216 The client zk syncer should deal with meta replica count \u2026", "pr_createdAt": "2020-11-02T03:55:15Z", "pr_url": "https://github.com/apache/hbase/pull/2614", "timeline": [{"oid": "4387a8ddbde5ed4f764fbfa9e308008055077c24", "url": "https://github.com/apache/hbase/commit/4387a8ddbde5ed4f764fbfa9e308008055077c24", "message": "HBASE-25216 The client zk syncer should deal with meta replica count change", "committedDate": "2020-11-02T07:17:25Z", "type": "forcePushed"}, {"oid": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15", "url": "https://github.com/apache/hbase/commit/8ad90d35a2b992ab88a3f7b00fc75b5602426a15", "message": "HBASE-25216 The client zk syncer should deal with meta replica count change", "committedDate": "2020-11-02T13:22:49Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjczNjA4Mw==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516736083", "bodyText": "The newly introduced ZKData structure is more efficient, shall we update the comments here and add some javadoc for the ZKData class?", "author": "carp84", "createdAt": "2020-11-03T15:06:21Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "diffHunk": "@@ -34,30 +33,69 @@\n import org.apache.yetus.audience.InterfaceAudience;\n import org.apache.zookeeper.CreateMode;\n import org.apache.zookeeper.KeeperException;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n  * Tracks the target znode(s) on server ZK cluster and synchronize them to client ZK cluster if\n  * changed\n  * <p/>\n- * The target znode(s) is given through {@link #getNodesToWatch()} method\n+ * The target znode(s) is given through {@link #getPathsToWatch()} method\n  */\n @InterfaceAudience.Private\n public abstract class ClientZKSyncer extends ZKListener {\n   private static final Logger LOG = LoggerFactory.getLogger(ClientZKSyncer.class);\n   private final Server server;\n   private final ZKWatcher clientZkWatcher;\n+\n+  private static final class ZKData {\n+\n+    byte[] data;\n+\n+    boolean delete = false;\n+\n+    synchronized void set(byte[] data) {\n+      this.data = data;\n+      notifyAll();\n+    }\n+\n+    synchronized byte[] get() throws InterruptedException {\n+      while (!delete && data == null) {\n+        wait();\n+      }\n+      byte[] d = data;\n+      data = null;\n+      return d;\n+    }\n+\n+    synchronized void delete() {\n+      this.delete = true;\n+      notifyAll();\n+    }\n+\n+    synchronized boolean isDeleted() {\n+      return delete;\n+    }\n+  }\n+\n   // We use queues and daemon threads to synchronize the data to client ZK cluster", "originalCommit": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4f29e809372ab3c6d1e1c08724b5361e12403c7e", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\nindex 1b88b025f2..51208e37d4 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\n\n@@ -48,6 +48,12 @@ public abstract class ClientZKSyncer extends ZKListener {\n   private final Server server;\n   private final ZKWatcher clientZkWatcher;\n \n+  /**\n+   * Used to store the newest data which we want to sync to client zk.\n+   * <p/>\n+   * For meta location, since we may reduce the replica number, so here we add a {@code delete} flag\n+   * to tell the updater delete the znode on client zk and quit.\n+   */\n   private static final class ZKData {\n \n     byte[] data;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjEwMA==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516742100", "bodyText": "So we choose not to reconnect if there are some issue on network stability that cause zookeeper connection loss? And it seems the reconnectAfterExpiration is not following the same handling on line 173-174", "author": "carp84", "createdAt": "2020-11-03T15:14:24Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java", "diffHunk": "@@ -145,8 +177,7 @@ private final void setDataForClientZkUntilSuccess(String node, byte[] data)\n           LOG.warn(\n             \"Failed to create znode \" + node + \" due to: \" + e.getMessage() + \", will retry later\");\n         }\n-      } catch (KeeperException.ConnectionLossException\n-          | KeeperException.SessionExpiredException ee) {\n+      } catch (KeeperException.SessionExpiredException see) {", "originalCommit": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3NzgwNQ==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517077805", "bodyText": "ConnectionLoss just means the connection is broken, the zk library will reconnect automatically to resume the session if possible.", "author": "Apache9", "createdAt": "2020-11-04T03:26:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjEwMA=="}], "type": "inlineReview", "revised_code": {"commit": "4f29e809372ab3c6d1e1c08724b5361e12403c7e", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\nindex 1b88b025f2..51208e37d4 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/zksyncer/ClientZKSyncer.java\n\n@@ -159,28 +165,28 @@ public abstract class ClientZKSyncer extends ZKListener {\n    * @throws InterruptedException if the thread is interrupted during process\n    */\n   private void setDataForClientZkUntilSuccess(String node, byte[] data)\n-      throws InterruptedException {\n+    throws InterruptedException {\n+    boolean create = false;\n     while (!server.isStopped()) {\n       try {\n         LOG.debug(\"Set data for remote \" + node + \", client zk wather: \" + clientZkWatcher);\n-        ZKUtil.setData(clientZkWatcher, node, data);\n-        break;\n-      } catch (KeeperException.NoNodeException nne) {\n-        // Node doesn't exist, create it and set value\n-        try {\n+        if (create) {\n           ZKUtil.createNodeIfNotExistsNoWatch(clientZkWatcher, node, data, CreateMode.PERSISTENT);\n-          break;\n-        } catch (KeeperException.ConnectionLossException\n-            | KeeperException.SessionExpiredException ee) {\n-          reconnectAfterExpiration();\n-        } catch (KeeperException e) {\n-          LOG.warn(\n-            \"Failed to create znode \" + node + \" due to: \" + e.getMessage() + \", will retry later\");\n+        } else {\n+          ZKUtil.setData(clientZkWatcher, node, data);\n         }\n-      } catch (KeeperException.SessionExpiredException see) {\n-        reconnectAfterExpiration();\n+        break;\n       } catch (KeeperException e) {\n-        LOG.debug(\"Failed to set data to client ZK, will retry later\", e);\n+        LOG.debug(\"Failed to set data for {} to client ZK, will retry later\", node, e);\n+        if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n+          reconnectAfterExpiration();\n+        }\n+        if (e.code() == KeeperException.Code.NONODE) {\n+          create = true;\n+        }\n+        if (e.code() == KeeperException.Code.NODEEXISTS) {\n+          create = false;\n+        }\n       }\n       Threads.sleep(HConstants.SOCKET_RETRY_WAIT_MS);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r516745626", "bodyText": "Maybe adding more logics to verify the ClientZKSyncer is working well when meta replica changes, especially when reducing from multiple to single replica?", "author": "carp84", "createdAt": "2020-11-03T15:19:08Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java", "diffHunk": "@@ -255,7 +260,20 @@ public void testAsyncTable() throws Exception {\n       Get get = new Get(row);\n       Result result = table.get(get).get();\n       LOG.debug(\"Result: \" + Bytes.toString(result.getValue(family, qualifier)));\n-      Assert.assertArrayEquals(value, result.getValue(family, qualifier));\n+      assertArrayEquals(value, result.getValue(family, qualifier));\n+    }\n+  }\n+\n+  @Test\n+  public void testChangeMetaReplicaCount() throws Exception {", "originalCommit": "8ad90d35a2b992ab88a3f7b00fc75b5602426a15", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3ODA3NA==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517078074", "bodyText": "In the test we increase from 1 to 3, and then reduce back to 2, you mean we should add one more assert to reduce to 1?", "author": "Apache9", "createdAt": "2020-11-04T03:27:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1ODMxMg==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517158312", "bodyText": "Yes, and it seems the test now didn't test any ClientZKSyncer logics, like if the client could still correctly access meta through client ZK, but checks against meta region locator?", "author": "carp84", "createdAt": "2020-11-04T08:06:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2MTE2NA==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517161164", "bodyText": "RegionLocator will go to ConnectionRegistry to ask for the meta locations and we have already set the ConnectionRegistry to ZKConnectionRegistry against the client zk in the setup method, so it is testing the ClientZKSyncer logics, you could try comment out the set data logic in ClientZKSyncer, the test will fail with timeout...", "author": "Apache9", "createdAt": "2020-11-04T08:12:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2NDI1MQ==", "url": "https://github.com/apache/hbase/pull/2614#discussion_r517164251", "bodyText": "ok, got it, makes sense. Thanks for the clarification.", "author": "carp84", "createdAt": "2020-11-04T08:18:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTYyNg=="}], "type": "inlineReview", "revised_code": {"commit": "4f29e809372ab3c6d1e1c08724b5361e12403c7e", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java\nindex 2d2e9c827b..7fc9552345 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestSeparateClientZKCluster.java\n\n@@ -274,6 +274,8 @@ public class TestSeparateClientZKCluster {\n       TEST_UTIL.waitFor(30000, () -> locator.getAllRegionLocations().size() == 3);\n       HBaseTestingUtility.setReplicas(admin, TableName.META_TABLE_NAME, 2);\n       TEST_UTIL.waitFor(30000, () -> locator.getAllRegionLocations().size() == 2);\n+      HBaseTestingUtility.setReplicas(admin, TableName.META_TABLE_NAME, 1);\n+      TEST_UTIL.waitFor(30000, () -> locator.getAllRegionLocations().size() == 1);\n     }\n   }\n }\n"}}, {"oid": "4f29e809372ab3c6d1e1c08724b5361e12403c7e", "url": "https://github.com/apache/hbase/commit/4f29e809372ab3c6d1e1c08724b5361e12403c7e", "message": "HBASE-25216 The client zk syncer should deal with meta replica count change", "committedDate": "2020-11-04T03:48:13Z", "type": "commit"}, {"oid": "4f29e809372ab3c6d1e1c08724b5361e12403c7e", "url": "https://github.com/apache/hbase/commit/4f29e809372ab3c6d1e1c08724b5361e12403c7e", "message": "HBASE-25216 The client zk syncer should deal with meta replica count change", "committedDate": "2020-11-04T03:48:13Z", "type": "forcePushed"}]}