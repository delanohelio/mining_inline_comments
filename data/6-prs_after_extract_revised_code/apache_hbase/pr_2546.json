{"pr_number": 2546, "pr_title": "HBASE-24813 ReplicationSource should clear buffer usage on Replicatio\u2026", "pr_createdAt": "2020-10-14T18:09:24Z", "pr_url": "https://github.com/apache/hbase/pull/2546", "timeline": [{"oid": "8c49c1bc175c58bd62c857eb3863ddefbc552469", "url": "https://github.com/apache/hbase/commit/8c49c1bc175c58bd62c857eb3863ddefbc552469", "message": "HBASE-24813 ReplicationSource should clear buffer usage on ReplicationSourceManager upon termination (rebased after HBASE-25117)", "committedDate": "2020-10-14T18:07:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTE5NjcyNA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r505196724", "bodyText": "If move \"stop\" here, the HBASE-25117 problem still exist?", "author": "infraio", "createdAt": "2020-10-15T06:24:54Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java", "diffHunk": "@@ -712,8 +707,14 @@ public void terminate(String reason, Exception cause, boolean clearMetrics,\n           worker.entryReader.interrupt();\n         }\n       }\n+      //If worker is already stopped but there was still entries batched,\n+      //we need to clear buffer used for non processed entries\n+      worker.clearWALEntryBatch();\n     }\n \n+    if (this.replicationEndpoint != null) {\n+      this.replicationEndpoint.stop();", "originalCommit": "8c49c1bc175c58bd62c857eb3863ddefbc552469", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY0MTE3NA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r507641174", "bodyText": "Nope, you are right. This ended up here while resolving the conflicts. Let me move it prior to the block stopping the workers.", "author": "wchevreuil", "createdAt": "2020-10-19T10:31:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTE5NjcyNA=="}], "type": "inlineReview", "revised_code": {"commit": "af8166f4548a19cb29f405ff716905498680791d", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\nindex c1ddf9f67f..d9ac8cb84a 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\n\n@@ -712,9 +717,6 @@ public class ReplicationSource implements ReplicationSourceInterface {\n       worker.clearWALEntryBatch();\n     }\n \n-    if (this.replicationEndpoint != null) {\n-      this.replicationEndpoint.stop();\n-    }\n     if (join) {\n       for (ReplicationSourceShipper worker : workers) {\n         Threads.shutdown(worker, this.sleepForRetries);\n"}}, {"oid": "af8166f4548a19cb29f405ff716905498680791d", "url": "https://github.com/apache/hbase/commit/af8166f4548a19cb29f405ff716905498680791d", "message": "addressing Guanghao's comments", "committedDate": "2020-10-19T10:30:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk5ODg0Nw==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r519998847", "bodyText": "please add if (LOG.isTrace) { LOG.trace..}", "author": "esteban", "createdAt": "2020-11-09T17:42:11Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch: {}\",\n+          this.source.getPeerId(), this.getName(), e);\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+    LongAccumulator totalToDecrement = new LongAccumulator((a,b) -> a + b, 0);\n+    entryReader.entryBatchQueue.forEach(w -> {\n+      entryReader.entryBatchQueue.remove(w);\n+      w.getWalEntries().forEach(e -> {\n+        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n+      });\n+    });\n+\n+    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",", "originalCommit": "8c49c1bc175c58bd62c857eb3863ddefbc552469", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAwMzQ4Mg==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520003482", "bodyText": "Shouldn't be just INFO? Also, I think it might be better tho handle those InterruptedException inside ReplicationSource.terminate().", "author": "esteban", "createdAt": "2020-11-09T17:49:32Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch: {}\",\n+          this.source.getPeerId(), this.getName(), e);\n+        Thread.currentThread().interrupt();", "originalCommit": "8c49c1bc175c58bd62c857eb3863ddefbc552469", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc2MzAwNQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520763005", "bodyText": "Left as WARN because it aborts the flow without effectively updating the buffer usage, which is the fundamental issue we are trying to solve here.", "author": "wchevreuil", "createdAt": "2020-11-10T18:01:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAwMzQ4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjI2OA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520332268", "bodyText": "If a worker is doing some async work when it is asked to stop and can take time. then I think we should keep the implementation as it was done before, like ask all to stop at once and then wait. because if no. of workers gets large due to backlog and someone changes wait time config to 10s of seconds, then removePeer command/procedure has to wait for a long time (no. of workers * (sleep time + time for clearWalEntryBatch) ) to terminate the replication source.", "author": "ankitsinghal", "createdAt": "2020-11-10T06:58:24Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java", "diffHunk": "@@ -684,17 +684,17 @@ public void terminate(String reason, Exception cause, boolean clearMetrics,\n       Threads.shutdown(initThread, this.sleepForRetries);\n     }\n     Collection<ReplicationSourceShipper> workers = workerThreads.values();\n-    for (ReplicationSourceShipper worker : workers) {\n-      worker.stopWorker();\n-      if(worker.entryReader != null) {\n-        worker.entryReader.setReaderRunning(false);\n-      }\n-    }\n+\n \n     if (this.replicationEndpoint != null) {\n       this.replicationEndpoint.stop();\n     }\n+\n     for (ReplicationSourceShipper worker : workers) {\n+      worker.stopWorker();\n+      if (worker.entryReader != null) {\n+        worker.entryReader.setReaderRunning(false);", "originalCommit": "af8166f4548a19cb29f405ff716905498680791d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgwNjY5OA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520806698", "bodyText": "Sorry, I'm not following your concern here. I don't see how the extra loop in the same method context just setting two a flag in the shipper and other in the reader can help with the contention scenario described, terminate execution would be stuck in the second for loop anyways.", "author": "wchevreuil", "createdAt": "2020-11-10T19:04:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjI2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk5OTA1OQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520999059", "bodyText": "sure, let me try to explain again.\nI was referring to restore this loop.\nfor (ReplicationSourceShipper worker : workers) {\t\n      worker.stopWorker();\t\n      if(worker.entryReader != null) {\t\n        worker.entryReader.setReaderRunning(false);\t\n      }\t\n    }\n\nAs your current flow is stopping the worker in a linear manner:-\n\nStop a worker\nwait for the worker thread to complete.\nstop another worker\nwait for it finishes\ncontinue for others......\nSo in the worst case, you would have to wait for the number of workers * min(time taken by the worker to finish, timeout)\n\nthough by restoring the old loop, you are parallelizing the stopping of the workers.\n\nask all worker threads to finish their work by setting their state.\nthen in the second loop, wait for each worker to finish, while you are waiting for 1 worker, others are also completing their work in parallel.\nso when you are done with one worker it is possible that all other workers are also done.", "author": "ankitsinghal", "createdAt": "2020-11-11T01:34:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjI2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTExNQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r521449115", "bodyText": "Got you, thanks for explaining in more details. Will address it on next commit.", "author": "wchevreuil", "createdAt": "2020-11-11T15:44:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjI2OA=="}], "type": "inlineReview", "revised_code": {"commit": "8e5c77b4e70c08b012d010ea4207dd9399a95deb", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\nindex d9ac8cb84a..eb6bf2a4b0 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java\n\n@@ -685,16 +685,18 @@ public class ReplicationSource implements ReplicationSourceInterface {\n     }\n     Collection<ReplicationSourceShipper> workers = workerThreads.values();\n \n+    for (ReplicationSourceShipper worker : workers) {\n+      worker.stopWorker();\n+      if(worker.entryReader != null) {\n+        worker.entryReader.setReaderRunning(false);\n+      }\n+    }\n \n     if (this.replicationEndpoint != null) {\n       this.replicationEndpoint.stop();\n     }\n \n     for (ReplicationSourceShipper worker : workers) {\n-      worker.stopWorker();\n-      if (worker.entryReader != null) {\n-        worker.entryReader.setReaderRunning(false);\n-      }\n       if (worker.isAlive() || worker.entryReader.isAlive()) {\n         try {\n           // Wait worker to stop\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM2MDMxMQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520360311", "bodyText": "It is a best practice to avoid Collection.remove(object) while iterating, to be agnostic to collection's iterator implementation as some can throw ConcurrentModificationException in such a scenario, instead use Iterator.remove()", "author": "ankitsinghal", "createdAt": "2020-11-10T08:03:08Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch: {}\",\n+          this.source.getPeerId(), this.getName(), e);\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+    LongAccumulator totalToDecrement = new LongAccumulator((a,b) -> a + b, 0);\n+    entryReader.entryBatchQueue.forEach(w -> {\n+      entryReader.entryBatchQueue.remove(w);", "originalCommit": "af8166f4548a19cb29f405ff716905498680791d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgwNjYwNg==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520806606", "bodyText": "Right. We are not referring Collection here, but BlockingQueue, which defines it's own remove. Personally, I would rather leave the lambda iteration, then change to for loop over iterator. Could alternatively use an additional list, but sounds too much for the sake of style.", "author": "wchevreuil", "createdAt": "2020-11-10T19:04:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM2MDMxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMTMzMQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r521031331", "bodyText": "As BlockingQueue is also a collection and it depends upon whether the Iterator(used by foreach) in the implementation of the blocking queue allows structural change while iterating or not.\nIt seems BlockingQueue implementation has only weakly consistent iterators(and doesn't throw ConcurrentModificationException) and guaranteed to return all elements as they existed during iterator creation , so we should be fine here.", "author": "ankitsinghal", "createdAt": "2020-11-11T02:22:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM2MDMxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM2MzEwOA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520363108", "bodyText": "we may also need to update global metric (tracking memory used for these edits ) here\nlong   newBufferUsed = source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue()); \nsource.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);", "author": "ankitsinghal", "createdAt": "2020-11-10T08:08:36Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch: {}\",\n+          this.source.getPeerId(), this.getName(), e);\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+    LongAccumulator totalToDecrement = new LongAccumulator((a,b) -> a + b, 0);\n+    entryReader.entryBatchQueue.forEach(w -> {\n+      entryReader.entryBatchQueue.remove(w);\n+      w.getWalEntries().forEach(e -> {\n+        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n+      });\n+    });\n+\n+    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+      totalToDecrement.longValue());\n+    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());", "originalCommit": "af8166f4548a19cb29f405ff716905498680791d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM4NzMzNQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520387335", "bodyText": "nit: refer Static Method using classname, ReplicationSourceWALReader. getEntrySizeExcludeBulkLoad()", "author": "ankitsinghal", "createdAt": "2020-11-10T08:48:53Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch: {}\",\n+          this.source.getPeerId(), this.getName(), e);\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+    LongAccumulator totalToDecrement = new LongAccumulator((a,b) -> a + b, 0);\n+    entryReader.entryBatchQueue.forEach(w -> {\n+      entryReader.entryBatchQueue.remove(w);\n+      w.getWalEntries().forEach(e -> {\n+        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);", "originalCommit": "af8166f4548a19cb29f405ff716905498680791d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5ODg0NQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520398845", "bodyText": "why do we need additional interrupt here when ReplicationSource.terminate() is already interrupted the worker thread prior to clearWALEntryBatch method call?", "author": "ankitsinghal", "createdAt": "2020-11-10T09:07:09Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,53 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n+            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop.\", this.source.getPeerId());\n+          Thread.currentThread().interrupt();", "originalCommit": "af8166f4548a19cb29f405ff716905498680791d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc1MzczNQ==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r520753735", "bodyText": "We are just interrupting if either shipper or reader thread is still alive. We can't guarantee that the caller will always have stopped these threads, therefore, the extra check here.", "author": "wchevreuil", "createdAt": "2020-11-10T17:47:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5ODg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyMjkxNw==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r521022917", "bodyText": "This method should only be called upon replication source termination.\n\n\n\n\nso what this interrupt will do, how is it handled in the source?\nLOG.warn(\"Interrupting source thread for peer {} without cleaning buffer usage \"\n            + \"because clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n            + \"thread to stop.\", this.source.getPeerId());\n\ndon't we need to return here as we timed out and not clearing the batch?", "author": "ankitsinghal", "createdAt": "2020-11-11T02:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5ODg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU1NDQxMA==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r521554410", "bodyText": "Right, it's not been handled. Changing to simply log the exceptional and return back to source.", "author": "wchevreuil", "createdAt": "2020-11-11T18:24:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5ODg0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\nindex bb55275773..6e5e7b089e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java\n\n@@ -367,13 +367,16 @@ public class ReplicationSourceShipper extends Thread {\n     entryReader.entryBatchQueue.forEach(w -> {\n       entryReader.entryBatchQueue.remove(w);\n       w.getWalEntries().forEach(e -> {\n-        long entrySizeExcludeBulkLoad = entryReader.getEntrySizeExcludeBulkLoad(e);\n+        long entrySizeExcludeBulkLoad = ReplicationSourceWALReader.getEntrySizeExcludeBulkLoad(e);\n         totalToDecrement.accumulate(entrySizeExcludeBulkLoad);\n       });\n     });\n-\n-    LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n-      totalToDecrement.longValue());\n-    source.getSourceManager().getTotalBufferUsed().addAndGet(-totalToDecrement.longValue());\n+    if( LOG.isTraceEnabled()) {\n+      LOG.trace(\"Decrementing totalBufferUsed by {}B while stopping Replication WAL Readers.\",\n+        totalToDecrement.longValue());\n+    }\n+    long newBufferUsed = source.getSourceManager().getTotalBufferUsed()\n+      .addAndGet(-totalToDecrement.longValue());\n+    source.getSourceManager().getGlobalMetrics().setWALReaderEditsBufferBytes(newBufferUsed);\n   }\n }\n"}}, {"oid": "9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "url": "https://github.com/apache/hbase/commit/9dafe5f3f3c9261eea0d242b0c7c8c7d5016909f", "message": "adding latest review suggestions", "committedDate": "2020-11-10T19:07:12Z", "type": "commit"}, {"oid": "8e5c77b4e70c08b012d010ea4207dd9399a95deb", "url": "https://github.com/apache/hbase/commit/8e5c77b4e70c08b012d010ea4207dd9399a95deb", "message": "Addressing addtional suggestions and fixing UT errors.", "committedDate": "2020-11-11T18:23:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc3MTAxNw==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r521771017", "bodyText": "please restore interrupt flag here (Thread.currentThread().interrupt();) and then return.", "author": "ankitsinghal", "createdAt": "2020-11-12T02:04:44Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceShipper.java", "diffHunk": "@@ -325,4 +327,56 @@ void stopWorker() {\n   public boolean isFinished() {\n     return state == WorkerState.FINISHED;\n   }\n+\n+  /**\n+   * Attempts to properly update <code>ReplicationSourceManager.totalBufferUser</code>,\n+   * in case there were unprocessed entries batched by the reader to the shipper,\n+   * but the shipper didn't manage to ship those because the replication source is being terminated.\n+   * In that case, it iterates through the batched entries and decrease the pending\n+   * entries size from <code>ReplicationSourceManager.totalBufferUser</code>\n+   * <p/>\n+   * <b>NOTES</b>\n+   * 1) This method should only be called upon replication source termination.\n+   * It blocks waiting for both shipper and reader threads termination,\n+   * to make sure no race conditions\n+   * when updating <code>ReplicationSourceManager.totalBufferUser</code>.\n+   *\n+   * 2) It <b>does not</b> attempt to terminate reader and shipper threads. Those <b>must</b>\n+   * have been triggered interruption/termination prior to calling this method.\n+   */\n+  void clearWALEntryBatch() {\n+    long timeout = System.currentTimeMillis() + this.shipEditsTimeout;\n+    while(this.isAlive() || this.entryReader.isAlive()){\n+      try {\n+        if (System.currentTimeMillis() >= timeout) {\n+          LOG.warn(\"Shipper clearWALEntryBatch method timed out whilst waiting reader/shipper \"\n+            + \"thread to stop. Not cleaning buffer usage. Shipper alive: {}; Reader alive: {}\",\n+            this.source.getPeerId(), this.isAlive(), this.entryReader.isAlive());\n+          return;\n+        } else {\n+          // Wait both shipper and reader threads to stop\n+          Thread.sleep(this.sleepForRetries);\n+        }\n+      } catch (InterruptedException e) {\n+        LOG.warn(\"{} Interrupted while waiting {} to stop on clearWALEntryBatch. \"\n+            + \"Not cleaning buffer usage: {}\", this.source.getPeerId(), this.getName(), e);", "originalCommit": "8e5c77b4e70c08b012d010ea4207dd9399a95deb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIwNjI5Ng==", "url": "https://github.com/apache/hbase/pull/2546#discussion_r523206296", "bodyText": "We don't do any handling of interrupt at ReplicationSource. Would you still think we need this here?", "author": "wchevreuil", "createdAt": "2020-11-13T20:29:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc3MTAxNw=="}], "type": "inlineReview", "revised_code": null}]}