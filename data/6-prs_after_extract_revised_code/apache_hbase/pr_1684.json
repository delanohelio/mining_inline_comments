{"pr_number": 1684, "pr_title": "HBASE-24327 : Handle shutdown() if master cannot be contacted", "pr_createdAt": "2020-05-08T13:43:03Z", "pr_url": "https://github.com/apache/hbase/pull/1684", "timeline": [{"oid": "5588de651f0470f2a7071fca585a1e2fe3bb50cf", "url": "https://github.com/apache/hbase/commit/5588de651f0470f2a7071fca585a1e2fe3bb50cf", "message": "HBASE-24327 : Handle shutdown() if master cannot be contacted", "committedDate": "2020-05-08T13:15:08Z", "type": "commit"}, {"oid": "5a5dfd16764c5606507460ba877d86dc0e112763", "url": "https://github.com/apache/hbase/commit/5a5dfd16764c5606507460ba877d86dc0e112763", "message": "minor change", "committedDate": "2020-05-08T13:41:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422305113", "bodyText": "I have some on context on this test. Did you happen to dig into the root cause of the ConnectionRefused stack trace that you posted (you have the full stack trace with failed RPC name?)?\nIdeally that shouldn't happen right? The waitFor() above means the bootstrap of the master is complete and it should be able to process the shutdown() command, in a normal case. Just want to be sure we are not masking a real bug, especially after Duo moved all the code from RPC to registry.", "author": "bharathv", "createdAt": "2020-05-08T18:37:29Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java", "diffHunk": "@@ -163,7 +164,16 @@ public void testMasterShutdownBeforeStartingAnyRegionServer() throws Exception {\n       assertNotEquals(\"Timeout waiting for server manager to become available.\",\n         -1, Waiter.waitFor(htu.getConfiguration(), timeout,\n           () -> masterThread.getMaster().getServerManager() != null));\n-      htu.getConnection().getAdmin().shutdown();\n+      try {\n+        htu.getConnection().getAdmin().shutdown();", "originalCommit": "5a5dfd16764c5606507460ba877d86dc0e112763", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNTgxNw==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422315817", "bodyText": "This is what I thought that after waitFor(), bootstrap should be over but in 2/50 cases, this stacktrace comes. This test is also present in flaky report and I just realized that flaky results data accessible is 2 days after Duo's commit. Let me check 5-10 older builds before the commit and see if this was not flaky before.", "author": "virajjasani", "createdAt": "2020-05-08T18:59:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxODU1MQ==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422318551", "bodyText": "Test results before 5th May doesn't seem available and the flakes seem present on the day of commit (need to check timezone diff): https://builds.apache.org/job/HBase-Flaky-Tests/job/master/6184/", "author": "virajjasani", "createdAt": "2020-05-08T19:04:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMzOTg5OQ==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422339899", "bodyText": "Btw the root cause that I have seen for the above Exception:\n2020-05-09 00:58:39,957 ERROR [RpcServer.priority.RWQ.Fifo.read.handler=1,queue=1,port=53033] master.HMaster(2878): ZooKeeper exception trying to set cluster as down in ZK\norg.apache.zookeeper.KeeperException$SystemErrorException: KeeperErrorCode = SystemError\n\tat org.apache.hadoop.hbase.zookeeper.ZKWatcher.interruptedException(ZKWatcher.java:626)\n\tat org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1285)\n\tat org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1269)\n\tat org.apache.hadoop.hbase.zookeeper.ClusterStatusTracker.setClusterDown(ClusterStatusTracker.java:84)\n\tat org.apache.hadoop.hbase.master.HMaster.shutdown(HMaster.java:2876)\n\tat org.apache.hadoop.hbase.master.MasterRpcServices.shutdown(MasterRpcServices.java:1630)\n\tat org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java)\n\tat org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:395)\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:133)\n\tat org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:338)\n\tat org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:318)\nCaused by: java.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Object.wait(Object.java:502)\n\tat org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1529)\n\tat org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1512)\n\tat org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:1791)\n\tat org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:171)\n\tat org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1280)\n\t... 9 more\n2020-05-09 00:58:39,957 DEBUG [Time-limited test-EventThread] zookeeper.ZKWatcher(490): master:53033-0x1000d0785dd0000, quorum=127.0.0.1:60460, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master\n2020-05-09 00:58:39,957 INFO  [M:0;172.20.10.2:53033] regionserver.HRegionServer(1119): stopping server 172.20.10.2,53033,1588966118448; all regions closed.\n2020-05-09 00:58:39,958 INFO  [M:0;172.20.10.2:53033] hbase.ChoreService(329): Chore service for: master/172.20.10.2:0 had [] on shutdown\n2020-05-09 00:58:39,958 DEBUG [M:0;172.20.10.2:53033] master.HMaster(1516): Stopping service threads\n\nDoes not look like issue with moving code to registry.", "author": "virajjasani", "createdAt": "2020-05-08T19:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQxMjgyMA==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422412820", "bodyText": "Ya, doesn't look like it. This is a known problem I think (Root cause is a flaky Zk connection. I can repro it locally once every ~100 runs). The problem here seems to me that shutdown is running inline with the rpc call [1]. Nick actually made the shutdown call async in HBASE-23808 but Stack undid that in HBASE-24052 [2]. Perhaps the fix is to actually make it async in test until we fix HBASE-24070? Thoughts? (@saintstack curious what the rationale was in HBASE-24052).\n[1] https://issues.apache.org/jira/browse/HBASE-24070\n[2] https://issues.apache.org/jira/browse/HBASE-24052?focusedCommentId=17068822&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17068822", "author": "bharathv", "createdAt": "2020-05-08T23:03:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjUwODE3OA==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422508178", "bodyText": "Thanks @bharathv for the context. IMHO we should make shutdown() async in the test until fixing HBASE-24070.", "author": "virajjasani", "createdAt": "2020-05-09T15:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwNTExMw=="}], "type": "inlineReview", "revised_code": {"commit": "01178e64782f19ab874cae805fef509be849191f", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\nindex f4d4ca03db..d78b1128b5 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n\n@@ -152,28 +156,47 @@ public class TestMasterShutdown {\n       hbaseCluster = new LocalHBaseCluster(htu.getConfiguration(), options.getNumMasters(),\n         options.getNumRegionServers(), options.getMasterClass(), options.getRsClass());\n       final MasterThread masterThread = hbaseCluster.getMasters().get(0);\n+\n+      final CompletableFuture<Void> shutdownFuture = CompletableFuture.runAsync(() -> {\n+        // Switching to master registry exacerbated a race in the master bootstrap that can result\n+        // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n+        // the server manager in HMaster is not initialized by the time shutdown() RPC (below) is\n+        // made to the master. The suspected reason as to why it was uncommon before HBASE-18095\n+        // is because the connection creation with ZK registry is so slow that by then the server\n+        // manager is usually init'ed in time for the RPC to be made. For now, adding an explicit\n+        // wait() in the test, waiting for the server manager to become available.\n+        final long timeout = TimeUnit.MINUTES.toMillis(10);\n+        assertNotEquals(\"timeout waiting for server manager to become available.\", -1,\n+          htu.waitFor(timeout, () -> masterThread.getMaster().getServerManager() != null));\n+\n+        // Master has come up far enough that we can terminate it without creating a zombie.\n+        final long result = htu.waitFor(timeout, 1000, () -> {\n+          final Configuration conf = createResponsiveZkConfig(htu.getConfiguration());\n+          LOG.debug(\"Attempting to establish connection.\");\n+          final CompletableFuture<AsyncConnection> connFuture =\n+            ConnectionFactory.createAsyncConnection(conf);\n+          try (final AsyncConnection conn = connFuture.join()) {\n+            LOG.info(\"Sending shutdown RPC.\");\n+            try {\n+              conn.getAdmin().shutdown().join();\n+              LOG.info(\"Shutdown RPC sent.\");\n+              return true;\n+            } catch (CompletionException e) {\n+              LOG.error(\"Failure sending shutdown RPC.\");\n+            }\n+          } catch (IOException|CompletionException e) {\n+            LOG.error(\"Failed to establish connection.\");\n+          } catch (Throwable e) {\n+            LOG.error(\"Something unexpected happened.\", e);\n+          }\n+          return false;\n+        });\n+        assertNotEquals(\"Failed to issue shutdown RPC after \" + Duration.ofMillis(timeout),\n+          -1, result);\n+      });\n+\n       masterThread.start();\n-      // Switching to master registry exacerbated a race in the master bootstrap that can result\n-      // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n-      // the server manager in HMaster is not initialized by the time shutdown() RPC (below) is\n-      // made to the master. The suspected reason as to why it was uncommon before HBASE-18095\n-      // is because the connection creation with ZK registry is so slow that by then the server\n-      // manager is usually init'ed in time for the RPC to be made. For now, adding an explicit\n-      // wait() in the test, waiting for the server manager to become available.\n-      final long timeout = TimeUnit.MINUTES.toMillis(10);\n-      assertNotEquals(\"Timeout waiting for server manager to become available.\",\n-        -1, Waiter.waitFor(htu.getConfiguration(), timeout,\n-          () -> masterThread.getMaster().getServerManager() != null));\n-      try {\n-        htu.getConnection().getAdmin().shutdown();\n-      } catch (IOException e) {\n-        LOG.error(\"Failed to shut down the cluster.\", e);\n-        if (!(e.getCause() instanceof MasterRegistryFetchException)\n-            || !(e.getCause().getCause() != null && e.getCause().getCause().getMessage()\n-              .startsWith(\"Failed contacting masters\"))) {\n-          throw e;\n-        }\n-      }\n+      shutdownFuture.join();\n       masterThread.join();\n     } finally {\n       if (hbaseCluster != null) {\n"}}, {"oid": "01178e64782f19ab874cae805fef509be849191f", "url": "https://github.com/apache/hbase/commit/01178e64782f19ab874cae805fef509be849191f", "message": "async call to shutdown()", "committedDate": "2020-05-09T18:03:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTYwMw==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422555603", "bodyText": "we can use htu.getConnection()?", "author": "bharathv", "createdAt": "2020-05-09T22:45:48Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java", "diffHunk": "@@ -151,19 +156,47 @@ public void testMasterShutdownBeforeStartingAnyRegionServer() throws Exception {\n       hbaseCluster = new LocalHBaseCluster(htu.getConfiguration(), options.getNumMasters(),\n         options.getNumRegionServers(), options.getMasterClass(), options.getRsClass());\n       final MasterThread masterThread = hbaseCluster.getMasters().get(0);\n+\n+      final CompletableFuture<Void> shutdownFuture = CompletableFuture.runAsync(() -> {\n+        // Switching to master registry exacerbated a race in the master bootstrap that can result\n+        // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n+        // the server manager in HMaster is not initialized by the time shutdown() RPC (below) is\n+        // made to the master. The suspected reason as to why it was uncommon before HBASE-18095\n+        // is because the connection creation with ZK registry is so slow that by then the server\n+        // manager is usually init'ed in time for the RPC to be made. For now, adding an explicit\n+        // wait() in the test, waiting for the server manager to become available.\n+        final long timeout = TimeUnit.MINUTES.toMillis(10);\n+        assertNotEquals(\"timeout waiting for server manager to become available.\", -1,\n+          htu.waitFor(timeout, () -> masterThread.getMaster().getServerManager() != null));\n+\n+        // Master has come up far enough that we can terminate it without creating a zombie.\n+        final long result = htu.waitFor(timeout, 1000, () -> {\n+          final Configuration conf = createResponsiveZkConfig(htu.getConfiguration());\n+          LOG.debug(\"Attempting to establish connection.\");\n+          final CompletableFuture<AsyncConnection> connFuture =\n+            ConnectionFactory.createAsyncConnection(conf);\n+          try (final AsyncConnection conn = connFuture.join()) {", "originalCommit": "01178e64782f19ab874cae805fef509be849191f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU5ODY3MQ==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422598671", "bodyText": "since we want to use AsynAdmin with AsyncConnection, htu.getConnection() wouldn't work.", "author": "virajjasani", "createdAt": "2020-05-10T07:00:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTYwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjY2OTE1Nw==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422669157", "bodyText": "This is already running inside a thread. What purpose does AsyncAdmin serve? Also, you are joining on it right away.", "author": "bharathv", "createdAt": "2020-05-10T16:43:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTYwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjY3NTQ1Ng==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422675456", "bodyText": "Hmm since it is already in ForkJoin, this doesn't matter much. I don't have strong opinion, but it's just that we are directly using AsyncConnection and AsyncAdmin rather than via Connection and Admin interfaces. But yes even htu.getConnection() should work after putting ZK recovery configs in htu directly.\nHowever, since it's not much of a diff, do you want Addendum now, or let's wait for some time and see reports and then we can add it maybe in a week?", "author": "virajjasani", "createdAt": "2020-05-10T17:35:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTYwMw=="}], "type": "inlineReview", "revised_code": {"commit": "d2bb8a7b36e2eb9a79ce29e40a4933529363f8cf", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\nindex d78b1128b5..703455a722 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n\n@@ -157,6 +157,7 @@ public class TestMasterShutdown {\n         options.getNumRegionServers(), options.getMasterClass(), options.getRsClass());\n       final MasterThread masterThread = hbaseCluster.getMasters().get(0);\n \n+      masterThread.start();\n       final CompletableFuture<Void> shutdownFuture = CompletableFuture.runAsync(() -> {\n         // Switching to master registry exacerbated a race in the master bootstrap that can result\n         // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTkwMQ==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422555901", "bodyText": "Shouldn't this be before we trigger the shutdown command?", "author": "bharathv", "createdAt": "2020-05-09T22:49:07Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java", "diffHunk": "@@ -151,19 +156,47 @@ public void testMasterShutdownBeforeStartingAnyRegionServer() throws Exception {\n       hbaseCluster = new LocalHBaseCluster(htu.getConfiguration(), options.getNumMasters(),\n         options.getNumRegionServers(), options.getMasterClass(), options.getRsClass());\n       final MasterThread masterThread = hbaseCluster.getMasters().get(0);\n+\n+      final CompletableFuture<Void> shutdownFuture = CompletableFuture.runAsync(() -> {\n+        // Switching to master registry exacerbated a race in the master bootstrap that can result\n+        // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n+        // the server manager in HMaster is not initialized by the time shutdown() RPC (below) is\n+        // made to the master. The suspected reason as to why it was uncommon before HBASE-18095\n+        // is because the connection creation with ZK registry is so slow that by then the server\n+        // manager is usually init'ed in time for the RPC to be made. For now, adding an explicit\n+        // wait() in the test, waiting for the server manager to become available.\n+        final long timeout = TimeUnit.MINUTES.toMillis(10);\n+        assertNotEquals(\"timeout waiting for server manager to become available.\", -1,\n+          htu.waitFor(timeout, () -> masterThread.getMaster().getServerManager() != null));\n+\n+        // Master has come up far enough that we can terminate it without creating a zombie.\n+        final long result = htu.waitFor(timeout, 1000, () -> {\n+          final Configuration conf = createResponsiveZkConfig(htu.getConfiguration());\n+          LOG.debug(\"Attempting to establish connection.\");\n+          final CompletableFuture<AsyncConnection> connFuture =\n+            ConnectionFactory.createAsyncConnection(conf);\n+          try (final AsyncConnection conn = connFuture.join()) {\n+            LOG.info(\"Sending shutdown RPC.\");\n+            try {\n+              conn.getAdmin().shutdown().join();\n+              LOG.info(\"Shutdown RPC sent.\");\n+              return true;\n+            } catch (CompletionException e) {\n+              LOG.error(\"Failure sending shutdown RPC.\");\n+            }\n+          } catch (IOException|CompletionException e) {\n+            LOG.error(\"Failed to establish connection.\");\n+          } catch (Throwable e) {\n+            LOG.error(\"Something unexpected happened.\", e);\n+          }\n+          return false;\n+        });\n+        assertNotEquals(\"Failed to issue shutdown RPC after \" + Duration.ofMillis(timeout),\n+          -1, result);\n+      });\n+\n       masterThread.start();", "originalCommit": "01178e64782f19ab874cae805fef509be849191f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwMDM4NA==", "url": "https://github.com/apache/hbase/pull/1684#discussion_r422600384", "bodyText": "Oh yes, let me update.\nThanks", "author": "virajjasani", "createdAt": "2020-05-10T07:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU1NTkwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "d2bb8a7b36e2eb9a79ce29e40a4933529363f8cf", "chunk": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\nindex d78b1128b5..703455a722 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/master/TestMasterShutdown.java\n\n@@ -157,6 +157,7 @@ public class TestMasterShutdown {\n         options.getNumRegionServers(), options.getMasterClass(), options.getRsClass());\n       final MasterThread masterThread = hbaseCluster.getMasters().get(0);\n \n+      masterThread.start();\n       final CompletableFuture<Void> shutdownFuture = CompletableFuture.runAsync(() -> {\n         // Switching to master registry exacerbated a race in the master bootstrap that can result\n         // in a lost shutdown command (HBASE-8422, HBASE-23836). The race is essentially because\n"}}, {"oid": "d2bb8a7b36e2eb9a79ce29e40a4933529363f8cf", "url": "https://github.com/apache/hbase/commit/d2bb8a7b36e2eb9a79ce29e40a4933529363f8cf", "message": "order change", "committedDate": "2020-05-10T07:17:01Z", "type": "commit"}]}