{"pr_number": 2669, "pr_title": "HBASE-25292 Improve InetSocketAddress usage discipline", "pr_createdAt": "2020-11-17T22:50:01Z", "pr_url": "https://github.com/apache/hbase/pull/2669", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4Mjc2OQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525582769", "bodyText": "This change is a forward port of the branch-1 change here: https://github.com/apache/hbase/pull/2671/files#diff-1a7ec27a8107293b6c87132823c262fc250570687a40f45646c43ae46dc6b04eR255\nThis change fixes a bug we encountered in production while running in Amazon's Elastic Kubernetes Service.", "author": "apurtell", "createdAt": "2020-11-17T23:01:07Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/BlockingRpcConnection.java", "diffHunk": "@@ -257,7 +256,17 @@ protected void setupConnection() throws IOException {\n         if (this.rpcClient.localAddr != null) {\n           this.socket.bind(this.rpcClient.localAddr);\n         }\n-        NetUtils.connect(this.socket, remoteId.getAddress(), this.rpcClient.connectTO);\n+        if (this.rpcClient.metrics != null) {", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4MzkyNg==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525583926", "bodyText": "This is the netty version of the bug fix here: https://github.com/apache/hbase/pull/2669/files#diff-1a7ec27a8107293b6c87132823c262fc250570687a40f45646c43ae46dc6b04eR259", "author": "apurtell", "createdAt": "2020-11-17T23:04:08Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -265,23 +279,32 @@ public void operationComplete(Future<Boolean> future) throws Exception {\n     });\n   }\n \n-  private void connect() {\n+  private void connect() throws UnknownHostException {\n     assert eventLoop.inEventLoop();\n-    LOG.trace(\"Connecting to {}\", remoteId.address);\n-\n+    LOG.trace(\"Connecting to {}\", remoteId.getAddress());", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MjczMw==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525642733", "bodyText": "I do not think the old behavior is to ignore the unresolveable address? It just wants to make the stub key shorter and do not need to actual do a DNS lookup if we can make sure that the hostname will not change. And this is important for an async implementation, as we do not expect this method to be blocked but a DNS lookup could take several seconds if the the hostname can not be resolved.\nAnd in general, I never understand why here we need to add the ip address in the stub key... We have timestamp in server name so we could know whether it is the same region server, and for the rpc framework, there is no problem that they have the same stub key? We just use a string here and once we want to connect, we will resolve it and it will point to the correct ip address. We could point the hostname of a regionserver to another regionserver while both the regionservers are alive and can accept requests? This is not a good practice and can cause big troubles... I guess once we have done this, the old regionserver need to reconnect to master to again to tell master that its hostname has been changed?", "author": "Apache9", "createdAt": "2020-11-18T01:51:16Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java", "diffHunk": "@@ -186,6 +183,33 @@ private void spawnRenewalChore(final UserGroupInformation user) {\n     authService.scheduleChore(AuthUtil.getAuthRenewalChore(user));\n   }\n \n+  /**\n+   * Get a unique key for the rpc stub to the given server.\n+   */\n+  private String getStubKey(String serviceName, ServerName serverName) throws UnknownHostException {\n+    // Sometimes, servers go down and they come back up with the same hostname but a different\n+    // IP address. Force a resolution of the hostname by trying to instantiate an\n+    // InetSocketAddress, and this way we will rightfully get a new stubKey.\n+    // Also, include the hostname in the key so as to take care of those cases where the\n+    // DNS name is different but IP address remains the same.\n+    String hostname = serverName.getHostname();\n+    int port = serverName.getPort();\n+    // We used to ignore when the address was unresolvable but that makes no sense. It", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI4OTQ5Mw==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526289493", "bodyText": "So we should use the ServerName here directly to make the key instead?\nI can do that. Let me make the change.", "author": "apurtell", "createdAt": "2020-11-18T17:38:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MjczMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUxMDMxOQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526510319", "bodyText": "I'm not sure whether we really need to identify different region servers here. What is the problem if we just use host and port as the stub key here? It will not be a problem if we will resolve it when we actually connecting the remote side? Thoughts?", "author": "Apache9", "createdAt": "2020-11-19T00:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MjczMw=="}], "type": "inlineReview", "revised_code": {"commit": "07f79532e8239cdb0e8079b604da3a6b28c5aa18", "chunk": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\nindex 712347ea26..b60f7bef06 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\n\n@@ -186,28 +185,8 @@ class AsyncConnectionImpl implements AsyncConnection {\n   /**\n    * Get a unique key for the rpc stub to the given server.\n    */\n-  private String getStubKey(String serviceName, ServerName serverName) throws UnknownHostException {\n-    // Sometimes, servers go down and they come back up with the same hostname but a different\n-    // IP address. Force a resolution of the hostname by trying to instantiate an\n-    // InetSocketAddress, and this way we will rightfully get a new stubKey.\n-    // Also, include the hostname in the key so as to take care of those cases where the\n-    // DNS name is different but IP address remains the same.\n-    String hostname = serverName.getHostname();\n-    int port = serverName.getPort();\n-    // We used to ignore when the address was unresolvable but that makes no sense. It\n-    // would lead to a stub key mapping to an instance where the host cannot be resolved;\n-    // and therefore, cannot be contacted anyway.\n-    if (this.metrics.isPresent()) {\n-      this.metrics.get().incrNsLookups();\n-    }\n-    InetAddress i =  new InetSocketAddress(hostname, port).getAddress();\n-    if (i == null) {\n-      if (this.metrics.isPresent()) {\n-        this.metrics.get().incrNsLookupsFailed();\n-      }\n-      throw new UnknownHostException(hostname + \" cannot be resolved\");\n-    }\n-    return String.format(\"%s@%s-%s:%d\", serviceName, i.getHostAddress(), hostname, port);\n+  private static String getStubKey(String serviceName, ServerName serverName) {\n+    return String.format(\"%s@%s\", serviceName, serverName);\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NjE5Mg==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525646192", "bodyText": "Good. When implementing an in-house rpc framework in the past, I used to use InetSocketAddress.createUnresolved. But it has a problem that usually a network framework will not accept a unresolved InetSocketAddress so if you forget to  recreate a resolved one you will get exception. Since here we have a special structure, I think it is good to make use it to explicitly say that, here we do not want a resolve yet.", "author": "Apache9", "createdAt": "2020-11-18T02:02:09Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java", "diffHunk": "@@ -135,10 +136,10 @@\n \n   private int maxConcurrentCallsPerServer;\n \n-  private static final LoadingCache<InetSocketAddress, AtomicInteger> concurrentCounterCache =\n+  private static final LoadingCache<Address, AtomicInteger> concurrentCounterCache =", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5288408e8a5de515b199116a20d8798b7eea3cb5", "chunk": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java\nindex cbb1598f2b..7c95857949 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java\n\n@@ -128,7 +127,7 @@ public abstract class AbstractRpcClient<T extends RpcConnection> implements RpcC\n   protected final int readTO;\n   protected final int writeTO;\n \n-  protected final PoolMap<ConnectionId, T> connections;\n+  private final PoolMap<ConnectionId, T> connections;\n \n   private final AtomicInteger callIdCnt = new AtomicInteger(0);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525647369", "bodyText": "Could we change this to use Address directly? And we could also remove the UnknownHostException from the createAddr method then which could makes the createRpcChannel and createBlockingRpcChannel not throw IOException, which will be very good.", "author": "Apache9", "createdAt": "2020-11-18T02:05:50Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AbstractRpcClient.java", "diffHunk": "@@ -390,8 +391,8 @@ private void onCallFinished(Call call, HBaseRpcController hrc, InetSocketAddress\n   }\n \n   Call callMethod(final Descriptors.MethodDescriptor md, final HBaseRpcController hrc,\n-      final Message param, Message returnType, final User ticket, final InetSocketAddress addr,\n-      final RpcCallback<Message> callback) {\n+      final Message param, Message returnType, final User ticket,\n+      final InetSocketAddress inetAddr, final RpcCallback<Message> callback) {", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI5MTgxNA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526291814", "bodyText": "Let me check.\nWhat we want to avoid is making an ISA for every Call.\nWill try this and get back to you.", "author": "apurtell", "createdAt": "2020-11-18T17:40:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ0OTYzOA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526449638", "bodyText": "I can't do this or else there will be a new InetSocketAddress() for every callMethod(), which may cause a DNS lookup per call.", "author": "apurtell", "createdAt": "2020-11-18T21:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3Njk5Ng==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526476996", "bodyText": "Ok, done. Lookup done upon first call and then cached there; or else an exception or failure indication is returned at that time.", "author": "apurtell", "createdAt": "2020-11-18T22:52:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUxMjc0NA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526512744", "bodyText": "Can not view the code now but IIRC, on this execution path, we will use a ConnectionId to get a RpcConnection and then use it to send the rpc call? Then I think we could put the actual resolving in the connect method? Before connecting we could always use the Address class to represent the remote address.", "author": "Apache9", "createdAt": "2020-11-19T00:29:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDgxMTA5NA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r530811094", "bodyText": "Checked the code, I think we could avoid creating an InetSocketAddress everytime here, we just need to change more classes to make use of Address instead of InetSocketAddress, such as ConnetionId, FailedServers, as well as the RpcClient interface. And the resolving of the actual address could be delayed to NettyRpcConnection.connect and BlockingRpcConnection.setupConnection, where we really want to connect to the remote side. And once the connection has been established, and it has not been closed because of error or idle for too long, we do not need to involve InetSocketAddress again. I think it is OK?", "author": "Apache9", "createdAt": "2020-11-26T07:07:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzM2OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0NzUyOA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r525647528", "bodyText": "Good.", "author": "Apache9", "createdAt": "2020-11-18T02:06:21Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/ConnectionId.java", "diffHunk": "@@ -32,9 +32,9 @@\n   private static final int PRIME = 16777619;\n   final User ticket;\n   final String serviceName;\n-  final InetSocketAddress address;\n+  final Address address;", "originalCommit": "1dfa1f3cf13bf89ab46b4be2dda436391953512e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "07f79532e8239cdb0e8079b604da3a6b28c5aa18", "url": "https://github.com/apache/hbase/commit/07f79532e8239cdb0e8079b604da3a6b28c5aa18", "message": "Use ServerName directly to build a stub key", "committedDate": "2020-11-18T22:03:34Z", "type": "forcePushed"}, {"oid": "09b6eeb3dc64735f2b68c3d8312427a5fd3d8633", "url": "https://github.com/apache/hbase/commit/09b6eeb3dc64735f2b68c3d8312427a5fd3d8633", "message": "Use ServerName directly to build a stub key", "committedDate": "2020-11-18T22:19:56Z", "type": "forcePushed"}, {"oid": "eaece7e3b4ce959f0853e4b44c8e10bca5462e4e", "url": "https://github.com/apache/hbase/commit/eaece7e3b4ce959f0853e4b44c8e10bca5462e4e", "message": "Use ServerName directly to build a stub key", "committedDate": "2020-11-18T22:23:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcyMTEzMg==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526721132", "bodyText": "nit: both InetAddress and InetSocketAddress are no longer in use, imports can be removed.", "author": "virajjasani", "createdAt": "2020-11-19T09:41:04Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java", "diffHunk": "@@ -25,6 +25,7 @@\n import java.io.IOException;\n import java.lang.reflect.UndeclaredThrowableException;\n import java.net.InetAddress;\n+import java.net.InetSocketAddress;", "originalCommit": "e02560a78677d16a81f775be5f1c8be820c9179e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxMjQ4MQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r527012481", "bodyText": "Ok. There are going to be other checkstyle nits too, will look at the report and fix them all.", "author": "apurtell", "createdAt": "2020-11-19T16:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcyMTEzMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcyMjIxNQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526722215", "bodyText": "nit: same here, no longer in use.", "author": "virajjasani", "createdAt": "2020-11-19T09:42:38Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java", "diffHunk": "@@ -28,6 +28,8 @@\n import static org.apache.hadoop.hbase.util.FutureUtils.addListener;\n \n import java.io.IOException;\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;", "originalCommit": "e02560a78677d16a81f775be5f1c8be820c9179e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5288408e8a5de515b199116a20d8798b7eea3cb5", "chunk": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\nindex d6ff7ba3d2..f9b831359e 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncConnectionImpl.java\n\n@@ -22,7 +22,6 @@ import static org.apache.hadoop.hbase.HConstants.STATUS_PUBLISHED_DEFAULT;\n import static org.apache.hadoop.hbase.client.ClusterStatusListener.DEFAULT_STATUS_LISTENER_CLASS;\n import static org.apache.hadoop.hbase.client.ClusterStatusListener.STATUS_LISTENER_CLASS;\n import static org.apache.hadoop.hbase.client.ConnectionUtils.NO_NONCE_GENERATOR;\n-import static org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey;\n import static org.apache.hadoop.hbase.client.MetricsConnection.CLIENT_SIDE_METRICS_ENABLED_KEY;\n import static org.apache.hadoop.hbase.client.NonceGenerator.CLIENT_NONCES_ENABLED_KEY;\n import static org.apache.hadoop.hbase.util.FutureUtils.addListener;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjczNzU3NQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526737575", "bodyText": "This conversion to InetSocketAddress[] takes place for each new StoreFileWriter creation right? Is there any other usecase that I am missing here?", "author": "virajjasani", "createdAt": "2020-11-19T10:05:08Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java", "diffHunk": "@@ -3485,25 +3488,26 @@ boolean checkFileSystem() {\n   @Override\n   public void updateRegionFavoredNodesMapping(String encodedRegionName,\n       List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes) {\n-    InetSocketAddress[] addr = new InetSocketAddress[favoredNodes.size()];\n+    Address[] addr = new Address[favoredNodes.size()];\n     // Refer to the comment on the declaration of regionFavoredNodesMap on why\n-    // it is a map of region name to InetSocketAddress[]\n+    // it is a map of region name to Address[]\n     for (int i = 0; i < favoredNodes.size(); i++) {\n-      addr[i] = InetSocketAddress.createUnresolved(favoredNodes.get(i).getHostName(),\n+      addr[i] = Address.fromParts(favoredNodes.get(i).getHostName(),\n           favoredNodes.get(i).getPort());\n     }\n     regionFavoredNodesMap.put(encodedRegionName, addr);\n   }\n \n   /**\n    * Return the favored nodes for a region given its encoded name. Look at the\n-   * comment around {@link #regionFavoredNodesMap} on why it is InetSocketAddress[]\n-   *\n+   * comment around {@link #regionFavoredNodesMap} on why we convert to InetSocketAddress[]\n+   * here.\n+   * @param encodedRegionName\n    * @return array of favored locations\n    */\n   @Override\n   public InetSocketAddress[] getFavoredNodesForRegion(String encodedRegionName) {\n-    return regionFavoredNodesMap.get(encodedRegionName);\n+    return Address.toSocketAddress(regionFavoredNodesMap.get(encodedRegionName));", "originalCommit": "e02560a78677d16a81f775be5f1c8be820c9179e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjc0ODA3OA==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r526748078", "bodyText": "Where do we check if these addresses are resolved? Or we don't need to for this specific use-case?", "author": "virajjasani", "createdAt": "2020-11-19T10:21:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjczNzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAxMTk5MQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r527011991", "bodyText": "This will happen whenever the regionserver needs to build a list of ISA of datanodes for handing to FileSystem#create, but only if Favored Nodes is enabled. (As far as I know, nobody actually uses favored nodes, well, perhaps Francis and ex-Yahoo team.) So yeah, just before store file creation time. We can hand the ISA directly to HDFS without checking ISA#isUnresolved because should an ISA be unresolved when HDFS tries to use it the Java network API will throw an exception, which will propagate up to us. However if you would prefer to check the resolution status of the ISAs and explicitly throw our own exception, the place to do this would be FSUtils.java where the call to FileSystem#create including ISA parameters is performed via reflection.", "author": "apurtell", "createdAt": "2020-11-19T16:12:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjczNzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODEwNjkwOQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r528106909", "bodyText": "the place to do this would be FSUtils.java where the call to FileSystem#create including ISA parameters is performed via reflection.\n\nOh, what a giant reflection happening here :)\n          return (FSDataOutputStream) (DistributedFileSystem.class\n            .getDeclaredMethod(\"create\", Path.class, FsPermission.class, boolean.class, int.class,\n              short.class, long.class, Progressable.class, InetSocketAddress[].class)\n            .invoke(backingFs, path, perm, true, CommonFSUtils.getDefaultBufferSize(backingFs),\n              replication > 0 ? replication : CommonFSUtils.getDefaultReplication(backingFs, path),\n              CommonFSUtils.getDefaultBlockSize(backingFs, path), null, favoredNodes));\n\n\nWe can hand the ISA directly to HDFS without checking ISA#isUnresolved because should an ISA be unresolved when HDFS tries to use it the Java network API will throw an exception, which will propagate up to us.\n\nMakes sense, I think we should be good with this as is, rather than performing resolution checks at both layers.", "author": "virajjasani", "createdAt": "2020-11-21T07:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjczNzU3NQ=="}], "type": "inlineReview", "revised_code": null}, {"oid": "42a9227c054d25e8071f95bbe486908451b60ff7", "url": "https://github.com/apache/hbase/commit/42a9227c054d25e8071f95bbe486908451b60ff7", "message": "Resolve and cache ISA on a RpcChannel as late as possible, at first call", "committedDate": "2020-11-19T23:14:47Z", "type": "forcePushed"}, {"oid": "e33cf77cd08c5a68f1a2b2966acc380dbbcc904d", "url": "https://github.com/apache/hbase/commit/e33cf77cd08c5a68f1a2b2966acc380dbbcc904d", "message": "Remove now invalid unit test TestCIBadHostname\n\nWe resolve DNS at the latest possible time, at first call, so this unit\ntest as written will not work.", "committedDate": "2020-11-20T21:33:52Z", "type": "forcePushed"}, {"oid": "14c3626ad999935c068cacb1ff83545c7aae882b", "url": "https://github.com/apache/hbase/commit/14c3626ad999935c068cacb1ff83545c7aae882b", "message": "Remove now invalid unit test TestCIBadHostname\n\nWe resolve DNS at the latest possible time, at first call, and do not\nresolve hostnames for creating stubs at all, so this unit test cannot\nwork now.", "committedDate": "2020-11-20T22:07:20Z", "type": "forcePushed"}, {"oid": "5288408e8a5de515b199116a20d8798b7eea3cb5", "url": "https://github.com/apache/hbase/commit/5288408e8a5de515b199116a20d8798b7eea3cb5", "message": "HBASE-25292 Improve InetSocketAddress usage discipline\n\nNetwork identities should be bound late. Remote addresses should be\nresolved at the last possible moment, just before connect(). Network\nidentity mappings can change, so our code should not inappropriately\ncache them. Otherwise we might miss a change and fail to operate normally.\n\nRevert \"HBASE-14544 Allow HConnectionImpl to not refresh the dns on errors\"\nRemoves hbase.resolve.hostnames.on.failure and related code. We always\nresolve hostnames, as late as possible.\n\nPreserve InetSocketAddress caching per RPC connection. Avoids potential\nlookups per Call.\n\nReplace InetSocketAddress with Address where used as a map key. If we want\nto key by hostname and/or resolved address we should be explicit about it.\nUsing Address chooses mapping by hostname and port only.\n\nAdd metrics for potential nameservice resolution attempts, whenever an\nInetSocketAddress is instantiated for connect; and metrics for failed\nresolution, whenever InetSocketAddress#isUnresolved on the new instance\nis true.", "committedDate": "2020-11-25T22:36:06Z", "type": "commit"}, {"oid": "986302a3c5332277a2e95e91d5c8e2da7410300c", "url": "https://github.com/apache/hbase/commit/986302a3c5332277a2e95e91d5c8e2da7410300c", "message": "Use ServerName directly to build a stub key", "committedDate": "2020-11-25T22:36:09Z", "type": "commit"}, {"oid": "77755c0d6e0816b0e48d0452dc2faaffd35c137d", "url": "https://github.com/apache/hbase/commit/77755c0d6e0816b0e48d0452dc2faaffd35c137d", "message": "Resolve and cache ISA on a RpcChannel as late as possible, at first call", "committedDate": "2020-11-25T22:36:09Z", "type": "commit"}, {"oid": "df43787aa25d98d5796e4d7ada20337d4f593d33", "url": "https://github.com/apache/hbase/commit/df43787aa25d98d5796e4d7ada20337d4f593d33", "message": "Remove now invalid unit test TestCIBadHostname\n\nWe resolve DNS at the latest possible time, at first call, and do not\nresolve hostnames for creating stubs at all, so this unit test cannot\nwork now.", "committedDate": "2020-11-25T22:36:09Z", "type": "commit"}, {"oid": "df43787aa25d98d5796e4d7ada20337d4f593d33", "url": "https://github.com/apache/hbase/commit/df43787aa25d98d5796e4d7ada20337d4f593d33", "message": "Remove now invalid unit test TestCIBadHostname\n\nWe resolve DNS at the latest possible time, at first call, and do not\nresolve hostnames for creating stubs at all, so this unit test cannot\nwork now.", "committedDate": "2020-11-25T22:36:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDgwNTY1NQ==", "url": "https://github.com/apache/hbase/pull/2669#discussion_r530805655", "bodyText": "As said before, I wonder what is the problem if we just use host:port directly here? In the past I think the problem is that we will not resolve again when connecting, for now, I think the problem has been solved?", "author": "Apache9", "createdAt": "2020-11-26T06:52:45Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java", "diffHunk": "@@ -128,32 +129,17 @@ public static void setServerSideHConnectionRetriesConfig(final Configuration c,\n   }\n \n   /**\n-   * Return retires + 1. The returned value will be in range [1, Integer.MAX_VALUE].\n+   * Get a unique key for the rpc stub to the given server.\n    */\n-  static int retries2Attempts(int retries) {\n-    return Math.max(1, retries == Integer.MAX_VALUE ? Integer.MAX_VALUE : retries + 1);\n+  static String getStubKey(String serviceName, ServerName serverName) {", "originalCommit": "df43787aa25d98d5796e4d7ada20337d4f593d33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}