{"pr_number": 2800, "pr_title": "HBASE-25249 Adding StoreContext", "pr_createdAt": "2020-12-21T19:10:50Z", "pr_url": "https://github.com/apache/hbase/pull/2800", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNDE0Mg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546914142", "bodyText": "Consider naming this getEncryptionContext (as elsewhere)", "author": "apurtell", "createdAt": "2020-12-21T20:26:55Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -474,33 +501,14 @@ public long getBlockingFileCount() {\n   }\n   /* End implementation of StoreConfigInformation */\n \n-  /**\n-   * Returns the configured bytesPerChecksum value.\n-   * @param conf The configuration\n-   * @return The bytesPerChecksum that is set in the configuration\n-   */\n-  public static int getBytesPerChecksum(Configuration conf) {\n-    return conf.getInt(HConstants.BYTES_PER_CHECKSUM,\n-                       HFile.DEFAULT_BYTES_PER_CHECKSUM);\n-  }\n-\n-  /**\n-   * Returns the configured checksum algorithm.\n-   * @param conf The configuration\n-   * @return The checksum algorithm that is set in the configuration\n-   */\n-  public static ChecksumType getChecksumType(Configuration conf) {\n-    String checksumName = conf.get(HConstants.CHECKSUM_TYPE_NAME);\n-    if (checksumName == null) {\n-      return ChecksumType.getDefaultChecksumType();\n-    } else {\n-      return ChecksumType.nameToType(checksumName);\n-    }\n-  }\n \n   @Override\n   public ColumnFamilyDescriptor getColumnFamilyDescriptor() {\n-    return this.family;\n+    return this.storeContext.getFamily();\n+  }\n+\n+  public Encryption.Context getCryptoContext() {", "originalCommit": "e5e21fa09a6869fc3de3179ec1dee077e0019a9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MTc5MA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546951790", "bodyText": "sure, and thanks for pointing it out", "author": "taklwu", "createdAt": "2020-12-21T22:02:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNDE0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY1NjQwOA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r551656408", "bodyText": "I have changed that in the latest update, please see if you have more comments, and I marked it as resolved first", "author": "taklwu", "createdAt": "2021-01-05T00:56:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNDE0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "742e7374a1b066b0d45ffadaf2c55a38b6f0513c", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 1cd50329e9..b332ccee6e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -507,7 +508,7 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n     return this.storeContext.getFamily();\n   }\n \n-  public Encryption.Context getCryptoContext() {\n+  public Encryption.Context getEncryptionContext() {\n     return storeContext.getDefaultFileContext().getEncryptionContext();\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTMxMw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546915313", "bodyText": "Does DEEP_OVERHEAD and heapSize() need to change? Does TestHeapSize still pass?", "author": "apurtell", "createdAt": "2020-12-21T20:29:56Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -2559,7 +2572,7 @@ public boolean needsCompaction() {\n    * @return cache configuration for this Store.\n    */\n   public CacheConfig getCacheConfig() {\n-    return this.cacheConf;\n+    return storeContext.getCacheConf();\n   }\n \n   public static final long FIXED_OVERHEAD = ClassSize.estimateBase(HStore.class, false);", "originalCommit": "e5e21fa09a6869fc3de3179ec1dee077e0019a9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MTgwOA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546951808", "bodyText": "TestHeapSize still passed when I checked it locally.\nfrom what I understood from the FIXED_OVERHEAD were being calculated by ClassSize.estimateBase, it will automatically calculate the our newly added fields and reference included the change of HStoreContext storeContext.\nSo for the DEEP_OVERHEAD that takes new calculated FIXED_OVERHEAD to come up the heap size, it should be done already. Or did I miss something here?", "author": "taklwu", "createdAt": "2020-12-21T22:02:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTMxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY1NjU5MA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r551656590", "bodyText": "this has been change as well, can you have another look ?", "author": "taklwu", "createdAt": "2021-01-05T00:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTMxMw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTU3NA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546915574", "bodyText": "Should this implement HeapSize? This information used to be included in Store/HStore heap utilization estimation via HStore#heapSize() and so we should still track it?", "author": "apurtell", "createdAt": "2020-12-21T20:30:37Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStoreContext.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.CellComparator;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.function.Supplier;\n+\n+/**\n+ * This carries the information on some of the meta data about the HStore. This\n+ * meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n+ * need of passing around the complete store.\n+ */\n+@InterfaceAudience.Private\n+public class HStoreContext {", "originalCommit": "e5e21fa09a6869fc3de3179ec1dee077e0019a9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MTgzMQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546951831", "bodyText": "as I mentioned above about FIXED_OVERHEAD were being calculated by ClassSize.estimateBase, it should be already covered", "author": "taklwu", "createdAt": "2020-12-21T22:02:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTUyOA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r546965528", "bodyText": "after a second look, you're right that this HStoreContext should have implemented HeapSize, I will change it for the next diff", "author": "taklwu", "createdAt": "2020-12-21T22:41:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY1NjY5OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r551656699", "bodyText": "fixed and implemented heapSize()", "author": "taklwu", "createdAt": "2021-01-05T00:57:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTU3NA=="}], "type": "inlineReview", "revised_code": {"commit": "742e7374a1b066b0d45ffadaf2c55a38b6f0513c", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStoreContext.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStoreContext.java\nindex 4a0c7afe8c..18ae7a6290 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStoreContext.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStoreContext.java\n\n@@ -20,8 +20,10 @@ package org.apache.hadoop.hbase.regionserver;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.hbase.CellComparator;\n import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.io.HeapSize;\n import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.util.ClassSize;\n import org.apache.yetus.audience.InterfaceAudience;\n \n import java.net.InetSocketAddress;\n"}}, {"oid": "742e7374a1b066b0d45ffadaf2c55a38b6f0513c", "url": "https://github.com/apache/hbase/commit/742e7374a1b066b0d45ffadaf2c55a38b6f0513c", "message": "HBASE-25249 Adding HStoreContext\n\nAdding HStoreContext which contains the metadata about the HStore. This\nmeta data can be used across the HFileWriter/Readers and other HStore\nconsumers without the need of passing around the complete store and\nexposing its internals.", "committedDate": "2020-12-21T23:15:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY4ODQxNw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r547688417", "bodyText": "You don't want to do get\nreturn ChecksymType.nameToType(conf.get(HConstants.CHECKSUM_TYPE_NAME, DEFAULT_WHATEVER_IT_IS));\nIs this a candidate for StoreContext? (Perhaps if called frequently). Perhaps StoreContext is not available where this is used?", "author": "saintstack", "createdAt": "2020-12-23T06:05:29Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreUtils.java", "diffHunk": "@@ -136,4 +140,26 @@ public static OptionalLong getMaxSequenceIdInList(Collection<HStoreFile> sfs) {\n     return largestFile.isPresent() ? StoreUtils.getFileSplitPoint(largestFile.get(), comparator)\n         : Optional.empty();\n   }\n+\n+  /**\n+   * Returns the configured checksum algorithm.\n+   * @param conf The configuration\n+   * @return The checksum algorithm that is set in the configuration\n+   */\n+  public static ChecksumType getChecksumType(Configuration conf) {\n+    String checksumName = conf.get(HConstants.CHECKSUM_TYPE_NAME);", "originalCommit": "e3a02b9daa452be8b3ce3b3cc6ce480537cbe13a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODE2Mjc5Mg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548162792", "bodyText": "will change in next commit. we put it as it's a static helper method, IMO we're writing it in the right Utils class?", "author": "taklwu", "createdAt": "2020-12-23T19:25:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY4ODQxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjIwMzMyOQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552203329", "bodyText": "@saintstack  we have updated it in the last commit, do you mind to have a second look?", "author": "taklwu", "createdAt": "2021-01-05T21:23:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY4ODQxNw=="}], "type": "inlineReview", "revised_code": {"commit": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreUtils.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreUtils.java\nindex 6d383e86eb..ac5955feca 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreUtils.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreUtils.java\n\n@@ -147,9 +147,8 @@ public class StoreUtils {\n    * @return The checksum algorithm that is set in the configuration\n    */\n   public static ChecksumType getChecksumType(Configuration conf) {\n-    String checksumName = conf.get(HConstants.CHECKSUM_TYPE_NAME);\n-    return checksumName == null ? ChecksumType.getDefaultChecksumType() :\n-        ChecksumType.nameToType(checksumName);\n+    return ChecksumType.nameToType(\n+      conf.get(HConstants.CHECKSUM_TYPE_NAME, ChecksumType.getDefaultChecksumType().getName()));\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r547691119", "bodyText": "Why introduce an StoreContext? Isn't that what a Store is? Store spans files.\n(We need the 'H' in HStoreContext?)", "author": "saintstack", "createdAt": "2020-12-23T06:09:02Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -246,6 +234,8 @@\n   private AtomicLong compactedCellsSize = new AtomicLong();\n   private AtomicLong majorCompactedCellsSize = new AtomicLong();\n \n+  private HStoreContext storeContext;", "originalCommit": "e3a02b9daa452be8b3ce3b3cc6ce480537cbe13a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5NTk3OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r547695979", "bodyText": "Yeah, just trying to understand why. You want to swap out the HStore implementation or something?", "author": "saintstack", "createdAt": "2020-12-23T06:15:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODEyNjA0OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548126048", "bodyText": "we introduced this context for a reason. HStore is a big informative object passed as a input to many file operation classes e.g. StoreFlusher to get access for related information in reference, e.g. columnFamilyDescriptor and regionFileSystem, we're trying to group those read-only reference such that we don't have to always use HStore object in the lower classes.\nAlthough this refactoring is the base for the upcoming patches in HBASE-24749 that we will introduce new StoreFileWriterFactory and StoreFileCommitter, we think this could be a good wrapper to group and limit access for internal reference as well.\n\n(We need the 'H' in HStoreContext?)\n\nwe can remove the H from naming, will do in the next commit", "author": "taklwu", "createdAt": "2020-12-23T18:38:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIwOTk0OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548209948", "bodyText": "Yeah the idea is that HStore has way more scope than most consumers of HStore actually need (1. The information about the store and 2. the functions to mutate things - A lot of callers just care about the info, not the actual functions) so it made sense to separate out the info to a POJO to reduce the scope of what is being exposed.", "author": "z-york", "createdAt": "2020-12-23T20:28:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIxMzQ0Ng==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548213446", "bodyText": "Ok. Stick that on the head of the context class justifying why it exists.\nWhere do you draw the line on what is in context and what is in Store? Thanks.", "author": "saintstack", "createdAt": "2020-12-23T20:33:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODMxNzg0NA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548317844", "bodyText": "IMO those informative accessor/reference and final/read-only primitives should ideally be in the context, although we're focusing on writer (StoreFileWriter) related reference and may have missed few of them (e.g. scanInfo) in this commit.\nlet's try to clarify your suggestion\n\nif you see the StoreContext is general to be applied on most cases, are those missing fields (e.g. scanInfo and  final primitives) what you're trying to point out ? if so, we can revisit and filter/add more into the StoreContext\nThe scope of this Context is more related to Writer(StoreFileWriter)/Committer(will be added), should we rename it to StoreWriterContext/StoreWriteContext  that used by those operators?", "author": "taklwu", "createdAt": "2020-12-23T23:26:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjIwNTc4NQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552205785", "bodyText": "@saintstack , do you have other comments about the scope of this StoreContext ? do we need to rename it ? or do you think we could move forward and introduce this context object with the proposed set of informative accessor/reference ?", "author": "taklwu", "createdAt": "2021-01-05T21:26:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NDEzMA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552254130", "bodyText": "@taklwu\nSorry for late reply (Thanks for pinging).\n\nlet's try to clarify your suggestion\n\nI was asking a question, not making a suggestion -- smile.\nOne thing I notice is that you and @z-york talk of the Store 'info' or 'information'. So, would StoreInfo make more sense than StoreContext? It would align with ScanInfo (Yeah, StoreInfo looks like it should have ScanInfo since it a superset or should subsume ScanInfo).\nAbove you say this... \"...we're trying to group those read-only reference such that we don't have to always use HStore object in the lower classes.\"  Seems like you could use a version of this to answer my question (ScanInfo is 'Immutable information for scans over a store'... so StoreInfo could be Store immutable info?).\nBack to your comments...\nI was trying to figure when to pass Store and when I'd pass StoreInfo/StoreContext only.\nLets just have a StoreContext/StoreInfo. Lets NOT have a StoreWriterContext; i.e. a context for write-side only.\nOne sec.... let me look at the PR here.", "author": "saintstack", "createdAt": "2021-01-05T23:12:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMzEzNw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552323137", "bodyText": "thanks, I should have provide a followup in the latest diff and proposed to keep with the StoreContext naming.\nmarked this conversation as resolved.", "author": "taklwu", "createdAt": "2021-01-06T02:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY5MTExOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex c66e3aec45..c617ae46d6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -234,7 +234,7 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n   private AtomicLong compactedCellsSize = new AtomicLong();\n   private AtomicLong majorCompactedCellsSize = new AtomicLong();\n \n-  private HStoreContext storeContext;\n+  private StoreContext storeContext;\n \n   /**\n    * Constructor\n"}}, {"oid": "69f4aa2a00accbe53341300c6c46de724f8436e8", "url": "https://github.com/apache/hbase/commit/69f4aa2a00accbe53341300c6c46de724f8436e8", "message": "HBASE-25249 Adding HStoreContext\n\nAdding HStoreContext which contains the metadata about the HStore. This\nmeta data can be used across the HFileWriter/Readers and other HStore\nconsumers without the need of passing around the complete store and\nexposing its internals.", "committedDate": "2020-12-23T20:09:10Z", "type": "commit"}, {"oid": "2731227aaedbcb904b6a8f6036459ea53a296aa2", "url": "https://github.com/apache/hbase/commit/2731227aaedbcb904b6a8f6036459ea53a296aa2", "message": "fix checkstyle", "committedDate": "2020-12-23T20:09:10Z", "type": "commit"}, {"oid": "baeef9cad915d22678151920ac968bc675a3116f", "url": "https://github.com/apache/hbase/commit/baeef9cad915d22678151920ac968bc675a3116f", "message": "additional fix checkstyle for HStoreContext", "committedDate": "2020-12-23T20:09:10Z", "type": "commit"}, {"oid": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "url": "https://github.com/apache/hbase/commit/7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "message": "Address comments from stack\n\n- rename HStoreContext to StoreContext\n- rewrite the getChecksumType\n- fix one more style issues", "committedDate": "2020-12-23T20:09:10Z", "type": "commit"}, {"oid": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "url": "https://github.com/apache/hbase/commit/7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "message": "Address comments from stack\n\n- rename HStoreContext to StoreContext\n- rewrite the getChecksumType\n- fix one more style issues", "committedDate": "2020-12-23T20:09:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIwMDQ0Ng==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548200446", "bodyText": "Should this be final? I wouldn't expect you would need to change StoreContext (the reference) after it has been initialized", "author": "z-york", "createdAt": "2020-12-23T20:15:38Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -246,6 +234,8 @@\n   private AtomicLong compactedCellsSize = new AtomicLong();\n   private AtomicLong majorCompactedCellsSize = new AtomicLong();\n \n+  private StoreContext storeContext;", "originalCommit": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI4MTg0Mw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548281843", "bodyText": "you're right, it could be final, will do it in next commit", "author": "taklwu", "createdAt": "2020-12-23T22:07:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIwMDQ0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "8a9af9fa8f2efcd7bfda6cff4dd4635f1227d810", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex c617ae46d6..4fc79a38c1 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -234,7 +234,7 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n   private AtomicLong compactedCellsSize = new AtomicLong();\n   private AtomicLong majorCompactedCellsSize = new AtomicLong();\n \n-  private StoreContext storeContext;\n+  private final StoreContext storeContext;\n \n   /**\n    * Constructor\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIwMzc2NA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548203764", "bodyText": "Does it simplify things to be able to pass StoreContext directly to the builders?", "author": "z-york", "createdAt": "2020-12-23T20:20:45Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -1236,18 +1248,19 @@ private HFileContext createFileContext(Compression.Algorithm compression,\n                                 .withIncludesMvcc(includeMVCCReadpoint)\n                                 .withIncludesTags(includesTag)\n                                 .withCompression(compression)\n-                                .withCompressTags(family.isCompressTags())\n-                                .withChecksumType(checksumType)\n-                                .withBytesPerCheckSum(bytesPerChecksum)\n+                                .withCompressTags(getColumnFamilyDescriptor().isCompressTags())", "originalCommit": "7725f5f131525c73a27cd4e5e26eedd8ee8920bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODI4NjM5NQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r548286395", "bodyText": "I'd like to keep the current way that passing required fields to the creation of HFileContext.  Mainly HFileContext is also a member of the StoreContext which if we pass into StoreContext to the creation of HFileContext, it will be a loop and is very strange.", "author": "taklwu", "createdAt": "2020-12-23T22:14:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODIwMzc2NA=="}], "type": "inlineReview", "revised_code": {"commit": "8a9af9fa8f2efcd7bfda6cff4dd4635f1227d810", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex c617ae46d6..4fc79a38c1 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -1254,12 +1254,12 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n                                 .withBlockSize(blocksize)\n                                 .withHBaseCheckSum(true)\n                                 .withDataBlockEncoding(getColumnFamilyDescriptor()\n-                                      .getDataBlockEncoding())\n+                                  .getDataBlockEncoding())\n                                 .withEncryptionContext(cryptoContext)\n                                 .withCreateTime(EnvironmentEdgeManager.currentTime())\n                                 .withColumnFamily(getColumnFamilyDescriptor().getName())\n                                 .withTableName(region.getTableDescriptor()\n-                                    .getTableName().getName())\n+                                  .getTableName().getName())\n                                 .withCellComparator(getComparator())\n                                 .build();\n     return hFileContext;\n"}}, {"oid": "8a9af9fa8f2efcd7bfda6cff4dd4635f1227d810", "url": "https://github.com/apache/hbase/commit/8a9af9fa8f2efcd7bfda6cff4dd4635f1227d810", "message": "make storecontext final in HStore and fix import", "committedDate": "2020-12-23T22:17:43Z", "type": "commit"}, {"oid": "b3c9561e16621296589f36554419e28edb67cdf9", "url": "https://github.com/apache/hbase/commit/b3c9561e16621296589f36554419e28edb67cdf9", "message": "use storecontext with writer generation", "committedDate": "2020-12-24T00:14:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUxMzM5Ng==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r549513396", "bodyText": "Does it make sense to return the supplier or just a straight getter where internal to this method it calls and returns the result of the .get()?", "author": "z-york", "createdAt": "2020-12-28T23:06:35Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.function.Supplier;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.CellComparator;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.io.HeapSize;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.util.ClassSize;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+/**\n+ * This carries the information on some of the meta data about the HStore. This\n+ * meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n+ * need of passing around the complete store.\n+ */\n+@InterfaceAudience.Private\n+public final class StoreContext implements HeapSize {\n+  public static final long FIXED_OVERHEAD = ClassSize.estimateBase(HStore.class, false);\n+\n+  private final HFileContext defaultFileContext;\n+  private final CacheConfig cacheConf;\n+  private final HRegionFileSystem regionFileSystem;\n+  private final CellComparator comparator;\n+  private final BloomType bloomFilterType;\n+  private final Supplier<Collection<HStoreFile>> compactedFilesSupplier;\n+  private final Supplier<InetSocketAddress[]> favoredNodesSupplier;\n+  private final ColumnFamilyDescriptor family;\n+  private final Path familyStoreDirectoryPath;\n+  private final RegionCoprocessorHost coprocessorHost;\n+\n+  private StoreContext(Builder builder) {\n+    this.defaultFileContext = builder.defaultFileContext;\n+    this.cacheConf = builder.cacheConf;\n+    this.regionFileSystem = builder.regionFileSystem;\n+    this.comparator = builder.comparator;\n+    this.bloomFilterType = builder.bloomFilterType;\n+    this.compactedFilesSupplier = builder.compactedFilesSupplier;\n+    this.favoredNodesSupplier = builder.favoredNodesSupplier;\n+    this.family = builder.family;\n+    this.familyStoreDirectoryPath = builder.familyStoreDirectoryPath;\n+    this.coprocessorHost = builder.coprocessorHost;\n+  }\n+\n+  public HFileContext getDefaultFileContext() {\n+    return defaultFileContext;\n+  }\n+\n+  public CacheConfig getCacheConf() {\n+    return cacheConf;\n+  }\n+\n+  public HRegionFileSystem getRegionFileSystem() {\n+    return regionFileSystem;\n+  }\n+\n+  public CellComparator getComparator() {\n+    return comparator;\n+  }\n+\n+  public BloomType getBloomFilterType() {\n+    return bloomFilterType;\n+  }\n+\n+  public Supplier<Collection<HStoreFile>> getCompactedFilesSupplier() {\n+    return compactedFilesSupplier;\n+  }\n+\n+  public Supplier<InetSocketAddress[]> getFavoredNodesSupplier() {\n+    return favoredNodesSupplier;\n+  }", "originalCommit": "b3c9561e16621296589f36554419e28edb67cdf9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUxNDE3OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r549514178", "bodyText": "I guess the answer to this will depend on whether we expect the contents to change... I see it is passed into the HFileContext... is it evaluated right away or only used when it is needed?", "author": "z-york", "createdAt": "2020-12-28T23:10:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUxMzM5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTg5NDk5MQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r549894991", "bodyText": "For the getCompactedFilesSupplier(), we should keep it as using supplier because the actual values at that time will be used when StoreFileWriter.java#appendMetadata is being called for writing COMPACTION_EVENT_KEY. unless we change the builder of StoreFileWriter, I would propose to keep the supplier like this.\nfor the getFavoredNodesSupplier(), I think you may be right that withFavoredNodes could be using the values directly per writer creation, will update in next change.", "author": "taklwu", "createdAt": "2020-12-30T00:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUxMzM5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\nindex 53ce790d7f..1a66076f1c 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\n\n@@ -86,8 +86,8 @@ public final class StoreContext implements HeapSize {\n     return compactedFilesSupplier;\n   }\n \n-  public Supplier<InetSocketAddress[]> getFavoredNodesSupplier() {\n-    return favoredNodesSupplier;\n+  public InetSocketAddress[] getFavoredNodes() {\n+    return favoredNodesSupplier.get();\n   }\n \n   public ColumnFamilyDescriptor getFamily() {\n"}}, {"oid": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "url": "https://github.com/apache/hbase/commit/5e87534477d0f130a10476ae6b1ae2128c21d28c", "message": "hide supplier from the getter of `FavoredNodes`", "committedDate": "2020-12-30T00:18:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NTgwNw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552255807", "bodyText": "Whats going on here?\nHFileContext is supposed to be ' Read-only HFile Context Information' but here we are adding a setter. I see there are one or two setters but we also have HFileContextBuilder. Shouldn't we be going via the Builder making HFileContexts? And why is this method not added on the Builder? (Can it be added non-public to encourage users to go via the Builder)?", "author": "saintstack", "createdAt": "2021-01-05T23:17:27Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java", "diffHunk": "@@ -138,6 +138,10 @@ public boolean isCompressedOrEncrypted() {\n     return compressAlgo;\n   }\n \n+  public void setCompression(Compression.Algorithm compressAlgo) {\n+    this.compressAlgo = compressAlgo;\n+  }\n+", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMTY1Ng==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552321656", "bodyText": "fixed, and reverted back to builder pattern", "author": "taklwu", "createdAt": "2021-01-06T01:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NTgwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM4MjQ3Mg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552382472", "bodyText": "You haven't uploaded new PR so will leave this as unresovled for now.", "author": "saintstack", "createdAt": "2021-01-06T05:48:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NTgwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM4OTAzOQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552389039", "bodyText": "oops, I missed this change. and now it should have updated/removed.", "author": "taklwu", "createdAt": "2021-01-06T06:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NTgwNw=="}], "type": "inlineReview", "revised_code": {"commit": "8a0269fbe6faa6b12edfab1db13c36d923558576", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\nindex 2e8da6481a..cfadb6cfd3 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\n\n@@ -138,10 +138,6 @@ public class HFileContext implements HeapSize, Cloneable {\n     return compressAlgo;\n   }\n \n-  public void setCompression(Compression.Algorithm compressAlgo) {\n-    this.compressAlgo = compressAlgo;\n-  }\n-\n   public boolean isUseHBaseChecksum() {\n     return usesHBaseChecksum;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NzU3OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552257579", "bodyText": "nit: why bother with this change at all? 'family' is passed on the constructor. Its final. Why bother going via the accessor in the constructor?", "author": "saintstack", "createdAt": "2021-01-05T23:22:30Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -254,48 +244,47 @@\n   protected HStore(final HRegion region, final ColumnFamilyDescriptor family,\n       final Configuration confParam, boolean warmup) throws IOException {\n \n-    this.fs = region.getRegionFileSystem();\n-\n-    // Assemble the store's home directory and Ensure it exists.\n-    fs.createStoreDir(family.getNameAsString());\n-    this.region = region;\n-    this.family = family;\n     // 'conf' renamed to 'confParam' b/c we use this.conf in the constructor\n     // CompoundConfiguration will look for keys in reverse order of addition, so we'd\n     // add global config first, then table and cf overrides, then cf metadata.\n     this.conf = new CompoundConfiguration()\n-      .add(confParam)\n-      .addBytesMap(region.getTableDescriptor().getValues())\n-      .addStringMap(family.getConfiguration())\n-      .addBytesMap(family.getValues());\n-    this.blocksize = family.getBlocksize();\n+        .add(confParam)\n+        .addBytesMap(region.getTableDescriptor().getValues())\n+        .addStringMap(family.getConfiguration())\n+        .addBytesMap(family.getValues());\n+\n+    this.region = region;\n+    this.storeContext = initializeStoreContext(family);\n+\n+    // Assemble the store's home directory and Ensure it exists.\n+    getRegionFileSystem().createStoreDir(getColumnFamilyName());\n+\n+    this.blocksize = getColumnFamilyDescriptor().getBlocksize();\n \n     // set block storage policy for store directory\n-    String policyName = family.getStoragePolicy();\n+    String policyName = getColumnFamilyDescriptor().getStoragePolicy();", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMTUyNg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552321526", "bodyText": "fixed.", "author": "taklwu", "createdAt": "2021-01-06T01:59:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1NzU3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b2df4758903235ba4feb7508d0986debb35e32a9", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8a8191d09f..4d740db1f6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -257,12 +256,10 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n     this.storeContext = initializeStoreContext(family);\n \n     // Assemble the store's home directory and Ensure it exists.\n-    getRegionFileSystem().createStoreDir(getColumnFamilyName());\n-\n-    this.blocksize = getColumnFamilyDescriptor().getBlocksize();\n+    getRegionFileSystem().createStoreDir(family.getNameAsString());\n \n     // set block storage policy for store directory\n-    String policyName = getColumnFamilyDescriptor().getStoragePolicy();\n+    String policyName = family.getStoragePolicy();\n     if (null == policyName) {\n       policyName = this.conf.get(BLOCK_STORAGE_POLICY_KEY, DEFAULT_BLOCK_STORAGE_POLICY);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1ODc4OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552258789", "bodyText": "Could be static?", "author": "saintstack", "createdAt": "2021-01-05T23:26:02Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -347,6 +331,48 @@ protected HStore(final HRegion region, final ColumnFamilyDescriptor family,\n     cacheOnWriteLogged = false;\n   }\n \n+  private StoreContext initializeStoreContext(ColumnFamilyDescriptor family) throws IOException {\n+    return new StoreContext.Builder()\n+        .withBloomType(family.getBloomFilterType())\n+        .withCacheConfig(createCacheConf(family))\n+        .withCellComparator(region.getCellComparator())\n+        .withColumnFamilyDescriptor(family)\n+        .withCompactedFilesSupplier(this::getCompactedFiles)\n+        .withRegionFileSystem(region.getRegionFileSystem())\n+        .withDefaultHFileContext(getDefaultHFileContext(family))\n+        .withFavoredNodesSupplier(this::getFavoredNodes)\n+        .withFamilyStoreDirectoryPath(region.getRegionFileSystem()\n+            .getStoreDir(family.getNameAsString()))\n+        .withRegionCoprocessorHost(region.getCoprocessorHost())\n+        .build();\n+  }\n+\n+  private InetSocketAddress[] getFavoredNodes() {\n+    InetSocketAddress[] favoredNodes = null;\n+    if (region.getRegionServerServices() != null) {\n+      favoredNodes = region.getRegionServerServices().getFavoredNodesForRegion(\n+          region.getRegionInfo().getEncodedName());\n+    }\n+    return favoredNodes;\n+  }\n+\n+  private HFileContext getDefaultHFileContext(ColumnFamilyDescriptor family) throws IOException {", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMTQ3OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552321478", "bodyText": "the conf and region used within this function was blocking it to be static, but thinking it again, having this big defaultHFileContext within StoreFileContext is strange and the original thought was to reuse reference if we can.\nI will remove this getDefaultHFileContext and defaultHFileContext in StoreContext", "author": "taklwu", "createdAt": "2021-01-06T01:58:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1ODc4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b2df4758903235ba4feb7508d0986debb35e32a9", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8a8191d09f..4d740db1f6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -333,18 +330,19 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n \n   private StoreContext initializeStoreContext(ColumnFamilyDescriptor family) throws IOException {\n     return new StoreContext.Builder()\n-        .withBloomType(family.getBloomFilterType())\n-        .withCacheConfig(createCacheConf(family))\n-        .withCellComparator(region.getCellComparator())\n-        .withColumnFamilyDescriptor(family)\n-        .withCompactedFilesSupplier(this::getCompactedFiles)\n-        .withRegionFileSystem(region.getRegionFileSystem())\n-        .withDefaultHFileContext(getDefaultHFileContext(family))\n-        .withFavoredNodesSupplier(this::getFavoredNodes)\n-        .withFamilyStoreDirectoryPath(region.getRegionFileSystem()\n-            .getStoreDir(family.getNameAsString()))\n-        .withRegionCoprocessorHost(region.getCoprocessorHost())\n-        .build();\n+      .withBlockSize(family.getBlocksize())\n+      .withEncryptionContext(EncryptionUtil.createEncryptionContext(conf, family))\n+      .withBloomType(family.getBloomFilterType())\n+      .withCacheConfig(createCacheConf(family))\n+      .withCellComparator(region.getCellComparator())\n+      .withColumnFamilyDescriptor(family)\n+      .withCompactedFilesSupplier(this::getCompactedFiles)\n+      .withRegionFileSystem(region.getRegionFileSystem())\n+      .withFavoredNodesSupplier(this::getFavoredNodes)\n+      .withFamilyStoreDirectoryPath(region.getRegionFileSystem()\n+        .getStoreDir(family.getNameAsString()))\n+      .withRegionCoprocessorHost(region.getCoprocessorHost())\n+      .build();\n   }\n \n   private InetSocketAddress[] getFavoredNodes() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1OTM0Ng==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552259346", "bodyText": "Has to be public? Has to be on HStore? Can it be on StoreContext? Is there a getStoreContext method on HStore?", "author": "saintstack", "createdAt": "2021-01-05T23:27:32Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -474,33 +502,14 @@ public long getBlockingFileCount() {\n   }\n   /* End implementation of StoreConfigInformation */\n \n-  /**\n-   * Returns the configured bytesPerChecksum value.\n-   * @param conf The configuration\n-   * @return The bytesPerChecksum that is set in the configuration\n-   */\n-  public static int getBytesPerChecksum(Configuration conf) {\n-    return conf.getInt(HConstants.BYTES_PER_CHECKSUM,\n-                       HFile.DEFAULT_BYTES_PER_CHECKSUM);\n-  }\n-\n-  /**\n-   * Returns the configured checksum algorithm.\n-   * @param conf The configuration\n-   * @return The checksum algorithm that is set in the configuration\n-   */\n-  public static ChecksumType getChecksumType(Configuration conf) {\n-    String checksumName = conf.get(HConstants.CHECKSUM_TYPE_NAME);\n-    if (checksumName == null) {\n-      return ChecksumType.getDefaultChecksumType();\n-    } else {\n-      return ChecksumType.nameToType(checksumName);\n-    }\n-  }\n \n   @Override\n   public ColumnFamilyDescriptor getColumnFamilyDescriptor() {\n-    return this.family;\n+    return this.storeContext.getFamily();\n+  }\n+\n+  public Encryption.Context getEncryptionContext() {", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMTA2OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552321068", "bodyText": "getEncryptionContext was used by HMobStore such we set it to public , it could be package-private.\ngetStoreContext was planned to add in a followup PR when used, tho you're right that if we have a getStoreContext then this getEncryptionContext could be removed", "author": "taklwu", "createdAt": "2021-01-06T01:57:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1OTM0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM4MTkxMQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552381911", "bodyText": "Package private sounds good if only used locally.", "author": "saintstack", "createdAt": "2021-01-06T05:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI1OTM0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b2df4758903235ba4feb7508d0986debb35e32a9", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8a8191d09f..4d740db1f6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -508,10 +498,6 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n     return this.storeContext.getFamily();\n   }\n \n-  public Encryption.Context getEncryptionContext() {\n-    return storeContext.getDefaultFileContext().getEncryptionContext();\n-  }\n-\n   @Override\n   public OptionalLong getMaxSequenceId() {\n     return StoreUtils.getMaxSequenceIdInList(this.getStorefiles());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDA2NQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552260065", "bodyText": "Why would we do this here and not as methods on the builder?", "author": "saintstack", "createdAt": "2021-01-05T23:29:48Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -1206,53 +1218,34 @@ public StoreFileWriter createWriterInTmp(long maxKeyCount, Compression.Algorithm\n         }\n       }\n     }\n-    InetSocketAddress[] favoredNodes = null;\n-    if (region.getRegionServerServices() != null) {\n-      favoredNodes = region.getRegionServerServices().getFavoredNodesForRegion(\n-          region.getRegionInfo().getEncodedName());\n-    }\n-    HFileContext hFileContext = createFileContext(compression, includeMVCCReadpoint, includesTag,\n-      cryptoContext);\n-    Path familyTempDir = new Path(fs.getTempDir(), family.getNameAsString());\n-    StoreFileWriter.Builder builder = new StoreFileWriter.Builder(conf, writerCacheConf,\n-        this.getFileSystem())\n-            .withOutputDir(familyTempDir)\n-            .withBloomType(family.getBloomFilterType())\n-            .withMaxKeyCount(maxKeyCount)\n-            .withFavoredNodes(favoredNodes)\n-            .withFileContext(hFileContext)\n-            .withShouldDropCacheBehind(shouldDropBehind)\n-            .withCompactedFilesSupplier(this::getCompactedFiles)\n-            .withFileStoragePolicy(fileStoragePolicy);\n+    HFileContext hFileContext = createFileContext(compression, includeMVCCReadpoint, includesTag);\n+    Path familyTempDir = new Path(getRegionFileSystem().getTempDir(), getColumnFamilyName());\n+    StoreFileWriter.Builder builder =\n+      new StoreFileWriter.Builder(conf, writerCacheConf, getFileSystem())\n+        .withOutputDir(familyTempDir)\n+        .withBloomType(storeContext.getBloomFilterType())\n+        .withMaxKeyCount(maxKeyCount)\n+        .withFavoredNodes(storeContext.getFavoredNodes())\n+        .withFileContext(hFileContext)\n+        .withShouldDropCacheBehind(shouldDropBehind)\n+        .withCompactedFilesSupplier(storeContext.getCompactedFilesSupplier())\n+        .withFileStoragePolicy(fileStoragePolicy);\n     return builder.build();\n   }\n \n   private HFileContext createFileContext(Compression.Algorithm compression,\n-      boolean includeMVCCReadpoint, boolean includesTag, Encryption.Context cryptoContext) {\n+    boolean includeMVCCReadpoint, boolean includesTag) {\n     if (compression == null) {\n       compression = HFile.DEFAULT_COMPRESSION_ALGORITHM;\n     }\n-    HFileContext hFileContext = new HFileContextBuilder()\n-                                .withIncludesMvcc(includeMVCCReadpoint)\n-                                .withIncludesTags(includesTag)\n-                                .withCompression(compression)\n-                                .withCompressTags(family.isCompressTags())\n-                                .withChecksumType(checksumType)\n-                                .withBytesPerCheckSum(bytesPerChecksum)\n-                                .withBlockSize(blocksize)\n-                                .withHBaseCheckSum(true)\n-                                .withDataBlockEncoding(family.getDataBlockEncoding())\n-                                .withEncryptionContext(cryptoContext)\n-                                .withCreateTime(EnvironmentEdgeManager.currentTime())\n-                                .withColumnFamily(family.getName())\n-                                .withTableName(region.getTableDescriptor()\n-                                    .getTableName().getName())\n-                                .withCellComparator(this.comparator)\n-                                .build();\n-    return hFileContext;\n+    HFileContext fileContext = storeContext.getDefaultFileContext();\n+    fileContext.setIncludesMvcc(includeMVCCReadpoint);\n+    fileContext.setIncludesTags(includesTag);\n+    fileContext.setCompression(compression);\n+    fileContext.setFileCreateTime(EnvironmentEdgeManager.currentTime());", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMDcwOQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552320709", "bodyText": "it was trying to reuse the defaultFileContext built with initializeStoreContext, but after rethinking on your comment, I'm going to remove the defaultFileContext and go back with the original builder pattern.", "author": "taklwu", "createdAt": "2021-01-06T01:56:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM4MTAwMg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552381002", "bodyText": "That'd be better. If a builder, lets use it everywhere (can add a constructor on builder that allows a bit of shortcutting auto-filling most fields....)", "author": "saintstack", "createdAt": "2021-01-06T05:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDA2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "b2df4758903235ba4feb7508d0986debb35e32a9", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8a8191d09f..4d740db1f6 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -1218,7 +1204,9 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n         }\n       }\n     }\n-    HFileContext hFileContext = createFileContext(compression, includeMVCCReadpoint, includesTag);\n+    Encryption.Context encryptionContext = storeContext.getEncryptionContext();\n+    HFileContext hFileContext = createFileContext(compression, includeMVCCReadpoint, includesTag,\n+      encryptionContext);\n     Path familyTempDir = new Path(getRegionFileSystem().getTempDir(), getColumnFamilyName());\n     StoreFileWriter.Builder builder =\n       new StoreFileWriter.Builder(conf, writerCacheConf, getFileSystem())\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDU0MQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552260541", "bodyText": "I would like to know here in class comment if this is read-only/immutable. I think it should be.", "author": "saintstack", "createdAt": "2021-01-05T23:31:10Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.function.Supplier;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.CellComparator;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.io.HeapSize;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.util.ClassSize;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+/**\n+ * This carries the information on some of the meta data about the HStore. This\n+ * meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n+ * need of passing around the complete store.", "originalCommit": "5e87534477d0f130a10476ae6b1ae2128c21d28c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MTU3OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552261579", "bodyText": "Also, just a comment... the HFileContext has this for a comment...\n\nRead-only HFile Context Information. Meta data that is used by HFileWriter/Readers and by\nHFileBlocks. Create one using the {@link HFileContextBuilder} (See HFileInfo and the HFile\nTrailer class).\n\nso it is for readers and writers.... So, StoreContext is probably fine but if you are wondering... here is incidences of Info.java vs Context.java....  If it helps.\nkalashnikov:hbase.apache.git stack$ find src/main/java -name *Info.java\nfind: src/main/java: No such file or directory\nkalashnikov:hbase.apache.git stack$ find hbase-*/src/main/java -name *Info.java\nhbase-backup/src/main/java/org/apache/hadoop/hbase/backup/BackupTableInfo.java\nhbase-backup/src/main/java/org/apache/hadoop/hbase/backup/BackupInfo.java\nhbase-client/src/main/java/org/apache/hadoop/hbase/security/SecurityInfo.java\nhbase-client/src/main/java/org/apache/hadoop/hbase/client/MutableRegionInfo.java\nhbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionInfo.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/rsgroup/RSGroupInfo.java\nhbase-hbtop/src/main/java/org/apache/hadoop/hbase/hbtop/mode/DrillDownInfo.java\nhbase-hbtop/src/main/java/org/apache/hadoop/hbase/hbtop/field/FieldInfo.java\nhbase-metrics-api/src/main/java/org/apache/hadoop/hbase/metrics/MetricRegistryInfo.java\nhbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueueInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/HbckTableInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/HbckRegionInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/BlockWithScanInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/namespace/NamespaceTableAndRegionInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/master/webapp/RegionReplicaInfo.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallQueueInfo.java\nhbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THRegionInfo.java\nhbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TRegionInfo.java\n\n\nkalashnikov:hbase.apache.git stack$ find hbase-*/src/main/java -name *Context.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/Context.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDecodingContext.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockEncodingContext.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultDecodingContext.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContext.java\nhbase-common/src/main/java/org/apache/hadoop/hbase/io/TagCompressionContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/RowPrefixFixedLengthBloomContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/RowBloomContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/RowColBloomContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/util/BloomContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/ReaderContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/ObserverContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/CompressionContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScannerContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/NoLimitScannerContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFlushContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcCallContext.java\nhbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcSchedulerContext.java", "author": "saintstack", "createdAt": "2021-01-05T23:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDU0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjMyMDY3OA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552320678", "bodyText": "thanks for sharing a list of *Info and *Context, I browsed few of them and seems Context should be still okie. so let's keep it with StoreContext and made this change simple, and I add the immutable keyword in the block of the class comment.", "author": "taklwu", "createdAt": "2021-01-06T01:56:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDU0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjM4MDc5Nw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552380797", "bodyText": "Sounds good.", "author": "saintstack", "createdAt": "2021-01-06T05:42:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjI2MDU0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b2df4758903235ba4feb7508d0986debb35e32a9", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\nindex 1a66076f1c..26233505db 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java\n\n@@ -24,21 +24,22 @@ import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.hbase.CellComparator;\n import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n import org.apache.hadoop.hbase.io.HeapSize;\n+import org.apache.hadoop.hbase.io.crypto.Encryption;\n import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n-import org.apache.hadoop.hbase.io.hfile.HFileContext;\n import org.apache.hadoop.hbase.util.ClassSize;\n import org.apache.yetus.audience.InterfaceAudience;\n \n /**\n- * This carries the information on some of the meta data about the HStore. This\n- * meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n+ * This carries the immutable information and references on some of the meta data about the HStore.\n+ * This meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n  * need of passing around the complete store.\n  */\n @InterfaceAudience.Private\n public final class StoreContext implements HeapSize {\n   public static final long FIXED_OVERHEAD = ClassSize.estimateBase(HStore.class, false);\n \n-  private final HFileContext defaultFileContext;\n+  private final int blockSize;\n+  private final Encryption.Context encryptionContext;\n   private final CacheConfig cacheConf;\n   private final HRegionFileSystem regionFileSystem;\n   private final CellComparator comparator;\n"}}, {"oid": "b2df4758903235ba4feb7508d0986debb35e32a9", "url": "https://github.com/apache/hbase/commit/b2df4758903235ba4feb7508d0986debb35e32a9", "message": "address comments and remove the defaultFileContext from StoreContext", "committedDate": "2021-01-06T02:01:56Z", "type": "commit"}, {"oid": "8a0269fbe6faa6b12edfab1db13c36d923558576", "url": "https://github.com/apache/hbase/commit/8a0269fbe6faa6b12edfab1db13c36d923558576", "message": "removed setter for encryptionContext in HFileContext and fixed indentation in constructor of HStore", "committedDate": "2021-01-06T06:09:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyMDgxNg==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552820816", "bodyText": "You were going to change these back?", "author": "saintstack", "createdAt": "2021-01-06T17:12:22Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -268,34 +251,37 @@ protected HStore(final HRegion region, final ColumnFamilyDescriptor family,\n       .addBytesMap(region.getTableDescriptor().getValues())\n       .addStringMap(family.getConfiguration())\n       .addBytesMap(family.getValues());\n-    this.blocksize = family.getBlocksize();\n+\n+    this.region = region;\n+    this.storeContext = initializeStoreContext(family);\n+\n+    // Assemble the store's home directory and Ensure it exists.\n+    getRegionFileSystem().createStoreDir(family.getNameAsString());\n \n     // set block storage policy for store directory\n     String policyName = family.getStoragePolicy();\n     if (null == policyName) {\n       policyName = this.conf.get(BLOCK_STORAGE_POLICY_KEY, DEFAULT_BLOCK_STORAGE_POLICY);\n     }\n-    this.fs.setStoragePolicy(family.getNameAsString(), policyName.trim());\n+    getRegionFileSystem().setStoragePolicy(getColumnFamilyName(), policyName.trim());", "originalCommit": "8a0269fbe6faa6b12edfab1db13c36d923558576", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjg4NzYzOQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552887639", "bodyText": "changed back to use family and region.getRegionFileSystem() directly.", "author": "taklwu", "createdAt": "2021-01-06T18:26:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyMDgxNg=="}], "type": "inlineReview", "revised_code": {"commit": "4b8ab2955ad3d9810256d7f22d7de630c5617364", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8161747392..99880efece 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -256,28 +256,26 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n     this.storeContext = initializeStoreContext(family);\n \n     // Assemble the store's home directory and Ensure it exists.\n-    getRegionFileSystem().createStoreDir(family.getNameAsString());\n+    region.getRegionFileSystem().createStoreDir(family.getNameAsString());\n \n     // set block storage policy for store directory\n     String policyName = family.getStoragePolicy();\n     if (null == policyName) {\n       policyName = this.conf.get(BLOCK_STORAGE_POLICY_KEY, DEFAULT_BLOCK_STORAGE_POLICY);\n     }\n-    getRegionFileSystem().setStoragePolicy(getColumnFamilyName(), policyName.trim());\n+    region.getRegionFileSystem().setStoragePolicy(family.getNameAsString(), policyName.trim());\n \n-    this.dataBlockEncoder = new HFileDataBlockEncoderImpl(getColumnFamilyDescriptor()\n-        .getDataBlockEncoding());\n+    this.dataBlockEncoder = new HFileDataBlockEncoderImpl(family.getDataBlockEncoding());\n \n     // used by ScanQueryMatcher\n     long timeToPurgeDeletes =\n         Math.max(conf.getLong(\"hbase.hstore.time.to.purge.deletes\", 0), 0);\n     LOG.trace(\"Time to purge deletes set to {}ms in {}\", timeToPurgeDeletes, this);\n     // Get TTL\n-    long ttl = determineTTLFromFamily(getColumnFamilyDescriptor());\n+    long ttl = determineTTLFromFamily(family);\n     // Why not just pass a HColumnDescriptor in here altogether?  Even if have\n     // to clone it?\n-    scanInfo = new ScanInfo(conf, getColumnFamilyDescriptor(), ttl, timeToPurgeDeletes,\n-        getComparator());\n+    scanInfo = new ScanInfo(conf, family, ttl, timeToPurgeDeletes, region.getCellComparator());\n     this.memstore = getMemstore();\n \n     this.offPeakHours = OffPeakHours.getInstance(conf);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyMTA0OQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552821049", "bodyText": "ditto", "author": "saintstack", "createdAt": "2021-01-06T17:12:37Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -308,7 +294,7 @@ protected HStore(final HRegion region, final ColumnFamilyDescriptor family,\n       this.compactionCheckMultiplier = DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER;\n     }\n \n-    this.storeEngine = createStoreEngine(this, this.conf, this.comparator);\n+    this.storeEngine = createStoreEngine(this, this.conf, getComparator());", "originalCommit": "8a0269fbe6faa6b12edfab1db13c36d923558576", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjg4Nzg1MQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552887851", "bodyText": "changed to use region.getCellComparator().", "author": "taklwu", "createdAt": "2021-01-06T18:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyMTA0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "4b8ab2955ad3d9810256d7f22d7de630c5617364", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8161747392..99880efece 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n\n@@ -294,7 +292,7 @@ public class HStore implements Store, HeapSize, StoreConfigInformation,\n       this.compactionCheckMultiplier = DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER;\n     }\n \n-    this.storeEngine = createStoreEngine(this, this.conf, getComparator());\n+    this.storeEngine = createStoreEngine(this, this.conf, region.getCellComparator());\n     List<HStoreFile> hStoreFiles = loadStoreFiles(warmup);\n     // Move the storeSize calculation out of loadStoreFiles() method, because the secondary read\n     // replica's refreshStoreFiles() will also use loadStoreFiles() to refresh its store files and\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyNjQxOA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552826418", "bodyText": "Is this necessary? Its available on the ColumnFamilyDescriptor. Do we need to add new method on Store?\nWas this change always here or did it just show up in recent amendments to PRs (I don't remember seeing it before but probably just me).\nThanks.", "author": "saintstack", "createdAt": "2021-01-06T17:18:20Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java", "diffHunk": "@@ -46,6 +46,8 @@\n   int PRIORITY_USER = 1;\n   int NO_PRIORITY = Integer.MIN_VALUE;\n \n+  int getBlockSize();", "originalCommit": "8a0269fbe6faa6b12edfab1db13c36d923558576", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjg3NDg3Mw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552874873", "bodyText": "this was new change in the latest commit of this PR, mainly it's used for HMobStore when calling createWriterInTmp. but let me change it using  getStoreContext().getBlockSize() to avoid adding a new interface.", "author": "taklwu", "createdAt": "2021-01-06T18:10:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyNjQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjg4NDU3Mw==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552884573", "bodyText": "Yes. Please. Then I'll +1 this nice PR. Thanks.", "author": "saintstack", "createdAt": "2021-01-06T18:21:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjgyNjQxOA=="}], "type": "inlineReview", "revised_code": {"commit": "4b8ab2955ad3d9810256d7f22d7de630c5617364", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\nindex 5414c51146..6ec9c51930 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\n\n@@ -46,8 +46,6 @@ public interface Store {\n   int PRIORITY_USER = 1;\n   int NO_PRIORITY = Integer.MIN_VALUE;\n \n-  int getBlockSize();\n-\n   // General Accessors\n   CellComparator getComparator();\n \n"}}, {"oid": "4b8ab2955ad3d9810256d7f22d7de630c5617364", "url": "https://github.com/apache/hbase/commit/4b8ab2955ad3d9810256d7f22d7de630c5617364", "message": "remove getters in constructor of HStore and remove getBlockSize from Store interface", "committedDate": "2021-01-06T18:24:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjk4NjA4MQ==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r552986081", "bodyText": "@apurtell ping again on the heapSize() and implements HeapSize for StoreContext class, could you have another look? I should have fixed it, but will wait for your approval/resolve in 1 day or 2 day before merging it.", "author": "taklwu", "createdAt": "2021-01-06T22:07:47Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreContext.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.net.InetSocketAddress;\n+import java.util.Collection;\n+import java.util.function.Supplier;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.CellComparator;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.io.HeapSize;\n+import org.apache.hadoop.hbase.io.crypto.Encryption;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.util.ClassSize;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+/**\n+ * This carries the immutable information and references on some of the meta data about the HStore.\n+ * This meta data can be used across the HFileWriter/Readers and other HStore consumers without the\n+ * need of passing around the complete store.\n+ */\n+@InterfaceAudience.Private\n+public final class StoreContext implements HeapSize {\n+  public static final long FIXED_OVERHEAD = ClassSize.estimateBase(HStore.class, false);\n+\n+  private final int blockSize;\n+  private final Encryption.Context encryptionContext;\n+  private final CacheConfig cacheConf;\n+  private final HRegionFileSystem regionFileSystem;\n+  private final CellComparator comparator;\n+  private final BloomType bloomFilterType;\n+  private final Supplier<Collection<HStoreFile>> compactedFilesSupplier;\n+  private final Supplier<InetSocketAddress[]> favoredNodesSupplier;\n+  private final ColumnFamilyDescriptor family;\n+  private final Path familyStoreDirectoryPath;\n+  private final RegionCoprocessorHost coprocessorHost;\n+\n+  private StoreContext(Builder builder) {\n+    this.blockSize = builder.blockSize;\n+    this.encryptionContext = builder.encryptionContext;\n+    this.cacheConf = builder.cacheConf;\n+    this.regionFileSystem = builder.regionFileSystem;\n+    this.comparator = builder.comparator;\n+    this.bloomFilterType = builder.bloomFilterType;\n+    this.compactedFilesSupplier = builder.compactedFilesSupplier;\n+    this.favoredNodesSupplier = builder.favoredNodesSupplier;\n+    this.family = builder.family;\n+    this.familyStoreDirectoryPath = builder.familyStoreDirectoryPath;\n+    this.coprocessorHost = builder.coprocessorHost;\n+  }\n+\n+  public int getBlockSize() {\n+    return blockSize;\n+  }\n+\n+  public Encryption.Context getEncryptionContext() {\n+    return encryptionContext;\n+  }\n+\n+  public CacheConfig getCacheConf() {\n+    return cacheConf;\n+  }\n+\n+  public HRegionFileSystem getRegionFileSystem() {\n+    return regionFileSystem;\n+  }\n+\n+  public CellComparator getComparator() {\n+    return comparator;\n+  }\n+\n+  public BloomType getBloomFilterType() {\n+    return bloomFilterType;\n+  }\n+\n+  public Supplier<Collection<HStoreFile>> getCompactedFilesSupplier() {\n+    return compactedFilesSupplier;\n+  }\n+\n+  public InetSocketAddress[] getFavoredNodes() {\n+    return favoredNodesSupplier.get();\n+  }\n+\n+  public ColumnFamilyDescriptor getFamily() {\n+    return family;\n+  }\n+\n+  public Path getFamilyStoreDirectoryPath() {\n+    return familyStoreDirectoryPath;\n+  }\n+\n+  public RegionCoprocessorHost getCoprocessorHost() {\n+    return coprocessorHost;\n+  }\n+\n+  public static Builder getBuilder() {\n+    return new Builder();\n+  }\n+\n+  @Override\n+  public long heapSize() {\n+    return FIXED_OVERHEAD;\n+  }", "originalCommit": "4b8ab2955ad3d9810256d7f22d7de630c5617364", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDE0Nzg4MA==", "url": "https://github.com/apache/hbase/pull/2800#discussion_r554147880", "bodyText": "@apurtell sorry for pinging again, I will merge this evening if I don't hear from you", "author": "taklwu", "createdAt": "2021-01-08T19:30:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjk4NjA4MQ=="}], "type": "inlineReview", "revised_code": null}]}