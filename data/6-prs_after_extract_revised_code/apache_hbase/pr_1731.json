{"pr_number": 1731, "pr_title": "HBASE-24387 TableSnapshotInputFormatImpl support row limit on each InputSplit", "pr_createdAt": "2020-05-18T10:42:13Z", "pr_url": "https://github.com/apache/hbase/pull/1731", "timeline": [{"oid": "2e413d5245ea220daabaa62d4c789c779e69cb96", "url": "https://github.com/apache/hbase/commit/2e413d5245ea220daabaa62d4c789c779e69cb96", "message": "HBASE-24387 TableSnapshotInputFormatImpl support scan limit on each InputSplit", "committedDate": "2020-05-19T05:49:04Z", "type": "forcePushed"}, {"oid": "c4c3e4cf90376d34433fb9e782ac4aa8a0d2407e", "url": "https://github.com/apache/hbase/commit/c4c3e4cf90376d34433fb9e782ac4aa8a0d2407e", "message": "HBASE-24387 TableSnapshotInputFormatImpl support scan limit on each InputSplit", "committedDate": "2020-05-19T05:52:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ4NjQ4Nw==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r427486487", "bodyText": "NIT: Can you please remove this additional empty line?", "author": "HorizonNet", "createdAt": "2020-05-19T17:46:20Z", "path": "hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java", "diffHunk": "@@ -304,6 +304,56 @@ public void testWithMockedMapReduceWithNoStartRowStopRow() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testScanLimit() throws Exception {\n+    setupCluster();\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final String snapshotName = tableName + \"Snapshot\";\n+    Table table = null;\n+    try {\n+      if (UTIL.getAdmin().tableExists(tableName)) {\n+        UTIL.deleteTable(tableName);\n+      }\n+\n+      UTIL.createTable(tableName, FAMILIES, new byte[][] { bbb, yyy });\n+\n+      Admin admin = UTIL.getAdmin();\n+\n+      int regionNum = admin.getRegions(tableName).size();\n+      // put some stuff in the table\n+      table = UTIL.getConnection().getTable(tableName);\n+      UTIL.loadTable(table, FAMILIES);\n+\n+      Path rootDir = CommonFSUtils.getRootDir(UTIL.getConfiguration());\n+      FileSystem fs = rootDir.getFileSystem(UTIL.getConfiguration());\n+\n+      SnapshotTestingUtils.createSnapshotAndValidate(admin, tableName, Arrays.asList(FAMILIES),\n+        null, snapshotName, rootDir, fs, true);\n+\n+      Job job = new Job(UTIL.getConfiguration());\n+      Path tmpTableDir = UTIL.getDataTestDirOnTestFS(snapshotName);\n+      // limit the scan\n+      Scan scan = new Scan().setLimit(10);\n+      TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(),\n+        TestTableSnapshotInputFormat.class);\n+\n+      TableMapReduceUtil.initTableSnapshotMapperJob(snapshotName, scan,\n+        RowCounter.RowCounterMapper.class, NullWritable.class, NullWritable.class, job, true,\n+        tmpTableDir);\n+      Assert.assertTrue(job.waitForCompletion(true));\n+      Assert.assertEquals(10 * regionNum,\n+        job.getCounters().findCounter(RowCounter.RowCounterMapper.Counters.ROWS).getValue());\n+    } finally {\n+      if (table != null) {\n+        table.close();\n+      }\n+      UTIL.getAdmin().deleteSnapshot(snapshotName);\n+      UTIL.deleteTable(tableName);\n+      tearDownCluster();\n+    }\n+  }\n+\n+", "originalCommit": "c4c3e4cf90376d34433fb9e782ac4aa8a0d2407e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b4e1f97bf27511554a05205563d7eff185a602b1", "chunk": "diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\nindex 8f87b7ad22..60622d7be2 100644\n--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\n+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\n\n@@ -311,6 +312,7 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa\n     final String snapshotName = tableName + \"Snapshot\";\n     Table table = null;\n     try {\n+      UTIL.getConfiguration().setInt(SNAPSHOT_INPUTFORMAT_ROW_LIMIT_PER_SPLIT, 10);\n       if (UTIL.getAdmin().tableExists(tableName)) {\n         UTIL.deleteTable(tableName);\n       }\n"}}, {"oid": "b4e1f97bf27511554a05205563d7eff185a602b1", "url": "https://github.com/apache/hbase/commit/b4e1f97bf27511554a05205563d7eff185a602b1", "message": "HBASE-24387 TableSnapshotInputFormatImpl support scan limit on each InputSplit", "committedDate": "2020-05-20T10:34:07Z", "type": "forcePushed"}, {"oid": "3dcefa21a7b104590b23cfa0b0cd5f18951f14d6", "url": "https://github.com/apache/hbase/commit/3dcefa21a7b104590b23cfa0b0cd5f18951f14d6", "message": "HBASE-24387 TableSnapshotInputFormatImpl support scan limit on each InputSplit", "committedDate": "2020-05-20T10:41:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzMDc2OQ==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r428030769", "bodyText": "Not needed?", "author": "infraio", "createdAt": "2020-05-20T13:54:45Z", "path": "hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java", "diffHunk": "@@ -304,6 +305,57 @@ public void testWithMockedMapReduceWithNoStartRowStopRow() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testScanLimit() throws Exception {\n+    setupCluster();\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final String snapshotName = tableName + \"Snapshot\";\n+    Table table = null;\n+    try {\n+      UTIL.getConfiguration().setInt(SNAPSHOT_INPUTFORMAT_ROW_LIMIT_PER_INPUTSPLIT, 10);\n+      if (UTIL.getAdmin().tableExists(tableName)) {\n+        UTIL.deleteTable(tableName);\n+      }\n+\n+      UTIL.createTable(tableName, FAMILIES, new byte[][] { bbb, yyy });\n+\n+      Admin admin = UTIL.getAdmin();\n+\n+      int regionNum = admin.getRegions(tableName).size();\n+      // put some stuff in the table\n+      table = UTIL.getConnection().getTable(tableName);\n+      UTIL.loadTable(table, FAMILIES);\n+\n+      Path rootDir = CommonFSUtils.getRootDir(UTIL.getConfiguration());\n+      FileSystem fs = rootDir.getFileSystem(UTIL.getConfiguration());\n+\n+      SnapshotTestingUtils.createSnapshotAndValidate(admin, tableName, Arrays.asList(FAMILIES),\n+        null, snapshotName, rootDir, fs, true);\n+\n+      Job job = new Job(UTIL.getConfiguration());\n+      Path tmpTableDir = UTIL.getDataTestDirOnTestFS(snapshotName);\n+      // limit the scan\n+      Scan scan = new Scan().setLimit(10);", "originalCommit": "3dcefa21a7b104590b23cfa0b0cd5f18951f14d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "chunk": "diff --git a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\nindex 4c569c61f3..2262a6cc89 100644\n--- a/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\n+++ b/hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java\n\n@@ -334,8 +334,7 @@ public class TestTableSnapshotInputFormat extends TableSnapshotInputFormatTestBa\n \n       Job job = new Job(UTIL.getConfiguration());\n       Path tmpTableDir = UTIL.getDataTestDirOnTestFS(snapshotName);\n-      // limit the scan\n-      Scan scan = new Scan().setLimit(10);\n+      Scan scan = new Scan();\n       TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(),\n         TestTableSnapshotInputFormat.class);\n \n"}}, {"oid": "169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "url": "https://github.com/apache/hbase/commit/169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "message": "HBASE-24387 TableSnapshotInputFormatImpl support row limit on each InputSplit", "committedDate": "2020-05-20T13:58:06Z", "type": "commit"}, {"oid": "169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "url": "https://github.com/apache/hbase/commit/169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "message": "HBASE-24387 TableSnapshotInputFormatImpl support row limit on each InputSplit", "committedDate": "2020-05-20T13:58:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMDUyNQ==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r428200525", "bodyText": "Does it make sense to move this one to a test initializer method? I see it used in several tests in here.", "author": "HorizonNet", "createdAt": "2020-05-20T17:53:51Z", "path": "hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java", "diffHunk": "@@ -304,6 +305,56 @@ public void testWithMockedMapReduceWithNoStartRowStopRow() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testScanLimit() throws Exception {\n+    setupCluster();", "originalCommit": "169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQwODY3MQ==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r428408671", "bodyText": "It is better to submit another PR to fix?after this one merged, I will amend it", "author": "nyl3532016", "createdAt": "2020-05-21T02:17:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMDUyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUzMDI1Mg==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r429530252", "bodyText": "It's up to you. We can also do it in a separate ticket.", "author": "HorizonNet", "createdAt": "2020-05-23T09:19:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMDUyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU1MzEzNA==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r429553134", "bodyText": "Would you like to help merge this PR?  Thanks", "author": "nyl3532016", "createdAt": "2020-05-23T14:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMDUyNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMDYwOA==", "url": "https://github.com/apache/hbase/pull/1731#discussion_r428200608", "bodyText": "Ditto.", "author": "HorizonNet", "createdAt": "2020-05-20T17:54:01Z", "path": "hbase-mapreduce/src/test/java/org/apache/hadoop/hbase/mapreduce/TestTableSnapshotInputFormat.java", "diffHunk": "@@ -304,6 +305,56 @@ public void testWithMockedMapReduceWithNoStartRowStopRow() throws Exception {\n     }\n   }\n \n+  @Test\n+  public void testScanLimit() throws Exception {\n+    setupCluster();\n+    final TableName tableName = TableName.valueOf(name.getMethodName());\n+    final String snapshotName = tableName + \"Snapshot\";\n+    Table table = null;\n+    try {\n+      UTIL.getConfiguration().setInt(SNAPSHOT_INPUTFORMAT_ROW_LIMIT_PER_INPUTSPLIT, 10);\n+      if (UTIL.getAdmin().tableExists(tableName)) {\n+        UTIL.deleteTable(tableName);\n+      }\n+\n+      UTIL.createTable(tableName, FAMILIES, new byte[][] { bbb, yyy });\n+\n+      Admin admin = UTIL.getAdmin();\n+\n+      int regionNum = admin.getRegions(tableName).size();\n+      // put some stuff in the table\n+      table = UTIL.getConnection().getTable(tableName);\n+      UTIL.loadTable(table, FAMILIES);\n+\n+      Path rootDir = CommonFSUtils.getRootDir(UTIL.getConfiguration());\n+      FileSystem fs = rootDir.getFileSystem(UTIL.getConfiguration());\n+\n+      SnapshotTestingUtils.createSnapshotAndValidate(admin, tableName, Arrays.asList(FAMILIES),\n+        null, snapshotName, rootDir, fs, true);\n+\n+      Job job = new Job(UTIL.getConfiguration());\n+      Path tmpTableDir = UTIL.getDataTestDirOnTestFS(snapshotName);\n+      Scan scan = new Scan();\n+      TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(),\n+        TestTableSnapshotInputFormat.class);\n+\n+      TableMapReduceUtil.initTableSnapshotMapperJob(snapshotName, scan,\n+        RowCounter.RowCounterMapper.class, NullWritable.class, NullWritable.class, job, true,\n+        tmpTableDir);\n+      Assert.assertTrue(job.waitForCompletion(true));\n+      Assert.assertEquals(10 * regionNum,\n+        job.getCounters().findCounter(RowCounter.RowCounterMapper.Counters.ROWS).getValue());\n+    } finally {\n+      if (table != null) {\n+        table.close();\n+      }\n+      UTIL.getConfiguration().unset(SNAPSHOT_INPUTFORMAT_ROW_LIMIT_PER_INPUTSPLIT);\n+      UTIL.getAdmin().deleteSnapshot(snapshotName);\n+      UTIL.deleteTable(tableName);\n+      tearDownCluster();", "originalCommit": "169ab8c062d86fe9109fa4b88079e7e31ba9a25b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}