{"pr_number": 1022, "pr_title": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "pr_createdAt": "2020-01-11T07:14:57Z", "pr_url": "https://github.com/apache/hbase/pull/1022", "timeline": [{"oid": "6d2b43013b69176de3b12c7466024bbfd8293a37", "url": "https://github.com/apache/hbase/commit/6d2b43013b69176de3b12c7466024bbfd8293a37", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-11T12:41:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUzMTU5MA==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r365531590", "bodyText": "We just delete archived files? Why even archive them then? Can we delay the delete at least?", "author": "saintstack", "createdAt": "2020-01-11T17:05:07Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java", "diffHunk": "@@ -136,9 +146,30 @@ static void setupConf(Configuration conf) {\n       flushPerChanges, flushIntervalMs);\n   }\n \n+  private void deleteCompactedHFiles() throws IOException {\n+    HStore store = Iterables.getOnlyElement(region.getStores());\n+    store.closeAndArchiveCompactedFiles();\n+    // for now we just deleted these HFiles, without moving them to the global archive directory.\n+    // This is because that, our HFiles are on the WAL file system, but the global HFile archive\n+    // directory is on the root(HFile) file system, we can not move between two different file\n+    // systems.\n+    Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, region.getRegionInfo(),\n+      store.getColumnFamilyDescriptor().getName());\n+    FileSystem fs = archiveDir.getFileSystem(conf);\n+    if (LOG.isDebugEnabled()) {\n+      FileStatus[] toDelete = fs.listStatus(archiveDir);\n+      if (toDelete != null && toDelete.length > 0) {\n+        LOG.debug(\"Delete all archived HFiles under {}: {}\", archiveDir, Stream.of(toDelete)\n+          .map(s -> s.getPath().getName()).collect(Collectors.joining(\", \", \"[\", \"]\")));\n+      }\n+    }\n+    fs.delete(archiveDir, true);\n+  }\n+\n   private void compact() {\n     try {\n       region.compact(true);\n+      deleteCompactedHFiles();", "originalCommit": "6d2b43013b69176de3b12c7466024bbfd8293a37", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUzMTY5MQ==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r365531691", "bodyText": "Why we writing hfiles into WAL fs out of interest?", "author": "saintstack", "createdAt": "2020-01-11T17:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUzMTU5MA=="}], "type": "inlineReview", "revised_code": {"commit": "e9e831c835912efef2dbc19f2e879ece823110f8", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\nindex d3ca202c08..fa69df108b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\n\n@@ -146,30 +155,43 @@ class RegionFlusherAndCompactor implements Closeable {\n       flushPerChanges, flushIntervalMs);\n   }\n \n-  private void deleteCompactedHFiles() throws IOException {\n+  private boolean isHFileDeleteable(FileStatus status) {\n+    long currentTime = EnvironmentEdgeManager.currentTime();\n+    long time = status.getModificationTime();\n+    long life = currentTime - time;\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"HFile life: {}ms, ttl: {}ms, current: {}, from: {}\", life, compactedHFileTTLMs,\n+        currentTime, time);\n+    }\n+    if (life < 0) {\n+      LOG.warn(\"Found a hfile ({}) newer than current time ({} < {}), probably a clock skew\",\n+        status.getPath(), currentTime, time);\n+      return false;\n+    }\n+    return life > compactedHFileTTLMs;\n+  }\n+\n+  void cleanupCompactedHFiles() throws IOException {\n     HStore store = Iterables.getOnlyElement(region.getStores());\n-    store.closeAndArchiveCompactedFiles();\n-    // for now we just deleted these HFiles, without moving them to the global archive directory.\n-    // This is because that, our HFiles are on the WAL file system, but the global HFile archive\n-    // directory is on the root(HFile) file system, we can not move between two different file\n-    // systems.\n+    // our HFiles are on the WAL file system, but the global HFile archive directory is on the\n+    // root(HFile) file system, we can not move between two different file systems. So here we have\n+    // to implement our own TTL cleaner.\n     Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, region.getRegionInfo(),\n       store.getColumnFamilyDescriptor().getName());\n     FileSystem fs = archiveDir.getFileSystem(conf);\n-    if (LOG.isDebugEnabled()) {\n-      FileStatus[] toDelete = fs.listStatus(archiveDir);\n-      if (toDelete != null && toDelete.length > 0) {\n-        LOG.debug(\"Delete all archived HFiles under {}: {}\", archiveDir, Stream.of(toDelete)\n-          .map(s -> s.getPath().getName()).collect(Collectors.joining(\", \", \"[\", \"]\")));\n+    \n+    for (FileStatus status: fs.listStatus(archiveDir)) {\n+      if (isHFileDeleteable(status)) {\n+        LOG.debug(\"Deleted archived HFile {}\", status.getPath());\n+        fs.delete(status.getPath(), false);\n       }\n     }\n-    fs.delete(archiveDir, true);\n   }\n \n   private void compact() {\n     try {\n       region.compact(true);\n-      deleteCompactedHFiles();\n+      Iterables.getOnlyElement(region.getStores()).closeAndArchiveCompactedFiles();\n     } catch (IOException e) {\n       LOG.error(\"Failed to compact procedure store region\", e);\n     }\n"}}, {"oid": "e9e831c835912efef2dbc19f2e879ece823110f8", "url": "https://github.com/apache/hbase/commit/e9e831c835912efef2dbc19f2e879ece823110f8", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-12T05:44:19Z", "type": "forcePushed"}, {"oid": "dbe7d1d16da5246d62acb308a31790bf1501c862", "url": "https://github.com/apache/hbase/commit/dbe7d1d16da5246d62acb308a31790bf1501c862", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-12T12:52:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3NTg0NQ==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r366475845", "bodyText": "We should be asking the other cleaner delegates if it's okay to delete these files. I could see it being either the WAL cleaner delegates or the HFile Cleaner delegates, but it needs to be one of them.", "author": "busbey", "createdAt": "2020-01-14T17:34:30Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java", "diffHunk": "@@ -136,9 +156,43 @@ static void setupConf(Configuration conf) {\n       flushPerChanges, flushIntervalMs);\n   }\n \n+  private boolean isHFileDeleteable(FileStatus status) {\n+    long currentTime = EnvironmentEdgeManager.currentTime();\n+    long time = status.getModificationTime();\n+    long life = currentTime - time;\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"HFile life: {}ms, ttl: {}ms, current: {}, from: {}\", life, compactedHFileTTLMs,\n+        currentTime, time);\n+    }\n+    if (life < 0) {\n+      LOG.warn(\"Found a hfile ({}) newer than current time ({} < {}), probably a clock skew\",\n+        status.getPath(), currentTime, time);\n+      return false;\n+    }\n+    return life > compactedHFileTTLMs;\n+  }\n+\n+  void cleanupCompactedHFiles() throws IOException {\n+    HStore store = Iterables.getOnlyElement(region.getStores());\n+    // our HFiles are on the WAL file system, but the global HFile archive directory is on the\n+    // root(HFile) file system, we can not move between two different file systems. So here we have\n+    // to implement our own TTL cleaner.\n+    Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, region.getRegionInfo(),\n+      store.getColumnFamilyDescriptor().getName());\n+    FileSystem fs = archiveDir.getFileSystem(conf);\n+\n+    for (FileStatus status : fs.listStatus(archiveDir)) {\n+      if (isHFileDeleteable(status)) {", "originalCommit": "dbe7d1d16da5246d62acb308a31790bf1501c862", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njg4OTQxMA==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r366889410", "bodyText": "We are on a different file system comparing to other HFiles so it is not suitable to ask the HFileCleaner, and it seems strange to test a HFile with WALCleaner?", "author": "Apache9", "createdAt": "2020-01-15T14:00:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3NTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Njk0NjgwMA==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r366946800", "bodyText": "Then we should instantiate our own hfile cleaner delegate chain. Defualt it to the TTL delegate and we can skip a custom impl here as well.", "author": "busbey", "createdAt": "2020-01-15T15:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3NTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3ODM1MQ==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r367178351", "bodyText": "Maybe a bit overkill? AFAIK, the only suitable HFileCleaner for this region is the TTL one, others like Links or Back Ref are not needed. Just saying. If you think this is the correct way then I could pass the ChoreService in and create a cleaner chain for cleaning the hfiles.", "author": "Apache9", "createdAt": "2020-01-16T00:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3NTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE4MTMyMQ==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r367181321", "bodyText": "No not overkill. This is the specific mechanism I mentioned needing to feel comfortable with this landing in branches where I will probably have to support deployments.\nI agree that the TTL cleaner is the only one needed by default.\nAt some point something will go wrong where I need to avoid things getting cleaned out of archive. Being able to reuse a cleaner delegate that normally is used with HFiles will make that easier. It's exactly the kind of operational reuse that makes this implementation shift attractive.", "author": "busbey", "createdAt": "2020-01-16T00:46:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3NTg0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "936c95224a2d7a74d5998d41cdc794a5089e6066", "chunk": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\nindex ccb222f02b..57e62ddf65 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionFlusherAndCompactor.java\n\n@@ -156,39 +136,6 @@ class RegionFlusherAndCompactor implements Closeable {\n       flushPerChanges, flushIntervalMs);\n   }\n \n-  private boolean isHFileDeleteable(FileStatus status) {\n-    long currentTime = EnvironmentEdgeManager.currentTime();\n-    long time = status.getModificationTime();\n-    long life = currentTime - time;\n-    if (LOG.isTraceEnabled()) {\n-      LOG.trace(\"HFile life: {}ms, ttl: {}ms, current: {}, from: {}\", life, compactedHFileTTLMs,\n-        currentTime, time);\n-    }\n-    if (life < 0) {\n-      LOG.warn(\"Found a hfile ({}) newer than current time ({} < {}), probably a clock skew\",\n-        status.getPath(), currentTime, time);\n-      return false;\n-    }\n-    return life > compactedHFileTTLMs;\n-  }\n-\n-  void cleanupCompactedHFiles() throws IOException {\n-    HStore store = Iterables.getOnlyElement(region.getStores());\n-    // our HFiles are on the WAL file system, but the global HFile archive directory is on the\n-    // root(HFile) file system, we can not move between two different file systems. So here we have\n-    // to implement our own TTL cleaner.\n-    Path archiveDir = HFileArchiveUtil.getStoreArchivePath(conf, region.getRegionInfo(),\n-      store.getColumnFamilyDescriptor().getName());\n-    FileSystem fs = archiveDir.getFileSystem(conf);\n-\n-    for (FileStatus status : fs.listStatus(archiveDir)) {\n-      if (isHFileDeleteable(status)) {\n-        LOG.debug(\"Deleted archived HFile {}\", status.getPath());\n-        fs.delete(status.getPath(), false);\n-      }\n-    }\n-  }\n-\n   private void compact() {\n     try {\n       region.compact(true);\n"}}, {"oid": "936c95224a2d7a74d5998d41cdc794a5089e6066", "url": "https://github.com/apache/hbase/commit/936c95224a2d7a74d5998d41cdc794a5089e6066", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-16T08:51:24Z", "type": "forcePushed"}, {"oid": "ee1d497428e68e019bf2c6530a30eff263855dbe", "url": "https://github.com/apache/hbase/commit/ee1d497428e68e019bf2c6530a30eff263855dbe", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-16T15:31:24Z", "type": "commit"}, {"oid": "ee1d497428e68e019bf2c6530a30eff263855dbe", "url": "https://github.com/apache/hbase/commit/ee1d497428e68e019bf2c6530a30eff263855dbe", "message": "HBASE-23680 RegionProcedureStore missing cleaning of hfile archive", "committedDate": "2020-01-16T15:31:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3NDIwMA==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r368174200", "bodyText": "Strange place to start cleanerPool down here in the procedure startup given it is used cleaning WALs and hfile...", "author": "saintstack", "createdAt": "2020-01-17T23:14:48Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1520,8 +1518,10 @@ protected void stopServiceThreads() {\n \n   private void createProcedureExecutor() throws IOException {\n     MasterProcedureEnv procEnv = new MasterProcedureEnv(this);\n-    procedureStore =\n-      new RegionProcedureStore(this, new MasterProcedureEnv.FsUtilsLeaseRecovery(this));\n+    // Create cleaner thread pool\n+    cleanerPool = new DirScanPool(conf);", "originalCommit": "ee1d497428e68e019bf2c6530a30eff263855dbe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIyNDQ4Mg==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r368224482", "bodyText": "But we have no choice as we need to use it in the next line...", "author": "Apache9", "createdAt": "2020-01-18T12:30:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3NDIwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIzMTUyOQ==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r368231529", "bodyText": "I was thinking you'd call it up in the caller's method, in startServiceThreads, rather than down hidden in here in startProcedureExecutor... i.e. move the line up thee lines from where it was.", "author": "saintstack", "createdAt": "2020-01-18T15:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3NDIwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NDU4Ng==", "url": "https://github.com/apache/hbase/pull/1022#discussion_r368254586", "bodyText": "The startServiceThreads method is called after createProcedureExecutor, notice that, it is create, not start...", "author": "Apache9", "createdAt": "2020-01-18T23:31:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE3NDIwMA=="}], "type": "inlineReview", "revised_code": null}]}