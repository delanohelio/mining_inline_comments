{"pr_number": 1036, "pr_title": "HBASE-23686 Revert binary incompatible change in ByteRangeUtils and removed reflections in CommonFSUtils", "pr_createdAt": "2020-01-14T16:55:12Z", "pr_url": "https://github.com/apache/hbase/pull/1036", "timeline": [{"oid": "1cb54388bd1fd4e05f865299fa87d7a760e825bc", "url": "https://github.com/apache/hbase/commit/1cb54388bd1fd4e05f865299fa87d7a760e825bc", "message": "HBASE-23686 Revert binary incompatible change in ByteRangeUtils and removed reflections in CommonFSUtils", "committedDate": "2020-01-14T16:53:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3MTk4OQ==", "url": "https://github.com/apache/hbase/pull/1036#discussion_r366471989", "bodyText": "This should be two direct checks for RemoteException and UnsupportedOperationException respectively. Now that we're not using reflection it won't be wrapped in InvocationTargetException", "author": "busbey", "createdAt": "2020-01-14T17:26:21Z", "path": "hbase-common/src/main/java/org/apache/hadoop/hbase/util/CommonFSUtils.java", "diffHunk": "@@ -568,83 +521,54 @@ static void setStoragePolicy(final FileSystem fs, final Path path, final String\n    */\n   private static void invokeSetStoragePolicy(final FileSystem fs, final Path path,\n       final String storagePolicy) throws IOException {\n-    Method m = null;\n     Exception toThrow = null;\n+\n     try {\n-      m = fs.getClass().getDeclaredMethod(\"setStoragePolicy\", Path.class, String.class);\n-      m.setAccessible(true);\n-    } catch (NoSuchMethodException e) {\n-      toThrow = e;\n-      final String msg = \"FileSystem doesn't support setStoragePolicy; HDFS-6584, HDFS-9345 \" +\n-          \"not available. This is normal and expected on earlier Hadoop versions.\";\n-      if (!warningMap.containsKey(fs)) {\n-        warningMap.put(fs, true);\n-        LOG.warn(msg, e);\n-      } else if (LOG.isDebugEnabled()) {\n-        LOG.debug(msg, e);\n+      fs.setStoragePolicy(path, storagePolicy);\n+\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Set storagePolicy={} for path={}\", storagePolicy, path);\n       }\n-      m = null;\n-    } catch (SecurityException e) {\n+    } catch (Exception e) {\n       toThrow = e;\n-      final String msg = \"No access to setStoragePolicy on FileSystem from the SecurityManager; \" +\n-          \"HDFS-6584, HDFS-9345 not available. This is unusual and probably warrants an email \" +\n-          \"to the user@hbase mailing list. Please be sure to include a link to your configs, and \" +\n-          \"logs that include this message and period of time before it. Logs around service \" +\n-          \"start up will probably be useful as well.\";\n+      // This swallows FNFE, should we be throwing it? seems more likely to indicate dev\n+      // misuse than a runtime problem with HDFS.\n       if (!warningMap.containsKey(fs)) {\n         warningMap.put(fs, true);\n-        LOG.warn(msg, e);\n+        LOG.warn(\"Unable to set storagePolicy=\" + storagePolicy + \" for path=\" + path + \". \" +\n+            \"DEBUG log level might have more details.\", e);\n       } else if (LOG.isDebugEnabled()) {\n-        LOG.debug(msg, e);\n+        LOG.debug(\"Unable to set storagePolicy=\" + storagePolicy + \" for path=\" + path, e);\n       }\n-      m = null; // could happen on setAccessible() or getDeclaredMethod()\n-    }\n-    if (m != null) {\n-      try {\n-        m.invoke(fs, path, storagePolicy);\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Set storagePolicy={} for path={}\", storagePolicy, path);\n-        }\n-      } catch (Exception e) {\n-        toThrow = e;\n-        // This swallows FNFE, should we be throwing it? seems more likely to indicate dev\n-        // misuse than a runtime problem with HDFS.\n-        if (!warningMap.containsKey(fs)) {\n-          warningMap.put(fs, true);\n-          LOG.warn(\"Unable to set storagePolicy=\" + storagePolicy + \" for path=\" + path + \". \" +\n-              \"DEBUG log level might have more details.\", e);\n-        } else if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Unable to set storagePolicy=\" + storagePolicy + \" for path=\" + path, e);\n-        }\n-        // check for lack of HDFS-7228\n-        if (e instanceof InvocationTargetException) {\n-          final Throwable exception = e.getCause();\n-          if (exception instanceof RemoteException &&\n-              HadoopIllegalArgumentException.class.getName().equals(\n-                ((RemoteException)exception).getClassName())) {\n-            if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"Given storage policy, '\" +storagePolicy +\"', was rejected and probably \" +\n-                \"isn't a valid policy for the version of Hadoop you're running. I.e. if you're \" +\n-                \"trying to use SSD related policies then you're likely missing HDFS-7228. For \" +\n-                \"more information see the 'ArchivalStorage' docs for your Hadoop release.\");\n-            }\n-          // Hadoop 2.8+, 3.0-a1+ added FileSystem.setStoragePolicy with a default implementation\n-          // that throws UnsupportedOperationException\n-          } else if (exception instanceof UnsupportedOperationException) {\n-            if (LOG.isDebugEnabled()) {\n-              LOG.debug(\"The underlying FileSystem implementation doesn't support \" +\n-                  \"setStoragePolicy. This is probably intentional on their part, since HDFS-9345 \" +\n-                  \"appears to be present in your version of Hadoop. For more information check \" +\n-                  \"the Hadoop documentation on 'ArchivalStorage', the Hadoop FileSystem \" +\n-                  \"specification docs from HADOOP-11981, and/or related documentation from the \" +\n-                  \"provider of the underlying FileSystem (its name should appear in the \" +\n-                  \"stacktrace that accompanies this message). Note in particular that Hadoop's \" +\n-                  \"local filesystem implementation doesn't support storage policies.\", exception);\n-            }\n+      // check for lack of HDFS-7228\n+      if (e instanceof InvocationTargetException) {", "originalCommit": "1cb54388bd1fd4e05f865299fa87d7a760e825bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3OTE0MQ==", "url": "https://github.com/apache/hbase/pull/1036#discussion_r366479141", "bodyText": "Removed the outer check for the InvocationTargetException.", "author": "HorizonNet", "createdAt": "2020-01-14T17:41:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjQ3MTk4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "47f5ba53f6a2ce0c67e4b79e3614f5fe54fe7d73", "chunk": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/CommonFSUtils.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/CommonFSUtils.java\nindex 927579c9a4..12aa968c4d 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/CommonFSUtils.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/CommonFSUtils.java\n\n@@ -540,31 +540,30 @@ public abstract class CommonFSUtils {\n       } else if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Unable to set storagePolicy=\" + storagePolicy + \" for path=\" + path, e);\n       }\n+\n       // check for lack of HDFS-7228\n-      if (e instanceof InvocationTargetException) {\n-        final Throwable exception = e.getCause();\n-        if (exception instanceof RemoteException &&\n-            HadoopIllegalArgumentException.class.getName().equals(\n-              ((RemoteException)exception).getClassName())) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Given storage policy, '\" +storagePolicy +\"', was rejected and probably \" +\n-              \"isn't a valid policy for the version of Hadoop you're running. I.e. if you're \" +\n-              \"trying to use SSD related policies then you're likely missing HDFS-7228. For \" +\n-              \"more information see the 'ArchivalStorage' docs for your Hadoop release.\");\n-          }\n-        // Hadoop 2.8+, 3.0-a1+ added FileSystem.setStoragePolicy with a default implementation\n-        // that throws UnsupportedOperationException\n-        } else if (exception instanceof UnsupportedOperationException) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"The underlying FileSystem implementation doesn't support \" +\n-                \"setStoragePolicy. This is probably intentional on their part, since HDFS-9345 \" +\n-                \"appears to be present in your version of Hadoop. For more information check \" +\n-                \"the Hadoop documentation on 'ArchivalStorage', the Hadoop FileSystem \" +\n-                \"specification docs from HADOOP-11981, and/or related documentation from the \" +\n-                \"provider of the underlying FileSystem (its name should appear in the \" +\n-                \"stacktrace that accompanies this message). Note in particular that Hadoop's \" +\n-                \"local filesystem implementation doesn't support storage policies.\", exception);\n-          }\n+      final Throwable exception = e.getCause();\n+      if (exception instanceof RemoteException &&\n+          HadoopIllegalArgumentException.class.getName().equals(\n+            ((RemoteException)exception).getClassName())) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Given storage policy, '\" +storagePolicy +\"', was rejected and probably \" +\n+            \"isn't a valid policy for the version of Hadoop you're running. I.e. if you're \" +\n+            \"trying to use SSD related policies then you're likely missing HDFS-7228. For \" +\n+            \"more information see the 'ArchivalStorage' docs for your Hadoop release.\");\n+        }\n+      // Hadoop 2.8+, 3.0-a1+ added FileSystem.setStoragePolicy with a default implementation\n+      // that throws UnsupportedOperationException\n+      } else if (exception instanceof UnsupportedOperationException) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"The underlying FileSystem implementation doesn't support \" +\n+              \"setStoragePolicy. This is probably intentional on their part, since HDFS-9345 \" +\n+              \"appears to be present in your version of Hadoop. For more information check \" +\n+              \"the Hadoop documentation on 'ArchivalStorage', the Hadoop FileSystem \" +\n+              \"specification docs from HADOOP-11981, and/or related documentation from the \" +\n+              \"provider of the underlying FileSystem (its name should appear in the \" +\n+              \"stacktrace that accompanies this message). Note in particular that Hadoop's \" +\n+              \"local filesystem implementation doesn't support storage policies.\", exception);\n         }\n       }\n     }\n"}}, {"oid": "47f5ba53f6a2ce0c67e4b79e3614f5fe54fe7d73", "url": "https://github.com/apache/hbase/commit/47f5ba53f6a2ce0c67e4b79e3614f5fe54fe7d73", "message": "HBASE-23686 Fixed review comments", "committedDate": "2020-01-14T17:39:53Z", "type": "commit"}, {"oid": "81ea953140b3fb4477dc6181b2d1a615e7010c3b", "url": "https://github.com/apache/hbase/commit/81ea953140b3fb4477dc6181b2d1a615e7010c3b", "message": "HBASE-23686 Removed getting the cause", "committedDate": "2020-01-14T19:57:51Z", "type": "commit"}]}