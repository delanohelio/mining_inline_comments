{"pr_number": 11754, "pr_title": "[BEAM-10037] BeamSqlExample.java fails to build ", "pr_createdAt": "2020-05-20T00:14:38Z", "pr_url": "https://github.com/apache/beam/pull/11754", "timeline": [{"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d", "url": "https://github.com/apache/beam/commit/76b8c0a01b9f47633002b70ef95b739c7a61252d", "message": "[BEAM-10037] BeamSqlExample.java fails to build when running ./gradlew command", "committedDate": "2020-05-20T00:11:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQxNQ==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427674415", "bodyText": "could you change this to withRowSchema(type)? It does the same thing, but it's less verbose", "author": "TheNeuralBit", "createdAt": "2020-05-20T00:26:10Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));", "originalCommit": "76b8c0a01b9f47633002b70ef95b739c7a61252d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NzY4MQ==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427677681", "bodyText": "I can do that. I did setRowSchema(type) and it worked!", "author": "omarismail94", "createdAt": "2020-05-20T00:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2e74ab7009a11394a7cd1dc411ce2d70a38965f4", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\nindex 0850d17e21..e3ab8574e3 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\n\n@@ -65,7 +64,7 @@ class BeamSqlExample {\n \n     // Case 1. run a simple SQL query over input PCollection with BeamSql.simpleQuery;\n     PCollection<Row> outputStream =\n-        inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n+        inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c3 > 1\"));\n \n     // print the output record of case 1;\n     outputStream\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427674472", "bodyText": "Here as well", "author": "TheNeuralBit", "createdAt": "2020-05-20T00:26:21Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "originalCommit": "76b8c0a01b9f47633002b70ef95b739c7a61252d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3ODAzMw==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427678033", "bodyText": "I tried setRowSchema(type) and it failed with : java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer.\nI think it is inferring the schema as 3 fields, but the result only returns two fields, and that's why it throws the error", "author": "omarismail94", "createdAt": "2020-05-20T00:39:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3ODcyNw==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427678727", "bodyText": "This is part of the Stack trace that makes me think that\nCaused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer\n        at org.apache.beam.sdk.coders.VarIntCoder.encode(VarIntCoder.java:33)\n        at org.apache.beam.sdk.coders.RowCoderGenerator$EncodeInstruction.encodeDelegate(RowCoderGenerator.java:270)\n        at org.apache.beam.sdk.coders.Coder$ByteBuddy$E99UrF3W.encode(Unknown Source)\n        at org.apache.beam.sdk.coders.Coder$ByteBuddy$E99UrF3W.encode(Unknown Source)\n        at org.apache.beam.sdk.schemas.SchemaCoder.encode(SchemaCoder.java:115)", "author": "omarismail94", "createdAt": "2020-05-20T00:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTU4MA==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427681580", "bodyText": "oh for this call you will need to use\nSchema.builder()\n\ufffc                    .addStringField(\"stringField\")\n\ufffc                    .addDoubleField(\"doubleField\")\n\ufffc                    .build()\n\nlike you had in the setCoder call", "author": "TheNeuralBit", "createdAt": "2020-05-20T00:52:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4NjcwMw==", "url": "https://github.com/apache/beam/pull/11754#discussion_r427686703", "bodyText": "Actually, it is not due to the reduction in the number of field, but the order in which the fields are selected in the SELECT statement. Here is the order it expects\n\nInt, String, Double\n\nand the fields that represent those types are: c1, c2, c3\nIf your results print out of order, it fails due to the ClassCastException. I tried doing this query and it failed:\nselect  c2, sum(c1), sum(c3) from CASE1_RESULT group by c2,\nbut if I do\nselect  sum(c1),c2, sum(c3) from CASE1_RESULT group by c2\nit works! You can see that in the one that failed, c1 and c2s positions have switched, so the encoder trips out. What's cool is that you can see the results correctly calculated in:\n System.out.println(\"CASE1_RESULT: \" + input.getValues());\nbut it seems that when the result is encoded, the program throws an error due to the results being out of order. I guess this is because it sees .setRowSchema(type);, and as the order of the schema is \"Int, String, Double\", the results have to abide by that rule. That why it fails when we did:\nc2, sum(c3) from CASE1_RESULT group by c2", "author": "omarismail94", "createdAt": "2020-05-20T01:13:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "2e74ab7009a11394a7cd1dc411ce2d70a38965f4", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\nindex 0850d17e21..e3ab8574e3 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java\n\n@@ -65,7 +64,7 @@ class BeamSqlExample {\n \n     // Case 1. run a simple SQL query over input PCollection with BeamSql.simpleQuery;\n     PCollection<Row> outputStream =\n-        inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n+        inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c3 > 1\"));\n \n     // print the output record of case 1;\n     outputStream\n"}}, {"oid": "2e74ab7009a11394a7cd1dc411ce2d70a38965f4", "url": "https://github.com/apache/beam/commit/2e74ab7009a11394a7cd1dc411ce2d70a38965f4", "message": "[BEAM-10037] Added BeamSQLExample and PojoExample to sqlPreCommit(), and fixed coder in BeamSqlExample", "committedDate": "2020-05-20T01:29:08Z", "type": "commit"}, {"oid": "eb31bc8743126729f5f09e03231b303cb55df9ad", "url": "https://github.com/apache/beam/commit/eb31bc8743126729f5f09e03231b303cb55df9ad", "message": "[BEAM-10037] Reverted first query to c1>1 as opposed to c3. I added c3 for testing and forgot to change it back :)", "committedDate": "2020-05-20T01:31:33Z", "type": "commit"}]}