{"pr_number": 11039, "pr_title": "[BEAM-9383] Staging Dataflow artifacts from environment", "pr_createdAt": "2020-03-04T02:30:48Z", "pr_url": "https://github.com/apache/beam/pull/11039", "timeline": [{"oid": "4ad6a3840921557745ff89c88fd69e5d091cd257", "url": "https://github.com/apache/beam/commit/4ad6a3840921557745ff89c88fd69e5d091cd257", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-03-12T17:18:12Z", "type": "forcePushed"}, {"oid": "d975d8b08e62bc9e585ac865fbac3912e4429f38", "url": "https://github.com/apache/beam/commit/d975d8b08e62bc9e585ac865fbac3912e4429f38", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-03-12T21:06:16Z", "type": "forcePushed"}, {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "url": "https://github.com/apache/beam/commit/02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-03-12T22:07:14Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ1NQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530455", "bodyText": "Check the ROLE as well ?", "author": "chamikaramj", "createdAt": "2020-03-13T23:47:30Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -752,6 +759,27 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n+    ImmutableList.Builder<String> filesToStageBuilder = ImmutableList.builder();\n+    for (Map.Entry<String, RunnerApi.Environment> entry :\n+        pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n+      for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Types.FILE).equals(info.getTypeUrn())) {", "originalCommit": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDcyMjgzMg==", "url": "https://github.com/apache/beam/pull/11039#discussion_r394722832", "bodyText": "Currently, DataflowRunner auto-generates staging names based on source file names. So ROLE (STAGING_TO) is ignored anyway. We could change this behavior later in BEAM-9455.", "author": "ihji", "createdAt": "2020-03-19T00:35:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\nindex 33644f61df..f1e7ab39d7 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n\n@@ -760,7 +784,7 @@ public class DataflowRunner extends PipelineRunner<DataflowPipelineJob> {\n   }\n \n   private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n-    ImmutableList.Builder<String> filesToStageBuilder = ImmutableList.builder();\n+    ImmutableList.Builder<StagedFile> filesToStageBuilder = ImmutableList.builder();\n     for (Map.Entry<String, RunnerApi.Environment> entry :\n         pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n       for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ3Mg==", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530472", "bodyText": "Please add a unit test.", "author": "chamikaramj", "createdAt": "2020-03-13T23:47:36Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -752,6 +759,27 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {", "originalCommit": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDcyMTg2OA==", "url": "https://github.com/apache/beam/pull/11039#discussion_r394721868", "bodyText": "It's private method so we can't directly test it. Existing test (such as https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java#L758) should cover this method too.", "author": "ihji", "createdAt": "2020-03-19T00:31:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\nindex 33644f61df..f1e7ab39d7 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n\n@@ -760,7 +784,7 @@ public class DataflowRunner extends PipelineRunner<DataflowPipelineJob> {\n   }\n \n   private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n-    ImmutableList.Builder<String> filesToStageBuilder = ImmutableList.builder();\n+    ImmutableList.Builder<StagedFile> filesToStageBuilder = ImmutableList.builder();\n     for (Map.Entry<String, RunnerApi.Environment> entry :\n         pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n       for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n"}}, {"oid": "0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "url": "https://github.com/apache/beam/commit/0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-04-24T02:58:35Z", "type": "forcePushed"}, {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "url": "https://github.com/apache/beam/commit/331f30d6bfe8acf069476f539c4b1bdd91e03675", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-04-24T07:19:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1MjE1Mg==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418652152", "bodyText": "Isn't order important to preserve? (Also, why do we need to make a copy?)", "author": "robertwb", "createdAt": "2020-05-01T17:41:03Z", "path": "runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java", "diffHunk": "@@ -210,56 +209,55 @@ public static Environment createProcessEnvironment(\n     }\n   }\n \n-  private static List<ArtifactInformation> getArtifacts(List<String> stagingFiles) {\n-    Set<String> pathsToStage = Sets.newHashSet(stagingFiles);\n+  public static List<ArtifactInformation> getArtifacts(\n+      List<String> stagingFiles, StagingFileNameGenerator generator) {\n     ImmutableList.Builder<ArtifactInformation> artifactsBuilder = ImmutableList.builder();\n-    for (String path : pathsToStage) {\n+    for (String path : ImmutableSet.copyOf(stagingFiles)) {", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgyOTY1OQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r419829659", "bodyText": "ImmutableSet preserves the order but I think we don't need to make a copy here. Will use LinkedHashSet instead.", "author": "ihji", "createdAt": "2020-05-05T02:14:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1MjE1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "5298d69ee753aead758cc92ecf44558af8c5f97e", "chunk": "diff --git a/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java\nindex 6e54363078..c324b92e7f 100644\n--- a/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java\n+++ b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java\n\n@@ -209,16 +210,30 @@ public class Environments {\n     }\n   }\n \n-  public static List<ArtifactInformation> getArtifacts(\n-      List<String> stagingFiles, StagingFileNameGenerator generator) {\n+  public static List<ArtifactInformation> getArtifacts(List<String> stagingFiles) {\n     ImmutableList.Builder<ArtifactInformation> artifactsBuilder = ImmutableList.builder();\n-    for (String path : ImmutableSet.copyOf(stagingFiles)) {\n-      File file = new File(path);\n+    Set<String> deduplicatedStagingFiles = new LinkedHashSet<>(stagingFiles);\n+    for (String path : deduplicatedStagingFiles) {\n+      File file;\n+      String stagedName;\n+      if (path.contains(\"=\")) {\n+        String[] components = path.split(\"=\", 2);\n+        file = new File(components[1]);\n+        stagedName = components[0];\n+      } else {\n+        file = new File(path);\n+        stagedName = createStagingFileName(file);\n+      }\n       // Spurious items get added to the classpath. Filter by just those that exist.\n       if (file.exists()) {\n         ArtifactInformation.Builder artifactBuilder = ArtifactInformation.newBuilder();\n         artifactBuilder.setTypeUrn(BeamUrns.getUrn(StandardArtifacts.Types.FILE));\n         artifactBuilder.setRoleUrn(BeamUrns.getUrn(StandardArtifacts.Roles.STAGING_TO));\n+        artifactBuilder.setRolePayload(\n+            RunnerApi.ArtifactStagingToRolePayload.newBuilder()\n+                .setStagedName(stagedName)\n+                .build()\n+                .toByteString());\n         HashCode hashCode;\n         if (file.isDirectory()) {\n           File zippedFile;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NTgwMg==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418655802", "bodyText": "This is a really big log message, even for debug. (Even computing it could be expensive, for pipelines with 1000s of stages.)", "author": "robertwb", "createdAt": "2020-05-01T17:49:01Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -784,7 +877,25 @@ public DataflowPipelineJob run(Pipeline pipeline) {\n         \"Executing pipeline on the Dataflow Service, which will have billing implications \"\n             + \"related to Google Compute Engine usage and other Google Cloud Services.\");\n \n-    List<DataflowPackage> packages = options.getStager().stageDefaultFiles();\n+    // Capture the sdkComponents for look up during step translations\n+    SdkComponents sdkComponents = SdkComponents.create();\n+\n+    DataflowPipelineOptions dataflowOptions = options.as(DataflowPipelineOptions.class);\n+    String workerHarnessContainerImageURL = DataflowRunner.getContainerImageForJob(dataflowOptions);\n+    RunnerApi.Environment defaultEnvironmentForDataflow =\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+\n+    sdkComponents.registerEnvironment(\n+        defaultEnvironmentForDataflow\n+            .toBuilder()\n+            .addAllDependencies(getDefaultArtifacts())\n+            .build());\n+\n+    RunnerApi.Pipeline pipelineProto = PipelineTranslation.toProto(pipeline, sdkComponents, true);\n+\n+    LOG.debug(\"Portable pipeline proto:\\n{}\", TextFormat.printToString(pipelineProto));", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgyOTk3MQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r419829971", "bodyText": "This debug log is not new. It's just relocated. Do you think it would be better to remove this?", "author": "ihji", "createdAt": "2020-05-05T02:15:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg4NzU0OQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426887549", "bodyText": "OK, we don't have to change this.", "author": "robertwb", "createdAt": "2020-05-18T20:53:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NTgwMg=="}], "type": "inlineReview", "revised_code": {"commit": "7b623517487bd8e32631e8246af49b0ac2b0c0c0", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\nindex f1e7ab39d7..a4ea1c9520 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n\n@@ -889,6 +855,7 @@ public class DataflowRunner extends PipelineRunner<DataflowPipelineJob> {\n         defaultEnvironmentForDataflow\n             .toBuilder()\n             .addAllDependencies(getDefaultArtifacts())\n+            .addAllCapabilities(Environments.getJavaCapabilities())\n             .build());\n \n     RunnerApi.Pipeline pipelineProto = PipelineTranslation.toProto(pipeline, sdkComponents, true);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NzA3OQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418657079", "bodyText": "How does this get invoked for cross-language pipelines?", "author": "robertwb", "createdAt": "2020-05-01T17:51:39Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -784,7 +877,25 @@ public DataflowPipelineJob run(Pipeline pipeline) {\n         \"Executing pipeline on the Dataflow Service, which will have billing implications \"\n             + \"related to Google Compute Engine usage and other Google Cloud Services.\");\n \n-    List<DataflowPackage> packages = options.getStager().stageDefaultFiles();\n+    // Capture the sdkComponents for look up during step translations\n+    SdkComponents sdkComponents = SdkComponents.create();\n+\n+    DataflowPipelineOptions dataflowOptions = options.as(DataflowPipelineOptions.class);\n+    String workerHarnessContainerImageURL = DataflowRunner.getContainerImageForJob(dataflowOptions);\n+    RunnerApi.Environment defaultEnvironmentForDataflow =\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+\n+    sdkComponents.registerEnvironment(\n+        defaultEnvironmentForDataflow\n+            .toBuilder()\n+            .addAllDependencies(getDefaultArtifacts())", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI5MTc1Nw==", "url": "https://github.com/apache/beam/pull/11039#discussion_r423291757", "bodyText": "It does nothing with the cross-language pipelines. Cross-language dependency should also be a part of the native dependency list here. #11557 improved this so the expansion service could  return its own dependencies.", "author": "ihji", "createdAt": "2020-05-11T20:13:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NzA3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3Mzk0NQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426973945", "bodyText": "We also need to make sure we have the capabilities set, I have this PR: #11748 since it was missing before.", "author": "lukecwik", "createdAt": "2020-05-19T01:10:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NzA3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b623517487bd8e32631e8246af49b0ac2b0c0c0", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\nindex f1e7ab39d7..a4ea1c9520 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n\n@@ -889,6 +855,7 @@ public class DataflowRunner extends PipelineRunner<DataflowPipelineJob> {\n         defaultEnvironmentForDataflow\n             .toBuilder()\n             .addAllDependencies(getDefaultArtifacts())\n+            .addAllCapabilities(Environments.getJavaCapabilities())\n             .build());\n \n     RunnerApi.Pipeline pipelineProto = PipelineTranslation.toProto(pipeline, sdkComponents, true);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NDYyNQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418664625", "bodyText": "Is this = support a dataflow-only thing? Seems we don't support that in Environments.getArtifacts() (but if we did nearly all of this code could go away).", "author": "robertwb", "createdAt": "2020-05-01T18:07:50Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -772,6 +783,88 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n+    ImmutableList.Builder<StagedFile> filesToStageBuilder = ImmutableList.builder();\n+    for (Map.Entry<String, RunnerApi.Environment> entry :\n+        pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n+      for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Types.FILE).equals(info.getTypeUrn())) {\n+          throw new RuntimeException(\n+              String.format(\"unsupported artifact type %s\", info.getTypeUrn()));\n+        }\n+        RunnerApi.ArtifactFilePayload filePayload;\n+        try {\n+          filePayload = RunnerApi.ArtifactFilePayload.parseFrom(info.getTypePayload());\n+        } catch (InvalidProtocolBufferException e) {\n+          throw new RuntimeException(\"Error parsing artifact file payload.\", e);\n+        }\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Roles.STAGING_TO)\n+            .equals(info.getRoleUrn())) {\n+          throw new RuntimeException(\n+              String.format(\"unsupported artifact role %s\", info.getRoleUrn()));\n+        }\n+        RunnerApi.ArtifactStagingToRolePayload stagingPayload;\n+        try {\n+          stagingPayload = RunnerApi.ArtifactStagingToRolePayload.parseFrom(info.getRolePayload());\n+        } catch (InvalidProtocolBufferException e) {\n+          throw new RuntimeException(\"Error parsing artifact staging_to role payload.\", e);\n+        }\n+        DataflowPackage target = new DataflowPackage();\n+        target.setLocation(stagingPayload.getStagedName());\n+        if (!Strings.isNullOrEmpty(stagingPayload.getAliasName())) {\n+          target.setName(stagingPayload.getAliasName());\n+        }\n+        filesToStageBuilder.add(StagedFile.of(filePayload.getPath(), target));\n+      }\n+    }\n+    return options.getStager().stageFiles(filesToStageBuilder.build());\n+  }\n+\n+  private List<RunnerApi.ArtifactInformation> getDefaultArtifacts() {\n+    ImmutableList.Builder<String> pathsToStageBuilder = ImmutableList.builder();\n+    ImmutableMap.Builder<String, String> aliasMapBuilder = ImmutableMap.builder();\n+    String windmillBinary =\n+        options.as(DataflowPipelineDebugOptions.class).getOverrideWindmillBinary();\n+    String dataflowWorkerJar = options.getDataflowWorkerJar();\n+    if (dataflowWorkerJar != null && !dataflowWorkerJar.isEmpty()) {\n+      // Put the user specified worker jar at the start of the classpath, to be consistent with the\n+      // built in worker order.\n+      pathsToStageBuilder.add(dataflowWorkerJar);\n+      aliasMapBuilder.put(dataflowWorkerJar, \"dataflow-worker.jar\");\n+    }\n+    for (String path : options.getFilesToStage()) {\n+      if (path.contains(\"=\")) {", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzMjMzOQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r419832339", "bodyText": "Yes. This syntax is only supported in Dataflow runner. DataflowPackage has a separate field name in addition to location and \"=\" separator allows to prefix name to the location of the source e.g. \"dataflow.jar=/tmp/foo.jar\". I could remove this special syntax but I decided to keep it since it's already exposed to users via --filesToStage option so removing it may cause backward compatibility issue.", "author": "ihji", "createdAt": "2020-05-05T02:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NDYyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "5298d69ee753aead758cc92ecf44558af8c5f97e", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\nindex f1e7ab39d7..20a76cff17 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java\n\n@@ -809,12 +806,9 @@ public class DataflowRunner extends PipelineRunner<DataflowPipelineJob> {\n         } catch (InvalidProtocolBufferException e) {\n           throw new RuntimeException(\"Error parsing artifact staging_to role payload.\", e);\n         }\n-        DataflowPackage target = new DataflowPackage();\n-        target.setLocation(stagingPayload.getStagedName());\n-        if (!Strings.isNullOrEmpty(stagingPayload.getAliasName())) {\n-          target.setName(stagingPayload.getAliasName());\n-        }\n-        filesToStageBuilder.add(StagedFile.of(filePayload.getPath(), target));\n+        filesToStageBuilder.add(\n+            StagedFile.of(\n+                filePayload.getPath(), filePayload.getSha256(), stagingPayload.getStagedName()));\n       }\n     }\n     return options.getStager().stageFiles(filesToStageBuilder.build());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NTUyNQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418665525", "bodyText": "Why do we have to handle this here and above?", "author": "robertwb", "createdAt": "2020-05-01T18:09:43Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java", "diffHunk": "@@ -336,25 +323,26 @@ public DataflowPackage stageToFile(\n     final AtomicInteger numCached = new AtomicInteger(0);\n     List<CompletionStage<DataflowPackage>> destinationPackages = new ArrayList<>();\n \n-    for (String classpathElement : classpathElements) {\n-      DataflowPackage sourcePackage = new DataflowPackage();\n-      if (classpathElement.contains(\"=\")) {\n-        String[] components = classpathElement.split(\"=\", 2);\n-        sourcePackage.setName(components[0]);\n-        sourcePackage.setLocation(components[1]);\n-      } else {\n-        sourcePackage.setName(null);\n-        sourcePackage.setLocation(classpathElement);\n+    for (StagedFile classpathElement : classpathElements) {\n+      DataflowPackage targetPackage = classpathElement.getStagedPackage();\n+      String source = classpathElement.getSource();\n+      if (source.contains(\"=\")) {", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzODQ1Ng==", "url": "https://github.com/apache/beam/pull/11039#discussion_r419838456", "bodyText": "removed.", "author": "ihji", "createdAt": "2020-05-05T02:57:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NTUyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "5298d69ee753aead758cc92ecf44558af8c5f97e", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\nindex acd54fcb9c..0b5e47828d 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\n\n@@ -324,16 +299,9 @@ public class PackageUtil implements Closeable {\n     List<CompletionStage<DataflowPackage>> destinationPackages = new ArrayList<>();\n \n     for (StagedFile classpathElement : classpathElements) {\n-      DataflowPackage targetPackage = classpathElement.getStagedPackage();\n+      String dest = classpathElement.getDestination();\n       String source = classpathElement.getSource();\n-      if (source.contains(\"=\")) {\n-        if (targetPackage == null) {\n-          targetPackage = new DataflowPackage();\n-        }\n-        String[] components = source.split(\"=\", 2);\n-        targetPackage.setName(components[0]);\n-        source = components[1];\n-      }\n+      String hash = classpathElement.getSha256();\n \n       File sourceFile = new File(source);\n       if (!sourceFile.exists()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NjcxNw==", "url": "https://github.com/apache/beam/pull/11039#discussion_r418666717", "bodyText": "This seems highly redundant with what we're already doing in Environments.getArtifacts. Can't we ensure we have a set of (existing, non-directory) files in the environment, and then have these utilities simply do the uploading?", "author": "robertwb", "createdAt": "2020-05-01T18:12:43Z", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java", "diffHunk": "@@ -442,45 +448,56 @@ public static StagingResult uploaded(PackageAttributes attributes) {\n   /** Holds the metadata necessary to stage a file or confirm that a staged file has not changed. */\n   @AutoValue\n   abstract static class PackageAttributes {\n-\n-    public static PackageAttributes forFileToStage(File source, String stagingPath)\n+    public static PackageAttributes forFileToStage(File file, String stagingPath)\n         throws IOException {\n+      return forFileToStage(file.getPath(), null, stagingPath);\n+    }\n \n+    public static PackageAttributes forFileToStage(", "originalCommit": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTI3MTE1Nw==", "url": "https://github.com/apache/beam/pull/11039#discussion_r421271157", "bodyText": "I think we can remove those hashing and zipping. It's redundant except test cases. Will update the code.", "author": "ihji", "createdAt": "2020-05-07T06:37:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NjcxNw=="}], "type": "inlineReview", "revised_code": {"commit": "5298d69ee753aead758cc92ecf44558af8c5f97e", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\nindex acd54fcb9c..0b5e47828d 100644\n--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\n+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java\n\n@@ -448,70 +396,44 @@ public class PackageUtil implements Closeable {\n   /** Holds the metadata necessary to stage a file or confirm that a staged file has not changed. */\n   @AutoValue\n   abstract static class PackageAttributes {\n-    public static PackageAttributes forFileToStage(File file, String stagingPath)\n-        throws IOException {\n-      return forFileToStage(file.getPath(), null, stagingPath);\n-    }\n-\n     public static PackageAttributes forFileToStage(\n-        String source, DataflowPackage target, String stagingPath) throws IOException {\n+        String source, String hash, String dest, String stagingPath) throws IOException {\n       final File file = new File(source);\n       if (!file.exists()) {\n         throw new FileNotFoundException(\n             String.format(\"Non-existent file to stage: %s\", file.getAbsolutePath()));\n       }\n-      // Compute size and hash in one pass over file or directory.\n-      long size;\n-      String hash;\n-      Hasher hasher = Hashing.sha256().newHasher();\n-      OutputStream hashStream = Funnels.asOutputStream(hasher);\n-      try (CountingOutputStream countingOutputStream = new CountingOutputStream(hashStream)) {\n-        if (!file.isDirectory()) {\n-          // Files are staged as-is.\n-          Files.asByteSource(file).copyTo(countingOutputStream);\n-        } else {\n-          // Directories are recursively zipped.\n-          ZipFiles.zipDirectory(file, countingOutputStream);\n-        }\n-        countingOutputStream.flush();\n-\n-        size = countingOutputStream.getCount();\n-        hash = Base64Variants.MODIFIED_FOR_URL.encode(hasher.hash().asBytes());\n-      }\n+      checkState(!file.isDirectory(), \"Source file must not be a directory.\");\n       DataflowPackage destination = new DataflowPackage();\n-      DataflowPackage targetPackage = target == null ? new DataflowPackage() : target;\n-      if (targetPackage.getLocation() == null) {\n-        targetPackage.setLocation(getUniqueContentName(file, hash));\n-      }\n-      if (targetPackage.getName() == null) {\n-        targetPackage.setName(targetPackage.getLocation());\n-      }\n+      String target = dest == null ? Environments.createStagingFileName(file) : dest;\n       String resourcePath =\n           FileSystems.matchNewResource(stagingPath, true)\n-              .resolve(targetPackage.getLocation(), StandardResolveOptions.RESOLVE_FILE)\n+              .resolve(target, StandardResolveOptions.RESOLVE_FILE)\n               .toString();\n       destination.setLocation(resourcePath);\n-      destination.setName(targetPackage.getName());\n-      return new AutoValue_PackageUtil_PackageAttributes(file, null, destination, size, hash);\n+      destination.setName(target);\n+      return new AutoValue_PackageUtil_PackageAttributes(\n+          file, null, destination, file.length(), hash);\n     }\n \n     public static PackageAttributes forBytesToStage(\n         byte[] bytes, String targetName, String stagingPath) {\n+\n       Hasher hasher = Hashing.sha256().newHasher();\n-      String hash = Base64Variants.MODIFIED_FOR_URL.encode(hasher.putBytes(bytes).hash().asBytes());\n+      String hash = hasher.putBytes(bytes).hash().toString();\n       long size = bytes.length;\n \n-      String uniqueName = getUniqueContentName(new File(targetName), hash);\n+      String target = targetName == null ? UUID.randomUUID().toString() : targetName;\n \n       String resourcePath =\n           FileSystems.matchNewResource(stagingPath, true)\n-              .resolve(uniqueName, StandardResolveOptions.RESOLVE_FILE)\n+              .resolve(target, StandardResolveOptions.RESOLVE_FILE)\n               .toString();\n-      DataflowPackage target = new DataflowPackage();\n-      target.setName(uniqueName);\n-      target.setLocation(resourcePath);\n+      DataflowPackage targetPackage = new DataflowPackage();\n+      targetPackage.setName(target);\n+      targetPackage.setLocation(resourcePath);\n \n-      return new AutoValue_PackageUtil_PackageAttributes(null, bytes, target, size, hash);\n+      return new AutoValue_PackageUtil_PackageAttributes(null, bytes, targetPackage, size, hash);\n     }\n \n     public PackageAttributes withPackageName(String overridePackageName) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg3NjgzMw==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426876833", "bodyText": "You could just match \".*.txt\" here, rather than hard-coding the uuid format. (Same blow.)", "author": "robertwb", "createdAt": "2020-05-18T20:30:58Z", "path": "runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java", "diffHunk": "@@ -195,7 +187,7 @@ public void testFileWithExtensionPackageNamingAndSize() throws Exception {\n     PackageAttributes attr = makePackageAttributes(tmpFile, null);\n     DataflowPackage target = attr.getDestination();\n \n-    assertThat(target.getName(), RegexMatcher.matches(\"file-\" + HASH_PATTERN + \".txt\"));\n+    assertThat(target.getName(), RegexMatcher.matches(UUID_PATTERN + \".txt\"));", "originalCommit": "3e368f7f2fc9993960d5d070a2865ae6ef161c92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNDg1OQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426924859", "bodyText": "but it only checks whether the staged file name has the same extension (vs. checks whether the staged file name is in the form of UUID with the same extension)", "author": "ihji", "createdAt": "2020-05-18T22:24:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg3NjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNjcyMA==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426926720", "bodyText": "Is it important, for the purposes of this test (or Dataflow in general) that the staged file name is in the form of a UUID? If not (and I don't think it is) it's better not to test for it. (A test that might be good to add is to see if two same-named files in different directories actually get staged to different places, which is the underlying, important intent.)", "author": "robertwb", "createdAt": "2020-05-18T22:29:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg3NjgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MTk5OQ==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426971999", "bodyText": "Hmm. You're right. UUID is implementation detail behind the uniqueness guarantee. I changed the tests to only check whether it keeps the same extension.", "author": "ihji", "createdAt": "2020-05-19T01:03:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg3NjgzMw=="}], "type": "inlineReview", "revised_code": {"commit": "7b623517487bd8e32631e8246af49b0ac2b0c0c0", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java\nindex 949b5a05a2..2847279bab 100644\n--- a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java\n+++ b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java\n\n@@ -187,7 +185,7 @@ public class PackageUtilTest {\n     PackageAttributes attr = makePackageAttributes(tmpFile, null);\n     DataflowPackage target = attr.getDestination();\n \n-    assertThat(target.getName(), RegexMatcher.matches(UUID_PATTERN + \".txt\"));\n+    assertThat(target.getName(), endsWith(\".txt\"));\n     assertThat(target.getLocation(), equalTo(STAGING_PATH + target.getName()));\n     assertThat(attr.getSize(), equalTo((long) contents.length()));\n   }\n"}}, {"oid": "5298d69ee753aead758cc92ecf44558af8c5f97e", "url": "https://github.com/apache/beam/commit/5298d69ee753aead758cc92ecf44558af8c5f97e", "message": "make pipeline files unique", "committedDate": "2020-05-18T22:12:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU0OA==", "url": "https://github.com/apache/beam/pull/11039#discussion_r426974548", "bodyText": "Shouldn't we have a test to show the artifacts were properly set?", "author": "lukecwik", "createdAt": "2020-05-19T01:12:42Z", "path": "runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java", "diffHunk": "@@ -53,9 +53,12 @@\n import org.apache.beam.model.pipeline.v1.RunnerApi.DockerPayload;", "originalCommit": "26045210fc0e16732e55a4dd25e813c4e98f228c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzA3OTY5OA==", "url": "https://github.com/apache/beam/pull/11039#discussion_r427079698", "bodyText": "done.", "author": "ihji", "createdAt": "2020-05-19T07:16:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU0OA=="}], "type": "inlineReview", "revised_code": {"commit": "ee53ccc953595bba47254122d6e64c760ae3938f", "chunk": "diff --git a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java\nindex c247c150b7..6481b504ad 100644\n--- a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java\n+++ b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java\n\n@@ -49,6 +51,7 @@ import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.model.pipeline.v1.RunnerApi.ArtifactInformation;\n import org.apache.beam.model.pipeline.v1.RunnerApi.Components;\n import org.apache.beam.model.pipeline.v1.RunnerApi.DockerPayload;\n import org.apache.beam.model.pipeline.v1.RunnerApi.Environment;\n"}}, {"oid": "7b623517487bd8e32631e8246af49b0ac2b0c0c0", "url": "https://github.com/apache/beam/commit/7b623517487bd8e32631e8246af49b0ac2b0c0c0", "message": "[BEAM-9383] Staging Dataflow artifacts from environment", "committedDate": "2020-05-19T04:00:05Z", "type": "commit"}, {"oid": "ee53ccc953595bba47254122d6e64c760ae3938f", "url": "https://github.com/apache/beam/commit/ee53ccc953595bba47254122d6e64c760ae3938f", "message": "rebase, adding test", "committedDate": "2020-05-19T07:12:55Z", "type": "commit"}, {"oid": "ee53ccc953595bba47254122d6e64c760ae3938f", "url": "https://github.com/apache/beam/commit/ee53ccc953595bba47254122d6e64c760ae3938f", "message": "rebase, adding test", "committedDate": "2020-05-19T07:12:55Z", "type": "forcePushed"}]}