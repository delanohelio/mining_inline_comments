{"pr_number": 10694, "pr_title": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure", "pr_createdAt": "2020-01-27T17:01:22Z", "pr_url": "https://github.com/apache/beam/pull/10694", "timeline": [{"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "url": "https://github.com/apache/beam/commit/0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-28T18:52:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMDYzMw==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372000633", "bodyText": "Isn't close only called from unref? If so, how does this change the behavior? (Possibly some more explanation needs to be added.)", "author": "tweise", "createdAt": "2020-01-28T19:10:42Z", "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -464,6 +474,8 @@ ServerInfo getServerInfo() {\n     }\n \n     public void close() {", "originalCommit": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMTIzMg==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372001232", "bodyText": "It's now also called from here: https://github.com/apache/beam/pull/10694/files#diff-e80c769f0011537cc2b60d3e7898cf5aR260", "author": "mxm", "createdAt": "2020-01-28T19:11:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMDYzMw=="}], "type": "inlineReview", "revised_code": {"commit": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "chunk": "diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\nindex ae73ecc245..6e641c3775 100644\n--- a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n\n@@ -474,18 +465,20 @@ public class DefaultJobBundleFactory implements JobBundleFactory {\n     }\n \n     public void close() {\n-      // Invalidate bundle ref count to avoid cleaning up again\n-      bundleRefCount.set(-1);\n       // DO NOT ADD ANYTHING HERE WHICH MIGHT CAUSE THE BLOCK BELOW TO NOT BE EXECUTED.\n       // If we exit prematurely (e.g. due to an exception), resources won't be cleaned up properly.\n       // Please make an AutoCloseable and add it to the try statement below.\n-      try (AutoCloseable envCloser = environment;\n+      try (\n+          // These will be closed in the reverse creation order\n+          AutoCloseable envCloser = environment;\n+          AutoCloseable provisioningServer = serverInfo.getProvisioningServer();\n+          AutoCloseable retrievalServer = serverInfo.getRetrievalServer();\n           AutoCloseable stateServer = serverInfo.getStateServer();\n-          AutoCloseable dateServer = serverInfo.getDataServer();\n+          AutoCloseable dataServer = serverInfo.getDataServer();\n           AutoCloseable controlServer = serverInfo.getControlServer();\n+          // Close the logging server first to prevent spaming the logs with error messages\n           AutoCloseable loggingServer = serverInfo.getLoggingServer();\n-          AutoCloseable retrievalServer = serverInfo.getRetrievalServer();\n-          AutoCloseable provisioningServer = serverInfo.getProvisioningServer()) {\n+      ) {\n         // Wrap resources in try-with-resources to ensure all are cleaned up.\n         // This will close _all_ of these even in the presence of exceptions.\n         // The first exception encountered will be the base exception,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMTczMA==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372001730", "bodyText": "What would cause this extra ref in the actual operator lifecycle?", "author": "tweise", "createdAt": "2020-01-28T19:13:01Z", "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java", "diffHunk": "@@ -360,6 +360,19 @@ public void closesEnvironmentOnCleanup() throws Exception {\n     verify(remoteEnvironment).close();\n   }\n \n+  @Test\n+  public void closesEnvironmentOnCleanupWithPendingRefs() throws Exception {\n+    try (DefaultJobBundleFactory bundleFactory =\n+        createDefaultJobBundleFactory(envFactoryProviderMap)) {\n+      DefaultJobBundleFactory.SimpleStageBundleFactory stageBundleFactory =\n+          (DefaultJobBundleFactory.SimpleStageBundleFactory)\n+              bundleFactory.forStage(getExecutableStage(environment));\n+      // The client is still being used, e.g. when the pipeline fails and is shut down\n+      stageBundleFactory.currentClient.wrappedClient.ref();", "originalCommit": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAxNDI4NA==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372014284", "bodyText": "I'm assuming here we have a ref() due to the client being used. If we had no ref, we would be idling. The error message we were seeing is only possible if we are currently processing a bundle.", "author": "mxm", "createdAt": "2020-01-28T19:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMTczMA=="}], "type": "inlineReview", "revised_code": {"commit": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "chunk": "diff --git a/runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java b/runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java\nindex 240fcc9319..369115f775 100644\n--- a/runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java\n+++ b/runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java\n\n@@ -361,16 +362,21 @@ public class DefaultJobBundleFactoryTest {\n   }\n \n   @Test\n-  public void closesEnvironmentOnCleanupWithPendingRefs() throws Exception {\n+  public void closesLoggingServerFirst() throws Exception {\n+    InOrder inOrder = Mockito.inOrder(loggingServer, controlServer, dataServer, stateServer, retrievalServer, provisioningServer, remoteEnvironment);\n+\n     try (DefaultJobBundleFactory bundleFactory =\n         createDefaultJobBundleFactory(envFactoryProviderMap)) {\n-      DefaultJobBundleFactory.SimpleStageBundleFactory stageBundleFactory =\n-          (DefaultJobBundleFactory.SimpleStageBundleFactory)\n-              bundleFactory.forStage(getExecutableStage(environment));\n-      // The client is still being used, e.g. when the pipeline fails and is shut down\n-      stageBundleFactory.currentClient.wrappedClient.ref();\n+      bundleFactory.forStage(getExecutableStage(environment));\n     }\n-    verify(remoteEnvironment).close();\n+\n+    inOrder.verify(loggingServer).close();\n+    inOrder.verify(controlServer).close();\n+    inOrder.verify(dataServer).close();\n+    inOrder.verify(stateServer).close();\n+    inOrder.verify(retrievalServer).close();\n+    inOrder.verify(provisioningServer).close();\n+    inOrder.verify(remoteEnvironment).close();\n   }\n \n   @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI5OQ==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372004299", "bodyText": "Worth mentioning that this is added to close the environments irrespective of open bundles, since this will occur only during shutdown?", "author": "tweise", "createdAt": "2020-01-28T19:18:07Z", "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -255,6 +255,14 @@ public void close() throws Exception {\n     // Clear the cache. This closes all active environments.\n     // note this may cause open calls to be cancelled by the peer\n     for (LoadingCache<Environment, WrappedSdkHarnessClient> environmentCache : environmentCaches) {\n+      for (WrappedSdkHarnessClient client : environmentCache.asMap().values()) {\n+        try {\n+          client.close();", "originalCommit": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0MDM1MQ==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372540351", "bodyText": "I've removed this in favor of using unref(). I think I found the case where unref() would not be called: https://github.com/apache/beam/pull/10694/files#diff-e80c769f0011537cc2b60d3e7898cf5aR413", "author": "mxm", "createdAt": "2020-01-29T17:59:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "chunk": "diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\nindex ae73ecc245..6e641c3775 100644\n--- a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n\n@@ -255,14 +256,6 @@ public class DefaultJobBundleFactory implements JobBundleFactory {\n     // Clear the cache. This closes all active environments.\n     // note this may cause open calls to be cancelled by the peer\n     for (LoadingCache<Environment, WrappedSdkHarnessClient> environmentCache : environmentCaches) {\n-      for (WrappedSdkHarnessClient client : environmentCache.asMap().values()) {\n-        try {\n-          client.close();\n-        } catch (Exception e) {\n-          // This shouldn't throw because the client catches errors, but just in case...\n-          LOG.warn(\"Error closing client.\", e);\n-        }\n-      }\n       environmentCache.invalidateAll();\n       environmentCache.cleanUp();\n     }\n"}}, {"oid": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "url": "https://github.com/apache/beam/commit/54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-29T16:29:10Z", "type": "forcePushed"}, {"oid": "ae714925001f4ebb829d2a935238451b8caff37b", "url": "https://github.com/apache/beam/commit/ae714925001f4ebb829d2a935238451b8caff37b", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-29T16:42:08Z", "type": "forcePushed"}, {"oid": "132e627cddb4392196694b608a0011a3a3f46462", "url": "https://github.com/apache/beam/commit/132e627cddb4392196694b608a0011a3a3f46462", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-29T17:48:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU4NTU1MQ==", "url": "https://github.com/apache/beam/pull/10694#discussion_r372585551", "bodyText": "Looks like this was responsible for the cleanup failing. bundle.close() may throw leaving the environment still referenced. My tests do not yield any more errors like in the description.", "author": "mxm", "createdAt": "2020-01-29T19:28:55Z", "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -406,11 +407,14 @@ public void split(double fractionOfRemainder) {\n \n         @Override\n         public void close() throws Exception {\n-          bundle.close();\n-          currentClient.wrappedClient.unref();\n-          if (loadBalanceBundles) {\n-            availableCaches.offer(currentCache);\n-            availableCachesSemaphore.release();\n+          try {\n+            bundle.close();\n+          } finally {\n+            currentClient.wrappedClient.unref();\n+            if (loadBalanceBundles) {\n+              availableCaches.offer(currentCache);\n+              availableCachesSemaphore.release();\n+            }", "originalCommit": "132e627cddb4392196694b608a0011a3a3f46462", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "chunk": "diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\nindex bb7dd06cb0..84dc918fed 100644\n--- a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java\n\n@@ -410,7 +401,7 @@ public class DefaultJobBundleFactory implements JobBundleFactory {\n           try {\n             bundle.close();\n           } finally {\n-            currentClient.wrappedClient.unref();\n+            client.unref();\n             if (loadBalanceBundles) {\n               availableCaches.offer(currentCache);\n               availableCachesSemaphore.release();\n"}}, {"oid": "22d0bcbbcb87a05839ec7ff629cefcc16457e776", "url": "https://github.com/apache/beam/commit/22d0bcbbcb87a05839ec7ff629cefcc16457e776", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-29T20:54:48Z", "type": "forcePushed"}, {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "url": "https://github.com/apache/beam/commit/7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-31T10:47:26Z", "type": "commit"}, {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "url": "https://github.com/apache/beam/commit/7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.", "committedDate": "2020-01-31T10:47:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ1MjA5Ng==", "url": "https://github.com/apache/beam/pull/10694#discussion_r373452096", "bodyText": "I discovered another issue in this code path. ref() is not called on the client in this case. Also, unref() will never be called because the code below does not insert the call to the bundle close. close() is only ever called on unref().", "author": "mxm", "createdAt": "2020-01-31T12:16:42Z", "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -342,22 +343,14 @@ public RemoteBundle getBundle(\n       // TODO: Consider having BundleProcessor#newBundle take in an OutputReceiverFactory rather\n       // than constructing the receiver map here. Every bundle factory will need this.\n \n-      if (environmentExpirationMillis == 0 && !loadBalanceBundles) {\n-        return currentClient.processor.newBundle(\n-            getOutputReceivers(currentClient.processBundleDescriptor, outputReceiverFactory)\n-                .build(),\n-            stateRequestHandler,\n-            progressHandler);\n-      }", "originalCommit": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU2MzY1NA==", "url": "https://github.com/apache/beam/pull/10694#discussion_r373563654", "bodyText": "This is the original code path that was used when no reference counting is required. What was the problem with it?", "author": "tweise", "createdAt": "2020-01-31T16:19:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ1MjA5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4MDIwOA==", "url": "https://github.com/apache/beam/pull/10694#discussion_r373580208", "bodyText": "I suppose it was working correctly due to the initial ref() when creating the environment. Still, it doesn't hurt to remove this bit because it just adds a specialized execution path to the generalized version. The ref business is already complex enough. If you think differently feel free to add it back, but IMHO this is easier to understand.", "author": "mxm", "createdAt": "2020-01-31T16:53:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ1MjA5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4MTExMQ==", "url": "https://github.com/apache/beam/pull/10694#discussion_r373581111", "bodyText": "During the initial review of the bundle load balancing the idea came up to have two implementations, one with refing, one without. I think that would be the best improvement moving forward.", "author": "mxm", "createdAt": "2020-01-31T16:54:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ1MjA5Ng=="}], "type": "inlineReview", "revised_code": null}]}