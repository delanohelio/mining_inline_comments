{"pr_number": 12232, "pr_title": "[Beam-9543] Support Match Recognition in Beam SQL", "pr_createdAt": "2020-07-12T09:38:54Z", "pr_url": "https://github.com/apache/beam/pull/12232", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453294680", "bodyText": "In my last PR (#12073), Rui suggested there is a row comparator available for use. I found it a private class in BeamSortRel. I just wonder if I could copy the code from there (maybe also and a reference?). What is the correct way of doing it?", "author": "Mark-Zeng", "createdAt": "2020-07-12T09:52:17Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }\n+      }\n+    }\n+\n+    private static class SortPerKey extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final Schema cSchema;\n+      private final ArrayList<OrderKey> orderKeys;\n+\n+      public SortPerKey(Schema cSchema, RelCollation orderKeys) {\n+        this.cSchema = cSchema;\n+\n+        List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+        Collections.reverse(revOrderKeys);\n+        ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n+        for (RelFieldCollation i : revOrderKeys) {\n+          int fIndex = i.getFieldIndex();\n+          RelFieldCollation.Direction dir = i.getDirection();\n+          if (dir == RelFieldCollation.Direction.ASCENDING) {\n+            revOrderKeysList.add(new OrderKey(fIndex, false));\n+          } else {\n+            revOrderKeysList.add(new OrderKey(fIndex, true));\n+          }\n+        }\n+\n+        this.orderKeys = revOrderKeysList;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<Row>();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+        }\n+        for (OrderKey i : orderKeys) {\n+          int fIndex = i.getIndex();\n+          boolean dir = i.getDir();\n+          rows.sort(new SortComparator(fIndex, dir));\n+        }\n+        // TODO: Change the comparator to the row comparator:\n+        // https://github.com/apache/beam/blob/master/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamSortRel.java#L373\n+\n+        out.output(KV.of(keyRows.getKey(), rows));\n+      }\n+\n+      private class SortComparator implements Comparator<Row> {\n+\n+        private final int fIndex;\n+        private final int inv;\n+", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3OTgwMA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453979800", "bodyText": "Hi you can update that class to public to use it.", "author": "amaliujia", "createdAt": "2020-07-13T22:27:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTgzNA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989834", "bodyText": "In fact what you are doing is ok. This is minor.", "author": "amaliujia", "createdAt": "2020-07-13T22:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxMjY2OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r454912669", "bodyText": "I just updated the implementation using the comparator in BeamSortRel. You will see it in my next commit!", "author": "Mark-Zeng", "createdAt": "2020-07-15T09:19:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4Nzc4OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453987789", "bodyText": "This seems a unused class?", "author": "amaliujia", "createdAt": "2020-07-13T22:40:15Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPOperand.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+public class CEPOperand {}", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxMTc2OA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r454911768", "bodyText": "This is indeed redundant.", "author": "Mark-Zeng", "createdAt": "2020-07-15T09:18:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4Nzc4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPOperand.java b/sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/package-info.java\nsimilarity index 90%\nrename from sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPOperand.java\nrename to sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/package-info.java\nindex ef451aa93e..642ebf1460 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPOperand.java\n+++ b/sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/package-info.java\n\n@@ -15,6 +15,6 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.impl.cep;\n \n-public class CEPOperand {}\n+/** Snowflake IO data types. */\n+package org.apache.beam.sdk.io.snowflake.data;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTIwMg==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989202", "bodyText": "To make sure I understand this example.\nDoes PATTERN(A B C) means it should produce rows, in which each three rows are a set, and in each set, names should be a, b, c and also in this order?", "author": "amaliujia", "createdAt": "2020-07-13T22:44:14Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n+\n+import org.apache.beam.sdk.extensions.sql.TestUtils;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+public class BeamMatchRelTest {\n+\n+  @Rule public final TestPipeline pipeline = TestPipeline.create();\n+\n+  @Test\n+  public void matchLogicalPlanTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"PATTERN (A B C) \"", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyNTQwMQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r454925401", "bodyText": "Yes, if by ''set'' you mean partition. There are 2 output modes: ALL ROWS PER MATCH and ONE ROW PER MATCH (default) which I have not implemented. I just output all rows from a match because I want to check if the pattern-match part works.", "author": "Mark-Zeng", "createdAt": "2020-07-15T09:41:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyODAwOA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r454928008", "bodyText": "In Flink CEP, it only supports ONE ROW PER MATCH and the output columns are determined by the PARTITION BY and the MEASURES (not implemented yet) clauses.", "author": "Mark-Zeng", "createdAt": "2020-07-15T09:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTM5MjE0OA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455392148", "bodyText": "I see. Thanks for clarification.", "author": "amaliujia", "createdAt": "2020-07-15T22:05:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTIwMg=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java\ndeleted file mode 100644\nindex a6657685e0..0000000000\n--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java\n+++ /dev/null\n\n@@ -1,75 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.sdk.extensions.sql.impl.rel;\n-\n-import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n-import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n-\n-import org.apache.beam.sdk.extensions.sql.TestUtils;\n-import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n-import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.sdk.testing.PAssert;\n-import org.apache.beam.sdk.testing.TestPipeline;\n-import org.apache.beam.sdk.values.PCollection;\n-import org.apache.beam.sdk.values.Row;\n-import org.junit.Rule;\n-import org.junit.Test;\n-\n-public class BeamMatchRelTest {\n-\n-  @Rule public final TestPipeline pipeline = TestPipeline.create();\n-\n-  @Test\n-  public void matchLogicalPlanTest() {\n-    Schema schemaType =\n-        Schema.builder()\n-            .addInt32Field(\"id\")\n-            .addStringField(\"name\")\n-            .addInt32Field(\"proctime\")\n-            .build();\n-\n-    registerTable(\n-        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n-\n-    String sql =\n-        \"SELECT * \"\n-            + \"FROM TestTable \"\n-            + \"MATCH_RECOGNIZE (\"\n-            + \"PARTITION BY id \"\n-            + \"ORDER BY proctime \"\n-            + \"PATTERN (A B C) \"\n-            + \"DEFINE \"\n-            + \"A AS name = 'a', \"\n-            + \"B AS name = 'b', \"\n-            + \"C AS name = 'c' \"\n-            + \") AS T\";\n-\n-    PCollection<Row> result = compilePipeline(sql, pipeline);\n-\n-    PAssert.that(result)\n-        .containsInAnyOrder(\n-            TestUtils.RowsBuilder.of(\n-                    Schema.FieldType.INT32, \"id\",\n-                    Schema.FieldType.STRING, \"name\",\n-                    Schema.FieldType.INT32, \"proctime\")\n-                .addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3)\n-                .getRows());\n-\n-    pipeline.run().waitUntilFinish();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTM4OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989389", "bodyText": "For all new classes, please add javadoc to explain these classes (i.e. /** */). Adding comments are usual good idea to improve your code's readability.", "author": "amaliujia", "createdAt": "2020-07-13T22:44:44Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rule;\n+\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamLogicalConvention;\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamMatchRel;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.Convention;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.convert.ConverterRule;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.logical.LogicalMatch;\n+\n+public class BeamMatchRule extends ConverterRule {", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java\nindex efdd0da649..6b2decaf63 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java\n\n@@ -1,24 +1,7 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rule;\n \n-import org.apache.beam.sdk.extensions.sql.impl.rel.BeamLogicalConvention;\n import org.apache.beam.sdk.extensions.sql.impl.rel.BeamMatchRel;\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamLogicalConvention;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.Convention;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.convert.ConverterRule;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTEzMQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453991131", "bodyText": "Nit: upstreamSchema might be a better variable name.", "author": "amaliujia", "createdAt": "2020-07-13T22:49:42Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxOTg2MA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r454919860", "bodyText": "Done.", "author": "Mark-Zeng", "createdAt": "2020-07-15T09:32:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTEzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjI1Nw==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453992257", "bodyText": "Ah so is collectionSchema's field name the same as varNode's name (including that $)?\nSee Schema.getName API: https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L1270", "author": "amaliujia", "createdAt": "2020-07-13T22:53:05Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE5NzgzNg==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455197836", "bodyText": "The varNode is an instance of RexVariable. I wanted to get the index or column name from it; the getName method returns a string like '$9' which is the field index preceded by a dollar sign. This is a very awkward way of extracting the information, but I could not think of a better one.", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjI1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgxNDUwNQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r458814505", "bodyText": "I just spotted that I used the wrong class. The subclass RexInputRef of RexVariable has the information of both the column index and field (column) name. This part will change in my later commits.", "author": "Mark-Zeng", "createdAt": "2020-07-22T14:00:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjI1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjQyNA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453992424", "bodyText": "Nit: name it PartitionKeySchema might be more readable.", "author": "amaliujia", "createdAt": "2020-07-13T22:53:36Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE5ODkzMg==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455198932", "bodyText": "Agree. Still need practice on naming variables : )", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:03:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjQyNA=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Mzc5OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453993799", "bodyText": "In fact, there is also a NullDirection to consider (Null first/Null last): https://github.com/apache/calcite/blob/master/core/src/main/java/org/apache/calcite/rel/RelFieldCollation.java#L185\nIt is ok to not handle it for now, but please leave a TODO comment (i.e. // TODO: handle NullDirection)", "author": "amaliujia", "createdAt": "2020-07-13T22:57:36Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }\n+      }\n+    }\n+\n+    private static class SortPerKey extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final Schema cSchema;\n+      private final ArrayList<OrderKey> orderKeys;\n+\n+      public SortPerKey(Schema cSchema, RelCollation orderKeys) {\n+        this.cSchema = cSchema;\n+\n+        List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+        Collections.reverse(revOrderKeys);\n+        ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n+        for (RelFieldCollation i : revOrderKeys) {\n+          int fIndex = i.getFieldIndex();\n+          RelFieldCollation.Direction dir = i.getDirection();\n+          if (dir == RelFieldCollation.Direction.ASCENDING) {", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIwMTU2MA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455201560", "bodyText": "I have just added the implementation for it.", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:07:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Mzc5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NDcxNA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453994714", "bodyText": "I think you got to make Pattern p as a variable to compile once?", "author": "amaliujia", "createdAt": "2020-07-13T23:00:14Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIwNDc5MQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455204791", "bodyText": "I am very new to the regex library of Java. This my first time of using it. I just followed the Oracle doc on regex and the example in it.", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:12:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NDcxNA=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453995446", "bodyText": "Is it possible to reuse https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L413?", "author": "amaliujia", "createdAt": "2020-07-13T23:02:28Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.io.Serializable;\n+\n+public enum CEPTypeName implements Serializable {", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NjI0OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453996249", "bodyText": "It is ok though if you still want to use a separate enum for CEP types, since it is a standalone library.\nJust curious, is there a type that is not covered by https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L413?", "author": "amaliujia", "createdAt": "2020-07-13T23:04:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIxMzk0OQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455213949", "bodyText": "I think it is possible; reusing the schema types seems natural also. I will update it in my next commit.", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:26:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIxODUyMg==", "url": "https://github.com/apache/beam/pull/12232#discussion_r455218522", "bodyText": "There are some differences. RexLiteral class seems to have a wider support for time interval. And I just found in the page that the value of the Double type in a literal node is BigDecimal? weird.", "author": "Mark-Zeng", "createdAt": "2020-07-15T17:31:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java b/sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/SnowflakeDataType.java\nsimilarity index 80%\nrename from sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java\nrename to sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/SnowflakeDataType.java\nindex ede10e431f..4b8caf5748 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java\n+++ b/sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/data/SnowflakeDataType.java\n\n@@ -15,19 +15,11 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.impl.cep;\n+package org.apache.beam.sdk.io.snowflake.data;\n \n import java.io.Serializable;\n \n-public enum CEPTypeName implements Serializable {\n-  BYTE,\n-  INT16,\n-  INT32,\n-  INT64,\n-  DECIMAL,\n-  FLOAT,\n-  DOUBLE,\n-  STRING,\n-  DATETIME,\n-  BOOLEAN\n+/** Interface for data types to provide SQLs for themselves. */\n+public interface SnowflakeDataType extends Serializable {\n+  String sql();\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NjgwMw==", "url": "https://github.com/apache/beam/pull/12232#discussion_r453996803", "bodyText": "This will rely on an assumption that Fusion will fuse operators here so the sorted result will be preserved for the next match transform. In most of the runners (if not all) this should be true.", "author": "amaliujia", "createdAt": "2020-07-13T23:06:30Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));", "originalCommit": "1727e170ef88ed8150a7fd30f6f9254ef1031548", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex b948ca791b..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,45 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2Nzc1MA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r457867750", "bodyText": "I realized this should be a while loop. And for regex implementation, the default after match strategy is \"skip past last row\". I will change it to a while loop in my next commit.", "author": "Mark-Zeng", "createdAt": "2020-07-21T06:34:19Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil.makeOrderKeysFromCollation;\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@code BeamRelNode} to replace a {@code Match} node.\n+ *\n+ * <p>The {@code BeamMatchRel} is the Beam implementation of {@code MATCH_RECOGNIZE} in SQL.\n+ *\n+ * <p>For now, the underline implementation is based on java.util.regex.\n+ */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema upstreamSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(upstreamSchema.getField(index));\n+      }\n+      Schema partitionKeySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream =\n+          upstream.apply(ParDo.of(new MapKeys(partitionKeySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(partitionKeySchema), RowCoder.of(upstreamSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      ArrayList<OrderKey> orderKeyList = makeOrderKeysFromCollation(orderKeys);\n+      // This will rely on an assumption that Fusion will fuse\n+      // operators here so the sorted result will be preserved\n+      // for the next match transform.\n+      // In most of the runners (if not all) this should be true.\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(upstreamSchema, orderKeyList)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(upstreamSchema, pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern(pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output all rows of each pattern matched (for testing purpose)\n+      // TODO: add ONE ROW PER MATCH and MEASURES implementation.\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(upstreamSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.getPatternVar();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }", "originalCommit": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\nindex 380af0528f..c20c4b189b 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java\n\n@@ -1,43 +1,10 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n package org.apache.beam.sdk.extensions.sql.impl.rel;\n \n-import static org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil.makeOrderKeysFromCollation;\n-import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.SortedSet;\n-import java.util.regex.Matcher;\n-import java.util.regex.Pattern;\n-import org.apache.beam.sdk.coders.KvCoder;\n-import org.apache.beam.sdk.coders.RowCoder;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n-import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.transforms.DoFn;\n-import org.apache.beam.sdk.transforms.GroupByKey;\n import org.apache.beam.sdk.transforms.PTransform;\n-import org.apache.beam.sdk.transforms.ParDo;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollection;\n import org.apache.beam.sdk.values.PCollectionList;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r460341711", "bodyText": "Is it correct to not handle other classes?\nIf so can you add an exception in the last else?", "author": "amaliujia", "createdAt": "2020-07-25T00:42:35Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexPatternFieldRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n+\n+/**\n+ * A {@code CEPCall} instance represents an operation (node) that contains an operator and a list of\n+ * operands. It has the similar functionality as Calcite's {@code RexCall}.\n+ */\n+public class CEPCall extends CEPOperation {\n+\n+  private final CEPOperator operator;\n+  private final List<CEPOperation> operands;\n+\n+  private CEPCall(CEPOperator operator, List<CEPOperation> operands) {\n+    this.operator = operator;\n+    this.operands = operands;\n+  }\n+\n+  public CEPOperator getOperator() {\n+    return operator;\n+  }\n+\n+  public List<CEPOperation> getOperands() {\n+    return operands;\n+  }\n+\n+  public static CEPCall of(RexCall operation) {\n+    SqlOperator call = operation.getOperator();\n+    CEPOperator myOp = CEPOperator.of(call);\n+\n+    ArrayList<CEPOperation> operandsList = new ArrayList<>();\n+    for (RexNode i : operation.getOperands()) {\n+      if (i.getClass() == RexCall.class) {\n+        CEPCall callToAdd = CEPCall.of((RexCall) i);\n+        operandsList.add(callToAdd);\n+      } else if (i.getClass() == RexLiteral.class) {\n+        RexLiteral lit = (RexLiteral) i;\n+        CEPLiteral litToAdd = CEPLiteral.of(lit);\n+        operandsList.add(litToAdd);\n+      } else if (i.getClass() == RexPatternFieldRef.class) {\n+        RexPatternFieldRef fieldRef = (RexPatternFieldRef) i;\n+        CEPFieldRef fieldRefToAdd = CEPFieldRef.of(fieldRef);\n+        operandsList.add(fieldRefToAdd);\n+      }", "originalCommit": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk2NjU1Mg==", "url": "https://github.com/apache/beam/pull/12232#discussion_r463966552", "bodyText": "will do.", "author": "Mark-Zeng", "createdAt": "2020-08-01T14:21:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNjY3NA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r464116674", "bodyText": "Please print the RexNode so people can see which RexNode is not supported.\n \"the RexNode is not recognized: \" + i", "author": "amaliujia", "createdAt": "2020-08-02T19:50:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDMzNzI2NA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r464337264", "bodyText": "Ok", "author": "Mark-Zeng", "createdAt": "2020-08-03T10:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java\ndeleted file mode 100644\nindex b4978035f2..0000000000\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java\n+++ /dev/null\n\n@@ -1,72 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.sdk.extensions.sql.impl.cep;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexPatternFieldRef;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n-\n-/**\n- * A {@code CEPCall} instance represents an operation (node) that contains an operator and a list of\n- * operands. It has the similar functionality as Calcite's {@code RexCall}.\n- */\n-public class CEPCall extends CEPOperation {\n-\n-  private final CEPOperator operator;\n-  private final List<CEPOperation> operands;\n-\n-  private CEPCall(CEPOperator operator, List<CEPOperation> operands) {\n-    this.operator = operator;\n-    this.operands = operands;\n-  }\n-\n-  public CEPOperator getOperator() {\n-    return operator;\n-  }\n-\n-  public List<CEPOperation> getOperands() {\n-    return operands;\n-  }\n-\n-  public static CEPCall of(RexCall operation) {\n-    SqlOperator call = operation.getOperator();\n-    CEPOperator myOp = CEPOperator.of(call);\n-\n-    ArrayList<CEPOperation> operandsList = new ArrayList<>();\n-    for (RexNode i : operation.getOperands()) {\n-      if (i.getClass() == RexCall.class) {\n-        CEPCall callToAdd = CEPCall.of((RexCall) i);\n-        operandsList.add(callToAdd);\n-      } else if (i.getClass() == RexLiteral.class) {\n-        RexLiteral lit = (RexLiteral) i;\n-        CEPLiteral litToAdd = CEPLiteral.of(lit);\n-        operandsList.add(litToAdd);\n-      } else if (i.getClass() == RexPatternFieldRef.class) {\n-        RexPatternFieldRef fieldRef = (RexPatternFieldRef) i;\n-        CEPFieldRef fieldRefToAdd = CEPFieldRef.of(fieldRef);\n-        operandsList.add(fieldRefToAdd);\n-      }\n-    }\n-\n-    return new CEPCall(myOp, operandsList);\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTg2OA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r460341868", "bodyText": "nit: no need add literal here.", "author": "amaliujia", "createdAt": "2020-07-25T00:43:45Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPLiteral.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.math.BigDecimal;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.joda.time.ReadableDateTime;\n+\n+/**\n+ * {@code CEPLiteral} represents a literal node. It corresponds to {@code RexLiteral} in Calcite.\n+ */\n+public class CEPLiteral extends CEPOperation {\n+\n+  private final Schema.TypeName typeName;\n+\n+  private CEPLiteral(Schema.TypeName typeName) {\n+    this.typeName = typeName;\n+  }\n+\n+  // TODO: deal with other types (byte, short...)\n+  public static CEPLiteral of(RexLiteral lit) {\n+    switch (lit.getTypeName()) {\n+      case INTEGER:\n+        return of(lit.getValueAs(Integer.class));\n+      case BIGINT:\n+        return of(lit.getValueAs(Long.class));\n+      case DECIMAL:\n+        return of(lit.getValueAs(BigDecimal.class));\n+      case FLOAT:\n+        return of(lit.getValueAs(Float.class));\n+      case DOUBLE:\n+        return of(lit.getValueAs(Double.class));\n+      case BOOLEAN:\n+        return of(lit.getValueAs(Boolean.class));\n+      case DATE:\n+        return of(lit.getValueAs(ReadableDateTime.class));\n+      case CHAR:\n+      case VARCHAR:\n+        return of(lit.getValueAs(String.class));\n+      default:\n+        throw new SqlConversionException(\n+            \"sql literal type not supported: \" + lit.getTypeName().toString());", "originalCommit": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk2NjU1NQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r463966555", "bodyText": "ok.", "author": "Mark-Zeng", "createdAt": "2020-08-01T14:21:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTg2OA=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPLiteral.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPLiteral.java\ndeleted file mode 100644\nindex 19505b35fd..0000000000\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPLiteral.java\n+++ /dev/null\n\n@@ -1,196 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.sdk.extensions.sql.impl.cep;\n-\n-import java.math.BigDecimal;\n-import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n-import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n-import org.joda.time.ReadableDateTime;\n-\n-/**\n- * {@code CEPLiteral} represents a literal node. It corresponds to {@code RexLiteral} in Calcite.\n- */\n-public class CEPLiteral extends CEPOperation {\n-\n-  private final Schema.TypeName typeName;\n-\n-  private CEPLiteral(Schema.TypeName typeName) {\n-    this.typeName = typeName;\n-  }\n-\n-  // TODO: deal with other types (byte, short...)\n-  public static CEPLiteral of(RexLiteral lit) {\n-    switch (lit.getTypeName()) {\n-      case INTEGER:\n-        return of(lit.getValueAs(Integer.class));\n-      case BIGINT:\n-        return of(lit.getValueAs(Long.class));\n-      case DECIMAL:\n-        return of(lit.getValueAs(BigDecimal.class));\n-      case FLOAT:\n-        return of(lit.getValueAs(Float.class));\n-      case DOUBLE:\n-        return of(lit.getValueAs(Double.class));\n-      case BOOLEAN:\n-        return of(lit.getValueAs(Boolean.class));\n-      case DATE:\n-        return of(lit.getValueAs(ReadableDateTime.class));\n-      case CHAR:\n-      case VARCHAR:\n-        return of(lit.getValueAs(String.class));\n-      default:\n-        throw new SqlConversionException(\n-            \"sql literal type not supported: \" + lit.getTypeName().toString());\n-    }\n-  }\n-\n-  public static CEPLiteral of(Byte myByte) {\n-    return new CEPLiteral(Schema.TypeName.BYTE) {\n-      @Override\n-      public Byte getByte() {\n-        return myByte;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Short myShort) {\n-    return new CEPLiteral(Schema.TypeName.INT16) {\n-      @Override\n-      public Short getInt16() {\n-        return myShort;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Integer myInt) {\n-    return new CEPLiteral(Schema.TypeName.INT32) {\n-      @Override\n-      public Integer getInt32() {\n-        return myInt;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Long myLong) {\n-    return new CEPLiteral(Schema.TypeName.INT64) {\n-      @Override\n-      public Long getInt64() {\n-        return myLong;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(BigDecimal myDecimal) {\n-    return new CEPLiteral(Schema.TypeName.DECIMAL) {\n-      @Override\n-      public BigDecimal getDecimal() {\n-        return myDecimal;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Float myFloat) {\n-    return new CEPLiteral(Schema.TypeName.FLOAT) {\n-      @Override\n-      public Float getFloat() {\n-        return myFloat;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Double myDouble) {\n-    return new CEPLiteral(Schema.TypeName.DOUBLE) {\n-      @Override\n-      public Double getDouble() {\n-        return myDouble;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(ReadableDateTime myDateTime) {\n-    return new CEPLiteral(Schema.TypeName.DATETIME) {\n-      @Override\n-      public ReadableDateTime getDateTime() {\n-        return myDateTime;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(Boolean myBoolean) {\n-    return new CEPLiteral(Schema.TypeName.BOOLEAN) {\n-      @Override\n-      public Boolean getBoolean() {\n-        return myBoolean;\n-      }\n-    };\n-  }\n-\n-  public static CEPLiteral of(String myString) {\n-    return new CEPLiteral(Schema.TypeName.STRING) {\n-      @Override\n-      public String getString() {\n-        return myString;\n-      }\n-    };\n-  }\n-\n-  public Byte getByte() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Short getInt16() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Integer getInt32() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Long getInt64() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public BigDecimal getDecimal() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Float getFloat() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Double getDouble() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public ReadableDateTime getDateTime() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Boolean getBoolean() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public String getString() {\n-    throw new SqlConversionException(\"the class must be subclassed properly to get the value\");\n-  }\n-\n-  public Schema.TypeName getTypeName() {\n-    return typeName;\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzM3NA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r460343374", "bodyText": "This reverse seems not useful.", "author": "amaliujia", "createdAt": "2020-07-25T00:54:12Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPUtil.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlKind;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n+\n+/**\n+ * Some utility methods for transforming Calcite's constructs into our own Beam constructs (for\n+ * serialization purpose).\n+ */\n+public class CEPUtil {\n+\n+  private static Quantifier getQuantifier(int start, int end, boolean isReluctant) {\n+    Quantifier quantToAdd;\n+    if (!isReluctant) {\n+      if (start == end) {\n+        quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n+      } else {\n+        if (end == -1) {\n+          if (start == 0) {\n+            quantToAdd = Quantifier.ASTERISK;\n+          } else if (start == 1) {\n+            quantToAdd = Quantifier.PLUS;\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n+          }\n+        } else {\n+          if (start == 0 && end == 1) {\n+            quantToAdd = Quantifier.QMARK;\n+          } else if (start == -1) {\n+            quantToAdd = new Quantifier(\"{ , \" + end + \" }\");\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" , }\");\n+          }\n+        }\n+      }\n+    } else {\n+      if (start == end) {\n+        quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n+      } else {\n+        if (end == -1) {\n+          if (start == 0) {\n+            quantToAdd = Quantifier.ASTERISK_RELUCTANT;\n+          } else if (start == 1) {\n+            quantToAdd = Quantifier.PLUS_RELUCTANT;\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n+          }\n+        } else {\n+          if (start == 0 && end == 1) {\n+            quantToAdd = Quantifier.QMARK_RELUCTANT;\n+          } else if (start == -1) {\n+            quantToAdd = new Quantifier(\"{ , \" + end + \" }?\");\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" , }?\");\n+          }\n+        }\n+      }\n+    }\n+\n+    return quantToAdd;\n+  }\n+\n+  /** Construct a list of {@code CEPPattern}s from a {@code RexNode}. */\n+  public static ArrayList<CEPPattern> getCEPPatternFromPattern(\n+      Schema upStreamSchema, RexNode call, Map<String, RexNode> patternDefs) {\n+    ArrayList<CEPPattern> patternList = new ArrayList<>();\n+    if (call.getClass() == RexLiteral.class) {\n+      String p = ((RexLiteral) call).getValueAs(String.class);\n+      RexNode pd = patternDefs.get(p);\n+      patternList.add(CEPPattern.of(upStreamSchema, p, (RexCall) pd, Quantifier.NONE));\n+    } else {\n+      RexCall patCall = (RexCall) call;\n+      SqlOperator operator = patCall.getOperator();\n+      List<RexNode> operands = patCall.getOperands();\n+\n+      // check if if the node has quantifier\n+      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n+        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n+        RexNode pd = patternDefs.get(p);\n+        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n+        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n+        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n+\n+        patternList.add(\n+            CEPPattern.of(upStreamSchema, p, (RexCall) pd, getQuantifier(start, end, isReluctant)));\n+      } else {\n+        for (RexNode i : operands) {\n+          patternList.addAll(getCEPPatternFromPattern(upStreamSchema, i, patternDefs));\n+        }\n+      }\n+    }\n+    return patternList;\n+  }\n+\n+  /** Recursively construct a regular expression from a {@code RexNode}. */\n+  public static String getRegexFromPattern(RexNode call) {\n+    if (call.getClass() == RexLiteral.class) {\n+      return ((RexLiteral) call).getValueAs(String.class);\n+    } else {\n+      RexCall opr = (RexCall) call;\n+      SqlOperator operator = opr.getOperator();\n+      List<RexNode> operands = opr.getOperands();\n+      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n+        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n+        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n+        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n+        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n+        Quantifier quantifier = getQuantifier(start, end, isReluctant);\n+        return p + quantifier.toString();\n+      }\n+      return getRegexFromPattern(opr.getOperands().get(0))\n+          + getRegexFromPattern(opr.getOperands().get(1));\n+    }\n+  }\n+\n+  /** Transform a list of keys in Calcite to {@code ORDER BY} to {@code OrderKey}s. */\n+  public static ArrayList<OrderKey> makeOrderKeysFromCollation(RelCollation orderKeys) {\n+    List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+    Collections.reverse(revOrderKeys);", "originalCommit": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzk2NjgxMQ==", "url": "https://github.com/apache/beam/pull/12232#discussion_r463966811", "bodyText": "The thing is, for the order clause, the leftmost (the beginning) key is the most significant. I think the right way to sort should be starting from the least significant key to the most significant key. That is why I wanted to reverse the array.", "author": "Mark-Zeng", "createdAt": "2020-08-01T14:24:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDMzODcwMA==", "url": "https://github.com/apache/beam/pull/12232#discussion_r464338700", "bodyText": "I have changed this part as well. I think reversing the order could be confusing. I moved it into the SortKey transform.", "author": "Mark-Zeng", "createdAt": "2020-08-03T10:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzM3NA=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPUtil.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPUtil.java\ndeleted file mode 100644\nindex 9d073c897c..0000000000\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPUtil.java\n+++ /dev/null\n\n@@ -1,155 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.sdk.extensions.sql.impl.cep;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Map;\n-import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlKind;\n-import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n-\n-/**\n- * Some utility methods for transforming Calcite's constructs into our own Beam constructs (for\n- * serialization purpose).\n- */\n-public class CEPUtil {\n-\n-  private static Quantifier getQuantifier(int start, int end, boolean isReluctant) {\n-    Quantifier quantToAdd;\n-    if (!isReluctant) {\n-      if (start == end) {\n-        quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n-      } else {\n-        if (end == -1) {\n-          if (start == 0) {\n-            quantToAdd = Quantifier.ASTERISK;\n-          } else if (start == 1) {\n-            quantToAdd = Quantifier.PLUS;\n-          } else {\n-            quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n-          }\n-        } else {\n-          if (start == 0 && end == 1) {\n-            quantToAdd = Quantifier.QMARK;\n-          } else if (start == -1) {\n-            quantToAdd = new Quantifier(\"{ , \" + end + \" }\");\n-          } else {\n-            quantToAdd = new Quantifier(\"{ \" + start + \" , }\");\n-          }\n-        }\n-      }\n-    } else {\n-      if (start == end) {\n-        quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n-      } else {\n-        if (end == -1) {\n-          if (start == 0) {\n-            quantToAdd = Quantifier.ASTERISK_RELUCTANT;\n-          } else if (start == 1) {\n-            quantToAdd = Quantifier.PLUS_RELUCTANT;\n-          } else {\n-            quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n-          }\n-        } else {\n-          if (start == 0 && end == 1) {\n-            quantToAdd = Quantifier.QMARK_RELUCTANT;\n-          } else if (start == -1) {\n-            quantToAdd = new Quantifier(\"{ , \" + end + \" }?\");\n-          } else {\n-            quantToAdd = new Quantifier(\"{ \" + start + \" , }?\");\n-          }\n-        }\n-      }\n-    }\n-\n-    return quantToAdd;\n-  }\n-\n-  /** Construct a list of {@code CEPPattern}s from a {@code RexNode}. */\n-  public static ArrayList<CEPPattern> getCEPPatternFromPattern(\n-      Schema upStreamSchema, RexNode call, Map<String, RexNode> patternDefs) {\n-    ArrayList<CEPPattern> patternList = new ArrayList<>();\n-    if (call.getClass() == RexLiteral.class) {\n-      String p = ((RexLiteral) call).getValueAs(String.class);\n-      RexNode pd = patternDefs.get(p);\n-      patternList.add(CEPPattern.of(upStreamSchema, p, (RexCall) pd, Quantifier.NONE));\n-    } else {\n-      RexCall patCall = (RexCall) call;\n-      SqlOperator operator = patCall.getOperator();\n-      List<RexNode> operands = patCall.getOperands();\n-\n-      // check if if the node has quantifier\n-      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n-        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n-        RexNode pd = patternDefs.get(p);\n-        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n-        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n-        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n-\n-        patternList.add(\n-            CEPPattern.of(upStreamSchema, p, (RexCall) pd, getQuantifier(start, end, isReluctant)));\n-      } else {\n-        for (RexNode i : operands) {\n-          patternList.addAll(getCEPPatternFromPattern(upStreamSchema, i, patternDefs));\n-        }\n-      }\n-    }\n-    return patternList;\n-  }\n-\n-  /** Recursively construct a regular expression from a {@code RexNode}. */\n-  public static String getRegexFromPattern(RexNode call) {\n-    if (call.getClass() == RexLiteral.class) {\n-      return ((RexLiteral) call).getValueAs(String.class);\n-    } else {\n-      RexCall opr = (RexCall) call;\n-      SqlOperator operator = opr.getOperator();\n-      List<RexNode> operands = opr.getOperands();\n-      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n-        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n-        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n-        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n-        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n-        Quantifier quantifier = getQuantifier(start, end, isReluctant);\n-        return p + quantifier.toString();\n-      }\n-      return getRegexFromPattern(opr.getOperands().get(0))\n-          + getRegexFromPattern(opr.getOperands().get(1));\n-    }\n-  }\n-\n-  /** Transform a list of keys in Calcite to {@code ORDER BY} to {@code OrderKey}s. */\n-  public static ArrayList<OrderKey> makeOrderKeysFromCollation(RelCollation orderKeys) {\n-    List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n-    Collections.reverse(revOrderKeys);\n-\n-    ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n-    for (RelFieldCollation i : revOrderKeys) {\n-      revOrderKeysList.add(OrderKey.of(i));\n-    }\n-\n-    return revOrderKeysList;\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNjM4Nw==", "url": "https://github.com/apache/beam/pull/12232#discussion_r464116387", "bodyText": "You can either remove this commented test, or leave it with @ignore(\"the reason to ignore this test\").", "author": "amaliujia", "createdAt": "2020-08-02T19:47:34Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n+\n+import org.apache.beam.sdk.extensions.sql.TestUtils;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for {@code BeamMatchRel}. */\n+public class BeamMatchRelTest {\n+\n+  @Rule public final TestPipeline pipeline = TestPipeline.create();\n+\n+  @Test\n+  public void matchLogicalPlanTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"ALL ROWS PER MATCH \"\n+            + \"PATTERN (A B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.STRING, \"name\",\n+                    Schema.FieldType.INT32, \"proctime\")\n+                .addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  @Test\n+  public void matchQuantifierTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\",\n+        TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"ALL ROWS PER MATCH \"\n+            + \"PATTERN (A+ B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.STRING, \"name\",\n+                    Schema.FieldType.INT32, \"proctime\")\n+                .addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  @Test\n+  public void matchMeasuresTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\",\n+        TestBoundedTable.of(schemaType)\n+            .addRows(\n+                1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4, 1, \"b\", 8, 1, \"a\", 7, 1, \"c\", 9, 2, \"a\",\n+                6, 2, \"b\", 10, 2, \"c\", 11, 5, \"a\", 0));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"MEASURES \"\n+            + \"LAST (A.proctime) AS atime, \"\n+            + \"B.proctime AS btime, \"\n+            + \"C.proctime AS ctime \"\n+            + \"PATTERN (A+ B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.INT32, \"T.atime\",\n+                    Schema.FieldType.INT32, \"T.btime\",\n+                    Schema.FieldType.INT32, \"T.ctime\")\n+                .addRows(1, 2, 3, 4, 1, 7, 8, 9, 2, 6, 10, 11)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  /*", "originalCommit": "f79922b3b4c1d3b2a88cea091ebb6257806b23aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDMzOTEyNw==", "url": "https://github.com/apache/beam/pull/12232#discussion_r464339127", "bodyText": "I will ignore it for now. This test is wrote for testing the NFA.", "author": "Mark-Zeng", "createdAt": "2020-08-03T10:51:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNjM4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4e56953a135e40bbb3415d05ec6d14bbab947927", "chunk": "diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java\ndeleted file mode 100644\nindex 2df29eb4d4..0000000000\n--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java\n+++ /dev/null\n\n@@ -1,234 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.sdk.extensions.sql.impl.rel;\n-\n-import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n-import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n-\n-import org.apache.beam.sdk.extensions.sql.TestUtils;\n-import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n-import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.sdk.testing.PAssert;\n-import org.apache.beam.sdk.testing.TestPipeline;\n-import org.apache.beam.sdk.values.PCollection;\n-import org.apache.beam.sdk.values.Row;\n-import org.junit.Rule;\n-import org.junit.Test;\n-\n-/** Test for {@code BeamMatchRel}. */\n-public class BeamMatchRelTest {\n-\n-  @Rule public final TestPipeline pipeline = TestPipeline.create();\n-\n-  @Test\n-  public void matchLogicalPlanTest() {\n-    Schema schemaType =\n-        Schema.builder()\n-            .addInt32Field(\"id\")\n-            .addStringField(\"name\")\n-            .addInt32Field(\"proctime\")\n-            .build();\n-\n-    registerTable(\n-        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n-\n-    String sql =\n-        \"SELECT * \"\n-            + \"FROM TestTable \"\n-            + \"MATCH_RECOGNIZE (\"\n-            + \"PARTITION BY id \"\n-            + \"ORDER BY proctime \"\n-            + \"ALL ROWS PER MATCH \"\n-            + \"PATTERN (A B C) \"\n-            + \"DEFINE \"\n-            + \"A AS name = 'a', \"\n-            + \"B AS name = 'b', \"\n-            + \"C AS name = 'c' \"\n-            + \") AS T\";\n-\n-    PCollection<Row> result = compilePipeline(sql, pipeline);\n-\n-    PAssert.that(result)\n-        .containsInAnyOrder(\n-            TestUtils.RowsBuilder.of(\n-                    Schema.FieldType.INT32, \"id\",\n-                    Schema.FieldType.STRING, \"name\",\n-                    Schema.FieldType.INT32, \"proctime\")\n-                .addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3)\n-                .getRows());\n-\n-    pipeline.run().waitUntilFinish();\n-  }\n-\n-  @Test\n-  public void matchQuantifierTest() {\n-    Schema schemaType =\n-        Schema.builder()\n-            .addInt32Field(\"id\")\n-            .addStringField(\"name\")\n-            .addInt32Field(\"proctime\")\n-            .build();\n-\n-    registerTable(\n-        \"TestTable\",\n-        TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4));\n-\n-    String sql =\n-        \"SELECT * \"\n-            + \"FROM TestTable \"\n-            + \"MATCH_RECOGNIZE (\"\n-            + \"PARTITION BY id \"\n-            + \"ORDER BY proctime \"\n-            + \"ALL ROWS PER MATCH \"\n-            + \"PATTERN (A+ B C) \"\n-            + \"DEFINE \"\n-            + \"A AS name = 'a', \"\n-            + \"B AS name = 'b', \"\n-            + \"C AS name = 'c' \"\n-            + \") AS T\";\n-\n-    PCollection<Row> result = compilePipeline(sql, pipeline);\n-\n-    PAssert.that(result)\n-        .containsInAnyOrder(\n-            TestUtils.RowsBuilder.of(\n-                    Schema.FieldType.INT32, \"id\",\n-                    Schema.FieldType.STRING, \"name\",\n-                    Schema.FieldType.INT32, \"proctime\")\n-                .addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4)\n-                .getRows());\n-\n-    pipeline.run().waitUntilFinish();\n-  }\n-\n-  @Test\n-  public void matchMeasuresTest() {\n-    Schema schemaType =\n-        Schema.builder()\n-            .addInt32Field(\"id\")\n-            .addStringField(\"name\")\n-            .addInt32Field(\"proctime\")\n-            .build();\n-\n-    registerTable(\n-        \"TestTable\",\n-        TestBoundedTable.of(schemaType)\n-            .addRows(\n-                1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4, 1, \"b\", 8, 1, \"a\", 7, 1, \"c\", 9, 2, \"a\",\n-                6, 2, \"b\", 10, 2, \"c\", 11, 5, \"a\", 0));\n-\n-    String sql =\n-        \"SELECT * \"\n-            + \"FROM TestTable \"\n-            + \"MATCH_RECOGNIZE (\"\n-            + \"PARTITION BY id \"\n-            + \"ORDER BY proctime \"\n-            + \"MEASURES \"\n-            + \"LAST (A.proctime) AS atime, \"\n-            + \"B.proctime AS btime, \"\n-            + \"C.proctime AS ctime \"\n-            + \"PATTERN (A+ B C) \"\n-            + \"DEFINE \"\n-            + \"A AS name = 'a', \"\n-            + \"B AS name = 'b', \"\n-            + \"C AS name = 'c' \"\n-            + \") AS T\";\n-\n-    PCollection<Row> result = compilePipeline(sql, pipeline);\n-\n-    PAssert.that(result)\n-        .containsInAnyOrder(\n-            TestUtils.RowsBuilder.of(\n-                    Schema.FieldType.INT32, \"id\",\n-                    Schema.FieldType.INT32, \"T.atime\",\n-                    Schema.FieldType.INT32, \"T.btime\",\n-                    Schema.FieldType.INT32, \"T.ctime\")\n-                .addRows(1, 2, 3, 4, 1, 7, 8, 9, 2, 6, 10, 11)\n-                .getRows());\n-\n-    pipeline.run().waitUntilFinish();\n-  }\n-\n-  /*\n-  @Test\n-  public void matchNFATest() {\n-    Schema schemaType =\n-        Schema.builder()\n-            .addStringField(\"Symbol\")\n-            .addDateTimeField(\"TradeDay\")\n-            .addInt32Field(\"Price\")\n-            .build();\n-\n-    registerTable(\n-        \"Ticker\", TestBoundedTable.of(schemaType).addRows(\n-            \"a\", \"2020-07-01\", 32, // 1st A\n-            \"a\", \"2020-06-01\", 34,\n-            \"a\", \"2020-07-02\", 31, // B\n-            \"a\", \"2020-08-30\", 30, // B\n-            \"a\", \"2020-08-31\", 35, // C\n-            \"a\", \"2020-10-01\", 28,\n-            \"a\", \"2020-10-15\", 30, // 2nd A\n-            \"a\", \"2020-11-01\", 22, // B\n-            \"a\", \"2020-11-08\", 29, // C\n-            \"a\", \"2020-12-10\", 30, // C\n-            \"b\", \"2020-12-01\", 22,\n-            \"c\", \"2020-05-16\", 27, // A\n-            \"c\", \"2020-09-14\", 26, // B\n-            \"c\", \"2020-10-13\", 30)); // C\n-\n-    // match `V` shapes in prices\n-    String sql =\n-        \"SELECT M.Symbol,\"\n-            + \" M.Matchno,\"\n-            + \" M.Startp,\"\n-            + \" M.Bottomp,\"\n-            + \" M.Endp,\"\n-            + \" M.Avgp\"\n-            + \"FROM Ticker \"\n-            + \"MATCH_RECOGNIZE (\"\n-              + \"PARTITION BY Symbol \"\n-              + \"ORDER BY Tradeday \"\n-              + \"MEASURES \"\n-              + \"MATCH_NUMBER() AS Matchno, \"\n-              + \"A.price AS Startp, \"\n-              + \"LAST (B.Price) AS Bottomp, \"\n-              + \"LAST (C.Price) AS ENDp, \"\n-              + \"AVG (U.Price) AS Avgp \"\n-              + \"AFTER MATCH SKIP PAST LAST ROW \"\n-              + \"PATTERN (A B+ C+) \"\n-              + \"SUBSET U = (A, B, C) \"\n-              + \"DEFINE \"\n-              + \"B AS B.Price < PREV (B.Price), \"\n-              + \"C AS C.Price > PREV (C.Price) \"\n-            + \") AS T\";\n-\n-    PCollection<Row> result = compilePipeline(sql, pipeline);\n-\n-    PAssert.that(result)\n-        .containsInAnyOrder(\n-            TestUtils.RowsBuilder.of(\n-                Schema.FieldType.INT32, \"id\",\n-                Schema.FieldType.STRING, \"name\",\n-                Schema.FieldType.INT32, \"proctime\")\n-                .addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3)\n-                .getRows());\n-\n-    pipeline.run().waitUntilFinish();\n-  }\n-  */\n-}\n"}}, {"oid": "4e56953a135e40bbb3415d05ec6d14bbab947927", "url": "https://github.com/apache/beam/commit/4e56953a135e40bbb3415d05ec6d14bbab947927", "message": "[BEAM-9543] built the basis for Match_Recog", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "72232fcdf157ab0a09d72d57603d1f348774a116", "url": "https://github.com/apache/beam/commit/72232fcdf157ab0a09d72d57603d1f348774a116", "message": "[BEAM-9543] built the basis for Match_Recog", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "064ada7257970bcb1d35530be1b88cb3830f242b", "url": "https://github.com/apache/beam/commit/064ada7257970bcb1d35530be1b88cb3830f242b", "message": "[BEAM-9543] implemented `partition by`", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "9cd1a82bec7b2f7c44aacfbd72f5f775bb58b650", "url": "https://github.com/apache/beam/commit/9cd1a82bec7b2f7c44aacfbd72f5f775bb58b650", "message": "[BEAM-9543] implemented `order by`", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "c07b8a89e6c54f699590d5b9e8242cb92de3c505", "url": "https://github.com/apache/beam/commit/c07b8a89e6c54f699590d5b9e8242cb92de3c505", "message": "[BEAM-9543] fixed `order by` coder issue", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "cdb7e9f120a21506a800f6f6840fb315c4b6524b", "url": "https://github.com/apache/beam/commit/cdb7e9f120a21506a800f6f6840fb315c4b6524b", "message": "[BEAM-9543] fixed `order by` coder issue", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "cc63e557faf36656c330f305b3924016fdad2151", "url": "https://github.com/apache/beam/commit/cc63e557faf36656c330f305b3924016fdad2151", "message": "[BEAM-9543] applied regex pattern match", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "b2b189dfdea88baf34849a17b203058f29212b00", "url": "https://github.com/apache/beam/commit/b2b189dfdea88baf34849a17b203058f29212b00", "message": "[BEAM-9543] applied regex pattern match", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "08abbab35e1ee71fe3c9b2b92aa049b945a92763", "url": "https://github.com/apache/beam/commit/08abbab35e1ee71fe3c9b2b92aa049b945a92763", "message": "[BEAM-9543] fixed sortKey serialization problem", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "03a33c6ea20b4bde3541d3acba742903cc03b24e", "url": "https://github.com/apache/beam/commit/03a33c6ea20b4bde3541d3acba742903cc03b24e", "message": "[BEAM-9543] fixed sortKey serialization problem", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "ec7c929c340ba38615145908249be24778ffc436", "url": "https://github.com/apache/beam/commit/ec7c929c340ba38615145908249be24778ffc436", "message": "[BEAM-9543] fixed serialization problem", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "f52d96fc33382fc9e46d3249a2600e2af9f67326", "url": "https://github.com/apache/beam/commit/f52d96fc33382fc9e46d3249a2600e2af9f67326", "message": "[BEAM-9543] recognized simple pattern", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "8d6ffcc213e30999fc495c119b68da4f62fad258", "url": "https://github.com/apache/beam/commit/8d6ffcc213e30999fc495c119b68da4f62fad258", "message": "[BEAM-9543] recognized simple pattern", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "a7d111f896f5f8e14f6211d01811a618b905ec32", "url": "https://github.com/apache/beam/commit/a7d111f896f5f8e14f6211d01811a618b905ec32", "message": "[BEAM-9543] fixed code style", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "f529b876a2c2e43d012c71b3a83ebd55eb16f4ff", "url": "https://github.com/apache/beam/commit/f529b876a2c2e43d012c71b3a83ebd55eb16f4ff", "message": "[BEAM-9543] supported regex quantifier", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "0bf24db5e75c0db715c6954b11afac357c49d7f6", "url": "https://github.com/apache/beam/commit/0bf24db5e75c0db715c6954b11afac357c49d7f6", "message": "[BEAM-9543] added javadoc", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "422cbe2b87a6f69b8efda0f6ec88baa973bd26c4", "url": "https://github.com/apache/beam/commit/422cbe2b87a6f69b8efda0f6ec88baa973bd26c4", "message": "[BEAM-9543] removed CEPTypeName.java", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "adc2354752ef48237020f3fa84d00ab65c2ead74", "url": "https://github.com/apache/beam/commit/adc2354752ef48237020f3fa84d00ab65c2ead74", "message": "[BEAM-9543] added Measures implementation (unfinished)", "committedDate": "2020-08-03T10:40:12Z", "type": "commit"}, {"oid": "ebc41a263dc07b305c190f0ded1ec86e90099ee7", "url": "https://github.com/apache/beam/commit/ebc41a263dc07b305c190f0ded1ec86e90099ee7", "message": "[BEAM-9543] added Measures implementation", "committedDate": "2020-08-03T10:40:13Z", "type": "commit"}, {"oid": "87935746647611aa139d664ebed10c8e638bb024", "url": "https://github.com/apache/beam/commit/87935746647611aa139d664ebed10c8e638bb024", "message": "[BEAM-9543] added Measures implementation", "committedDate": "2020-08-03T10:40:13Z", "type": "commit"}, {"oid": "040d1f41db568a00b1fef898bddfa690be21015e", "url": "https://github.com/apache/beam/commit/040d1f41db568a00b1fef898bddfa690be21015e", "message": "[BEAM-9543] fixed minor issues", "committedDate": "2020-08-03T10:40:13Z", "type": "commit"}, {"oid": "799491bbe96fdcefd6ca1cc0f974c202159c8a91", "url": "https://github.com/apache/beam/commit/799491bbe96fdcefd6ca1cc0f974c202159c8a91", "message": "[BEAM-9543] fixed minor style issues", "committedDate": "2020-08-03T10:40:13Z", "type": "commit"}, {"oid": "799491bbe96fdcefd6ca1cc0f974c202159c8a91", "url": "https://github.com/apache/beam/commit/799491bbe96fdcefd6ca1cc0f974c202159c8a91", "message": "[BEAM-9543] fixed minor style issues", "committedDate": "2020-08-03T10:40:13Z", "type": "forcePushed"}]}