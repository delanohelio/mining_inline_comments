{"pr_number": 10945, "pr_title": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "pr_createdAt": "2020-02-24T03:16:54Z", "pr_url": "https://github.com/apache/beam/pull/10945", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDI4NDIzNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r384284237", "bodyText": "It has sets the default managed memory size to 128MB for MiniCluster in https://issues.apache.org/jira/browse/FLINK-15763. Have set it to a large value when the master host is [local]. Appreciate for any suggestions on a better way to address this issue.", "author": "sunjincheng121", "createdAt": "2020-02-26T05:41:33Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -67,6 +69,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"2048m\"));", "originalCommit": "156c43747f81ee6b539af054769f54155ff039c4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "chunk": "diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\nindex d92cca6eac..9bbce78228 100644\n--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n\n@@ -69,7 +67,7 @@ public class FlinkExecutionEnvironments {\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n-      flinkConfiguration.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"2048m\"));\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");\n       flinkBatchEnv = ExecutionEnvironment.createLocalEnvironment(flinkConfiguration);\n     } else if (\"[collection]\".equals(flinkMasterHostPort)) {\n       flinkBatchEnv = new CollectionEnvironment();\n"}}, {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "url": "https://github.com/apache/beam/commit/82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "message": "fixup! [BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-02-27T03:51:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg==", "url": "https://github.com/apache/beam/pull/10945#discussion_r385577426", "bodyText": "This cannot be removed yet. The feature is only present in 1.8.", "author": "mxm", "createdAt": "2020-02-28T09:01:17Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -311,78 +302,4 @@ private static void applyLatencyTrackingInterval(\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n-\n-  /**\n-   * Remote stream environment that supports job execution with restore from savepoint.\n-   *\n-   * <p>This class can be removed once Flink provides this functionality.\n-   *\n-   * <p>TODO: https://issues.apache.org/jira/browse/BEAM-5396\n-   */\n-  private static class BeamFlinkRemoteStreamEnvironment extends RemoteStreamEnvironment {", "originalCommit": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwMjg0MA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r386002840", "bodyText": "BeamFlinkRemoteStreamEnvironment has not been removed. Actually it has been moved to runner 1.7. The reason is that in 1.10 we don't need it any more. What do you think?", "author": "sunjincheng121", "createdAt": "2020-02-29T05:20:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MzA4Nw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389763087", "bodyText": "I didn't see that. In this case \ud83d\udc4d", "author": "mxm", "createdAt": "2020-03-09T15:22:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}], "type": "inlineReview", "revised_code": {"commit": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "chunk": "diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\nindex 9bbce78228..6de289eb54 100644\n--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n\n@@ -302,4 +305,13 @@ public class FlinkExecutionEnvironments {\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n+\n+  private static void setManagedMemoryByFraction(final Configuration config) {\n+    if (!config.containsKey(\"taskmanager.memory.managed.size\")) {\n+      float managedMemoryFraction = config.getFloat(TaskManagerOptions.MANAGED_MEMORY_FRACTION);\n+      long freeHeapMemory = EnvironmentInformation.getSizeOfFreeHeapMemoryWithDefrag();\n+      long managedMemorySize = (long) (freeHeapMemory * managedMemoryFraction);\n+      config.setString(\"taskmanager.memory.managed.size\", String.valueOf(managedMemorySize));\n+    }\n+  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3ODU5NA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r385578594", "bodyText": "No need to copy everything because of one change package name. We can load JobStatus dynamically.", "author": "mxm", "createdAt": "2020-02-28T09:04:12Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/**\n+ * End-to-end submission test of Beam jobs on a Flink cluster.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the package name of JobStatus has changed in Flink\n+ * 1.10, please refer to", "originalCommit": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3657ca43c6d58172083c9b980f1d42cbba1cd95a", "chunk": "diff --git a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java b/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\ndeleted file mode 100644\nindex 2a99f28e35..0000000000\n--- a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\n+++ /dev/null\n\n@@ -1,256 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.is;\n-\n-import java.io.File;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.nio.file.Files;\n-import java.security.Permission;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.beam.runners.core.construction.resources.PipelineResources;\n-import org.apache.beam.sdk.Pipeline;\n-import org.apache.beam.sdk.io.GenerateSequence;\n-import org.apache.beam.sdk.options.PipelineOptions;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n-import org.apache.flink.api.common.JobStatus;\n-import org.apache.flink.client.cli.CliFrontend;\n-import org.apache.flink.configuration.ConfigConstants;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.JobManagerOptions;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.client.JobStatusMessage;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.Timeout;\n-\n-/**\n- * End-to-end submission test of Beam jobs on a Flink cluster.\n- *\n- * <p>This test is copied to 1.10 is becauses the package name of JobStatus has changed in Flink\n- * 1.10, please refer to\n- * https://github.com/apache/flink/commit/f3df25d7f295d65a425136141da8c8af6c944c4f for more details.\n- */\n-public class FlinkSubmissionTest {\n-\n-  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n-  private static final Map<String, String> ENV = System.getenv();\n-  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n-\n-  /** Flink cluster that runs over the lifespan of the tests. */\n-  private static transient RemoteMiniCluster flinkCluster;\n-\n-  /** Each test has a timeout of 60 seconds (for safety). */\n-  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n-\n-  /** Whether to run in streaming or batch translation mode. */\n-  private static boolean streaming;\n-\n-  /** Counter which keeps track of the number of jobs submitted. */\n-  private static int expectedNumberOfJobs;\n-\n-  @BeforeClass\n-  public static void beforeClass() throws Exception {\n-    Configuration config = new Configuration();\n-    // Avoid port collision in parallel tests on the same machine\n-    config.setInteger(RestOptions.PORT.key(), 0);\n-\n-    MiniClusterConfiguration clusterConfig =\n-        new MiniClusterConfiguration.Builder()\n-            .setConfiguration(config)\n-            .setNumTaskManagers(1)\n-            .setNumSlotsPerTaskManager(1)\n-            // Create a shared actor system for all cluster services\n-            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n-            .build();\n-\n-    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n-    flinkCluster.start();\n-    prepareEnvironment();\n-  }\n-\n-  @AfterClass\n-  public static void afterClass() throws Exception {\n-    restoreEnvironment();\n-    flinkCluster.close();\n-    flinkCluster = null;\n-  }\n-\n-  @Test\n-  public void testSubmissionBatch() throws Exception {\n-    runSubmission(false, false);\n-  }\n-\n-  @Test\n-  public void testSubmissionStreaming() throws Exception {\n-    runSubmission(false, true);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmissionBatch() throws Exception {\n-    runSubmission(true, false);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmissionStreaming() throws Exception {\n-    runSubmission(true, true);\n-  }\n-\n-  private void runSubmission(boolean isDetached, boolean isStreaming) throws Exception {\n-    PipelineOptions options = PipelineOptionsFactory.create();\n-    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n-    String jarPath =\n-        Iterables.getFirst(\n-            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n-            null);\n-\n-    try {\n-      throwExceptionOnSystemExit();\n-      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n-      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n-      if (isDetached) {\n-        argsBuilder.add(\"-d\");\n-      }\n-      argsBuilder.add(jarPath);\n-\n-      FlinkSubmissionTest.streaming = isStreaming;\n-      FlinkSubmissionTest.expectedNumberOfJobs++;\n-      // Run end-to-end test\n-      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n-    } catch (SystemExitException e) {\n-      // The CliFrontend exited and we can move on to check if the job has finished\n-    } finally {\n-      restoreDefaultSystemExitBehavior();\n-    }\n-\n-    waitUntilJobIsCompleted();\n-  }\n-\n-  /** The Flink program which is executed by the CliFrontend. */\n-  public static void main(String[] args) {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setStreaming(streaming);\n-    if (streaming) {\n-      options.setShutdownSourcesOnFinalWatermark(true);\n-    }\n-    options.setParallelism(1);\n-    Pipeline p = Pipeline.create(options);\n-    p.apply(GenerateSequence.from(0).to(1));\n-    p.run();\n-  }\n-\n-  private static void prepareEnvironment() throws Exception {\n-    // Write a Flink config\n-    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n-    String config =\n-        String.format(\n-            \"%s: %s\\n%s: %s\\n%s: %s\",\n-            JobManagerOptions.ADDRESS.key(),\n-            \"localhost\",\n-            JobManagerOptions.PORT.key(),\n-            flinkCluster.getClusterPort(),\n-            RestOptions.PORT.key(),\n-            flinkCluster.getRestPort());\n-    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n-\n-    // Create a new environment with the location of the Flink config for CliFrontend\n-    ImmutableMap<String, String> newEnv =\n-        ImmutableMap.<String, String>builder()\n-            .putAll(ENV.entrySet())\n-            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n-            .build();\n-\n-    modifyEnv(newEnv);\n-  }\n-\n-  private static void restoreEnvironment() throws Exception {\n-    modifyEnv(ENV);\n-  }\n-\n-  /**\n-   * We modify the JVM's environment variables here. This is necessary for the end-to-end test\n-   * because Flink's CliFrontend requires a Flink configuration file for which the location can only\n-   * be set using the {@code ConfigConstants.ENV_FLINK_CONF_DIR} environment variable.\n-   */\n-  private static void modifyEnv(Map<String, String> env) throws Exception {\n-    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n-    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n-\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n-\n-    envField.setAccessible(true);\n-    envField.set(null, env);\n-    envField.setAccessible(false);\n-\n-    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n-    modifiersField.setAccessible(false);\n-  }\n-\n-  private void waitUntilJobIsCompleted() throws Exception {\n-    while (true) {\n-      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n-      assertThat(\n-          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n-      if (allJobsStates.stream()\n-          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n-        return;\n-      }\n-      Thread.sleep(50);\n-    }\n-  }\n-\n-  /** Prevents the CliFrontend from calling System.exit. */\n-  private static void throwExceptionOnSystemExit() {\n-    System.setSecurityManager(\n-        new SecurityManager() {\n-          @Override\n-          public void checkPermission(Permission permission) {\n-            if (permission.getName().startsWith(\"exitVM\")) {\n-              throw new SystemExitException();\n-            }\n-            if (SECURITY_MANAGER != null) {\n-              SECURITY_MANAGER.checkPermission(permission);\n-            }\n-          }\n-        });\n-  }\n-\n-  private static void restoreDefaultSystemExitBehavior() {\n-    System.setSecurityManager(SECURITY_MANAGER);\n-  }\n-\n-  private static class SystemExitException extends SecurityException {}\n-}\n"}}, {"oid": "3657ca43c6d58172083c9b980f1d42cbba1cd95a", "url": "https://github.com/apache/beam/commit/3657ca43c6d58172083c9b980f1d42cbba1cd95a", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-02-29T05:18:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTAzOA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761038", "bodyText": "We could avoid duplication of this file and just have a check method which branches depending on whether we have 1.10 or a version below.", "author": "mxm", "createdAt": "2020-03-09T15:20:04Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.util.Collections;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.LocalEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;\n+import org.apache.flink.streaming.api.environment.LocalStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+import org.junit.rules.TemporaryFolder;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkExecutionEnvironments}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field host, port, etc have been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+public class FlinkExecutionEnvironmentsTest {\n+\n+  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+  @Rule public ExpectedException expectedException = ExpectedException.none();\n+\n+  @Test\n+  public void shouldSetParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(bev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(sev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetMaxParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setMaxParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getMaxParallelism(), is(42));\n+    assertThat(sev.getMaxParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentBatch() throws IOException {\n+    String flinkConfDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList(), flinkConfDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(bev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentStreaming() throws IOException {\n+    String confDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList(), confDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(sev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(bev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(sev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(LocalEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(bev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(LocalStreamEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(sev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    ExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    ExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    StreamExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createBatchExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createStreamExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldRemoveHttpProtocolFromHostBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    for (String flinkMaster :\n+        new String[] {\n+          \"http://host:1234\", \" http://host:1234\", \"https://host:1234\", \" https://host:1234\"\n+        }) {\n+      options.setFlinkMaster(flinkMaster);\n+      ExecutionEnvironment sev =\n+          FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+              options, Collections.emptyList());\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getString(RestOptions.ADDRESS),\n+          is(\"host\"));\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getInteger(RestOptions.PORT),\n+          is(1234));", "originalCommit": "7d87a6db4e71b753693058ac8010c04b8f78ab2e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "chunk": "diff --git a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java b/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\ndeleted file mode 100644\nindex 79766901de..0000000000\n--- a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\n+++ /dev/null\n\n@@ -1,533 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.instanceOf;\n-import static org.hamcrest.core.Is.is;\n-import static org.junit.Assert.assertEquals;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.io.InputStream;\n-import java.nio.file.Files;\n-import java.util.Collections;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.flink.api.java.ExecutionEnvironment;\n-import org.apache.flink.api.java.LocalEnvironment;\n-import org.apache.flink.api.java.RemoteEnvironment;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;\n-import org.apache.flink.streaming.api.environment.LocalStreamEnvironment;\n-import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n-import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.ExpectedException;\n-import org.junit.rules.TemporaryFolder;\n-import org.powermock.reflect.Whitebox;\n-\n-/**\n- * Tests for {@link FlinkExecutionEnvironments}.\n- *\n- * <p>This test is copied to 1.10 is becauses the field host, port, etc have been removed from\n- * RemoteEnvironment in Flink 1.10, please refer to\n- * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n- */\n-public class FlinkExecutionEnvironmentsTest {\n-\n-  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n-  @Rule public ExpectedException expectedException = ExpectedException.none();\n-\n-  @Test\n-  public void shouldSetParallelismBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setParallelism(42);\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(options.getParallelism(), is(42));\n-    assertThat(bev.getParallelism(), is(42));\n-  }\n-\n-  @Test\n-  public void shouldSetParallelismStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setParallelism(42);\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(options.getParallelism(), is(42));\n-    assertThat(sev.getParallelism(), is(42));\n-  }\n-\n-  @Test\n-  public void shouldSetMaxParallelismStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setMaxParallelism(42);\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(options.getMaxParallelism(), is(42));\n-    assertThat(sev.getMaxParallelism(), is(42));\n-  }\n-\n-  @Test\n-  public void shouldInferParallelismFromEnvironmentBatch() throws IOException {\n-    String flinkConfDir = extractFlinkConfig();\n-\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setFlinkMaster(\"host:80\");\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList(), flinkConfDir);\n-\n-    assertThat(options.getParallelism(), is(23));\n-    assertThat(bev.getParallelism(), is(23));\n-  }\n-\n-  @Test\n-  public void shouldInferParallelismFromEnvironmentStreaming() throws IOException {\n-    String confDir = extractFlinkConfig();\n-\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setFlinkMaster(\"host:80\");\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList(), confDir);\n-\n-    assertThat(options.getParallelism(), is(23));\n-    assertThat(sev.getParallelism(), is(23));\n-  }\n-\n-  @Test\n-  public void shouldFallbackToDefaultParallelismBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setFlinkMaster(\"host:80\");\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(options.getParallelism(), is(1));\n-    assertThat(bev.getParallelism(), is(1));\n-  }\n-\n-  @Test\n-  public void shouldFallbackToDefaultParallelismStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setFlinkMaster(\"host:80\");\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(options.getParallelism(), is(1));\n-    assertThat(sev.getParallelism(), is(1));\n-  }\n-\n-  @Test\n-  public void useDefaultParallelismFromContextBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(bev, instanceOf(LocalEnvironment.class));\n-    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n-    assertThat(bev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n-  }\n-\n-  @Test\n-  public void useDefaultParallelismFromContextStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(sev, instanceOf(LocalStreamEnvironment.class));\n-    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n-    assertThat(sev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n-  }\n-\n-  @Test\n-  public void shouldParsePortForRemoteEnvironmentBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host:1234\");\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(bev, instanceOf(RemoteEnvironment.class));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"host\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-  }\n-\n-  @Test\n-  public void shouldParsePortForRemoteEnvironmentStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host:1234\");\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"host\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-  }\n-\n-  @Test\n-  public void shouldAllowPortOmissionForRemoteEnvironmentBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host\");\n-\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(bev, instanceOf(RemoteEnvironment.class));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"host\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldAllowPortOmissionForRemoteEnvironmentStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host\");\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"host\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldTreatAutoAndEmptyHostTheSameBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    ExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    options.setFlinkMaster(\"[auto]\");\n-\n-    ExecutionEnvironment sev2 =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertEquals(sev.getClass(), sev2.getClass());\n-  }\n-\n-  @Test\n-  public void shouldTreatAutoAndEmptyHostTheSameStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    options.setFlinkMaster(\"[auto]\");\n-\n-    StreamExecutionEnvironment sev2 =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-\n-    assertEquals(sev.getClass(), sev2.getClass());\n-  }\n-\n-  @Test\n-  public void shouldDetectMalformedPortBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host:p0rt\");\n-\n-    expectedException.expect(IllegalArgumentException.class);\n-    expectedException.expectMessage(\"Unparseable port number\");\n-\n-    FlinkExecutionEnvironments.createBatchExecutionEnvironment(options, Collections.emptyList());\n-  }\n-\n-  @Test\n-  public void shouldDetectMalformedPortStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setFlinkMaster(\"host:p0rt\");\n-\n-    expectedException.expect(IllegalArgumentException.class);\n-    expectedException.expectMessage(\"Unparseable port number\");\n-\n-    FlinkExecutionEnvironments.createStreamExecutionEnvironment(options, Collections.emptyList());\n-  }\n-\n-  @Test\n-  public void shouldSupportIPv4Batch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    options.setFlinkMaster(\"192.168.1.1:1234\");\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"192.168.1.1\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-\n-    options.setFlinkMaster(\"192.168.1.1\");\n-    bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"192.168.1.1\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldSupportIPv4Streaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    options.setFlinkMaster(\"192.168.1.1:1234\");\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"192.168.1.1\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-\n-    options.setFlinkMaster(\"192.168.1.1\");\n-    bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"192.168.1.1\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldSupportIPv6Batch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n-    ExecutionEnvironment bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-\n-    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n-    bev =\n-        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldSupportIPv6Streaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(1234));\n-\n-    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n-    sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getString(RestOptions.ADDRESS),\n-        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getInteger(RestOptions.PORT),\n-        is(RestOptions.PORT.defaultValue()));\n-  }\n-\n-  @Test\n-  public void shouldRemoveHttpProtocolFromHostBatch() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    for (String flinkMaster :\n-        new String[] {\n-          \"http://host:1234\", \" http://host:1234\", \"https://host:1234\", \" https://host:1234\"\n-        }) {\n-      options.setFlinkMaster(flinkMaster);\n-      ExecutionEnvironment sev =\n-          FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n-              options, Collections.emptyList());\n-      assertThat(\n-          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-              .getString(RestOptions.ADDRESS),\n-          is(\"host\"));\n-      assertThat(\n-          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-              .getInteger(RestOptions.PORT),\n-          is(1234));\n-    }\n-  }\n-\n-  @Test\n-  public void shouldRemoveHttpProtocolFromHostStreaming() {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-\n-    for (String flinkMaster :\n-        new String[] {\n-          \"http://host:1234\", \" http://host:1234\", \"https://host:1234\", \" https://host:1234\"\n-        }) {\n-      options.setFlinkMaster(flinkMaster);\n-      StreamExecutionEnvironment sev =\n-          FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-              options, Collections.emptyList());\n-      assertThat(\n-          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-              .getString(RestOptions.ADDRESS),\n-          is(\"host\"));\n-      assertThat(\n-          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-              .getInteger(RestOptions.PORT),\n-          is(1234));\n-    }\n-  }\n-\n-  private String extractFlinkConfig() throws IOException {\n-    InputStream inputStream = getClass().getResourceAsStream(\"/flink-conf.yaml\");\n-    File root = temporaryFolder.getRoot();\n-    Files.copy(inputStream, new File(root, \"flink-conf.yaml\").toPath());\n-    return root.getAbsolutePath();\n-  }\n-\n-  @Test\n-  public void shouldSetSavepointRestoreForRemoteStreaming() {\n-    String path = \"fakePath\";\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(TestFlinkRunner.class);\n-    options.setFlinkMaster(\"host:80\");\n-    options.setSavepointPath(path);\n-\n-    StreamExecutionEnvironment sev =\n-        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n-            options, Collections.emptyList());\n-    // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n-    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n-            .getString(SavepointConfigOptions.SAVEPOINT_PATH),\n-        is(path));\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTcxNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761717", "bodyText": "We could avoid duplicating this file if we had a Flink 1.10 dependent branching here.", "author": "mxm", "createdAt": "2020-03-09T15:20:59Z", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -0,0 +1,441 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.apache.beam.sdk.testing.RegexMatcher.matches;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.CoreMatchers.instanceOf;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.CoreMatchers.startsWith;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasItem;\n+import static org.hamcrest.core.Every.everyItem;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.fail;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.Serializable;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.beam.runners.core.construction.PTransformMatchers;\n+import org.apache.beam.runners.core.construction.PTransformTranslation;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.io.TextIO;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.sdk.runners.PTransformOverride;\n+import org.apache.beam.sdk.runners.PTransformOverrideFactory;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.windowing.FixedWindows;\n+import org.apache.beam.sdk.transforms.windowing.Window;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.client.cli.ExecutionConfigAccessor;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.hamcrest.BaseMatcher;\n+import org.hamcrest.Description;\n+import org.hamcrest.Matchers;\n+import org.joda.time.Duration;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkPipelineExecutionEnvironment}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field jarFiles has been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+@RunWith(JUnit4.class)\n+public class FlinkPipelineExecutionEnvironmentTest implements Serializable {\n+\n+  @Rule public transient TemporaryFolder tmpFolder = new TemporaryFolder();\n+\n+  @Test\n+  public void shouldRecognizeAndTranslateStreamingPipeline() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+    Pipeline pipeline = Pipeline.create();\n+\n+    pipeline\n+        .apply(GenerateSequence.from(0).withRate(1, Duration.standardSeconds(1)))\n+        .apply(\n+            ParDo.of(\n+                new DoFn<Long, String>() {\n+\n+                  @ProcessElement\n+                  public void processElement(ProcessContext c) throws Exception {\n+                    c.output(Long.toString(c.element()));\n+                  }\n+                }))\n+        .apply(Window.into(FixedWindows.of(Duration.standardHours(1))))\n+        .apply(TextIO.write().withNumShards(1).withWindowedWrites().to(\"/dummy/path\"));\n+\n+    flinkEnv.translate(pipeline);\n+\n+    // no exception should be thrown\n+  }\n+\n+  @Test\n+  public void shouldPrepareFilesToStageWhenFlinkMasterIsSetExplicitly() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"localhost:8081\", true, false);\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage().get(0), matches(\".*\\\\.jar\"));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenFileDoesNotExistAndFlinkMasterIsSetExplicitly() {\n+    assertThrows(\n+        \"To-be-staged file does not exist: \",\n+        IllegalStateException.class,\n+        () -> testPreparingResourcesToStage(\"localhost:8081\", true, true));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToAuto() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[auto]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStagewhenFlinkMasterIsSetToCollection() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[collection]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToLocal() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[local]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldUseDefaultTempLocationIfNoneSet() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    String defaultTmpDir = System.getProperty(\"java.io.tmpdir\");\n+\n+    assertThat(options.getFilesToStage(), hasItem(startsWith(defaultTmpDir)));\n+  }\n+\n+  @Test\n+  public void shouldUsePreparedFilesOnRemoteEnvironment() throws Exception {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    ExecutionEnvironment executionEnvironment = flinkEnv.getBatchExecutionEnvironment();\n+    assertThat(executionEnvironment, instanceOf(RemoteEnvironment.class));\n+\n+    ExecutionConfigAccessor accesor =\n+        ExecutionConfigAccessor.fromConfiguration(\n+            (Configuration) Whitebox.getInternalState(executionEnvironment, \"configuration\"));\n+    List<URL> jarFiles = accesor.getJars();", "originalCommit": "7d87a6db4e71b753693058ac8010c04b8f78ab2e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "chunk": "diff --git a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\nsimilarity index 94%\nrename from runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\nrename to runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\nindex ac84cb6d67..1d90d25661 100644\n--- a/runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\n+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\n\n@@ -34,6 +34,7 @@ import java.io.File;\n import java.io.IOException;\n import java.io.PrintStream;\n import java.io.Serializable;\n+import java.lang.reflect.Method;\n import java.net.MalformedURLException;\n import java.net.URL;\n import java.util.ArrayList;\n"}}, {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "url": "https://github.com/apache/beam/commit/1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-10T08:17:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390239907", "bodyText": "I have the feeling this won't be reliable enough. Why not instead taskmanager.memory.managed.fraction?", "author": "mxm", "createdAt": "2020-03-10T11:06:23Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI4NzYwNQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390287605", "bodyText": "It will set the taskmanager.memory.managed.size as 128MB for MiniCluster if it's not set. I think set taskmanager.memory.managed.fraction\" doesn't take effect here. Thoughts? :)", "author": "sunjincheng121", "createdAt": "2020-03-10T12:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDMyODYwNg==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390328606", "bodyText": "I'm hesitant with this default because it will always pre-allocate 2GB of memory which won't be used most of the time, except for the one large record test case you mentioned.\nWe could set I'd go for something like https://github.com/apache/flink/blob/42a56f4c75693773e21fa2dea45df640c2d7f9da/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/TaskExecutorProcessUtils.java#L287 based on the memory available.\nActually, that is what the Flink 1.8 code used to do: https://github.com/apache/flink/blob/60d9b96456f142f8d18d5882016840a00159403e/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerServices.java#L296\nSo let's just check the free memory and use a fraction for memory managed memory by default. What do you think?", "author": "mxm", "createdAt": "2020-03-10T13:53:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDc0NzUxMQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390747511", "bodyText": "Thanks @mxm, Sounds good to me ;)", "author": "sunjincheng121", "createdAt": "2020-03-11T05:03:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEyMjAxOA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r391122018", "bodyText": "Cool, thanks for the changes.", "author": "mxm", "createdAt": "2020-03-11T17:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}], "type": "inlineReview", "revised_code": {"commit": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "chunk": "diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\nindex 9bbce78228..6de289eb54 100644\n--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java\n\n@@ -67,7 +69,7 @@ public class FlinkExecutionEnvironments {\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n-      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");\n+      setManagedMemoryByFraction(flinkConfiguration);\n       flinkBatchEnv = ExecutionEnvironment.createLocalEnvironment(flinkConfiguration);\n     } else if (\"[collection]\".equals(flinkMasterHostPort)) {\n       flinkBatchEnv = new CollectionEnvironment();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDYxNA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240614", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:07:58Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\nindex 540d1c396e..4842ef986e 100644\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\n+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\n\n@@ -431,7 +432,7 @@ public class FlinkExecutionEnvironmentsTest {\n     try {\n       assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n       assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n-    } catch (Throwable t) {\n+    } catch (FieldNotFoundException t) {\n       // for flink 1.10+\n       String host =\n           ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDcyNQ==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240725", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:08:12Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {\n+      // for flink 1.10+\n+      String host =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getString(RestOptions.ADDRESS);\n+      int port =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getInteger(RestOptions.PORT);\n+      assertThat(\n+          new InetSocketAddress(host, port), is(new InetSocketAddress(expectedHost, expectedPort)));\n+    }\n+  }\n+\n+  private String getSavepointPath(Object env) {\n+    try {\n+      return ((SavepointRestoreSettings) Whitebox.getInternalState(env, \"restoreSettings\"))\n+          .getRestorePath();\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\nindex 540d1c396e..4842ef986e 100644\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\n+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java\n\n@@ -431,7 +432,7 @@ public class FlinkExecutionEnvironmentsTest {\n     try {\n       assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n       assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n-    } catch (Throwable t) {\n+    } catch (FieldNotFoundException t) {\n       // for flink 1.10+\n       String host =\n           ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MTE4OA==", "url": "https://github.com/apache/beam/pull/10945#discussion_r390241188", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "author": "mxm", "createdAt": "2020-03-10T11:09:10Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -418,4 +426,20 @@ private FlinkPipelineOptions setPipelineOptions(\n             })\n         .collect(Collectors.toList());\n   }\n+\n+  private List<URL> getJars(Object env) throws Exception {\n+    try {\n+      return (List<URL>) Whitebox.getInternalState(env, \"jarFiles\");\n+    } catch (Throwable t) {", "originalCommit": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\nindex 1d90d25661..37a49c1b9b 100644\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\n+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java\n\n@@ -430,7 +431,7 @@ public class FlinkPipelineExecutionEnvironmentTest implements Serializable {\n   private List<URL> getJars(Object env) throws Exception {\n     try {\n       return (List<URL>) Whitebox.getInternalState(env, \"jarFiles\");\n-    } catch (Throwable t) {\n+    } catch (FieldNotFoundException t) {\n       // for flink 1.10+\n       Configuration config = Whitebox.getInternalState(env, \"configuration\");\n       Class accesorClass = Class.forName(\"org.apache.flink.client.cli.ExecutionConfigAccessor\");\n"}}, {"oid": "4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "url": "https://github.com/apache/beam/commit/4cc537a76643d3c58b27ffb4af32bccba7a8bc6d", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-10T12:45:21Z", "type": "forcePushed"}, {"oid": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "url": "https://github.com/apache/beam/commit/f91b390c8bbab4afe14734c1266da51dcc7558c9", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-11T04:58:43Z", "type": "commit"}, {"oid": "f91b390c8bbab4afe14734c1266da51dcc7558c9", "url": "https://github.com/apache/beam/commit/f91b390c8bbab4afe14734c1266da51dcc7558c9", "message": "[BEAM-9295] Add Flink 1.10 build target and Make FlinkRunner compatible with Flink 1.10", "committedDate": "2020-03-11T04:58:43Z", "type": "forcePushed"}]}