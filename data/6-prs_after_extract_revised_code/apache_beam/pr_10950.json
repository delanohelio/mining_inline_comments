{"pr_number": 10950, "pr_title": "[BEAM-9345] Add end-to-end Flink job submission test", "pr_createdAt": "2020-02-24T17:34:34Z", "pr_url": "https://github.com/apache/beam/pull/10950", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3MDQ2Nw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383470467", "bodyText": "This method will return -1 if createRpcService has not been called. Maybe we should add an assertion here to prevent that.", "author": "ibzib", "createdAt": "2020-02-24T19:35:01Z", "path": "runners/flink/1.7/src/test/java/org/apache/beam/runners/flink/RemoteMiniClusterImpl.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import akka.actor.ActorSystem;\n+import com.typesafe.config.Config;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.akka.AkkaUtils;\n+import org.apache.flink.runtime.minicluster.MiniCluster;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.rpc.RpcService;\n+import org.apache.flink.runtime.rpc.akka.AkkaRpcService;\n+\n+/** A {@link MiniCluster} which allows remote connections for the end-to-end test. */\n+public class RemoteMiniClusterImpl extends RemoteMiniCluster {\n+\n+  private int port = -1;\n+\n+  public RemoteMiniClusterImpl(MiniClusterConfiguration miniClusterConfiguration) {\n+    super(miniClusterConfiguration);\n+  }\n+\n+  @Override\n+  protected RpcService createRpcService(\n+      Configuration configuration, Time askTimeout, boolean remoteEnabled, String bindAddress) {\n+\n+    // Enable remote connections to the mini cluster which are disabled by default\n+    final Config akkaConfig = AkkaUtils.getAkkaConfig(configuration, \"localhost\", 0);\n+\n+    final Config effectiveAkkaConfig = AkkaUtils.testDispatcherConfig().withFallback(akkaConfig);\n+\n+    final ActorSystem actorSystem = AkkaUtils.createActorSystem(effectiveAkkaConfig);\n+\n+    AkkaRpcService akkaRpcService = new AkkaRpcService(actorSystem, askTimeout);\n+    this.port = akkaRpcService.getPort();\n+\n+    return akkaRpcService;\n+  }\n+\n+  @Override\n+  public int getClusterPort() {\n+    return port;", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzIwMA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763200", "bodyText": "Yes, I was thinking the same but somehow missed this before opening the PR. Added the check now.", "author": "mxm", "createdAt": "2020-02-25T09:42:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3MDQ2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "chunk": "diff --git a/runners/flink/1.7/src/test/java/org/apache/beam/runners/flink/RemoteMiniClusterImpl.java b/runners/flink/1.7/src/test/java/org/apache/beam/runners/flink/RemoteMiniClusterImpl.java\ndeleted file mode 100644\nindex 921aefdc0f..0000000000\n--- a/runners/flink/1.7/src/test/java/org/apache/beam/runners/flink/RemoteMiniClusterImpl.java\n+++ /dev/null\n\n@@ -1,65 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import akka.actor.ActorSystem;\n-import com.typesafe.config.Config;\n-import org.apache.flink.api.common.time.Time;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.runtime.akka.AkkaUtils;\n-import org.apache.flink.runtime.minicluster.MiniCluster;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.rpc.RpcService;\n-import org.apache.flink.runtime.rpc.akka.AkkaRpcService;\n-\n-/** A {@link MiniCluster} which allows remote connections for the end-to-end test. */\n-public class RemoteMiniClusterImpl extends RemoteMiniCluster {\n-\n-  private int port = -1;\n-\n-  public RemoteMiniClusterImpl(MiniClusterConfiguration miniClusterConfiguration) {\n-    super(miniClusterConfiguration);\n-  }\n-\n-  @Override\n-  protected RpcService createRpcService(\n-      Configuration configuration, Time askTimeout, boolean remoteEnabled, String bindAddress) {\n-\n-    // Enable remote connections to the mini cluster which are disabled by default\n-    final Config akkaConfig = AkkaUtils.getAkkaConfig(configuration, \"localhost\", 0);\n-\n-    final Config effectiveAkkaConfig = AkkaUtils.testDispatcherConfig().withFallback(akkaConfig);\n-\n-    final ActorSystem actorSystem = AkkaUtils.createActorSystem(effectiveAkkaConfig);\n-\n-    AkkaRpcService akkaRpcService = new AkkaRpcService(actorSystem, askTimeout);\n-    this.port = akkaRpcService.getPort();\n-\n-    return akkaRpcService;\n-  }\n-\n-  @Override\n-  public int getClusterPort() {\n-    return port;\n-  }\n-\n-  @Override\n-  public int getRestPort() {\n-    return getRestAddress().getPort();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3NDMzNQ==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383474335", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  // The Clifrontend exited and we can move on to check if the job has finished\n          \n          \n            \n                  // The CliFrontend exited and we can move on to check if the job has finished", "author": "ibzib", "createdAt": "2020-02-24T19:42:29Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\ndeleted file mode 100644\nindex af34492f78..0000000000\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\n+++ /dev/null\n\n@@ -1,224 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.is;\n-\n-import java.io.File;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.nio.file.Files;\n-import java.security.Permission;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.beam.runners.core.construction.resources.PipelineResources;\n-import org.apache.beam.sdk.Pipeline;\n-import org.apache.beam.sdk.io.GenerateSequence;\n-import org.apache.beam.sdk.options.PipelineOptions;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n-import org.apache.flink.client.cli.CliFrontend;\n-import org.apache.flink.configuration.ConfigConstants;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.JobManagerOptions;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.client.JobStatusMessage;\n-import org.apache.flink.runtime.jobgraph.JobStatus;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.Timeout;\n-\n-/** End-to-end submission test of Beam jobs on a Flink cluster. */\n-public class FlinkSubmissionTest {\n-\n-  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n-  private static final Map<String, String> ENV = System.getenv();\n-  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n-\n-  /** Flink cluster that runs over the lifespan of the tests. */\n-  private static transient RemoteMiniCluster flinkCluster;\n-\n-  /** Each test has a timeout of 60 seconds (for safety). */\n-  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n-\n-  /** Counter which keeps track of the number of jobs submitted. */\n-  private static int expectedNumberOfJobs;\n-\n-  @BeforeClass\n-  public static void beforeClass() throws Exception {\n-    Configuration config = new Configuration();\n-    // Avoid port collision in parallel tests on the same machine\n-    config.setInteger(RestOptions.PORT.key(), 0);\n-\n-    MiniClusterConfiguration clusterConfig =\n-        new MiniClusterConfiguration.Builder()\n-            .setConfiguration(config)\n-            .setNumTaskManagers(1)\n-            .setNumSlotsPerTaskManager(1)\n-            // Create a shared actor system for all cluster services\n-            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n-            .build();\n-\n-    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n-    flinkCluster.start();\n-    prepareEnvironment();\n-  }\n-\n-  @AfterClass\n-  public static void afterClass() throws Exception {\n-    restoreEnvironment();\n-    flinkCluster.close();\n-    flinkCluster = null;\n-  }\n-\n-  @Test\n-  public void testSubmission() throws Exception {\n-    runSubmission(false);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmission() throws Exception {\n-    runSubmission(true);\n-  }\n-\n-  private void runSubmission(boolean detached) throws Exception {\n-    PipelineOptions options = PipelineOptionsFactory.create();\n-    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n-    String jarPath =\n-        Iterables.getFirst(\n-            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n-            null);\n-\n-    try {\n-      throwExceptionOnSystemExit();\n-      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n-      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n-      if (detached) {\n-        argsBuilder.add(\"-d\");\n-      }\n-      argsBuilder.add(jarPath);\n-\n-      expectedNumberOfJobs++;\n-      // Run end-to-end test\n-      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n-    } catch (SystemExitException e) {\n-      // The Clifrontend exited and we can move on to check if the job has finished\n-    } finally {\n-      restoreDefaultSystemExitBehavior();\n-    }\n-\n-    waitUntilJobIsCompleted();\n-  }\n-\n-  /** The Flink program which is executed by the CliFrontend. */\n-  public static void main(String[] args) {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setParallelism(1);\n-    Pipeline p = Pipeline.create(options);\n-    p.apply(GenerateSequence.from(0).to(1));\n-    p.run();\n-  }\n-\n-  private static void prepareEnvironment() throws Exception {\n-    // Write a Flink config\n-    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n-    String config =\n-        String.format(\n-            \"%s: %s\\n%s: %s\\n%s: %s\",\n-            JobManagerOptions.ADDRESS.key(),\n-            \"localhost\",\n-            JobManagerOptions.PORT.key(),\n-            flinkCluster.getClusterPort(),\n-            RestOptions.PORT.key(),\n-            flinkCluster.getRestPort());\n-    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n-\n-    // Create a new environment with the location of the Flink config for Clifrontend\n-    ImmutableMap<String, String> newEnv =\n-        ImmutableMap.<String, String>builder()\n-            .putAll(ENV.entrySet())\n-            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n-            .build();\n-\n-    modifyEnv(newEnv);\n-  }\n-\n-  private static void restoreEnvironment() throws Exception {\n-    modifyEnv(ENV);\n-  }\n-\n-  private static void modifyEnv(Map<String, String> env) throws Exception {\n-    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n-    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n-\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n-\n-    envField.setAccessible(true);\n-    envField.set(null, env);\n-    envField.setAccessible(false);\n-\n-    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n-    modifiersField.setAccessible(false);\n-  }\n-\n-  private void waitUntilJobIsCompleted() throws Exception {\n-    while (true) {\n-      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n-      assertThat(\n-          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n-      if (allJobsStates.stream()\n-          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n-        return;\n-      }\n-      Thread.sleep(50);\n-    }\n-  }\n-\n-  /** Prevents the CliFrontend from calling System.exit. */\n-  private static void throwExceptionOnSystemExit() {\n-    System.setSecurityManager(\n-        new SecurityManager() {\n-          @Override\n-          public void checkPermission(Permission permission) {\n-            if (permission.getName().startsWith(\"exitVM\")) {\n-              throw new SystemExitException();\n-            }\n-          }\n-        });\n-  }\n-\n-  private static void restoreDefaultSystemExitBehavior() {\n-    System.setSecurityManager(SECURITY_MANAGER);\n-  }\n-\n-  private static class SystemExitException extends SecurityException {}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3NDQ5Mw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383474493", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // Create a new environment with the location of the Flink config for Clifrontend\n          \n          \n            \n                // Create a new environment with the location of the Flink config for CliFrontend", "author": "ibzib", "createdAt": "2020-02-24T19:42:46Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\ndeleted file mode 100644\nindex af34492f78..0000000000\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\n+++ /dev/null\n\n@@ -1,224 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.is;\n-\n-import java.io.File;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.nio.file.Files;\n-import java.security.Permission;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.beam.runners.core.construction.resources.PipelineResources;\n-import org.apache.beam.sdk.Pipeline;\n-import org.apache.beam.sdk.io.GenerateSequence;\n-import org.apache.beam.sdk.options.PipelineOptions;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n-import org.apache.flink.client.cli.CliFrontend;\n-import org.apache.flink.configuration.ConfigConstants;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.JobManagerOptions;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.client.JobStatusMessage;\n-import org.apache.flink.runtime.jobgraph.JobStatus;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.Timeout;\n-\n-/** End-to-end submission test of Beam jobs on a Flink cluster. */\n-public class FlinkSubmissionTest {\n-\n-  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n-  private static final Map<String, String> ENV = System.getenv();\n-  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n-\n-  /** Flink cluster that runs over the lifespan of the tests. */\n-  private static transient RemoteMiniCluster flinkCluster;\n-\n-  /** Each test has a timeout of 60 seconds (for safety). */\n-  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n-\n-  /** Counter which keeps track of the number of jobs submitted. */\n-  private static int expectedNumberOfJobs;\n-\n-  @BeforeClass\n-  public static void beforeClass() throws Exception {\n-    Configuration config = new Configuration();\n-    // Avoid port collision in parallel tests on the same machine\n-    config.setInteger(RestOptions.PORT.key(), 0);\n-\n-    MiniClusterConfiguration clusterConfig =\n-        new MiniClusterConfiguration.Builder()\n-            .setConfiguration(config)\n-            .setNumTaskManagers(1)\n-            .setNumSlotsPerTaskManager(1)\n-            // Create a shared actor system for all cluster services\n-            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n-            .build();\n-\n-    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n-    flinkCluster.start();\n-    prepareEnvironment();\n-  }\n-\n-  @AfterClass\n-  public static void afterClass() throws Exception {\n-    restoreEnvironment();\n-    flinkCluster.close();\n-    flinkCluster = null;\n-  }\n-\n-  @Test\n-  public void testSubmission() throws Exception {\n-    runSubmission(false);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmission() throws Exception {\n-    runSubmission(true);\n-  }\n-\n-  private void runSubmission(boolean detached) throws Exception {\n-    PipelineOptions options = PipelineOptionsFactory.create();\n-    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n-    String jarPath =\n-        Iterables.getFirst(\n-            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n-            null);\n-\n-    try {\n-      throwExceptionOnSystemExit();\n-      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n-      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n-      if (detached) {\n-        argsBuilder.add(\"-d\");\n-      }\n-      argsBuilder.add(jarPath);\n-\n-      expectedNumberOfJobs++;\n-      // Run end-to-end test\n-      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n-    } catch (SystemExitException e) {\n-      // The Clifrontend exited and we can move on to check if the job has finished\n-    } finally {\n-      restoreDefaultSystemExitBehavior();\n-    }\n-\n-    waitUntilJobIsCompleted();\n-  }\n-\n-  /** The Flink program which is executed by the CliFrontend. */\n-  public static void main(String[] args) {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setParallelism(1);\n-    Pipeline p = Pipeline.create(options);\n-    p.apply(GenerateSequence.from(0).to(1));\n-    p.run();\n-  }\n-\n-  private static void prepareEnvironment() throws Exception {\n-    // Write a Flink config\n-    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n-    String config =\n-        String.format(\n-            \"%s: %s\\n%s: %s\\n%s: %s\",\n-            JobManagerOptions.ADDRESS.key(),\n-            \"localhost\",\n-            JobManagerOptions.PORT.key(),\n-            flinkCluster.getClusterPort(),\n-            RestOptions.PORT.key(),\n-            flinkCluster.getRestPort());\n-    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n-\n-    // Create a new environment with the location of the Flink config for Clifrontend\n-    ImmutableMap<String, String> newEnv =\n-        ImmutableMap.<String, String>builder()\n-            .putAll(ENV.entrySet())\n-            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n-            .build();\n-\n-    modifyEnv(newEnv);\n-  }\n-\n-  private static void restoreEnvironment() throws Exception {\n-    modifyEnv(ENV);\n-  }\n-\n-  private static void modifyEnv(Map<String, String> env) throws Exception {\n-    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n-    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n-\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n-\n-    envField.setAccessible(true);\n-    envField.set(null, env);\n-    envField.setAccessible(false);\n-\n-    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n-    modifiersField.setAccessible(false);\n-  }\n-\n-  private void waitUntilJobIsCompleted() throws Exception {\n-    while (true) {\n-      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n-      assertThat(\n-          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n-      if (allJobsStates.stream()\n-          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n-        return;\n-      }\n-      Thread.sleep(50);\n-    }\n-  }\n-\n-  /** Prevents the CliFrontend from calling System.exit. */\n-  private static void throwExceptionOnSystemExit() {\n-    System.setSecurityManager(\n-        new SecurityManager() {\n-          @Override\n-          public void checkPermission(Permission permission) {\n-            if (permission.getName().startsWith(\"exitVM\")) {\n-              throw new SystemExitException();\n-            }\n-          }\n-        });\n-  }\n-\n-  private static void restoreDefaultSystemExitBehavior() {\n-    System.setSecurityManager(SECURITY_MANAGER);\n-  }\n-\n-  private static class SystemExitException extends SecurityException {}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU3OA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383479578", "bodyText": "Instead of creating an all-new SecurityManager, should we instead wrap the original one? (Not sure if it actually matters.)", "author": "ibzib", "createdAt": "2020-02-24T19:52:41Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend\n+    ImmutableMap<String, String> newEnv =\n+        ImmutableMap.<String, String>builder()\n+            .putAll(ENV.entrySet())\n+            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n+            .build();\n+\n+    modifyEnv(newEnv);\n+  }\n+\n+  private static void restoreEnvironment() throws Exception {\n+    modifyEnv(ENV);\n+  }\n+\n+  private static void modifyEnv(Map<String, String> env) throws Exception {\n+    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n+    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n+\n+    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n+    modifiersField.setAccessible(true);\n+    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n+\n+    envField.setAccessible(true);\n+    envField.set(null, env);\n+    envField.setAccessible(false);\n+\n+    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n+    modifiersField.setAccessible(false);\n+  }\n+\n+  private void waitUntilJobIsCompleted() throws Exception {\n+    while (true) {\n+      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n+      assertThat(\n+          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n+      if (allJobsStates.stream()\n+          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n+        return;\n+      }\n+      Thread.sleep(50);\n+    }\n+  }\n+\n+  /** Prevents the CliFrontend from calling System.exit. */\n+  private static void throwExceptionOnSystemExit() {\n+    System.setSecurityManager(\n+        new SecurityManager() {", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzQ1MA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763450", "bodyText": "I don't think it matters for tests, but doesn't hurt either. Updated.", "author": "mxm", "createdAt": "2020-02-25T09:42:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU3OA=="}], "type": "inlineReview", "revised_code": {"commit": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\ndeleted file mode 100644\nindex af34492f78..0000000000\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\n+++ /dev/null\n\n@@ -1,224 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.is;\n-\n-import java.io.File;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.nio.file.Files;\n-import java.security.Permission;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.beam.runners.core.construction.resources.PipelineResources;\n-import org.apache.beam.sdk.Pipeline;\n-import org.apache.beam.sdk.io.GenerateSequence;\n-import org.apache.beam.sdk.options.PipelineOptions;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n-import org.apache.flink.client.cli.CliFrontend;\n-import org.apache.flink.configuration.ConfigConstants;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.JobManagerOptions;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.client.JobStatusMessage;\n-import org.apache.flink.runtime.jobgraph.JobStatus;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.Timeout;\n-\n-/** End-to-end submission test of Beam jobs on a Flink cluster. */\n-public class FlinkSubmissionTest {\n-\n-  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n-  private static final Map<String, String> ENV = System.getenv();\n-  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n-\n-  /** Flink cluster that runs over the lifespan of the tests. */\n-  private static transient RemoteMiniCluster flinkCluster;\n-\n-  /** Each test has a timeout of 60 seconds (for safety). */\n-  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n-\n-  /** Counter which keeps track of the number of jobs submitted. */\n-  private static int expectedNumberOfJobs;\n-\n-  @BeforeClass\n-  public static void beforeClass() throws Exception {\n-    Configuration config = new Configuration();\n-    // Avoid port collision in parallel tests on the same machine\n-    config.setInteger(RestOptions.PORT.key(), 0);\n-\n-    MiniClusterConfiguration clusterConfig =\n-        new MiniClusterConfiguration.Builder()\n-            .setConfiguration(config)\n-            .setNumTaskManagers(1)\n-            .setNumSlotsPerTaskManager(1)\n-            // Create a shared actor system for all cluster services\n-            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n-            .build();\n-\n-    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n-    flinkCluster.start();\n-    prepareEnvironment();\n-  }\n-\n-  @AfterClass\n-  public static void afterClass() throws Exception {\n-    restoreEnvironment();\n-    flinkCluster.close();\n-    flinkCluster = null;\n-  }\n-\n-  @Test\n-  public void testSubmission() throws Exception {\n-    runSubmission(false);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmission() throws Exception {\n-    runSubmission(true);\n-  }\n-\n-  private void runSubmission(boolean detached) throws Exception {\n-    PipelineOptions options = PipelineOptionsFactory.create();\n-    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n-    String jarPath =\n-        Iterables.getFirst(\n-            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n-            null);\n-\n-    try {\n-      throwExceptionOnSystemExit();\n-      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n-      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n-      if (detached) {\n-        argsBuilder.add(\"-d\");\n-      }\n-      argsBuilder.add(jarPath);\n-\n-      expectedNumberOfJobs++;\n-      // Run end-to-end test\n-      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n-    } catch (SystemExitException e) {\n-      // The Clifrontend exited and we can move on to check if the job has finished\n-    } finally {\n-      restoreDefaultSystemExitBehavior();\n-    }\n-\n-    waitUntilJobIsCompleted();\n-  }\n-\n-  /** The Flink program which is executed by the CliFrontend. */\n-  public static void main(String[] args) {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setParallelism(1);\n-    Pipeline p = Pipeline.create(options);\n-    p.apply(GenerateSequence.from(0).to(1));\n-    p.run();\n-  }\n-\n-  private static void prepareEnvironment() throws Exception {\n-    // Write a Flink config\n-    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n-    String config =\n-        String.format(\n-            \"%s: %s\\n%s: %s\\n%s: %s\",\n-            JobManagerOptions.ADDRESS.key(),\n-            \"localhost\",\n-            JobManagerOptions.PORT.key(),\n-            flinkCluster.getClusterPort(),\n-            RestOptions.PORT.key(),\n-            flinkCluster.getRestPort());\n-    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n-\n-    // Create a new environment with the location of the Flink config for Clifrontend\n-    ImmutableMap<String, String> newEnv =\n-        ImmutableMap.<String, String>builder()\n-            .putAll(ENV.entrySet())\n-            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n-            .build();\n-\n-    modifyEnv(newEnv);\n-  }\n-\n-  private static void restoreEnvironment() throws Exception {\n-    modifyEnv(ENV);\n-  }\n-\n-  private static void modifyEnv(Map<String, String> env) throws Exception {\n-    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n-    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n-\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n-\n-    envField.setAccessible(true);\n-    envField.set(null, env);\n-    envField.setAccessible(false);\n-\n-    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n-    modifiersField.setAccessible(false);\n-  }\n-\n-  private void waitUntilJobIsCompleted() throws Exception {\n-    while (true) {\n-      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n-      assertThat(\n-          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n-      if (allJobsStates.stream()\n-          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n-        return;\n-      }\n-      Thread.sleep(50);\n-    }\n-  }\n-\n-  /** Prevents the CliFrontend from calling System.exit. */\n-  private static void throwExceptionOnSystemExit() {\n-    System.setSecurityManager(\n-        new SecurityManager() {\n-          @Override\n-          public void checkPermission(Permission permission) {\n-            if (permission.getName().startsWith(\"exitVM\")) {\n-              throw new SystemExitException();\n-            }\n-          }\n-        });\n-  }\n-\n-  private static void restoreDefaultSystemExitBehavior() {\n-    System.setSecurityManager(SECURITY_MANAGER);\n-  }\n-\n-  private static class SystemExitException extends SecurityException {}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDAxMw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383480013", "bodyText": "Can you please add a comment saying why this is necessary?", "author": "ibzib", "createdAt": "2020-02-24T19:53:33Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend\n+    ImmutableMap<String, String> newEnv =\n+        ImmutableMap.<String, String>builder()\n+            .putAll(ENV.entrySet())\n+            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n+            .build();\n+\n+    modifyEnv(newEnv);\n+  }\n+\n+  private static void restoreEnvironment() throws Exception {\n+    modifyEnv(ENV);\n+  }\n+\n+  private static void modifyEnv(Map<String, String> env) throws Exception {", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzUwMA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763500", "bodyText": "+1", "author": "mxm", "createdAt": "2020-02-25T09:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDAxMw=="}], "type": "inlineReview", "revised_code": {"commit": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "chunk": "diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\ndeleted file mode 100644\nindex af34492f78..0000000000\n--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java\n+++ /dev/null\n\n@@ -1,224 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.beam.runners.flink;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.Matchers.is;\n-\n-import java.io.File;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.nio.file.Files;\n-import java.security.Permission;\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.beam.runners.core.construction.resources.PipelineResources;\n-import org.apache.beam.sdk.Pipeline;\n-import org.apache.beam.sdk.io.GenerateSequence;\n-import org.apache.beam.sdk.options.PipelineOptions;\n-import org.apache.beam.sdk.options.PipelineOptionsFactory;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n-import org.apache.flink.client.cli.CliFrontend;\n-import org.apache.flink.configuration.ConfigConstants;\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.configuration.JobManagerOptions;\n-import org.apache.flink.configuration.RestOptions;\n-import org.apache.flink.runtime.client.JobStatusMessage;\n-import org.apache.flink.runtime.jobgraph.JobStatus;\n-import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n-import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n-import org.junit.AfterClass;\n-import org.junit.BeforeClass;\n-import org.junit.ClassRule;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-import org.junit.rules.Timeout;\n-\n-/** End-to-end submission test of Beam jobs on a Flink cluster. */\n-public class FlinkSubmissionTest {\n-\n-  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n-  private static final Map<String, String> ENV = System.getenv();\n-  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n-\n-  /** Flink cluster that runs over the lifespan of the tests. */\n-  private static transient RemoteMiniCluster flinkCluster;\n-\n-  /** Each test has a timeout of 60 seconds (for safety). */\n-  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n-\n-  /** Counter which keeps track of the number of jobs submitted. */\n-  private static int expectedNumberOfJobs;\n-\n-  @BeforeClass\n-  public static void beforeClass() throws Exception {\n-    Configuration config = new Configuration();\n-    // Avoid port collision in parallel tests on the same machine\n-    config.setInteger(RestOptions.PORT.key(), 0);\n-\n-    MiniClusterConfiguration clusterConfig =\n-        new MiniClusterConfiguration.Builder()\n-            .setConfiguration(config)\n-            .setNumTaskManagers(1)\n-            .setNumSlotsPerTaskManager(1)\n-            // Create a shared actor system for all cluster services\n-            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n-            .build();\n-\n-    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n-    flinkCluster.start();\n-    prepareEnvironment();\n-  }\n-\n-  @AfterClass\n-  public static void afterClass() throws Exception {\n-    restoreEnvironment();\n-    flinkCluster.close();\n-    flinkCluster = null;\n-  }\n-\n-  @Test\n-  public void testSubmission() throws Exception {\n-    runSubmission(false);\n-  }\n-\n-  @Test\n-  public void testDetachedSubmission() throws Exception {\n-    runSubmission(true);\n-  }\n-\n-  private void runSubmission(boolean detached) throws Exception {\n-    PipelineOptions options = PipelineOptionsFactory.create();\n-    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n-    String jarPath =\n-        Iterables.getFirst(\n-            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n-            null);\n-\n-    try {\n-      throwExceptionOnSystemExit();\n-      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n-      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n-      if (detached) {\n-        argsBuilder.add(\"-d\");\n-      }\n-      argsBuilder.add(jarPath);\n-\n-      expectedNumberOfJobs++;\n-      // Run end-to-end test\n-      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n-    } catch (SystemExitException e) {\n-      // The Clifrontend exited and we can move on to check if the job has finished\n-    } finally {\n-      restoreDefaultSystemExitBehavior();\n-    }\n-\n-    waitUntilJobIsCompleted();\n-  }\n-\n-  /** The Flink program which is executed by the CliFrontend. */\n-  public static void main(String[] args) {\n-    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n-    options.setRunner(FlinkRunner.class);\n-    options.setParallelism(1);\n-    Pipeline p = Pipeline.create(options);\n-    p.apply(GenerateSequence.from(0).to(1));\n-    p.run();\n-  }\n-\n-  private static void prepareEnvironment() throws Exception {\n-    // Write a Flink config\n-    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n-    String config =\n-        String.format(\n-            \"%s: %s\\n%s: %s\\n%s: %s\",\n-            JobManagerOptions.ADDRESS.key(),\n-            \"localhost\",\n-            JobManagerOptions.PORT.key(),\n-            flinkCluster.getClusterPort(),\n-            RestOptions.PORT.key(),\n-            flinkCluster.getRestPort());\n-    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n-\n-    // Create a new environment with the location of the Flink config for Clifrontend\n-    ImmutableMap<String, String> newEnv =\n-        ImmutableMap.<String, String>builder()\n-            .putAll(ENV.entrySet())\n-            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n-            .build();\n-\n-    modifyEnv(newEnv);\n-  }\n-\n-  private static void restoreEnvironment() throws Exception {\n-    modifyEnv(ENV);\n-  }\n-\n-  private static void modifyEnv(Map<String, String> env) throws Exception {\n-    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n-    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n-\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n-\n-    envField.setAccessible(true);\n-    envField.set(null, env);\n-    envField.setAccessible(false);\n-\n-    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n-    modifiersField.setAccessible(false);\n-  }\n-\n-  private void waitUntilJobIsCompleted() throws Exception {\n-    while (true) {\n-      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n-      assertThat(\n-          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n-      if (allJobsStates.stream()\n-          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n-        return;\n-      }\n-      Thread.sleep(50);\n-    }\n-  }\n-\n-  /** Prevents the CliFrontend from calling System.exit. */\n-  private static void throwExceptionOnSystemExit() {\n-    System.setSecurityManager(\n-        new SecurityManager() {\n-          @Override\n-          public void checkPermission(Permission permission) {\n-            if (permission.getName().startsWith(\"exitVM\")) {\n-              throw new SystemExitException();\n-            }\n-          }\n-        });\n-  }\n-\n-  private static void restoreDefaultSystemExitBehavior() {\n-    System.setSecurityManager(SECURITY_MANAGER);\n-  }\n-\n-  private static class SystemExitException extends SecurityException {}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDY1Mw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383480653", "bodyText": "Removing the workaround and adding the new test should be in two discrete commits.", "author": "ibzib", "createdAt": "2020-02-24T19:54:51Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkJobInvoker.java", "diffHunk": "@@ -23,7 +23,6 @@\n import javax.annotation.Nullable;\n import org.apache.beam.model.pipeline.v1.RunnerApi;\n import org.apache.beam.runners.core.construction.PipelineOptionsTranslation;\n-import org.apache.beam.runners.flink.translation.utils.Workarounds;", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2NTAwNQ==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383765005", "bodyText": "That is debatable. I've split it up, but I do think these changes can exist together. It helps to reason why the test was introduced.", "author": "mxm", "createdAt": "2020-02-25T09:44:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDY1Mw=="}], "type": "inlineReview", "revised_code": null}, {"oid": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "url": "https://github.com/apache/beam/commit/6fe154275f2cfcdb11af9dbed5f50dec95458c41", "message": "[BEAM-9345] Remove workaround to restore stdout/stderr during JobGraph creation\n\nThis removes the workaround to restore stdout/stderr during JobGraph\ncreation. It has caused problems during job submission. Also, the workaround is\nnot necessary anymore in Flink 1.10 due to an upstream fix:\nhttps://issues.apache.org/jira/browse/FLINK-15504\n\nThe parent commit will add an end-to-end test to prevent breakage in the future.", "committedDate": "2020-02-25T09:37:13Z", "type": "commit"}, {"oid": "4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "url": "https://github.com/apache/beam/commit/4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "message": "[BEAM-9345] Add end-to-end Flink job submission test\n\nTo catch submission problems in the future (see child commit), this change\nadds an end-to-end test with a Flink cluster. The test starts from the\ncommand-line interface and executes a simple job for all combinations of\nregular/detached and batch/streaming mode.", "committedDate": "2020-02-25T09:42:11Z", "type": "commit"}, {"oid": "4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "url": "https://github.com/apache/beam/commit/4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "message": "[BEAM-9345] Add end-to-end Flink job submission test\n\nTo catch submission problems in the future (see child commit), this change\nadds an end-to-end test with a Flink cluster. The test starts from the\ncommand-line interface and executes a simple job for all combinations of\nregular/detached and batch/streaming mode.", "committedDate": "2020-02-25T09:42:11Z", "type": "forcePushed"}]}