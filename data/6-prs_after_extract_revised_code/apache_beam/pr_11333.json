{"pr_number": 11333, "pr_title": "[BEAM-9418] Support ANY_VALUE aggregation functions", "pr_createdAt": "2020-04-07T18:21:44Z", "pr_url": "https://github.com/apache/beam/pull/11333", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE4NzkyMA==", "url": "https://github.com/apache/beam/pull/11333#discussion_r409187920", "bodyText": "Please import concrete Java imports than .*", "author": "amaliujia", "createdAt": "2020-04-15T23:14:55Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java", "diffHunk": "@@ -24,11 +24,8 @@\n import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n import static org.junit.internal.matchers.ThrowableMessageMatcher.hasMessage;\n-\n import java.math.BigDecimal;\n-import java.util.Arrays;\n-import java.util.Iterator;\n-import java.util.List;\n+import java.util.*;", "originalCommit": "5de65de9e39427d2f55fd212993787002ea4bf10", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "chunk": "diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\nindex d82f4572bc..80964f58e1 100644\n--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\n+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\n\n@@ -24,8 +24,13 @@ import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n import static org.junit.internal.matchers.ThrowableMessageMatcher.hasMessage;\n+\n import java.math.BigDecimal;\n-import java.util.*;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n import org.apache.beam.sdk.extensions.sql.impl.ParseException;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.testing.PAssert;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE4ODAzMw==", "url": "https://github.com/apache/beam/pull/11333#discussion_r409188033", "bodyText": "run ./gradlew spotlessApply to fix style issues.", "author": "amaliujia", "createdAt": "2020-04-15T23:15:19Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java", "diffHunk": "@@ -241,6 +238,53 @@ private void runAggregationFunctions(PCollection<Row> input) throws Exception {\n     pipeline.run().waitUntilFinish();\n   }\n \n+  /** GROUP-BY with the any_value aggregation function. */\n+  @Test\n+  public void testAnyValueFunction() throws Exception {\n+    pipeline.enableAbandonedNodeEnforcement(false);\n+\n+    Schema schema =\n+            Schema.builder().addInt32Field(\"key\").addInt32Field(\"col\").build();\n+\n+    PCollection<Row> inputRows =", "originalCommit": "5de65de9e39427d2f55fd212993787002ea4bf10", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "chunk": "diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\nindex d82f4572bc..80964f58e1 100644\n--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\n+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlDslAggregationTest.java\n\n@@ -243,44 +248,44 @@ public class BeamSqlDslAggregationTest extends BeamSqlDslBase {\n   public void testAnyValueFunction() throws Exception {\n     pipeline.enableAbandonedNodeEnforcement(false);\n \n-    Schema schema =\n-            Schema.builder().addInt32Field(\"key\").addInt32Field(\"col\").build();\n+    Schema schema = Schema.builder().addInt32Field(\"key\").addInt32Field(\"col\").build();\n \n     PCollection<Row> inputRows =\n-            pipeline\n-                    .apply(\n-                            Create.of(\n-                                    TestUtils.rowsBuilderOf(schema)\n-                                            .addRows(\n-                                                    0, 1,\n-                                                    0, 2,\n-                                                    1, 3,\n-                                                    2, 4,\n-                                                    2, 5)\n-                                            .getRows()))\n-                    .setRowSchema(schema);\n+        pipeline\n+            .apply(\n+                Create.of(\n+                    TestUtils.rowsBuilderOf(schema)\n+                        .addRows(\n+                            0, 1,\n+                            0, 2,\n+                            1, 3,\n+                            2, 4,\n+                            2, 5)\n+                        .getRows()))\n+            .setRowSchema(schema);\n \n     String sql = \"SELECT key, any_value(col) as any_value FROM PCOLLECTION GROUP BY key\";\n \n     PCollection<Row> result = inputRows.apply(\"sql\", SqlTransform.query(sql));\n \n     Map<Integer, List<Integer>> allowedTuples = new HashMap<>();\n-    allowedTuples.put(0, Arrays.asList(1,2));\n+    allowedTuples.put(0, Arrays.asList(1, 2));\n     allowedTuples.put(1, Arrays.asList(3));\n-    allowedTuples.put(2, Arrays.asList(4,5));\n+    allowedTuples.put(2, Arrays.asList(4, 5));\n \n-    PAssert.that(result).satisfies(input -> {\n-      Iterator<Row> iter = input.iterator();\n-      while (iter.hasNext()){\n-        Row row = iter.next();\n-        List<Schema.Field> fields = row.getSchema().getFields();\n-        List<Integer> values= allowedTuples.remove(row.getInt32(\"key\"));\n-        assertTrue(values !=null);\n-        assertTrue(values.contains(row.getInt32(\"any_value\")));\n-      }\n-      assertTrue(allowedTuples.isEmpty());\n-      return null;\n-    });\n+    PAssert.that(result)\n+        .satisfies(\n+            input -> {\n+              Iterator<Row> iter = input.iterator();\n+              while (iter.hasNext()) {\n+                Row row = iter.next();\n+                List<Integer> values = allowedTuples.remove(row.getInt32(\"key\"));\n+                assertTrue(values != null);\n+                assertTrue(values.contains(row.getInt32(\"any_value\")));\n+              }\n+              assertTrue(allowedTuples.isEmpty());\n+              return null;\n+            });\n \n     pipeline.run();\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTE5MDQ4Mg==", "url": "https://github.com/apache/beam/pull/11333#discussion_r409190482", "bodyText": "Same. If you are using inteliij, I think you will need to disable: https://www.jetbrains.com/help/idea/creating-and-optimizing-imports.html#import-packages-instead-of-single-classes", "author": "amaliujia", "createdAt": "2020-04-15T23:22:43Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamBuiltinAggregations.java", "diffHunk": "@@ -33,12 +33,8 @@\n import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.schemas.Schema.FieldType;\n-import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.*;", "originalCommit": "5de65de9e39427d2f55fd212993787002ea4bf10", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "chunk": "diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamBuiltinAggregations.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamBuiltinAggregations.java\nindex 6cbca7a0e3..106e609800 100644\n--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamBuiltinAggregations.java\n+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamBuiltinAggregations.java\n\n@@ -33,8 +33,13 @@ import org.apache.beam.sdk.extensions.sql.impl.transform.agg.VarianceFn;\n import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n import org.apache.beam.sdk.schemas.Schema;\n import org.apache.beam.sdk.schemas.Schema.FieldType;\n-import org.apache.beam.sdk.transforms.*;\n+import org.apache.beam.sdk.transforms.Combine;\n import org.apache.beam.sdk.transforms.Combine.CombineFn;\n+import org.apache.beam.sdk.transforms.Count;\n+import org.apache.beam.sdk.transforms.Max;\n+import org.apache.beam.sdk.transforms.Min;\n+import org.apache.beam.sdk.transforms.Sample;\n+import org.apache.beam.sdk.transforms.Sum;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.vendor.calcite.v1_20_0.com.google.common.collect.ImmutableMap;\n \n"}}, {"oid": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "url": "https://github.com/apache/beam/commit/27876f035e3afdd478ef5e7f21d8524d17b59e13", "message": "[BEAM-9418] Support ANY_VALUE aggregation functions\n\nThe implementation is based on the function Sample#anyCombineFn(int)\nof the Java SDK core.Also, the support for ZetaSQL was enabled.", "committedDate": "2020-04-29T03:11:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzUxOTc5Nw==", "url": "https://github.com/apache/beam/pull/11333#discussion_r417519797", "bodyText": "Why ? as a part of template? (just asking. I am not familiar with how it should be used)", "author": "amaliujia", "createdAt": "2020-04-29T18:21:38Z", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java", "diffHunk": "@@ -58,6 +58,14 @@\n     return new SampleAnyCombineFn<>(sampleSize);\n   }\n \n+  /**\n+   * Returns a {@link CombineFn} that computes a single and potentially non-uniform sample value of\n+   * its inputs.\n+   */\n+  public static <T> CombineFn<T, ?, T> anyValueCombineFn() {", "originalCommit": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI3NDg3NQ==", "url": "https://github.com/apache/beam/pull/11333#discussion_r418274875", "bodyText": "To be frank with you, I copied the the method anyCombineFn and just adapted it. So, I am not sure the reason behind the template usage, I wanted to stick to existing methods.", "author": "jhnmora000", "createdAt": "2020-04-30T20:38:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzUxOTc5Nw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzUyMTk3Nw==", "url": "https://github.com/apache/beam/pull/11333#discussion_r417521977", "bodyText": "I think this is right to return a null.\nper 1, if empty or input rows are all null, return null.\nThough returning null in Java sometimes do causing problems (not the problem in SQL layer, but in Java world). But in BeamSQL we just did it so far.", "author": "amaliujia", "createdAt": "2020-04-29T18:25:18Z", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java", "diffHunk": "@@ -246,6 +254,36 @@ private SampleAnyCombineFn(long limit) {\n     }\n   }\n \n+  /** A {@link CombineFn} that combines into a single element. */\n+  private static class AnyValueCombineFn<T> extends CombineFn<T, List<T>, T> {\n+    private SampleAnyCombineFn internal;\n+\n+    private AnyValueCombineFn() {\n+      internal = new SampleAnyCombineFn<>(1);\n+    }\n+\n+    @Override\n+    public List<T> createAccumulator() {\n+      return internal.createAccumulator();\n+    }\n+\n+    @Override\n+    public List<T> addInput(List<T> accumulator, T input) {\n+      return internal.addInput(accumulator, input);\n+    }\n+\n+    @Override\n+    public List<T> mergeAccumulators(Iterable<List<T>> accumulators) {\n+      return internal.mergeAccumulators(accumulators);\n+    }\n+\n+    @Override\n+    public T extractOutput(List<T> accumulator) {\n+      Iterator<T> it = internal.extractOutput(accumulator).iterator();\n+      return it.hasNext() ? it.next() : null;", "originalCommit": "27876f035e3afdd478ef5e7f21d8524d17b59e13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI3OTE1Ng==", "url": "https://github.com/apache/beam/pull/11333#discussion_r418279156", "bodyText": "Yes, I was aware of that. I thought that I could have used java Optional<T> or similar, but I was not sure it would be compliant with other components. Are there other functions that return optional or nullable objects in the Java SDK?, I could give them a look.", "author": "jhnmora000", "createdAt": "2020-04-30T20:46:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzUyMTk3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI4NDY0Nw==", "url": "https://github.com/apache/beam/pull/11333#discussion_r418284647", "bodyText": "BTW, I created an issue for OVER/window clauses as you suggested.", "author": "jhnmora000", "createdAt": "2020-04-30T20:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzUyMTk3Nw=="}], "type": "inlineReview", "revised_code": null}]}