{"pr_number": 12700, "pr_title": "add support for partial update/remove for tensor and map  ", "pr_createdAt": "2020-03-25T03:13:36Z", "pr_url": "https://github.com/vespa-engine/vespa/pull/12700", "timeline": [{"oid": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "url": "https://github.com/vespa-engine/vespa/commit/a3756480c7886ad029db6f2fbfaacb088d3ffee1", "message": "add support for partial update tensor and map", "committedDate": "2020-03-25T02:38:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY5OTg0Nw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397699847", "bodyText": "I think this line is for debugging.\nRemove this.", "author": "leisureshadow", "createdAt": "2020-03-25T09:07:09Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -107,7 +115,7 @@ public String exec(Tuple tuple) throws IOException {\n             Schema inputSchema = getInputSchema();\n             Map<String, Object> fields = TupleTools.tupleMap(inputSchema, tuple);\n             String docId = TupleTools.toString(fields, template);\n-\n+            System.out.println(docId);", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex 9427ae962d..b7c58fe968 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -115,7 +137,6 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n             Schema inputSchema = getInputSchema();\n             Map<String, Object> fields = TupleTools.tupleMap(inputSchema, tuple);\n             String docId = TupleTools.toString(fields, template);\n-            System.out.println(docId);\n             // create json\n             json = create(operation, docId, fields, properties, inputSchema);\n             if (json == null || json.length() == 0) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcwODQ5Ng==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397708496", "bodyText": "is this an unused dependency?", "author": "leisureshadow", "createdAt": "2020-03-25T09:21:51Z", "path": "vespa-hadoop/src/test/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperationTest.java", "diffHunk": "@@ -1,6 +1,7 @@\n // Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.\n package com.yahoo.vespa.hadoop.pig;\n \n+import com.google.gson.JsonArray;", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/test/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperationTest.java b/vespa-hadoop/src/test/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperationTest.java\nindex b86e927e91..72d0a2ec06 100644\n--- a/vespa-hadoop/src/test/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperationTest.java\n+++ b/vespa-hadoop/src/test/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperationTest.java\n\n@@ -1,7 +1,6 @@\n // Copyright 2017 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.\n package com.yahoo.vespa.hadoop.pig;\n \n-import com.google.gson.JsonArray;\n import org.apache.pig.data.*;\n import org.apache.pig.impl.logicalLayer.FrontendException;\n import org.apache.pig.impl.logicalLayer.schema.Schema;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxMTY5Nw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397711697", "bodyText": "Can we separate removeTensor and add/create into two method since they are quite different?\nSince the common part is not much, two different purpose methods would be easier to read rather than a complex method with multiple functionalities.", "author": "leisureshadow", "createdAt": "2020-03-25T09:26:59Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -408,45 +529,72 @@ private static boolean shouldWriteField(String name, Properties properties, int\n         return true;\n     }\n \n-    private static void writeTensor(Map<Object, Object> map, JsonGenerator g) throws IOException {\n-        g.writeFieldName(\"cells\");\n+    private static void writeTensor(Map<Object, Object> map, JsonGenerator g, Boolean isRemoveTensor) throws IOException {", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex 9427ae962d..b7c58fe968 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -529,70 +569,71 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         return true;\n     }\n \n-    private static void writeTensor(Map<Object, Object> map, JsonGenerator g, Boolean isRemoveTensor) throws IOException {\n-        if (!isRemoveTensor){\n-            g.writeFieldName(\"cells\");\n-        }else{\n-            g.writeFieldName(\"address\");\n-        }\n+    private static void writeTensor(Map<Object, Object> map, JsonGenerator g) throws IOException {\n+        g.writeFieldName(\"cells\");\n         g.writeStartArray();\n         for (Map.Entry<Object, Object> entry : map.entrySet()) {\n             String k = entry.getKey().toString();\n             Double v = Double.parseDouble(entry.getValue().toString());\n \n-            // Write address\n-            if (!isRemoveTensor){\n-\n-                g.writeStartObject();\n+            g.writeStartObject();\n \n-                g.writeFieldName(\"address\");\n-                g.writeStartObject();\n+            // Write address\n+            g.writeFieldName(\"address\");\n+            g.writeStartObject();\n \n-                String[] dimensions = k.split(\",\");\n-                for (String dimension : dimensions) {\n-                    if (dimension == null || dimension.isEmpty()) {\n-                        continue;\n-                    }\n-                    String[] address = dimension.split(\":\");\n-                    if (address.length != 2) {\n-                        throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n-                    }\n-                    String dim = address[0];\n-                    String label = address[1];\n-                    if (dim == null || label == null || dim.isEmpty() || label.isEmpty()) {\n-                        throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n-                    }\n-                    g.writeFieldName(dim.trim());\n-                    g.writeString(label.trim());\n+            String[] dimensions = k.split(\",\");\n+            for (String dimension : dimensions) {\n+                if (dimension == null || dimension.isEmpty()) {\n+                    continue;\n                 }\n-                g.writeEndObject();\n+                String[] address = dimension.split(\":\");\n+                if (address.length != 2) {\n+                    throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n+                }\n+                String dim = address[0];\n+                String label = address[1];\n+                if (dim == null || label == null || dim.isEmpty() || label.isEmpty()) {\n+                    throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n+                }\n+                g.writeFieldName(dim.trim());\n+                g.writeString(label.trim());\n+            }\n+            g.writeEndObject();\n \n-                // Write value\n-                g.writeFieldName(\"value\");\n-                g.writeNumber(v);\n+            // Write value\n+            g.writeFieldName(\"value\");\n+            g.writeNumber(v);\n \n-                g.writeEndObject();\n+            g.writeEndObject();\n+        }\n+        g.writeEndArray();\n+    }\n \n-            }else{\n-                String[] dimensions = k.split(\",\");\n-                for (String dimension : dimensions) {\n-                    g.writeStartObject();\n-                    if (dimension == null || dimension.isEmpty()) {\n-                        continue;\n-                    }\n-                    String[] address = dimension.split(\":\");\n-                    if (address.length != 2) {\n-                        throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n-                    }\n-                    String dim = address[0];\n-                    String label = address[1];\n-                    if (dim == null || label == null || dim.isEmpty() || label.isEmpty()) {\n-                        throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n-                    }\n-                    g.writeFieldName(dim.trim());\n-                    g.writeString(label.trim());\n-                    g.writeEndObject();\n+    private static void writeRemoveTensor(Map<Object, Object> map, JsonGenerator g) throws IOException {\n+        g.writeFieldName(\"addresses\");\n+        g.writeStartArray();\n+        for (Map.Entry<Object, Object> entry : map.entrySet()) {\n+            String k = entry.getKey().toString();\n+            String[] dimensions = k.split(\",\");\n+            for (String dimension : dimensions) {\n+                g.writeStartObject();\n+                if (dimension == null || dimension.isEmpty()) {\n+                    continue;\n                 }\n+                String[] address = dimension.split(\":\");\n+                if (address.length != 2) {\n+                    throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n+                }\n+                String dim = address[0];\n+                String label = address[1];\n+                if (dim == null || label == null || dim.isEmpty() || label.isEmpty()) {\n+                    throw new IllegalArgumentException(\"Malformed cell address: \" + dimension);\n+                }\n+                g.writeFieldName(dim.trim());\n+                g.writeString(label.trim());\n+                g.writeEndObject();\n+                // Write address\n             }\n         }\n         g.writeEndArray();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxNTQyMA==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397715420", "bodyText": "Can we merge isPartialOperation into writePartialUpdate?\nThe main purpose of isPartialOperation is to write assign to the output.\nAnd the purpose of isPartialOperation is to check it's a partial operation and write the operation to the output.\nI think the purpose of these two method is alike.\nIt's better to write the same purpose code into same place.", "author": "leisureshadow", "createdAt": "2020-03-25T09:32:43Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -309,9 +351,32 @@ private static boolean shouldWritePartialUpdate(Operation op, int depth) {\n \n     private static void writePartialUpdate(Object value, Byte type, JsonGenerator g, String name, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         g.writeStartObject();\n-        g.writeFieldName(PARTIAL_UPDATE_ASSIGN); // TODO: lookup field name in a property to determine correct operation\n+        // look up which operation to do by checking names and their respected properties\n+        if (!isPartialOperation(REMOVE_TENSOR_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, true)\n+        && !isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, true)\n+                && !isPartialOperation(ADD_TENSOR_FIELDS, name, properties, g, PARTIAL_UPDATE_ADD, true)) {\n+            g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n+        }\n         writeValue(value, type, g, name, properties, schema, op, depth);\n         g.writeEndObject();\n+\n+\n+    }\n+\n+    private static boolean isPartialOperation(String label, String name, Properties properties, JsonGenerator g, String targetOperation, boolean writeFieldName) throws IOException{", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex 9427ae962d..b7c58fe968 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -350,29 +387,32 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n     }\n \n     private static void writePartialUpdate(Object value, Byte type, JsonGenerator g, String name, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n+        boolean isAssign = true;\n+\n         g.writeStartObject();\n-        // look up which operation to do by checking names and their respected properties\n-        if (!isPartialOperation(REMOVE_TENSOR_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, true)\n-        && !isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, true)\n-                && !isPartialOperation(ADD_TENSOR_FIELDS, name, properties, g, PARTIAL_UPDATE_ADD, true)) {\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    g.writeFieldName(operationMap.get(label));\n+                    isAssign = false;\n+                }\n+            }\n+        }\n+        if (isAssign) {\n             g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n         }\n         writeValue(value, type, g, name, properties, schema, op, depth);\n         g.writeEndObject();\n-\n-\n     }\n \n-    private static boolean isPartialOperation(String label, String name, Properties properties, JsonGenerator g, String targetOperation, boolean writeFieldName) throws IOException{\n+    private static boolean isPartialOperation(String label, String name, Properties properties) {\n         // when dealing with partial update operations, write the desired operation\n         // writeFieldName decides if a field name should be written when checking\n         boolean isPartialOperation = false;\n         if (properties.getProperty(label) != null) {\n             String[] p = properties.getProperty(label).split(\",\");\n             if (Arrays.asList(p).contains(name)) {\n-                if (writeFieldName) {\n-                    g.writeFieldName(targetOperation);\n-                }\n                 isPartialOperation = true;\n             }\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxNzYxMw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397717613", "bodyText": "can we check it's a partial operation first, then generate the field name according to its data type?\ncurrently, u specifically check it's a remove/add _bag_as_map_fields, then transform the bag to field name directly.\nIt'll be more general to depend on data type than on field name.", "author": "leisureshadow", "createdAt": "2020-03-25T09:36:30Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -182,12 +190,47 @@ public static String create(Operation op, String docId, Map<String, Object> fiel\n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            g.writeFieldName(name);\n-            if (shouldWritePartialUpdate(op, depth)) {\n-                writePartialUpdate(value, type, g, name, properties, schema, op, depth);\n-            } else {\n-                writeValue(value, type, g, name, properties, schema, op, depth);\n+            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, false) ||\n+                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_ASSIGN, false)){", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY4ODA1Ng==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400688056", "bodyText": "per discussion, cannot merge writeMapPartialUpdate into writePartialUpdate method because we have to generate special key name of map partial update fields.", "author": "leisureshadow", "createdAt": "2020-03-31T07:09:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxNzYxMw=="}], "type": "inlineReview", "revised_code": {"commit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex 9427ae962d..b7c58fe968 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -190,8 +223,8 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_REMOVE, false) ||\n-                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties, g, PARTIAL_UPDATE_ASSIGN, false)){\n+            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n+                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n                 schema = (schema != null) ? schema.getField(0).schema : null;\n                 // extract the key of map and keys in map for writing json when partial updating maps\n                 Schema valueSchema = (schema != null) ? schema.getField(1).schema : null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcyMDgzOQ==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r397720839", "bodyText": "From pig user perspective, remove/add-bag-as-map-fields may be confused.\nUsers need to know that there is a functionality to transform bag as map.\nThen he/she may know that these two feature is to add/remove a data in map.\nMost of the pig users don't need to know the detail of this Java UDF.\nIt's better to rename them so that pig users would understand what are these for easily.", "author": "leisureshadow", "createdAt": "2020-03-25T09:41:47Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -68,10 +68,18 @@ public static boolean valid(String text) {\n     private static final String SIMPLE_ARRAY_FIELDS = \"simple-array-fields\";\n     private static final String SIMPLE_OBJECT_FIELDS = \"simple-object-fields\";\n     private static final String CREATE_TENSOR_FIELDS = \"create-tensor-fields\";\n+    private static final String REMOVE_TENSOR_FIELDS = \"remove-tensor-fields\";\n+    private static final String ADD_TENSOR_FIELDS = \"add-tensor-fields\";\n+    private static final String REMOVE_BAG_AS_MAP_FIELDS = \"remove-bag-as-map-fields\";\n+    private static final String ADD_BAG_AS_MAP_FIELDS = \"add-bag-as-map-fields\";", "originalCommit": "a3756480c7886ad029db6f2fbfaacb088d3ffee1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex 9427ae962d..b7c58fe968 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -74,18 +76,29 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n     private static final String ADD_BAG_AS_MAP_FIELDS = \"add-bag-as-map-fields\";\n     private static final String EXCLUDE_FIELDS = \"exclude-fields\";\n     private static final String TESTSET_CONDITION = \"condition\";\n-\n-\n     private static final String PARTIAL_UPDATE_ASSIGN = \"assign\";\n     private static final String PARTIAL_UPDATE_ADD = \"add\";\n     private static final String PARTIAL_UPDATE_REMOVE = \"remove\";\n+    private static Map<String, String> operationMap;\n \n+    static {\n+        operationMap = new HashMap<>();\n+        operationMap.put(REMOVE_TENSOR_FIELDS, PARTIAL_UPDATE_REMOVE);\n+        operationMap.put(REMOVE_BAG_AS_MAP_FIELDS, PARTIAL_UPDATE_REMOVE);\n+        operationMap.put(ADD_TENSOR_FIELDS, PARTIAL_UPDATE_ADD);\n+    }\n \n     private final String template;\n     private final Operation operation;\n     private final Properties properties;\n+    private PigStatusReporter statusReporter;\n \n     public VespaDocumentOperation(String... params) {\n+        statusReporter = PigStatusReporter.getInstance();\n+        if(statusReporter != null){\n+            statusReporter.incrCounter(\"Vespa Document Operation Counters\",\"Document operation ok\",0);\n+            statusReporter.incrCounter(\"Vespa Document Operation Counters\",\"Document operation failed\",0);\n+        }\n         properties = VespaConfiguration.loadProperties(params);\n         template = properties.getProperty(PROPERTY_ID_TEMPLATE);\n         operation = Operation.fromString(properties.getProperty(PROPERTY_OPERATION, \"put\"));\n"}}, {"oid": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "url": "https://github.com/vespa-engine/vespa/commit/4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "message": "pr review", "committedDate": "2020-03-31T06:53:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY4ODMyOQ==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400688329", "bodyText": "Don't comment out this line. This bug should be fixed in other PR.", "author": "leisureshadow", "createdAt": "2020-03-31T07:10:07Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -6,16 +6,18 @@\n import com.fasterxml.jackson.core.JsonGenerator;\n import com.yahoo.vespa.hadoop.mapreduce.util.TupleTools;\n import com.yahoo.vespa.hadoop.mapreduce.util.VespaConfiguration;\n-import org.apache.commons.lang.exception.ExceptionUtils;\n+//import org.apache.commons.lang.exception.ExceptionUtils;", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -6,18 +6,17 @@ import com.fasterxml.jackson.core.JsonFactory;\n import com.fasterxml.jackson.core.JsonGenerator;\n import com.yahoo.vespa.hadoop.mapreduce.util.TupleTools;\n import com.yahoo.vespa.hadoop.mapreduce.util.VespaConfiguration;\n-//import org.apache.commons.lang.exception.ExceptionUtils;\n+import org.apache.commons.lang.exception.ExceptionUtils;\n import org.apache.pig.EvalFunc;\n import org.apache.pig.PigWarning;\n import org.apache.pig.data.DataBag;\n import org.apache.pig.data.DataByteArray;\n import org.apache.pig.data.DataType;\n import org.apache.pig.data.Tuple;\n-import org.apache.pig.impl.logicalLayer.schema.Schema;\n import org.apache.pig.tools.pigstats.PigStatusReporter;\n+import org.apache.pig.impl.logicalLayer.schema.Schema;\n import org.joda.time.DateTime;\n \n-\n import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n import java.math.BigDecimal;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY4ODk2MQ==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400688961", "bodyText": "Suggest to merge this two condition into one method.\nLike the one, shouldWritePartialUpdate.", "author": "leisureshadow", "createdAt": "2020-03-31T07:11:30Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -182,12 +223,47 @@ public static String create(Operation op, String docId, Map<String, Object> fiel\n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            g.writeFieldName(name);\n-            if (shouldWritePartialUpdate(op, depth)) {\n-                writePartialUpdate(value, type, g, name, properties, schema, op, depth);\n-            } else {\n-                writeValue(value, type, g, name, properties, schema, op, depth);\n+            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n+                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -219,42 +219,35 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         return out.toString();\n     }\n \n+    private static String getPartialOperation(Map<String, String> operationMap, String name, Properties properties) {\n+        // This function checks if the property of the name falls into the map provided\n+        // if yes, return the desired operation. if no, return null\n+        // for example, input:\n+        // operationMap map{\"update-map-fields\":\"assign\",\"remove-map-fields\":\"remove\"}\n+        // name date\n+        // properties \"update-map-fields\":\"date,month\"\n+        // output: assign\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    return operationMap.get(label);\n+                }\n+            }\n+        }\n+        return null;\n+    }\n \n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n-                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n-                schema = (schema != null) ? schema.getField(0).schema : null;\n-                // extract the key of map and keys in map for writing json when partial updating maps\n-                Schema valueSchema = (schema != null) ? schema.getField(1).schema : null;\n-                // data format  { ( key; id, value: (abc,123,(123234,bbaa))) }\n-                // the first element of each tuple in the bag will be the map to update\n-                // the second element of each tuple in the bag will be the new value of the map\n-                DataBag bag = (DataBag) value;\n-                for (Tuple element : bag) {\n-                    if (element.size() != 2) {\n-                        continue;\n-                    }\n-                    String k = (String) element.get(0);\n-                    Object v = element.get(1);\n-                    Byte t = DataType.findType(v);\n-                    if (t == DataType.TUPLE) {\n-                        g.writeFieldName(name + \"{\" + k + \"}\");\n-                        if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties)) {\n-                            g.writeStartObject();\n-                            g.writeFieldName(PARTIAL_UPDATE_REMOVE);\n-                            g.writeNumber(0);\n-                            g.writeEndObject();\n-                        }else{\n-                            if (shouldWritePartialUpdate(op, depth)) {\n-                                writePartialUpdate(v, t, g, name, properties, valueSchema, op, depth);\n-                            } else {\n-                                writeValue(v, t, g, name, properties, valueSchema, op, depth);\n-                            }\n-                        }\n-                    }\n-                }\n+            String operation = getPartialOperation(mapPartialOperationMap, name, properties);\n+            // check if the name has the property update-map-fields/remove-map-fields\n+            // if yes, we need special treatments here as we need to loop through the tuple\n+            // be aware the the operation here is not vespa operation such as \"put\" and \"update\"\n+            // operation here are the field name we wish use to such as \"assign\" and \"remove\"\n+            if (operation != null) {\n+                writePartialUpdateAndRemoveMap(name ,value, g, properties, schema, op, depth, operation);\n             }else{\n                 g.writeFieldName(name);\n                 if (shouldWritePartialUpdate(op, depth)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY4OTMzNw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400689337", "bodyText": "Extract line 228~257 into a new method. This could increase the readability of method, writeField.", "author": "leisureshadow", "createdAt": "2020-03-31T07:12:19Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -182,12 +223,47 @@ public static String create(Operation op, String docId, Map<String, Object> fiel\n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            g.writeFieldName(name);\n-            if (shouldWritePartialUpdate(op, depth)) {\n-                writePartialUpdate(value, type, g, name, properties, schema, op, depth);\n-            } else {\n-                writeValue(value, type, g, name, properties, schema, op, depth);\n+            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n+                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n+                schema = (schema != null) ? schema.getField(0).schema : null;", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -219,42 +219,35 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         return out.toString();\n     }\n \n+    private static String getPartialOperation(Map<String, String> operationMap, String name, Properties properties) {\n+        // This function checks if the property of the name falls into the map provided\n+        // if yes, return the desired operation. if no, return null\n+        // for example, input:\n+        // operationMap map{\"update-map-fields\":\"assign\",\"remove-map-fields\":\"remove\"}\n+        // name date\n+        // properties \"update-map-fields\":\"date,month\"\n+        // output: assign\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    return operationMap.get(label);\n+                }\n+            }\n+        }\n+        return null;\n+    }\n \n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n-                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n-                schema = (schema != null) ? schema.getField(0).schema : null;\n-                // extract the key of map and keys in map for writing json when partial updating maps\n-                Schema valueSchema = (schema != null) ? schema.getField(1).schema : null;\n-                // data format  { ( key; id, value: (abc,123,(123234,bbaa))) }\n-                // the first element of each tuple in the bag will be the map to update\n-                // the second element of each tuple in the bag will be the new value of the map\n-                DataBag bag = (DataBag) value;\n-                for (Tuple element : bag) {\n-                    if (element.size() != 2) {\n-                        continue;\n-                    }\n-                    String k = (String) element.get(0);\n-                    Object v = element.get(1);\n-                    Byte t = DataType.findType(v);\n-                    if (t == DataType.TUPLE) {\n-                        g.writeFieldName(name + \"{\" + k + \"}\");\n-                        if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties)) {\n-                            g.writeStartObject();\n-                            g.writeFieldName(PARTIAL_UPDATE_REMOVE);\n-                            g.writeNumber(0);\n-                            g.writeEndObject();\n-                        }else{\n-                            if (shouldWritePartialUpdate(op, depth)) {\n-                                writePartialUpdate(v, t, g, name, properties, valueSchema, op, depth);\n-                            } else {\n-                                writeValue(v, t, g, name, properties, valueSchema, op, depth);\n-                            }\n-                        }\n-                    }\n-                }\n+            String operation = getPartialOperation(mapPartialOperationMap, name, properties);\n+            // check if the name has the property update-map-fields/remove-map-fields\n+            // if yes, we need special treatments here as we need to loop through the tuple\n+            // be aware the the operation here is not vespa operation such as \"put\" and \"update\"\n+            // operation here are the field name we wish use to such as \"assign\" and \"remove\"\n+            if (operation != null) {\n+                writePartialUpdateAndRemoveMap(name ,value, g, properties, schema, op, depth, operation);\n             }else{\n                 g.writeFieldName(name);\n                 if (shouldWritePartialUpdate(op, depth)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY4OTY1MA==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400689650", "bodyText": "Remove shouldWritePartialUpdate if-else because else won't be happen here.", "author": "leisureshadow", "createdAt": "2020-03-31T07:12:57Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -182,12 +223,47 @@ public static String create(Operation op, String docId, Map<String, Object> fiel\n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            g.writeFieldName(name);\n-            if (shouldWritePartialUpdate(op, depth)) {\n-                writePartialUpdate(value, type, g, name, properties, schema, op, depth);\n-            } else {\n-                writeValue(value, type, g, name, properties, schema, op, depth);\n+            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n+                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n+                schema = (schema != null) ? schema.getField(0).schema : null;\n+                // extract the key of map and keys in map for writing json when partial updating maps\n+                Schema valueSchema = (schema != null) ? schema.getField(1).schema : null;\n+                // data format  { ( key; id, value: (abc,123,(123234,bbaa))) }\n+                // the first element of each tuple in the bag will be the map to update\n+                // the second element of each tuple in the bag will be the new value of the map\n+                DataBag bag = (DataBag) value;\n+                for (Tuple element : bag) {\n+                    if (element.size() != 2) {\n+                        continue;\n+                    }\n+                    String k = (String) element.get(0);\n+                    Object v = element.get(1);\n+                    Byte t = DataType.findType(v);\n+                    if (t == DataType.TUPLE) {\n+                        g.writeFieldName(name + \"{\" + k + \"}\");\n+                        if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties)) {\n+                            g.writeStartObject();\n+                            g.writeFieldName(PARTIAL_UPDATE_REMOVE);\n+                            g.writeNumber(0);\n+                            g.writeEndObject();\n+                        }else{\n+                            if (shouldWritePartialUpdate(op, depth)) {\n+                                writePartialUpdate(v, t, g, name, properties, valueSchema, op, depth);\n+                            } else {", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -219,42 +219,35 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         return out.toString();\n     }\n \n+    private static String getPartialOperation(Map<String, String> operationMap, String name, Properties properties) {\n+        // This function checks if the property of the name falls into the map provided\n+        // if yes, return the desired operation. if no, return null\n+        // for example, input:\n+        // operationMap map{\"update-map-fields\":\"assign\",\"remove-map-fields\":\"remove\"}\n+        // name date\n+        // properties \"update-map-fields\":\"date,month\"\n+        // output: assign\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    return operationMap.get(label);\n+                }\n+            }\n+        }\n+        return null;\n+    }\n \n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties) ||\n-                    isPartialOperation(ADD_BAG_AS_MAP_FIELDS, name, properties)){\n-                schema = (schema != null) ? schema.getField(0).schema : null;\n-                // extract the key of map and keys in map for writing json when partial updating maps\n-                Schema valueSchema = (schema != null) ? schema.getField(1).schema : null;\n-                // data format  { ( key; id, value: (abc,123,(123234,bbaa))) }\n-                // the first element of each tuple in the bag will be the map to update\n-                // the second element of each tuple in the bag will be the new value of the map\n-                DataBag bag = (DataBag) value;\n-                for (Tuple element : bag) {\n-                    if (element.size() != 2) {\n-                        continue;\n-                    }\n-                    String k = (String) element.get(0);\n-                    Object v = element.get(1);\n-                    Byte t = DataType.findType(v);\n-                    if (t == DataType.TUPLE) {\n-                        g.writeFieldName(name + \"{\" + k + \"}\");\n-                        if (isPartialOperation(REMOVE_BAG_AS_MAP_FIELDS, name, properties)) {\n-                            g.writeStartObject();\n-                            g.writeFieldName(PARTIAL_UPDATE_REMOVE);\n-                            g.writeNumber(0);\n-                            g.writeEndObject();\n-                        }else{\n-                            if (shouldWritePartialUpdate(op, depth)) {\n-                                writePartialUpdate(v, t, g, name, properties, valueSchema, op, depth);\n-                            } else {\n-                                writeValue(v, t, g, name, properties, valueSchema, op, depth);\n-                            }\n-                        }\n-                    }\n-                }\n+            String operation = getPartialOperation(mapPartialOperationMap, name, properties);\n+            // check if the name has the property update-map-fields/remove-map-fields\n+            // if yes, we need special treatments here as we need to loop through the tuple\n+            // be aware the the operation here is not vespa operation such as \"put\" and \"update\"\n+            // operation here are the field name we wish use to such as \"assign\" and \"remove\"\n+            if (operation != null) {\n+                writePartialUpdateAndRemoveMap(name ,value, g, properties, schema, op, depth, operation);\n             }else{\n                 g.writeFieldName(name);\n                 if (shouldWritePartialUpdate(op, depth)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY5MDc4OQ==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400690789", "bodyText": "Suggest to change the condition of writing assign operation.\nThere are two type of partial update: 1. single field partial update 2. whole document partial update\nThe 1st one is decided by property. The 2nd one is decided by operation name and the depth.\nIt's better to change the logic to the operation name and the depth so that we know this assign is added because of whole document partial update.", "author": "leisureshadow", "createdAt": "2020-03-31T07:15:21Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -308,12 +387,38 @@ private static boolean shouldWritePartialUpdate(Operation op, int depth) {\n     }\n \n     private static void writePartialUpdate(Object value, Byte type, JsonGenerator g, String name, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n+        boolean isAssign = true;\n+\n         g.writeStartObject();\n-        g.writeFieldName(PARTIAL_UPDATE_ASSIGN); // TODO: lookup field name in a property to determine correct operation\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    g.writeFieldName(operationMap.get(label));\n+                    isAssign = false;\n+                }\n+            }\n+        }\n+        if (isAssign) {\n+            g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n+        }", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -387,19 +409,14 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n     }\n \n     private static void writePartialUpdate(Object value, Byte type, JsonGenerator g, String name, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n-        boolean isAssign = true;\n-\n         g.writeStartObject();\n-        for (String label: operationMap.keySet()) {\n-            if (properties.getProperty(label) != null) {\n-                String[] p = properties.getProperty(label).split(\",\");\n-                if (Arrays.asList(p).contains(name)) {\n-                    g.writeFieldName(operationMap.get(label));\n-                    isAssign = false;\n-                }\n-            }\n-        }\n-        if (isAssign) {\n+        // here we check if the operation falls into the four partial operations we do on map/tensor structure\n+        // if no, we assume it's a update on the whole document and we write assign here\n+        // if yes, we write the desired operation here\n+        String operation = getPartialOperation(partialOperationMap, name, properties);\n+        if (operation != null) {\n+            g.writeFieldName(operation);\n+        }else{\n             g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n         }\n         writeValue(value, type, g, name, properties, schema, op, depth);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY5MDk2Nw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400690967", "bodyText": "coding style", "author": "leisureshadow", "createdAt": "2020-03-31T07:15:44Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -235,7 +311,11 @@ private static void writeValue(Object value, Byte type, JsonGenerator g, String\n                 g.writeStartObject();\n                 Map<Object, Object> map = (Map<Object, Object>) value;\n                 if (shouldCreateTensor(map, name, properties)) {\n-                    writeTensor(map, g);\n+                    if(isRemoveTensor(name,properties)){\n+                        writeRemoveTensor(map,g);", "originalCommit": "4788d1fdaae9a49f4cde171066f589cc0d5e3f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b7c58fe968..b81b0e732b 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -312,7 +334,7 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n                 Map<Object, Object> map = (Map<Object, Object>) value;\n                 if (shouldCreateTensor(map, name, properties)) {\n                     if(isRemoveTensor(name,properties)){\n-                        writeRemoveTensor(map,g);\n+                        writeRemoveTensor(map, g);\n                     }else{\n                         writeTensor(map, g);\n                     }\n"}}, {"oid": "d254707e6a9f5555321c108996cfd7b61c55f23d", "url": "https://github.com/vespa-engine/vespa/commit/d254707e6a9f5555321c108996cfd7b61c55f23d", "message": "pr fix and add counter", "committedDate": "2020-03-31T09:39:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc4NzUxMw==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400787513", "bodyText": "coding style", "author": "leisureshadow", "createdAt": "2020-03-31T09:57:16Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -178,15 +219,72 @@ public static String create(Operation op, String docId, Map<String, Object> fiel\n         return out.toString();\n     }\n \n+    private static String getPartialOperation(Map<String, String> operationMap, String name, Properties properties) {\n+        // This function checks if the property of the name falls into the map provided\n+        // if yes, return the desired operation. if no, return null\n+        // for example, input:\n+        // operationMap map{\"update-map-fields\":\"assign\",\"remove-map-fields\":\"remove\"}\n+        // name date\n+        // properties \"update-map-fields\":\"date,month\"\n+        // output: assign\n+        for (String label: operationMap.keySet()) {\n+            if (properties.getProperty(label) != null) {\n+                String[] p = properties.getProperty(label).split(\",\");\n+                if (Arrays.asList(p).contains(name)) {\n+                    return operationMap.get(label);\n+                }\n+            }\n+        }\n+        return null;\n+    }\n \n     @SuppressWarnings(\"unchecked\")\n     private static void writeField(String name, Object value, Byte type, JsonGenerator g, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         if (shouldWriteField(name, properties, depth)) {\n-            g.writeFieldName(name);\n-            if (shouldWritePartialUpdate(op, depth)) {\n-                writePartialUpdate(value, type, g, name, properties, schema, op, depth);\n-            } else {\n-                writeValue(value, type, g, name, properties, schema, op, depth);\n+            String operation = getPartialOperation(mapPartialOperationMap, name, properties);\n+            // check if the name has the property update-map-fields/remove-map-fields\n+            // if yes, we need special treatments here as we need to loop through the tuple\n+            // be aware the the operation here is not vespa operation such as \"put\" and \"update\"\n+            // operation here are the field name we wish use to such as \"assign\" and \"remove\"\n+            if (operation != null) {\n+                writePartialUpdateAndRemoveMap(name ,value, g, properties, schema, op, depth, operation);\n+            }else{", "originalCommit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c339a407bdcdd3a33e03628d593830dd66091072", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b81b0e732b..219996ee9a 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -227,7 +229,7 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         // name date\n         // properties \"update-map-fields\":\"date,month\"\n         // output: assign\n-        for (String label: operationMap.keySet()) {\n+        for (String label : operationMap.keySet()) {\n             if (properties.getProperty(label) != null) {\n                 String[] p = properties.getProperty(label).split(\",\");\n                 if (Arrays.asList(p).contains(name)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc4ODI5MQ==", "url": "https://github.com/vespa-engine/vespa/pull/12700#discussion_r400788291", "bodyText": "we can break here to reduce some time.", "author": "leisureshadow", "createdAt": "2020-03-31T09:58:24Z", "path": "vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java", "diffHunk": "@@ -309,11 +410,32 @@ private static boolean shouldWritePartialUpdate(Operation op, int depth) {\n \n     private static void writePartialUpdate(Object value, Byte type, JsonGenerator g, String name, Properties properties, Schema schema, Operation op, int depth) throws IOException {\n         g.writeStartObject();\n-        g.writeFieldName(PARTIAL_UPDATE_ASSIGN); // TODO: lookup field name in a property to determine correct operation\n+        // here we check if the operation falls into the four partial operations we do on map/tensor structure\n+        // if no, we assume it's a update on the whole document and we write assign here\n+        // if yes, we write the desired operation here\n+        String operation = getPartialOperation(partialOperationMap, name, properties);\n+        if (operation != null) {\n+            g.writeFieldName(operation);\n+        }else{\n+            g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n+        }\n         writeValue(value, type, g, name, properties, schema, op, depth);\n         g.writeEndObject();\n     }\n \n+    private static boolean isPartialOperation(String label, String name, Properties properties) {\n+        // when dealing with partial update operations, write the desired operation\n+        // writeFieldName decides if a field name should be written when checking\n+        boolean isPartialOperation = false;\n+        if (properties.getProperty(label) != null) {\n+            String[] p = properties.getProperty(label).split(\",\");\n+            if (Arrays.asList(p).contains(name)) {\n+                isPartialOperation = true;", "originalCommit": "d254707e6a9f5555321c108996cfd7b61c55f23d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c339a407bdcdd3a33e03628d593830dd66091072", "chunk": "diff --git a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\nindex b81b0e732b..219996ee9a 100644\n--- a/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n+++ b/vespa-hadoop/src/main/java/com/yahoo/vespa/hadoop/pig/VespaDocumentOperation.java\n\n@@ -416,26 +418,13 @@ public class VespaDocumentOperation extends EvalFunc<String> {\n         String operation = getPartialOperation(partialOperationMap, name, properties);\n         if (operation != null) {\n             g.writeFieldName(operation);\n-        }else{\n+        } else {\n             g.writeFieldName(PARTIAL_UPDATE_ASSIGN);\n         }\n         writeValue(value, type, g, name, properties, schema, op, depth);\n         g.writeEndObject();\n     }\n \n-    private static boolean isPartialOperation(String label, String name, Properties properties) {\n-        // when dealing with partial update operations, write the desired operation\n-        // writeFieldName decides if a field name should be written when checking\n-        boolean isPartialOperation = false;\n-        if (properties.getProperty(label) != null) {\n-            String[] p = properties.getProperty(label).split(\",\");\n-            if (Arrays.asList(p).contains(name)) {\n-                isPartialOperation = true;\n-            }\n-        }\n-        return isPartialOperation;\n-    }\n-\n     private static boolean shouldWriteTupleStart(Tuple tuple, String name, Properties properties) {\n         if (tuple.size() > 1 || properties == null) {\n             return true;\n"}}, {"oid": "c339a407bdcdd3a33e03628d593830dd66091072", "url": "https://github.com/vespa-engine/vespa/commit/c339a407bdcdd3a33e03628d593830dd66091072", "message": "pr fix", "committedDate": "2020-03-31T10:16:32Z", "type": "commit"}, {"oid": "cd15c0e9021bce99839fcccb40d9406054de6c08", "url": "https://github.com/vespa-engine/vespa/commit/cd15c0e9021bce99839fcccb40d9406054de6c08", "message": "Merge branch 'master' into partial_update_bag_as_map_and_tensor", "committedDate": "2020-04-02T11:06:54Z", "type": "commit"}]}