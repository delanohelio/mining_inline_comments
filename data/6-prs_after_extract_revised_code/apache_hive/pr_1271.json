{"pr_number": 1271, "pr_title": "HIVE-23851: MSCK REPAIR Command With Partition Filtering Fails While Dropping Partitions", "pr_createdAt": "2020-07-17T07:36:02Z", "pr_url": "https://github.com/apache/hive/pull/1271", "timeline": [{"oid": "94051c8059c31b13fc550225514676fa0f2d0d8d", "url": "https://github.com/apache/hive/commit/94051c8059c31b13fc550225514676fa0f2d0d8d", "message": "Add more test case", "committedDate": "2020-07-31T14:58:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk0OTE0NA==", "url": "https://github.com/apache/hive/pull/1271#discussion_r484949144", "bodyText": "I don't know - have you explored using the SA approach ? seeing the ql class thru reflection looks a bit wierd.\nother way around could be to move Expr related classes out from ql (not sure if that's possible)", "author": "kgyrtkirk", "createdAt": "2020-09-08T14:07:47Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MsckPartitionExpressionProxy.java", "diffHunk": "@@ -1,114 +0,0 @@\n-package org.apache.hadoop.hive.metastore;\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-import java.nio.charset.StandardCharsets;\n-import java.util.ArrayList;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Set;\n-\n-import org.apache.hadoop.hive.metastore.api.FieldSchema;\n-import org.apache.hadoop.hive.metastore.api.FileMetadataExprType;\n-import org.apache.hadoop.hive.metastore.api.MetaException;\n-import org.apache.hadoop.hive.metastore.utils.FileUtils;\n-import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n-import org.apache.hadoop.util.StringUtils;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-// This is added as part of moving MSCK code from ql to standalone-metastore. There is a metastore API to drop\n-// partitions by name but we cannot use it because msck typically will contain partition value (year=2014). We almost\n-// never drop partition by name (year). So we need to construct expression filters, the current\n-// PartitionExpressionProxy implementations (PartitionExpressionForMetastore and HCatClientHMSImpl.ExpressionBuilder)\n-// all depend on ql code to build ExprNodeDesc for the partition expressions. It also depends on kryo for serializing\n-// the expression objects to byte[]. For MSCK drop partition, we don't need complex expression generator. For now,\n-// all we do is split the partition spec (year=2014/month=24) into filter expression year='2014' and month='24' and\n-// rely on metastore database to deal with type conversions. Ideally, PartitionExpressionProxy default implementation\n-// should use SearchArgument (storage-api) to construct the filter expression and not depend on ql, but the usecase\n-// for msck is pretty simple and this specific implementation should suffice.", "originalCommit": "b2d6235d46e73a1966f37d3ef0d87279780b93aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM0NjE0OQ==", "url": "https://github.com/apache/hive/pull/1271#discussion_r485346149", "bodyText": "Hm..hm.. using SARG will complicate a lot i guess and moving ExprNode related classes from ql is not trivial (we could explore this a bit further) but looking at a big picture most of the ExprNode classes is dependent on serde classes since we don't want serde classes in standalone-metastore We should either put the ExprNode related class in some other module or new a new module which both ql and standalone-metastore can use.\nI could think of an another approach even though it is hacky, It solves the purpose. - Since PartitionExpressionForMetastore class is required only during partition pruning step, We can switch back the expression proxy class to MsckPartitionExpressionProxy once the partition pruning step is done. This way we could solve the compatability issue.\n@kgyrtkirk Any thoughts on validity of the above approach?", "author": "shameersss1", "createdAt": "2020-09-09T05:26:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk0OTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM5MzQ5NA==", "url": "https://github.com/apache/hive/pull/1271#discussion_r485393494", "bodyText": "or another approach could be when we fail to deserizalize the expr bytes with kyro on exception simply try converting byte array to string", "author": "shameersss1", "createdAt": "2020-09-09T07:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk0OTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTM5Mzg2MA==", "url": "https://github.com/apache/hive/pull/1271#discussion_r485393860", "bodyText": "@kgyrtkirk Any thoughts on above two approaches?", "author": "shameersss1", "createdAt": "2020-09-09T07:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk0OTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjIyMDk5Ng==", "url": "https://github.com/apache/hive/pull/1271#discussion_r486220996", "bodyText": "I have changed the approach, Please take a look at the new implementation.", "author": "shameersss1", "createdAt": "2020-09-10T10:07:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk0OTE0NA=="}], "type": "inlineReview", "revised_code": {"commit": "1b4e3836b827d8573459f60b18d290e29ff4b5db", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MsckPartitionExpressionProxy.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MsckPartitionExpressionProxy.java\nnew file mode 100644\nindex 0000000000..0ba2f2b95f\n--- /dev/null\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/MsckPartitionExpressionProxy.java\n\n@@ -0,0 +1,114 @@\n+package org.apache.hadoop.hive.metastore;\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.FileMetadataExprType;\n+import org.apache.hadoop.hive.metastore.api.MetaException;\n+import org.apache.hadoop.hive.metastore.utils.FileUtils;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.util.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+// This is added as part of moving MSCK code from ql to standalone-metastore. There is a metastore API to drop\n+// partitions by name but we cannot use it because msck typically will contain partition value (year=2014). We almost\n+// never drop partition by name (year). So we need to construct expression filters, the current\n+// PartitionExpressionProxy implementations (PartitionExpressionForMetastore and HCatClientHMSImpl.ExpressionBuilder)\n+// all depend on ql code to build ExprNodeDesc for the partition expressions. It also depends on kryo for serializing\n+// the expression objects to byte[]. For MSCK drop partition, we don't need complex expression generator. For now,\n+// all we do is split the partition spec (year=2014/month=24) into filter expression year='2014' and month='24' and\n+// rely on metastore database to deal with type conversions. Ideally, PartitionExpressionProxy default implementation\n+// should use SearchArgument (storage-api) to construct the filter expression and not depend on ql, but the usecase\n+// for msck is pretty simple and this specific implementation should suffice.\n+public class MsckPartitionExpressionProxy implements PartitionExpressionProxy {\n+  private static final Logger LOG = LoggerFactory.getLogger(MsckPartitionExpressionProxy.class);\n+\n+  @Override\n+  public String convertExprToFilter(final byte[] exprBytes, final String defaultPartitionName, boolean useStringConversion) throws MetaException {\n+    return new String(exprBytes, StandardCharsets.UTF_8);\n+  }\n+\n+  @Override\n+  public boolean filterPartitionsByExpr(List<FieldSchema> partColumns, byte[] expr, String\n+    defaultPartitionName, List<String> partitionNames) throws MetaException {\n+    String partExpr = new String(expr, StandardCharsets.UTF_8);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Partition expr: {}\", expr);\n+    }\n+    //This is to find in partitionNames all that match expr\n+    //reverse of the Msck.makePartExpr\n+    Set<String> partValueSet = new HashSet<>();\n+    String[] parts = partExpr.split(\" AND \");\n+    for ( String part : parts){\n+      String[] colAndValue = part.split(\"=\");\n+      String key = FileUtils.unescapePathName(colAndValue[0]);\n+      //take the value inside without the single quote marks '2018-10-30' becomes 2018-10-31\n+      String value = FileUtils.unescapePathName(colAndValue[1].substring(1, colAndValue[1].length()-1));\n+      partValueSet.add(key+\"=\"+value);\n+    }\n+\n+    List<String> partNamesSeq =  new ArrayList<>();\n+    for (String partition : partitionNames){\n+      boolean isMatch = true;\n+      //list of partitions [year=2001/month=1, year=2002/month=2, year=2001/month=3]\n+      //Given expr: e.g. year='2001' AND month='1'. Only when all the expressions in the expr can be found,\n+      //do we add the partition to the filtered result [year=2001/month=1]\n+      String [] partnames = partition.split(\"/\");\n+      for (String part: partnames) {\n+        if (!partValueSet.contains(FileUtils.unescapePathName(part))){\n+          isMatch = false;\n+          break;\n+        }\n+      }\n+      if (isMatch){\n+        partNamesSeq.add(partition);\n+      }\n+    }\n+    partitionNames.clear();\n+    partitionNames.addAll(partNamesSeq);\n+    LOG.info(\"The returned partition list is of size: {}\", partitionNames.size());\n+    if (LOG.isDebugEnabled()) {\n+      for(String s : partitionNames){\n+        LOG.debug(\"Matched partition: {}\", s);\n+      }\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public FileMetadataExprType getMetadataType(String inputFormat) {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public FileFormatProxy getFileFormatProxy(FileMetadataExprType type) {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public SearchArgument createSarg(byte[] expr) {\n+    throw new UnsupportedOperationException();\n+  }\n+}\n"}}, {"oid": "1b4e3836b827d8573459f60b18d290e29ff4b5db", "url": "https://github.com/apache/hive/commit/1b4e3836b827d8573459f60b18d290e29ff4b5db", "message": "HIVE-23851: MSCK REPAIR Command With Partition Filtering Fails While Dropping Partitions", "committedDate": "2020-09-09T11:18:45Z", "type": "commit"}, {"oid": "822d80aeab42d00bd54ed2ff775937edd2dc6640", "url": "https://github.com/apache/hive/commit/822d80aeab42d00bd54ed2ff775937edd2dc6640", "message": "Refactorig", "committedDate": "2020-09-09T14:08:46Z", "type": "commit"}, {"oid": "18fad95a2fc2031d0bb1484ba9e10386d12219aa", "url": "https://github.com/apache/hive/commit/18fad95a2fc2031d0bb1484ba9e10386d12219aa", "message": "Renaming flags", "committedDate": "2020-09-09T14:37:50Z", "type": "commit"}, {"oid": "18fad95a2fc2031d0bb1484ba9e10386d12219aa", "url": "https://github.com/apache/hive/commit/18fad95a2fc2031d0bb1484ba9e10386d12219aa", "message": "Renaming flags", "committedDate": "2020-09-09T14:37:50Z", "type": "forcePushed"}, {"oid": "a61a2a5fdf78d7f129449a4490b66e06073f9a32", "url": "https://github.com/apache/hive/commit/a61a2a5fdf78d7f129449a4490b66e06073f9a32", "message": "Refactoring", "committedDate": "2020-09-29T07:37:52Z", "type": "commit"}]}