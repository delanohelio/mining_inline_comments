{"pr_number": 1222, "pr_title": "HIVE-23814: Clean up Driver (Miklos Gergely)", "pr_createdAt": "2020-07-08T08:22:50Z", "pr_url": "https://github.com/apache/hive/pull/1222", "timeline": [{"oid": "035b689f3cbe65e1582f565721aeffec19c96072", "url": "https://github.com/apache/hive/commit/035b689f3cbe65e1582f565721aeffec19c96072", "message": "HIVE-23814: Clean up Driver (Miklos Gergely)", "committedDate": "2020-07-10T13:02:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1MzExMQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453153111", "bodyText": "Shouldn't this be the first thing in the life cycle? Or minimally in this method? Previous code paths might already started to use the perf logger.", "author": "pvary", "createdAt": "2020-07-11T04:19:49Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1MzQxNw==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453153417", "bodyText": "I had to read this comment several times to understand. Does this mean:\n\"A single Driver can run multiple queries at the same time, and txn manager is shared between these queries\"?\nMaybe some rewording could help", "author": "pvary", "createdAt": "2020-07-11T04:23:38Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-    driverTxnHandler.setContext(context);\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1Mzc5Nw==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453153797", "bodyText": "It might be better message that it was interrupted \"before acquiring the locks\"\nAlso getting the locks might take serious amount of time, so it might worth check for interrupt after it too. What do you think", "author": "pvary", "createdAt": "2020-07-11T04:28:28Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-    driverTxnHandler.setContext(context);\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+      context.setHiveTxnManager(driverContext.getTxnManager());\n \n-  private void setQueryId() {\n-    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n-        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n+      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NDA2MQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453154061", "bodyText": "Putting this to the \"else\" part seems counterintuitive for me", "author": "pvary", "createdAt": "2020-07-11T04:31:31Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-    driverTxnHandler.setContext(context);\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+      context.setHiveTxnManager(driverContext.getTxnManager());\n \n-  private void setQueryId() {\n-    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n-        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n+      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n \n-    SparkSession ss = SessionState.get().getSparkSession();\n-    if (ss != null) {\n-      ss.onQuerySubmission(queryId);\n-    }\n-    driverContext.getQueryDisplay().setQueryId(queryId);\n+      lockAndRespond();\n+      validateTxnListState();\n+      execute();\n+      driverTxnHandler.handleTransactionAfterExecution();\n \n-    setTriggerContext(queryId);\n-  }\n+      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n+      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n \n-  private void setTriggerContext(String queryId) {\n-    long queryStartTime;\n-    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n-    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n-    // the time when query display object is created)\n-    if (driverContext.getQueryInfo() != null) {\n-      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n-    } else {\n-      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n+      runPostDriverHooks(hookContext);\n+      isFinishedWithError = false;\n+    } finally {\n+      if (driverState.isAborted()) {\n+        closeInProcess(true);\n+      } else {\n+        releaseResources();", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NDIzNw==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453154237", "bodyText": "This will collide @mustafaiman's concurrent pull request. You might have to rebase this change", "author": "pvary", "createdAt": "2020-07-11T04:34:18Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-    driverTxnHandler.setContext(context);\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+      context.setHiveTxnManager(driverContext.getTxnManager());\n \n-  private void setQueryId() {\n-    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n-        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n+      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n \n-    SparkSession ss = SessionState.get().getSparkSession();\n-    if (ss != null) {\n-      ss.onQuerySubmission(queryId);\n-    }\n-    driverContext.getQueryDisplay().setQueryId(queryId);\n+      lockAndRespond();\n+      validateTxnListState();\n+      execute();\n+      driverTxnHandler.handleTransactionAfterExecution();\n \n-    setTriggerContext(queryId);\n-  }\n+      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n+      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n \n-  private void setTriggerContext(String queryId) {\n-    long queryStartTime;\n-    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n-    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n-    // the time when query display object is created)\n-    if (driverContext.getQueryInfo() != null) {\n-      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n-    } else {\n-      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n+      runPostDriverHooks(hookContext);\n+      isFinishedWithError = false;\n+    } finally {\n+      if (driverState.isAborted()) {\n+        closeInProcess(true);\n+      } else {\n+        releaseResources();\n+      }\n+\n+      driverState.executionFinishedWithLocking(isFinishedWithError);\n     }\n-    WmContext wmContext = new WmContext(queryStartTime, queryId);\n-    context.setWmContext(wmContext);\n-  }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n+    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n   }\n \n-  /**\n-   * @return The current query plan associated with this Driver, if any.\n-   */\n-  @Override\n-  public QueryPlan getPlan() {\n-    return driverContext.getPlan();\n+  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n+    driverState.lock();\n+    try {\n+      if (alreadyCompiled) {\n+        if (driverState.isCompiled()) {\n+          driverState.executing();\n+        } else {\n+          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n+          CONSOLE.printError(errorMessage);\n+          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n+        }\n+      } else {\n+        driverState.compiling();\n+      }\n+    } finally {\n+      driverState.unlock();\n+    }\n   }\n \n-  /**\n-   * @return The current FetchTask associated with the Driver's plan, if any.\n-   */\n-  @Override\n-  public FetchTask getFetchTask() {\n-    return driverContext.getFetchTask();\n+  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n+    try {\n+      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n+    } catch (Exception e) {\n+      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n+      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n+      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n+          ErrorMsg.findSQLState(e.getMessage()), e);\n+    }\n   }\n \n-  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n-    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n-  }\n+  public void lockAndRespond() throws CommandProcessorException {\n+    // Assumes the query has already been compiled\n+    if (driverContext.getPlan() == null) {\n+      throw new IllegalStateException(\n+          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n+    }\n \n-  /**\n-   * @param commit if there is an open transaction and if true, commit,\n-   *               if false rollback.  If there is no open transaction this parameter is ignored.\n-   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n-   *\n-   **/\n-  @VisibleForTesting\n-  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n-    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n+    try {\n+      driverTxnHandler.acquireLocksIfNeeded();\n+    } catch (CommandProcessorException cpe) {\n+      driverTxnHandler.rollback(cpe);\n+      throw cpe;\n+    }\n   }\n \n-  /**\n-   * Release some resources after a query is executed\n-   * while keeping the result around.\n-   */\n-  public void releaseResources() {\n-    releasePlan();\n-    releaseTaskQueue();\n+  private void validateTxnListState() throws CommandProcessorException {\n+    try {\n+      if (!driverTxnHandler.isValidTxnListState()) {\n+        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n+        // Snapshot was outdated when locks were acquired, hence regenerate context,\n+        // txn list and retry (see ReExecutionRetryLockPlugin)\n+        try {\n+          driverTxnHandler.releaseLocksAndCommitOrRollback(false);", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NDY3Mw==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453154673", "bodyText": "We still do not want to get rid of this method here and call the txnmanager directly?", "author": "pvary", "createdAt": "2020-07-11T04:40:34Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -410,260 +386,304 @@ private void compileInternal(String command, boolean deferClose) throws CommandP\n       }\n     }\n     //Save compile-time PerfLogging for WebUI.\n-    //Execution-time Perf logs are done by either another thread's PerfLogger\n-    //or a reset PerfLogger.\n+    //Execution-time Perf logs are done by either another thread's PerfLogger or a reset PerfLogger.\n     driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.COMPILATION, perfLogger.getStartTimes());\n     driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.COMPILATION, perfLogger.getEndTimes());\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  /**\n+   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n+   * is useful for generating re-entrant QL queries.\n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n+  }\n+\n+  // deferClose indicates if the close/destroy should be deferred when the process has been\n+  // interrupted, it should be set to true if the compile is called within another method like\n+  // runInternal, which defers the close to the called in that method.\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n+\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n+\n+    compileFinished(deferClose);\n+  }\n+\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n+    prepareContext();\n+    setQueryId();\n \n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n+\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n     }\n \n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n     try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      // Get all the driver run hooks and pre-execute them.\n-      try {\n-        driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-      } catch (Exception e) {\n-        String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-        CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-        throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-            ErrorMsg.findSQLState(e.getMessage()), e);\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n       }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      if (!alreadyCompiled) {\n-        // compile internal will automatically reset the perf logger\n-        compileInternal(command, true);\n-      } else {\n-        // Since we're reusing the compiled plan, we need to update its start time for current run\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n+\n+    driverTxnHandler.setContext(context);\n+  }\n+\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n+\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n+    }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n+\n+    setTriggerContext(queryId);\n+  }\n+\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n+    }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n+  }\n \n-      //Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each\n-      // query has its own ctx object. The txn mgr is shared across the\n-      // same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n+  }\n \n-      lockAndRespond();\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -384,306 +417,197 @@ private void compileInternal(String command, boolean deferClose) throws CommandP\n         }\n         throw cpe;\n       }\n-    }\n-    //Save compile-time PerfLogging for WebUI.\n-    //Execution-time Perf logs are done by either another thread's PerfLogger or a reset PerfLogger.\n-    driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.COMPILATION, perfLogger.getStartTimes());\n-    driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.COMPILATION, perfLogger.getEndTimes());\n-  }\n-\n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n-  }\n-\n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n-  }\n-\n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n-\n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n-    }\n-  }\n-\n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n-\n-    try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n-      }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n-\n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n-\n-    driverTxnHandler.setContext(context);\n-  }\n-\n-  private void setQueryId() {\n-    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n-        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n-\n-    SparkSession ss = SessionState.get().getSparkSession();\n-    if (ss != null) {\n-      ss.onQuerySubmission(queryId);\n-    }\n-    driverContext.getQueryDisplay().setQueryId(queryId);\n-\n-    setTriggerContext(queryId);\n-  }\n-\n-  private void setTriggerContext(String queryId) {\n-    long queryStartTime;\n-    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n-    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n-    // the time when query display object is created)\n-    if (driverContext.getQueryInfo() != null) {\n-      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n-    } else {\n-      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n-    }\n-    WmContext wmContext = new WmContext(queryStartTime, queryId);\n-    context.setWmContext(wmContext);\n-  }\n-\n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n-  }\n-\n-  /**\n-   * @return The current query plan associated with this Driver, if any.\n-   */\n-  @Override\n-  public QueryPlan getPlan() {\n-    return driverContext.getPlan();\n+    }\n+    //Save compile-time PerfLogging for WebUI.\n+    //Execution-time Perf logs are done by either another thread's PerfLogger\n+    //or a reset PerfLogger.\n+    driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.COMPILATION, perfLogger.getStartTimes());\n+    driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.COMPILATION, perfLogger.getEndTimes());\n   }\n \n-  /**\n-   * @return The current FetchTask associated with the Driver's plan, if any.\n-   */\n-  @Override\n-  public FetchTask getFetchTask() {\n-    return driverContext.getFetchTask();\n-  }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n \n-  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n-    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n-  }\n+    driverState.lock();\n+    try {\n+      if (alreadyCompiled) {\n+        if (driverState.isCompiled()) {\n+          driverState.executing();\n+        } else {\n+          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n+          CONSOLE.printError(errorMessage);\n+          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n+        }\n+      } else {\n+        driverState.compiling();\n+      }\n+    } finally {\n+      driverState.unlock();\n+    }\n \n-  /**\n-   * @param commit if there is an open transaction and if true, commit,\n-   *               if false rollback.  If there is no open transaction this parameter is ignored.\n-   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n-   *\n-   **/\n-  @VisibleForTesting\n-  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n-    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n-  }\n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n+    try {\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      // Get all the driver run hooks and pre-execute them.\n+      try {\n+        driverContext.getHookRunner().runPreDriverHooks(hookContext);\n+      } catch (Exception e) {\n+        String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n+        CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n+        throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n+            ErrorMsg.findSQLState(e.getMessage()), e);\n+      }\n \n-  /**\n-   * Release some resources after a query is executed while keeping the result around.\n-   */\n-  public void releaseResources() {\n-    releasePlan();\n-    releaseTaskQueue();\n-  }\n+      if (!alreadyCompiled) {\n+        // compile internal will automatically reset the perf logger\n+        compileInternal(command, true);\n+      } else {\n+        // Since we're reusing the compiled plan, we need to update its start time for current run\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n+      }\n \n-  public PlanMapper getPlanMapper() {\n-    return context.getPlanMapper();\n-  }\n+      //Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-  @Override\n-  public boolean isFetchingTable() {\n-    return driverContext.getFetchTask() != null;\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each\n+      // query has its own ctx object. The txn mgr is shared across the\n+      // same instance of Driver, which can run multiple queries.\n+      context.setHiveTxnManager(driverContext.getTxnManager());\n \n-  @Override\n-  public Schema getSchema() {\n-    return driverContext.getSchema();\n-  }\n+      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n \n-  @Override\n-  public boolean hasResultSet() {\n-    // TODO explain should use a FetchTask for reading\n-    for (Task<?> task : driverContext.getPlan().getRootTasks()) {\n-      if (task.getClass() == ExplainTask.class) {\n-        return true;\n+      lockAndRespond();\n+      driverTxnHandler.validateTxnListState();\n+\n+      try {\n+        taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n+        Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n+        executor.execute();\n+      } catch (CommandProcessorException cpe) {\n+        driverTxnHandler.rollback(cpe);\n+        throw cpe;\n       }\n-    }\n \n-    return driverContext.getPlan().getFetchTask() != null && driverContext.getPlan().getResultSchema() != null &&\n-        driverContext.getPlan().getResultSchema().isSetFieldSchemas();\n-  }\n+      //if needRequireLock is false, the release here will do nothing because there is no lock\n+      driverTxnHandler.handleTransactionAfterExecution();\n \n-  @Override\n-  public void resetFetch() throws IOException {\n-    if (driverState.isDestroyed() || driverState.isClosed()) {\n-      throw new IOException(\"FAILED: driver has been cancelled, closed or destroyed.\");\n-    }\n-    if (isFetchingTable()) {\n+      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n+      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+\n+      // Take all the driver run hooks and post-execute them.\n       try {\n-        driverContext.getFetchTask().clearFetch();\n+        driverContext.getHookRunner().runPostDriverHooks(hookContext);\n       } catch (Exception e) {\n-        throw new IOException(\"Error closing the current fetch task\", e);\n+        String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n+        CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n+        throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n+            ErrorMsg.findSQLState(e.getMessage()), e);\n       }\n-      // FetchTask should not depend on the plan.\n-      driverContext.getFetchTask().initialize(driverContext.getQueryState(), null, null, context);\n-    } else {\n-      context.resetStream();\n-      driverContext.setResStream(null);\n+      isFinishedWithError = false;\n+    } finally {\n+      if (driverState.isAborted()) {\n+        closeInProcess(true);\n+      } else {\n+        // only release the related resources ctx, taskQueue as normal\n+        releaseResources();\n+      }\n+\n+      driverState.executionFinishedWithLocking(isFinishedWithError);\n     }\n+\n+    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n   }\n \n-  /**\n-   * Set the maximum number of rows returned by getResults.\n-   */\n   @Override\n-  public void setMaxRows(int maxRows) {\n-    this.maxRows = maxRows;\n+  public boolean isFetchingTable() {\n+    return driverContext.getFetchTask() != null;\n   }\n \n   @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n   @Override\n-  public boolean getResults(List results) throws IOException {\n+  public boolean getResults(List res) throws IOException {\n     if (driverState.isDestroyed() || driverState.isClosed()) {\n       throw new IOException(\"FAILED: query has been cancelled, closed, or destroyed.\");\n     }\n \n     if (isFetchingTable()) {\n-      return getFetchingTableResults(results);\n+      /**\n+       * If resultset serialization to thrift object is enabled, and if the destination table is\n+       * indeed written using ThriftJDBCBinarySerDe, read one row from the output sequence file,\n+       * since it is a blob of row batches.\n+       */\n+      if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n+        maxRows = 1;\n+      }\n+      driverContext.getFetchTask().setMaxRows(maxRows);\n+      return driverContext.getFetchTask().fetch(res);\n     }\n \n     if (driverContext.getResStream() == null) {\n       driverContext.setResStream(context.getStream());\n-      if (driverContext.getResStream() == null) {\n-        return false;\n-      }\n+    }\n+    if (driverContext.getResStream() == null) {\n+      return false;\n     }\n \n     int numRows = 0;\n-    ByteStream.Output bos = new ByteStream.Output();\n+\n     while (numRows < maxRows) {\n+      final String row;\n+\n       if (driverContext.getResStream() == null) {\n         return (numRows > 0);\n       }\n \n       bos.reset();\n-      Utilities.StreamStatus streamStatus;\n+      Utilities.StreamStatus ss;\n       try {\n-        streamStatus = Utilities.readColumn(driverContext.getResStream(), bos);\n-        String row = getRow(bos, streamStatus);\n+        ss = Utilities.readColumn(driverContext.getResStream(), bos);\n+        if (bos.getLength() > 0) {\n+          row = new String(bos.getData(), 0, bos.getLength(), StandardCharsets.UTF_8);\n+        } else if (ss == Utilities.StreamStatus.TERMINATED) {\n+          row = \"\";\n+        } else {\n+          row = null;\n+        }\n+\n         if (row != null) {\n           numRows++;\n-          results.add(row);\n+          res.add(row);\n         }\n       } catch (IOException e) {\n         CONSOLE.printError(\"FAILED: Unexpected IO exception : \" + e.getMessage());\n         return false;\n       }\n \n-      if (streamStatus == Utilities.StreamStatus.EOF) {\n+      if (ss == Utilities.StreamStatus.EOF) {\n         driverContext.setResStream(context.getStream());\n       }\n     }\n     return true;\n   }\n \n-  @SuppressWarnings(\"rawtypes\")\n-  private boolean getFetchingTableResults(List results) throws IOException {\n-    // If result set serialization to thrift object is enabled, and if the destination table is indeed written using\n-    // ThriftJDBCBinarySerDe, read one row from the output sequence file, since it is a blob of row batches.\n-    if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n-      maxRows = 1;\n-    }\n-    driverContext.getFetchTask().setMaxRows(maxRows);\n-    return driverContext.getFetchTask().fetch(results);\n-  }\n-\n-  private String getRow(ByteStream.Output bos, Utilities.StreamStatus streamStatus) {\n-    String row;\n-    if (bos.getLength() > 0) {\n-      row = new String(bos.getData(), 0, bos.getLength(), StandardCharsets.UTF_8);\n-    } else if (streamStatus == Utilities.StreamStatus.TERMINATED) {\n-      row = \"\";\n-    } else {\n-      row = null;\n-    }\n-    return row;\n-  }\n-\n-  // Close and release resources within a running query process. Since it runs under\n-  // driver state COMPILING, EXECUTING or INTERRUPT, it would not have race condition\n-  // with the releases probably running in the other closing thread.\n-  private int closeInProcess(boolean destroyed) {\n-    releaseTaskQueue();\n-    releasePlan();\n-    releaseCachedResult();\n-    releaseFetchTask();\n-    releaseResStream();\n-    releaseContext();\n-    if (destroyed) {\n-      driverTxnHandler.release();\n-    }\n-    return 0;\n-  }\n-\n-  // is called to stop the query if it is running, clean query results, and release resources.\n   @Override\n-  public void close() {\n-    driverState.lock();\n-    try {\n-      releaseTaskQueue();\n-      if (driverState.isCompiling() || driverState.isExecuting()) {\n-        driverState.abort();\n+  public void resetFetch() throws IOException {\n+    if (driverState.isDestroyed() || driverState.isClosed()) {\n+      throw new IOException(\"FAILED: driver has been cancelled, closed or destroyed.\");\n+    }\n+    if (isFetchingTable()) {\n+      try {\n+        driverContext.getFetchTask().clearFetch();\n+      } catch (Exception e) {\n+        throw new IOException(\"Error closing the current fetch task\", e);\n       }\n-      releasePlan();\n-      releaseContext();\n-      releaseCachedResult();\n-      releaseFetchTask();\n-      releaseResStream();\n-      driverState.closed();\n-    } finally {\n-      driverState.unlock();\n-      DriverState.removeDriverState();\n+      // FetchTask should not depend on the plan.\n+      driverContext.getFetchTask().initialize(driverContext.getQueryState(), null, null, context);\n+    } else {\n+      context.resetStream();\n+      driverContext.setResStream(null);\n     }\n-    destroy();\n   }\n \n   // TaskQueue could be released in the query and close processes at same\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NTI1OA==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453155258", "bodyText": "How could this happen? Maybe at least a debug level log would be good.", "author": "pvary", "createdAt": "2020-07-11T04:49:00Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java", "diffHunk": "@@ -529,6 +529,34 @@ private void addTableFromEntity(Entity entity, Map<String, Table> tables) {\n       .collect(Collectors.toList());\n   }\n \n+  void rollback(CommandProcessorException cpe) throws CommandProcessorException {\n+    try {\n+      releaseLocksAndCommitOrRollback(false);\n+    } catch (LockException e) {\n+      LOG.error(\"rollback() FAILED: \" + cpe); //make sure not to loose\n+      DriverUtils.handleHiveException(driverContext, e, 12, \"Additional info in hive.log at \\\"rollback() FAILED\\\"\");\n+    }\n+  }\n+\n+  void handleTransactionAfterExecution() throws CommandProcessorException {\n+    try {\n+      if (driverContext.getTxnManager().isImplicitTransactionOpen() ||\n+          driverContext.getPlan().getOperation() == HiveOperation.COMMIT) {\n+        releaseLocksAndCommitOrRollback(true);\n+      } else if (driverContext.getPlan().getOperation() == HiveOperation.ROLLBACK) {\n+        releaseLocksAndCommitOrRollback(false);\n+      } else if (!driverContext.getTxnManager().isTxnOpen() &&\n+          driverContext.getQueryState().getHiveOperation() == HiveOperation.REPLLOAD) {\n+        // repl load during migration, commits the explicit txn and start some internal txns. Call\n+        // releaseLocksAndCommitOrRollback to do the clean up.\n+        releaseLocksAndCommitOrRollback(false);\n+      }\n+      // if none of the above is true, then txn (if there is one started) is not finished", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java\nindex 7b1f2e2ac5..a2aba8a89a 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java\n\n@@ -522,13 +543,6 @@ private void addTableFromEntity(Entity entity, Map<String, Table> tables) {\n     tables.put(fullTableName, table);\n   }\n \n-  private List<String> getTransactionalTables(Map<String, Table> tables) {\n-    return tables.entrySet().stream()\n-      .filter(entry -> AcidUtils.isTransactionalTable(entry.getValue()))\n-      .map(Map.Entry::getKey)\n-      .collect(Collectors.toList());\n-  }\n-\n   void rollback(CommandProcessorException cpe) throws CommandProcessorException {\n     try {\n       releaseLocksAndCommitOrRollback(false);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NTUyMQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453155521", "bodyText": "What does this public method do? Javadoc might be useful", "author": "pvary", "createdAt": "2020-07-11T04:52:09Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NTU4NQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453155585", "bodyText": "Javadoc maybe here too, but at least it is easier to understand :)", "author": "pvary", "createdAt": "2020-07-11T04:53:01Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NTgzMQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453155831", "bodyText": "Maybe Javadoc here?", "author": "pvary", "createdAt": "2020-07-11T04:56:27Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    if (resetTaskIds) {\n-      TaskFactory.resetId();\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    try {\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      processRunException(cpe);\n+      throw cpe;\n     }\n   }\n \n-  private void prepareContext() throws CommandProcessorException {\n-    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n-      // close the existing ctx etc before compiling a new query, but does not destroy driver\n-      closeInProcess(false);\n-    }\n+  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+    DriverState.setDriverState(driverState);\n+    setInitialStateForRun(alreadyCompiled);\n \n+    // a flag that helps to set the correct driver state in finally block by tracking if\n+    // the method has been returned by an error or not.\n+    boolean isFinishedWithError = true;\n     try {\n-      if (context == null) {\n-        context = new Context(driverContext.getConf());\n+      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n+          alreadyCompiled ? context.getCmd() : command);\n+      runPreDriverHooks(hookContext);\n+\n+      if (!alreadyCompiled) {\n+        compileInternal(command, true);\n+      } else {\n+        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n       }\n-    } catch (IOException e) {\n-      throw new CommandProcessorException(e);\n-    }\n \n-    context.setHiveTxnManager(driverContext.getTxnManager());\n-    context.setStatsSource(driverContext.getStatsSource());\n-    context.setHDFSCleanup(true);\n+      // Reset the PerfLogger so that it doesn't retain any previous values.\n+      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n+      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n \n-    driverTxnHandler.setContext(context);\n-  }\n+      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+      context.setHiveTxnManager(driverContext.getTxnManager());\n \n-  private void setQueryId() {\n-    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n-        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n+      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n \n-    SparkSession ss = SessionState.get().getSparkSession();\n-    if (ss != null) {\n-      ss.onQuerySubmission(queryId);\n-    }\n-    driverContext.getQueryDisplay().setQueryId(queryId);\n+      lockAndRespond();\n+      validateTxnListState();\n+      execute();\n+      driverTxnHandler.handleTransactionAfterExecution();\n \n-    setTriggerContext(queryId);\n-  }\n+      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n+      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n \n-  private void setTriggerContext(String queryId) {\n-    long queryStartTime;\n-    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n-    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n-    // the time when query display object is created)\n-    if (driverContext.getQueryInfo() != null) {\n-      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n-    } else {\n-      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n+      runPostDriverHooks(hookContext);\n+      isFinishedWithError = false;\n+    } finally {\n+      if (driverState.isAborted()) {\n+        closeInProcess(true);\n+      } else {\n+        releaseResources();\n+      }\n+\n+      driverState.executionFinishedWithLocking(isFinishedWithError);\n     }\n-    WmContext wmContext = new WmContext(queryStartTime, queryId);\n-    context.setWmContext(wmContext);\n-  }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n+    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n   }\n \n-  /**\n-   * @return The current query plan associated with this Driver, if any.\n-   */\n-  @Override\n-  public QueryPlan getPlan() {\n-    return driverContext.getPlan();\n+  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n+    driverState.lock();\n+    try {\n+      if (alreadyCompiled) {\n+        if (driverState.isCompiled()) {\n+          driverState.executing();\n+        } else {\n+          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n+          CONSOLE.printError(errorMessage);\n+          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n+        }\n+      } else {\n+        driverState.compiling();\n+      }\n+    } finally {\n+      driverState.unlock();\n+    }\n   }\n \n-  /**\n-   * @return The current FetchTask associated with the Driver's plan, if any.\n-   */\n-  @Override\n-  public FetchTask getFetchTask() {\n-    return driverContext.getFetchTask();\n+  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n+    try {\n+      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n+    } catch (Exception e) {\n+      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n+      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n+      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n+          ErrorMsg.findSQLState(e.getMessage()), e);\n+    }\n   }\n \n-  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n-    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n-  }\n+  public void lockAndRespond() throws CommandProcessorException {", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NjM2Ng==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453156366", "bodyText": "Won't we miss this state setting?", "author": "pvary", "createdAt": "2020-07-11T05:03:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1NjQwNQ==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453156405", "bodyText": "Won't we miss setting the query id?", "author": "pvary", "createdAt": "2020-07-11T05:03:46Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -139,205 +119,215 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  /**\n-   * Compile a new query, but potentially reset taskID counter.  Not resetting task counter\n-   * is useful for generating re-entrant QL queries.\n-   * @param command  The HiveQL query to compile\n-   * @param resetTaskIds Resets taskID counter if true.\n-   * @return 0 for ok\n-   */\n-  public int compile(String command, boolean resetTaskIds) {\n-    try {\n-      compile(command, resetTaskIds, false);\n-      return 0;\n-    } catch (CommandProcessorException cpr) {\n-      return cpr.getErrorCode();\n-    }\n+  @Override\n+  public Context getContext() {\n+    return context;\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n-  @VisibleForTesting\n-  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n-    preparForCompile(resetTaskIds);\n-\n-    Compiler compiler = new Compiler(context, driverContext, driverState);\n-    QueryPlan plan = compiler.compile(command, deferClose);\n-    driverContext.setPlan(plan);\n-\n-    compileFinished(deferClose);\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  private void compileFinished(boolean deferClose) {\n-    if (DriverState.getDriverState().isAborted() && !deferClose) {\n-      closeInProcess(true);\n-    }\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n   }\n \n-  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n-    driverTxnHandler.createTxnManager();\n-    DriverState.setDriverState(driverState);\n-    prepareContext();\n-    setQueryId();", "originalCommit": "035b689f3cbe65e1582f565721aeffec19c96072", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1317d03009b40b00229088e68caeec98b52e269d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex c97674b602..94e78edb22 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -119,215 +140,213 @@ public Driver(QueryState queryState, QueryInfo queryInfo, HiveTxnManager txnMana\n     driverTxnHandler = new DriverTxnHandler(this, driverContext, driverState);\n   }\n \n-  @Override\n-  public Context getContext() {\n-    return context;\n+  /**\n+   * Compile a new query, but potentially reset taskID counter. Not resetting task counter is useful for generating\n+   * re-entrant QL queries.\n+   * \n+   * @param command  The HiveQL query to compile\n+   * @param resetTaskIds Resets taskID counter if true.\n+   * @return 0 for ok\n+   */\n+  public int compile(String command, boolean resetTaskIds) {\n+    try {\n+      compile(command, resetTaskIds, false);\n+      return 0;\n+    } catch (CommandProcessorException cpr) {\n+      return cpr.getErrorCode();\n+    }\n   }\n \n-  @Override\n-  public HiveConf getConf() {\n-    return driverContext.getConf();\n-  }\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n+   *             set to true if the compile is called within another method like runInternal, which defers the close to\n+   *             the called in that method.\n+   */\n+  @VisibleForTesting\n+  public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n+    preparForCompile(resetTaskIds);\n \n-  @Override\n-  public CommandProcessorResponse run() throws CommandProcessorException {\n-    return run(null, true);\n-  }\n+    Compiler compiler = new Compiler(context, driverContext, driverState);\n+    QueryPlan plan = compiler.compile(command, deferClose);\n+    driverContext.setPlan(plan);\n \n-  @Override\n-  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n-    return run(command, false);\n+    compileFinished(deferClose);\n   }\n \n-  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n-    try {\n-      runInternal(command, alreadyCompiled);\n-      return new CommandProcessorResponse(getSchema(), null);\n-    } catch (CommandProcessorException cpe) {\n-      processRunException(cpe);\n-      throw cpe;\n+  private void compileFinished(boolean deferClose) {\n+    if (DriverState.getDriverState().isAborted() && !deferClose) {\n+      closeInProcess(true);\n     }\n   }\n \n-  private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n+  private void preparForCompile(boolean resetTaskIds) throws CommandProcessorException {\n+    driverTxnHandler.createTxnManager();\n     DriverState.setDriverState(driverState);\n-    setInitialStateForRun(alreadyCompiled);\n-\n-    // a flag that helps to set the correct driver state in finally block by tracking if\n-    // the method has been returned by an error or not.\n-    boolean isFinishedWithError = true;\n-    try {\n-      HiveDriverRunHookContext hookContext = new HiveDriverRunHookContextImpl(driverContext.getConf(),\n-          alreadyCompiled ? context.getCmd() : command);\n-      runPreDriverHooks(hookContext);\n-\n-      if (!alreadyCompiled) {\n-        compileInternal(command, true);\n-      } else {\n-        driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-      }\n+    prepareContext();\n+    setQueryId();\n \n-      // Reset the PerfLogger so that it doesn't retain any previous values.\n-      // Any value from compilation phase can be obtained through the map set in queryDisplay during compilation.\n-      PerfLogger perfLogger = SessionState.getPerfLogger(true);\n+    if (resetTaskIds) {\n+      TaskFactory.resetId();\n+    }\n+  }\n \n-      // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n-      // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n-      context.setHiveTxnManager(driverContext.getTxnManager());\n+  private void prepareContext() throws CommandProcessorException {\n+    if (context != null && context.getExplainAnalyze() != AnalyzeState.RUNNING) {\n+      // close the existing ctx etc before compiling a new query, but does not destroy driver\n+      closeInProcess(false);\n+    }\n \n-      DriverUtils.checkInterrupted(driverState, driverContext, \"at acquiring the lock.\", null, null);\n+    try {\n+      if (context == null) {\n+        context = new Context(driverContext.getConf());\n+      }\n+    } catch (IOException e) {\n+      throw new CommandProcessorException(e);\n+    }\n \n-      lockAndRespond();\n-      validateTxnListState();\n-      execute();\n-      driverTxnHandler.handleTransactionAfterExecution();\n+    context.setHiveTxnManager(driverContext.getTxnManager());\n+    context.setStatsSource(driverContext.getStatsSource());\n+    context.setHDFSCleanup(true);\n \n-      driverContext.getQueryDisplay().setPerfLogStarts(QueryDisplay.Phase.EXECUTION, perfLogger.getStartTimes());\n-      driverContext.getQueryDisplay().setPerfLogEnds(QueryDisplay.Phase.EXECUTION, perfLogger.getEndTimes());\n+    driverTxnHandler.setContext(context);\n+  }\n \n-      runPostDriverHooks(hookContext);\n-      isFinishedWithError = false;\n-    } finally {\n-      if (driverState.isAborted()) {\n-        closeInProcess(true);\n-      } else {\n-        releaseResources();\n-      }\n+  private void setQueryId() {\n+    String queryId = Strings.isNullOrEmpty(driverContext.getQueryState().getQueryId()) ?\n+        QueryPlan.makeQueryId() : driverContext.getQueryState().getQueryId();\n \n-      driverState.executionFinishedWithLocking(isFinishedWithError);\n+    SparkSession ss = SessionState.get().getSparkSession();\n+    if (ss != null) {\n+      ss.onQuerySubmission(queryId);\n     }\n+    driverContext.getQueryDisplay().setQueryId(queryId);\n \n-    SessionState.getPerfLogger().cleanupPerfLogMetrics();\n+    setTriggerContext(queryId);\n   }\n \n-  private void setInitialStateForRun(boolean alreadyCompiled) throws CommandProcessorException {\n-    driverState.lock();\n-    try {\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+  private void setTriggerContext(String queryId) {\n+    long queryStartTime;\n+    // query info is created by SQLOperation which will have start time of the operation. When JDBC Statement is not\n+    // used queryInfo will be null, in which case we take creation of Driver instance as query start time (which is also\n+    // the time when query display object is created)\n+    if (driverContext.getQueryInfo() != null) {\n+      queryStartTime = driverContext.getQueryInfo().getBeginTime();\n+    } else {\n+      queryStartTime = driverContext.getQueryDisplay().getQueryStartTime();\n     }\n+    WmContext wmContext = new WmContext(queryStartTime, queryId);\n+    context.setWmContext(wmContext);\n   }\n \n-  private void runPreDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPreDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  @Override\n+  public HiveConf getConf() {\n+    return driverContext.getConf();\n   }\n \n-  public void lockAndRespond() throws CommandProcessorException {\n-    // Assumes the query has already been compiled\n-    if (driverContext.getPlan() == null) {\n-      throw new IllegalStateException(\n-          \"No previously compiled query for driver - queryId=\" + driverContext.getQueryState().getQueryId());\n-    }\n+  /**\n+   * @return The current query plan associated with this Driver, if any.\n+   */\n+  @Override\n+  public QueryPlan getPlan() {\n+    return driverContext.getPlan();\n+  }\n \n-    try {\n-      driverTxnHandler.acquireLocksIfNeeded();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @return The current FetchTask associated with the Driver's plan, if any.\n+   */\n+  @Override\n+  public FetchTask getFetchTask() {\n+    return driverContext.getFetchTask();\n   }\n \n-  private void validateTxnListState() throws CommandProcessorException {\n-    try {\n-      if (!driverTxnHandler.isValidTxnListState()) {\n-        LOG.warn(\"Reexecuting after acquiring locks, since snapshot was outdated.\");\n-        // Snapshot was outdated when locks were acquired, hence regenerate context,\n-        // txn list and retry (see ReExecutionRetryLockPlugin)\n-        try {\n-          driverTxnHandler.releaseLocksAndCommitOrRollback(false);\n-        } catch (LockException e) {\n-          DriverUtils.handleHiveException(driverContext, e, 12, null);\n-        }\n-        HiveException e = new HiveException(\n-            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n-        DriverUtils.handleHiveException(driverContext, e, 14, null);\n-      }\n-    } catch (LockException e) {\n-      DriverUtils.handleHiveException(driverContext, e, 13, null);\n-    }\n+  public void releaseLocksAndCommitOrRollback(boolean commit) throws LockException {\n+    releaseLocksAndCommitOrRollback(commit, driverContext.getTxnManager());\n   }\n \n-  private void execute() throws CommandProcessorException {\n-    try {\n-      taskQueue = new TaskQueue(context); // for canceling the query (should be bound to session?)\n-      Executor executor = new Executor(context, driverContext, driverState, taskQueue);\n-      executor.execute();\n-    } catch (CommandProcessorException cpe) {\n-      driverTxnHandler.rollback(cpe);\n-      throw cpe;\n-    }\n+  /**\n+   * @param commit if there is an open transaction and if true, commit,\n+   *               if false rollback.  If there is no open transaction this parameter is ignored.\n+   * @param txnManager an optional existing transaction manager retrieved earlier from the session\n+   *\n+   **/\n+  @VisibleForTesting\n+  public void releaseLocksAndCommitOrRollback(boolean commit, HiveTxnManager txnManager) throws LockException {\n+    driverTxnHandler.releaseLocksAndCommitOrRollback(commit, txnManager);\n   }\n \n-  private void runPostDriverHooks(HiveDriverRunHookContext hookContext) throws CommandProcessorException {\n-    try {\n-      driverContext.getHookRunner().runPostDriverHooks(hookContext);\n-    } catch (Exception e) {\n-      String errorMessage = \"FAILED: Hive Internal Error: \" + Utilities.getNameMessage(e);\n-      CONSOLE.printError(errorMessage + \"\\n\" + StringUtils.stringifyException(e));\n-      throw DriverUtils.createProcessorException(driverContext, 12, errorMessage,\n-          ErrorMsg.findSQLState(e.getMessage()), e);\n-    }\n+  /**\n+   * Release some resources after a query is executed\n+   * while keeping the result around.\n+   */\n+  public void releaseResources() {\n+    releasePlan();\n+    releaseTaskQueue();\n   }\n \n-  private void processRunException(CommandProcessorException cpe) {\n-    SessionState ss = SessionState.get();\n-    if (ss == null) {\n-      return;\n-    }\n+  /**\n+   * Compiles and executes an HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run(String command) throws CommandProcessorException {\n+    return run(command, false);\n+  }\n \n-    MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-    if (!(mdf instanceof JsonMetaDataFormatter)) {\n-      return;\n-    }\n+  /**\n+   * Executes a previously compiled HQL command.\n+   */\n+  @Override\n+  public CommandProcessorResponse run() throws CommandProcessorException {\n+    return run(null, true);\n+  }\n \n-    /* Here we want to encode the error in machine readable way (e.g. JSON). Ideally, errorCode would always be set\n-     * to a canonical error defined in ErrorMsg. In practice that is rarely the case, so the messy logic below tries\n-     * to tease out canonical error code if it can.  Exclude stack trace from output when the error is a\n-     * specific/expected one. It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+  private CommandProcessorResponse run(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     try {\n-      if (cpe.getCause() == null) {\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-        return;\n+      runInternal(command, alreadyCompiled);\n+      return new CommandProcessorResponse(getSchema(), null);\n+    } catch (CommandProcessorException cpe) {\n+      SessionState ss = SessionState.get();\n+      if (ss == null) {\n+        throw cpe;\n       }\n-      ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-      if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-        /* Some HiveExceptions (e.g. SemanticException) don't set canonical ErrorMsg explicitly, but there is logic\n-         * (e.g. #compile()) to find an appropriate canonical error and return its code as error code. In this case\n-         * we want to preserve it for downstream code to interpret*/\n-        mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-        return;\n+      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n+      if (!(mdf instanceof JsonMetaDataFormatter)) {\n+        throw cpe;\n       }\n-      if (cpe.getCause() instanceof HiveException) {\n-        HiveException rc = (HiveException)cpe.getCause();\n-        mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-            rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-      } else {\n-        ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-        mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-            StringUtils.stringifyException(cpe.getCause()));\n+      /*Here we want to encode the error in machine readable way (e.g. JSON)\n+       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n+       * In practice that is rarely the case, so the messy logic below tries to tease\n+       * out canonical error code if it can.  Exclude stack trace from output when\n+       * the error is a specific/expected one.\n+       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n+      try {\n+        if (cpe.getCause() == null) {\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n+          throw cpe;\n+        }\n+        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n+        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n+          /*Some HiveExceptions (e.g. SemanticException) don't set\n+            canonical ErrorMsg explicitly, but there is logic\n+            (e.g. #compile()) to find an appropriate canonical error and\n+            return its code as error code. In this case we want to\n+            preserve it for downstream code to interpret*/\n+          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n+          throw cpe;\n+        }\n+        if (cpe.getCause() instanceof HiveException) {\n+          HiveException rc = (HiveException)cpe.getCause();\n+          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n+              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n+        } else {\n+          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n+          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n+              StringUtils.stringifyException(cpe.getCause()));\n+        }\n+      } catch (HiveException ex) {\n+        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n       }\n-    } catch (HiveException ex) {\n-      CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n+      throw cpe;\n     }\n-    return;\n   }\n \n   @Override\n"}}, {"oid": "1317d03009b40b00229088e68caeec98b52e269d", "url": "https://github.com/apache/hive/commit/1317d03009b40b00229088e68caeec98b52e269d", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-11T13:02:49Z", "type": "forcePushed"}, {"oid": "10ff6ee4c02fafb3ec1748f1950a6d849e3b8cbf", "url": "https://github.com/apache/hive/commit/10ff6ee4c02fafb3ec1748f1950a6d849e3b8cbf", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-11T22:04:24Z", "type": "forcePushed"}, {"oid": "ddde236dbc2ecc7c7f05c2dd994288c9498fe2c6", "url": "https://github.com/apache/hive/commit/ddde236dbc2ecc7c7f05c2dd994288c9498fe2c6", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-12T17:43:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ5ODA0MA==", "url": "https://github.com/apache/hive/pull/1222#discussion_r453498040", "bodyText": "Maybe a correct javadoc comment? The meaning and the usage of resetTaskIds is not trivial either", "author": "pvary", "createdAt": "2020-07-13T08:57:29Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -155,9 +157,11 @@ public int compile(String command, boolean resetTaskIds) {\n     }\n   }\n \n-  // deferClose indicates if the close/destroy should be deferred when the process has been\n-  // interrupted, it should be set to true if the compile is called within another method like\n-  // runInternal, which defers the close to the called in that method.\n+  /**\n+   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be", "originalCommit": "ddde236dbc2ecc7c7f05c2dd994288c9498fe2c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4910b860c30b634e75e8cac16e3e9f2851034b14", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex 94e78edb22..5590cf3c62 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -158,9 +158,12 @@ public int compile(String command, boolean resetTaskIds) {\n   }\n \n   /**\n-   * @deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it should be\n-   *             set to true if the compile is called within another method like runInternal, which defers the close to\n-   *             the called in that method.\n+   * Compiles an HQL command, creates an execution plan for it.\n+   * \n+   * @param deferClose indicates if the close/destroy should be deferred when the process has been interrupted, it\n+   *        should be set to true if the compile is called within another method like runInternal, which defers the\n+   *        close to the called in that method.\n+   * @param resetTaskIds Resets taskID counter if true.\n    */\n   @VisibleForTesting\n   public void compile(String command, boolean resetTaskIds, boolean deferClose) throws CommandProcessorException {\n"}}, {"oid": "4910b860c30b634e75e8cac16e3e9f2851034b14", "url": "https://github.com/apache/hive/commit/4910b860c30b634e75e8cac16e3e9f2851034b14", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-13T16:23:47Z", "type": "forcePushed"}, {"oid": "1060311bc1b6285b2f3942d0076f09051475d8cf", "url": "https://github.com/apache/hive/commit/1060311bc1b6285b2f3942d0076f09051475d8cf", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-13T22:16:31Z", "type": "forcePushed"}, {"oid": "f0767faf3e559b472591d957eb7ddca569642a3c", "url": "https://github.com/apache/hive/commit/f0767faf3e559b472591d957eb7ddca569642a3c", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-14T09:48:38Z", "type": "forcePushed"}, {"oid": "d3c105aaad97237ea4b35e9c08101f7d3939eb58", "url": "https://github.com/apache/hive/commit/d3c105aaad97237ea4b35e9c08101f7d3939eb58", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-14T13:42:02Z", "type": "commit"}, {"oid": "d3c105aaad97237ea4b35e9c08101f7d3939eb58", "url": "https://github.com/apache/hive/commit/d3c105aaad97237ea4b35e9c08101f7d3939eb58", "message": "Clean up Driver (Miklos Gergely, reviewed by Peter Vary)", "committedDate": "2020-07-14T13:42:02Z", "type": "forcePushed"}]}