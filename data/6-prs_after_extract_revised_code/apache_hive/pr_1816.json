{"pr_number": 1816, "pr_title": "HIVE-24570 Hive on spark tmp file should be delete when driver process finished", "pr_createdAt": "2020-12-25T12:06:51Z", "pr_url": "https://github.com/apache/hive/pull/1816", "timeline": [{"oid": "32a86738d20e441a980178e4f6de18828f4eb7c4", "url": "https://github.com/apache/hive/commit/32a86738d20e441a980178e4f6de18828f4eb7c4", "message": "fix HIVE-24570", "committedDate": "2020-12-25T12:04:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjk0MzUwNQ==", "url": "https://github.com/apache/hive/pull/1816#discussion_r552943505", "bodyText": "Is sparkTmpProperties only assigned when cancel called? Is there any normal scenario the properties need to be deleted?", "author": "yongzhi", "createdAt": "2021-01-06T20:22:32Z", "path": "spark-client/src/main/java/org/apache/hive/spark/client/AbstractSparkClient.java", "diffHunk": "@@ -260,7 +265,7 @@ public void cancel(String jobId) {\n     if (!properties.setReadable(false) || !properties.setReadable(true, true)) {\n       throw new IOException(\"Cannot change permissions of job properties file.\");\n     }\n-    properties.deleteOnExit();\n+    sparkTmpProperties = properties;", "originalCommit": "32a86738d20e441a980178e4f6de18828f4eb7c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzA2MTg5Nw==", "url": "https://github.com/apache/hive/pull/1816#discussion_r553061897", "bodyText": "not only cancel, when spark driver stop include success finished and killed, both will be delete this applicationId tmp file", "author": "fsilent", "createdAt": "2021-01-07T01:42:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjk0MzUwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzA3MzE1OQ==", "url": "https://github.com/apache/hive/pull/1816#discussion_r553073159", "bodyText": "Test result like this:\n\n\nhive on spark task is running\nQueue | Application Priority | StartTime | FinishTime | State | FinalStatus | Running Containers\n-- | -- | -- | -- | -- | -- | --\nHive on Spark (sessionId =   5e75b839-0a66-45c6-bc98-4ea14befc267) | SPARK | default | 0 | Thu Jan 7 09:52:31 +0800 2021 | Thu Jan 7 N/A | RUNNING\n\n\nspark tmp file in java.io.tmpdir(default is /tmp)\nroot@xxxx tmp]# ll spark*\n-rw------- 1 xxx xxxx 37438 Jan  7 09:56 spark-submit.2308482618955056124.properties\n\n\nbeeline is finished\n\n\nHive on Spark (sessionId =   6228c803-55be-4c2a-9868-3deae7c432c3) | SPARK | default | 0 | Thu Jan 7 09:52:31 +0800 2021 | Thu Jan 7 09:54:04 +0800 2021 | FINISHED | SUCCEEDED\n\n\nspark tmp file was deleted\n[root@xxxx tmp]# ll spark*\nls: cannot access spark*: No such file or directory\n\n\nif use kill -9 beeline pid, also can delete spark tmp file", "author": "fsilent", "createdAt": "2021-01-07T02:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mjk0MzUwNQ=="}], "type": "inlineReview", "revised_code": null}]}