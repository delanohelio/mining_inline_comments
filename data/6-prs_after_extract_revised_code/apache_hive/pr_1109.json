{"pr_number": 1109, "pr_title": "HIVE-22015: Add table constraints in CachedStore", "pr_createdAt": "2020-06-15T10:29:36Z", "pr_url": "https://github.com/apache/hive/pull/1109", "timeline": [{"oid": "c6f370c129c3f977afb76740275841dabcc7ce34", "url": "https://github.com/apache/hive/commit/c6f370c129c3f977afb76740275841dabcc7ce34", "message": "renaming variables/reorganizing imports", "committedDate": "2020-06-15T17:00:08Z", "type": "forcePushed"}, {"oid": "111bf3dffed83715334e1d6c029febffdda2e6e7", "url": "https://github.com/apache/hive/commit/111bf3dffed83715334e1d6c029febffdda2e6e7", "message": "renaming variables/reorganizing imports", "committedDate": "2020-06-18T08:53:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU3NzU0MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445577541", "bodyText": "Should be 2 spaced indentation. Check other places too.", "author": "sankarh", "createdAt": "2020-06-25T13:55:56Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -402,6 +385,32 @@ private static void updateStatsForAlterTable(RawStore rawStore, Table tblBefore,\n         sharedCache.removePartitionColStatsFromCache(catalogName, dbName, tableName, msgPart.getPartValues(),\n             msgPart.getColName());\n         break;\n+      case MessageBuilder.ADD_PRIMARYKEY_EVENT:\n+          AddPrimaryKeyMessage addPrimaryKeyMessage = deserializer.getAddPrimaryKeyMessage(message);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -386,30 +386,30 @@ private static void updateStatsForAlterTable(RawStore rawStore, Table tblBefore,\n             msgPart.getColName());\n         break;\n       case MessageBuilder.ADD_PRIMARYKEY_EVENT:\n-          AddPrimaryKeyMessage addPrimaryKeyMessage = deserializer.getAddPrimaryKeyMessage(message);\n-          sharedCache.addPrimaryKeysToCache(catalogName, dbName, tableName, addPrimaryKeyMessage.getPrimaryKeys());\n+        AddPrimaryKeyMessage addPrimaryKeyMessage = deserializer.getAddPrimaryKeyMessage(message);\n+        sharedCache.addPrimaryKeysToCache(catalogName, dbName, tableName, addPrimaryKeyMessage.getPrimaryKeys());\n         break;\n       case MessageBuilder.ADD_FOREIGNKEY_EVENT:\n-          AddForeignKeyMessage addForeignKeyMessage = deserializer.getAddForeignKeyMessage(message);\n-          for (SQLForeignKey fk : addForeignKeyMessage.getForeignKeys()) {\n-            // This is done because dbName and tblName for Foreign key events are currently set to PK table and db.\n-            sharedCache.addForeignKeysToCache(catalogName, fk.getFktable_db(), fk.getFktable_name(), Arrays.asList(fk));\n-          }\n+        AddForeignKeyMessage addForeignKeyMessage = deserializer.getAddForeignKeyMessage(message);\n+        for (SQLForeignKey fk : addForeignKeyMessage.getForeignKeys()) {\n+          // This is done because dbName and tblName for Foreign key events are currently set to PK table and db.\n+          sharedCache.addForeignKeysToCache(catalogName, fk.getFktable_db(), fk.getFktable_name(), Arrays.asList(fk));\n+        }\n \n         break;\n       case MessageBuilder.ADD_NOTNULLCONSTRAINT_EVENT:\n-          AddNotNullConstraintMessage notNullConstraintMessage = deserializer.getAddNotNullConstraintMessage(message);\n-          sharedCache.addNotNullConstraintsToCache(catalogName, dbName, tableName,\n-                  notNullConstraintMessage.getNotNullConstraints());\n+        AddNotNullConstraintMessage notNullConstraintMessage = deserializer.getAddNotNullConstraintMessage(message);\n+        sharedCache.addNotNullConstraintsToCache(catalogName, dbName, tableName,\n+            notNullConstraintMessage.getNotNullConstraints());\n         break;\n       case MessageBuilder.ADD_UNIQUECONSTRAINT_EVENT:\n-          AddUniqueConstraintMessage uniqueConstraintMessage = deserializer.getAddUniqueConstraintMessage(message);\n-          sharedCache.addUniqueConstraintsToCache(catalogName, dbName, tableName,\n-                  uniqueConstraintMessage.getUniqueConstraints());\n+        AddUniqueConstraintMessage uniqueConstraintMessage = deserializer.getAddUniqueConstraintMessage(message);\n+        sharedCache.addUniqueConstraintsToCache(catalogName, dbName, tableName,\n+            uniqueConstraintMessage.getUniqueConstraints());\n         break;\n       case MessageBuilder.DROP_CONSTRAINT_EVENT:\n-          DropConstraintMessage dropConstraintMessage = deserializer.getDropConstraintMessage(message);\n-          sharedCache.removeConstraintFromCache(catalogName, dbName, tableName, dropConstraintMessage.getConstraint());\n+        DropConstraintMessage dropConstraintMessage = deserializer.getDropConstraintMessage(message);\n+        sharedCache.removeConstraintFromCache(catalogName, dbName, tableName, dropConstraintMessage.getConstraint());\n         break;\n       default:\n         LOG.error(\"Event is not supported for cache invalidation : \" + event.getEventType());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU5OTYzOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445599638", "bodyText": "It seems missed to assign the return values from these rawStore calls to the local variables.", "author": "sankarh", "createdAt": "2020-06-25T14:26:18Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -557,23 +558,29 @@ static void prewarm(RawStore rawStore) {\n                 Deadline.stopTimer();\n               }\n               Deadline.startTimer(\"getPrimaryKeys\");\n-              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setPrimaryKeys(primaryKeys);\n+\n               Deadline.startTimer(\"getForeignKeys\");\n-              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              foreignKeys = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setForeignKeys(foreignKeys);\n+\n               Deadline.startTimer(\"getUniqueConstraints\");\n-              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              uniqueConstraints = rawStore.getUniqueConstraints(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setUniqueConstraints(uniqueConstraints);\n+\n               Deadline.startTimer(\"getNotNullConstraints\");\n-              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              notNullConstraints = rawStore.getNotNullConstraints(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setNotNullConstraints(notNullConstraints);\n \n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,\n-                      aggrStatsAllButDefaultPartition, primaryKeys, foreignKeys, uniqueConstraints,\n-                          notNullConstraints);\n+                      aggrStatsAllButDefaultPartition, cacheObjects);\n               if (isSuccess) {\n                 LOG.trace(\"Cached Database: {}'s Table: {}.\", dbName, tblName);\n               } else {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445603527", "bodyText": "Too many arguments. Can we have another class (TableCacheObjects) to store all these arguments using set methods?", "author": "sankarh", "createdAt": "2020-06-25T14:31:32Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getForeignKeys\");\n+              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getUniqueConstraints\");\n+              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getNotNullConstraints\");\n+              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+\n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5ODQwNA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446898404", "bodyText": "Done. Though the new class just contains constraints objects for now, we can have a different refactoring jira for partition/column stat that can also refactor the array created to store size/dirtyCache variable.", "author": "adesh-rao", "createdAt": "2020-06-29T11:29:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwMzQyMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448903420", "bodyText": "I think, we can make this refactoring also here itself. It needs change only in this method and so less risky. Having another ticket for this is time consuming.", "author": "sankarh", "createdAt": "2020-07-02T10:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw=="}], "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -557,23 +558,29 @@ static void prewarm(RawStore rawStore) {\n                 Deadline.stopTimer();\n               }\n               Deadline.startTimer(\"getPrimaryKeys\");\n-              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setPrimaryKeys(primaryKeys);\n+\n               Deadline.startTimer(\"getForeignKeys\");\n-              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              foreignKeys = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setForeignKeys(foreignKeys);\n+\n               Deadline.startTimer(\"getUniqueConstraints\");\n-              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              uniqueConstraints = rawStore.getUniqueConstraints(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setUniqueConstraints(uniqueConstraints);\n+\n               Deadline.startTimer(\"getNotNullConstraints\");\n-              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              notNullConstraints = rawStore.getNotNullConstraints(catName, dbName, tblName);\n               Deadline.stopTimer();\n+              cacheObjects.setNotNullConstraints(notNullConstraints);\n \n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,\n-                      aggrStatsAllButDefaultPartition, primaryKeys, foreignKeys, uniqueConstraints,\n-                          notNullConstraints);\n+                      aggrStatsAllButDefaultPartition, cacheObjects);\n               if (isSuccess) {\n                 LOG.trace(\"Cached Database: {}'s Table: {}.\", dbName, tblName);\n               } else {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwOTY5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445609698", "bodyText": "Failure logs can have catName and dbName too.", "author": "sankarh", "createdAt": "2020-06-25T14:39:33Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +902,73 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of table: \" + tblName, e);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -914,7 +921,8 @@ private void updateTableForeignKeys(RawStore rawStore, String catName, String db\n         LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n                 dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read foreign keys of table: \" + tblName, e);\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"\n+        + dbName + \", table: \" + tblName, e);\n       }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDQ2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446104460", "bodyText": "Arguments names can be uks and uk.", "author": "sankarh", "createdAt": "2020-06-26T10:32:49Z", "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java", "diffHunk": "@@ -295,6 +295,178 @@ public void testTableOpsForUpdateUsingEvents() throws Exception {\n     sharedCache.getSdCache().clear();\n   }\n \n+  @Test\n+  public void testConstraintsForUpdateUsingEvents() throws Exception {\n+    long lastEventId = -1;\n+    RawStore rawStore = hmsHandler.getMS();\n+\n+    // Prewarm CachedStore\n+    CachedStore.setCachePrewarmedState(false);\n+    CachedStore.prewarm(rawStore);\n+\n+    // Add a db via rawStore\n+    String dbName = \"test_table_ops\";\n+    String dbOwner = \"user1\";\n+    Database db = createTestDb(dbName, dbOwner);\n+    hmsHandler.create_database(db);\n+    db = rawStore.getDatabase(DEFAULT_CATALOG_NAME, dbName);\n+\n+    String foreignDbName = \"test_table_ops_foreign\";\n+    Database foreignDb = createTestDb(foreignDbName, dbOwner);\n+    hmsHandler.create_database(foreignDb);\n+    foreignDb = rawStore.getDatabase(DEFAULT_CATALOG_NAME, foreignDbName);\n+    // Add a table via rawStore\n+    String tblName = \"tbl\";\n+    String tblOwner = \"user1\";\n+    FieldSchema col1 = new FieldSchema(\"col1\", \"int\", \"integer column\");\n+    FieldSchema col2 = new FieldSchema(\"col2\", \"string\", \"string column\");\n+    List<FieldSchema> cols = new ArrayList<FieldSchema>();\n+    cols.add(col1);\n+    cols.add(col2);\n+    List<FieldSchema> ptnCols = new ArrayList<FieldSchema>();\n+    Table tbl = createTestTbl(dbName, tblName, tblOwner, cols, ptnCols);\n+    String foreignTblName = \"ftbl\";\n+    Table foreignTbl = createTestTbl(foreignDbName, foreignTblName, tblOwner, cols, ptnCols);\n+\n+    SQLPrimaryKey key = new SQLPrimaryKey(dbName, tblName, col1.getName(), 1, \"pk1\",\n+            false, false, false);\n+    SQLUniqueConstraint uC = new SQLUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), 2, \"uc1\", false, false, false);\n+    SQLNotNullConstraint nN = new SQLNotNullConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), \"nn1\", false, false, false);\n+    SQLForeignKey foreignKey = new SQLForeignKey(key.getTable_db(), key.getTable_name(), key.getColumn_name(),\n+            foreignDbName, foreignTblName, key.getColumn_name(), 2, 1,2,\n+            \"fk1\", key.getPk_name(), false, false, false);\n+\n+    hmsHandler.create_table_with_constraints(tbl,\n+            Arrays.asList(key), null, Arrays.asList(uC), Arrays.asList(nN), null, null);\n+    hmsHandler.create_table_with_constraints(foreignTbl, null, Arrays.asList(foreignKey),\n+            null, null, null, null);\n+\n+    tbl = rawStore.getTable(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    foreignTbl = rawStore.getTable(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+\n+    // Read database, table via CachedStore\n+    Database dbRead= sharedCache.getDatabaseFromCache(DEFAULT_CATALOG_NAME, dbName);\n+    Assert.assertEquals(db, dbRead);\n+    Table tblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    compareTables(tblRead, tbl);\n+\n+    Table foreignTblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+    compareTables(foreignTblRead, foreignTbl);\n+\n+    List<SQLPrimaryKey> keys = rawStore.getPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLPrimaryKey> keysRead = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keysRead, 1, 0, keys.get(0));\n+\n+    List<SQLNotNullConstraint> nNs = rawStore.getNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLNotNullConstraint> nNsRead = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNsRead, 1, 0, nNs.get(0));\n+\n+    List<SQLUniqueConstraint> uns = rawStore.getUniqueConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLUniqueConstraint> unsRead = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(unsRead, 1, 0, uns.get(0));\n+\n+    List<SQLForeignKey> fks = rawStore.getForeignKeys(DEFAULT_CATALOG_NAME, dbName, tblName, foreignDbName, foreignTblName);\n+    List<SQLForeignKey> fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName,\n+            foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, fks.get(0));\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            dbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, tblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            null, null);\n+    Assert.assertEquals(fksRead.size(), 1);\n+\n+    // Dropping the constraint\n+    DropConstraintRequest dropConstraintRequest = new DropConstraintRequest(foreignDbName, foreignTblName, foreignKey.getFk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, key.getPk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, nN.getNn_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, uC.getUk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    Assert.assertEquals(keys.size(), 0);\n+    Assert.assertEquals(nNs.size(), 0);\n+    Assert.assertEquals(uns.size(), 0);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    // Adding keys back\n+    AddPrimaryKeyRequest req = new AddPrimaryKeyRequest(Arrays.asList(key));\n+    hmsHandler.add_primary_key(req);\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keys, 1, 0, key);\n+\n+    AddUniqueConstraintRequest uniqueConstraintRequest = new AddUniqueConstraintRequest(Arrays.asList(uC));\n+    hmsHandler.add_unique_constraint(uniqueConstraintRequest);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(uns, 1, 0, uC);\n+\n+    AddNotNullConstraintRequest notNullConstraintRequest = new AddNotNullConstraintRequest(Arrays.asList(nN));\n+    hmsHandler.add_not_null_constraint(notNullConstraintRequest);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNs, 1, 0, nN);\n+\n+    AddForeignKeyRequest foreignKeyRequest = new AddForeignKeyRequest(Arrays.asList(foreignKey));\n+    hmsHandler.add_foreign_key(foreignKeyRequest);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, foreignKey);\n+\n+    sharedCache.getDatabaseCache().clear();\n+    sharedCache.clearTableCache();\n+    sharedCache.getSdCache().clear();\n+  }\n+\n+  private void assertsForPrimarkaryKey(List<SQLPrimaryKey> keys, int size, int ele, SQLPrimaryKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getColumn_name(), key.getColumn_name());\n+    Assert.assertEquals(keys.get(ele).getTable_name(), key.getTable_name());\n+    Assert.assertEquals(keys.get(ele).getTable_db(), key.getTable_db());\n+  }\n+\n+  private void assertsForForeignKey(List<SQLForeignKey> keys, int size, int ele, SQLForeignKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getFk_name(), key.getFk_name());\n+    Assert.assertEquals(keys.get(ele).getFktable_db(), key.getFktable_db());\n+    Assert.assertEquals(keys.get(ele).getFktable_name(), key.getFktable_name());\n+    Assert.assertEquals(keys.get(ele).getPktable_db(), key.getPktable_db());\n+    Assert.assertEquals(keys.get(ele).getPktable_name(), key.getPktable_name());\n+    Assert.assertEquals(keys.get(ele).getPkcolumn_name(), key.getPkcolumn_name());\n+    Assert.assertEquals(keys.get(ele).getFkcolumn_name(), key.getFkcolumn_name());\n+  }\n+\n+  private void assertsForNotNullConstraints(List<SQLNotNullConstraint> nns, int size, int ele, SQLNotNullConstraint nN) {\n+    Assert.assertEquals(nns.size(), size);\n+    Assert.assertEquals(nns.get(ele).getNn_name(), nN.getNn_name());\n+    Assert.assertEquals(nns.get(ele).getColumn_name(), nN.getColumn_name());\n+    Assert.assertEquals(nns.get(ele).getTable_name(), nN.getTable_name());\n+    Assert.assertEquals(nns.get(ele).getTable_db(), nN.getTable_db());\n+  }\n+\n+  private void assertsForUniqueConstraints(List<SQLUniqueConstraint> nns, int size, int ele, SQLUniqueConstraint nN) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java\nindex 3e1124243c..0b7fce1ea3 100644\n--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java\n+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java\n\n@@ -459,12 +459,12 @@ private void assertsForNotNullConstraints(List<SQLNotNullConstraint> nns, int si\n     Assert.assertEquals(nns.get(ele).getTable_db(), nN.getTable_db());\n   }\n \n-  private void assertsForUniqueConstraints(List<SQLUniqueConstraint> nns, int size, int ele, SQLUniqueConstraint nN) {\n-    Assert.assertEquals(nns.size(), size);\n-    Assert.assertEquals(nns.get(ele).getUk_name(), nN.getUk_name());\n-    Assert.assertEquals(nns.get(ele).getColumn_name(), nN.getColumn_name());\n-    Assert.assertEquals(nns.get(ele).getTable_name(), nN.getTable_name());\n-    Assert.assertEquals(nns.get(ele).getTable_db(), nN.getTable_db());\n+  private void assertsForUniqueConstraints(List<SQLUniqueConstraint> uks, int size, int ele, SQLUniqueConstraint uk) {\n+    Assert.assertEquals(uks.size(), size);\n+    Assert.assertEquals(uks.get(ele).getUk_name(), uk.getUk_name());\n+    Assert.assertEquals(uks.get(ele).getColumn_name(), uk.getColumn_name());\n+    Assert.assertEquals(uks.get(ele).getTable_name(), uk.getTable_name());\n+    Assert.assertEquals(uks.get(ele).getTable_db(), uk.getTable_db());\n   }\n \n   @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446106308", "bodyText": "Is it possible that table is cached but not the constraints?", "author": "sankarh", "createdAt": "2020-06-26T10:37:18Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMDc0Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446900743", "bodyText": "Yes, While updating the cache, there is a possibility that table got updated but constraints didn't (they are yet to be updated). But this is similar to partition/columnStats caching.", "author": "adesh-rao", "createdAt": "2020-06-29T11:33:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNTU4Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448905586", "bodyText": "I think, we should handle the case where table object is cached but constraints are not cached. Now, it seems, we just return empty key list to caller but ideally, we should invoke rawStore.", "author": "sankarh", "createdAt": "2020-07-02T10:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNTc5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449525799", "bodyText": "done. Fetching keys from rawStore if we got empty/null.", "author": "adesh-rao", "createdAt": "2020-07-03T11:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}], "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -2619,11 +2630,16 @@ long getPartsFound() {\n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n      // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {\n+      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+    }\n+\n     catName = normalizeIdentifier(catName);\n-    foreignDbName = (foreignDbName == null) ? \"\" : normalizeIdentifier(foreignDbName);\n-    foreignTblName = (foreignTblName == null) ? \"\" : StringUtils.normalizeIdentifier(foreignTblName);\n+    foreignDbName = normalizeIdentifier(foreignDbName);\n+    foreignTblName = StringUtils.normalizeIdentifier(foreignTblName);\n     parentDbName = (parentDbName == null) ? \"\" : normalizeIdentifier(parentDbName);\n     parentTblName = (parentTblName == null) ? \"\" : StringUtils.normalizeIdentifier(parentTblName);\n+\n     if (!shouldCacheTable(catName, foreignDbName, foreignTblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n       return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwODU0NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446108545", "bodyText": "If foreign db or table names are null, then we should just invoke rawStore apis instead of using empty string. It can cause issues.", "author": "sankarh", "createdAt": "2020-06-26T10:42:48Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    catName = normalizeIdentifier(catName);\n+    foreignDbName = (foreignDbName == null) ? \"\" : normalizeIdentifier(foreignDbName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex ce6ee99341..b1ae562b5d 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -2619,11 +2630,16 @@ long getPartsFound() {\n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n      // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {\n+      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+    }\n+\n     catName = normalizeIdentifier(catName);\n-    foreignDbName = (foreignDbName == null) ? \"\" : normalizeIdentifier(foreignDbName);\n-    foreignTblName = (foreignTblName == null) ? \"\" : StringUtils.normalizeIdentifier(foreignTblName);\n+    foreignDbName = normalizeIdentifier(foreignDbName);\n+    foreignTblName = StringUtils.normalizeIdentifier(foreignTblName);\n     parentDbName = (parentDbName == null) ? \"\" : normalizeIdentifier(parentDbName);\n     parentTblName = (parentTblName == null) ? \"\" : StringUtils.normalizeIdentifier(parentTblName);\n+\n     if (!shouldCacheTable(catName, foreignDbName, foreignTblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n       return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNTY5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446115699", "bodyText": "Indentation of \"case' statement is not matching with others.", "author": "sankarh", "createdAt": "2020-06-26T11:00:57Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -410,6 +436,34 @@ private void updateMemberSize(MemberName mn, Integer size, SizeMode mode) {\n           aggrColStatsCacheSize = size;\n         }\n         break;\n+      case PRIMARY_KEY_CACHE:\n+        if (mode == SizeMode.Delta) {\n+          primaryKeyCacheSize += size;\n+        } else {\n+          primaryKeyCacheSize = size;\n+        }\n+        break;\n+        case FOREIGN_KEY_CACHE:", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -437,33 +441,15 @@ private void updateMemberSize(MemberName mn, Integer size, SizeMode mode) {\n         }\n         break;\n       case PRIMARY_KEY_CACHE:\n+      case FOREIGN_KEY_CACHE:\n+      case UNIQUE_CONSTRAINT_CACHE:\n+      case NOTNULL_CONSTRAINT_CACHE:\n         if (mode == SizeMode.Delta) {\n-          primaryKeyCacheSize += size;\n+          this.memberObjectsSize[mn.ordinal()] += size;\n         } else {\n-          primaryKeyCacheSize = size;\n+          this.memberObjectsSize[mn.ordinal()] = size;\n         }\n         break;\n-        case FOREIGN_KEY_CACHE:\n-          if (mode == SizeMode.Delta) {\n-            foreignKeyCacheSize += size;\n-          } else {\n-            foreignKeyCacheSize = size;\n-          }\n-          break;\n-        case UNIQUE_CONSTRAINT_CACHE:\n-          if (mode == SizeMode.Delta) {\n-            uniqueConstraintCacheSize += size;\n-          } else {\n-            uniqueConstraintCacheSize = size;\n-          }\n-          break;\n-        case NOTNULL_CONSTRAINT_CACHE:\n-          if (mode == SizeMode.Delta) {\n-            notNullConstraintCacheSize += size;\n-          } else {\n-            notNullConstraintCacheSize = size;\n-          }\n-          break;\n       default:\n         break;\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNzA4OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446117088", "bodyText": "Shall consolidate all these size variables into an array(say, memberObjectsSize) of size = (number of items in enum MemberName) and can refer to it using enum value as index. It reduces lot of code especially the switch cases.", "author": "sankarh", "createdAt": "2020-06-26T11:04:29Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -265,6 +270,10 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionCacheSize;\n     private int partitionColStatsCacheSize;\n     private int aggrColStatsCacheSize;\n+    private int primaryKeyCacheSize;", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -270,10 +271,13 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionCacheSize;\n     private int partitionColStatsCacheSize;\n     private int aggrColStatsCacheSize;\n-    private int primaryKeyCacheSize;\n-    private int foreignKeyCacheSize;\n-    private int uniqueConstraintCacheSize;\n-    private int notNullConstraintCacheSize;\n+\n+    // Arrays to hold the size/dirty bit of cached objects.\n+    // These arrays are to be referenced using MemberName enum only.\n+    // Currently hold valid values only for Constraints objects.\n+    // ToDo: Add partitions/columnStats\n+    private int[] memberObjectsSize = new int[MemberName.values().length];\n+    private AtomicBoolean[] memberCacheDirty = new AtomicBoolean[MemberName.values().length];\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExODQ2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446118460", "bodyText": "Same as size, even dirty check boolean also can be an array.", "author": "sankarh", "createdAt": "2020-06-26T11:07:39Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -287,6 +296,18 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n     private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+    private AtomicBoolean isPrimaryKeyCacheDirty = new AtomicBoolean(false);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -297,16 +301,12 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n-    private AtomicBoolean isPrimaryKeyCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLForeignKey> foreignKeyCache = new ConcurrentHashMap<>();\n-    private AtomicBoolean isForeignKeyCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLNotNullConstraint> notNullConstraintCache = new ConcurrentHashMap<>();\n-    private AtomicBoolean isNotNullConstraintCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLUniqueConstraint> uniqueConstraintCache = new ConcurrentHashMap<>();\n-    private AtomicBoolean isUniqueConstraintCacheDirty = new AtomicBoolean(false);\n \n     TableWrapper(Table t, byte[] sdHash, String location, Map<String, String> parameters) {\n       this.t = t;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMjUxMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446122511", "bodyText": "Why do we need to pass both member name and constraint class name. We can derive it from member name itself.", "author": "sankarh", "createdAt": "2020-06-26T11:17:09Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -525,31 +511,25 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n     }\n \n     boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n-      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n-              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n     }\n \n     boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n-      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n-              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n     }\n \n     boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n-              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n     }\n \n     boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n-              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n     }\n \n     // Common method to cache constraints\n     private boolean cacheConstraints(List constraintsList,\n-                             Class constraintClass,\n                              boolean fromPrewarm,\n-                             MemberName mn,\n-                             AtomicBoolean dirtyConstaintVariable) {\n+                             MemberName mn) {\n       if (constraintsList == null || constraintsList.isEmpty()) {\n         return true;\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNDk3MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446124971", "bodyText": "Can be a switch-case.", "author": "sankarh", "createdAt": "2020-06-26T11:22:45Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -525,31 +511,25 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n     }\n \n     boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n-      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n-              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n     }\n \n     boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n-      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n-              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n     }\n \n     boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n-              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n     }\n \n     boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n-              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n     }\n \n     // Common method to cache constraints\n     private boolean cacheConstraints(List constraintsList,\n-                             Class constraintClass,\n                              boolean fromPrewarm,\n-                             MemberName mn,\n-                             AtomicBoolean dirtyConstaintVariable) {\n+                             MemberName mn) {\n       if (constraintsList == null || constraintsList.isEmpty()) {\n         return true;\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDgxMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446140811", "bodyText": "Double assignment. Shall directly return from here and avoid local variable.", "author": "sankarh", "createdAt": "2020-06-26T12:00:52Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {\n+            SQLPrimaryKey key = (SQLPrimaryKey) constraintsList.get(i);\n+            this.primaryKeyCache.put(key.getPk_name(), key);\n+          } else if (constraintClass == SQLForeignKey.class) {\n+            SQLForeignKey key = (SQLForeignKey) constraintsList.get(i);\n+            this.foreignKeyCache.put(key.getFk_name(), key);\n+          } else if (constraintClass == SQLNotNullConstraint.class) {\n+            SQLNotNullConstraint key = (SQLNotNullConstraint) constraintsList.get(i);\n+            this.notNullConstraintCache.put(key.getNn_name(), key);\n+          } else if (constraintClass == SQLUniqueConstraint.class) {\n+            SQLUniqueConstraint key = (SQLUniqueConstraint) constraintsList.get(i);\n+            this.uniqueConstraintCache.put(key.getUk_name(), key);\n+          }\n+          size += getObjectSize(constraintClass, constraintsList.get(i));\n+        }\n+\n+        if (!fromPrewarm) {\n+          dirtyConstaintVariable.set(true);\n+        }\n+\n+        updateMemberSize(mn, size, SizeMode.Delta);\n+        return true;\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public List<SQLPrimaryKey> getPrimaryKeys() {\n+      List<SQLPrimaryKey> keys = new ArrayList<>();\n+      try {\n+        tableLock.readLock().lock();\n+        keys = new ArrayList<>(this.primaryKeyCache.values());", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -525,31 +511,25 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n     }\n \n     boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n-      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n-              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n     }\n \n     boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n-      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n-              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n     }\n \n     boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n-              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n     }\n \n     boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n-              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n     }\n \n     // Common method to cache constraints\n     private boolean cacheConstraints(List constraintsList,\n-                             Class constraintClass,\n                              boolean fromPrewarm,\n-                             MemberName mn,\n-                             AtomicBoolean dirtyConstaintVariable) {\n+                             MemberName mn) {\n       if (constraintsList == null || constraintsList.isEmpty()) {\n         return true;\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzQyMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446143421", "bodyText": "It can happen that for multi HMS instance case, table can be cached but not constraints right? If yes, then it can hit here.", "author": "sankarh", "createdAt": "2020-06-26T12:06:51Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -681,27 +664,27 @@ public void removeConstraint(String name) {\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          isPrimaryKeyCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          isForeignKeyCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          isNotNullConstraintCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          isUniqueConstraintCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n         if(constraint == null) {\n-          // Should not reach here\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n           return;\n         }\n         int size = getObjectSize(constraintClass, constraint);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDUzNg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446144536", "bodyText": "Shouldn't we use ConcurrentHashMap here?", "author": "sankarh", "createdAt": "2020-06-26T12:09:37Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new HashMap<>();", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -681,27 +664,27 @@ public void removeConstraint(String name) {\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          isPrimaryKeyCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          isForeignKeyCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          isNotNullConstraintCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          isUniqueConstraintCacheDirty.set(true);\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n         if(constraint == null) {\n-          // Should not reach here\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n           return;\n         }\n         int size = getObjectSize(constraintClass, constraint);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjU1MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446146551", "bodyText": "Shall use List.stream().filter() instead of loop and check.", "author": "sankarh", "createdAt": "2020-06-26T12:14:20Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2247,125 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {\n+      List<SQLForeignKey> filteredKeys = new ArrayList<>();\n+      for (SQLForeignKey key : keys) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 83e3a53eea..330f87e371 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -2276,14 +2257,11 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n \n     // filter out required foreign keys based on parent db/tbl name\n     if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {\n-      List<SQLForeignKey> filteredKeys = new ArrayList<>();\n-      for (SQLForeignKey key : keys) {\n-        if (parentTblName.equalsIgnoreCase(key.getPktable_name())\n-                && parentDbName.equalsIgnoreCase(key.getPktable_db())) {\n-          filteredKeys.add(key);\n-        }\n-      }\n-      keys = filteredKeys;\n+      return keys\n+        .stream()\n+        .filter(key -> parentDbName.equalsIgnoreCase(key.getPktable_db())\n+          && parentTblName.equalsIgnoreCase(key.getPktable_name()))\n+        .collect(Collectors.toList());\n     }\n     return keys;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0ODM0OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446148349", "bodyText": "Too many blank lines.", "author": "sankarh", "createdAt": "2020-06-26T12:18:27Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1507,6 +1490,305 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLPrimaryKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.refreshNotNullConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.refreshUniqueConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // List operation with different parent table\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"dummyDB\", \"dummyTable\");\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    // Refresh Operation\n+    SQLForeignKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setFkcolumn_name(\"col3\");\n+    modifiedKey.setFk_name(\"fk_modified\");\n+\n+    sharedCache.refreshForeignKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col3\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "chunk": "diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\nindex 8cc9b39612..607ba1a17f 100644\n--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n\n@@ -1747,8 +1747,6 @@ public void testForeignKeys() {\n             DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n     Assert.assertEquals(cachedKeys.size(), 0);\n \n-\n-\n     cachedStore.shutdown();\n   }\n \n"}}, {"oid": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "url": "https://github.com/apache/hive/commit/628f0e7fa1891f05946b843bdb2a3463b43d3d08", "message": "address review comments part 2", "committedDate": "2020-06-29T10:53:15Z", "type": "forcePushed"}, {"oid": "f009640f85ff76ff1041ef75462b4e9058eae295", "url": "https://github.com/apache/hive/commit/f009640f85ff76ff1041ef75462b4e9058eae295", "message": "Fix compilation issue", "committedDate": "2020-06-30T10:48:44Z", "type": "forcePushed"}, {"oid": "22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "url": "https://github.com/apache/hive/commit/22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "message": "Fix compilation issue", "committedDate": "2020-07-01T10:52:57Z", "type": "forcePushed"}, {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "url": "https://github.com/apache/hive/commit/00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "message": "Fix compilation issue", "committedDate": "2020-07-02T07:23:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNDk2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r447414960", "bodyText": "We should take the same path if parentDbName or parentTblName is null.", "author": "sankarh", "createdAt": "2020-06-30T05:16:56Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {", "originalCommit": "f7a7e0d79b5be5dc856591567daed4e825811757", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex b1ae562b5d..1b550de407 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -2623,6 +2629,9 @@ long getPartsFound() {\n       return rawStore.getPrimaryKeys(catName, dbName, tblName);\n     }\n     List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+    if (keys == null || keys.isEmpty()) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n \n     return keys;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTM2Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r447415363", "bodyText": "This flow is a candidate for improvement as it tries to fetch all foreignkeys of give parent table and vice-versa which is frequent operations. Pls create a follow-up JIRA to use CachedStore for this case too.", "author": "sankarh", "createdAt": "2020-06-30T05:18:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {\n+      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);", "originalCommit": "f7a7e0d79b5be5dc856591567daed4e825811757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU5OTU2Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r450599566", "bodyText": "Created https://issues.apache.org/jira/browse/HIVE-23810 for followup.", "author": "adesh-rao", "createdAt": "2020-07-07T04:05:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTM2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex b1ae562b5d..1b550de407 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -2623,6 +2629,9 @@ long getPartsFound() {\n       return rawStore.getPrimaryKeys(catName, dbName, tblName);\n     }\n     List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+    if (keys == null || keys.isEmpty()) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n \n     return keys;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDAwMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904003", "bodyText": "Method is to \"update\" but the log msg says \"read\"", "author": "sankarh", "createdAt": "2020-07-02T10:25:43Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyODgzNw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449528837", "bodyText": "Fixed.", "author": "adesh-rao", "createdAt": "2020-07-03T11:15:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDAwMw=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex b1ae562b5d..1b550de407 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -912,72 +914,81 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n     private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLForeignKey> fks = null;\n       try {\n         Deadline.startTimer(\"getForeignKeys\");\n-        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n-                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n-        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update foreign keys of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (fks != null) {\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTableNotNullConstraints(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached not null constraints for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLNotNullConstraint> nns = null;\n       try {\n         Deadline.startTimer(\"getNotNullConstraints\");\n-        List<SQLNotNullConstraint> nns = rawStore.getNotNullConstraints(catName, dbName, tblName);\n+        nns = rawStore.getNotNullConstraints(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshNotNullConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), nns);\n-        LOG.debug(\"CachedStore: updated cached not null constraints for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read not null constraints of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update not null constraints of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (nns != null) {\n+        sharedCache.refreshNotNullConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), nns);\n+        LOG.debug(\"CachedStore: updated cached not null constraints for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTableUniqueConstraints(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached unique constraints for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLUniqueConstraint> ucs = null;\n       try {\n         Deadline.startTimer(\"getUniqueConstraints\");\n-        List<SQLUniqueConstraint> uc = rawStore.getUniqueConstraints(catName, dbName, tblName);\n+        ucs = rawStore.getUniqueConstraints(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshUniqueConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), uc);\n-        LOG.debug(\"CachedStore: updated cached unique constraints for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read unique constraints of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update unique constraints of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (ucs != null) {\n+        sharedCache.refreshUniqueConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), ucs);\n+        LOG.debug(\"CachedStore: updated cached unique constraints for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTablePrimaryKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached primary keys objects for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLPrimaryKey> pks = null;\n       try {\n         Deadline.startTimer(\"getPrimaryKeys\");\n-        List<SQLPrimaryKey> pks = rawStore.getPrimaryKeys(catName, dbName, tblName);\n+        pks = rawStore.getPrimaryKeys(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshPrimaryKeysInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), pks);\n-        LOG.debug(\"CachedStore: updated cached primary keys objects for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read primary keys of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update primary keys of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (pks != null) {\n+        sharedCache.refreshPrimaryKeysInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), pks);\n+        LOG.debug(\"CachedStore: updated cached primary keys objects for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTablePartitions(RawStore rawStore, String catName, String dbName, String tblName) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDI2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904262", "bodyText": "Shall limit the try-catch block only for rawStore calls.", "author": "sankarh", "createdAt": "2020-07-02T10:26:13Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNTUzOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449525538", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-03T11:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDI2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex b1ae562b5d..1b550de407 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -912,72 +914,81 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n     private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLForeignKey> fks = null;\n       try {\n         Deadline.startTimer(\"getForeignKeys\");\n-        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n-                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n-        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update foreign keys of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (fks != null) {\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTableNotNullConstraints(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached not null constraints for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLNotNullConstraint> nns = null;\n       try {\n         Deadline.startTimer(\"getNotNullConstraints\");\n-        List<SQLNotNullConstraint> nns = rawStore.getNotNullConstraints(catName, dbName, tblName);\n+        nns = rawStore.getNotNullConstraints(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshNotNullConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), nns);\n-        LOG.debug(\"CachedStore: updated cached not null constraints for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read not null constraints of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update not null constraints of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (nns != null) {\n+        sharedCache.refreshNotNullConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), nns);\n+        LOG.debug(\"CachedStore: updated cached not null constraints for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTableUniqueConstraints(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached unique constraints for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLUniqueConstraint> ucs = null;\n       try {\n         Deadline.startTimer(\"getUniqueConstraints\");\n-        List<SQLUniqueConstraint> uc = rawStore.getUniqueConstraints(catName, dbName, tblName);\n+        ucs = rawStore.getUniqueConstraints(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshUniqueConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), uc);\n-        LOG.debug(\"CachedStore: updated cached unique constraints for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read unique constraints of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update unique constraints of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (ucs != null) {\n+        sharedCache.refreshUniqueConstraintsInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), ucs);\n+        LOG.debug(\"CachedStore: updated cached unique constraints for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTablePrimaryKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n       LOG.debug(\"CachedStore: updating cached primary keys objects for catalog: {}, database: {}, table: {}\", catName,\n               dbName, tblName);\n+      List<SQLPrimaryKey> pks = null;\n       try {\n         Deadline.startTimer(\"getPrimaryKeys\");\n-        List<SQLPrimaryKey> pks = rawStore.getPrimaryKeys(catName, dbName, tblName);\n+        pks = rawStore.getPrimaryKeys(catName, dbName, tblName);\n         Deadline.stopTimer();\n-        sharedCache\n-                .refreshPrimaryKeysInCache(StringUtils.normalizeIdentifier(catName),\n-                        StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), pks);\n-        LOG.debug(\"CachedStore: updated cached primary keys objects for catalog: {}, database: {}, table: {}\", catName,\n-                dbName, tblName);\n       } catch (MetaException e) {\n-        LOG.info(\"Updating CachedStore: unable to read primary keys of catalog: \" + catName + \", database: \"\n+        LOG.info(\"Updating CachedStore: unable to update primary keys of catalog: \" + catName + \", database: \"\n         + dbName + \", table: \" + tblName, e);\n       }\n+      if (pks != null) {\n+        sharedCache.refreshPrimaryKeysInCache(StringUtils.normalizeIdentifier(catName),\n+          StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), pks);\n+        LOG.debug(\"CachedStore: updated cached primary keys objects for catalog: {}, database: {}, table: {}\",\n+          catName, dbName, tblName);\n+      }\n     }\n \n     private void updateTablePartitions(RawStore rawStore, String catName, String dbName, String tblName) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448907251", "bodyText": "We need to check if the caller queries the foreign key constraints using parentDb and table as input. If yes, it make sense to map it against parent table object rather than foreign table.", "author": "sankarh", "createdAt": "2020-07-02T10:32:16Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +557,30 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              cacheObjects.setPrimaryKeys(primaryKeys);\n+\n+              Deadline.startTimer(\"getForeignKeys\");\n+              foreignKeys = rawStore.getForeignKeys(catName, null, null, dbName, tblName);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM4NzE2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449387162", "bodyText": "Then should we store foreign key mappings against parentDb and table for quick access (otherwise we will be scanning all the db/tables in cache)?\nAnd this also means we will be keeping two copies, one with parent table and another with foreign table.", "author": "adesh-rao", "createdAt": "2020-07-03T05:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4OTQ3Nw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449789477", "bodyText": "We can have the foreignkeys kept under foreignkey table wrapper but the reference such as foreignkey db/table and key name in parent table wrapper. It will be useful when getForeignKeys is called with null for foreign db/tbl. I just want to confirm if this a frequent call with null as input. If yes, then let's do it, if not ignore this comment.", "author": "sankarh", "createdAt": "2020-07-04T17:11:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU5ODM5NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r450598395", "bodyText": "Current usages in code of getForeignKeys  contains null only for parentDb/table, foreignDb/table are always being populated. So let's skip it as you mentioned.", "author": "adesh-rao", "createdAt": "2020-07-07T03:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex b1ae562b5d..1b550de407 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -551,11 +554,13 @@ static void prewarm(RawStore rawStore) {\n                   aggrStatsAllButDefaultPartition =\n                       rawStore.get_aggr_stats_for(catName, dbName, tblName, partNames, colNames, CacheUtils.HIVE_ENGINE);\n                   Deadline.stopTimer();\n+                  cacheObjects.setAggrStatsAllButDefaultPartition(aggrStatsAllButDefaultPartition);\n                 }\n               } else {\n                 Deadline.startTimer(\"getTableColumnStatistics\");\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n+                cacheObjects.setTableColStats(tableColStats);\n               }\n               Deadline.startTimer(\"getPrimaryKeys\");\n               primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkzNjQ4NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448936484", "bodyText": "We shall remove these variables for stats and partition too as we already have memberObjectsSize and memberCacheDirty.", "author": "sankarh", "createdAt": "2020-07-02T11:32:59Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -266,6 +272,13 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionColStatsCacheSize;", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -267,38 +283,28 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, String> parameters;\n     private byte[] sdHash;\n     private int otherSize;\n-    private int tableColStatsCacheSize;\n-    private int partitionCacheSize;\n-    private int partitionColStatsCacheSize;\n-    private int aggrColStatsCacheSize;\n \n-    // Arrays to hold the size/dirty bit of cached objects.\n+    // Arrays to hold the size/updated bit of cached objects.\n     // These arrays are to be referenced using MemberName enum only.\n-    // Currently hold valid values only for Constraints objects.\n-    // ToDo: Add partitions/columnStats\n     private int[] memberObjectsSize = new int[MemberName.values().length];\n-    private AtomicBoolean[] memberCacheDirty = new AtomicBoolean[MemberName.values().length];\n+    private AtomicBoolean[] memberCacheUpdated = new AtomicBoolean[MemberName.values().length];\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n     // Key is column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> tableColStatsCache = new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isTableColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching partition objects\n     // Ket is partition values and the value is a wrapper around the partition object\n     private Map<String, PartitionWrapper> partitionCache = new ConcurrentHashMap<String, PartitionWrapper>();\n-    private AtomicBoolean isPartitionCacheDirty = new AtomicBoolean(false);\n     // For caching column stats for a partitioned table\n     // Key is aggregate of partition values, column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> partitionColStatsCache =\n         new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isPartitionColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching aggregate column stats for all and all minus default partition\n     // Key is column name and the value is a list of 2 col stat objects\n     // (all partitions and all but default)\n     private Map<String, List<ColumnStatisticsObj>> aggrColStatsCache =\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n-    private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2ODg5Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448968893", "bodyText": "Shall do the following to avoid using variable i and get(i).\nconstraintsList.stream().forEach(constraint -> {\nswitch (mn) {\ncase PRIMARY_KEY_CACHE:\nSQLPrimaryKey pk = (SQLPrimaryKey) constraint;\nthis.primaryKeyCache.put(pk.getPk_name(), pk);\nsize += getObjectSize(SQLPrimaryKey.class, constraint);\nbreak;\n...\n}\n});", "author": "sankarh", "createdAt": "2020-07-02T12:36:09Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +510,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -522,7 +496,7 @@ boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, bool\n       return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n     }\n \n-    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+    boolean cacheNotNullConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n       return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4NjczNA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448986734", "bodyText": "Check if we need to normalize the case of \"name\" before using for search. it might be coming from user input.", "author": "sankarh", "createdAt": "2020-07-02T13:05:40Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzE3Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449527172", "bodyText": "Fixed.", "author": "adesh-rao", "createdAt": "2020-07-03T11:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4NjczNA=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MjMxMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992310", "bodyText": "memberCacheDirty.set is common code and can be moved outside if-else blocks.", "author": "sankarh", "createdAt": "2020-07-02T13:14:17Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5Mjc5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992799", "bodyText": "Extra blank line.", "author": "sankarh", "createdAt": "2020-07-02T13:15:02Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NDAzMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448994033", "bodyText": "We can directly use MemberName.PRIMARY_KEY_CACHE if we assign 0 to first member in the enum.", "author": "sankarh", "createdAt": "2020-07-02T13:16:54Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NzEyMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448997120", "bodyText": "What is the significance of this check? memberCacheDirty flag is confusing. Pls add a comment describing the meaning of this value and how read/write to cache behave for true or false. If true means, cache is already set, then pls rename it to give correct meaning. It sounds like true means invalid cache.", "author": "sankarh", "createdAt": "2020-07-02T13:21:42Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyODY3NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449528675", "bodyText": "Updated the name of the variable. This is used during refreshOperation. If a particular Object cache is set to true, means it was updated after the last refresh operation and should be refreshed now, otherwise, current refresh operation will not modify/refresh the cache.", "author": "adesh-rao", "createdAt": "2020-07-03T11:14:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NzEyMA=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMDQ4NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449000484", "bodyText": "Add a debug log to mark the cache refresh is successful.", "author": "sankarh", "createdAt": "2020-07-02T13:26:51Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzIyMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449527223", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-03T11:10:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMDQ4NA=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -661,25 +635,22 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n+        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLPrimaryKey.class;\n         } else if (this.foreignKeyCache.containsKey(name)) {\n           constraint = this.foreignKeyCache.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLForeignKey.class;\n         } else if (this.notNullConstraintCache.containsKey(name)) {\n           constraint = this.notNullConstraintCache.remove(name);\n           mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLNotNullConstraint.class;\n         } else if (this.uniqueConstraintCache.containsKey(name)) {\n           constraint = this.uniqueConstraintCache.remove(name);\n           mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n-          this.memberCacheDirty[mn.ordinal()].set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMjg2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449002862", "bodyText": "TableWrapper can have setMemberCacheDirty(MemberName, boolean) method to make it clean.", "author": "sankarh", "createdAt": "2020-07-02T13:30:29Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -1693,40 +1666,41 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n           }\n         }\n       }\n-      tblWrapper.cacheAggrPartitionColStats(aggrStatsAllPartitions, aggrStatsAllButDefaultPartition);\n+      tblWrapper.cacheAggrPartitionColStats(cacheObjects.getAggrStatsAllPartitions(),\n+        cacheObjects.getAggrStatsAllButDefaultPartition());\n     }\n-    tblWrapper.isPartitionCacheDirty.set(false);\n-    tblWrapper.isTableColStatsCacheDirty.set(false);\n-    tblWrapper.isPartitionColStatsCacheDirty.set(false);\n-    tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PARTITION_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.TABLE_COL_STATS_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PARTITION_COL_STATS_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.AGGR_COL_STATS_CACHE, false);\n \n     if (cacheObjects.getPrimaryKeys() != null) {\n       if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE,false);\n \n     if (cacheObjects.getForeignKeys() != null) {\n       if(!tblWrapper.cacheForeignKeys(cacheObjects.getForeignKeys(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE,false);\n \n     if (cacheObjects.getNotNullConstraints() != null) {\n-      if(!tblWrapper.cacheNotNulConstraints(cacheObjects.getNotNullConstraints(), true)) {\n+      if(!tblWrapper.cacheNotNullConstraints(cacheObjects.getNotNullConstraints(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE,false);\n \n     if (cacheObjects.getUniqueConstraints() != null) {\n       if(!tblWrapper.cacheUniqueConstraints(cacheObjects.getUniqueConstraints(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE,false);\n \n     try {\n       cacheLock.writeLock().lock();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMzQzMg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449003432", "bodyText": "Member name is incorrect. Check other places below.", "author": "sankarh", "createdAt": "2020-07-02T13:31:20Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+\n+    if (cacheObjects.getForeignKeys() != null) {\n+      if(!tblWrapper.cacheForeignKeys(cacheObjects.getForeignKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -1693,40 +1666,41 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n           }\n         }\n       }\n-      tblWrapper.cacheAggrPartitionColStats(aggrStatsAllPartitions, aggrStatsAllButDefaultPartition);\n+      tblWrapper.cacheAggrPartitionColStats(cacheObjects.getAggrStatsAllPartitions(),\n+        cacheObjects.getAggrStatsAllButDefaultPartition());\n     }\n-    tblWrapper.isPartitionCacheDirty.set(false);\n-    tblWrapper.isTableColStatsCacheDirty.set(false);\n-    tblWrapper.isPartitionColStatsCacheDirty.set(false);\n-    tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PARTITION_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.TABLE_COL_STATS_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PARTITION_COL_STATS_CACHE, false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.AGGR_COL_STATS_CACHE, false);\n \n     if (cacheObjects.getPrimaryKeys() != null) {\n       if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE,false);\n \n     if (cacheObjects.getForeignKeys() != null) {\n       if(!tblWrapper.cacheForeignKeys(cacheObjects.getForeignKeys(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE,false);\n \n     if (cacheObjects.getNotNullConstraints() != null) {\n-      if(!tblWrapper.cacheNotNulConstraints(cacheObjects.getNotNullConstraints(), true)) {\n+      if(!tblWrapper.cacheNotNullConstraints(cacheObjects.getNotNullConstraints(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE,false);\n \n     if (cacheObjects.getUniqueConstraints() != null) {\n       if(!tblWrapper.cacheUniqueConstraints(cacheObjects.getUniqueConstraints(), true)) {\n         return false;\n       }\n     }\n-    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+    tblWrapper.setMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE,false);\n \n     try {\n       cacheLock.writeLock().lock();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNDUwOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449004508", "bodyText": "We are writing in to cache. Check if we need read or write lock here? Looks like we take write lock on the table. Pls confirm if this is fine.", "author": "sankarh", "createdAt": "2020-07-02T13:32:59Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ4NjAxMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449486010", "bodyText": "This is fine, the below method (cachePrimaryKeys), takes the writeLock. the read lock here, is just to get the tblWrapper object.", "author": "adesh-rao", "createdAt": "2020-07-03T09:37:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNDUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -2127,7 +2101,7 @@ public void addNotNullConstraintsToCache(String catName, String dbName, String t\n       String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n       TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n       if (tblWrapper != null) {\n-        tblWrapper.cacheNotNulConstraints(keys, false);\n+        tblWrapper.cacheNotNullConstraints(keys, false);\n       }\n     } finally {\n       cacheLock.readLock().unlock();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNzMxOQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449007319", "bodyText": "Shall move this if block under if (tblWrapper != null) block above.", "author": "sankarh", "createdAt": "2020-07-02T13:37:23Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2228,122 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMTg5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449401898", "bodyText": "Even if tblWrapper is null, keys will be empty list and hence an empty list will be returned. So this should be fine, right?\nIn case we move it to above if block, and assuming the list is not-empty, we will keep the read lock on for a longer duration (though only in milliseconds or even less), that's why I added it below.", "author": "adesh-rao", "createdAt": "2020-07-03T06:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNzMxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..c0c418e244 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -2242,30 +2275,6 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return keys;\n   }\n \n-  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n-                                                   String parentDbName, String parentTblName) {\n-    List<SQLForeignKey> keys = new ArrayList<>();\n-    try {\n-      cacheLock.readLock().lock();\n-      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n-      if (tblWrapper != null) {\n-        keys = tblWrapper.getForeignKeys();\n-      }\n-    } finally {\n-      cacheLock.readLock().unlock();\n-    }\n-\n-    // filter out required foreign keys based on parent db/tbl name\n-    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {\n-      return keys\n-        .stream()\n-        .filter(key -> parentDbName.equalsIgnoreCase(key.getPktable_db())\n-          && parentTblName.equalsIgnoreCase(key.getPktable_name()))\n-        .collect(Collectors.toList());\n-    }\n-    return keys;\n-  }\n-\n   public List<SQLUniqueConstraint> listCachedUniqueConstraint(String catName, String dbName, String tblName) {\n     List<SQLUniqueConstraint> keys = new ArrayList<>();\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODM1NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449008354", "bodyText": "Method name cacheNotNulConstraints missing one \"l\". :)", "author": "sankarh", "createdAt": "2020-07-02T13:38:54Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cachePrimaryKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addForeignKeysToCache(String catName, String dbName, String tblName, List<SQLForeignKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheForeignKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addUniqueConstraintsToCache(String catName, String dbName, String tblName, List<SQLUniqueConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheUniqueConstraints(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addNotNullConstraintsToCache(String catName, String dbName, String tblName, List<SQLNotNullConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheNotNulConstraints(keys, false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 330f87e371..85118052fa 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -2127,7 +2101,7 @@ public void addNotNullConstraintsToCache(String catName, String dbName, String t\n       String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n       TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n       if (tblWrapper != null) {\n-        tblWrapper.cacheNotNulConstraints(keys, false);\n+        tblWrapper.cacheNotNullConstraints(keys, false);\n       }\n     } finally {\n       cacheLock.readLock().unlock();\n"}}, {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "url": "https://github.com/apache/hive/commit/6f5125dc6304cfa3d52aa39902df48b5605241f2", "message": "Review comments p3", "committedDate": "2020-07-03T11:05:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2NjY1NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452766655", "bodyText": "Can we have a flag in TableWrapper in Cache to tell if it was set or not? Can be a follow-up jira.", "author": "sankarh", "createdAt": "2020-07-10T10:40:21Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2490,26 +2616,99 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+    if (keys == null || keys.isEmpty()) {", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3Nzc5Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452777793", "bodyText": "Created a follow up jira. https://issues.apache.org/jira/browse/HIVE-23834", "author": "adesh-rao", "createdAt": "2020-07-10T11:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2NjY1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\nindex 1b550de407..c4fb9fdd97 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java\n\n@@ -2629,42 +2530,14 @@ long getPartsFound() {\n       return rawStore.getPrimaryKeys(catName, dbName, tblName);\n     }\n     List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n-    if (keys == null || keys.isEmpty()) {\n-      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n-    }\n \n     return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-     // Get correct ForeignDBName and TableName\n-    if (foreignDbName == null || foreignTblName == null || parentDbName == null || parentTblName == null) {\n-      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n-    }\n-\n-    catName = normalizeIdentifier(catName);\n-    foreignDbName = normalizeIdentifier(foreignDbName);\n-    foreignTblName = StringUtils.normalizeIdentifier(foreignTblName);\n-    parentDbName = (parentDbName == null) ? \"\" : normalizeIdentifier(parentDbName);\n-    parentTblName = (parentTblName == null) ? \"\" : StringUtils.normalizeIdentifier(parentTblName);\n-\n-    if (!shouldCacheTable(catName, foreignDbName, foreignTblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n-      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n-    }\n-\n-    Table tbl = sharedCache.getTableFromCache(catName, foreignDbName, foreignTblName);\n-    if (tbl == null) {\n-      // The table containing the foreign keys is not yet loaded in cache\n-      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n-    }\n-    List<SQLForeignKey> keys = sharedCache.listCachedForeignKeys(\n-            catName, foreignDbName, foreignTblName, parentDbName, parentTblName);\n-\n-    if (keys == null || keys.isEmpty()) {\n-      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n-    }\n-    return keys;\n+    // TODO constraintCache\n+    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n   }\n \n   @Override public List<SQLUniqueConstraint> getUniqueConstraints(String catName, String dbName, String tblName)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452768398", "bodyText": "Can't we just use mn instead of mn.getValue()?", "author": "sankarh", "createdAt": "2020-07-10T10:44:26Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -261,44 +283,57 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, String> parameters;\n     private byte[] sdHash;\n     private int otherSize;\n-    private int tableColStatsCacheSize;\n-    private int partitionCacheSize;\n-    private int partitionColStatsCacheSize;\n-    private int aggrColStatsCacheSize;\n+\n+    // Arrays to hold the size/updated bit of cached objects.\n+    // These arrays are to be referenced using MemberName enum only.\n+    private int[] memberObjectsSize = new int[MemberName.values().length];\n+    private AtomicBoolean[] memberCacheUpdated = new AtomicBoolean[MemberName.values().length];\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n     // Key is column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> tableColStatsCache = new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isTableColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching partition objects\n     // Ket is partition values and the value is a wrapper around the partition object\n     private Map<String, PartitionWrapper> partitionCache = new ConcurrentHashMap<String, PartitionWrapper>();\n-    private AtomicBoolean isPartitionCacheDirty = new AtomicBoolean(false);\n     // For caching column stats for a partitioned table\n     // Key is aggregate of partition values, column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> partitionColStatsCache =\n         new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isPartitionColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching aggregate column stats for all and all minus default partition\n     // Key is column name and the value is a list of 2 col stat objects\n     // (all partitions and all but default)\n     private Map<String, List<ColumnStatisticsObj>> aggrColStatsCache =\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n-    private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n+\n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLForeignKey> foreignKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLNotNullConstraint> notNullConstraintCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLUniqueConstraint> uniqueConstraintCache = new ConcurrentHashMap<>();\n \n     TableWrapper(Table t, byte[] sdHash, String location, Map<String, String> parameters) {\n       this.t = t;\n       this.sdHash = sdHash;\n       this.location = location;\n       this.parameters = parameters;\n-      this.tableColStatsCacheSize = 0;\n-      this.partitionCacheSize = 0;\n-      this.partitionColStatsCacheSize = 0;\n-      this.aggrColStatsCacheSize = 0;\n+      for(MemberName mn : MemberName.values()) {\n+        this.memberObjectsSize[mn.getValue()] = 0;", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc5OTg3OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452799879", "bodyText": "Java treats enum as objects. Array indexes can be integers only. Therefore, I have to use mn.getValue() only.\nPS: Enum also provides ordinal method that returns the position of enum member, but that can cause issues if order is changed. So, I decided to go ahead with creating own getValue() method.", "author": "adesh-rao", "createdAt": "2020-07-10T12:01:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgxNjE0Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452816142", "bodyText": "In second thought, I think ordinal is better as we freshly load cache entries during HMS startup. So, the ordering doesn't matter. However, setting values can be a problem if someone pass incorrect value or remove an element without updating other values.", "author": "sankarh", "createdAt": "2020-07-10T12:37:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA=="}], "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 85118052fa..c0c418e244 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -283,57 +251,74 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, String> parameters;\n     private byte[] sdHash;\n     private int otherSize;\n-\n-    // Arrays to hold the size/updated bit of cached objects.\n-    // These arrays are to be referenced using MemberName enum only.\n-    private int[] memberObjectsSize = new int[MemberName.values().length];\n-    private AtomicBoolean[] memberCacheUpdated = new AtomicBoolean[MemberName.values().length];\n+    private int tableColStatsCacheSize;\n+    private int partitionCacheSize;\n+    private int partitionColStatsCacheSize;\n+    private int aggrColStatsCacheSize;\n+    private int primaryKeyCacheSize;\n+    private int foreignKeyCacheSize;\n+    private int uniqueConstraintCacheSize;\n+    private int notNullConstraintCacheSize;\n+    private int defaultConstraintCacheSize;\n+    private int checkConstraintCacheSize;\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n     // Key is column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> tableColStatsCache = new ConcurrentHashMap<String, ColumnStatisticsObj>();\n+    private AtomicBoolean isTableColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching partition objects\n     // Ket is partition values and the value is a wrapper around the partition object\n     private Map<String, PartitionWrapper> partitionCache = new ConcurrentHashMap<String, PartitionWrapper>();\n+    private AtomicBoolean isPartitionCacheDirty = new AtomicBoolean(false);\n     // For caching column stats for a partitioned table\n     // Key is aggregate of partition values, column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> partitionColStatsCache =\n         new ConcurrentHashMap<String, ColumnStatisticsObj>();\n+    private AtomicBoolean isPartitionColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching aggregate column stats for all and all minus default partition\n     // Key is column name and the value is a list of 2 col stat objects\n     // (all partitions and all but default)\n     private Map<String, List<ColumnStatisticsObj>> aggrColStatsCache =\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n+    private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n     private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+    private AtomicBoolean isPrimaryKeyCacheDirty = new AtomicBoolean(false);\n \n-    private Map<String, SQLForeignKey> foreignKeyCache = new ConcurrentHashMap<>();\n+    private Map<String, SQLForeignKey> foreignKeyMap = new ConcurrentHashMap<>();\n+    private AtomicBoolean isForeignKeyCacheDirty = new AtomicBoolean(false);\n \n-    private Map<String, SQLNotNullConstraint> notNullConstraintCache = new ConcurrentHashMap<>();\n+    private Map<String, SQLDefaultConstraint> defaultConstraintMap = new ConcurrentHashMap<>();\n+    private AtomicBoolean isDefaultConstraintCacheDirty = new AtomicBoolean(false);\n \n-    private Map<String, SQLUniqueConstraint> uniqueConstraintCache = new ConcurrentHashMap<>();\n+    private Map<String, SQLNotNullConstraint> notNullConstraintMap = new ConcurrentHashMap<>();\n+    private AtomicBoolean isNotNullConstraintCacheDirty = new AtomicBoolean(false);\n+\n+    private Map<String, SQLCheckConstraint> checkConstraintMap = new ConcurrentHashMap<>();\n+    private AtomicBoolean isCheckConstraintCacheDirty = new AtomicBoolean(false);\n+\n+    private Map<String, SQLUniqueConstraint> uniqueConstraintMap = new ConcurrentHashMap<>();\n+    private AtomicBoolean isUniqueConstraintCacheDirty = new AtomicBoolean(false);\n \n     TableWrapper(Table t, byte[] sdHash, String location, Map<String, String> parameters) {\n       this.t = t;\n       this.sdHash = sdHash;\n       this.location = location;\n       this.parameters = parameters;\n-      for(MemberName mn : MemberName.values()) {\n-        this.memberObjectsSize[mn.getValue()] = 0;\n-        this.memberCacheUpdated[mn.getValue()] = new AtomicBoolean(false);\n-      }\n+      this.tableColStatsCacheSize = 0;\n+      this.partitionCacheSize = 0;\n+      this.partitionColStatsCacheSize = 0;\n+      this.aggrColStatsCacheSize = 0;\n+      this.primaryKeyCacheSize = 0;\n+      this.foreignKeyCacheSize = 0;\n+      this.uniqueConstraintCacheSize = 0;\n+      this.checkConstraintCacheSize = 0;\n+      this.notNullConstraintCacheSize = 0;\n+      this.defaultConstraintCacheSize = 0;\n       this.otherSize = getTableWrapperSizeWithoutMaps();\n     }\n \n-    public boolean compareAndSetMemberCacheUpdated(MemberName mn, boolean oldValue, boolean newValue) {\n-      return this.memberCacheUpdated[mn.getValue()].compareAndSet(oldValue, newValue);\n-    }\n-\n-    public void setMemberCacheUpdated(MemberName mn, boolean newValue) {\n-      this.memberCacheUpdated[mn.getValue()].set(newValue);\n-    }\n-\n     private int getTableWrapperSizeWithoutMaps() {\n       Class<?> clazz = TableWrapper.class;\n       Field[] fields = clazz.getDeclaredFields();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MDA2NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452770065", "bodyText": "Why do we use int array if we just want to store one value? and why is it final?", "author": "sankarh", "createdAt": "2020-07-10T10:48:24Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +484,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNullConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        final int[] size = {0};", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3OTQ4Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452779486", "bodyText": "This is being used inside lambda function. It requires the variable to be used as final. Because of this, I can't use int or Integer. So I chose int array instead.", "author": "adesh-rao", "createdAt": "2020-07-10T11:11:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MDA2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 85118052fa..c0c418e244 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -485,64 +534,75 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n     }\n \n     boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n-      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n     }\n \n     boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n-      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n     }\n \n     boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheDefaultConstraints(List<SQLDefaultConstraint> defaultConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(defaultConstraints, SQLDefaultConstraint.class, fromPrewarm,\n+              MemberName.DEFAULT_CONSTRAINT_CACHE, this.isDefaultConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT, this.isNotNullConstraintCacheDirty);\n     }\n \n-    boolean cacheNotNullConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n-      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    boolean cacheCheckConstraints(List<SQLCheckConstraint> checkConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(checkConstraints, SQLCheckConstraint.class, fromPrewarm,\n+              MemberName.CHECK_CONSTRAINT, this.isCheckConstraintCacheDirty);\n     }\n \n     // Common method to cache constraints\n     private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n                              boolean fromPrewarm,\n-                             MemberName mn) {\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n       if (constraintsList == null || constraintsList.isEmpty()) {\n         return true;\n       }\n       try {\n         tableLock.writeLock().lock();\n-        final int[] size = {0};\n-        constraintsList.forEach(constraint -> {\n-          switch (mn) {\n-            case PRIMARY_KEY_CACHE:\n-              SQLPrimaryKey pk = (SQLPrimaryKey) constraint;\n-              this.primaryKeyCache.put(pk.getPk_name().toLowerCase(), pk);\n-              size[0] += getObjectSize(SQLPrimaryKey.class, constraint);\n-              break;\n-            case FOREIGN_KEY_CACHE:\n-              SQLForeignKey fk = (SQLForeignKey) constraint;\n-              this.foreignKeyCache.put(fk.getFk_name().toLowerCase(), fk);\n-              size[0] += getObjectSize(SQLForeignKey.class, constraint);\n-              break;\n-            case UNIQUE_CONSTRAINT_CACHE:\n-              SQLUniqueConstraint uc = (SQLUniqueConstraint) constraint;\n-              this.uniqueConstraintCache.put(uc.getUk_name().toLowerCase(), uc);\n-              size[0] += getObjectSize(SQLUniqueConstraint.class, constraint);\n-              break;\n-            case NOTNULL_CONSTRAINT_CACHE:\n-              SQLNotNullConstraint nn = (SQLNotNullConstraint) constraint;\n-              this.notNullConstraintCache.put(nn.getNn_name().toLowerCase(), nn);\n-              size[0] += getObjectSize(SQLNotNullConstraint.class, constraint);\n-              break;\n-            default:\n-              LOG.error(\"Should not reach here\");\n-              break;\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {\n+            SQLPrimaryKey key = (SQLPrimaryKey) constraintsList.get(i);\n+            this.primaryKeyCache.put(key.getPk_name(), key);\n+          } else if (constraintClass == SQLForeignKey.class) {\n+            SQLForeignKey key = (SQLForeignKey) constraintsList.get(i);\n+            this.foreignKeyMap.put(key.getFk_name(), key);\n+          } else if (constraintClass == SQLDefaultConstraint.class) {\n+            SQLDefaultConstraint key = (SQLDefaultConstraint) constraintsList.get(i);\n+            this.defaultConstraintMap.put(key.getDc_name(), key);\n+          } else if (constraintClass == SQLNotNullConstraint.class) {\n+            SQLNotNullConstraint key = (SQLNotNullConstraint) constraintsList.get(i);\n+            this.notNullConstraintMap.put(key.getNn_name(), key);\n+          } else if (constraintClass == SQLCheckConstraint.class) {\n+            SQLCheckConstraint key = (SQLCheckConstraint) constraintsList.get(i);\n+            this.checkConstraintMap.put(key.getDc_name(), key);\n+          } else if (constraintClass == SQLUniqueConstraint.class) {\n+            SQLUniqueConstraint key = (SQLUniqueConstraint) constraintsList.get(i);\n+            this.uniqueConstraintMap.put(key.getUk_name(), key);\n           }\n-        });\n+          size += getObjectSize(constraintClass, constraintsList.get(i));\n+        }\n \n         if (!fromPrewarm) {\n-          setMemberCacheUpdated(mn, true);\n+          dirtyConstaintVariable.set(true);\n         }\n \n-        updateMemberSize(mn, size[0], SizeMode.Delta);\n+        updateMemberSize(mn, size, SizeMode.Delta);\n         return true;\n       } finally {\n         tableLock.writeLock().unlock();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MTM5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452771399", "bodyText": "Shall add catalog, db and table names in the log msg otherwise this is no use. Same for other methods too.", "author": "sankarh", "createdAt": "2020-07-10T10:51:19Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name().toLowerCase(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n+        LOG.debug(\"Primary keys refresh in cache was successful.\");", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 85118052fa..c0c418e244 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -635,120 +725,45 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n-        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n           constraintClass = SQLPrimaryKey.class;\n-        } else if (this.foreignKeyCache.containsKey(name)) {\n-          constraint = this.foreignKeyCache.remove(name);\n+        } else if (this.foreignKeyMap.containsKey(name)) {\n+          constraint = this.foreignKeyMap.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n           constraintClass = SQLForeignKey.class;\n-        } else if (this.notNullConstraintCache.containsKey(name)) {\n-          constraint = this.notNullConstraintCache.remove(name);\n-          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+        } else if (this.defaultConstraintMap.containsKey(name)) {\n+          constraint = this.defaultConstraintMap.remove(name);\n+          mn = MemberName.DEFAULT_CONSTRAINT_CACHE;\n+          isDefaultConstraintCacheDirty.set(true);\n+          constraintClass = SQLDefaultConstraint.class;\n+        } else if (this.checkConstraintMap.containsKey(name)) {\n+          constraint = this.checkConstraintMap.remove(name);\n+          mn = MemberName.CHECK_CONSTRAINT;\n+          isCheckConstraintCacheDirty.set(true);\n+          constraintClass = SQLCheckConstraint.class;\n+        } else if (this.notNullConstraintMap.containsKey(name)) {\n+          constraint = this.notNullConstraintMap.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT;\n+          isNotNullConstraintCacheDirty.set(true);\n           constraintClass = SQLNotNullConstraint.class;\n-        } else if (this.uniqueConstraintCache.containsKey(name)) {\n-          constraint = this.uniqueConstraintCache.remove(name);\n-          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+        } else if (this.uniqueConstraintMap.containsKey(name)) {\n+          constraint = this.uniqueConstraintMap.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT;\n+          isUniqueConstraintCacheDirty.set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n         if(constraint == null) {\n-          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          // Should not reach here\n           return;\n         }\n-        setMemberCacheUpdated(mn, true);\n         int size = getObjectSize(constraintClass, constraint);\n         updateMemberSize(mn, -1 * size, SizeMode.Delta);\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n-      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLPrimaryKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n-                    + \"; the primary keys we have is dirty.\");\n-            return;\n-          }\n-          newKeys.put(key.getPk_name().toLowerCase(), key);\n-          size += getObjectSize(SQLPrimaryKey.class, key);\n-        }\n-        primaryKeyCache = newKeys;\n-        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Primary keys refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshForeignKeys(List<SQLForeignKey> keys) {\n-      Map<String, SQLForeignKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLForeignKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping foreign key cache update for table: \" + getTable().getTableName()\n-                    + \"; the foreign keys we have is dirty.\");\n-            return;\n-          }\n-          newKeys.put(key.getFk_name().toLowerCase(), key);\n-          size += getObjectSize(SQLForeignKey.class, key);\n-        }\n-        foreignKeyCache = newKeys;\n-        updateMemberSize(MemberName.FOREIGN_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Foreign keys refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshNotNullConstraints(List<SQLNotNullConstraint> constraints) {\n-      Map<String, SQLNotNullConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLNotNullConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping not null constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the not null constraints we have is dirty.\");\n-            return;\n-          }\n-          newConstraints.put(constraint.getNn_name().toLowerCase(), constraint);\n-          size += getObjectSize(SQLNotNullConstraint.class, constraint);\n-        }\n-        notNullConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.NOTNULL_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Not null constraints refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n \n-    public void refreshUniqueConstraints(List<SQLUniqueConstraint> constraints) {\n-      Map<String, SQLUniqueConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLUniqueConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping unique constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the unique costraints we have is dirty.\");\n-            return;\n-          }\n-          newConstraints.put(constraint.getUk_name().toLowerCase(), constraint);\n-          size += getObjectSize(SQLUniqueConstraint.class, constraint);\n-        }\n-        uniqueConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.UNIQUE_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Unique constraints refresh in cache was successful.\");\n       } finally {\n         tableLock.writeLock().unlock();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MjMwMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452772300", "bodyText": "The debug log msg is confusing. It says, primary keys is dirty and so skipping the update. I think, it should be \"Skipping the primary keys update for table:  as it was already refreshed.\"\nSame for other methods too.", "author": "sankarh", "createdAt": "2020-07-10T10:53:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\nindex 85118052fa..c0c418e244 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java\n\n@@ -635,120 +725,45 @@ public void removeConstraint(String name) {\n         Object constraint = null;\n         MemberName mn = null;\n         Class constraintClass = null;\n-        name = name.toLowerCase();\n         if (this.primaryKeyCache.containsKey(name)) {\n           constraint = this.primaryKeyCache.remove(name);\n           mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n           constraintClass = SQLPrimaryKey.class;\n-        } else if (this.foreignKeyCache.containsKey(name)) {\n-          constraint = this.foreignKeyCache.remove(name);\n+        } else if (this.foreignKeyMap.containsKey(name)) {\n+          constraint = this.foreignKeyMap.remove(name);\n           mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n           constraintClass = SQLForeignKey.class;\n-        } else if (this.notNullConstraintCache.containsKey(name)) {\n-          constraint = this.notNullConstraintCache.remove(name);\n-          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+        } else if (this.defaultConstraintMap.containsKey(name)) {\n+          constraint = this.defaultConstraintMap.remove(name);\n+          mn = MemberName.DEFAULT_CONSTRAINT_CACHE;\n+          isDefaultConstraintCacheDirty.set(true);\n+          constraintClass = SQLDefaultConstraint.class;\n+        } else if (this.checkConstraintMap.containsKey(name)) {\n+          constraint = this.checkConstraintMap.remove(name);\n+          mn = MemberName.CHECK_CONSTRAINT;\n+          isCheckConstraintCacheDirty.set(true);\n+          constraintClass = SQLCheckConstraint.class;\n+        } else if (this.notNullConstraintMap.containsKey(name)) {\n+          constraint = this.notNullConstraintMap.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT;\n+          isNotNullConstraintCacheDirty.set(true);\n           constraintClass = SQLNotNullConstraint.class;\n-        } else if (this.uniqueConstraintCache.containsKey(name)) {\n-          constraint = this.uniqueConstraintCache.remove(name);\n-          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+        } else if (this.uniqueConstraintMap.containsKey(name)) {\n+          constraint = this.uniqueConstraintMap.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT;\n+          isUniqueConstraintCacheDirty.set(true);\n           constraintClass = SQLUniqueConstraint.class;\n         }\n \n         if(constraint == null) {\n-          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          // Should not reach here\n           return;\n         }\n-        setMemberCacheUpdated(mn, true);\n         int size = getObjectSize(constraintClass, constraint);\n         updateMemberSize(mn, -1 * size, SizeMode.Delta);\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n-      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLPrimaryKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n-                    + \"; the primary keys we have is dirty.\");\n-            return;\n-          }\n-          newKeys.put(key.getPk_name().toLowerCase(), key);\n-          size += getObjectSize(SQLPrimaryKey.class, key);\n-        }\n-        primaryKeyCache = newKeys;\n-        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Primary keys refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshForeignKeys(List<SQLForeignKey> keys) {\n-      Map<String, SQLForeignKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLForeignKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping foreign key cache update for table: \" + getTable().getTableName()\n-                    + \"; the foreign keys we have is dirty.\");\n-            return;\n-          }\n-          newKeys.put(key.getFk_name().toLowerCase(), key);\n-          size += getObjectSize(SQLForeignKey.class, key);\n-        }\n-        foreignKeyCache = newKeys;\n-        updateMemberSize(MemberName.FOREIGN_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Foreign keys refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshNotNullConstraints(List<SQLNotNullConstraint> constraints) {\n-      Map<String, SQLNotNullConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLNotNullConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping not null constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the not null constraints we have is dirty.\");\n-            return;\n-          }\n-          newConstraints.put(constraint.getNn_name().toLowerCase(), constraint);\n-          size += getObjectSize(SQLNotNullConstraint.class, constraint);\n-        }\n-        notNullConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.NOTNULL_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Not null constraints refresh in cache was successful.\");\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n \n-    public void refreshUniqueConstraints(List<SQLUniqueConstraint> constraints) {\n-      Map<String, SQLUniqueConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLUniqueConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping unique constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the unique costraints we have is dirty.\");\n-            return;\n-          }\n-          newConstraints.put(constraint.getUk_name().toLowerCase(), constraint);\n-          size += getObjectSize(SQLUniqueConstraint.class, constraint);\n-        }\n-        uniqueConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.UNIQUE_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Unique constraints refresh in cache was successful.\");\n       } finally {\n         tableLock.writeLock().unlock();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3NTc2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452775760", "bodyText": "Can we add foreign keys for multiple parent db/tbl and get it from cache to verify if return correct fk?", "author": "sankarh", "createdAt": "2020-07-10T11:01:57Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1556,6 +1543,289 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLPrimaryKey modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\nindex 407960d7f0..f2e665941d 100644\n--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n\n@@ -1543,289 +1556,6 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n-  @Test\n-  public void testPrimaryKeys() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n-    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLPrimaryKey modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setPk_name(\"pk_modified\");\n-\n-    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-      Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-      Arrays.asList(modifiedKey));\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    // remove constraints\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testNotNullConstraint() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n-    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLNotNullConstraint modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setNn_name(\"nn_modified\");\n-\n-    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n-\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testUniqueConstraint() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n-    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLUniqueConstraint modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setUk_name(\"uk_modified\");\n-\n-    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testForeignKeys() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n-    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    // List operation with different parent table\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"dummyDB\", \"dummyTable\");\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    SQLForeignKey modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setFkcolumn_name(\"col3\");\n-    modifiedKey.setFk_name(\"fk_modified\");\n-\n-    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk1\");\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-      DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col3\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  private List<SQLPrimaryKey> createPrimaryKeys(Table tbl) {\n-    SQLPrimaryKey key = new SQLPrimaryKey(tbl.getDbName(), tbl.getTableName(), \"col1\",\n-            1, \"pk1\",false, false, false);\n-    key.setCatName(DEFAULT_CATALOG_NAME);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLNotNullConstraint> createNotNullConstraint(Table tbl) {\n-    SQLNotNullConstraint key = new SQLNotNullConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            \"col1\", \"nn1\",false, false, false);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLUniqueConstraint> createUniqueConstraint(Table tbl) {\n-    SQLUniqueConstraint key = new SQLUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            \"col1\", 1, \"uk1\",false, false, false);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLForeignKey> createForeignKeys(Table primaryKeytbl, Table foreignKeyTbl) {\n-    String foreignKeyColumn;\n-    if (primaryKeytbl == foreignKeyTbl) {\n-      foreignKeyColumn = \"col2\";\n-    } else {\n-      foreignKeyColumn = \"col1\";\n-    }\n-    SQLForeignKey key = new SQLForeignKey(primaryKeytbl.getDbName(), primaryKeytbl.getTableName(), \"col1\",\n-            foreignKeyTbl.getDbName(), foreignKeyTbl.getTableName(), foreignKeyColumn,\n-            1,1,1, \"fk1\", \"pk1\", false, false, false);\n-    key.setCatName(DEFAULT_CATALOG_NAME);\n-\n-    return Arrays.asList(key);\n-  }\n-\n   private Table createTable(String dbName, String tblName, List<FieldSchema> cols, List<FieldSchema> ptnCols) {\n     SerDeInfo serdeInfo = new SerDeInfo(\"serde\", \"seriallib\", new HashMap<>());\n     StorageDescriptor sd = new StorageDescriptor(cols, \"file:/tmp\", \"input\", \"output\", false, 0, serdeInfo, null, null,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgwNjM3OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452806379", "bodyText": "Also validate if parent tbl name is proper too.", "author": "sankarh", "createdAt": "2020-07-10T12:16:33Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1754,6 +1760,16 @@ public void testForeignKeys() {\n     Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n     Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n \n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl1.getDbName(), tbl1.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk2\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col1\");", "originalCommit": "fec5a1770f598b7f1d9c1d3c1dcd674e9a69d93c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgxNjI1Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452816256", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-10T12:37:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgwNjM3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "73ad4f6db3ff0a4640347e88380a3055b9041880", "chunk": "diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\nindex 905d7ed5f9..f2e665941d 100644\n--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java\n\n@@ -1543,305 +1556,6 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n-  @Test\n-  public void testPrimaryKeys() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n-    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLPrimaryKey modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setPk_name(\"pk_modified\");\n-\n-    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-      Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-      Arrays.asList(modifiedKey));\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    // remove constraints\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testNotNullConstraint() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n-    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLNotNullConstraint modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setNn_name(\"nn_modified\");\n-\n-    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n-\n-    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testUniqueConstraint() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n-\n-    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n-    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-\n-    // List operation\n-    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    SQLUniqueConstraint modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setColumn_name(\"col2\");\n-    modifiedKey.setUk_name(\"uk_modified\");\n-\n-    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  @Test\n-  public void testForeignKeys() {\n-    Configuration conf = MetastoreConf.newMetastoreConf();\n-    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n-    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n-    MetaStoreTestUtils.setConfForStandloneMode(conf);\n-    CachedStore cachedStore = new CachedStore();\n-    CachedStore.clearSharedCache();\n-    cachedStore.setConfForTest(conf);\n-    SharedCache sharedCache = CachedStore.getSharedCache();\n-\n-    Database db = createDatabaseObject(\"db\", \"testUser\");\n-    Database db1 = createDatabaseObject(\"db1\", \"testUser\");\n-    Table tbl = createUnpartitionedTableObject(db);\n-    Table tbl1 = createUnpartitionedTableObject(db1);\n-\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n-    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db1\", tbl1.getTableName(), tbl1);\n-\n-    Assert.assertEquals(sharedCache.getCachedTableCount(), 2);\n-\n-    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl, \"fk1\");\n-    List<SQLForeignKey> extraKeys = createForeignKeys(tbl1, tbl, \"fk2\");\n-\n-    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n-    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), extraKeys);\n-\n-    // List operation\n-    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk1\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl1.getDbName(), tbl1.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk2\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col1\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk2\");\n-    // List operation with different parent table\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"dummyDB\", \"dummyTable\");\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    SQLForeignKey modifiedKey = origKeys.get(0).deepCopy();\n-    modifiedKey.setFkcolumn_name(\"col3\");\n-    modifiedKey.setFk_name(\"fk_modified\");\n-\n-    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            Arrays.asList(modifiedKey));\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-\n-    Assert.assertEquals(cachedKeys.size(), 2);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk1\");\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-      DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 1);\n-    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk_modified\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n-    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col3\");\n-    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n-\n-    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk_modified\");\n-\n-    cachedKeys = sharedCache.listCachedForeignKeys(\n-            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n-    Assert.assertEquals(cachedKeys.size(), 0);\n-\n-    cachedStore.shutdown();\n-  }\n-\n-  private List<SQLPrimaryKey> createPrimaryKeys(Table tbl) {\n-    SQLPrimaryKey key = new SQLPrimaryKey(tbl.getDbName(), tbl.getTableName(), \"col1\",\n-            1, \"pk1\",false, false, false);\n-    key.setCatName(DEFAULT_CATALOG_NAME);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLNotNullConstraint> createNotNullConstraint(Table tbl) {\n-    SQLNotNullConstraint key = new SQLNotNullConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            \"col1\", \"nn1\",false, false, false);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLUniqueConstraint> createUniqueConstraint(Table tbl) {\n-    SQLUniqueConstraint key = new SQLUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n-            \"col1\", 1, \"uk1\",false, false, false);\n-\n-    return Arrays.asList(key);\n-  }\n-\n-  private List<SQLForeignKey> createForeignKeys(Table primaryKeytbl, Table foreignKeyTbl, String fKeyName) {\n-    String foreignKeyColumn;\n-    if (primaryKeytbl == foreignKeyTbl) {\n-      foreignKeyColumn = \"col2\";\n-    } else {\n-      foreignKeyColumn = \"col1\";\n-    }\n-    SQLForeignKey key = new SQLForeignKey(primaryKeytbl.getDbName(), primaryKeytbl.getTableName(), \"col1\",\n-            foreignKeyTbl.getDbName(), foreignKeyTbl.getTableName(), foreignKeyColumn,\n-            1,1,1, fKeyName, \"pk1\", false, false, false);\n-    key.setCatName(DEFAULT_CATALOG_NAME);\n-\n-    return Arrays.asList(key);\n-  }\n-\n   private Table createTable(String dbName, String tblName, List<FieldSchema> cols, List<FieldSchema> ptnCols) {\n     SerDeInfo serdeInfo = new SerDeInfo(\"serde\", \"seriallib\", new HashMap<>());\n     StorageDescriptor sd = new StorageDescriptor(cols, \"file:/tmp\", \"input\", \"output\", false, 0, serdeInfo, null, null,\n"}}, {"oid": "73ad4f6db3ff0a4640347e88380a3055b9041880", "url": "https://github.com/apache/hive/commit/73ad4f6db3ff0a4640347e88380a3055b9041880", "message": "First cut for adding constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "url": "https://github.com/apache/hive/commit/830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "message": "Add updation of cache", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "005ea861cb6294d7dc41d5e92212d4596d5c502d", "url": "https://github.com/apache/hive/commit/005ea861cb6294d7dc41d5e92212d4596d5c502d", "message": "Remove check/default constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "eccc6b05557e691449ecdb733db53a7d17e0dae9", "url": "https://github.com/apache/hive/commit/eccc6b05557e691449ecdb733db53a7d17e0dae9", "message": "Add foreign keys caching", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f8a0b062f67192d9725938afbc74dbc76ab0cb84", "url": "https://github.com/apache/hive/commit/f8a0b062f67192d9725938afbc74dbc76ab0cb84", "message": "Add UT for constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "29fb02300a3074fe2c42657573b9d5934c97167a", "url": "https://github.com/apache/hive/commit/29fb02300a3074fe2c42657573b9d5934c97167a", "message": "Add test for foreign key constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f5e877da60fdb8d085476ea13678c88e826f0359", "url": "https://github.com/apache/hive/commit/f5e877da60fdb8d085476ea13678c88e826f0359", "message": "renaming variables/reorganizing imports", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "url": "https://github.com/apache/hive/commit/ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "message": "dummy commit to re-run the tests", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "c8828383f824cf3f52572175e4173e72f0fab15b", "url": "https://github.com/apache/hive/commit/c8828383f824cf3f52572175e4173e72f0fab15b", "message": "Fix review comment part 1", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "url": "https://github.com/apache/hive/commit/68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "message": "address review comments part 2", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "url": "https://github.com/apache/hive/commit/936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "message": "Fix tests failure", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "d0706fccc68e2660be42d8469d5d9a2d005ecc17", "url": "https://github.com/apache/hive/commit/d0706fccc68e2660be42d8469d5d9a2d005ecc17", "message": "Fix compilation issue", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "54b837f6c487d91071bb7dd14c0419507a61ecbd", "url": "https://github.com/apache/hive/commit/54b837f6c487d91071bb7dd14c0419507a61ecbd", "message": "Review comments p3", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f5dacc72f1dab8cf77d296998cc05cf271179c03", "url": "https://github.com/apache/hive/commit/f5dacc72f1dab8cf77d296998cc05cf271179c03", "message": "review comments", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "3e980fd88bce3d98bef1216b08ab1e4b907c495b", "url": "https://github.com/apache/hive/commit/3e980fd88bce3d98bef1216b08ab1e4b907c495b", "message": "Validate parent db/table too for fk", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "7a9d425b708317de126943613d72228f94b502d1", "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "message": "Fix enum accessor", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "7a9d425b708317de126943613d72228f94b502d1", "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "message": "Fix enum accessor", "committedDate": "2020-07-12T03:56:25Z", "type": "forcePushed"}]}