{"pr_number": 1070, "pr_title": "HIVE-19653: Incorrect predicate pushdown for groupby with grouping sets.", "pr_createdAt": "2020-06-07T09:29:54Z", "pr_url": "https://github.com/apache/hive/pull/1070", "timeline": [{"oid": "49221e186ebf0503b1a01e52920a802d05983711", "url": "https://github.com/apache/hive/commit/49221e186ebf0503b1a01e52920a802d05983711", "message": "HIVE-19653: Incorrect predicate pushdown for groupby with grouping sets.", "committedDate": "2020-06-07T08:34:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyMTQyMg==", "url": "https://github.com/apache/hive/pull/1070#discussion_r437021422", "bodyText": "Please use a while.", "author": "jcamachor", "createdAt": "2020-06-08T21:50:40Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java", "diffHunk": "@@ -733,6 +736,97 @@ private void applyFilterTransitivity(JoinOperator join, int targetPos, OpWalkerI\n     }\n   }\n \n+  public static class GroupByPPD extends DefaultPPD implements SemanticNodeProcessor {\n+\n+    @Override\n+    public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,\n+        Object... nodeOutputs) throws SemanticException {\n+      super.process(nd, stack, procCtx, nodeOutputs);\n+      OpWalkerInfo owi = (OpWalkerInfo) procCtx;\n+      GroupByDesc groupByDesc = ((GroupByOperator)nd).getConf();\n+      ExprWalkerInfo prunedPred = owi.getPrunedPreds((Operator<? extends OperatorDesc>) nd);\n+      if (prunedPred == null || !prunedPred.hasAnyCandidates() ||\n+          !groupByDesc.isGroupingSetsPresent()) {\n+        return null;\n+      }\n+\n+      List<Long> groupingSets = groupByDesc.getListGroupingSets();\n+      Map<String, List<ExprNodeDesc>> candidates = prunedPred.getFinalCandidates();\n+      FastBitSet[] fastBitSets = new FastBitSet[groupingSets.size()];\n+      int groupingSetPosition = groupByDesc.getGroupingSetPosition();\n+      for (int pos = 0; pos < fastBitSets.length; pos ++) {\n+        fastBitSets[pos] = GroupByOperator.groupingSet2BitSet(groupingSets.get(pos),\n+            groupingSetPosition);\n+      }\n+      List<ExprNodeDesc> groupByKeys = ((GroupByOperator)nd).getConf().getKeys();\n+      Map<ExprNodeDesc, ExprNodeDesc> newToOldExprMap = prunedPred.getNewToOldExprMap();\n+      Map<String, List<ExprNodeDesc>> nonFinalCandidates = new HashMap<String, List<ExprNodeDesc>>();\n+      for (Iterator<Map.Entry<String, List<ExprNodeDesc>>>", "originalCommit": "49221e186ebf0503b1a01e52920a802d05983711", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2MjEzNQ==", "url": "https://github.com/apache/hive/pull/1070#discussion_r437062135", "bodyText": "Done, Thanks @jcamachor for the review!", "author": "dengzhhu653", "createdAt": "2020-06-08T23:51:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyMTQyMg=="}], "type": "inlineReview", "revised_code": {"commit": "dd415a0180294286b0b53c939c557b2874cd154c", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\nindex a53eda916c..6c66260e56 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\n\n@@ -761,8 +761,8 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,\n       List<ExprNodeDesc> groupByKeys = ((GroupByOperator)nd).getConf().getKeys();\n       Map<ExprNodeDesc, ExprNodeDesc> newToOldExprMap = prunedPred.getNewToOldExprMap();\n       Map<String, List<ExprNodeDesc>> nonFinalCandidates = new HashMap<String, List<ExprNodeDesc>>();\n-      for (Iterator<Map.Entry<String, List<ExprNodeDesc>>>\n-           iter = candidates.entrySet().iterator(); iter.hasNext(); ) {\n+      Iterator<Map.Entry<String, List<ExprNodeDesc>>> iter = candidates.entrySet().iterator();\n+      while (iter.hasNext()) {\n         Map.Entry<String, List<ExprNodeDesc>> entry = iter.next();\n         List<ExprNodeDesc> residualExprs = new ArrayList<ExprNodeDesc>();\n         List<ExprNodeDesc> finalCandidates = new ArrayList<ExprNodeDesc>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyMTU5NA==", "url": "https://github.com/apache/hive/pull/1070#discussion_r437021594", "bodyText": "Please use a while.", "author": "jcamachor", "createdAt": "2020-06-08T21:51:05Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java", "diffHunk": "@@ -733,6 +736,97 @@ private void applyFilterTransitivity(JoinOperator join, int targetPos, OpWalkerI\n     }\n   }\n \n+  public static class GroupByPPD extends DefaultPPD implements SemanticNodeProcessor {\n+\n+    @Override\n+    public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,\n+        Object... nodeOutputs) throws SemanticException {\n+      super.process(nd, stack, procCtx, nodeOutputs);\n+      OpWalkerInfo owi = (OpWalkerInfo) procCtx;\n+      GroupByDesc groupByDesc = ((GroupByOperator)nd).getConf();\n+      ExprWalkerInfo prunedPred = owi.getPrunedPreds((Operator<? extends OperatorDesc>) nd);\n+      if (prunedPred == null || !prunedPred.hasAnyCandidates() ||\n+          !groupByDesc.isGroupingSetsPresent()) {\n+        return null;\n+      }\n+\n+      List<Long> groupingSets = groupByDesc.getListGroupingSets();\n+      Map<String, List<ExprNodeDesc>> candidates = prunedPred.getFinalCandidates();\n+      FastBitSet[] fastBitSets = new FastBitSet[groupingSets.size()];\n+      int groupingSetPosition = groupByDesc.getGroupingSetPosition();\n+      for (int pos = 0; pos < fastBitSets.length; pos ++) {\n+        fastBitSets[pos] = GroupByOperator.groupingSet2BitSet(groupingSets.get(pos),\n+            groupingSetPosition);\n+      }\n+      List<ExprNodeDesc> groupByKeys = ((GroupByOperator)nd).getConf().getKeys();\n+      Map<ExprNodeDesc, ExprNodeDesc> newToOldExprMap = prunedPred.getNewToOldExprMap();\n+      Map<String, List<ExprNodeDesc>> nonFinalCandidates = new HashMap<String, List<ExprNodeDesc>>();\n+      for (Iterator<Map.Entry<String, List<ExprNodeDesc>>>\n+           iter = candidates.entrySet().iterator(); iter.hasNext(); ) {\n+        Map.Entry<String, List<ExprNodeDesc>> entry = iter.next();\n+        List<ExprNodeDesc> residualExprs = new ArrayList<ExprNodeDesc>();\n+        List<ExprNodeDesc> finalCandidates = new ArrayList<ExprNodeDesc>();\n+        List<ExprNodeDesc> exprs = entry.getValue();\n+        for (ExprNodeDesc expr : exprs) {\n+          if (canPredPushdown(expr, groupByKeys, fastBitSets, groupingSetPosition)) {\n+            finalCandidates.add(expr);\n+          } else {\n+            residualExprs.add(newToOldExprMap.get(expr));\n+          }\n+        }\n+        if (!residualExprs.isEmpty()) {\n+          nonFinalCandidates.put(entry.getKey(), residualExprs);\n+        }\n+\n+        if (finalCandidates.isEmpty()) {\n+          iter.remove();\n+        } else {\n+          exprs.clear();\n+          exprs.addAll(finalCandidates);\n+        }\n+      }\n+      \n+      if (!nonFinalCandidates.isEmpty()) {\n+        createFilter((Operator) nd, nonFinalCandidates, owi);\n+      }\n+      return null;\n+    }\n+\n+    private boolean canPredPushdown(ExprNodeDesc expr, List<ExprNodeDesc> groupByKeys,\n+        FastBitSet[] bitSets, int groupingSetPosition) {\n+      List<ExprNodeDesc> columns = new ArrayList<ExprNodeDesc>();\n+      extractCols(expr, columns);\n+      for (ExprNodeDesc col : columns) {\n+        int index = groupByKeys.indexOf(col);\n+        assert index >= 0;\n+        for (FastBitSet bitset : bitSets) {\n+          int keyPos = bitset.nextClearBit(0);\n+          for (; keyPos < groupingSetPosition && keyPos != index;", "originalCommit": "49221e186ebf0503b1a01e52920a802d05983711", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzExMjUzNA==", "url": "https://github.com/apache/hive/pull/1070#discussion_r437112534", "bodyText": "Done", "author": "dengzhhu653", "createdAt": "2020-06-09T03:07:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzAyMTU5NA=="}], "type": "inlineReview", "revised_code": {"commit": "dd415a0180294286b0b53c939c557b2874cd154c", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java b/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\nindex a53eda916c..6c66260e56 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java\n\n@@ -761,8 +761,8 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx,\n       List<ExprNodeDesc> groupByKeys = ((GroupByOperator)nd).getConf().getKeys();\n       Map<ExprNodeDesc, ExprNodeDesc> newToOldExprMap = prunedPred.getNewToOldExprMap();\n       Map<String, List<ExprNodeDesc>> nonFinalCandidates = new HashMap<String, List<ExprNodeDesc>>();\n-      for (Iterator<Map.Entry<String, List<ExprNodeDesc>>>\n-           iter = candidates.entrySet().iterator(); iter.hasNext(); ) {\n+      Iterator<Map.Entry<String, List<ExprNodeDesc>>> iter = candidates.entrySet().iterator();\n+      while (iter.hasNext()) {\n         Map.Entry<String, List<ExprNodeDesc>> entry = iter.next();\n         List<ExprNodeDesc> residualExprs = new ArrayList<ExprNodeDesc>();\n         List<ExprNodeDesc> finalCandidates = new ArrayList<ExprNodeDesc>();\n"}}, {"oid": "dd415a0180294286b0b53c939c557b2874cd154c", "url": "https://github.com/apache/hive/commit/dd415a0180294286b0b53c939c557b2874cd154c", "message": "change loop", "committedDate": "2020-06-10T01:07:21Z", "type": "commit"}, {"oid": "dd415a0180294286b0b53c939c557b2874cd154c", "url": "https://github.com/apache/hive/commit/dd415a0180294286b0b53c939c557b2874cd154c", "message": "change loop", "committedDate": "2020-06-10T01:07:21Z", "type": "forcePushed"}]}