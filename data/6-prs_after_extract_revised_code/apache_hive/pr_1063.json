{"pr_number": 1063, "pr_title": "HIVE-23617: Fixing storage-api FindBug issues", "pr_createdAt": "2020-06-05T12:51:23Z", "pr_url": "https://github.com/apache/hive/pull/1063", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436048066", "bodyText": "Isn't there a SuppressFBWarnings annotation in findbugs package? Why do we need to introduce our own annotation?", "author": "mustafaiman", "createdAt": "2020-06-05T17:01:18Z", "path": "storage-api/src/java/org/apache/hive/common/util/SuppressFBWarnings.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.apache.hive.common.util;\n+\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+\n+@Retention(RetentionPolicy.CLASS)\n+public @interface SuppressFBWarnings {", "originalCommit": "ed084759cc57675eaecc774ffbd5633099a2771e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MzY3Nw==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436063677", "bodyText": "Hey @mustafaiman  -- in the main pom.xml we are only using the finbugs-maven-plugin and not the findbugs-annotation package (only hive-ql is using it as dependency and I would like to remove it eventually).\nIn order to avoid adding just another dependency (findbugs-annotation), I implemented the annotation as a separate class, Findbugs doesn't care in which package the annotation is, so it works pretty well -- we can also reuse it across hive packages.\nhttps://sourceforge.net/p/findbugs/feature-requests/298/#5e88", "author": "pgaref", "createdAt": "2020-06-05T17:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3Njc5NQ==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436076795", "bodyText": "If we are defining our own annotation, I would like to put it in a common to prevent each module having their own copy of the same annotation. I thought hive-common would be a good candidate but storage-api does not depend on hive-common either. This looks like the only way then. Thanks for the link.", "author": "mustafaiman", "createdAt": "2020-06-05T17:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA0ODA2Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436118081", "bodyText": "I think it's a little bit more than this.  There shouldn't be any \"+\" concatenation.  Should all be .append()\nI already proposed to addressed this issue (HIVE-23540), but happy to defer to this PR\nhttps://issues.apache.org/jira/browse/HIVE-23540", "author": "belugabehr", "createdAt": "2020-06-05T19:20:25Z", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +78,13 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuffer bufStr = new StringBuffer();\n       if (cacheBuffers != null) {\n         for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");", "originalCommit": "ed084759cc57675eaecc774ffbd5633099a2771e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNTQ5Ng==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436125496", "bodyText": "Hey @belugabehr  -- I see your point.\nSure, happy to integrate HIVE-23540 here.", "author": "pgaref", "createdAt": "2020-06-05T19:38:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyNzcyMA==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436127720", "bodyText": "Updated", "author": "pgaref", "createdAt": "2020-06-05T19:43:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODA4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6bcfcc34c2ea1215a58f697f1c547619e80c2d15", "chunk": "diff --git a/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java b/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\nindex d00919e3dd..037c1cec5a 100644\n--- a/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\n+++ b/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\n\n@@ -78,13 +79,21 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      StringBuffer bufStr = new StringBuffer();\n+      StringBuilder sb = new StringBuilder();\n       if (cacheBuffers != null) {\n-        for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");\n+        Iterator<MemoryBuffer> iter = cacheBuffers.iterator();\n+        while (iter.hasNext()) {\n+          MemoryBuffer mb = iter.next();\n+          sb.append(mb.getClass().getSimpleName());\n+          sb.append(\" with \");\n+          sb.append(mb.getByteBufferRaw().remaining());\n+          sb.append(\" bytes\");\n+          if (iter.hasNext()) {\n+            sb.append(\", \");\n+          }\n         }\n       }\n-      return \"ColumnStreamData [cacheBuffers=[\" + bufStr.toString()\n+      return \"ColumnStreamData [cacheBuffers=[\" + sb.toString()\n           + \"], indexBaseOffset=\" + indexBaseOffset + \"]\";\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNjU4MQ==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436136581", "bodyText": "Will have to check this.  I think from my own patch experience, that this change might break a bunch of unit tests because they are checking the output of toString() which previously always adds a comma, even if it's not really needed.  I'm not 100%, but just FYI.", "author": "belugabehr", "createdAt": "2020-06-05T19:57:48Z", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java", "diffHunk": "@@ -78,13 +79,21 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      String bufStr = \"\";\n+      StringBuilder sb = new StringBuilder();\n       if (cacheBuffers != null) {\n-        for (MemoryBuffer mb : cacheBuffers) {\n-          bufStr += mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \";\n+        Iterator<MemoryBuffer> iter = cacheBuffers.iterator();\n+        while (iter.hasNext()) {\n+          MemoryBuffer mb = iter.next();\n+          sb.append(mb.getClass().getSimpleName());\n+          sb.append(\" with \");\n+          sb.append(mb.getByteBufferRaw().remaining());\n+          sb.append(\" bytes\");\n+          if (iter.hasNext()) {\n+            sb.append(\", \");", "originalCommit": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY1NDc4Nw==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436654787", "bodyText": "Tests passed so this change should be safe.", "author": "pgaref", "createdAt": "2020-06-08T12:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNjU4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "ed7ffa709d8c844fc15e6661c91aad214d47f64f", "chunk": "diff --git a/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java b/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\nindex 037c1cec5a..d00919e3dd 100644\n--- a/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\n+++ b/storage-api/src/java/org/apache/hadoop/hive/common/io/encoded/EncodedColumnBatch.java\n\n@@ -79,21 +78,13 @@ public void setIndexBaseOffset(int indexBaseOffset) {\n \n     @Override\n     public String toString() {\n-      StringBuilder sb = new StringBuilder();\n+      StringBuffer bufStr = new StringBuffer();\n       if (cacheBuffers != null) {\n-        Iterator<MemoryBuffer> iter = cacheBuffers.iterator();\n-        while (iter.hasNext()) {\n-          MemoryBuffer mb = iter.next();\n-          sb.append(mb.getClass().getSimpleName());\n-          sb.append(\" with \");\n-          sb.append(mb.getByteBufferRaw().remaining());\n-          sb.append(\" bytes\");\n-          if (iter.hasNext()) {\n-            sb.append(\", \");\n-          }\n+        for (MemoryBuffer mb : cacheBuffers) {\n+          bufStr.append(mb.getClass().getSimpleName() + \" with \" + mb.getByteBufferRaw().remaining() + \" bytes, \");\n         }\n       }\n-      return \"ColumnStreamData [cacheBuffers=[\" + sb.toString()\n+      return \"ColumnStreamData [cacheBuffers=[\" + bufStr.toString()\n           + \"], indexBaseOffset=\" + indexBaseOffset + \"]\";\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjYxNTY0OQ==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436615649", "bodyText": "this equals doesn't care about next/prev fields", "author": "kgyrtkirk", "createdAt": "2020-06-08T11:02:15Z", "path": "storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java", "diffHunk": "@@ -228,6 +228,16 @@ public long getTotalLength() {\n     return result;\n   }\n \n+  @Override\n+  public int hashCode() {\n+    return super.hashCode();\n+  }\n+\n+  @Override\n+  public boolean equals(Object other) {\n+    return super.equals(other);", "originalCommit": "36a933bb1e5eda6b73bcfe73b8302eb3956ac1e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY1NzU1Nw==", "url": "https://github.com/apache/hive/pull/1063#discussion_r436657557", "bodyText": "Addressed as part of 0e40c95\nAs discussed, let's make sure we update such methods across packages.", "author": "pgaref", "createdAt": "2020-06-08T12:32:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjYxNTY0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "ba037554a83d2ef8e6417216349351cc6c650bfd", "chunk": "diff --git a/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java b/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java\nindex 959ecbc39a..8f04732e26 100644\n--- a/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java\n+++ b/storage-api/src/java/org/apache/hadoop/hive/common/io/DiskRangeList.java\n\n@@ -229,13 +231,18 @@ public long getTotalLength() {\n   }\n \n   @Override\n-  public int hashCode() {\n-    return super.hashCode();\n+  public boolean equals(Object o) {\n+    if (this == o) return true;\n+    if (o == null || getClass() != o.getClass()) return false;\n+    if (!super.equals(o)) return false;\n+    DiskRangeList that = (DiskRangeList) o;\n+    return Objects.equals(prev, that.prev) &&\n+            Objects.equals(next, that.next);\n   }\n \n   @Override\n-  public boolean equals(Object other) {\n-    return super.equals(other);\n+  public int hashCode() {\n+    return Objects.hash(super.hashCode(), prev, next);\n   }\n \n   public static class CreateHelper {\n"}}, {"oid": "ed7ffa709d8c844fc15e6661c91aad214d47f64f", "url": "https://github.com/apache/hive/commit/ed7ffa709d8c844fc15e6661c91aad214d47f64f", "message": "Cleaning storage-api FindBug issues\n\nChange-Id: I077246ec60b59ba6c65fd86e416040a6fab7d12c", "committedDate": "2020-06-11T18:44:56Z", "type": "commit"}, {"oid": "90f25f7e4c5558613ada71f5932fbc9eccfa770e", "url": "https://github.com/apache/hive/commit/90f25f7e4c5558613ada71f5932fbc9eccfa770e", "message": "Up HiveIntervalDayTime\n\nChange-Id: Idbd68bd39ca0f9f57f507679da461667b985f016", "committedDate": "2020-06-11T18:44:56Z", "type": "commit"}, {"oid": "6bcfcc34c2ea1215a58f697f1c547619e80c2d15", "url": "https://github.com/apache/hive/commit/6bcfcc34c2ea1215a58f697f1c547619e80c2d15", "message": "Addressing comment regarding HIVE-23540\n\nChange-Id: I9814b6d5eea37e1c055b58b70f81d522b4def687", "committedDate": "2020-06-11T18:44:57Z", "type": "commit"}, {"oid": "ba037554a83d2ef8e6417216349351cc6c650bfd", "url": "https://github.com/apache/hive/commit/ba037554a83d2ef8e6417216349351cc6c650bfd", "message": "Addressing equals/hashcode comment to take into account class field (next, prev).\nLets make sure we update such methods across hive packages.\n\nChange-Id: I6be369010f581ab08d2b9d574b5495e754e132ee", "committedDate": "2020-06-11T18:44:57Z", "type": "commit"}, {"oid": "d2fea99781094ccb6f31b8fe2a3f17d0952794dc", "url": "https://github.com/apache/hive/commit/d2fea99781094ccb6f31b8fe2a3f17d0952794dc", "message": "Fix DiskRangeList equals/hashcode. This class provides just a simplistic iterator interface (check javadoc).\nThus, for equality/hashcode just check the actual DiskRange (super) content.\n\nChange-Id: I49f9cf0a632a485075a438d838765232167d0e41", "committedDate": "2020-06-11T18:44:57Z", "type": "commit"}, {"oid": "6e925bc94e2a3d1217cb6011041ac745c456cd99", "url": "https://github.com/apache/hive/commit/6e925bc94e2a3d1217cb6011041ac745c456cd99", "message": "Adding storage-api to Precheck findbugProjects\n\nChange-Id: I0cd289cc06f86b8d8e9c3ac66cad38c1854043a1", "committedDate": "2020-06-11T18:49:03Z", "type": "commit"}, {"oid": "6e925bc94e2a3d1217cb6011041ac745c456cd99", "url": "https://github.com/apache/hive/commit/6e925bc94e2a3d1217cb6011041ac745c456cd99", "message": "Adding storage-api to Precheck findbugProjects\n\nChange-Id: I0cd289cc06f86b8d8e9c3ac66cad38c1854043a1", "committedDate": "2020-06-11T18:49:03Z", "type": "forcePushed"}]}