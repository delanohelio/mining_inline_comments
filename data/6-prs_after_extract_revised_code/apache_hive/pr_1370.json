{"pr_number": 1370, "pr_title": "HIVE-23887: Reset table level basic/column stats during import", "pr_createdAt": "2020-08-06T16:49:55Z", "pr_url": "https://github.com/apache/hive/pull/1370", "timeline": [{"oid": "8dc467e9f6e640e10807db8c438327130b99d913", "url": "https://github.com/apache/hive/commit/8dc467e9f6e640e10807db8c438327130b99d913", "message": "HIVE-23887:Reset Columns stats in Export Statement", "committedDate": "2020-08-06T17:10:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MTkzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467461932", "bodyText": "Check the COLUMN_STATS_ACCURATE property is true on source table and partition before and after export operation to confirm we don't overwrite anything in their metadata.", "author": "sankarh", "createdAt": "2020-08-08T12:48:44Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +567,28 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex f129a5dfa3..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -568,26 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n-    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n+\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MTk0NA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467461944", "bodyText": "Can we also check the partition properties?", "author": "sankarh", "createdAt": "2020-08-08T12:49:10Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +567,28 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n+\n+    //load T\n+    runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex f129a5dfa3..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -568,26 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n-    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n+\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MjI3MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467462271", "bodyText": "There is already parameters != null check above in this method. Can we move this code there itself?", "author": "sankarh", "createdAt": "2020-08-08T12:53:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java", "diffHunk": "@@ -59,6 +61,11 @@ public void writeTo(JsonWriter writer, ReplicationSpec additionalPropertiesProvi\n                   additionalPropertiesProvider.getCurrentReplicationState());\n         }\n       }\n+\n+      if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java\nindex 75d2ed1959..ecd4c84651 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java\n\n@@ -61,11 +59,6 @@ public void writeTo(JsonWriter writer, ReplicationSpec additionalPropertiesProvi\n                   additionalPropertiesProvider.getCurrentReplicationState());\n         }\n       }\n-\n-      if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {\n-        parameters.remove(COLUMN_STATS_ACCURATE);\n-      }\n-\n       writer.jsonGenerator.writeString(serializer.toString(partition, UTF_8));\n       writer.jsonGenerator.flush();\n     } catch (TException e) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MjI5OA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467462298", "bodyText": "There is already parameters != null check above in this method. Can we move this code there itself?", "author": "sankarh", "createdAt": "2020-08-08T12:53:33Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java", "diffHunk": "@@ -96,6 +98,11 @@ private Table updatePropertiesInTable(Table table, ReplicationSpec additionalPro\n       // uncomment this else section, but currently unneeded. Will require a lot of golden file\n       // regen if we do so.\n     }\n+\n+    if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java\nindex a61f8610d3..898b839355 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java\n\n@@ -98,11 +96,6 @@ private Table updatePropertiesInTable(Table table, ReplicationSpec additionalPro\n       // uncomment this else section, but currently unneeded. Will require a lot of golden file\n       // regen if we do so.\n     }\n-\n-    if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {\n-      parameters.remove(COLUMN_STATS_ACCURATE);\n-    }\n-\n     return table;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ5OTE1MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471499151", "bodyText": "Can be combined with previous if block which also does the same thing. Also, the comment says \"column stats will be inaccurate\" but we are resetting both basic and column stats. Correct the log message and comment accordingly.", "author": "sankarh", "createdAt": "2020-08-17T14:00:38Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex a94b442a64..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -3177,15 +3178,12 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n       }\n       perfLogger.PerfLogEnd(\"MoveTask\", PerfLogger.FILE_MOVES);\n     }\n-    if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n-      LOG.debug(\"setting table statistics false for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n-    }\n \n-    //column stats will be inaccurate\n-    if (resetStatistics) {\n-      LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);\n+    // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+    // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+    if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+      LOG.debug(\"Clear table column statistics and set basic statistics to false for \" + tbl.getCompleteName());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n     }\n \n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ5OTQzOQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471499439", "bodyText": "Nit: Need a space after comma \",\".", "author": "sankarh", "createdAt": "2020-08-17T14:01:05Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex a94b442a64..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -3177,15 +3178,12 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n       }\n       perfLogger.PerfLogEnd(\"MoveTask\", PerfLogger.FILE_MOVES);\n     }\n-    if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n-      LOG.debug(\"setting table statistics false for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n-    }\n \n-    //column stats will be inaccurate\n-    if (resetStatistics) {\n-      LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);\n+    // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+    // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+    if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+      LOG.debug(\"Clear table column statistics and set basic statistics to false for \" + tbl.getCompleteName());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n     }\n \n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUwODQyNg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471508426", "bodyText": "Even during loadPartition, we need to reset stats in table properties as well which is missing now.", "author": "sankarh", "createdAt": "2020-08-17T14:15:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex a94b442a64..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -3177,15 +3178,12 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n       }\n       perfLogger.PerfLogEnd(\"MoveTask\", PerfLogger.FILE_MOVES);\n     }\n-    if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n-      LOG.debug(\"setting table statistics false for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n-    }\n \n-    //column stats will be inaccurate\n-    if (resetStatistics) {\n-      LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);\n+    // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+    // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+    if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+      LOG.debug(\"Clear table column statistics and set basic statistics to false for \" + tbl.getCompleteName());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(), StatsSetupConst.FALSE);\n     }\n \n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMDE2OQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471510169", "bodyText": "Nit: Add space before \"(\"", "author": "sankarh", "createdAt": "2020-08-17T14:17:34Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert\n+        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    //check basic stats in partition properties\n+    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n+    for(String rsPartition : rsPartitions) {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -389,36 +389,52 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n+    // Clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n-    final int[][] rows = {{3}};\n-    //now we have an archive with 3 partitions\n+    final int[][] rows = { { 3 } };\n+\n+    // Check Partitions statistics\n+    List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n+    for (String rsTstagePartition : rsTstagePartitionsProperties) {\n+      List<String> rsPartitionProperties =\n+          runStatementOnDriver(\"describe formatted Tstage partition(\" + rsTstagePartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n+    }\n+\n+    // Now we have an archive Tstage with 3 partitions\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n-\n-    //check basic stats in partition properties\n-    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n-    for(String rsPartition : rsPartitions) {\n-      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\"+ rsPartition +\")\");\n-      Assert\n-          .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsPartitionProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties of T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n+\n+    // Check Partitions statistics of T\n+    List<String> rsTPartitionsProperties = runStatementOnDriver(\"show partitions T\");\n+    for (String rsTPartition : rsTPartitionsProperties) {\n+      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\" + rsTPartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n     }\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMDQ3MA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471510470", "bodyText": "Nit: Add space before and after \"+\".", "author": "sankarh", "createdAt": "2020-08-17T14:17:58Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert\n+        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    //check basic stats in partition properties\n+    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n+    for(String rsPartition : rsPartitions) {\n+      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\"+ rsPartition +\")\");", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -389,36 +389,52 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n+    // Clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n-    final int[][] rows = {{3}};\n-    //now we have an archive with 3 partitions\n+    final int[][] rows = { { 3 } };\n+\n+    // Check Partitions statistics\n+    List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n+    for (String rsTstagePartition : rsTstagePartitionsProperties) {\n+      List<String> rsPartitionProperties =\n+          runStatementOnDriver(\"describe formatted Tstage partition(\" + rsTstagePartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n+    }\n+\n+    // Now we have an archive Tstage with 3 partitions\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n-\n-    //check basic stats in partition properties\n-    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n-    for(String rsPartition : rsPartitions) {\n-      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\"+ rsPartition +\")\");\n-      Assert\n-          .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsPartitionProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties of T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n+\n+    // Check Partitions statistics of T\n+    List<String> rsTPartitionsProperties = runStatementOnDriver(\"show partitions T\");\n+    for (String rsTPartition : rsTPartitionsProperties) {\n+      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\" + rsTPartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n     }\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTM0OQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511349", "bodyText": "Nit: Remove extra blank line.", "author": "sankarh", "createdAt": "2020-08-17T14:19:17Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTQ4Nw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511487", "bodyText": "Nit: Remove this blank line.", "author": "sankarh", "createdAt": "2020-08-17T14:19:31Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTg4MA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511880", "bodyText": "Nit: Add single blank line before a comment line. Check below places too.", "author": "sankarh", "createdAt": "2020-08-17T14:20:04Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMjcwNg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471512706", "bodyText": "The comment seems incorrect. This is non-partitioned table.", "author": "sankarh", "createdAt": "2020-08-17T14:21:21Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMzIyOA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471513228", "bodyText": "Comment incorrect. Tstage is source table.", "author": "sankarh", "createdAt": "2020-08-17T14:22:05Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyMDk0MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471520941", "bodyText": "Nit: The method definition and annotation can be in separate lines.", "author": "sankarh", "createdAt": "2020-08-17T14:33:10Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNDYzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471524632", "bodyText": "Can we check if stats are set in source table Tstage and their partitions?", "author": "sankarh", "createdAt": "2020-08-17T14:38:38Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -389,36 +389,52 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n+    // Clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n-    final int[][] rows = {{3}};\n-    //now we have an archive with 3 partitions\n+    final int[][] rows = { { 3 } };\n+\n+    // Check Partitions statistics\n+    List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n+    for (String rsTstagePartition : rsTstagePartitionsProperties) {\n+      List<String> rsPartitionProperties =\n+          runStatementOnDriver(\"describe formatted Tstage partition(\" + rsTstagePartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n+    }\n+\n+    // Now we have an archive Tstage with 3 partitions\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n-\n-    //check basic stats in partition properties\n-    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n-    for(String rsPartition : rsPartitions) {\n-      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\"+ rsPartition +\")\");\n-      Assert\n-          .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsPartitionProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties of T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n+\n+    // Check Partitions statistics of T\n+    List<String> rsTPartitionsProperties = runStatementOnDriver(\"show partitions T\");\n+    for (String rsTPartition : rsTPartitionsProperties) {\n+      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\" + rsTPartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTPartition + \" of T table\", false,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n     }\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNTIxNA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471525214", "bodyText": "Can we check if stats are set in source table Tstage?", "author": "sankarh", "createdAt": "2020-08-17T14:39:26Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNjM5Nw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471526397", "bodyText": "Can we also check if import sets stats to true in case of autostats_gather is set to true? For both partitioned and non-partitioned tables. Also check the values of stats listed in StatsSetupConst.SUPPORTED_STATS (atleast ROWNUM should match) in both source and target tables and they should match.", "author": "sankarh", "createdAt": "2020-08-17T14:41:04Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 47117c6dd1..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -582,31 +598,39 @@ public void testMMExportAborted() throws Exception {\n \n   }\n \n-\n-  @Test public void testImportOrc() throws Exception {\n-\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-    //this creates an ORC data file with correct schema under table root\n+\n+    // Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n-    //now we have an archive with 3 partitions\n+\n+    // Check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties\n-    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n-    Assert\n-        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+    // Check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n+        rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNTU0Mw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472335543", "bodyText": "Unused import.", "author": "sankarh", "createdAt": "2020-08-18T16:44:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -70,6 +70,7 @@\n \n import com.google.common.collect.ImmutableList;\n \n+import org.antlr.runtime.misc.Stats;", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -70,7 +70,6 @@\n \n import com.google.common.collect.ImmutableList;\n \n-import org.antlr.runtime.misc.Stats;\n import org.apache.calcite.plan.RelOptMaterialization;\n import org.apache.calcite.plan.hep.HepPlanner;\n import org.apache.calcite.plan.hep.HepProgramBuilder;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNjc3Mw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472336773", "bodyText": "Shall check resetStatistics first as it take less cpu cycles in positive flow.", "author": "sankarh", "createdAt": "2020-08-18T16:46:18Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -2449,12 +2448,11 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n \n-      //if hive.stats.autogather = false or resetStatistics = true then\n-      //clear partition column stats and set basic stats to false\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+      // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+      // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+      if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n         LOG.debug(\n-            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n-        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());\n+            \"Clear partition column statistics by setting basic stats to false for \" + newTPart.getCompleteName());\n         StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzODYzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472338632", "bodyText": "The comment can answer the \"why\" rather than \"what\". The below if statement is self explanatory.", "author": "sankarh", "createdAt": "2020-08-18T16:49:25Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -2449,12 +2448,11 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n \n-      //if hive.stats.autogather = false or resetStatistics = true then\n-      //clear partition column stats and set basic stats to false\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+      // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+      // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+      if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n         LOG.debug(\n-            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n-        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());\n+            \"Clear partition column statistics by setting basic stats to false for \" + newTPart.getCompleteName());\n         StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzOTQzNw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472339437", "bodyText": "Nit: Use upper-case for first character of log message.", "author": "sankarh", "createdAt": "2020-08-18T16:50:40Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+        LOG.debug(", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -2449,12 +2448,11 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n \n-      //if hive.stats.autogather = false or resetStatistics = true then\n-      //clear partition column stats and set basic stats to false\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+      // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+      // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+      if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n         LOG.debug(\n-            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n-        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());\n+            \"Clear partition column statistics by setting basic stats to false for \" + newTPart.getCompleteName());\n         StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzOTczMw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472339733", "bodyText": "Nit: Add single space after \"//\"", "author": "sankarh", "createdAt": "2020-08-18T16:51:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -2449,12 +2448,11 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n \n-      //if hive.stats.autogather = false or resetStatistics = true then\n-      //clear partition column stats and set basic stats to false\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+      // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+      // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+      if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n         LOG.debug(\n-            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n-        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());\n+            \"Clear partition column statistics by setting basic stats to false for \" + newTPart.getCompleteName());\n         StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM0NjExMA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472346110", "bodyText": "clearColumnStatsState call is redundant as setBasicStatsState(false) will remove the column stats as well.", "author": "sankarh", "createdAt": "2020-08-18T17:01:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+        LOG.debug(\n+            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n+        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\nindex 2d94325e6b..41ccdd005b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java\n\n@@ -2449,12 +2448,11 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n \n-      //if hive.stats.autogather = false or resetStatistics = true then\n-      //clear partition column stats and set basic stats to false\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+      // If there is no column stats gather stage present in the plan. So we don't know the accuracy of the stats or\n+      // auto gather stats is turn off explicitly. We need to reset the stats in both cases.\n+      if (resetStatistics || !this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n         LOG.debug(\n-            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n-        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());\n+            \"Clear partition column statistics by setting basic stats to false for \" + newTPart.getCompleteName());\n         StatsSetupConst.setBasicStatsState(newTPart.getParameters(), StatsSetupConst.FALSE);\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM1OTE1NQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472359155", "bodyText": "Can test the import with hive.stats.autogather=true and see if stats are accurate for both partitioned and non-partitioned tables.", "author": "sankarh", "createdAt": "2020-08-18T17:21:41Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +602,44 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    //Clear and Drop T and Tstage if exist\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+\n+    //create target table - T\n+    runStatementOnDriver(\"create table T (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    //Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };\n+\n+    //check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    //now we have an archive Tstage table\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n+\n+    //load T\n+    runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 50c09c2d3a..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -605,40 +600,37 @@ public void testMMExportAborted() throws Exception {\n \n   @Test\n   public void testImportOrc() throws Exception {\n-    //Clear and Drop T and Tstage if exist\n+    // Clear and Drop T and Tstage if exist\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n \n-    //create target table - T\n-    runStatementOnDriver(\"create table T (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n-\n-    //Create source table - Tstage\n+    // Create source table - Tstage\n     runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n \n-    //this creates an ORC data file with correct schema under table root\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n     final int[][] rows = { { 3 } };\n \n-    //check Tstage statistics\n+    // Check Tstage statistics\n     List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n     Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n         rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n     Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n     Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n \n-    //now we have an archive Tstage table\n+    // Now we have an archive Tstage table\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n-    //load T\n+    // Load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n \n-    //check basic stats in tblproperties T\n+    // Check basic stats in tblproperties T\n     List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n     Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,\n         rsTProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n     Assert.assertEquals(\"numRows of T table\", false, rsTProperties.contains(\"numRows\\t3\"));\n \n-    //verify the count(*) output\n+    // Verify the count(*) output\n     List<String> rs = runStatementOnDriver(\"select count(*) from T\");\n     Assert.assertEquals(\"Rowcount of imported table\", TestTxnCommands2.stringifyValues(rows), rs);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM2MDYzOQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472360639", "bodyText": "I think, stats are false as table T was already created. Can we check if it is set to false when import create the table.", "author": "sankarh", "createdAt": "2020-08-18T17:24:12Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -389,21 +390,56 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n+    //clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n+\n+    //create target table - T\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n+    //create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n     //this creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n-    final int[][] rows = {{3}};\n-    //now we have an archive with 3 partitions\n+    final int[][] rows = { { 3 } };\n+\n+    //check Partitions statistics\n+    List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n+    for (String rsTstagePartition : rsTstagePartitionsProperties) {\n+      List<String> rsPartitionProperties =\n+          runStatementOnDriver(\"describe formatted Tstage partition(\" + rsTstagePartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n+    }\n+\n+    //now we have an archive Tstage with 3 partitions\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties of T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b138022419df343e369a704c6c61d52fc7fecf7", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\nindex 50c09c2d3a..5801afa078 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java\n\n@@ -390,23 +389,19 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n-    //clear and drop table T,Tstage\n+    // Clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n \n-    //create target table - T\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n-        + \" as orc tblproperties('transactional'='true')\");\n-\n-    //create source table - Tstage\n+    // Create source table - Tstage\n     runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n         + \" as orc tblproperties('transactional'='true')\");\n \n-    //this creates an ORC data file with correct schema under table root\n+    // This creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n     final int[][] rows = { { 3 } };\n \n-    //check Partitions statistics\n+    // Check Partitions statistics\n     List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n     for (String rsTstagePartition : rsTstagePartitionsProperties) {\n       List<String> rsPartitionProperties =\n"}}, {"oid": "7b138022419df343e369a704c6c61d52fc7fecf7", "url": "https://github.com/apache/hive/commit/7b138022419df343e369a704c6c61d52fc7fecf7", "message": "HIVE-23887: Reset table level basic/column stats during import", "committedDate": "2020-08-21T11:18:16Z", "type": "commit"}, {"oid": "7b138022419df343e369a704c6c61d52fc7fecf7", "url": "https://github.com/apache/hive/commit/7b138022419df343e369a704c6c61d52fc7fecf7", "message": "HIVE-23887: Reset table level basic/column stats during import", "committedDate": "2020-08-21T11:18:16Z", "type": "forcePushed"}]}