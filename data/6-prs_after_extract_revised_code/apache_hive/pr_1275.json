{"pr_number": 1275, "pr_title": "HIVE-23324: Parallelise compaction directory cleaning process", "pr_createdAt": "2020-07-17T17:09:09Z", "pr_url": "https://github.com/apache/hive/pull/1275", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r457970694", "bodyText": "I think it would be a good idea to shut down the executor when we finished the run loop.\nWhat do you think?", "author": "pvary", "createdAt": "2020-07-21T09:42:47Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -64,13 +67,15 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n+  private Executor cleanerExecutor;\n \n   private ReplChangeManager replChangeManager;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    cleanerExecutor = Executors.newFixedThreadPool(conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE));", "originalCommit": "a94d0aacdf61a220514850b414ba0c126ef99f7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAxMzM3OA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458013378", "bodyText": "Yeah, makes sense. Added it.", "author": "adesh-rao", "createdAt": "2020-07-21T11:02:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAyNzkxMw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458027913", "bodyText": "I prefer the way how it was done in Worker.java:\n\nNamed threads\nPriority down\nSet daemon on/off\nStopped in finally\n\nShall we do it here, or should we create a follow-up jira for creating and cleaning up the executor threads for Cleaner and Initiator as well?\nThanks,\nPeter", "author": "pvary", "createdAt": "2020-07-21T11:31:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA5Njc2NQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458096765", "bodyText": "Just saw the approach in Worker.java, it looks much better/cleaner. I will make the changes here only ()for both cleaner/intiator) and update once it is ready.", "author": "adesh-rao", "createdAt": "2020-07-21T13:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI1NDM0NA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458254344", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-21T17:06:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3MDY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "82276808dc1bca746f77d4e31ff33adfc8ee0832", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 19a2a2433d..b9c8b847b0 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -67,7 +69,7 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private Executor cleanerExecutor;\n+  private ExecutorService cleanerExecutor;\n \n   private ReplChangeManager replChangeManager;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3NzcwOQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r457977709", "bodyText": "What happens if one of the futures throws the exception?\nAre the others continue to execute? Will we wait until all of the tasks are finished one way or another?\nWe do not want multiple Cleaning tasks running concurrently on the same partition.\nSeeing this the same problem might arise with the Initiator too. What do you think @deniskuzZ ?", "author": "pvary", "createdAt": "2020-07-21T09:55:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,9 +94,12 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n+            clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();", "originalCommit": "a94d0aacdf61a220514850b414ba0c126ef99f7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAwMTAwMQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458001001", "bodyText": "Talked with @deniskuzZ and he convinced me that join() will wait for all of the tasks to finish :)", "author": "pvary", "createdAt": "2020-07-21T10:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk3NzcwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "82276808dc1bca746f77d4e31ff33adfc8ee0832", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 19a2a2433d..b9c8b847b0 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -85,42 +93,48 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-            clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n-        try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n+          continue;\n+        } else {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n         }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNjY3MA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458136670", "bodyText": "Why not just declare cleanerExecutor as and ExecutorService to start?", "author": "belugabehr", "createdAt": "2020-07-21T14:23:13Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -113,6 +122,8 @@ public void run() {\n         }\n       }\n     } while (!stop.get());\n+\n+    ((ExecutorService)cleanerExecutor).shutdown();", "originalCommit": "ce1780f8f5e5e502a9c4e220df424b89fa3ab7bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI1NDYwMA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458254600", "bodyText": "Modify it now.", "author": "adesh-rao", "createdAt": "2020-07-21T17:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNjY3MA=="}], "type": "inlineReview", "revised_code": {"commit": "82276808dc1bca746f77d4e31ff33adfc8ee0832", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 2330fb7843..b9c8b847b0 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -86,44 +93,48 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-            clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n-        try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n+          continue;\n+        } else {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n         }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n-\n-    ((ExecutorService)cleanerExecutor).shutdown();\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"oid": "82276808dc1bca746f77d4e31ff33adfc8ee0832", "url": "https://github.com/apache/hive/commit/82276808dc1bca746f77d4e31ff33adfc8ee0832", "message": "Use named threads for initiator/cleaner parallelised threads", "committedDate": "2020-07-21T17:04:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYwOTY4NQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458609685", "bodyText": "Minimally log the error on info level?", "author": "pvary", "createdAt": "2020-07-22T08:03:21Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYwOTk1NA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458609954", "bodyText": "nit of the nit: formatting:\nfor (int i = 0; i < count; i++) {", "author": "pvary", "createdAt": "2020-07-22T08:03:52Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMDgxMQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458610811", "bodyText": "Shall we move this to the run method too? It would make it easier to understand the code IMHO", "author": "pvary", "createdAt": "2020-07-22T08:05:23Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -64,13 +72,23 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n+  private ExecutorService cleanerExecutor;\n+  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    ThreadFactory threadFactory = new ThreadFactoryBuilder()", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMTE4Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458611187", "bodyText": "Or maybe use this as an utility method to create the executor like and use this in the run method to create the executor:\nWhateverUtil.createExecutor(String name, int size) {}", "author": "pvary", "createdAt": "2020-07-22T08:06:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMDgxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NDg0Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458674847", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-22T09:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMDgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMTU1MQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458611551", "bodyText": "What's the reasoning behind this change?", "author": "deniskuzZ", "createdAt": "2020-07-22T08:06:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -149,17 +156,25 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              compactionList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n+              completionService.submit(() -> {\n+                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n+                return null;\n+              });\n+              count++;\n             } catch (Throwable t) {\n               LOG.error(\"Caught exception while trying to determine if we should compact {}. \" +\n                   \"Marking failed to avoid repeated failures, {}\", ci, t);\n               ci.errorMessage = t.getMessage();\n               txnHandler.markFailed(ci);\n             }\n           }\n-          CompletableFuture.allOf(compactionList.toArray(new CompletableFuture[0]))\n-            .join();\n+          for(int i=0; i<count; i++) {", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTY4MA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458675680", "bodyText": "Earlier I missed the fact that we don't care in how and when are task getting completed and using join is better in terms of readability and usability too. So I have reverted this change.", "author": "adesh-rao", "createdAt": "2020-07-22T09:54:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYxMTU1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\nindex 4b6d7d156e..f23d6b7e19 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n\n@@ -156,11 +150,8 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              completionService.submit(() -> {\n-                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n-                return null;\n-              });\n-              count++;\n+              compactionList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n             } catch (Throwable t) {\n               LOG.error(\"Caught exception while trying to determine if we should compact {}. \" +\n                   \"Marking failed to avoid repeated failures, {}\", ci, t);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyNDAyNg==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458624026", "bodyText": "what's the reasoning behind this? if you want to call it, do it before releasing the lock!!", "author": "deniskuzZ", "createdAt": "2020-07-22T08:27:46Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -182,6 +197,10 @@ public void run() {\n     } catch (Throwable t) {\n       LOG.error(\"Caught an exception in the main loop of compactor initiator, exiting \" +\n           StringUtils.stringifyException(t));\n+    } finally {\n+      if (compactionExecutor != null) {\n+        compactionExecutor.shutdownNow();", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTgyMw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458675823", "bodyText": "Fixed this.", "author": "adesh-rao", "createdAt": "2020-07-22T09:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyNDAyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NDkyNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458964924", "bodyText": "@adesh-rao, sorry that was actually a right spot, that's basically end of thread execution", "author": "deniskuzZ", "createdAt": "2020-07-22T17:33:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyNDAyNg=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\nindex 4b6d7d156e..f23d6b7e19 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n\n@@ -199,7 +185,7 @@ public void run() {\n           StringUtils.stringifyException(t));\n     } finally {\n       if (compactionExecutor != null) {\n-        compactionExecutor.shutdownNow();\n+        this.compactionExecutor.shutdownNow();\n       }\n     }\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyOTE0NA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458629144", "bodyText": "what's the reasoning behind this change? returning some null doesn't add more code readability", "author": "deniskuzZ", "createdAt": "2020-07-22T08:36:14Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -149,17 +156,25 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              compactionList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n-                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n+              completionService.submit(() -> {\n+                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n+                return null;", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTk3Mg==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458675972", "bodyText": "Same as above. Removed it.", "author": "adesh-rao", "createdAt": "2020-07-22T09:54:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODYyOTE0NA=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\nindex 4b6d7d156e..f23d6b7e19 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n\n@@ -156,11 +150,8 @@ public void run() {\n               String runAs = resolveUserToRunAs(tblNameOwners, t, p);\n               /* checkForCompaction includes many file metadata checks and may be expensive.\n                * Therefore, using a thread pool here and running checkForCompactions in parallel */\n-              completionService.submit(() -> {\n-                ThrowingRunnable.unchecked(() -> scheduleCompactionIfRequired(ci, t, p, runAs));\n-                return null;\n-              });\n-              count++;\n+              compactionList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  scheduleCompactionIfRequired(ci, t, p, runAs)), compactionExecutor));\n             } catch (Throwable t) {\n               LOG.error(\"Caught exception while trying to determine if we should compact {}. \" +\n                   \"Marking failed to avoid repeated failures, {}\", ci, t);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY0OTUxMw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458649513", "bodyText": "CompletableFuture is a better choice", "author": "deniskuzZ", "createdAt": "2020-07-22T09:09:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NjA2Mg==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458676062", "bodyText": "Agree, changed it.", "author": "adesh-rao", "createdAt": "2020-07-22T09:55:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY0OTUxMw=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MTg0Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458651847", "bodyText": "shutdown should be called here, otherwise you can terminate threads from 2nd iteration", "author": "deniskuzZ", "createdAt": "2020-07-22T09:13:43Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?\n+            }\n+          }\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NjEyOQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458676129", "bodyText": "Fixed this.", "author": "adesh-rao", "createdAt": "2020-07-22T09:55:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MTg0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NDE3OQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458654179", "bodyText": "could we refactor this block by negating if condition and removing continue part?", "author": "deniskuzZ", "createdAt": "2020-07-22T09:17:41Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -80,39 +98,58 @@ public void run() {\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n+        try {\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          int count = 0;\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            completionService.submit(() -> {\n+              ThrowingRunnable.unchecked(() -> clean(compactionInfo, minOpenTxnId));\n+              return null;\n+            });\n+            count++;\n+          }\n+\n+          for(int i=0; i<count; i++) {\n+            try {\n+              completionService.take().get();\n+            } catch (InterruptedException| ExecutionException ignore) {\n+              // What should we do here?\n+            }\n+          }\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n         }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n+        finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n-        try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime >= cleanerCheckInterval || stop.get())  {", "originalCommit": "b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NjIyMg==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458676222", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-22T09:55:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NDE3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 8bc6ff59d6..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -72,32 +67,25 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n-  private ExecutorService cleanerExecutor;\n-  private CompletionService<Void> completionService;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    ThreadFactory threadFactory = new ThreadFactoryBuilder()\n-            .setPriority(Thread.currentThread().getPriority())\n-            .setDaemon(Thread.currentThread().isDaemon())\n-            .setNameFormat(\"Cleaner-executor-thread-%d\")\n-            .build();\n-    cleanerExecutor = Executors.newFixedThreadPool(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadFactory);\n-    completionService = new ExecutorCompletionService<>(cleanerExecutor);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n+  @Override\n+  public void run() {\n     try {\n       do {\n         TxnStore.MutexAPI.LockHandle handle = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3OTI3Mw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458679273", "bodyText": "Could you please move this to constants", "author": "deniskuzZ", "createdAt": "2020-07-22T10:00:24Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -79,7 +81,9 @@ public void run() {\n       cleanerCheckInterval = conf.getTimeVar(\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n-\n+    String threadNameFormat = \"Cleaner-executor-thread-%d\";", "originalCommit": "d36b661a6f02c0584bdbad59785ab1d5d38da07c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 66a9dc802d..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -68,60 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    if (cleanerCheckInterval == 0) {\n+      cleanerCheckInterval = conf.getTimeVar(\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-    String threadNameFormat = \"Cleaner-executor-thread-%d\";\n-    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-        conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n-                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n-        }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-                StringUtils.stringifyException(t));\n-        if (cleanerExecutor != null) {\n-          cleanerExecutor.shutdownNow();\n-          cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-                  conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-        }\n-      } finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (!(elapsedTime >= cleanerCheckInterval || stop.get())) {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n+        }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n         }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        this.cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458702723", "bodyText": "what's the purpose of executor service shutdown? it would be needed only when Cleaner thread terminates", "author": "deniskuzZ", "createdAt": "2020-07-22T10:45:25Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,23 +93,28 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n       } catch (Throwable t) {\n         LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n+                StringUtils.stringifyException(t));\n+        if (cleanerExecutor != null) {", "originalCommit": "d36b661a6f02c0584bdbad59785ab1d5d38da07c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNTY5NQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458705695", "bodyText": "This is to handle the case when threads in executors are lost due to exception.", "author": "adesh-rao", "createdAt": "2020-07-22T10:51:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3Njc0Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458776747", "bodyText": "You are submitting tasks to the executor inside the loop, all at once, so if there will be an exception in main loop - there won't be any running threads in executor.", "author": "deniskuzZ", "createdAt": "2020-07-22T13:07:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk0MDMzNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458940334", "bodyText": "Agreed. I have removed the executor shutdown.\nBut where/should we add executor shutdown? I think since the Cleaner is supposed to be running all the time. We can skip executor shutdown?", "author": "adesh-rao", "createdAt": "2020-07-22T16:53:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2Nzg0Ng==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458967846", "bodyText": "@adesh-rao, sorry I think you have placed it originally at the right spot, at the end of run() method, you'll probably have to wrap it's internals (do while) with try and put shutdownNow in finally section. note: remove catch InterruptedException.", "author": "deniskuzZ", "createdAt": "2020-07-22T17:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzNTEwNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r459435104", "bodyText": "Which InterruptedException are you pointing at?  Also, I have moved the shutdown at the end of run method now.", "author": "adesh-rao", "createdAt": "2020-07-23T13:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDcwNDc1Ng==", "url": "https://github.com/apache/hive/pull/1275#discussion_r460704756", "bodyText": "@adesh-rao, exception from (see how it's done in Initiator)\ntry {\nThread.sleep(cleanerCheckInterval - elapsedTime);\n} catch (InterruptedException ie) {\n// What can I do about it?\n}\nrest looks good to me", "author": "deniskuzZ", "createdAt": "2020-07-27T07:45:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwMjcyMw=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 66a9dc802d..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -68,60 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    if (cleanerCheckInterval == 0) {\n+      cleanerCheckInterval = conf.getTimeVar(\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-    String threadNameFormat = \"Cleaner-executor-thread-%d\";\n-    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-        conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n-                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n-        }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-                StringUtils.stringifyException(t));\n-        if (cleanerExecutor != null) {\n-          cleanerExecutor.shutdownNow();\n-          cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-                  conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-        }\n-      } finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (!(elapsedTime >= cleanerCheckInterval || stop.get())) {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n+        }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n         }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        this.cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNDMzOQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458704339", "bodyText": "could you move negation inside: elapsedTime < cleanerCheckInterval && !stop.get()", "author": "deniskuzZ", "createdAt": "2020-07-22T10:48:41Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -89,23 +93,28 @@ public void run() {\n         handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n         startedAt = System.currentTimeMillis();\n         long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n         for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n+          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n       } catch (Throwable t) {\n         LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n+                StringUtils.stringifyException(t));\n+        if (cleanerExecutor != null) {\n+          cleanerExecutor.shutdownNow();\n+          cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+                  conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n+        }\n+      } finally {\n         if (handle != null) {\n           handle.releaseLocks();\n         }\n       }\n       // Now, go back to bed until it's time to do this again\n       long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+      if (!(elapsedTime >= cleanerCheckInterval || stop.get())) {", "originalCommit": "d36b661a6f02c0584bdbad59785ab1d5d38da07c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1MTQ1OQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458751459", "bodyText": "fixed.", "author": "adesh-rao", "createdAt": "2020-07-22T12:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNDMzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2OTQ1Mw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458969453", "bodyText": "can't see the change", "author": "deniskuzZ", "createdAt": "2020-07-22T17:41:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNDMzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzNDEzNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r459434134", "bodyText": "This is outdated. I have added a comment at the right place.", "author": "adesh-rao", "createdAt": "2020-07-23T13:07:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNDMzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 66a9dc802d..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -68,60 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    if (cleanerCheckInterval == 0) {\n+      cleanerCheckInterval = conf.getTimeVar(\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-    String threadNameFormat = \"Cleaner-executor-thread-%d\";\n-    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-        conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n-                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n-        }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-                StringUtils.stringifyException(t));\n-        if (cleanerExecutor != null) {\n-          cleanerExecutor.shutdownNow();\n-          cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-                  conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE), threadNameFormat);\n-        }\n-      } finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (!(elapsedTime >= cleanerCheckInterval || stop.get())) {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n+        }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n         }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        this.cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNTQ1OQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458705459", "bodyText": "same as above, what's the purpose of executor service shutdown? it would be needed only when Initiator thread terminates", "author": "deniskuzZ", "createdAt": "2020-07-22T10:50:51Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -166,6 +167,11 @@ public void run() {\n         } catch (Throwable t) {\n           LOG.error(\"Initiator loop caught unexpected exception this time through the loop: \" +\n               StringUtils.stringifyException(t));\n+          if (compactionExecutor != null) {", "originalCommit": "d36b661a6f02c0584bdbad59785ab1d5d38da07c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NDQyNQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458744425", "bodyText": "same as above. This is to fix the number of threads in case threads of executor are lost. This is similarly done in Worker.java too.", "author": "adesh-rao", "createdAt": "2020-07-22T12:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNTQ1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\nindex 01fa61ab8f..f23d6b7e19 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n\n@@ -167,11 +167,6 @@ public void run() {\n         } catch (Throwable t) {\n           LOG.error(\"Initiator loop caught unexpected exception this time through the loop: \" +\n               StringUtils.stringifyException(t));\n-          if (compactionExecutor != null) {\n-            compactionExecutor.shutdownNow();\n-            compactionExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-                conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_REQUEST_QUEUE), threadNameFormat);\n-          }\n         }\n         finally {\n           if(handle != null) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNjQxNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458706414", "bodyText": "should it be ThreadUtil?", "author": "deniskuzZ", "createdAt": "2020-07-22T10:52:53Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.txn.compactor;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class CompactorUtil {", "originalCommit": "d36b661a6f02c0584bdbad59785ab1d5d38da07c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NTgwNA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458745804", "bodyText": "Currently this only contains thread utility methods, but intention of this class is to have compactor utility methods which might be needed in future.", "author": "adesh-rao", "createdAt": "2020-07-22T12:12:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNjQxNA=="}], "type": "inlineReview", "revised_code": {"commit": "ca5addc861df51983a91f709bf5294ac05fc24ae", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java\ndeleted file mode 100644\nindex 6f74187e5c..0000000000\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java\n+++ /dev/null\n\n@@ -1,53 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hadoop.hive.ql.txn.compactor;\n-\n-import com.google.common.util.concurrent.ThreadFactoryBuilder;\n-import org.apache.hadoop.hive.conf.HiveConf;\n-\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.ThreadFactory;\n-\n-public class CompactorUtil {\n-    public interface ThrowingRunnable<E extends Exception> {\n-        void run() throws E;\n-\n-        static Runnable unchecked(ThrowingRunnable<?> r) {\n-            return () -> {\n-                try {\n-                    r.run();\n-                } catch (Exception e) {\n-                    throw new RuntimeException(e);\n-                }\n-            };\n-        }\n-    }\n-\n-    public static ThreadFactory createThreadFactory(String threadNameFormat) {\n-        return new ThreadFactoryBuilder()\n-                .setPriority(Thread.currentThread().getPriority())\n-                .setDaemon(Thread.currentThread().isDaemon())\n-                .setNameFormat(threadNameFormat)\n-                .build();\n-    }\n-\n-    public static ExecutorService createExecutorWithThreadFactory(int threadCount, String threadNameFormat) {\n-        return Executors.newFixedThreadPool(threadCount, createThreadFactory(threadNameFormat));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3NjM1OA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458976358", "bodyText": "move this under init, including cleanerCheckInterval initialization", "author": "deniskuzZ", "createdAt": "2020-07-22T17:52:41Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -79,7 +82,9 @@ public void run() {\n       cleanerCheckInterval = conf.getTimeVar(\n           HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n-\n+    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(", "originalCommit": "f1029d56a3867daa29035c67e8eca3fcec9080f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzMzg4MQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r459433881", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-23T13:06:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3NjM1OA=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex e3f1aa8dc8..14dffc592d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -69,55 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    if (cleanerCheckInterval == 0) {\n+      cleanerCheckInterval = conf.getTimeVar(\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-    ExecutorService cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-        conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n-        COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        List<CompletableFuture> cleanerList = new ArrayList<>();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n-                  clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n-        }\n-        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-                StringUtils.stringifyException(t));\n-      } finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {\n+            // What can I do about it?\n+          }\n+        }\n+      } while (!stop.get());\n+    } finally {\n+      if (cleanerExecutor != null) {\n+        this.cleanerExecutor.shutdownNow();\n       }\n-    } while (!stop.get());\n+    }\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3ODExNQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r458978115", "bodyText": "move this under init", "author": "deniskuzZ", "createdAt": "2020-07-22T17:55:26Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java", "diffHunk": "@@ -87,6 +87,9 @@\n   public void run() {\n     // Make sure nothing escapes this run method and kills the metastore at large,\n     // so wrap it in a big catch Throwable statement.\n+    ExecutorService compactionExecutor = CompactorUtil.createExecutorWithThreadFactory(", "originalCommit": "f1029d56a3867daa29035c67e8eca3fcec9080f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzMzgwMQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r459433801", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-23T13:06:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3ODExNQ=="}], "type": "inlineReview", "revised_code": {"commit": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\nindex 57837d81cf..f23d6b7e19 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java\n\n@@ -82,14 +82,12 @@\n \n   private long checkInterval;\n   private long prevStart = -1;\n+  private ExecutorService compactionExecutor;\n \n   @Override\n   public void run() {\n     // Make sure nothing escapes this run method and kills the metastore at large,\n     // so wrap it in a big catch Throwable statement.\n-    ExecutorService compactionExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_REQUEST_QUEUE),\n-            COMPACTOR_INTIATOR_THREAD_NAME_FORMAT);\n     try {\n       recoverFailedCompactions(false);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQzMzA3Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r459433077", "bodyText": "@deniskuzZ This condition is modified. The previous comment is there on the outdated code.", "author": "adesh-rao", "createdAt": "2020-07-23T13:05:31Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {\n       cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     }\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+  }\n \n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n-        }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+  @Override\n+  public void run() {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n+        }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {", "originalCommit": "001595fed553b5eec519e244c74e75d071f3ddf4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 14dffc592d..3762167298 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -75,10 +75,8 @@\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n+    cleanerCheckInterval = conf.getTimeVar(\n+            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n             conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n             COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n"}}, {"oid": "22df6f60e678119c89dc9e3a592d79a09d65a55b", "url": "https://github.com/apache/hive/commit/22df6f60e678119c89dc9e3a592d79a09d65a55b", "message": "Add executor shutdown", "committedDate": "2020-07-23T16:54:34Z", "type": "forcePushed"}, {"oid": "87414359c1ac92562e9d5de4249b6b68a9ab402a", "url": "https://github.com/apache/hive/commit/87414359c1ac92562e9d5de4249b6b68a9ab402a", "message": "Add executor shutdown", "committedDate": "2020-07-24T09:46:46Z", "type": "forcePushed"}, {"oid": "2c0798db8730e422a9a4bbf00dd81472ee5e9825", "url": "https://github.com/apache/hive/commit/2c0798db8730e422a9a4bbf00dd81472ee5e9825", "message": "Add executor shutdown", "committedDate": "2020-07-24T12:02:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDcwNjQ2NQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r460706465", "bodyText": "i think, this if check is redundant.", "author": "deniskuzZ", "createdAt": "2020-07-27T07:48:43Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,62 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-  }\n-\n-  @Override\n-  public void run() {\n     if (cleanerCheckInterval == 0) {", "originalCommit": "2c0798db8730e422a9a4bbf00dd81472ee5e9825", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMwNjc3Mw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r461306773", "bodyText": "Yes, this is redundant. Removed it.", "author": "adesh-rao", "createdAt": "2020-07-28T04:14:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDcwNjQ2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 14dffc592d..3762167298 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -75,10 +75,8 @@\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-              HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n+    cleanerCheckInterval = conf.getTimeVar(\n+            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n     cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n             conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n             COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n"}}, {"oid": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "url": "https://github.com/apache/hive/commit/c6ef5ddca2ea3009ceb99140079a6d694c642c17", "message": "Remove redundant check", "committedDate": "2020-07-27T14:59:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r461329189", "bodyText": "InterruptedException catch redundant as well (see Initiator)", "author": "deniskuzZ", "createdAt": "2020-07-28T05:35:30Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java", "diffHunk": "@@ -66,53 +69,60 @@\n   private long cleanerCheckInterval = 0;\n \n   private ReplChangeManager replChangeManager;\n+  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n+    cleanerCheckInterval = conf.getTimeVar(\n+            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n+            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n+            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n   }\n \n   @Override\n   public void run() {\n-    if (cleanerCheckInterval == 0) {\n-      cleanerCheckInterval = conf.getTimeVar(\n-          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    }\n-\n-    do {\n-      TxnStore.MutexAPI.LockHandle handle = null;\n-      long startedAt = -1;\n-      // Make sure nothing escapes this run method and kills the metastore at large,\n-      // so wrap it in a big catch Throwable statement.\n-      try {\n-        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-        startedAt = System.currentTimeMillis();\n-        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-          clean(compactionInfo, minOpenTxnId);\n-        }\n-      } catch (Throwable t) {\n-        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-            StringUtils.stringifyException(t));\n-      }\n-      finally {\n-        if (handle != null) {\n-          handle.releaseLocks();\n-        }\n-      }\n-      // Now, go back to bed until it's time to do this again\n-      long elapsedTime = System.currentTimeMillis() - startedAt;\n-      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n-        continue;\n-      } else {\n+    try {\n+      do {\n+        TxnStore.MutexAPI.LockHandle handle = null;\n+        long startedAt = -1;\n+        // Make sure nothing escapes this run method and kills the metastore at large,\n+        // so wrap it in a big catch Throwable statement.\n         try {\n-          Thread.sleep(cleanerCheckInterval - elapsedTime);\n-        } catch (InterruptedException ie) {\n-          // What can I do about it?\n+          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+          startedAt = System.currentTimeMillis();\n+          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+          List<CompletableFuture> cleanerList = new ArrayList<>();\n+          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n+                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n+          }\n+          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+        } catch (Throwable t) {\n+          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+                  StringUtils.stringifyException(t));\n+        } finally {\n+          if (handle != null) {\n+            handle.releaseLocks();\n+          }\n         }\n+        // Now, go back to bed until it's time to do this again\n+        long elapsedTime = System.currentTimeMillis() - startedAt;\n+        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n+          try {\n+            Thread.sleep(cleanerCheckInterval - elapsedTime);\n+          } catch (InterruptedException ie) {", "originalCommit": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTM0MDM1MQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r461340351", "bodyText": "I don't think it is redundant.\nIn initiator, the try-catch (catching throwable) is applied on the complete while loop. Since thread.sleep is inside while loop, it was redundant in initiator. (Though, sleep throws an Interrupted exception, we will get out of while loop and initiator will exit).\nIn case of cleaner, the try-catch (catching throwable) is applied only on the main logic for cleaning directories. This is inside while loop (as compared to complete while loop for initiator). Here, even if sleep throws Interrupted exception, Cleaner won't exit because of a separate try-catch statement inside while loop.", "author": "adesh-rao", "createdAt": "2020-07-28T06:09:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA2NzE1Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462067157", "bodyText": "@adesh-rao, it should behave same way as in Initiator. if you interrupt the thread - it should be cleanly interrupted. To be honest i don't see the difference. try-catch in Cleaner covers main do-while loop in Thread.run. Am I missing something here?", "author": "deniskuzZ", "createdAt": "2020-07-29T06:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA3MzAyNw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462073027", "bodyText": "There is no catch in Cleaner, its just try-finally.", "author": "adesh-rao", "createdAt": "2020-07-29T06:43:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA5MDM5Ng==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462090396", "bodyText": "Catch there is used to log the exceptions, you don't have any logging right now. I think, it's answer for \"// What can I do about it?\" comment.", "author": "deniskuzZ", "createdAt": "2020-07-29T07:20:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEzMzAxOA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462133018", "bodyText": "Added the logging in catch.", "author": "adesh-rao", "createdAt": "2020-07-29T08:34:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxODUyOQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462318529", "bodyText": "do you think it's ok to have un-interruptible thread ? in current situation if someone interrupts the Cleaner thread it will just go right away with next clean attempt", "author": "deniskuzZ", "createdAt": "2020-07-29T13:56:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMyOTE4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "ca5addc861df51983a91f709bf5294ac05fc24ae", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\nindex 3762167298..19a2a2433d 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Cleaner.java\n\n@@ -67,62 +67,60 @@\n   static final private String CLASS_NAME = Cleaner.class.getName();\n   static final private Logger LOG = LoggerFactory.getLogger(CLASS_NAME);\n   private long cleanerCheckInterval = 0;\n+  private Executor cleanerExecutor;\n \n   private ReplChangeManager replChangeManager;\n-  private ExecutorService cleanerExecutor;\n \n   @Override\n   public void init(AtomicBoolean stop) throws Exception {\n     super.init(stop);\n     replChangeManager = ReplChangeManager.getInstance(conf);\n-    cleanerCheckInterval = conf.getTimeVar(\n-            HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n-    cleanerExecutor = CompactorUtil.createExecutorWithThreadFactory(\n-            conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE),\n-            COMPACTOR_CLEANER_THREAD_NAME_FORMAT);\n+    cleanerExecutor = Executors.newFixedThreadPool(conf.getIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE));\n   }\n \n   @Override\n   public void run() {\n-    try {\n-      do {\n-        TxnStore.MutexAPI.LockHandle handle = null;\n-        long startedAt = -1;\n-        // Make sure nothing escapes this run method and kills the metastore at large,\n-        // so wrap it in a big catch Throwable statement.\n-        try {\n-          handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n-          startedAt = System.currentTimeMillis();\n-          long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n-          List<CompletableFuture> cleanerList = new ArrayList<>();\n-          for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n-            cleanerList.add(CompletableFuture.runAsync(CompactorUtil.ThrowingRunnable.unchecked(() ->\n-                    clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n-          }\n-          CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n-        } catch (Throwable t) {\n-          LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n-                  StringUtils.stringifyException(t));\n-        } finally {\n-          if (handle != null) {\n-            handle.releaseLocks();\n-          }\n+    if (cleanerCheckInterval == 0) {\n+      cleanerCheckInterval = conf.getTimeVar(\n+          HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_RUN_INTERVAL, TimeUnit.MILLISECONDS);\n+    }\n+\n+    do {\n+      TxnStore.MutexAPI.LockHandle handle = null;\n+      long startedAt = -1;\n+      // Make sure nothing escapes this run method and kills the metastore at large,\n+      // so wrap it in a big catch Throwable statement.\n+      try {\n+        handle = txnHandler.getMutexAPI().acquireLock(TxnStore.MUTEX_KEY.Cleaner.name());\n+        startedAt = System.currentTimeMillis();\n+        long minOpenTxnId = txnHandler.findMinOpenTxnIdForCleaner();\n+        List<CompletableFuture> cleanerList = new ArrayList<>();\n+        for(CompactionInfo compactionInfo : txnHandler.findReadyToClean()) {\n+          cleanerList.add(CompletableFuture.runAsync(ThrowingRunnable.unchecked(() ->\n+            clean(compactionInfo, minOpenTxnId)), cleanerExecutor));\n         }\n-        // Now, go back to bed until it's time to do this again\n-        long elapsedTime = System.currentTimeMillis() - startedAt;\n-        if (elapsedTime < cleanerCheckInterval && !stop.get()) {\n-          try {\n-            Thread.sleep(cleanerCheckInterval - elapsedTime);\n-          } catch (InterruptedException ie) {\n-            // What can I do about it?\n-          }\n+        CompletableFuture.allOf(cleanerList.toArray(new CompletableFuture[0])).join();\n+      } catch (Throwable t) {\n+        LOG.error(\"Caught an exception in the main loop of compactor cleaner, \" +\n+            StringUtils.stringifyException(t));\n+      }\n+      finally {\n+        if (handle != null) {\n+          handle.releaseLocks();\n         }\n-      } while (!stop.get());\n-    } finally {\n-      if (cleanerExecutor != null) {\n-        this.cleanerExecutor.shutdownNow();\n       }\n-    }\n+      // Now, go back to bed until it's time to do this again\n+      long elapsedTime = System.currentTimeMillis() - startedAt;\n+      if (elapsedTime >= cleanerCheckInterval || stop.get())  {\n+        continue;\n+      } else {\n+        try {\n+          Thread.sleep(cleanerCheckInterval - elapsedTime);\n+        } catch (InterruptedException ie) {\n+          // What can I do about it?\n+        }\n+      }\n+    } while (!stop.get());\n   }\n \n   private void clean(CompactionInfo ci, long minOpenTxnGLB) throws MetaException {\n"}}, {"oid": "ca5addc861df51983a91f709bf5294ac05fc24ae", "url": "https://github.com/apache/hive/commit/ca5addc861df51983a91f709bf5294ac05fc24ae", "message": "Parallelise compaction directory cleaning process", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "506103475d1088dcc86d2ef17c78acb15a1b5b39", "url": "https://github.com/apache/hive/commit/506103475d1088dcc86d2ef17c78acb15a1b5b39", "message": "Address review coment and fix configuration description", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "87b57be2533ae49c5e390ef792bdbd8e53a52e98", "url": "https://github.com/apache/hive/commit/87b57be2533ae49c5e390ef792bdbd8e53a52e98", "message": "Use named threads for initiator/cleaner parallelised threads", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "d5dc57a1925b811507e63d7d6397e38bbf07859f", "url": "https://github.com/apache/hive/commit/d5dc57a1925b811507e63d7d6397e38bbf07859f", "message": "Use completion service to wait for executor completion", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "8fb5a35a9c305413b92631f820e88a372df2bd59", "url": "https://github.com/apache/hive/commit/8fb5a35a9c305413b92631f820e88a372df2bd59", "message": "Revert \"Use completion service to wait for executor completion\"\n\nThis reverts commit b4c3d2e27d6b147f4cf8053b4388ad523ebdf7e1.", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "9510700d0a26e35789a0bcdd543371ad9139146f", "url": "https://github.com/apache/hive/commit/9510700d0a26e35789a0bcdd543371ad9139146f", "message": "Use utility to create executor and fix executor shutdown", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "6a505763f2c3e325083af7463dd7de4b6388ed99", "url": "https://github.com/apache/hive/commit/6a505763f2c3e325083af7463dd7de4b6388ed99", "message": "add constant and fix if condition", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "38ac6cd48cb9d24f1dc684de4172ebcda5c2aafe", "url": "https://github.com/apache/hive/commit/38ac6cd48cb9d24f1dc684de4172ebcda5c2aafe", "message": "do not reinitialize executor", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "6039bbffba51682f9cbfb073837e490994ca0106", "url": "https://github.com/apache/hive/commit/6039bbffba51682f9cbfb073837e490994ca0106", "message": "Add executor shutdown", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68", "url": "https://github.com/apache/hive/commit/5f16fd20aafe062e5c70cfacc22a944591210f68", "message": "Remove redundant check", "committedDate": "2020-07-28T12:32:44Z", "type": "commit"}, {"oid": "5f16fd20aafe062e5c70cfacc22a944591210f68", "url": "https://github.com/apache/hive/commit/5f16fd20aafe062e5c70cfacc22a944591210f68", "message": "Remove redundant check", "committedDate": "2020-07-28T12:32:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjM1Mg==", "url": "https://github.com/apache/hive/pull/1275#discussion_r461412352", "bodyText": "nit: Make it 2 space tabs.", "author": "sankarh", "createdAt": "2020-07-28T08:34:40Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.txn.compactor;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class CompactorUtil {\n+    public interface ThrowingRunnable<E extends Exception> {", "originalCommit": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca5addc861df51983a91f709bf5294ac05fc24ae", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java\ndeleted file mode 100644\nindex 6f74187e5c..0000000000\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorUtil.java\n+++ /dev/null\n\n@@ -1,53 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hadoop.hive.ql.txn.compactor;\n-\n-import com.google.common.util.concurrent.ThreadFactoryBuilder;\n-import org.apache.hadoop.hive.conf.HiveConf;\n-\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.ThreadFactory;\n-\n-public class CompactorUtil {\n-    public interface ThrowingRunnable<E extends Exception> {\n-        void run() throws E;\n-\n-        static Runnable unchecked(ThrowingRunnable<?> r) {\n-            return () -> {\n-                try {\n-                    r.run();\n-                } catch (Exception e) {\n-                    throw new RuntimeException(e);\n-                }\n-            };\n-        }\n-    }\n-\n-    public static ThreadFactory createThreadFactory(String threadNameFormat) {\n-        return new ThreadFactoryBuilder()\n-                .setPriority(Thread.currentThread().getPriority())\n-                .setDaemon(Thread.currentThread().isDaemon())\n-                .setNameFormat(threadNameFormat)\n-                .build();\n-    }\n-\n-    public static ExecutorService createExecutorWithThreadFactory(int threadCount, String threadNameFormat) {\n-        return Executors.newFixedThreadPool(threadCount, createThreadFactory(threadNameFormat));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyMTEwMQ==", "url": "https://github.com/apache/hive/pull/1275#discussion_r461421101", "bodyText": "The config name can be relevant. It actually represent how many threads that we use for parallelly run the cleaner. But, the name sounds like Queue name. Can we change it to \"HIVE_COMPACTOR_CLEANER_THREADS_NUM\"?", "author": "sankarh", "createdAt": "2020-07-28T08:49:06Z", "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "diffHunk": "@@ -3028,6 +3028,9 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n \n     HIVE_COMPACTOR_CLEANER_RUN_INTERVAL(\"hive.compactor.cleaner.run.interval\", \"5000ms\",\n         new TimeValidator(TimeUnit.MILLISECONDS), \"Time between runs of the cleaner thread\"),\n+    HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE(\"hive.compactor.cleaner.request.queue\", 1,", "originalCommit": "c6ef5ddca2ea3009ceb99140079a6d694c642c17", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ca5addc861df51983a91f709bf5294ac05fc24ae", "chunk": "diff --git a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\nindex 779119106d..38ec0c78ea 100644\n--- a/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\n+++ b/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java\n\n@@ -3029,8 +3028,8 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n     HIVE_COMPACTOR_CLEANER_RUN_INTERVAL(\"hive.compactor.cleaner.run.interval\", \"5000ms\",\n         new TimeValidator(TimeUnit.MILLISECONDS), \"Time between runs of the cleaner thread\"),\n     HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE(\"hive.compactor.cleaner.request.queue\", 1,\n-      \"Enables parallelization of the cleaning directories after compaction, that includes many file \\n\" +\n-      \"related checks and may be expensive\"),\n+      \"Enables parallelization of the checkForCompaction operation, that includes many file metadata checks\\n\" +\n+      \"and may be expensive\"),\n     COMPACTOR_JOB_QUEUE(\"hive.compactor.job.queue\", \"\", \"Used to specify name of Hadoop queue to which\\n\" +\n       \"Compaction jobs will be submitted.  Set to empty string to let Hadoop choose the queue.\"),\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMDE3Nw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462120177", "bodyText": "nit: Make it \"for (int i = 0; i < 10; i++)\". Check other places in this patch.", "author": "sankarh", "createdAt": "2020-07-29T08:14:37Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {", "originalCommit": "5f16fd20aafe062e5c70cfacc22a944591210f68", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "423fa2adb7631540c2d3f56af47429659814cb5f", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\nindex 2f05810658..a806c16e47 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n\n@@ -291,7 +282,7 @@ public void processCompactionCandidatesInParallel() throws Exception {\n     Table t = newTable(\"default\", \"camipc\", true);\n     List<Partition> partitions = new ArrayList<>();\n     Partition p = null;\n-    for(int i=0; i<10; i++) {\n+    for(int i = 0; i < 10; i++) {\n       p = newPartition(t, \"today\" + i);\n \n       addBaseFile(t, p, 20L, 20);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMTMyMw==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462121323", "bodyText": "nit: Need a blank line after closing braces,", "author": "sankarh", "createdAt": "2020-07-29T08:16:25Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {\n+      p = newPartition(t, \"today\" + i);\n+\n+      addBaseFile(t, p, 20L, 20);\n+      addDeltaFile(t, p, 21L, 22L, 2);\n+      addDeltaFile(t, p, 23L, 24L, 2);\n+      addDeltaFile(t, p, 21L, 24L, 4);\n+      partitions.add(p);\n+    }\n+    burnThroughTransactions(\"default\", \"camipc\", 25);", "originalCommit": "5f16fd20aafe062e5c70cfacc22a944591210f68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEzOTU1Ng==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462139556", "bodyText": "Done.", "author": "adesh-rao", "createdAt": "2020-07-29T08:46:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMTMyMw=="}], "type": "inlineReview", "revised_code": {"commit": "423fa2adb7631540c2d3f56af47429659814cb5f", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\nindex 2f05810658..a806c16e47 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n\n@@ -291,7 +282,7 @@ public void processCompactionCandidatesInParallel() throws Exception {\n     Table t = newTable(\"default\", \"camipc\", true);\n     List<Partition> partitions = new ArrayList<>();\n     Partition p = null;\n-    for(int i=0; i<10; i++) {\n+    for(int i = 0; i < 10; i++) {\n       p = newPartition(t, \"today\" + i);\n \n       addBaseFile(t, p, 20L, 20);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjEyMjEwMA==", "url": "https://github.com/apache/hive/pull/1275#discussion_r462122100", "bodyText": "nit: Keep the code block of \"if\", \"else if\" and \"else\" in new line with a tab space.", "author": "sankarh", "createdAt": "2020-07-29T08:17:36Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java", "diffHunk": "@@ -274,6 +285,55 @@ public void droppedPartition() throws Exception {\n     ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n     Assert.assertEquals(0, rsp.getCompactsSize());\n   }\n+\n+  @Test\n+  public void processCompactionCandidatesInParallel() throws Exception {\n+    Table t = newTable(\"default\", \"camipc\", true);\n+    List<Partition> partitions = new ArrayList<>();\n+    Partition p = null;\n+    for(int i=0; i<10; i++) {\n+      p = newPartition(t, \"today\" + i);\n+\n+      addBaseFile(t, p, 20L, 20);\n+      addDeltaFile(t, p, 21L, 22L, 2);\n+      addDeltaFile(t, p, 23L, 24L, 2);\n+      addDeltaFile(t, p, 21L, 24L, 4);\n+      partitions.add(p);\n+    }\n+    burnThroughTransactions(\"default\", \"camipc\", 25);\n+    for(int i=0; i<10; i++) {\n+      CompactionRequest rqst = new CompactionRequest(\"default\", \"camipc\", CompactionType.MINOR);\n+      rqst.setPartitionname(\"ds=today\"+i);\n+      txnHandler.compact(rqst);\n+      CompactionInfo ci = txnHandler.findNextToCompact(\"fred\");\n+      ci.runAs = System.getProperty(\"user.name\");\n+      txnHandler.updateCompactorState(ci, openTxn());\n+      txnHandler.markCompacted(ci);\n+    }\n+\n+    conf.setIntVar(HiveConf.ConfVars.HIVE_COMPACTOR_CLEANER_REQUEST_QUEUE, 3);\n+    startCleaner();\n+\n+    // Check there are no compactions requests left.\n+    ShowCompactResponse rsp = txnHandler.showCompact(new ShowCompactRequest());\n+    Assert.assertEquals(10, rsp.getCompactsSize());\n+    Assert.assertTrue(TxnStore.SUCCEEDED_RESPONSE.equals(rsp.getCompacts().get(0).getState()));\n+\n+    // Check that the files are removed\n+    for (Partition pa : partitions) {\n+      List<Path> paths = getDirectories(conf, t, pa);\n+      Assert.assertEquals(2, paths.size());\n+      boolean sawBase = false, sawDelta = false;\n+      for (Path path : paths) {\n+        if (path.getName().equals(\"base_20\")) sawBase = true;", "originalCommit": "5f16fd20aafe062e5c70cfacc22a944591210f68", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "423fa2adb7631540c2d3f56af47429659814cb5f", "chunk": "diff --git a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\nindex 2f05810658..a806c16e47 100644\n--- a/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n+++ b/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/TestCleaner.java\n\n@@ -291,7 +282,7 @@ public void processCompactionCandidatesInParallel() throws Exception {\n     Table t = newTable(\"default\", \"camipc\", true);\n     List<Partition> partitions = new ArrayList<>();\n     Partition p = null;\n-    for(int i=0; i<10; i++) {\n+    for(int i = 0; i < 10; i++) {\n       p = newPartition(t, \"today\" + i);\n \n       addBaseFile(t, p, 20L, 20);\n"}}, {"oid": "f3d1dc37bfa5bfbda075f84b181a3884c49c0e59", "url": "https://github.com/apache/hive/commit/f3d1dc37bfa5bfbda075f84b181a3884c49c0e59", "message": "Log exception", "committedDate": "2020-07-29T08:33:58Z", "type": "commit"}, {"oid": "423fa2adb7631540c2d3f56af47429659814cb5f", "url": "https://github.com/apache/hive/commit/423fa2adb7631540c2d3f56af47429659814cb5f", "message": "fix review comments", "committedDate": "2020-07-29T08:42:04Z", "type": "commit"}, {"oid": "0b61fa6003cec9d1c4716cb8957edc779d93fc76", "url": "https://github.com/apache/hive/commit/0b61fa6003cec9d1c4716cb8957edc779d93fc76", "message": "Exit if cleaner thread got interrupted", "committedDate": "2020-07-29T19:06:25Z", "type": "commit"}]}