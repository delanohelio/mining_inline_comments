{"pr_number": 1533, "pr_title": "HIVE-24211: Replace Snapshot invalidate logic with WriteSet check for txn conflict detection", "pr_createdAt": "2020-09-28T16:57:52Z", "pr_url": "https://github.com/apache/hive/pull/1533", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY4OTgwOA==", "url": "https://github.com/apache/hive/pull/1533#discussion_r496689808", "bodyText": "That is an interesting change, do I understand correctly, that this says we only need to do a follow up check only, if the txn was outdated, because in the other cases the exclusive lock + the partition based writeset checking guarantees, that writeIds will be always valid at the second time? Could you add some comments here", "author": "pvargacl", "createdAt": "2020-09-29T12:50:49Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -497,38 +497,41 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command\n         HiveConf.ConfVars.HIVE_TXN_MAX_RETRYSNAPSHOT_COUNT);\n \n       try {\n-        while (!driverTxnHandler.isValidTxnListState() && ++retryShapshotCnt <= maxRetrySnapshotCnt) {\n-          LOG.info(\"Re-compiling after acquiring locks, attempt #\" + retryShapshotCnt);\n-          // Snapshot was outdated when locks were acquired, hence regenerate context, txn list and retry.\n-          // TODO: Lock acquisition should be moved before analyze, this is a bit hackish.\n-          // Currently, we acquire a snapshot, compile the query with that snapshot, and then - acquire locks.\n-          // If snapshot is still valid, we continue as usual.\n-          // But if snapshot is not valid, we recompile the query.\n-          if (driverContext.isOutdatedTxn()) {\n-            LOG.info(\"Snapshot is outdated, re-initiating transaction ...\");\n-            driverContext.getTxnManager().rollbackTxn();\n-\n-            String userFromUGI = DriverUtils.getUserFromUGI(driverContext);\n-            driverContext.getTxnManager().openTxn(context, userFromUGI, driverContext.getTxnType());\n-            lockAndRespond();\n+        do {\n+          driverContext.setOutdatedTxn(false);\n+\n+          if (!driverTxnHandler.isValidTxnListState()) {\n+            LOG.info(\"Re-compiling after acquiring locks, attempt #\" + retryShapshotCnt);\n+            // Snapshot was outdated when locks were acquired, hence regenerate context, txn list and retry.\n+            // TODO: Lock acquisition should be moved before analyze, this is a bit hackish.\n+            // Currently, we acquire a snapshot, compile the query with that snapshot, and then - acquire locks.\n+            // If snapshot is still valid, we continue as usual.\n+            // But if snapshot is not valid, we recompile the query.\n+            if (driverContext.isOutdatedTxn()) {\n+              LOG.info(\"Snapshot is outdated, re-initiating transaction ...\");\n+              driverContext.getTxnManager().rollbackTxn();\n+\n+              String userFromUGI = DriverUtils.getUserFromUGI(driverContext);\n+              driverContext.getTxnManager().openTxn(context, userFromUGI, driverContext.getTxnType());\n+              lockAndRespond();\n+            }\n+            driverContext.setRetrial(true);\n+            driverContext.getBackupContext().addSubContext(context);\n+            driverContext.getBackupContext().setHiveLocks(context.getHiveLocks());\n+            context = driverContext.getBackupContext();\n+\n+            driverContext.getConf().set(ValidTxnList.VALID_TXNS_KEY,\n+              driverContext.getTxnManager().getValidTxns().toString());\n+\n+            if (driverContext.getPlan().hasAcidResourcesInQuery()) {\n+              compileInternal(context.getCmd(), true);\n+              driverTxnHandler.recordValidWriteIds();\n+              driverTxnHandler.setWriteIdForAcidFileSinks();\n+            }\n+            // Since we're reusing the compiled plan, we need to update its start time for current run\n+            driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n           }\n-\n-          driverContext.setRetrial(true);\n-          driverContext.getBackupContext().addSubContext(context);\n-          driverContext.getBackupContext().setHiveLocks(context.getHiveLocks());\n-          context = driverContext.getBackupContext();\n-\n-          driverContext.getConf().set(ValidTxnList.VALID_TXNS_KEY,\n-            driverContext.getTxnManager().getValidTxns().toString());\n-\n-          if (driverContext.getPlan().hasAcidResourcesInQuery()) {\n-            compileInternal(context.getCmd(), true);\n-            driverTxnHandler.recordValidWriteIds();\n-            driverTxnHandler.setWriteIdForAcidFileSinks();\n-          }\n-          // Since we're reusing the compiled plan, we need to update its start time for current run\n-          driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n-        }\n+        } while (driverContext.isOutdatedTxn() && ++retryShapshotCnt <= maxRetrySnapshotCnt);", "originalCommit": "d6ea97470067a90fbc1a6d0b809ddb28c5a7502c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MDM5OQ==", "url": "https://github.com/apache/hive/pull/1533#discussion_r497380399", "bodyText": "added comments", "author": "deniskuzZ", "createdAt": "2020-09-30T09:44:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY4OTgwOA=="}], "type": "inlineReview", "revised_code": {"commit": "fee7ea9bb4dab2e6b326a70e969bedfeed6216ec", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\nindex 9ee5ab0a79..dc68a20f2b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java\n\n@@ -508,6 +508,7 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command\n             // If snapshot is still valid, we continue as usual.\n             // But if snapshot is not valid, we recompile the query.\n             if (driverContext.isOutdatedTxn()) {\n+              // Later transaction invalidated the snapshot, a new transaction is required\n               LOG.info(\"Snapshot is outdated, re-initiating transaction ...\");\n               driverContext.getTxnManager().rollbackTxn();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY5NjU4MQ==", "url": "https://github.com/apache/hive/pull/1533#discussion_r496696581", "bodyText": "Maybe add some javadoc, what does it do. I would emphasise that this method call only makes sense if the caller holds an exclusive lock, that blocks other txns to commit writes. And also, that this deliberately ignores inserts, or maybe this should be added to the DriverTxnHandler, that inserts will not invalidate the snapshot, that can cause duplicates", "author": "pvargacl", "createdAt": "2020-09-29T13:00:44Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -1408,6 +1410,43 @@ private boolean isUpdateOrDelete(Statement stmt, String conflictSQLSuffix) throw\n     }\n   }\n \n+  public long getLatestTxnInConflict(long txnid) throws MetaException {", "originalCommit": "d6ea97470067a90fbc1a6d0b809ddb28c5a7502c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQwMjIyOQ==", "url": "https://github.com/apache/hive/pull/1533#discussion_r497402229", "bodyText": "added javadoc", "author": "deniskuzZ", "createdAt": "2020-09-30T10:22:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY5NjU4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "fee7ea9bb4dab2e6b326a70e969bedfeed6216ec", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\nindex 08b59252ae..7a23b619cb 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\n\n@@ -1410,6 +1410,12 @@ private boolean isUpdateOrDelete(Statement stmt, String conflictSQLSuffix) throw\n     }\n   }\n \n+  /**\n+   * Checks if there are transactions that are overlapping, i.e. conflicting with the current one.\n+   * @param txnid\n+   * @return max Id for the conflicting transaction, if any, otherwise -1\n+   * @throws MetaException\n+   */\n   public long getLatestTxnInConflict(long txnid) throws MetaException {\n     Connection dbConn = null;\n     Statement stmt = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY5OTk3NQ==", "url": "https://github.com/apache/hive/pull/1533#discussion_r496699975", "bodyText": "This fix is not related to the original problem, shouldn't it be committed separately?", "author": "pvargacl", "createdAt": "2020-09-29T13:05:53Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -3501,6 +3541,10 @@ public void addDynamicPartitions(AddDynamicPartitions rqst)\n             pstmt.executeBatch();\n           }\n         }\n+        try (PreparedStatement pstmt = dbConn.prepareStatement(TXN_COMPONENTS_DP_DELETE_QUERY)) {", "originalCommit": "d6ea97470067a90fbc1a6d0b809ddb28c5a7502c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI5MzEzMw==", "url": "https://github.com/apache/hive/pull/1533#discussion_r497293133", "bodyText": "It's actually related. Operation that involve dynamic partitioning doesn't generate TXN_COMPONENTS at the locking stage, making it impossible to check for write conflict.", "author": "deniskuzZ", "createdAt": "2020-09-30T07:20:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY5OTk3NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjcwNjkyMw==", "url": "https://github.com/apache/hive/pull/1533#discussion_r496706923", "bodyText": "This is probably a big enough change, but I was wondering if you could return all the conflicting txnIds and writeIds. In that case if the max conflicting txnId is less than the current one, you could skip two other call to the HMS for validTxnList and validWriteIdList and just remove the exceptions from the list.", "author": "pvargacl", "createdAt": "2020-09-29T13:15:51Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java", "diffHunk": "@@ -1408,6 +1410,43 @@ private boolean isUpdateOrDelete(Statement stmt, String conflictSQLSuffix) throw\n     }\n   }\n \n+  public long getLatestTxnInConflict(long txnid) throws MetaException {\n+    Connection dbConn = null;\n+    Statement stmt = null;\n+\n+    try {\n+      dbConn = getDbConn(Connection.TRANSACTION_READ_COMMITTED);\n+      stmt = dbConn.createStatement();\n+\n+      String writeConflictQuery = \"SELECT MAX(\\\"COMMITTED\\\".\\\"WS_TXNID\\\")\" +", "originalCommit": "d6ea97470067a90fbc1a6d0b809ddb28c5a7502c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI5NTM5MQ==", "url": "https://github.com/apache/hive/pull/1533#discussion_r497295391", "bodyText": "In most of the cases it will just decrease the performance. It could only be useful if there is a conflict with already registered in snapshot txn. Also won't work with dynamic partitioning as we need to re-compile and get a fresh validWriteIdList list.", "author": "deniskuzZ", "createdAt": "2020-09-30T07:24:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjcwNjkyMw=="}], "type": "inlineReview", "revised_code": {"commit": "fee7ea9bb4dab2e6b326a70e969bedfeed6216ec", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\nindex 08b59252ae..7a23b619cb 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java\n\n@@ -1410,6 +1410,12 @@ private boolean isUpdateOrDelete(Statement stmt, String conflictSQLSuffix) throw\n     }\n   }\n \n+  /**\n+   * Checks if there are transactions that are overlapping, i.e. conflicting with the current one.\n+   * @param txnid\n+   * @return max Id for the conflicting transaction, if any, otherwise -1\n+   * @throws MetaException\n+   */\n   public long getLatestTxnInConflict(long txnid) throws MetaException {\n     Connection dbConn = null;\n     Statement stmt = null;\n"}}, {"oid": "4696f8d97a236a44562d3b25820745aa65583c7e", "url": "https://github.com/apache/hive/commit/4696f8d97a236a44562d3b25820745aa65583c7e", "message": "Snapshot invalidate logic replace with writeset check for conflict detection", "committedDate": "2020-09-29T17:02:40Z", "type": "forcePushed"}, {"oid": "c0ab72f709b5bb91c326e63eb3fbe60844bce41e", "url": "https://github.com/apache/hive/commit/c0ab72f709b5bb91c326e63eb3fbe60844bce41e", "message": "Snapshot invalidate logic replace with writeset check for conflict detection", "committedDate": "2020-09-29T20:20:31Z", "type": "forcePushed"}, {"oid": "fee7ea9bb4dab2e6b326a70e969bedfeed6216ec", "url": "https://github.com/apache/hive/commit/fee7ea9bb4dab2e6b326a70e969bedfeed6216ec", "message": "HIVE-24211: Replace Snapshot invalidate logic with WriteSet check for txn conflict detection", "committedDate": "2020-09-30T09:43:55Z", "type": "forcePushed"}, {"oid": "8860246dad2109251507a53d587c757c26193a78", "url": "https://github.com/apache/hive/commit/8860246dad2109251507a53d587c757c26193a78", "message": "HIVE-24211: Replace Snapshot invalidate logic with WriteSet check for txn conflict detection", "committedDate": "2020-09-30T10:22:05Z", "type": "commit"}, {"oid": "8860246dad2109251507a53d587c757c26193a78", "url": "https://github.com/apache/hive/commit/8860246dad2109251507a53d587c757c26193a78", "message": "HIVE-24211: Replace Snapshot invalidate logic with WriteSet check for txn conflict detection", "committedDate": "2020-09-30T10:22:05Z", "type": "forcePushed"}]}