{"pr_number": 1305, "pr_title": "HIVE-23892: Remove interpretation for character RexLiteral", "pr_createdAt": "2020-07-23T19:55:13Z", "pr_url": "https://github.com/apache/hive/pull/1305", "timeline": [{"oid": "0b87bc71c4009d73597645592665b9515cbcc163", "url": "https://github.com/apache/hive/commit/0b87bc71c4009d73597645592665b9515cbcc163", "message": "q file changes", "committedDate": "2020-07-24T04:13:01Z", "type": "forcePushed"}, {"oid": "f3e785e5b4c926d6351ff834ccc11d2e4f8fc0cf", "url": "https://github.com/apache/hive/commit/f3e785e5b4c926d6351ff834ccc11d2e4f8fc0cf", "message": "q file changes", "committedDate": "2020-07-25T00:31:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDc2MzEzNA==", "url": "https://github.com/apache/hive/pull/1305#discussion_r460763134", "bodyText": "I don't know why I've not choosen this path in HIVE-21316...\nmaybe I missed that MAX_VARCHAR_LENGTH  and  MAX_CHAR_LENGTH is both below 64K", "author": "kgyrtkirk", "createdAt": "2020-07-27T09:28:14Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java", "diffHunk": "@@ -341,26 +342,22 @@ public static ExprNodeConstantDesc toExprNodeConstantDesc(RexLiteral literal) {\n       case DECIMAL:\n         return new ExprNodeConstantDesc(TypeInfoFactory.getDecimalTypeInfo(lType.getPrecision(),\n             lType.getScale()), HiveDecimal.create((BigDecimal)literal.getValue3()));\n-      case VARCHAR:\n       case CHAR: {\n-        if (literal.getValue() instanceof HiveNlsString) {\n-          HiveNlsString mxNlsString = (HiveNlsString) literal.getValue();\n-          switch (mxNlsString.interpretation) {\n-          case STRING:\n-            return new ExprNodeConstantDesc(TypeInfoFactory.stringTypeInfo, literal.getValue3());\n-          case CHAR: {\n-            int precision = lType.getPrecision();\n-            HiveChar value = new HiveChar((String) literal.getValue3(), precision);\n-            return new ExprNodeConstantDesc(new CharTypeInfo(precision), value);\n-          }\n-          case VARCHAR: {\n-            int precision = lType.getPrecision();\n-            HiveVarchar value = new HiveVarchar((String) literal.getValue3(), precision);\n-            return new ExprNodeConstantDesc(new VarcharTypeInfo(precision), value);\n-          }\n-          }\n+        Preconditions.checkState(literal.getValue() instanceof NlsString,\n+            \"char values must use NlsString for correctness\");\n+        int precision = lType.getPrecision();\n+        HiveChar value = new HiveChar((String) literal.getValue3(), precision);\n+        return new ExprNodeConstantDesc(new CharTypeInfo(precision), value);\n+      }\n+      case VARCHAR: {\n+        Preconditions.checkState(literal.getValue() instanceof NlsString,\n+            \"varchar/string values must use NlsString for correctness\");\n+        int precision = lType.getPrecision();\n+        if (precision == Integer.MAX_VALUE) {\n+          return new ExprNodeConstantDesc(TypeInfoFactory.stringTypeInfo, literal.getValue3());", "originalCommit": "6101458772eb1a2f8b934217af2657b6a306dc1a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c3daacf17449a5334f7ece95e1d7913772974e6d", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java\nindex 3ef5869986..d4978f8d8e 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/ExprNodeConverter.java\n\n@@ -343,21 +342,20 @@ public static ExprNodeConstantDesc toExprNodeConstantDesc(RexLiteral literal) {\n         return new ExprNodeConstantDesc(TypeInfoFactory.getDecimalTypeInfo(lType.getPrecision(),\n             lType.getScale()), HiveDecimal.create((BigDecimal)literal.getValue3()));\n       case CHAR: {\n-        Preconditions.checkState(literal.getValue() instanceof NlsString,\n-            \"char values must use NlsString for correctness\");\n         int precision = lType.getPrecision();\n         HiveChar value = new HiveChar((String) literal.getValue3(), precision);\n         return new ExprNodeConstantDesc(new CharTypeInfo(precision), value);\n       }\n       case VARCHAR: {\n-        Preconditions.checkState(literal.getValue() instanceof NlsString,\n-            \"varchar/string values must use NlsString for correctness\");\n-        int precision = lType.getPrecision();\n-        if (precision == Integer.MAX_VALUE) {\n-          return new ExprNodeConstantDesc(TypeInfoFactory.stringTypeInfo, literal.getValue3());\n+        if (literal.getValue() instanceof NlsString) {\n+          int precision = lType.getPrecision();\n+          if (precision == Integer.MAX_VALUE) {\n+            return new ExprNodeConstantDesc(TypeInfoFactory.stringTypeInfo, literal.getValue3());\n+          }\n+          HiveVarchar value = new HiveVarchar((String) literal.getValue3(), precision);\n+          return new ExprNodeConstantDesc(new VarcharTypeInfo(precision), value);\n         }\n-        HiveVarchar value = new HiveVarchar((String) literal.getValue3(), precision);\n-        return new ExprNodeConstantDesc(new VarcharTypeInfo(precision), value);\n+        throw new RuntimeException(\"varchar/string/char values must use HiveNlsString for correctness\");\n       }\n       case INTERVAL_YEAR:\n       case INTERVAL_MONTH:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDc2OTc5MA==", "url": "https://github.com/apache/hive/pull/1305#discussion_r460769790", "bodyText": "this will discard type distinction between char/varchar - but because CHAR is already padded at this point; it will work correctly!\nawesome! :)", "author": "kgyrtkirk", "createdAt": "2020-07-27T09:40:08Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/type/RexNodeExprFactory.java", "diffHunk": "@@ -374,7 +373,7 @@ protected Object interpretConstantAsPrimitive(PrimitiveTypeInfo targetType, Obje\n         HiveChar newValue = new HiveChar(constValue, length);\n         HiveChar maxCharConst = new HiveChar(constValue, HiveChar.MAX_CHAR_LENGTH);\n         if (maxCharConst.equals(newValue)) {\n-          return makeHiveUnicodeString(Interpretation.CHAR, newValue.getValue());\n+          return makeHiveUnicodeString(newValue.getValue());", "originalCommit": "6101458772eb1a2f8b934217af2657b6a306dc1a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "c3daacf17449a5334f7ece95e1d7913772974e6d", "url": "https://github.com/apache/hive/commit/c3daacf17449a5334f7ece95e1d7913772974e6d", "message": "HIVE-23892", "committedDate": "2020-07-28T15:14:52Z", "type": "commit"}, {"oid": "037bbb741588d87d3d4229f8178b1d0659f6c068", "url": "https://github.com/apache/hive/commit/037bbb741588d87d3d4229f8178b1d0659f6c068", "message": "q file changes", "committedDate": "2020-07-28T15:14:52Z", "type": "commit"}, {"oid": "0e2b27e0673be34f0f9dcd01adfb0ddb4c8f61a7", "url": "https://github.com/apache/hive/commit/0e2b27e0673be34f0f9dcd01adfb0ddb4c8f61a7", "message": "comments", "committedDate": "2020-07-28T15:14:52Z", "type": "commit"}, {"oid": "b5dfaeae48a0ca4019b3d869795102ded045ba54", "url": "https://github.com/apache/hive/commit/b5dfaeae48a0ca4019b3d869795102ded045ba54", "message": "additional test", "committedDate": "2020-07-28T15:14:52Z", "type": "commit"}, {"oid": "b5dfaeae48a0ca4019b3d869795102ded045ba54", "url": "https://github.com/apache/hive/commit/b5dfaeae48a0ca4019b3d869795102ded045ba54", "message": "additional test", "committedDate": "2020-07-28T15:14:52Z", "type": "forcePushed"}]}