{"pr_number": 1634, "pr_title": "HIVE-24332: Make AbstractSerDe Superclass of all SerDes", "pr_createdAt": "2020-10-30T16:20:34Z", "pr_url": "https://github.com/apache/hive/pull/1634", "timeline": [{"oid": "242a97f465095e920fcddd96edc5afbf9f959786", "url": "https://github.com/apache/hive/commit/242a97f465095e920fcddd96edc5afbf9f959786", "message": "Make parent SerDe interface", "committedDate": "2020-11-23T22:13:50Z", "type": "forcePushed"}, {"oid": "cfeffdeee24314d705805fef61e24c3ac0af769c", "url": "https://github.com/apache/hive/commit/cfeffdeee24314d705805fef61e24c3ac0af769c", "message": "Make parent SerDe interface", "committedDate": "2020-11-24T19:11:48Z", "type": "forcePushed"}, {"oid": "b45742bef0fc4d32b98d2382128a563b3b876c20", "url": "https://github.com/apache/hive/commit/b45742bef0fc4d32b98d2382128a563b3b876c20", "message": "Fix compile errors", "committedDate": "2020-11-24T20:55:48Z", "type": "forcePushed"}, {"oid": "e296dd8ccb114dd189bf4165074780dcaac3e743", "url": "https://github.com/apache/hive/commit/e296dd8ccb114dd189bf4165074780dcaac3e743", "message": "Fix compile errors", "committedDate": "2020-11-25T14:09:49Z", "type": "forcePushed"}, {"oid": "a82a5a1a471dd2448b6c8c36f52dd39b6bf5e27c", "url": "https://github.com/apache/hive/commit/a82a5a1a471dd2448b6c8c36f52dd39b6bf5e27c", "message": "Fix compile errors", "committedDate": "2020-11-25T15:00:08Z", "type": "forcePushed"}, {"oid": "075e119f06d7904704e15cc9b99ca5e423396fff", "url": "https://github.com/apache/hive/commit/075e119f06d7904704e15cc9b99ca5e423396fff", "message": "Fix compile errors", "committedDate": "2020-11-25T21:48:12Z", "type": "forcePushed"}, {"oid": "189342618df30cad639cd39c1185008f4b2eb2a9", "url": "https://github.com/apache/hive/commit/189342618df30cad639cd39c1185008f4b2eb2a9", "message": "Use correct configuration", "committedDate": "2020-12-02T20:17:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTAyNg==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031026", "bodyText": "Nit: please rename tt_desc so that it follows the java naming conventions.", "author": "miklosgergely", "createdAt": "2020-12-13T23:28:58Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java", "diffHunk": "@@ -775,7 +775,7 @@ public static void setTaskPlan(Path path, String alias,\n     if (topOp instanceof TableScanOperator) {\n       try {\n         Utilities.addSchemaEvolutionToTableScanOperator(\n-          (StructObjectInspector) tt_desc.getDeserializer().getObjectInspector(),\n+          (StructObjectInspector) tt_desc.getSerDe().getObjectInspector(),", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3MjU3NA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543372574", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:10:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTAyNg=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java\nindex b3a24c65ac..83ca3a40ad 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java\n\n@@ -775,7 +775,7 @@ public static void setTaskPlan(Path path, String alias,\n     if (topOp instanceof TableScanOperator) {\n       try {\n         Utilities.addSchemaEvolutionToTableScanOperator(\n-          (StructObjectInspector) tt_desc.getSerDe().getObjectInspector(),\n+          (StructObjectInspector) ttDesc.getSerDe().getObjectInspector(),\n           (TableScanOperator) topOp);\n       } catch (Exception e) {\n         throw new SemanticException(e);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTA4OA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031088", "bodyText": "Please call the variable serDe.", "author": "miklosgergely", "createdAt": "2020-12-13T23:29:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/TablePropertyEnrichmentOptimizer.java", "diffHunk": "@@ -115,13 +115,13 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx, Obje\n       String deserializerClassName = null;\n       try {\n         deserializerClassName = tableScanDesc.getTableMetadata().getSd().getSerdeInfo().getSerializationLib();\n-        Deserializer deserializer = ReflectionUtil.newInstance(\n+        AbstractSerDe deserializer = ReflectionUtil.newInstance(", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM4MzY5NQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543383695", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:19:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTA4OA=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/TablePropertyEnrichmentOptimizer.java b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/TablePropertyEnrichmentOptimizer.java\nindex e810459935..846aff7132 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/optimizer/TablePropertyEnrichmentOptimizer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/optimizer/TablePropertyEnrichmentOptimizer.java\n\n@@ -115,13 +115,13 @@ public Object process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx, Obje\n       String deserializerClassName = null;\n       try {\n         deserializerClassName = tableScanDesc.getTableMetadata().getSd().getSerdeInfo().getSerializationLib();\n-        AbstractSerDe deserializer = ReflectionUtil.newInstance(\n+        AbstractSerDe serDe = ReflectionUtil.newInstance(\n             context.conf.getClassByName(deserializerClassName)\n                 .asSubclass(AbstractSerDe.class),\n             context.conf);\n \n         if (context.serdeClassesUnderConsideration.contains(deserializerClassName)) {\n-          deserializer.initialize(context.conf, clonedTableParameters, null);\n+          serDe.initialize(context.conf, clonedTableParameters, null);\n           LOG.debug(\"SerDe init succeeded for class: \" + deserializerClassName);\n           for (Map.Entry property : clonedTableParameters.entrySet()) {\n             if (!property.getValue().equals(originalTableParameters.get(property.getKey()))) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTE3NQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031175", "bodyText": "Please call the variable serDe, and the function getSerDeClass, to be consistent with TableDesc.", "author": "miklosgergely", "createdAt": "2020-12-13T23:29:38Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java", "diffHunk": "@@ -171,9 +171,9 @@ public String getDeserializerClassName() {\n   public Deserializer getDeserializer(Configuration conf) throws Exception {\n     Properties schema = getProperties();\n     String clazzName = getDeserializerClassName();\n-    Deserializer deserializer = ReflectionUtil.newInstance(conf.getClassByName(clazzName)\n-        .asSubclass(Deserializer.class), conf);\n-    SerDeUtils.initializeSerDe(deserializer, conf, getTableDesc().getProperties(), schema);\n+    AbstractSerDe deserializer = ReflectionUtil.newInstance(conf.getClassByName(clazzName)", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3Mzk5Mw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543373993", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:11:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTE3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java b/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java\nindex 8914796c21..a6fbdc2874 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionDesc.java\n\n@@ -171,10 +171,10 @@ public String getDeserializerClassName() {\n   public Deserializer getDeserializer(Configuration conf) throws Exception {\n     Properties schema = getProperties();\n     String clazzName = getDeserializerClassName();\n-    AbstractSerDe deserializer = ReflectionUtil.newInstance(conf.getClassByName(clazzName)\n+    AbstractSerDe serDe = ReflectionUtil.newInstance(conf.getClassByName(clazzName)\n         .asSubclass(AbstractSerDe.class), conf);\n-    deserializer.initialize(conf, getTableDesc().getProperties(), schema);\n-    return deserializer;\n+    serDe.initialize(conf, getTableDesc().getProperties(), schema);\n+    return serDe;\n   }\n \n   public void setInputFileFormatClass(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTY2Mw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031663", "bodyText": "I suggest to call it inputKeySerDe, and it can be created under this name, no need to call it serde for an interim time.", "author": "miklosgergely", "createdAt": "2020-12-13T23:32:21Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java", "diffHunk": "@@ -152,10 +152,11 @@ void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyT\n     this.tag = tag;\n \n     try {\n-      inputKeyDeserializer = ReflectionUtils.newInstance(keyTableDesc\n-          .getDeserializerClass(), null);\n-      SerDeUtils.initializeSerDe(inputKeyDeserializer, null, keyTableDesc.getProperties(), null);\n-      keyObjectInspector = inputKeyDeserializer.getObjectInspector();\n+      AbstractSerDe serde = ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(), null);\n+      serde.initialize(null, keyTableDesc.getProperties(), null);\n+\n+      inputKeyDeserializer = serde; ", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM4OTQ1Ng==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543389456", "bodyText": "Done.  I had it this way because inputKeyDeserializer is a Deserializer class which does not have an 'initialize' method.  However, I change the type to be AbstractSerDe to address your comments here.", "author": "belugabehr", "createdAt": "2020-12-15T14:23:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTY2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\nindex d431b58812..c42d293854 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\n\n@@ -152,11 +151,10 @@ void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyT\n     this.tag = tag;\n \n     try {\n-      AbstractSerDe serde = ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(), null);\n-      serde.initialize(null, keyTableDesc.getProperties(), null);\n+      inputKeySerDe = ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(), null);\n+      inputKeySerDe.initialize(null, keyTableDesc.getProperties(), null);\n \n-      inputKeyDeserializer = serde; \n-      keyObjectInspector = serde.getObjectInspector();\n+      keyObjectInspector = inputKeySerDe.getObjectInspector();\n \n       if(vectorized) {\n         keyStructInspector = (StructObjectInspector) keyObjectInspector;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTcwMQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031701", "bodyText": "Please call this inputValueSerDe", "author": "miklosgergely", "createdAt": "2020-12-13T23:32:33Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java", "diffHunk": "@@ -164,10 +165,8 @@ void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyT\n \n       // We should initialize the SerDe with the TypeInfo when available.\n       this.valueTableDesc = valueTableDesc;\n-      inputValueDeserializer = (AbstractSerDe) ReflectionUtils.newInstance(\n-          valueTableDesc.getDeserializerClass(), null);\n-      SerDeUtils.initializeSerDe(inputValueDeserializer, null,\n-          valueTableDesc.getProperties(), null);\n+      inputValueDeserializer = (AbstractSerDe) ReflectionUtils.newInstance(valueTableDesc.getSerDeClass(), null);", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3NDk2Ng==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543374966", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:12:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTcwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\nindex d431b58812..c42d293854 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordSource.java\n\n@@ -165,9 +163,9 @@ void init(JobConf jconf, Operator<?> reducer, boolean vectorized, TableDesc keyT\n \n       // We should initialize the SerDe with the TypeInfo when available.\n       this.valueTableDesc = valueTableDesc;\n-      inputValueDeserializer = (AbstractSerDe) ReflectionUtils.newInstance(valueTableDesc.getSerDeClass(), null);\n-      inputValueDeserializer.initialize(null, valueTableDesc.getProperties(), null);\n-      valueObjectInspector = inputValueDeserializer.getObjectInspector();\n+      inputValueSerDe = (AbstractSerDe) ReflectionUtils.newInstance(valueTableDesc.getSerDeClass(), null);\n+      inputValueSerDe.initialize(null, valueTableDesc.getProperties(), null);\n+      valueObjectInspector = inputValueSerDe.getObjectInspector();\n \n       ArrayList<ObjectInspector> ois = new ArrayList<ObjectInspector>();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTc2Mg==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542031762", "bodyText": "Please call this serDe.", "author": "miklosgergely", "createdAt": "2020-12-13T23:32:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DynamicValueRegistryTez.java", "diffHunk": "@@ -104,8 +105,8 @@ public void init(RegistryConf conf) throws Exception {\n       RuntimeValuesInfo runtimeValuesInfo = rct.baseWork.getInputSourceToRuntimeValuesInfo().get(inputSourceName);\n \n       // Setup deserializer/obj inspectors for the incoming data source\n-      Deserializer deserializer = ReflectionUtils.newInstance(runtimeValuesInfo.getTableDesc().getDeserializerClass(), null);\n-      deserializer.initialize(rct.conf, runtimeValuesInfo.getTableDesc().getProperties());\n+      AbstractSerDe deserializer = ReflectionUtils.newInstance(runtimeValuesInfo.getTableDesc().getSerDeClass(), null);", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5MDA3MQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543390071", "bodyText": "Resolved.", "author": "belugabehr", "createdAt": "2020-12-15T14:24:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMTc2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DynamicValueRegistryTez.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DynamicValueRegistryTez.java\nindex 027161eed4..d1a2caff88 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DynamicValueRegistryTez.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DynamicValueRegistryTez.java\n\n@@ -105,9 +104,9 @@ public void init(RegistryConf conf) throws Exception {\n       RuntimeValuesInfo runtimeValuesInfo = rct.baseWork.getInputSourceToRuntimeValuesInfo().get(inputSourceName);\n \n       // Setup deserializer/obj inspectors for the incoming data source\n-      AbstractSerDe deserializer = ReflectionUtils.newInstance(runtimeValuesInfo.getTableDesc().getSerDeClass(), null);\n-      deserializer.initialize(rct.conf, runtimeValuesInfo.getTableDesc().getProperties(), null);\n-      ObjectInspector inspector = deserializer.getObjectInspector();\n+      AbstractSerDe serDe = ReflectionUtils.newInstance(runtimeValuesInfo.getTableDesc().getSerDeClass(), null);\n+      serDe.initialize(rct.conf, runtimeValuesInfo.getTableDesc().getProperties(), null);\n+      ObjectInspector inspector = serDe.getObjectInspector();\n \n       // Set up col expressions for the dynamic values using this input\n       List<ExprNodeEvaluator> colExprEvaluators = new ArrayList<ExprNodeEvaluator>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjI4Mw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542032283", "bodyText": "Please call this inputValueSerDe.", "author": "miklosgergely", "createdAt": "2020-12-13T23:36:04Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java", "diffHunk": "@@ -154,10 +157,11 @@ public void init(JobConf job, OutputCollector output, Reporter reporter) throws\n       for (int tag = 0; tag < gWork.getTagToValueDesc().size(); tag++) {\n         // We should initialize the SerDe with the TypeInfo when available.\n         valueTableDesc[tag] = gWork.getTagToValueDesc().get(tag);\n-        inputValueDeserializer[tag] = ReflectionUtils.newInstance(\n-            valueTableDesc[tag].getDeserializerClass(), null);\n-        SerDeUtils.initializeSerDe(inputValueDeserializer[tag], null,\n-            valueTableDesc[tag].getProperties(), null);\n+\n+        AbstractSerDe sd = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n+        sd.initialize(null, valueTableDesc[tag].getProperties(), null);\n+\n+        inputValueDeserializer[tag] = sd;", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5MzM4MA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543393380", "bodyText": "Done", "author": "belugabehr", "createdAt": "2020-12-15T14:28:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjI4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\nindex 5c123fb68a..32426a3a79 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\n\n@@ -158,11 +157,11 @@ public void init(JobConf job, OutputCollector output, Reporter reporter) throws\n         // We should initialize the SerDe with the TypeInfo when available.\n         valueTableDesc[tag] = gWork.getTagToValueDesc().get(tag);\n \n-        AbstractSerDe sd = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n-        sd.initialize(null, valueTableDesc[tag].getProperties(), null);\n+        AbstractSerDe inputValueSerDe = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n+        inputValueSerDe.initialize(null, valueTableDesc[tag].getProperties(), null);\n \n-        inputValueDeserializer[tag] = sd;\n-        valueObjectInspector[tag] = inputValueDeserializer[tag].getObjectInspector();\n+        inputValueDeserializer[tag] = inputValueSerDe;\n+        valueObjectInspector[tag] = inputValueSerDe.getObjectInspector();\n \n         ArrayList<ObjectInspector> ois = new ArrayList<ObjectInspector>();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjYyOA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542032628", "bodyText": "Please call this inputKeySerDe. Also no need to create a variable called serde for an interim time.", "author": "miklosgergely", "createdAt": "2020-12-13T23:37:53Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java", "diffHunk": "@@ -132,10 +133,12 @@ public void init(JobConf job, OutputCollector output, Reporter reporter) throws\n     isTagged = gWork.getNeedsTagging();\n     try {\n       keyTableDesc = gWork.getKeyDesc();\n-      inputKeyDeserializer = ReflectionUtils.newInstance(keyTableDesc\n-        .getDeserializerClass(), null);\n-      SerDeUtils.initializeSerDe(inputKeyDeserializer, null, keyTableDesc.getProperties(), null);\n-      keyObjectInspector = inputKeyDeserializer.getObjectInspector();\n+      AbstractSerDe serde = ReflectionUtils.newInstance(keyTableDesc\n+        .getSerDeClass(), null);\n+      serde.initialize(null, keyTableDesc.getProperties(), null);\n+      keyObjectInspector = serde.getObjectInspector();\n+\n+      inputKeyDeserializer = serde;", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5MTkzMQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543391931", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:26:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjYyOA=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\nindex 5c123fb68a..32426a3a79 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkReduceRecordHandler.java\n\n@@ -133,12 +133,11 @@ public void init(JobConf job, OutputCollector output, Reporter reporter) throws\n     isTagged = gWork.getNeedsTagging();\n     try {\n       keyTableDesc = gWork.getKeyDesc();\n-      AbstractSerDe serde = ReflectionUtils.newInstance(keyTableDesc\n+      inputKeySerDe = ReflectionUtils.newInstance(keyTableDesc\n         .getSerDeClass(), null);\n-      serde.initialize(null, keyTableDesc.getProperties(), null);\n-      keyObjectInspector = serde.getObjectInspector();\n+      inputKeySerDe.initialize(null, keyTableDesc.getProperties(), null);\n+      keyObjectInspector = inputKeySerDe.getObjectInspector();\n \n-      inputKeyDeserializer = serde;\n       valueTableDesc = new TableDesc[gWork.getTagToValueDesc().size()];\n \n       if (vectorized) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjgwNw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542032807", "bodyText": "Please call this inputKeySerDe, also no need for the interim serde variable.", "author": "miklosgergely", "createdAt": "2020-12-13T23:39:01Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java", "diffHunk": "@@ -100,20 +101,19 @@ public void configure(JobConf job) {\n     isTagged = gWork.getNeedsTagging();\n     try {\n       keyTableDesc = gWork.getKeyDesc();\n-      inputKeyDeserializer = ReflectionUtils.newInstance(keyTableDesc\n-          .getDeserializerClass(), null);\n-      SerDeUtils.initializeSerDe(inputKeyDeserializer, null, keyTableDesc.getProperties(), null);\n+      AbstractSerDe serDe = ReflectionUtils.newInstance(keyTableDesc\n+          .getSerDeClass(), null);\n+      serDe.initialize(null, keyTableDesc.getProperties(), null);\n+      inputKeyDeserializer = serDe;", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5NzExMg==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543397112", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:32:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjgwNw=="}], "type": "inlineReview", "revised_code": {"commit": "4fb20950d08e5e7d987f5f14224dad05b6e1c269", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\nindex fe0343b0b2..e66393bdd4 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\n\n@@ -112,8 +112,8 @@ public void configure(JobConf job) {\n         valueTableDesc[tag] = gWork.getTagToValueDesc().get(tag);\n         AbstractSerDe sd = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n         sd.initialize(null, valueTableDesc[tag].getProperties(), null);\n-        inputValueDeserializer[tag] = sd;\n         valueObjectInspector[tag] = inputValueDeserializer[tag].getObjectInspector();\n+        inputValueDeserializer[tag] = sd;\n \n         ArrayList<ObjectInspector> ois = new ArrayList<ObjectInspector>();\n         ois.add(keyObjectInspector);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjg0Mw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542032843", "bodyText": "Please call this valueObjectSerDe", "author": "miklosgergely", "createdAt": "2020-12-13T23:39:16Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java", "diffHunk": "@@ -100,20 +101,19 @@ public void configure(JobConf job) {\n     isTagged = gWork.getNeedsTagging();\n     try {\n       keyTableDesc = gWork.getKeyDesc();\n-      inputKeyDeserializer = ReflectionUtils.newInstance(keyTableDesc\n-          .getDeserializerClass(), null);\n-      SerDeUtils.initializeSerDe(inputKeyDeserializer, null, keyTableDesc.getProperties(), null);\n+      AbstractSerDe serDe = ReflectionUtils.newInstance(keyTableDesc\n+          .getSerDeClass(), null);\n+      serDe.initialize(null, keyTableDesc.getProperties(), null);\n+      inputKeyDeserializer = serDe;\n       keyObjectInspector = inputKeyDeserializer.getObjectInspector();\n       valueTableDesc = new TableDesc[gWork.getTagToValueDesc().size()];\n       for (int tag = 0; tag < gWork.getTagToValueDesc().size(); tag++) {\n         // We should initialize the SerDe with the TypeInfo when available.\n         valueTableDesc[tag] = gWork.getTagToValueDesc().get(tag);\n-        inputValueDeserializer[tag] = ReflectionUtils.newInstance(\n-            valueTableDesc[tag].getDeserializerClass(), null);\n-        SerDeUtils.initializeSerDe(inputValueDeserializer[tag], null,\n-                                   valueTableDesc[tag].getProperties(), null);\n-        valueObjectInspector[tag] = inputValueDeserializer[tag]\n-            .getObjectInspector();\n+        AbstractSerDe sd = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n+        sd.initialize(null, valueTableDesc[tag].getProperties(), null);\n+        inputValueDeserializer[tag] = sd;\n+        valueObjectInspector[tag] = inputValueDeserializer[tag].getObjectInspector();", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5Mzg1NA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543393854", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMjg0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "4fb20950d08e5e7d987f5f14224dad05b6e1c269", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\nindex fe0343b0b2..e66393bdd4 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java\n\n@@ -112,8 +112,8 @@ public void configure(JobConf job) {\n         valueTableDesc[tag] = gWork.getTagToValueDesc().get(tag);\n         AbstractSerDe sd = ReflectionUtils.newInstance(valueTableDesc[tag].getSerDeClass(), null);\n         sd.initialize(null, valueTableDesc[tag].getProperties(), null);\n-        inputValueDeserializer[tag] = sd;\n         valueObjectInspector[tag] = inputValueDeserializer[tag].getObjectInspector();\n+        inputValueDeserializer[tag] = sd;\n \n         ArrayList<ObjectInspector> ois = new ArrayList<ObjectInspector>();\n         ois.add(keyObjectInspector);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzAxNw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033017", "bodyText": "Nit: outputSerDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:40:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java", "diffHunk": "@@ -273,15 +273,14 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     try {\n       this.hconf = hconf;\n \n-      scriptOutputDeserializer = conf.getScriptOutputInfo()\n-          .getDeserializerClass().newInstance();\n-      SerDeUtils.initializeSerDe(scriptOutputDeserializer, hconf,\n-                                 conf.getScriptOutputInfo().getProperties(), null);\n+      AbstractSerDe outputSerde = conf.getScriptOutputInfo().getSerDeClass().newInstance();", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5NDQ1NQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543394455", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzAxNw=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\nindex 8dbea518a7..2ac0a92487 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\n\n@@ -273,13 +273,13 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     try {\n       this.hconf = hconf;\n \n-      AbstractSerDe outputSerde = conf.getScriptOutputInfo().getSerDeClass().newInstance();\n-      outputSerde.initialize(hconf, conf.getScriptOutputInfo().getProperties(), null);\n+      AbstractSerDe outputSerDe = conf.getScriptOutputInfo().getSerDeClass().newInstance();\n+      outputSerDe.initialize(hconf, conf.getScriptOutputInfo().getProperties(), null);\n \n       AbstractSerDe inputSerde = conf.getScriptInputInfo().getSerDeClass().newInstance();\n       inputSerde.initialize(hconf, conf.getScriptInputInfo().getProperties(), null);\n \n-      scriptOutputDeserializer = outputSerde;\n+      scriptOutputDeserializer = outputSerDe;\n       scriptInputSerializer = inputSerde;\n \n       outputObjInspector = scriptOutputDeserializer.getObjectInspector();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzA5NA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033094", "bodyText": "Nit: inputSerDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:40:40Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java", "diffHunk": "@@ -273,15 +273,14 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     try {\n       this.hconf = hconf;\n \n-      scriptOutputDeserializer = conf.getScriptOutputInfo()\n-          .getDeserializerClass().newInstance();\n-      SerDeUtils.initializeSerDe(scriptOutputDeserializer, hconf,\n-                                 conf.getScriptOutputInfo().getProperties(), null);\n+      AbstractSerDe outputSerde = conf.getScriptOutputInfo().getSerDeClass().newInstance();\n+      outputSerde.initialize(hconf, conf.getScriptOutputInfo().getProperties(), null);\n \n-      scriptInputSerializer = (Serializer) conf.getScriptInputInfo()\n-          .getDeserializerClass().newInstance();\n-      scriptInputSerializer.initialize(hconf, conf.getScriptInputInfo()\n-          .getProperties());\n+      AbstractSerDe inputSerde = conf.getScriptInputInfo().getSerDeClass().newInstance();", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5NTY4NQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543395685", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzA5NA=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\nindex 8dbea518a7..2ac0a92487 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java\n\n@@ -273,13 +273,13 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     try {\n       this.hconf = hconf;\n \n-      AbstractSerDe outputSerde = conf.getScriptOutputInfo().getSerDeClass().newInstance();\n-      outputSerde.initialize(hconf, conf.getScriptOutputInfo().getProperties(), null);\n+      AbstractSerDe outputSerDe = conf.getScriptOutputInfo().getSerDeClass().newInstance();\n+      outputSerDe.initialize(hconf, conf.getScriptOutputInfo().getProperties(), null);\n \n       AbstractSerDe inputSerde = conf.getScriptInputInfo().getSerDeClass().newInstance();\n       inputSerde.initialize(hconf, conf.getScriptInputInfo().getProperties(), null);\n \n-      scriptOutputDeserializer = outputSerde;\n+      scriptOutputDeserializer = outputSerDe;\n       scriptInputSerializer = inputSerde;\n \n       outputObjInspector = scriptOutputDeserializer.getObjectInspector();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzI5OA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033298", "bodyText": "Nit: AbstractSerDe serDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:41:46Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java", "diffHunk": "@@ -407,7 +407,7 @@ public void initEmptyInputChildren(List<Operator<?>> children, Configuration hco\n       StructObjectInspector soi = null;\n       PartitionDesc partDesc = conf.getAliasToPartnInfo().get(tsOp.getConf().getAlias());\n       Configuration newConf = tableNameToConf.get(partDesc.getTableDesc().getTableName());\n-      Deserializer serde = partDesc.getTableDesc().getDeserializer();\n+      Deserializer serde = partDesc.getTableDesc().getSerDe();", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM5NTgwMw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543395803", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzI5OA=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java\nindex 308df6c116..5c86025fb1 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java\n\n@@ -407,7 +408,7 @@ public void initEmptyInputChildren(List<Operator<?>> children, Configuration hco\n       StructObjectInspector soi = null;\n       PartitionDesc partDesc = conf.getAliasToPartnInfo().get(tsOp.getConf().getAlias());\n       Configuration newConf = tableNameToConf.get(partDesc.getTableDesc().getTableName());\n-      Deserializer serde = partDesc.getTableDesc().getSerDe();\n+      AbstractSerDe serde = partDesc.getTableDesc().getSerDe();\n       partDesc.setProperties(partDesc.getProperties());\n       MapOpCtx opCtx = new MapOpCtx(tsOp.getConf().getAlias(), child, partDesc);\n       StructObjectInspector tableRowOI = (StructObjectInspector) serde.getObjectInspector();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzM1MA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033350", "bodyText": "Please call this keySerDe", "author": "miklosgergely", "createdAt": "2020-12-13T23:42:03Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java", "diffHunk": "@@ -352,8 +351,8 @@ public void generateMapMetaData() throws HiveException {\n     try {\n       TableDesc keyTableDesc = conf.getKeyTblDesc();\n       AbstractSerDe keySerializer = (AbstractSerDe) ReflectionUtil.newInstance(", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3NTg3MA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543375870", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzM1MA=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java\nindex f6f5f02fc6..bd20ca84d0 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/MapJoinOperator.java\n\n@@ -350,10 +350,10 @@ public void generateMapMetaData() throws HiveException {\n \n     try {\n       TableDesc keyTableDesc = conf.getKeyTblDesc();\n-      AbstractSerDe keySerializer = (AbstractSerDe) ReflectionUtil.newInstance(\n+      AbstractSerDe keySerDe = (AbstractSerDe) ReflectionUtil.newInstance(\n           keyTableDesc.getSerDeClass(), null);\n-      keySerializer.initialize(null, keyTableDesc.getProperties(), null);\n-      MapJoinObjectSerDeContext keyContext = new MapJoinObjectSerDeContext(keySerializer, false);\n+      keySerDe.initialize(null, keyTableDesc.getProperties(), null);\n+      MapJoinObjectSerDeContext keyContext = new MapJoinObjectSerDeContext(keySerDe, false);\n       for (int pos = 0; pos < order.length; pos++) {\n         if (pos == posBigTable) {\n           continue;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzQ2Mg==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033462", "bodyText": "Nit: please call this keySerDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:42:32Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java", "diffHunk": "@@ -179,18 +178,18 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     }\n     try {\n       TableDesc keyTableDesc = conf.getKeyTblDesc();\n-      AbstractSerDe keySerde = (AbstractSerDe) ReflectionUtils.newInstance(keyTableDesc.getDeserializerClass(),\n+      AbstractSerDe keySerde = (AbstractSerDe) ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(),", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3NjY3OA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543376678", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:13:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzQ2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java\nindex 549b3e7ecb..ce7279c78a 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableSinkOperator.java\n\n@@ -178,10 +178,10 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     }\n     try {\n       TableDesc keyTableDesc = conf.getKeyTblDesc();\n-      AbstractSerDe keySerde = (AbstractSerDe) ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(),\n+      AbstractSerDe keySerDe = (AbstractSerDe) ReflectionUtils.newInstance(keyTableDesc.getSerDeClass(),\n           null);\n-      keySerde.initialize(null, keyTableDesc.getProperties(), null);\n-      MapJoinObjectSerDeContext keyContext = new MapJoinObjectSerDeContext(keySerde, false);\n+      keySerDe.initialize(null, keyTableDesc.getProperties(), null);\n+      MapJoinObjectSerDeContext keyContext = new MapJoinObjectSerDeContext(keySerDe, false);\n       for (Byte pos : order) {\n         if (pos == posBigTableAlias) {\n           continue;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzUzNQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033535", "bodyText": "Nit: please call this serDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:42:49Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java", "diffHunk": "@@ -45,8 +44,8 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     super.initializeOp(hconf);\n     TableDesc tbl = this.getConf().getTbl();\n     try {\n-      Deserializer serde = tbl.getDeserializerClass().newInstance();\n-      SerDeUtils.initializeSerDe(serde, hconf, tbl.getProperties(), null);\n+      AbstractSerDe serde = tbl.getSerDeClass().newInstance();", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3ODEyOA==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543378128", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzUzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java\nindex c0527b2253..363004eea4 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/HashTableDummyOperator.java\n\n@@ -44,9 +44,9 @@ protected void initializeOp(Configuration hconf) throws HiveException {\n     super.initializeOp(hconf);\n     TableDesc tbl = this.getConf().getTbl();\n     try {\n-      AbstractSerDe serde = tbl.getSerDeClass().newInstance();\n-      serde.initialize(hconf, tbl.getProperties(), null);\n-      this.outputObjInspector = serde.getObjectInspector();\n+      AbstractSerDe serDe = tbl.getSerDeClass().newInstance();\n+      serDe.initialize(hconf, tbl.getProperties(), null);\n+      this.outputObjInspector = serDe.getObjectInspector();\n     } catch (Exception e) {\n       LOG.error(\"Generating output obj inspector from dummy object error\", e);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzgxMw==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542033813", "bodyText": "Nit: please call this serDe for consistency.", "author": "miklosgergely", "createdAt": "2020-12-13T23:44:25Z", "path": "hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/InternalUtil.java", "diffHunk": "@@ -143,18 +142,16 @@ private static ObjectInspector getObjectInspector(TypeInfo type) throws IOExcept\n   //TODO this has to find a better home, it's also hardcoded as default in hive would be nice\n   // if the default was decided by the serde\n   static void initializeOutputSerDe(AbstractSerDe serDe, Configuration conf, OutputJobInfo jobInfo)\n-    throws SerDeException {\n-    SerDeUtils.initializeSerDe(serDe, conf,\n-                               getSerdeProperties(jobInfo.getTableInfo(),\n-                                                  jobInfo.getOutputSchema()),\n-                               null);\n+      throws SerDeException {\n+    serDe.initialize(conf, getSerdeProperties(jobInfo.getTableInfo(), jobInfo.getOutputSchema()), null);\n   }\n \n   static void initializeDeserializer(Deserializer deserializer, Configuration conf,\n                      HCatTableInfo info, HCatSchema schema) throws SerDeException {\n     Properties props = getSerdeProperties(info, schema);\n     LOG.info(\"Initializing \" + deserializer.getClass().getName() + \" with properties \" + props);\n-    SerDeUtils.initializeSerDe(deserializer, conf, props, null);\n+    AbstractSerDe serde = (AbstractSerDe)deserializer;", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3NzQ0OQ==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543377449", "bodyText": "Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:14:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzMzgxMw=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/InternalUtil.java b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/InternalUtil.java\nindex 9467b5dfa8..2d7016e3ca 100644\n--- a/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/InternalUtil.java\n+++ b/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/InternalUtil.java\n\n@@ -150,8 +150,8 @@ static void initializeDeserializer(Deserializer deserializer, Configuration conf\n                      HCatTableInfo info, HCatSchema schema) throws SerDeException {\n     Properties props = getSerdeProperties(info, schema);\n     LOG.info(\"Initializing \" + deserializer.getClass().getName() + \" with properties \" + props);\n-    AbstractSerDe serde = (AbstractSerDe)deserializer;\n-    serde.initialize(conf, props, null);\n+    AbstractSerDe serDe = (AbstractSerDe) deserializer;\n+    serDe.initialize(conf, props, null);\n   }\n \n   private static Properties getSerdeProperties(HCatTableInfo info, HCatSchema s)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzNjI4Mg==", "url": "https://github.com/apache/hive/pull/1634#discussion_r542036282", "bodyText": "Modify comment to \"(de)serializing\"", "author": "miklosgergely", "createdAt": "2020-12-13T23:58:30Z", "path": "serde/src/java/org/apache/hadoop/hive/serde2/SerDe.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.serde2;\n+\n+/**\n+ * A Hive Serializer/Deserializer.\n+ */\n+public interface SerDe {\n+\n+  /**\n+   * Returns statistics collected when serializing", "originalCommit": "b3d1d6b73c535f089cad3bd4878a68242550aede", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzM3OTU0Ng==", "url": "https://github.com/apache/hive/pull/1634#discussion_r543379546", "bodyText": "Thanks. Done.", "author": "belugabehr", "createdAt": "2020-12-15T14:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjAzNjI4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "chunk": "diff --git a/serde/src/java/org/apache/hadoop/hive/serde2/SerDe.java b/serde/src/java/org/apache/hadoop/hive/serde2/SerDe.java\nindex 4c201eb243..3b710a9196 100644\n--- a/serde/src/java/org/apache/hadoop/hive/serde2/SerDe.java\n+++ b/serde/src/java/org/apache/hadoop/hive/serde2/SerDe.java\n\n@@ -24,7 +24,7 @@\n public interface SerDe {\n \n   /**\n-   * Returns statistics collected when serializing\n+   * Returns statistics collected when (de)serializing.\n    *\n    * @return {@link SerDeStats} object; or in case not supported: null\n    */\n"}}, {"oid": "4fb20950d08e5e7d987f5f14224dad05b6e1c269", "url": "https://github.com/apache/hive/commit/4fb20950d08e5e7d987f5f14224dad05b6e1c269", "message": "HIVE-24332: Make AbstractSerDe Superclass of all Classes", "committedDate": "2020-12-15T14:09:15Z", "type": "commit"}, {"oid": "727b55b7c60e31d4344bcc1444f0cc5dd31d6d82", "url": "https://github.com/apache/hive/commit/727b55b7c60e31d4344bcc1444f0cc5dd31d6d82", "message": "Fix compile errors", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "c33e304954bc8bd0ce615aa5358b29e49f51eecd", "url": "https://github.com/apache/hive/commit/c33e304954bc8bd0ce615aa5358b29e49f51eecd", "message": "Use correct configuration", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "09590a8b381a54f7a856a865cb34874a8eb4431a", "url": "https://github.com/apache/hive/commit/09590a8b381a54f7a856a865cb34874a8eb4431a", "message": "expose getter for configuration", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "810813ac84bec00abba53050a1397de8e140f133", "url": "https://github.com/apache/hive/commit/810813ac84bec00abba53050a1397de8e140f133", "message": "Two more fixes", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "b105873989bbac95a3aa33e1d67f6f9014cf8364", "url": "https://github.com/apache/hive/commit/b105873989bbac95a3aa33e1d67f6f9014cf8364", "message": "next batch of fixes", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "71c3005f0021e051127818a65bd182291e93c588", "url": "https://github.com/apache/hive/commit/71c3005f0021e051127818a65bd182291e93c588", "message": "Use partition configurations", "committedDate": "2020-12-15T14:09:16Z", "type": "commit"}, {"oid": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "url": "https://github.com/apache/hive/commit/4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "message": "Updated based on review feedback", "committedDate": "2020-12-15T14:33:16Z", "type": "commit"}, {"oid": "4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "url": "https://github.com/apache/hive/commit/4f1f6a9a2d953c41b1be5f7442c33388dfd09b86", "message": "Updated based on review feedback", "committedDate": "2020-12-15T14:33:16Z", "type": "forcePushed"}]}