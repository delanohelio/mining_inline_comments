{"pr_number": 1693, "pr_title": "HIVE-24410: Query-based compaction hangs because of doAs", "pr_createdAt": "2020-11-23T10:23:22Z", "pr_url": "https://github.com/apache/hive/pull/1693", "timeline": [{"oid": "24777574e6b307d29748b6d1b5e03b27cdc88c46", "url": "https://github.com/apache/hive/commit/24777574e6b307d29748b6d1b5e03b27cdc88c46", "message": "HIVE-24410: Query-based compaction hangs because of doAs", "committedDate": "2020-11-23T10:20:56Z", "type": "commit"}, {"oid": "b8e44a2ac6e4d2e563e50baf75685011febeb6d3", "url": "https://github.com/apache/hive/commit/b8e44a2ac6e4d2e563e50baf75685011febeb6d3", "message": "Fix mistake", "committedDate": "2020-11-23T10:41:02Z", "type": "commit"}, {"oid": "133618a458446c510047e584fd047823e620da35", "url": "https://github.com/apache/hive/commit/133618a458446c510047e584fd047823e620da35", "message": "Fix signature in test", "committedDate": "2020-11-23T12:51:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc3NjA5NQ==", "url": "https://github.com/apache/hive/pull/1693#discussion_r528776095", "bodyText": "This is so much cleaner, +100 for this :)", "author": "pvargacl", "createdAt": "2020-11-23T15:14:52Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java", "diffHunk": "@@ -219,23 +219,6 @@ void run(HiveConf conf, String jobName, Table t, Partition p, StorageDescriptor\n            CompactionInfo ci, Worker.StatsUpdater su, IMetaStoreClient msc, Directory dir)\n       throws IOException, HiveException {\n \n-    if(conf.getBoolVar(HiveConf.ConfVars.HIVE_IN_TEST) && conf.getBoolVar(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION)) {\n-      throw new RuntimeException(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION.name() + \"=true\");\n-    }\n-\n-    /*\n-     Try to run compaction via HiveQL queries.\n-     Compaction for MM tables happens here, or run compaction for Crud tables if query-based compaction is enabled.\n-     todo Find a more generic approach to collecting files in the same logical bucket to compact within the same task\n-     (currently we're using Tez split grouping).\n-     */\n-    QueryCompactor queryCompactor = QueryCompactorFactory.getQueryCompactor(t, conf, ci);", "originalCommit": "133618a458446c510047e584fd047823e620da35", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "20515a959e8d444190869e2c8ed4f143e793ba4c", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java\nindex 81db0da945..a5ea747902 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorMR.java\n\n@@ -216,8 +216,7 @@ private void overrideMRProps(JobConf job, Map<String, String> properties) {\n    * @throws java.io.IOException if the job fails\n    */\n   void run(HiveConf conf, String jobName, Table t, Partition p, StorageDescriptor sd, ValidWriteIdList writeIds,\n-           CompactionInfo ci, Worker.StatsUpdater su, IMetaStoreClient msc, Directory dir)\n-      throws IOException, HiveException {\n+           CompactionInfo ci, Worker.StatsUpdater su, IMetaStoreClient msc, Directory dir) throws IOException {\n \n     JobConf job = createBaseJobConf(conf, jobName, t, sd, writeIds, ci);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc3NzM0Nw==", "url": "https://github.com/apache/hive/pull/1693#discussion_r528777347", "bodyText": "You can use lambda like this:\nugi.doAs((PrivilegedExceptionAction) () -> {\nmr.run(conf, jobName.toString(), t, fp, sd, tblValidWriteIds, fci, su, msc, dir);\nreturn null;\n});", "author": "pvargacl", "createdAt": "2020-11-23T15:16:30Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java", "diffHunk": "@@ -590,6 +587,39 @@ public Object run() throws Exception {\n     return true;\n   }\n \n+  private void failCompactionIfSetForTest() {\n+    if(conf.getBoolVar(HiveConf.ConfVars.HIVE_IN_TEST) && conf.getBoolVar(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION)) {\n+      throw new RuntimeException(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION.name() + \"=true\");\n+    }\n+  }\n+\n+  private void runCompactionViaMrJob(CompactionInfo ci, Table t, Partition p, StorageDescriptor sd,\n+      ValidCompactorWriteIdList tblValidWriteIds, StringBuilder jobName, AcidUtils.Directory dir, StatsUpdater su)\n+      throws IOException, HiveException, InterruptedException {\n+    final CompactorMR mr = new CompactorMR();\n+    if (runJobAsSelf(ci.runAs)) {\n+      mr.run(conf, jobName.toString(), t, p, sd, tblValidWriteIds, ci, su, msc, dir);\n+    } else {\n+      UserGroupInformation ugi = UserGroupInformation.createProxyUser(ci.runAs,\n+          UserGroupInformation.getLoginUser());\n+      final Partition fp = p;\n+      final CompactionInfo fci = ci;\n+      ugi.doAs(new PrivilegedExceptionAction<Object>() {", "originalCommit": "133618a458446c510047e584fd047823e620da35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgyOTY3Mg==", "url": "https://github.com/apache/hive/pull/1693#discussion_r528829672", "bodyText": "Noted, will do! Thanks for taking a look at this!", "author": "klcopp", "createdAt": "2020-11-23T16:21:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc3NzM0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b563c3d6a41c215460e270b744f41d6c616373d9", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\nindex b70c4278ec..8061c8544b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\n\n@@ -604,12 +604,9 @@ private void runCompactionViaMrJob(CompactionInfo ci, Table t, Partition p, Stor\n           UserGroupInformation.getLoginUser());\n       final Partition fp = p;\n       final CompactionInfo fci = ci;\n-      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n-        @Override\n-        public Object run() throws Exception {\n-          mr.run(conf, jobName.toString(), t, fp, sd, tblValidWriteIds, fci, su, msc, dir);\n-          return null;\n-        }\n+      ugi.doAs((PrivilegedExceptionAction<Object>) () -> {\n+        mr.run(conf, jobName.toString(), t, fp, sd, tblValidWriteIds, fci, su, msc, dir);\n+        return null;\n       });\n       try {\n         FileSystem.closeAllForUGI(ugi);\n"}}, {"oid": "b563c3d6a41c215460e270b744f41d6c616373d9", "url": "https://github.com/apache/hive/commit/b563c3d6a41c215460e270b744f41d6c616373d9", "message": "Addressed PVargacl's review comments", "committedDate": "2020-11-23T16:21:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI3MjE1NA==", "url": "https://github.com/apache/hive/pull/1693#discussion_r529272154", "bodyText": "last nit: you don't need these final copies anymore, since they are coming as parameters ad effectively finals.", "author": "pvargacl", "createdAt": "2020-11-24T08:02:43Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java", "diffHunk": "@@ -590,6 +587,36 @@ public Object run() throws Exception {\n     return true;\n   }\n \n+  private void failCompactionIfSetForTest() {\n+    if(conf.getBoolVar(HiveConf.ConfVars.HIVE_IN_TEST) && conf.getBoolVar(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION)) {\n+      throw new RuntimeException(HiveConf.ConfVars.HIVETESTMODEFAILCOMPACTION.name() + \"=true\");\n+    }\n+  }\n+\n+  private void runCompactionViaMrJob(CompactionInfo ci, Table t, Partition p, StorageDescriptor sd,\n+      ValidCompactorWriteIdList tblValidWriteIds, StringBuilder jobName, AcidUtils.Directory dir, StatsUpdater su)\n+      throws IOException, HiveException, InterruptedException {\n+    final CompactorMR mr = new CompactorMR();\n+    if (runJobAsSelf(ci.runAs)) {\n+      mr.run(conf, jobName.toString(), t, p, sd, tblValidWriteIds, ci, su, msc, dir);\n+    } else {\n+      UserGroupInformation ugi = UserGroupInformation.createProxyUser(ci.runAs,\n+          UserGroupInformation.getLoginUser());\n+      final Partition fp = p;", "originalCommit": "b563c3d6a41c215460e270b744f41d6c616373d9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDMzMjEyNQ==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530332125", "bodyText": "Done!", "author": "klcopp", "createdAt": "2020-11-25T12:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI3MjE1NA=="}], "type": "inlineReview", "revised_code": {"commit": "20515a959e8d444190869e2c8ed4f143e793ba4c", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\nindex 8061c8544b..42b258dc47 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java\n\n@@ -600,19 +600,16 @@ private void runCompactionViaMrJob(CompactionInfo ci, Table t, Partition p, Stor\n     if (runJobAsSelf(ci.runAs)) {\n       mr.run(conf, jobName.toString(), t, p, sd, tblValidWriteIds, ci, su, msc, dir);\n     } else {\n-      UserGroupInformation ugi = UserGroupInformation.createProxyUser(ci.runAs,\n-          UserGroupInformation.getLoginUser());\n-      final Partition fp = p;\n-      final CompactionInfo fci = ci;\n+      UserGroupInformation ugi = UserGroupInformation.createProxyUser(ci.runAs, UserGroupInformation.getLoginUser());\n       ugi.doAs((PrivilegedExceptionAction<Object>) () -> {\n-        mr.run(conf, jobName.toString(), t, fp, sd, tblValidWriteIds, fci, su, msc, dir);\n+        mr.run(conf, jobName.toString(), t, p, sd, tblValidWriteIds, ci, su, msc, dir);\n         return null;\n       });\n       try {\n         FileSystem.closeAllForUGI(ugi);\n       } catch (IOException exception) {\n-        LOG.error(\"Could not clean up file-system handles for UGI: \" + ugi + \" for \" +\n-                      ci.getFullPartitionName(), exception);\n+        LOG.error(\"Could not clean up file-system handles for UGI: \" + ugi + \" for \" + ci.getFullPartitionName(),\n+            exception);\n       }\n     }\n   }\n"}}, {"oid": "20515a959e8d444190869e2c8ed4f143e793ba4c", "url": "https://github.com/apache/hive/commit/20515a959e8d444190869e2c8ed4f143e793ba4c", "message": "Addressed review comments + formatting + fix tests", "committedDate": "2020-11-25T10:45:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3MjY0Ng==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530372646", "bodyText": "Is this test code?\nCould we find another way to test this?", "author": "pvary", "createdAt": "2020-11-25T13:27:08Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Worker.java", "diffHunk": "@@ -531,29 +531,26 @@ protected Boolean findNextCompactionAndExecute(boolean computeStats) throws Inte\n       final StatsUpdater su = computeStats ? StatsUpdater.init(ci, msc.findColumnsWithStats(\n           CompactionInfo.compactionInfoToStruct(ci)), conf,\n           runJobAsSelf(ci.runAs) ? ci.runAs : t.getOwner()) : null;\n-      final CompactorMR mr = new CompactorMR();\n+\n       try {\n-        if (runJobAsSelf(ci.runAs)) {\n-          mr.run(conf, jobName.toString(), t, p, sd, tblValidWriteIds, ci, su, msc, dir);\n+        failCompactionIfSetForTest();", "originalCommit": "20515a959e8d444190869e2c8ed4f143e793ba4c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3NTgyMw==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530375823", "bodyText": "Yes, it's test code and it used to be in CompactorMr#run, I just refactored it here.\nGreat question, shall I raise a jira for it?", "author": "klcopp", "createdAt": "2020-11-25T13:32:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3MjY0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQyMTU2Mg==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530421562", "bodyText": "Yes, please raise a jira!", "author": "pvary", "createdAt": "2020-11-25T14:38:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3MjY0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzMjU1Mg==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530432552", "bodyText": "Done: HIVE-24429", "author": "klcopp", "createdAt": "2020-11-25T14:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3MjY0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ1MDU3Mw==", "url": "https://github.com/apache/hive/pull/1693#discussion_r530450573", "bodyText": "Thanks @klcopp!", "author": "pvary", "createdAt": "2020-11-25T15:18:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM3MjY0Ng=="}], "type": "inlineReview", "revised_code": null}]}