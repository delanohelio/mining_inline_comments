{"pr_number": 1105, "pr_title": "HIVE-22957: Support Partition Filtering In MSCK REPAIR TABLE Command", "pr_createdAt": "2020-06-13T08:15:48Z", "pr_url": "https://github.com/apache/hive/pull/1105", "timeline": [{"oid": "d1f77c2b05d02b701ab1f83a8633ac7c9e607fc3", "url": "https://github.com/apache/hive/commit/d1f77c2b05d02b701ab1f83a8633ac7c9e607fc3", "message": "HIVE-22957: Add Option For Predicate Filtering In MSCK REPAIR TABLE Command", "committedDate": "2020-06-26T16:08:00Z", "type": "commit"}, {"oid": "747394343581b731385c88d6b3d745bfa7cd9266", "url": "https://github.com/apache/hive/commit/747394343581b731385c88d6b3d745bfa7cd9266", "message": "Refactoring Code", "committedDate": "2020-06-26T16:08:00Z", "type": "commit"}, {"oid": "3045ffa09dd928a76af8798f06ccf74f68c41bad", "url": "https://github.com/apache/hive/commit/3045ffa09dd928a76af8798f06ccf74f68c41bad", "message": "Msck Test Fix", "committedDate": "2020-06-26T16:08:00Z", "type": "commit"}, {"oid": "3045ffa09dd928a76af8798f06ccf74f68c41bad", "url": "https://github.com/apache/hive/commit/3045ffa09dd928a76af8798f06ccf74f68c41bad", "message": "Msck Test Fix", "committedDate": "2020-06-26T16:08:00Z", "type": "forcePushed"}, {"oid": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "url": "https://github.com/apache/hive/commit/c91b3d442872bbf57b33fdd1f38f1487407c1852", "message": "Rebase  master", "committedDate": "2020-06-26T16:27:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451503630", "bodyText": "I don't think this will work - this is the ql module ; while EXPRESSION_PROXY_CLASS is a metastore conf key; in a remote metastore setup this set will probably have no effect...\nhave you tried it?\nI think making a check and returning with an error that this feature is not available due to required conf change is fine", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:24:04Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMjk2Mw==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452132963", "bodyText": "Yes, It won't work with remote metastore. Currently only planning for embedded metastore, Sure, we should bail out if conditions are not met. Currently i have added the bail out code in HiveMetaStoreChecker. But i feel bail out should have been much more earlier. I Couldn't think of a better spot. Any thoughts on this?", "author": "shameersss1", "createdAt": "2020-07-09T10:53:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNzM0OA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452137348", "bodyText": "I think it would be great to throw an exception here; I think you should throw the type SemanticException\nThrowing exceptions from in the Analyzer classes works nicely! :)", "author": "kgyrtkirk", "createdAt": "2020-07-09T11:02:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIwMjU1Nw==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452202557", "bodyText": "Done!", "author": "shameersss1", "createdAt": "2020-07-09T13:06:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwMzYzMA=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\nindex 86640cd6b8..1ba4798554 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n\n@@ -67,7 +68,7 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = ParseUtils.getFullPartitionSpecs(root, table, conf, false);\n     byte[] filterExp = null;\n     if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n       // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwODUyOA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451508528", "bodyText": "why this needs to be flattened into a byte[] ?", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:32:45Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -63,13 +67,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    List<Map<String, String>> specs = getPartitionSpecs(table, root);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    byte[] filterExp = null;\n+    if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n+      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n+      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n+          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // fetch the first value of partitionSpecs map since it will always have one key, value pair\n+      filterExp = SerializationUtilities.serializeExpressionToKryo(", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzYyNw==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133627", "bodyText": "PartitionPruner and msc.listPartitionsByExpr() expects serialized byte array, Hence it is required to flatten out.", "author": "shameersss1", "createdAt": "2020-07-09T10:55:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwODUyOA=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\nindex 86640cd6b8..1ba4798554 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n\n@@ -67,7 +68,7 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     }\n \n     Table table = getTable(tableName);\n-    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = getFullPartitionSpecs(root, table, conf, false);\n+    Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = ParseUtils.getFullPartitionSpecs(root, table, conf, false);\n     byte[] filterExp = null;\n     if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n       // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTAyMw==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451511023", "bodyText": "can we find a new home for these 2 static methods? :)\nql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:37:03Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java", "diffHunk": "@@ -837,6 +844,118 @@ public static void checkColumnName(String columnName) throws SemanticException {\n     return colList;\n   }\n \n+  /**\n+   * Get the partition specs from the tree. This stores the full specification\n+   * with the comparator operator into the output list.\n+   *\n+   * @return Map of partitions by prefix length. Most of the time prefix length will\n+   *         be the same for all partition specs, so we can just OR the expressions.\n+   */\n+  public static Map<Integer, List<ExprNodeGenericFuncDesc>> getFullPartitionSpecs(", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzY4Mg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133682", "bodyText": "Fixed!", "author": "shameersss1", "createdAt": "2020-07-09T10:55:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTAyMw=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\nindex 63c09b1710..7971545b5b 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n\n@@ -844,118 +837,6 @@ public static void checkColumnName(String columnName) throws SemanticException {\n     return colList;\n   }\n \n-  /**\n-   * Get the partition specs from the tree. This stores the full specification\n-   * with the comparator operator into the output list.\n-   *\n-   * @return Map of partitions by prefix length. Most of the time prefix length will\n-   *         be the same for all partition specs, so we can just OR the expressions.\n-   */\n-  public static Map<Integer, List<ExprNodeGenericFuncDesc>> getFullPartitionSpecs(\n-      CommonTree ast, Table table, Configuration conf, boolean canGroupExprs) throws SemanticException {\n-    String defaultPartitionName = HiveConf.getVar(conf, HiveConf.ConfVars.DEFAULTPARTITIONNAME);\n-    Map<String, String> colTypes = new HashMap<>();\n-    for (FieldSchema fs : table.getPartitionKeys()) {\n-      colTypes.put(fs.getName().toLowerCase(), fs.getType());\n-    }\n-\n-    Map<Integer, List<ExprNodeGenericFuncDesc>> result = new HashMap<>();\n-    for (int childIndex = 0; childIndex < ast.getChildCount(); childIndex++) {\n-      Tree partSpecTree = ast.getChild(childIndex);\n-      if (partSpecTree.getType() != HiveParser.TOK_PARTSPEC) {\n-        continue;\n-      }\n-\n-      ExprNodeGenericFuncDesc expr = null;\n-      Set<String> names = new HashSet<>(partSpecTree.getChildCount());\n-      for (int i = 0; i < partSpecTree.getChildCount(); ++i) {\n-        CommonTree partSpecSingleKey = (CommonTree) partSpecTree.getChild(i);\n-        assert (partSpecSingleKey.getType() == HiveParser.TOK_PARTVAL);\n-        String key = stripIdentifierQuotes(partSpecSingleKey.getChild(0).getText()).toLowerCase();\n-        String operator = partSpecSingleKey.getChild(1).getText();\n-        ASTNode partValNode = (ASTNode)partSpecSingleKey.getChild(2);\n-        TypeCheckCtx typeCheckCtx = new TypeCheckCtx(null);\n-        ExprNodeConstantDesc valExpr =\n-            (ExprNodeConstantDesc) ExprNodeTypeCheck.genExprNode(partValNode, typeCheckCtx).get(partValNode);\n-        Object val = valExpr.getValue();\n-\n-        boolean isDefaultPartitionName = val.equals(defaultPartitionName);\n-\n-        String type = colTypes.get(key);\n-        if (type == null) {\n-          throw new SemanticException(\"Column \" + key + \" is not a partition key\");\n-        }\n-        PrimitiveTypeInfo pti = TypeInfoFactory.getPrimitiveTypeInfo(type);\n-        // Create the corresponding hive expression to filter on partition columns.\n-        if (!isDefaultPartitionName) {\n-          if (!valExpr.getTypeString().equals(type)) {\n-            ObjectInspectorConverters.Converter converter = ObjectInspectorConverters.getConverter(\n-                TypeInfoUtils.getStandardJavaObjectInspectorFromTypeInfo(valExpr.getTypeInfo()),\n-                TypeInfoUtils.getStandardJavaObjectInspectorFromTypeInfo(pti));\n-            val = converter.convert(valExpr.getValue());\n-          }\n-        }\n-\n-        ExprNodeColumnDesc column = new ExprNodeColumnDesc(pti, key, null, true);\n-        ExprNodeGenericFuncDesc op;\n-        if (!isDefaultPartitionName) {\n-          op = PartitionUtils.makeBinaryPredicate(operator, column, new ExprNodeConstantDesc(pti, val));\n-        } else {\n-          GenericUDF originalOp = FunctionRegistry.getFunctionInfo(operator).getGenericUDF();\n-          String fnName;\n-          if (FunctionRegistry.isEq(originalOp)) {\n-            fnName = \"isnull\";\n-          } else if (FunctionRegistry.isNeq(originalOp)) {\n-            fnName = \"isnotnull\";\n-          } else {\n-            throw new SemanticException(\n-                \"Cannot use \" + operator + \" in a default partition spec; only '=' and '!=' are allowed.\");\n-          }\n-          op = PartitionUtils.makeUnaryPredicate(fnName, column);\n-        }\n-        // If it's multi-expr filter (e.g. a='5', b='2012-01-02'), AND with previous exprs.\n-        expr = (expr == null) ? op : PartitionUtils.makeBinaryPredicate(\"and\", expr, op);\n-        names.add(key);\n-      }\n-\n-      if (expr == null) {\n-        continue;\n-      }\n-\n-      // We got the expr for one full partition spec. Determine the prefix length.\n-      int prefixLength = calculatePartPrefix(table, names);\n-      List<ExprNodeGenericFuncDesc> orExpr = result.get(prefixLength);\n-      // We have to tell apart partitions resulting from spec with different prefix lengths.\n-      // So, if we already have smth for the same prefix length, we can OR the two.\n-      // If we don't, create a new separate filter. In most cases there will only be one.\n-      if (orExpr == null) {\n-        result.put(prefixLength, Lists.newArrayList(expr));\n-      } else if (canGroupExprs) {\n-        orExpr.set(0, PartitionUtils.makeBinaryPredicate(\"or\", expr, orExpr.get(0)));\n-      } else {\n-        orExpr.add(expr);\n-      }\n-    }\n-    return result;\n-  }\n-\n-  /**\n-   * Calculates the partition prefix length based on the drop spec.\n-   * This is used to avoid deleting archived partitions with lower level.\n-   * For example, if, for A and B key cols, drop spec is A=5, B=6, we shouldn't drop\n-   * archived A=5/, because it can contain B-s other than 6.\n-   */\n-  private static int calculatePartPrefix(Table tbl, Set<String> partSpecKeys) {\n-    int partPrefixToDrop = 0;\n-    for (FieldSchema fs : tbl.getPartCols()) {\n-      if (!partSpecKeys.contains(fs.getName())) {\n-        break;\n-      }\n-      ++partPrefixToDrop;\n-    }\n-    return partPrefixToDrop;\n-  }\n-\n   public static List<String> getColumnNames(ASTNode ast) {\n     List<String> colList = new ArrayList<String>();\n     int numCh = ast.getChildCount();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTQ1MA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451511450", "bodyText": "is there a successor of this test?", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:37:52Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveMetaStoreChecker.java", "diffHunk": "@@ -330,17 +330,6 @@ public void testPartitionsCheck() throws HiveException,\n     assertEquals(partToRemove.getTable().getTableName(),\n         result.getPartitionsNotOnFs().iterator().next().getTableName());\n     assertEquals(Collections.<CheckResult.PartitionResult>emptySet(), result.getPartitionsNotInMs());\n-\n-    List<Map<String, String>> partsCopy = new ArrayList<Map<String, String>>();\n-    partsCopy.add(partitions.get(1).getSpec());", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzMzkyNg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452133926", "bodyText": "I think the qtests handles most of cases", "author": "shameersss1", "createdAt": "2020-07-09T10:55:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMTQ1MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451513654", "bodyText": "I wonder if there is a way to retain filterExp in a more natural way....it will be kryo-encoded almost all the time...but seems like the metastore interface method was designed to accept kryo stuff...", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:41:29Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -240,40 +243,27 @@ void checkTable(String catName, String dbName, String tableName,\n     }\n \n     PartitionIterable parts;\n-    boolean findUnknownPartitions = true;\n \n     if (isPartitioned(table)) {\n-      if (partitions == null || partitions.isEmpty()) {\n+      if (filterExp != null) {\n+        List<Partition> results = new ArrayList<>();\n+        getPartitionListByFilterExp(getMsc(), table, filterExp,", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNjIyMg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452136222", "bodyText": "I though this initially but it becomes difficult to serialize filter exp once we move out of ql code, Hence did the kyro stuff in the initial stage", "author": "shameersss1", "createdAt": "2020-07-09T11:00:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjE0MTE2Mg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452141162", "bodyText": "yeah I understand...sometimes we have to cook from what we have :D", "author": "kgyrtkirk", "createdAt": "2020-07-09T11:10:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxMzY1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNzUyNQ==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451517525", "bodyText": "this method accepts byte[] and if I'm not wrong this is like this since around 2013", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:48:00Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreServerUtils.java", "diffHunk": "@@ -1348,6 +1348,17 @@ public static Path getPath(Table table) {\n     }\n   }\n \n+  public static void getPartitionListByFilterExp(IMetaStoreClient msc, Table table, byte[] filterExp,\n+                                                 String defaultPartName, List<Partition> results)\n+      throws MetastoreException {\n+    try {\n+      msc.listPartitionsByExpr(table.getCatName(), table.getDbName(), table.getTableName(), filterExp,", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNTI0NA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452135244", "bodyText": "Yes, I think we also pass byte array", "author": "shameersss1", "createdAt": "2020-07-09T10:58:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNzUyNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxODgwNg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451518806", "bodyText": "move this variable inside the if", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:50:10Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDA0Mg==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134042", "bodyText": "Fixed", "author": "shameersss1", "createdAt": "2020-07-09T10:56:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxODgwNg=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\nindex 2a6ed8277f..208f303bfe 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n\n@@ -375,17 +375,26 @@ void findUnknownPartitions(Table table, Set<Path> partPaths, byte[] filterExp,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n-    Set<Path> partDirs = new HashSet<Path>();\n     List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n \n     if (filterExp != null) {\n       PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      if (expressionProxy instanceof MsckPartitionExpressionProxy) {\n+        throw new MetastoreException(\"Unsupported expressionProxy type. \" +\n+            \"This happens when remote metastore setup is used. Try with embedded metastore\");\n+      }\n       List<String> paritions = new ArrayList<>();\n+      Set<Path> partDirs = new HashSet<Path>();\n+      String tablePathStr = tablePath.toString();\n       for (Path path : allPartDirs) {\n         // remove the table's path from the partition path\n         // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n-        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+        if (tablePathStr.endsWith(\"/\")) {\n+          paritions.add(path.toString().substring(tablePathStr.length()));\n+        } else {\n+          paritions.add(path.toString().substring(tablePathStr.length() + 1));\n+        }\n       }\n       // Remove all partition paths which does not matches the filter expression.\n       expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyMjMzMA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451522330", "bodyText": "instead of concatenating with / use new Path(parentPath,child) - it's more portable", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:55:40Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+      }\n+      // Remove all partition paths which does not matches the filter expression.\n+      expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n+          conf.get(MetastoreConf.ConfVars.DEFAULTPARTITIONNAME.getVarname()), paritions);\n+\n+      // now the partition list will contain all the paths that matches the filter expression.\n+      // add them back to partDirs.\n+      for (String path : paritions) {\n+        partDirs.add(new Path(tablePath.toString() + \"/\" + path));", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDA5MA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134090", "bodyText": "Fixed!", "author": "shameersss1", "createdAt": "2020-07-09T10:56:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyMjMzMA=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\nindex 2a6ed8277f..208f303bfe 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n\n@@ -375,17 +375,26 @@ void findUnknownPartitions(Table table, Set<Path> partPaths, byte[] filterExp,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n-    Set<Path> partDirs = new HashSet<Path>();\n     List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n \n     if (filterExp != null) {\n       PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      if (expressionProxy instanceof MsckPartitionExpressionProxy) {\n+        throw new MetastoreException(\"Unsupported expressionProxy type. \" +\n+            \"This happens when remote metastore setup is used. Try with embedded metastore\");\n+      }\n       List<String> paritions = new ArrayList<>();\n+      Set<Path> partDirs = new HashSet<Path>();\n+      String tablePathStr = tablePath.toString();\n       for (Path path : allPartDirs) {\n         // remove the table's path from the partition path\n         // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n-        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+        if (tablePathStr.endsWith(\"/\")) {\n+          paritions.add(path.toString().substring(tablePathStr.length()));\n+        } else {\n+          paritions.add(path.toString().substring(tablePathStr.length() + 1));\n+        }\n       }\n       // Remove all partition paths which does not matches the filter expression.\n       expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyNDE2Ng==", "url": "https://github.com/apache/hive/pull/1105#discussion_r451524166", "bodyText": "I'm wondering if tablePath could end with a '/' or not; if it does, and checkPartitionDirs are removing double slashes this could eat up 1 extra char...", "author": "kgyrtkirk", "createdAt": "2020-07-08T12:58:36Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java", "diffHunk": "@@ -383,7 +375,29 @@ void findUnknownPartitions(Table table, Set<Path> partPaths,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n+    Set<Path> partDirs = new HashSet<Path>();\n+    List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n+\n+    if (filterExp != null) {\n+      PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      List<String> paritions = new ArrayList<>();\n+      for (Path path : allPartDirs) {\n+        // remove the table's path from the partition path\n+        // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n+        paritions.add(path.toString().substring(tablePath.toString().length() + 1));", "originalCommit": "c91b3d442872bbf57b33fdd1f38f1487407c1852", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEzNDMyNQ==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452134325", "bodyText": "Fixed!", "author": "shameersss1", "createdAt": "2020-07-09T10:56:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUyNDE2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "chunk": "diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\nindex 2a6ed8277f..208f303bfe 100644\n--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreChecker.java\n\n@@ -375,17 +375,26 @@ void findUnknownPartitions(Table table, Set<Path> partPaths, byte[] filterExp,\n     // now check the table folder and see if we find anything\n     // that isn't in the metastore\n     Set<Path> allPartDirs = new HashSet<Path>();\n-    Set<Path> partDirs = new HashSet<Path>();\n     List<FieldSchema> partColumns = table.getPartitionKeys();\n     checkPartitionDirs(tablePath, allPartDirs, Collections.unmodifiableList(getPartColNames(table)));\n \n     if (filterExp != null) {\n       PartitionExpressionProxy expressionProxy = createExpressionProxy(conf);\n+      if (expressionProxy instanceof MsckPartitionExpressionProxy) {\n+        throw new MetastoreException(\"Unsupported expressionProxy type. \" +\n+            \"This happens when remote metastore setup is used. Try with embedded metastore\");\n+      }\n       List<String> paritions = new ArrayList<>();\n+      Set<Path> partDirs = new HashSet<Path>();\n+      String tablePathStr = tablePath.toString();\n       for (Path path : allPartDirs) {\n         // remove the table's path from the partition path\n         // eg: <tablePath>/p1=1/p2=2/p3=3 ---> p1=1/p2=2/p3=3\n-        paritions.add(path.toString().substring(tablePath.toString().length() + 1));\n+        if (tablePathStr.endsWith(\"/\")) {\n+          paritions.add(path.toString().substring(tablePathStr.length()));\n+        } else {\n+          paritions.add(path.toString().substring(tablePathStr.length() + 1));\n+        }\n       }\n       // Remove all partition paths which does not matches the filter expression.\n       expressionProxy.filterPartitionsByExpr(partColumns, filterExp,\n"}}, {"oid": "2afd27e6ee7ed0c11223c62ff1883f52f917957a", "url": "https://github.com/apache/hive/commit/2afd27e6ee7ed0c11223c62ff1883f52f917957a", "message": "Fix PR Comments", "committedDate": "2020-07-09T10:52:26Z", "type": "commit"}, {"oid": "412ced9a3941a64e7df23ef7096c5a6928393321", "url": "https://github.com/apache/hive/commit/412ced9a3941a64e7df23ef7096c5a6928393321", "message": "Throw exception on invalid config", "committedDate": "2020-07-09T13:06:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxNDEyMA==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452214120", "bodyText": "you could avoid the null/empty check by using: !PartitionExpressionForMetastore.class.getCanonicalName()).equals(expressionProxyClass)", "author": "kgyrtkirk", "createdAt": "2020-07-09T13:24:15Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java", "diffHunk": "@@ -71,10 +71,15 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     Map<Integer, List<ExprNodeGenericFuncDesc>> partitionSpecs = ParseUtils.getFullPartitionSpecs(root, table, conf, false);\n     byte[] filterExp = null;\n     if (partitionSpecs != null & !partitionSpecs.isEmpty()) {\n-      // explicitly set expression proxy class to PartitionExpressionForMetastore since we intend to use the\n+      // expression proxy class needs to be PartitionExpressionForMetastore since we intend to use the\n       // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n-      conf.set(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname(),\n-          PartitionExpressionForMetastore.class.getCanonicalName());\n+      // Bail out early if expressionProxyClass is not configured properly.\n+      String expressionProxyClass = conf.get(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname());\n+      if (expressionProxyClass == null || expressionProxyClass.isEmpty() ||\n+          !expressionProxyClass.equals(PartitionExpressionForMetastore.class.getCanonicalName())) {", "originalCommit": "412ced9a3941a64e7df23ef7096c5a6928393321", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjI4ODYzMw==", "url": "https://github.com/apache/hive/pull/1105#discussion_r452288633", "bodyText": "Fixed!", "author": "shameersss1", "createdAt": "2020-07-09T15:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjIxNDEyMA=="}], "type": "inlineReview", "revised_code": {"commit": "3943cd5026299500ad492291d722bcab8821dbb4", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\nindex a16b0be19a..14b6c486dd 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/ddl/misc/msck/MsckAnalyzer.java\n\n@@ -75,8 +75,7 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n       // filterPartitionsByExpr of PartitionExpressionForMetastore for partition pruning down the line.\n       // Bail out early if expressionProxyClass is not configured properly.\n       String expressionProxyClass = conf.get(MetastoreConf.ConfVars.EXPRESSION_PROXY_CLASS.getVarname());\n-      if (expressionProxyClass == null || expressionProxyClass.isEmpty() ||\n-          !expressionProxyClass.equals(PartitionExpressionForMetastore.class.getCanonicalName())) {\n+      if (!PartitionExpressionForMetastore.class.getCanonicalName().equals(expressionProxyClass)) {\n         throw new SemanticException(\"Invalid expression proxy class. The config metastore.expression.proxy needs \" +\n             \"to be set to org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore\");\n       }\n"}}, {"oid": "3943cd5026299500ad492291d722bcab8821dbb4", "url": "https://github.com/apache/hive/commit/3943cd5026299500ad492291d722bcab8821dbb4", "message": "PR Commnets", "committedDate": "2020-07-09T15:05:12Z", "type": "commit"}]}