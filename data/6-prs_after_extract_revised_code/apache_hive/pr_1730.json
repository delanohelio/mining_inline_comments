{"pr_number": 1730, "pr_title": "HIVE-24475: Generalize fixacidkeyindex utility", "pr_createdAt": "2020-12-03T11:04:19Z", "pr_url": "https://github.com/apache/hive/pull/1730", "timeline": [{"oid": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956", "url": "https://github.com/apache/hive/commit/0ffb4b32761cc44d50af0948c6cd9cc9f67ee956", "message": "HIVE-24475: Generalize fixacidkeyindex utility\n\nChange-Id: I6b9f501f2804aa5c71ee03cadcea3ec24fdd6005", "committedDate": "2020-12-03T09:27:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw==", "url": "https://github.com/apache/hive/pull/1730#discussion_r535204663", "bodyText": "Shouldn't this check if the index was actually corrected in the new file? It just checks the output of the tool.", "author": "pvargacl", "createdAt": "2020-12-03T12:55:56Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/io/orc/TestFixAcidKeyIndex.java", "diffHunk": "@@ -243,6 +233,12 @@ public void testInvalidKeyIndex() throws Exception {\n     checkInvalidKeyIndex(testFilePath);\n     // Try fixing, this should result in new fixed file.\n     fixInvalidIndex(testFilePath);\n+\n+    // Multiple stripes\n+    createTestAcidFile(testFilePath, 12000, new FaultyKeyIndexBuilder());\n+    checkInvalidKeyIndex(testFilePath);\n+    // Try fixing, this should result in new fixed file.\n+    fixInvalidIndex(testFilePath);", "originalCommit": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIyMzk0Ng==", "url": "https://github.com/apache/hive/pull/1730#discussion_r535223946", "bodyText": "There is a validation in the tool itself after the recovery, so if the index was still invalid, the output would be different.\nhttps://github.com/asinkovits/hive/blob/HIVE-24475/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java#L265", "author": "asinkovits", "createdAt": "2020-12-03T13:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MTU3NA==", "url": "https://github.com/apache/hive/pull/1730#discussion_r535251574", "bodyText": "Ah ok, missed that.", "author": "pvargacl", "createdAt": "2020-12-03T14:03:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTIwNDY2Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjgyMTExMw==", "url": "https://github.com/apache/hive/pull/1730#discussion_r536821113", "bodyText": "Can this be moved out of the loop ?", "author": "maheshk114", "createdAt": "2020-12-05T16:48:18Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java", "diffHunk": "@@ -163,11 +144,52 @@ static void checkFile(Configuration conf, Path inputPath) throws IOException {\n       return;\n     }\n \n-    boolean validIndex = isAcidKeyIndexValid(reader);\n+    AcidKeyIndexValidationResult validationResult = validate(conf, inputPath);\n+    boolean validIndex = validationResult.isValid;\n     System.out.println(\"Checking \" + inputPath + \" - acid key index is \" +\n         (validIndex ? \"valid\" : \"invalid\"));\n   }\n \n+  public static AcidKeyIndexValidationResult validate(Configuration conf, Path inputPath) throws IOException {\n+    AcidKeyIndexValidationResult result = new AcidKeyIndexValidationResult();\n+    FileSystem fs = inputPath.getFileSystem(conf);\n+    Reader reader = OrcFile.createReader(fs, inputPath);\n+    List<StripeInformation> stripes = reader.getStripes();\n+    RecordIdentifier[] keyIndex = OrcRecordUpdater.parseKeyIndex(reader);\n+    StructObjectInspector soi = (StructObjectInspector) reader.getObjectInspector();\n+    // struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint\n+\n+    long rowsProcessed = 0;\n+    try (RecordReader rr = reader.rows()) {\n+      for(int i=0; i<stripes.size(); i++) {\n+        rowsProcessed += stripes.get(i).getNumberOfRows();\n+        rr.seekToRow(rowsProcessed-1);\n+        OrcStruct row = (OrcStruct) rr.next(null);\n+\n+        List<? extends StructField> structFields = soi.getAllStructFieldRefs();\n+\n+        StructField transactionField = structFields.get(1);\n+        StructField bucketField = structFields.get(2);", "originalCommit": "0ffb4b32761cc44d50af0948c6cd9cc9f67ee956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY3MTMxMg==", "url": "https://github.com/apache/hive/pull/1730#discussion_r537671312", "bodyText": "Fixed.", "author": "asinkovits", "createdAt": "2020-12-07T17:03:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjgyMTExMw=="}], "type": "inlineReview", "revised_code": {"commit": "995524fddeb6daa0e7b3ef01ae7320d1e582c968", "chunk": "diff --git a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java\nindex a1887858d3..b385f6540f 100644\n--- a/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java\n+++ b/ql/src/java/org/apache/hadoop/hive/ql/io/orc/FixAcidKeyIndex.java\n\n@@ -158,26 +158,24 @@ public static AcidKeyIndexValidationResult validate(Configuration conf, Path inp\n     RecordIdentifier[] keyIndex = OrcRecordUpdater.parseKeyIndex(reader);\n     StructObjectInspector soi = (StructObjectInspector) reader.getObjectInspector();\n     // struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint\n+    List<? extends StructField> structFields = soi.getAllStructFieldRefs();\n+    StructField transactionField = structFields.get(1);\n+    LongObjectInspector transactionOI = (LongObjectInspector) transactionField.getFieldObjectInspector();\n+    StructField bucketField = structFields.get(2);\n+    IntObjectInspector bucketOI = (IntObjectInspector) bucketField.getFieldObjectInspector();\n+    StructField rowIdField = structFields.get(3);\n+    LongObjectInspector rowIdOI = (LongObjectInspector) rowIdField.getFieldObjectInspector();\n \n     long rowsProcessed = 0;\n     try (RecordReader rr = reader.rows()) {\n-      for(int i=0; i<stripes.size(); i++) {\n+      for (int i = 0; i < stripes.size(); i++) {\n         rowsProcessed += stripes.get(i).getNumberOfRows();\n-        rr.seekToRow(rowsProcessed-1);\n+        rr.seekToRow(rowsProcessed - 1);\n         OrcStruct row = (OrcStruct) rr.next(null);\n \n-        List<? extends StructField> structFields = soi.getAllStructFieldRefs();\n-\n-        StructField transactionField = structFields.get(1);\n-        StructField bucketField = structFields.get(2);\n-        StructField rowIdField = structFields.get(3);\n-\n-        long lastTransaction = ((LongObjectInspector) transactionField.getFieldObjectInspector()).get(\n-                soi.getStructFieldData(row, transactionField));\n-        int lastBucket = ((IntObjectInspector) bucketField.getFieldObjectInspector()).get(\n-                soi.getStructFieldData(row, bucketField));\n-        long lastRowId = ((LongObjectInspector) rowIdField.getFieldObjectInspector()).get(\n-                soi.getStructFieldData(row, rowIdField));\n+        long lastTransaction = transactionOI.get(soi.getStructFieldData(row, transactionField));\n+        int lastBucket = bucketOI.get(soi.getStructFieldData(row, bucketField));\n+        long lastRowId = rowIdOI.get(soi.getStructFieldData(row, rowIdField));\n \n         RecordIdentifier recordIdentifier = new RecordIdentifier(lastTransaction, lastBucket, lastRowId);\n         result.recordIdentifiers.add(recordIdentifier);\n"}}, {"oid": "995524fddeb6daa0e7b3ef01ae7320d1e582c968", "url": "https://github.com/apache/hive/commit/995524fddeb6daa0e7b3ef01ae7320d1e582c968", "message": "Code review\n\nChange-Id: I074c260204f1049f2e9b0b5fec6fe979d80e248d", "committedDate": "2020-12-07T17:01:09Z", "type": "commit"}]}