{"pr_number": 3168, "pr_title": "SPLICE-2379 SparkExplain Statement", "pr_createdAt": "2020-01-29T06:28:29Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3168", "timeline": [{"oid": "ad9939797a8379a8c86053fbc138b62d9384fab7", "url": "https://github.com/splicemachine/spliceengine/commit/ad9939797a8379a8c86053fbc138b62d9384fab7", "message": "SPLICE-2379 SparkExplain Statement\n            Prefix a query with \"sparkexplain\" to display the query plan\n\t    including both native Spark operations and Splice operations.", "committedDate": "2020-01-29T06:15:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjg5OTMyNg==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r372899326", "bodyText": "Why is this change needed?", "author": "dgomezferro", "createdAt": "2020-01-30T11:35:18Z", "path": "db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/CompilerContext.java", "diffHunk": "@@ -656,9 +656,9 @@\n \t */\n \tboolean isReferenced(SequenceDescriptor sd);\n \n-    void setDataSetProcessorType(DataSetProcessorType type);\n+\tvoid setDataSetProcessorType(DataSetProcessorType type, boolean setDSPTypeinLCC);", "originalCommit": "ad9939797a8379a8c86053fbc138b62d9384fab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1ODgxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373058818", "bodyText": "I think this is an old change I made to avoid using control when we're running in the Olap Server.  But I have since fixed that in CostChoosingDataSetProcessorFactory, so I will remove the above change.", "author": "msirek", "createdAt": "2020-01-30T16:35:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjg5OTMyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEwNDM1Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373104352", "bodyText": "I tried backing out this change, but it broke some Spark Explain tests. CostChoosingDataSetProcessorFactory.chooseProcessor() pulls the DataSetProcessorType from the lcc to determine whether to run on control or spark.  The lcc is not properly updated in all flows, so that is the intent of this change, to make sure that the DataSetProcessorType we've picked in the CompilerContext is propagated to the lcc.  Spark Explain needs to be executed on the Olap Server, so the lcc must always have the proper DataSetProcessorType setting.", "author": "msirek", "createdAt": "2020-01-30T18:00:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mjg5OTMyNg=="}], "type": "inlineReview", "revised_code": {"commit": "7dd075f68da5e39879e250acc466079135ab72e7", "chunk": "diff --git a/db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/CompilerContext.java b/db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/CompilerContext.java\nindex 51f589491a..b3b4ce7771 100644\n--- a/db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/CompilerContext.java\n+++ b/db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/CompilerContext.java\n\n@@ -259,450 +253,456 @@ public interface CompilerContext extends Context\n      *\n      * @param num\n      */\n-\tvoid setNumTables(int num);\n-\n-\t/**\n-\t * Some where subqueries can be converted to fromSubquery, so the number of tables could increase\n-\t * during preprocess of optimization. maximalPossibleTableCount takes the where Subqueries into\n-\t * considration as potentially the maximal possible table count.\n-\t * @return\n-\t */\n-\tint getMaximalPossibleTableCount();\n-\n-\tvoid setMaximalPossibleTableCount(int num);\n-\n-\t/**\n-\t * Get the current next subquery number from this CompilerContext.\n-\t *\n-\t * @return int\tThe next subquery number for the current statement.\n-\t *\n-\t */\n-\n-\tint getNextSubqueryNumber();\n-\n-\t/**\n-\t * Get the number of subquerys in the current statement from this CompilerContext.\n-\t *\n-\t * @return int\tThe number of subquerys in the current statement.\n-\t *\n-\t */\n-\n-\tint getNumSubquerys();\n-\n-\t/**\n-\t * Get the current next ResultSet number from this CompilerContext.\n-\t *\n-\t * @return int\tThe next ResultSet number for the current statement.\n-\t *\n-\t */\n-\n-\tint getNextResultSetNumber();\n-\n-\t/**\n-\t * Reset the next ResultSet number from this CompilerContext.\n-\t */\n-\n-\tvoid resetNextResultSetNumber();\n-\n-\t/**\n-\t * Get the number of Results in the current statement from this CompilerContext.\n-\t *\n-\t * @return The number of ResultSets in the current statement.\n-\t *\n-\t */\n-\n-\tint getNumResultSets();\n-\n-\t/**\n-\t * Get a unique Class name from this CompilerContext.\n-\t * Ensures it is globally unique for this JVM.\n-\t *\n-\t * @return String\tA unique-enough class name.\n-\t *\n-\t */\n-\n-\tString getUniqueClassName();\n-\n-\t/**\n-\t * Set the current dependent from this CompilerContext.\n-\t * This should be called at the start of a compile to\n-\t * register who has the dependencies needed for the compilation.\n-\t *\n-\t * @param d\tThe Dependent currently being compiled.\n-\t *\n-\t */\n-\n-\tvoid setCurrentDependent(Dependent d);\n-\n-\t\tDependent getCurrentDependent();\n-\n-\t/**\n-\t * Get the current auxiliary provider list from this CompilerContext.\n-\t *\n-\t * @return\tThe current AuxiliaryProviderList.\n-\t *\n-\t */\n-\n-\tProviderList getCurrentAuxiliaryProviderList();\n-\n-\t/**\n-\t * Set the current auxiliary provider list for this CompilerContext.\n-\t *\n-\t * @param apl\tThe new current AuxiliaryProviderList.\n-\t *\n-\t */\n-\n-\tvoid setCurrentAuxiliaryProviderList(ProviderList apl);\n-\n-\t/**\n-\t * Add a dependency for the current dependent.\n-\t *\n-\t * @param p\tThe Provider of the dependency.\n-\t * @exception StandardException thrown on failure.\n-\t *\n-\t */\n-\tvoid createDependency(Provider p) throws StandardException;\n-\n-\t/**\n-\t * Add a dependency between two objects.\n-\t *\n-\t * @param d\tThe Dependent object.\n-\t * @param p\tThe Provider of the dependency.\n-\t * @exception StandardException thrown on failure.\n-\t *\n-\t */\n-\tvoid createDependency(Dependent d, Provider p) throws StandardException;\n-\n-\t/**\n-\t * Add an object to the pool that is created at compile time\n-\t * and used at execution time.  Use the integer to reference it\n-\t * in execution constructs.  Execution code will have to generate:\n-\t *\t<pre>\n-\t *\t(#objectType) (this.getPreparedStatement().getSavedObject(#int))\n-\t *  <\\pre>\n-\t *\n-\t * @param o object to add to the pool of saved objects\n-\t * @return the entry # for the object\n-\t */\n-\tint\taddSavedObject(Object o);\n-\n-\t/**\n-\t *\tGet the saved object pool (for putting into the prepared statement).\n-\t *  This turns it into its storable form, an array of objects.\n-\t *\n-\t * @return the saved object pool.\n-\t */\n-\tObject[] getSavedObjects(); \n-\n-\t/**\n-\t *\tSet the saved object pool (for putting into the prepared statement).\n-\t *\n-\t * @param objs\t The new saved objects\n-\t */\n-\tvoid setSavedObjects(Object[] objs);\n-\n-\t/**\n-\t * Set the in use state for the compiler context.\n-\t *\n-\t * @param inUse\t The new inUse state for the compiler context.\n-\t */\n-\tvoid setInUse(boolean inUse);\n-\n-\t/**\n-\t * Return the in use state for the compiler context.\n-\t *\n-\t * @return boolean\tThe in use state for the compiler context.\n-\t */\n-\tboolean getInUse();\n-\n-\t/**\n-\t * Mark this CompilerContext as the first on the stack, so we can avoid\n-\t * continually popping and pushing a CompilerContext.\n-\t */\n-\tvoid firstOnStack();\n-\n-\t/**\n-\t * Is this the first CompilerContext on the stack?\n-\t */\n-\tboolean isFirstOnStack();\n-\n-\t/**\n-\t * Sets which kind of query fragments are NOT allowed. Basically,\n-\t * these are fragments which return unstable results. CHECK CONSTRAINTS\n-\t * and CREATE PUBLICATION want to forbid certain kinds of fragments.\n-\t *\n-\t * @param reliability\tbitmask of types of query fragments to be forbidden\n-\t *\t\t\t\t\t\tsee the reliability bitmasks above\n-\t *\n-\t */\n-\tvoid\tsetReliability(int reliability);\n-\n-\t/**\n-\t * Return the reliability requirements of this clause. See setReliability()\n-\t * for a definition of clause reliability.\n-\t *\n-\t * @return a bitmask of which types of query fragments are to be forbidden\n-\t */\n-\tint getReliability();\n-\n-\t/**\n-\t * Get the compilation schema descriptor for this compilation context.\n-\t   Will be null if no default schema lookups have occured. Ie.\n-\t   the statement is independent of the current schema.\n-\t * \n-\t * @return the compilation schema descirptor\n-\t */\n-\tSchemaDescriptor getCompilationSchema();\n-\n-\t/**\n-\t * Set the compilation schema descriptor for this compilation context.\n-\t *\n-\t * @param newDefault compilation schema\n-\t * \n-\t * @return the previous compilation schema descirptor\n-\t */\n-\tSchemaDescriptor setCompilationSchema(SchemaDescriptor newDefault);\n-\n-\t/**\n-\t * Push a default schema to use when compiling.\n-\t * <p>\n-\t * Sometimes, we need to temporarily change the default schema, for example\n-\t * when recompiling a view, since the execution time default schema may\n-\t * differ from the required default schema when the view was defined.\n-\t * Another case is when compiling generated columns which reference\n-\t * unqualified user functions.\n-\t * </p>\n-\t * @param sd schema to use\n-\t */\n-\tvoid pushCompilationSchema(SchemaDescriptor sd);\n-\n-\n-\t/**\n-\t * Pop the default schema to use when compiling.\n-\t */\n-\tvoid popCompilationSchema();\n-\n-\t/**\n-\t * Get a StoreCostController for the given conglomerate.\n-\t *\n-\t * @param conglomerateDescriptor\tThe conglomerate for which to get a StoreCostController.\n-\t * @param skipStats do not fetch the stats from dictionary if true\n-\t * @param defaultRowCount it only take effect when skipStats is true, and forces the fake stats' rowcount to be the specified value\n-\t *\n-\t * @return\tThe appropriate StoreCostController.\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tStoreCostController getStoreCostController(TableDescriptor td, ConglomerateDescriptor conglomerateDescriptor, boolean skipStats, long defaultRowCount) throws StandardException;\n-\n-\t/**\n-\t * Get a SortCostController.\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tSortCostController getSortCostController() throws StandardException;\n-\n-\t/**\n-\t * Set the parameter list.\n-\t *\n-\t * @param parameterList\tThe parameter list.\n-\t */\n-\tvoid setParameterList(Vector parameterList);\n-\n-\t/**\n-\t * Get the parameter list.\n-\t *\n-\t * @return\tThe parameter list.\n-\t */\n-\tVector getParameterList();\n-\n-\t/**\n-\t * If callable statement uses ? = form\n-\t */\n-\tvoid setReturnParameterFlag();\n-\n-\t/**\n-\t * Is the callable statement uses ? for return parameter.\n-\t *\n-\t * @return\ttrue if ? = call else false\n-\t */\n-\tboolean getReturnParameterFlag();\n-\n-\t/**\n-\t * Get the array of DataTypeDescriptor representing the types of\n-\t * the ? parameters.\n-\t *\n-\t * @return\tThe parameter descriptors\n-\t */\n-\n-\tDataTypeDescriptor[] getParameterTypes();\n-\n-\t/**\n-\t * Get the cursor info stored in the context.\n-\t *\n-\t * @return the cursor info\n-\t */\n-\tObject getCursorInfo();\n-\t\n-\t/**\n-\t * Set params\n-\t *\n-\t * @param cursorInfo the cursor info\n-\t */\n-\tvoid setCursorInfo(Object cursorInfo);\n-\n-\t/**\n-\t * Set the isolation level for the scans in this query.\n-\t *\n-\t * @param isolationLevel\tThe isolation level to use.\n-\t */\n-\tvoid setScanIsolationLevel(int isolationLevel);\n-\n-\t/**\n-\t * Get the isolation level for the scans in this query.\n-\t *\n-\t * @return\tThe isolation level for the scans in this query.\n-\t */\n-\tint getScanIsolationLevel();\n-\n-\t/**\n-\t * Get the next equivalence class for equijoin clauses.\n-\t *\n-\t * @return The next equivalence class for equijoin clauses.\n-\t */\n-\tint getNextEquivalenceClass();\n-\n-\t/**\n-\t\tAdd a compile time warning.\n-\t*/\n-\tvoid addWarning(SQLWarning warning);\n-\n-\t/**\n-\t\tGet the chain of compile time warnings.\n-\t*/\n-\tSQLWarning getWarnings();\n-\n-\t/**\n-\t * Sets the current privilege type context and pushes the previous on onto a stack.\n-\t * Column and table nodes do not know how they are\n-\t * being used. Higher level nodes in the query tree do not know what is being\n-\t * referenced. Keeping the context allows the two to come together.\n-\t *\n-\t * @param privType One of the privilege types in \n-\t *\t\t\t\t\t\tcom.splicemachine.db.iapi.sql.conn.Authorizer.\n-\t */\n-\tvoid pushCurrentPrivType(int privType);\n-\t\n-\tvoid popCurrentPrivType();\n+    void setNumTables(int num);\n+\n+    /**\n+     * Some where subqueries can be converted to fromSubquery, so the number of tables could increase\n+     * during preprocess of optimization. maximalPossibleTableCount takes the where Subqueries into\n+     * considration as potentially the maximal possible table count.\n+     * @return\n+     */\n+    int getMaximalPossibleTableCount();\n+\n+    void setMaximalPossibleTableCount(int num);\n+\n+    /**\n+     * Get the current next subquery number from this CompilerContext.\n+     *\n+     * @return int    The next subquery number for the current statement.\n+     *\n+     */\n+\n+    int getNextSubqueryNumber();\n+\n+    /**\n+     * Get the number of subquerys in the current statement from this CompilerContext.\n+     *\n+     * @return int    The number of subquerys in the current statement.\n+     *\n+     */\n+\n+    int getNumSubquerys();\n+\n+    /**\n+     * Get the current next ResultSet number from this CompilerContext.\n+     *\n+     * @return int    The next ResultSet number for the current statement.\n+     *\n+     */\n+\n+    int getNextResultSetNumber();\n+\n+    /**\n+     * Reset the next ResultSet number from this CompilerContext.\n+     */\n+\n+    void resetNextResultSetNumber();\n+\n+    /**\n+     * Get the number of Results in the current statement from this CompilerContext.\n+     *\n+     * @return The number of ResultSets in the current statement.\n+     *\n+     */\n+\n+    int getNumResultSets();\n+\n+    /**\n+     * Get a unique Class name from this CompilerContext.\n+     * Ensures it is globally unique for this JVM.\n+     *\n+     * @return String    A unique-enough class name.\n+     *\n+     */\n+\n+    String getUniqueClassName();\n+\n+    /**\n+     * Set the current dependent from this CompilerContext.\n+     * This should be called at the start of a compile to\n+     * register who has the dependencies needed for the compilation.\n+     *\n+     * @param d    The Dependent currently being compiled.\n+     *\n+     */\n+\n+    void setCurrentDependent(Dependent d);\n+\n+        Dependent getCurrentDependent();\n+\n+    /**\n+     * Get the current auxiliary provider list from this CompilerContext.\n+     *\n+     * @return    The current AuxiliaryProviderList.\n+     *\n+     */\n+\n+    ProviderList getCurrentAuxiliaryProviderList();\n+\n+    /**\n+     * Set the current auxiliary provider list for this CompilerContext.\n+     *\n+     * @param apl    The new current AuxiliaryProviderList.\n+     *\n+     */\n+\n+    void setCurrentAuxiliaryProviderList(ProviderList apl);\n+\n+    /**\n+     * Add a dependency for the current dependent.\n+     *\n+     * @param p    The Provider of the dependency.\n+     * @exception StandardException thrown on failure.\n+     *\n+     */\n+    void createDependency(Provider p) throws StandardException;\n+\n+    /**\n+     * Add a dependency between two objects.\n+     *\n+     * @param d    The Dependent object.\n+     * @param p    The Provider of the dependency.\n+     * @exception StandardException thrown on failure.\n+     *\n+     */\n+    void createDependency(Dependent d, Provider p) throws StandardException;\n+\n+    /**\n+     * Add an object to the pool that is created at compile time\n+     * and used at execution time.  Use the integer to reference it\n+     * in execution constructs.  Execution code will have to generate:\n+     *    <pre>\n+     *    (#objectType) (this.getPreparedStatement().getSavedObject(#int))\n+     *  <\\pre>\n+     *\n+     * @param o object to add to the pool of saved objects\n+     * @return the entry # for the object\n+     */\n+    int    addSavedObject(Object o);\n+\n+    /**\n+     *    Get the saved object pool (for putting into the prepared statement).\n+     *  This turns it into its storable form, an array of objects.\n+     *\n+     * @return the saved object pool.\n+     */\n+    Object[] getSavedObjects();\n+\n+    /**\n+     *    Set the saved object pool (for putting into the prepared statement).\n+     *\n+     * @param objs     The new saved objects\n+     */\n+    void setSavedObjects(Object[] objs);\n+\n+    /**\n+     * Set the in use state for the compiler context.\n+     *\n+     * @param inUse     The new inUse state for the compiler context.\n+     */\n+    void setInUse(boolean inUse);\n+\n+    /**\n+     * Return the in use state for the compiler context.\n+     *\n+     * @return boolean    The in use state for the compiler context.\n+     */\n+    boolean getInUse();\n+\n+    /**\n+     * Mark this CompilerContext as the first on the stack, so we can avoid\n+     * continually popping and pushing a CompilerContext.\n+     */\n+    void firstOnStack();\n+\n+    /**\n+     * Is this the first CompilerContext on the stack?\n+     */\n+    boolean isFirstOnStack();\n+\n+    /**\n+     * Sets which kind of query fragments are NOT allowed. Basically,\n+     * these are fragments which return unstable results. CHECK CONSTRAINTS\n+     * and CREATE PUBLICATION want to forbid certain kinds of fragments.\n+     *\n+     * @param reliability    bitmask of types of query fragments to be forbidden\n+     *                        see the reliability bitmasks above\n+     *\n+     */\n+    void    setReliability(int reliability);\n+\n+    /**\n+     * Return the reliability requirements of this clause. See setReliability()\n+     * for a definition of clause reliability.\n+     *\n+     * @return a bitmask of which types of query fragments are to be forbidden\n+     */\n+    int getReliability();\n+\n+    /**\n+     * Get the compilation schema descriptor for this compilation context.\n+       Will be null if no default schema lookups have occured. Ie.\n+       the statement is independent of the current schema.\n+     *\n+     * @return the compilation schema descirptor\n+     */\n+    SchemaDescriptor getCompilationSchema();\n+\n+    /**\n+     * Set the compilation schema descriptor for this compilation context.\n+     *\n+     * @param newDefault compilation schema\n+     *\n+     * @return the previous compilation schema descirptor\n+     */\n+    SchemaDescriptor setCompilationSchema(SchemaDescriptor newDefault);\n+\n+    /**\n+     * Push a default schema to use when compiling.\n+     * <p>\n+     * Sometimes, we need to temporarily change the default schema, for example\n+     * when recompiling a view, since the execution time default schema may\n+     * differ from the required default schema when the view was defined.\n+     * Another case is when compiling generated columns which reference\n+     * unqualified user functions.\n+     * </p>\n+     * @param sd schema to use\n+     */\n+    void pushCompilationSchema(SchemaDescriptor sd);\n+\n+\n+    /**\n+     * Pop the default schema to use when compiling.\n+     */\n+    void popCompilationSchema();\n+\n+    /**\n+     * Get a StoreCostController for the given conglomerate.\n+     *\n+     * @param conglomerateDescriptor    The conglomerate for which to get a StoreCostController.\n+     * @param skipStats do not fetch the stats from dictionary if true\n+     * @param defaultRowCount it only take effect when skipStats is true, and forces the fake stats' rowcount to be the specified value\n+     *\n+     * @return    The appropriate StoreCostController.\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    StoreCostController getStoreCostController(TableDescriptor td, ConglomerateDescriptor conglomerateDescriptor, boolean skipStats, long defaultRowCount) throws StandardException;\n+\n+    /**\n+     * Get a SortCostController.\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    SortCostController getSortCostController() throws StandardException;\n+\n+    /**\n+     * Set the parameter list.\n+     *\n+     * @param parameterList    The parameter list.\n+     */\n+    void setParameterList(Vector parameterList);\n+\n+    /**\n+     * Get the parameter list.\n+     *\n+     * @return    The parameter list.\n+     */\n+    Vector getParameterList();\n+\n+    /**\n+     * If callable statement uses ? = form\n+     */\n+    void setReturnParameterFlag();\n+\n+    /**\n+     * Is the callable statement uses ? for return parameter.\n+     *\n+     * @return    true if ? = call else false\n+     */\n+    boolean getReturnParameterFlag();\n+\n+    /**\n+     * Get the array of DataTypeDescriptor representing the types of\n+     * the ? parameters.\n+     *\n+     * @return    The parameter descriptors\n+     */\n+\n+    DataTypeDescriptor[] getParameterTypes();\n+\n+    /**\n+     * Get the cursor info stored in the context.\n+     *\n+     * @return the cursor info\n+     */\n+    Object getCursorInfo();\n+\n+    /**\n+     * Set params\n+     *\n+     * @param cursorInfo the cursor info\n+     */\n+    void setCursorInfo(Object cursorInfo);\n+\n+    /**\n+     * Set the isolation level for the scans in this query.\n+     *\n+     * @param isolationLevel    The isolation level to use.\n+     */\n+    void setScanIsolationLevel(int isolationLevel);\n+\n+    /**\n+     * Get the isolation level for the scans in this query.\n+     *\n+     * @return    The isolation level for the scans in this query.\n+     */\n+    int getScanIsolationLevel();\n+\n+    /**\n+     * Get the next equivalence class for equijoin clauses.\n+     *\n+     * @return The next equivalence class for equijoin clauses.\n+     */\n+    int getNextEquivalenceClass();\n+\n+    /**\n+        Add a compile time warning.\n+    */\n+    void addWarning(SQLWarning warning);\n+\n+    /**\n+        Get the chain of compile time warnings.\n+    */\n+    SQLWarning getWarnings();\n+\n+    /**\n+     * Sets the current privilege type context and pushes the previous on onto a stack.\n+     * Column and table nodes do not know how they are\n+     * being used. Higher level nodes in the query tree do not know what is being\n+     * referenced. Keeping the context allows the two to come together.\n+     *\n+     * @param privType One of the privilege types in\n+     *                        com.splicemachine.db.iapi.sql.conn.Authorizer.\n+     */\n+    void pushCurrentPrivType(int privType);\n+\n+    void popCurrentPrivType();\n     \n-\t/**\n-\t * Add a column privilege to the list of used column privileges.\n-\t *\n-\t * @param column\n-\t */\n-\tvoid addRequiredColumnPriv(ColumnDescriptor column);\n-\n-\t/**\n-\t * Add a table or view privilege to the list of used table privileges.\n-\t *\n-\t * @param table\n-\t */\n-\tvoid addRequiredTablePriv(TableDescriptor table);\n-\n-\t/**\n-\t * Add a schema privilege to the list of used privileges.\n-\t *\n-\t * @param schema\tSchema name of the object that is being accessed\n-\t * @param aid\t\tRequested authorizationId for new schema\n-\t * @param privType\tCREATE_SCHEMA_PRIV, MODIFY_SCHEMA_PRIV or DROP_SCHEMA_PRIV\n-\t */\n-\tvoid addRequiredSchemaPriv(String schema, String aid, int privType);\n-\n-\tvoid addRequiredAccessSchemaPriv(UUID uuid);\n-\n-\t/**\n-\t * Add a routine execute privilege to the list of used routine privileges.\n-\t *\n-\t * @param routine\n-\t */\n-\tvoid addRequiredRoutinePriv(AliasDescriptor routine);\n-\n-\t/**\n-\t * Add a usage privilege to the list of required privileges.\n-\t *\n-\t * @param usableObject\n-\t */\n-\tvoid addRequiredUsagePriv(PrivilegedSQLObject usableObject);\n-\n-\t/**\n-\t * Add a required role privilege to the list of privileges.\n-\t *\n-\t * @see CompilerContext#addRequiredRolePriv\n-\t */\n-\tvoid addRequiredRolePriv(String roleName, int privType);\n-\n-\t/**\n-\t * @return The list of required privileges.\n-\t */\n-\tList getRequiredPermissionsList();\n+    /**\n+     * Add a column privilege to the list of used column privileges.\n+     *\n+     * @param column\n+     */\n+    void addRequiredColumnPriv(ColumnDescriptor column);\n+\n+    /**\n+     * Add a table or view privilege to the list of used table privileges.\n+     *\n+     * @param table\n+     */\n+    void addRequiredTablePriv(TableDescriptor table);\n+\n+    /**\n+     * Add a schema privilege to the list of used privileges.\n+     *\n+     * @param schema    Schema name of the object that is being accessed\n+     * @param aid        Requested authorizationId for new schema\n+     * @param privType    CREATE_SCHEMA_PRIV, MODIFY_SCHEMA_PRIV or DROP_SCHEMA_PRIV\n+     */\n+    void addRequiredSchemaPriv(String schema, String aid, int privType);\n+\n+    void addRequiredAccessSchemaPriv(UUID uuid);\n+\n+    /**\n+     * Add a routine execute privilege to the list of used routine privileges.\n+     *\n+     * @param routine\n+     */\n+    void addRequiredRoutinePriv(AliasDescriptor routine);\n+\n+    /**\n+     * Add a usage privilege to the list of required privileges.\n+     *\n+     * @param usableObject\n+     */\n+    void addRequiredUsagePriv(PrivilegedSQLObject usableObject);\n+\n+    /**\n+     * Add a required role privilege to the list of privileges.\n+     *\n+     * @see CompilerContext#addRequiredRolePriv\n+     */\n+    void addRequiredRolePriv(String roleName, int privType);\n+\n+    /**\n+     * @return The list of required privileges.\n+     */\n+    List getRequiredPermissionsList();\n     \n-\t/**\n-\t * Add a sequence descriptor to the list of referenced sequences.\n-\t */\n-\tvoid addReferencedSequence(SequenceDescriptor sd);\n+    /**\n+     * Add a sequence descriptor to the list of referenced sequences.\n+     */\n+    void addReferencedSequence(SequenceDescriptor sd);\n+\n+    /**\n+     * Report whether the given sequence has been referenced already.\n+     */\n+    boolean isReferenced(SequenceDescriptor sd);\n+\n+    void setDataSetProcessorType(DataSetProcessorType type) throws StandardException;\n+\n+    DataSetProcessorType getDataSetProcessorType();\n+\n+    boolean skipStats(int tableNumber);\n+\n+    Vector<Integer> getSkipStatsTableList();\n+\n+    public boolean getSelectivityEstimationIncludingSkewedDefault();\n+\n+    public void setSelectivityEstimationIncludingSkewedDefault(boolean onOff);\n+\n+    public boolean isProjectionPruningEnabled();\n+\n+    public void setProjectionPruningEnabled(boolean onOff);\n \n-\t/**\n-\t * Report whether the given sequence has been referenced already.\n-\t */\n-\tboolean isReferenced(SequenceDescriptor sd);\n+    public int getMaxMulticolumnProbeValues();\n \n-\tvoid setDataSetProcessorType(DataSetProcessorType type, boolean setDSPTypeinLCC);\n+    public void setMaxMulticolumnProbeValues(int newValue);\n \n-\tDataSetProcessorType getDataSetProcessorType();\n+    public void setMulticolumnInlistProbeOnSparkEnabled(boolean newValue);\n \n-\tboolean skipStats(int tableNumber);\n+    public boolean getMulticolumnInlistProbeOnSparkEnabled();\n \n-\tVector<Integer> getSkipStatsTableList();\n+    public void setConvertMultiColumnDNFPredicatesToInList(boolean newValue);\n \n-\tpublic boolean getSelectivityEstimationIncludingSkewedDefault();\n+    public boolean getConvertMultiColumnDNFPredicatesToInList();\n \n-\tpublic void setSelectivityEstimationIncludingSkewedDefault(boolean onOff);\n+    public void setDisablePredicateSimplification(boolean newValue);\n \n-\tpublic boolean isProjectionPruningEnabled();\n+    public boolean getDisablePredicateSimplification();\n \n-\tpublic void setProjectionPruningEnabled(boolean onOff);\n-\t\n-\tpublic int getMaxMulticolumnProbeValues();\n-\t\n-\tpublic void setMaxMulticolumnProbeValues(int newValue);\n-\t\n-\tpublic void setMulticolumnInlistProbeOnSparkEnabled(boolean newValue);\n-\t\n-\tpublic boolean getMulticolumnInlistProbeOnSparkEnabled();\n-\t\n-\tpublic void setConvertMultiColumnDNFPredicatesToInList(boolean newValue);\n-\t\n-\tpublic boolean getConvertMultiColumnDNFPredicatesToInList();\n+    public void setSparkVersion(SparkVersion newValue);\n \n-\tpublic void setDisablePredicateSimplification(boolean newValue);\n+    public SparkVersion getSparkVersion();\n \n-\tpublic boolean getDisablePredicateSimplification();\n+    public boolean isSparkVersionInitialized();\n \n-\tpublic void setSparkVersion(SparkVersion newValue);\n+    public void setNativeSparkAggregationMode(CompilerContext.NativeSparkModeType newValue);\n \n-\tpublic SparkVersion getSparkVersion();\n+    public CompilerContext.NativeSparkModeType getNativeSparkAggregationMode();\n \n-\tpublic boolean isSparkVersionInitialized();\n+    public void setAllowOverflowSensitiveNativeSparkExpressions(boolean newValue);\n \n-\tpublic void setNativeSparkAggregationMode(CompilerContext.NativeSparkModeType newValue);\n+    public boolean getAllowOverflowSensitiveNativeSparkExpressions();\n \n-\tpublic CompilerContext.NativeSparkModeType getNativeSparkAggregationMode();\n+    public void setCurrentTimestampPrecision(int newValue);\n \n-\tpublic void setAllowOverflowSensitiveNativeSparkExpressions(boolean newValue);\n+    public int getCurrentTimestampPrecision();\n \n-\tpublic boolean getAllowOverflowSensitiveNativeSparkExpressions();\n+    public int getNextOJLevel();\n \n-\tpublic void setCurrentTimestampPrecision(int newValue);\n+    public boolean isOuterJoinFlatteningDisabled();\n \n-\tpublic int getCurrentTimestampPrecision();\n+    public void setOuterJoinFlatteningDisabled(boolean onOff);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwMDg0MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r372900840", "bodyText": "You could return an empty dataset instead if this could be a problem, sampling might actually read the data from Splice anyway", "author": "dgomezferro", "createdAt": "2020-01-30T11:39:01Z", "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java", "diffHunk": "@@ -102,6 +101,14 @@ else if (storedAs.equals(\"O\"))\n                 // The predicates have variant qualifiers (or we are reading ORC with our own reader), we couldn't push them down to the scan, process them here\n                 return locatedRows.filter(new TableScanPredicateFunction<>(operationContext));\n             }\n+            if (dsp.isSparkExplain()) {", "originalCommit": "ad9939797a8379a8c86053fbc138b62d9384fab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1NjExMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373056110", "bodyText": "Thanks, I'll keep this in mind.  So far it's not an issue.  I'm not sure if this would change what's printed in the spark explain, for example, would it still indicate which parquet table is being read from for external tables, etc.", "author": "msirek", "createdAt": "2020-01-30T16:30:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwMDg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1ODM1MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373058351", "bodyText": "That's a good point, it wouldn't.", "author": "dgomezferro", "createdAt": "2020-01-30T16:34:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwMDg0MA=="}], "type": "inlineReview", "revised_code": {"commit": "6b6e04baa2724dac95951a6b1dbabbc5c8a77661", "chunk": "diff --git a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\nindex aabdd5f239..d24a753509 100644\n--- a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\n+++ b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\n\n@@ -101,14 +101,6 @@ public class SparkScanSetBuilder<V> extends TableScannerBuilder<V> {\n                 // The predicates have variant qualifiers (or we are reading ORC with our own reader), we couldn't push them down to the scan, process them here\n                 return locatedRows.filter(new TableScanPredicateFunction<>(operationContext));\n             }\n-            if (dsp.isSparkExplain()) {\n-                // The following doesn't appear to be required.\n-                // Enable if collection of any spark explain plans is found\n-                // to read rows and execute part of the query plan:\n-                // Filter out rows if we only care about the explain.  We don't actually want to\n-                // spend any time running the query if possible.\n-                //locatedRows = locatedRows.sampleWithoutReplacement(0.0d);\n-            }\n             return locatedRows;\n         }\n         \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwMDk1MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r372900950", "bodyText": "I'd either remove these blocks or make them return an empty dataset", "author": "dgomezferro", "createdAt": "2020-01-30T11:39:17Z", "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java", "diffHunk": "@@ -113,7 +120,19 @@ else if (storedAs.equals(\"O\"))\n         if (oneSplitPerRegion) {\n             conf.set(MRConstants.ONE_SPLIT_PER_REGION, \"true\");\n         }\n-        if (useSample) {\n+        if (dsp.isSparkExplain()) {", "originalCommit": "ad9939797a8379a8c86053fbc138b62d9384fab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEwNTk0Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373105942", "bodyText": "OK, I've reverted the changes.", "author": "msirek", "createdAt": "2020-01-30T18:04:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwMDk1MA=="}], "type": "inlineReview", "revised_code": {"commit": "6b6e04baa2724dac95951a6b1dbabbc5c8a77661", "chunk": "diff --git a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\nindex aabdd5f239..d24a753509 100644\n--- a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\n+++ b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkScanSetBuilder.java\n\n@@ -120,19 +112,7 @@ public class SparkScanSetBuilder<V> extends TableScannerBuilder<V> {\n         if (oneSplitPerRegion) {\n             conf.set(MRConstants.ONE_SPLIT_PER_REGION, \"true\");\n         }\n-        if (dsp.isSparkExplain()) {\n-            // The following doesn't appear to be required.\n-            // Enable if collection of any spark explain plans is found\n-            // to read rows and execute part of the query plan:\n-            // We need to call getDataSet() to get the spark explain, which may run part\n-            // of the query (for example, the broadcast in a broadcast join).\n-            // Let's keep the execution time to a minimum.\n-            // When the sampling rate is very small it can currently cause query hangs.\n-            // Do not decrease the following sampling rate until this is fixed.\n-            //conf.set(MRConstants.SPLICE_SAMPLING, Double.toString(0.0000001d));\n-        }\n-        else\n-            if (useSample) {\n+        if (useSample) {\n             conf.set(MRConstants.SPLICE_SAMPLING, Double.toString(sampleFraction));\n         }\n         if (op != null) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwNDA2Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r372904063", "bodyText": "Couldn't you use here dsp.getEmpty() ?", "author": "dgomezferro", "createdAt": "2020-01-30T11:47:14Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/RowCountOperation.java", "diffHunk": "@@ -199,8 +202,31 @@ public void writeExternal(ObjectOutput out) throws IOException {\n         final long fetchLimit = getFetchLimit();\n         long offset = getTotalOffset();\n         OperationContext operationContext = dsp.createOperationContext(this);\n-        DataSet<ExecRow> sourceSet = source.getDataSet(dsp).map(new CloneFunction<>(operationContext));\n-        return sourceSet.zipWithIndex(operationContext).mapPartitions(new OffsetFunction<SpliceOperation, ExecRow>(operationContext, offset, fetchLimit));\n+        dsp.incrementOpDepth();\n+        DataSet<ExecRow> sourceDS = source.getDataSet(dsp);\n+        dsp.decrementOpDepth();\n+        DataSet<ExecRow> sourceSet = sourceDS.map(new CloneFunction<>(operationContext));\n+        if (dsp.isSparkExplain()) {\n+                        DataSet<ExecRow> ds = dsp.createDataSet(Iterators.transform(Collections.emptyIterator(),", "originalCommit": "ad9939797a8379a8c86053fbc138b62d9384fab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEwNzEwMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3168#discussion_r373107101", "bodyText": "Made the change.", "author": "msirek", "createdAt": "2020-01-30T18:06:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjkwNDA2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "6b6e04baa2724dac95951a6b1dbabbc5c8a77661", "chunk": "diff --git a/splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/RowCountOperation.java b/splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/RowCountOperation.java\nindex ad33cc51a4..7417a7a2a6 100644\n--- a/splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/RowCountOperation.java\n+++ b/splice_machine/src/main/java/com/splicemachine/derby/impl/sql/execute/operations/RowCountOperation.java\n\n@@ -207,21 +204,7 @@ public class RowCountOperation extends SpliceBaseOperation {\n         dsp.decrementOpDepth();\n         DataSet<ExecRow> sourceSet = sourceDS.map(new CloneFunction<>(operationContext));\n         if (dsp.isSparkExplain()) {\n-                        DataSet<ExecRow> ds = dsp.createDataSet(Iterators.transform(Collections.emptyIterator(),\n-                                                                new Function<String, ExecRow>() {\n-                                                             @Nullable\n-                                                             @Override\n-                                                             public ExecRow apply(@Nullable String n) {\n-                                                                 try {\n-                                                                     return getExecRowDefinition().getClone();\n-                                                                 } catch (Exception e) {\n-                                                                     throw new RuntimeException(e);\n-                                                                 }\n-                                                             }\n-                                                         }\n-                    ),\n-                    this.explainPlan\n-            );\n+            DataSet<ExecRow> ds = dsp.getEmpty();\n             handleSparkExplain(ds, sourceDS, dsp);\n             return ds;\n         }\n"}}, {"oid": "6b6e04baa2724dac95951a6b1dbabbc5c8a77661", "url": "https://github.com/splicemachine/spliceengine/commit/6b6e04baa2724dac95951a6b1dbabbc5c8a77661", "message": "SPLICE-2379 Address review comments.", "committedDate": "2020-01-30T18:09:52Z", "type": "commit"}, {"oid": "6da9b3abd05efb8d51ab7b62029a1523718cfc09", "url": "https://github.com/splicemachine/spliceengine/commit/6da9b3abd05efb8d51ab7b62029a1523718cfc09", "message": "Merge branch 'master' into SPLICE-2379", "committedDate": "2020-02-07T06:20:29Z", "type": "commit"}, {"oid": "00362df318bdf7097c45be4e2b4769b2d438d4bd", "url": "https://github.com/splicemachine/spliceengine/commit/00362df318bdf7097c45be4e2b4769b2d438d4bd", "message": "SPLICE-2379 Fix compilation failure.", "committedDate": "2020-02-07T06:32:22Z", "type": "commit"}, {"oid": "7dd075f68da5e39879e250acc466079135ab72e7", "url": "https://github.com/splicemachine/spliceengine/commit/7dd075f68da5e39879e250acc466079135ab72e7", "message": "Merge branch 'master' into SPLICE-2379", "committedDate": "2020-02-20T12:11:04Z", "type": "commit"}, {"oid": "49b509c7fdabf758ac753b094690dfc79dd36ab9", "url": "https://github.com/splicemachine/spliceengine/commit/49b509c7fdabf758ac753b094690dfc79dd36ab9", "message": "SPLICE-2379 Fix tests", "committedDate": "2020-02-20T19:04:35Z", "type": "commit"}, {"oid": "49b509c7fdabf758ac753b094690dfc79dd36ab9", "url": "https://github.com/splicemachine/spliceengine/commit/49b509c7fdabf758ac753b094690dfc79dd36ab9", "message": "SPLICE-2379 Fix tests", "committedDate": "2020-02-20T19:04:35Z", "type": "forcePushed"}]}