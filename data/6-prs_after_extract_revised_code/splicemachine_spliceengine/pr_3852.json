{"pr_number": 3852, "pr_title": "DB-9846 Spark 3.0 Migrate minor API changes", "pr_createdAt": "2020-07-17T15:11:03Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3852", "timeline": [{"oid": "d1a70694c2400740b9b4997d3830de7a54465f16", "url": "https://github.com/splicemachine/spliceengine/commit/d1a70694c2400740b9b4997d3830de7a54465f16", "message": "DB-9846 Spark 3.0 Migrate minor API changes", "committedDate": "2020-07-17T08:43:56Z", "type": "commit"}, {"oid": "4256c7874ef3b9a052cffbe17c48017760eef260", "url": "https://github.com/splicemachine/spliceengine/commit/4256c7874ef3b9a052cffbe17c48017760eef260", "message": "DB-9846 adjusted for API change", "committedDate": "2020-07-17T10:14:40Z", "type": "commit"}, {"oid": "49424d2bce6468f0c4d710963daf4938a25df860", "url": "https://github.com/splicemachine/spliceengine/commit/49424d2bce6468f0c4d710963daf4938a25df860", "message": "DB-9846 unused imports removed", "committedDate": "2020-07-17T10:24:46Z", "type": "commit"}, {"oid": "92ca182000f6d82364c0dc911b0da24222011b02", "url": "https://github.com/splicemachine/spliceengine/commit/92ca182000f6d82364c0dc911b0da24222011b02", "message": "DB-9846 custom platform dependent class fix", "committedDate": "2020-07-17T10:34:10Z", "type": "commit"}, {"oid": "c8a5ecfbc4b744e43c2f8641df12111f2ec98dbc", "url": "https://github.com/splicemachine/spliceengine/commit/c8a5ecfbc4b744e43c2f8641df12111f2ec98dbc", "message": "DB-9846 SpotBugs annotations fixed", "committedDate": "2020-07-17T10:58:05Z", "type": "commit"}, {"oid": "068d12c34a3fe093932a2951a9ffc035f952a30c", "url": "https://github.com/splicemachine/spliceengine/commit/068d12c34a3fe093932a2951a9ffc035f952a30c", "message": "Merge branch 'master' into DB-9846", "committedDate": "2020-07-20T14:42:31Z", "type": "commit"}, {"oid": "0e35f0de3289511d208128853606eb0c68722699", "url": "https://github.com/splicemachine/spliceengine/commit/0e35f0de3289511d208128853606eb0c68722699", "message": "DB-9846 SpotBugs fixes", "committedDate": "2020-07-20T15:13:56Z", "type": "commit"}, {"oid": "5c083bcbf279f79a3a5b4a80dad95a24445f33cd", "url": "https://github.com/splicemachine/spliceengine/commit/5c083bcbf279f79a3a5b4a80dad95a24445f33cd", "message": "DB-9846 SpotBugs fixed 2", "committedDate": "2020-07-20T16:30:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDczODA1MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3852#discussion_r460738050", "bodyText": "for other reviewers: the difference between this file and e.g. hbase_sql/orc-spark-2.4/src/main/java/com/splicemachine/stream/output/ParquetWriterFactoryImpl.java is\n<         return encoder.createSerializer().apply(valueRow);\n---\n>         return encoder.toRow(valueRow);", "author": "martinrupp", "createdAt": "2020-07-27T08:45:39Z", "path": "hbase_sql/orc-spark-3.0/src/main/java/com/splicemachine/stream/output/ParquetWriterFactoryImpl.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Copyright (c) 2012 - 2020 Splice Machine, Inc.\n+ *\n+ * This file is part of Splice Machine.\n+ * Splice Machine is free software: you can redistribute it and/or modify it under the terms of the\n+ * GNU Affero General Public License as published by the Free Software Foundation, either\n+ * version 3, or (at your option) any later version.\n+ * Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Affero General Public License for more details.\n+ * You should have received a copy of the GNU Affero General Public License along with Splice Machine.\n+ * If not, see <http://www.gnu.org/licenses/>.\n+ *\n+ */\n+\n+package com.splicemachine.stream.output;\n+\n+import com.splicemachine.EngineDriver;\n+import com.splicemachine.db.impl.sql.execute.ValueRow;\n+import com.splicemachine.derby.stream.control.output.ParquetWriterFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapreduce.RecordWriter;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.parquet.hadoop.ParquetOutputFormat;\n+import org.apache.parquet.hadoop.metadata.CompressionCodecName;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder;\n+import org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport;\n+import org.apache.spark.sql.internal.SQLConf;\n+import org.apache.spark.sql.types.StructType;\n+\n+import java.io.IOException;\n+\n+public class ParquetWriterFactoryImpl implements ParquetWriterFactory{\n+    \n+    @Override\n+    public RecordWriter<Void, Object> getParquetRecordWriter(String location, String compression, StructType tableSchema) throws IOException, InterruptedException {\n+        ParquetWriteSupport pws = new ParquetWriteSupport();\n+        final Configuration conf = new Configuration((Configuration) EngineDriver.driver().getConfiguration().getConfigSource().unwrapDelegate());\n+        conf.set(SQLConf.PARQUET_WRITE_LEGACY_FORMAT().key(), \"false\");\n+        conf.set(SQLConf.PARQUET_OUTPUT_TIMESTAMP_TYPE().key(), \"INT96\");\n+        conf.set(SQLConf.PARQUET_INT96_AS_TIMESTAMP().key(), \"true\");\n+        conf.set(SQLConf.PARQUET_BINARY_AS_STRING().key(), \"false\");\n+\n+        pws.setSchema(tableSchema, conf);\n+        return new ParquetOutputFormat(new ParquetWriteSupport()) {\n+            @Override\n+            public Path getDefaultWorkFile(TaskAttemptContext context, String extension) throws IOException {\n+                return new Path(location+\"/part-r-00000\"+extension);\n+            }\n+\n+            @Override\n+            public RecordWriter<Void, Object> getRecordWriter(TaskAttemptContext taskAttemptContext)\n+                    throws IOException, InterruptedException {\n+\n+                CompressionCodecName codec;\n+                switch (compression) {\n+                    case \"none\":\n+                        codec = CompressionCodecName.UNCOMPRESSED;\n+                        break;\n+                    case \"snappy\":\n+                        codec = CompressionCodecName.SNAPPY;\n+                        break;\n+                    case \"lzo\":\n+                        codec = CompressionCodecName.LZO;\n+                        break;\n+                    case \"gzip\":\n+                    case \"zip\":\n+                        codec = CompressionCodecName.GZIP;\n+                        break;\n+                    default:\n+                        throw new IllegalArgumentException(\"Unknown compression: \" + compression);\n+                }\n+                String extension = codec.getExtension() + \".parquet\";\n+                Path file = getDefaultWorkFile(taskAttemptContext, extension);\n+                return getRecordWriter(conf, file, codec);\n+            }\n+        }.getRecordWriter(null);", "originalCommit": "5c083bcbf279f79a3a5b4a80dad95a24445f33cd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDc0MjE3Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3852#discussion_r460742172", "bodyText": "for other reviewers: underlying change here is that Spark2.4 uses encoder.toRow(valueRow); , while Spark3.0 uses return encoder.createSerializer().apply(valueRow); . see hbase_sql/orc-spark-3.0/src/main/java/com/splicemachine/stream/output/ParquetWriterFactoryImpl.java and 2.4", "author": "martinrupp", "createdAt": "2020-07-27T08:52:30Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/stream/control/ControlDataSet.java", "diffHunk": "@@ -591,7 +592,7 @@ public String getAttribute(String name) {\n                     ValueRow vr = (ValueRow) iterator.next();\n                     context.recordWrite();\n \n-                    rw.write(null, encoder.toRow(vr));\n+                    rw.write(null, ParquetWriterService.getFactory().encodeToRow(tableSchema, vr, encoder));", "originalCommit": "5c083bcbf279f79a3a5b4a80dad95a24445f33cd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "b03f5fa0de2ef60c1d1e26b630279b293f3767dd", "url": "https://github.com/splicemachine/spliceengine/commit/b03f5fa0de2ef60c1d1e26b630279b293f3767dd", "message": "master is merged into DB-9846", "committedDate": "2020-07-27T09:10:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2NTM0Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3852#discussion_r461165343", "bodyText": "Either isTraceEnabled() or debug().", "author": "OlegMazurov", "createdAt": "2020-07-27T20:57:32Z", "path": "hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java", "diffHunk": "@@ -161,8 +160,8 @@ public Object deserialize(Writable blob) throws SerDeException {\n      */\n     //@Override\n     public ObjectInspector getObjectInspector() throws SerDeException {\n-    \tif (Log.isDebugEnabled())\n-    \t\tSpliceLogUtils.trace(Log, \"getObjectInspector\");\n+    \tif (LOG.isDebugEnabled())", "originalCommit": "b03f5fa0de2ef60c1d1e26b630279b293f3767dd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b8d5712adaf41d1ecff02f8bfd76b62cc8488a0", "chunk": "diff --git a/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java b/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\nindex bb242f5bf5..3e4a354bd1 100644\n--- a/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\n+++ b/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\n\n@@ -160,7 +160,7 @@ public class SMSerDe extends AbstractSerDe {\n      */\n     //@Override\n     public ObjectInspector getObjectInspector() throws SerDeException {\n-    \tif (LOG.isDebugEnabled())\n+    \tif (LOG.isTraceEnabled())\n     \t\tSpliceLogUtils.trace(LOG, \"getObjectInspector\");\n         return rowOI;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE2NjQzMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3852#discussion_r461166431", "bodyText": "LOG.isDebugEnabled() -- the parameter is always computed even when debug logging is disabled", "author": "OlegMazurov", "createdAt": "2020-07-27T20:59:31Z", "path": "hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java", "diffHunk": "@@ -181,7 +180,7 @@ public SerDeStats getSerDeStats() {\n      */\n     //@Override\n     public Class<? extends Writable> getSerializedClass() {\n-        Log.debug(\"********\" + Thread.currentThread().getStackTrace()[1].getMethodName());\n+        LOG.debug(\"********\" + Thread.currentThread().getStackTrace()[1].getMethodName());", "originalCommit": "b03f5fa0de2ef60c1d1e26b630279b293f3767dd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b8d5712adaf41d1ecff02f8bfd76b62cc8488a0", "chunk": "diff --git a/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java b/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\nindex bb242f5bf5..3e4a354bd1 100644\n--- a/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\n+++ b/hbase_sql/src/main/java/com/splicemachine/mrio/api/hive/SMSerDe.java\n\n@@ -180,7 +180,8 @@ public class SMSerDe extends AbstractSerDe {\n      */\n     //@Override\n     public Class<? extends Writable> getSerializedClass() {\n-        LOG.debug(\"********\" + Thread.currentThread().getStackTrace()[1].getMethodName());\n+        if (LOG.isDebugEnabled())\n+            LOG.debug(\"********\" + Thread.currentThread().getStackTrace()[1].getMethodName());\n         return ExecRowWritable.class;\n     }\n \n"}}, {"oid": "393f9e8dd6765a5be2a194a74cac449d0db64aed", "url": "https://github.com/splicemachine/spliceengine/commit/393f9e8dd6765a5be2a194a74cac449d0db64aed", "message": "Merge branch 'master' into DB-9846", "committedDate": "2020-08-11T16:23:56Z", "type": "commit"}, {"oid": "a1d55d9f19d33e8ff537cd76db570bcca68f4b98", "url": "https://github.com/splicemachine/spliceengine/commit/a1d55d9f19d33e8ff537cd76db570bcca68f4b98", "message": "DB-9846 master merge conflict of custom platform dependent folder is fixed", "committedDate": "2020-08-11T16:30:59Z", "type": "commit"}, {"oid": "7b8d5712adaf41d1ecff02f8bfd76b62cc8488a0", "url": "https://github.com/splicemachine/spliceengine/commit/7b8d5712adaf41d1ecff02f8bfd76b62cc8488a0", "message": "DB-9846 PR trace/debug log calls optimized", "committedDate": "2020-08-12T08:13:29Z", "type": "commit"}, {"oid": "642113f25c624e6db684eead79d705e3509e7549", "url": "https://github.com/splicemachine/spliceengine/commit/642113f25c624e6db684eead79d705e3509e7549", "message": "DB-9846 PR comment for dependency is added", "committedDate": "2020-08-17T15:23:25Z", "type": "commit"}, {"oid": "f5c4932cb98107be2de3dafcfd5ef2204593d54d", "url": "https://github.com/splicemachine/spliceengine/commit/f5c4932cb98107be2de3dafcfd5ef2204593d54d", "message": "DB-9846 spark_3.0 profile is removed", "committedDate": "2020-08-18T12:53:16Z", "type": "commit"}, {"oid": "9c369d06c065eaebfebf0138608851467a796608", "url": "https://github.com/splicemachine/spliceengine/commit/9c369d06c065eaebfebf0138608851467a796608", "message": "Merge branch 'master' into DB-9846", "committedDate": "2020-08-18T13:46:20Z", "type": "commit"}, {"oid": "469e3b3993548988b269307a9fc81c239479c4ed", "url": "https://github.com/splicemachine/spliceengine/commit/469e3b3993548988b269307a9fc81c239479c4ed", "message": "Merge branch master into DB-9846", "committedDate": "2020-08-20T14:45:03Z", "type": "commit"}]}