{"pr_number": 4449, "pr_title": "DB-9556 DB-9586 NSDS v1 Column Names", "pr_createdAt": "2020-11-03T16:26:49Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/4449", "timeline": [{"oid": "a16dfbe5453916854c1c837e9fe0adf2c0ba8175", "url": "https://github.com/splicemachine/spliceengine/commit/a16dfbe5453916854c1c837e9fe0adf2c0ba8175", "message": "DB-9556 Using schema field names as column names. Qualifying duplicate field names.", "committedDate": "2020-11-03T16:22:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMTg1OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/4449#discussion_r516911859", "bodyText": "Do we need toUpperCase() here? It does not seem consistent with the subsequent HashSet logic, which honors case sensitivity.", "author": "yxia92", "createdAt": "2020-11-03T19:40:10Z", "path": "hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkUtils.java", "diffHunk": "@@ -224,19 +220,37 @@ public ExecRow call(ExecRow row) throws Exception {\n         SpliceBaseOperation operation = (SpliceBaseOperation) serverSideResultSet;\n         DataSetProcessor dsp = EngineDriver.driver().processorFactory().distributedProcessor();\n         DataSet<ExecRow> spliceDataSet = operation.getResultDataSet(dsp);\n-        if(spliceDataSet instanceof SparkDataSet) {\n-            JavaRDD<ExecRow> rdd = ((SparkDataSet)spliceDataSet).rdd;\n-            final ResultColumnDescriptor[] columns = serverSideResultSet.getResultDescription().getColumnInfo();\n-\n-            // Generate the schema based on the ResultColumnDescriptors\n-            List<StructField> fields = new ArrayList<>();\n+        \n+        final ResultColumnDescriptor[] columns = serverSideResultSet.getResultDescription().getColumnInfo();\n+        // Generate the schema based on the ResultColumnDescriptors\n+        List<StructField> fields = new ArrayList<>();\n+        for (ResultColumnDescriptor column : columns) {\n+            fields.add(column.getStructField());\n+        }\n+        if( fields.stream().map( f -> f.name().toUpperCase() ).distinct().count() != fields.size() ) {  // has duplicate names", "originalCommit": "a16dfbe5453916854c1c837e9fe0adf2c0ba8175", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1NzAyMQ==", "url": "https://github.com/splicemachine/spliceengine/pull/4449#discussion_r516957021", "bodyText": "I think I could leave that and change the HashSet uses to used.contains(name.toUpperCase()) and used.add(name.toUpperCase()).  I would also leave the case of the name passed to StructField unchanged.", "author": "jpanko1", "createdAt": "2020-11-03T21:09:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMTg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMDg2Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/4449#discussion_r517030863", "bodyText": "Thanks @jpanko1 ! We could have case sensitive column names. For example:\nsplice> create table t1 (\"a1\" int, \"A1\" int); \n0 rows inserted/updated/deleted\nELAPSED TIME = 19 milliseconds\nsplice> select * from t1;\na1         |A1         \n-----------------------\n\n0 rows selected\nELAPSED TIME = 28 milliseconds\n\nAfter the binding phase, all the regular column names should have already been in the UPPER case except for the case sensitive column names. With that consideration, should we remove the toUpperCase() call?", "author": "yxia92", "createdAt": "2020-11-04T00:22:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMTg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA4NTE3Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/4449#discussion_r517085172", "bodyText": "I see, thanks Yi!  I've removed toUpperCase().\nI also checked about case sensitivity in Spark and found that it can be set either way with a param: spark.sqlContext.setConf(\"spark.sql.caseSensitive\", \"true\").", "author": "jpanko1", "createdAt": "2020-11-04T04:00:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMTg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA5NTI2NA==", "url": "https://github.com/splicemachine/spliceengine/pull/4449#discussion_r517095264", "bodyText": "Thanks @jpanko1 for checking!", "author": "yxia92", "createdAt": "2020-11-04T04:46:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxMTg1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "02547d45c79cc8e134baa8c5113fe0aa2c4cbb0c", "chunk": "diff --git a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkUtils.java b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkUtils.java\nindex 39be0f8317..a144c6190c 100644\n--- a/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkUtils.java\n+++ b/hbase_sql/src/main/java/com/splicemachine/derby/stream/spark/SparkUtils.java\n\n@@ -227,7 +227,7 @@ public class SparkUtils {\n         for (ResultColumnDescriptor column : columns) {\n             fields.add(column.getStructField());\n         }\n-        if( fields.stream().map( f -> f.name().toUpperCase() ).distinct().count() != fields.size() ) {  // has duplicate names\n+        if( fields.stream().map( f -> f.name() ).distinct().count() != fields.size() ) {  // has duplicate names\n             fields = new ArrayList<>();\n             Set<String> used = new HashSet<>();\n             for (ResultColumnDescriptor column : columns) {\n"}}, {"oid": "02547d45c79cc8e134baa8c5113fe0aa2c4cbb0c", "url": "https://github.com/splicemachine/spliceengine/commit/02547d45c79cc8e134baa8c5113fe0aa2c4cbb0c", "message": "DB-9556 Made duplicate field name check case sensitive.", "committedDate": "2020-11-04T03:43:50Z", "type": "commit"}]}