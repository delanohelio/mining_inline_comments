{"pr_number": 1397, "pr_title": "LUCENE-9304: Refactor DWPTPool to pool DWPT directly", "pr_createdAt": "2020-04-02T20:25:43Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1397", "timeline": [{"oid": "7a31eee3ce8601708765f15756752587ec27979d", "url": "https://github.com/apache/lucene-solr/commit/7a31eee3ce8601708765f15756752587ec27979d", "message": "first cut", "committedDate": "2020-03-26T18:03:01Z", "type": "commit"}, {"oid": "154f585d4b12b77554ae1ac4e0654adcc1de4fa7", "url": "https://github.com/apache/lucene-solr/commit/154f585d4b12b77554ae1ac4e0654adcc1de4fa7", "message": "roll back to LIFO picking of DWPT", "committedDate": "2020-03-26T19:24:06Z", "type": "commit"}, {"oid": "3238801920166f1b71b6ef69173261c99db2b67b", "url": "https://github.com/apache/lucene-solr/commit/3238801920166f1b71b6ef69173261c99db2b67b", "message": "second step", "committedDate": "2020-04-01T21:59:59Z", "type": "commit"}, {"oid": "66e4bac3b080fdd520bd695381306d5152427ff3", "url": "https://github.com/apache/lucene-solr/commit/66e4bac3b080fdd520bd695381306d5152427ff3", "message": "more cleanups", "committedDate": "2020-04-02T10:42:13Z", "type": "commit"}, {"oid": "da33df7efee1c59754f5e785f0d9210979f8db25", "url": "https://github.com/apache/lucene-solr/commit/da33df7efee1c59754f5e785f0d9210979f8db25", "message": "cleanups", "committedDate": "2020-04-02T14:57:44Z", "type": "commit"}, {"oid": "3caaee6dda0baca38961034602e8f6b90351b57b", "url": "https://github.com/apache/lucene-solr/commit/3caaee6dda0baca38961034602e8f6b90351b57b", "message": "Merge branch 'master' into pick_smallest_dwpt", "committedDate": "2020-04-02T18:30:22Z", "type": "commit"}, {"oid": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "url": "https://github.com/apache/lucene-solr/commit/bd82f3193542de94f4c49726c3054c1fbe97e6c3", "message": "minor changes", "committedDate": "2020-04-02T20:11:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU4ODg5Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r402588893", "bodyText": "@mikemccand can you take a look at this please", "author": "s1monw", "createdAt": "2020-04-02T20:26:27Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -322,35 +316,27 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortThreadState(final ThreadState perThread) throws IOException {\n+  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n-    if (perThread.isInitialized()) { \n-      try {\n-        int abortedDocCount = perThread.dwpt.getNumDocsInRAM();\n-        subtractFlushedNumDocs(abortedDocCount);\n-        perThread.dwpt.abort();\n-        return abortedDocCount;\n-      } finally {\n-        flushControl.doOnAbort(perThread);\n-      }\n-    } else {\n+    try {\n+      int abortedDocCount = perThread.getNumDocsInRAM();\n+      subtractFlushedNumDocs(abortedDocCount);\n+      perThread.abort();\n+      return abortedDocCount;\n+    } finally {\n       flushControl.doOnAbort(perThread);\n-      // This DWPT was never initialized so it has no indexed documents:\n-      return 0;\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n   public long getMaxCompletedSequenceNumber() {\n-    long value = lastSeqNo;\n-    int limit = perThreadPool.getMaxThreadStates();\n-    for(int i = 0; i < limit; i++) {\n-      ThreadState perThread = perThreadPool.getThreadState(i);\n-      value = Math.max(value, perThread.lastSeqNo);\n-    }\n-    return value;\n+    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMDUwMg==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403700502", "bodyText": "Will do :)", "author": "mikemccand", "createdAt": "2020-04-05T13:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU4ODg5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMyMzk4MQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404323981", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-04-06T19:08:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU4ODg5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "06e746931bad2e0a17c4291786d264813116d643", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\nindex 45eaa3778b6..965c10d87d0 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n\n@@ -316,23 +319,18 @@ final class DocumentsWriter implements Closeable, Accountable {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n+  private void abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n     try {\n-      int abortedDocCount = perThread.getNumDocsInRAM();\n-      subtractFlushedNumDocs(abortedDocCount);\n+      subtractFlushedNumDocs(perThread.getNumDocsInRAM());\n       perThread.abort();\n-      return abortedDocCount;\n     } finally {\n       flushControl.doOnAbort(perThread);\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n-  public long getMaxCompletedSequenceNumber() {\n-    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/\n-    // Returning the last seqNum is as good as the way we had before IMO. I tried to figure out why this is better but\n-    // failed.\n+  long getMaxCompletedSequenceNumber() {\n     return deleteQueue.getLastSequenceNumber();\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTQ4Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701483", "bodyText": "s/event/even?", "author": "mikemccand", "createdAt": "2020-04-05T13:24:08Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -59,21 +58,25 @@\n  * Threads:\n  *\n  * Multiple threads are allowed into addDocument at once.\n- * There is an initial synchronized call to getThreadState\n- * which allocates a ThreadState for this thread.  The same\n- * thread will get the same ThreadState over time (thread\n- * affinity) so that if there are consistent patterns (for\n- * example each thread is indexing a different content\n- * source) then we make better use of RAM.  Then\n- * processDocument is called on that ThreadState without\n+ * There is an initial synchronized call to\n+ * {@link DocumentsWriterFlushControl#obtainAndLock()}\n+ * which allocates a DWPT for this indexing thread. The same\n+ * thread will not necessarily get the same DWPT over time.\n+ * Then updateDocuments is called on that DWPT without\n  * synchronization (most of the \"heavy lifting\" is in this\n- * call).  Finally the synchronized \"finishDocument\" is\n- * called to flush changes to the directory.\n+ * call). Once a DWPT fills up enough RAM or hold enough\n+ * documents in memory the DWPT is checked out for flush\n+ * and all changes are written to the directory. Each DWPT\n+ * corresponds to one segment being written.\n  *\n- * When flush is called by IndexWriter we forcefully idle\n- * all threads and flush only once they are all idle.  This\n- * means you can call flush with a given thread even while\n- * other threads are actively adding/deleting documents.\n+ * When flush is called by IndexWriter we check out all DWPTs\n+ * that are associated with the current {@link DocumentsWriterDeleteQueue}\n+ * out of the {@link DocumentsWriterPerThreadPool} and write\n+ * them to disk. The flush process can piggy-back on incoming\n+ * indexing threads or event block them from adding documents", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\nindex 45eaa3778b6..581828b880d 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n\n@@ -73,7 +73,7 @@ import org.apache.lucene.util.InfoStream;\n  * that are associated with the current {@link DocumentsWriterDeleteQueue}\n  * out of the {@link DocumentsWriterPerThreadPool} and write\n  * them to disk. The flush process can piggy-back on incoming\n- * indexing threads or event block them from adding documents\n+ * indexing threads or even block them from adding documents\n  * if flushing can't keep up with new documents being added.\n  * Unless the stall control kicks in to block indexing threads\n  * flushes are happening concurrently to actual index requests.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTY5OQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701699", "bodyText": "Isn't writer still an empty list here?  Oh I see, we are creating a lambda and only using it below, after we've added things to writer, OK.", "author": "mikemccand", "createdAt": "2020-04-05T13:26:04Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -273,33 +269,31 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n         pendingNumDocs.addAndGet(-ticket.getFlushedSegment().segmentInfo.info.maxDoc());\n       }\n     });\n-    List<ThreadState> threadStates = new ArrayList<>();\n+    List<DocumentsWriterPerThread> writer = new ArrayList<>();\n     AtomicBoolean released = new AtomicBoolean(false);\n     final Closeable release = () -> {\n       if (released.compareAndSet(false, true)) { // only once\n         if (infoStream.isEnabled(\"DW\")) {\n           infoStream.message(\"DW\", \"unlockAllAbortedThread\");\n         }\n-        perThreadPool.unlockNewThreadStates();\n-        for (ThreadState state : threadStates) {\n+        perThreadPool.unlockNewWriters();\n+        for (DocumentsWriterPerThread state : writer) {", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzgxNDE5Ng==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403814196", "bodyText": "It might be less confusing if we reassign the release inside the try clause after acquiring DWPTs. Also nits: writer -> writers and state -> writer.", "author": "dnhatn", "createdAt": "2020-04-06T03:41:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTY5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk0NjQxNQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403946415", "bodyText": "unfortunately we can't assign this later otherwise the ref can't be final. I will leave a comment.", "author": "s1monw", "createdAt": "2020-04-06T09:20:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTY5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\nindex 45eaa3778b6..581828b880d 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n\n@@ -269,24 +269,27 @@ final class DocumentsWriter implements Closeable, Accountable {\n         pendingNumDocs.addAndGet(-ticket.getFlushedSegment().segmentInfo.info.maxDoc());\n       }\n     });\n-    List<DocumentsWriterPerThread> writer = new ArrayList<>();\n+    List<DocumentsWriterPerThread> writers = new ArrayList<>();\n     AtomicBoolean released = new AtomicBoolean(false);\n     final Closeable release = () -> {\n+      // we return this closure to unlock all writers once done\n+      // or if hit an exception below in the try block.\n+      // we can't assign this later otherwise the ref can't be final\n       if (released.compareAndSet(false, true)) { // only once\n         if (infoStream.isEnabled(\"DW\")) {\n           infoStream.message(\"DW\", \"unlockAllAbortedThread\");\n         }\n         perThreadPool.unlockNewWriters();\n-        for (DocumentsWriterPerThread state : writer) {\n-          state.unlock();\n+        for (DocumentsWriterPerThread writer : writers) {\n+          writer.unlock();\n         }\n       }\n     };\n     try {\n       deleteQueue.clear();\n       perThreadPool.lockNewWriters();\n-      writer.addAll(perThreadPool.filterAndLock(x -> true));\n-      for (final DocumentsWriterPerThread perThread : writer) {\n+      writers.addAll(perThreadPool.filterAndLock(x -> true));\n+      for (final DocumentsWriterPerThread perThread : writers) {\n         assert perThread.isHeldByCurrentThread();\n         abortDocumentsWriterPerThread(perThread);\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTk1NA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403701954", "bodyText": "I left a (non-review) comment on the single commit about this.\nI think it's a good tradeoff?  Instead of making each indexing op compute max to save lastSeqNo, we are making caller of this API do the legwork.  I think it's a fair tradeoff since likely this API is very rarely called, but indexing ops are very often called.", "author": "mikemccand", "createdAt": "2020-04-05T13:28:36Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java", "diffHunk": "@@ -322,35 +316,27 @@ synchronized Closeable lockAndAbortAll() throws IOException {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortThreadState(final ThreadState perThread) throws IOException {\n+  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n-    if (perThread.isInitialized()) { \n-      try {\n-        int abortedDocCount = perThread.dwpt.getNumDocsInRAM();\n-        subtractFlushedNumDocs(abortedDocCount);\n-        perThread.dwpt.abort();\n-        return abortedDocCount;\n-      } finally {\n-        flushControl.doOnAbort(perThread);\n-      }\n-    } else {\n+    try {\n+      int abortedDocCount = perThread.getNumDocsInRAM();\n+      subtractFlushedNumDocs(abortedDocCount);\n+      perThread.abort();\n+      return abortedDocCount;\n+    } finally {\n       flushControl.doOnAbort(perThread);\n-      // This DWPT was never initialized so it has no indexed documents:\n-      return 0;\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n   public long getMaxCompletedSequenceNumber() {\n-    long value = lastSeqNo;\n-    int limit = perThreadPool.getMaxThreadStates();\n-    for(int i = 0; i < limit; i++) {\n-      ThreadState perThread = perThreadPool.getThreadState(i);\n-      value = Math.max(value, perThread.lastSeqNo);\n-    }\n-    return value;\n+    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/\n+    // Returning the last seqNum is as good as the way we had before IMO. I tried to figure out why this is better but\n+    // failed.", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA2ODkxMw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404068913", "bodyText": "hmm, I am not sure I understand fully. You mean the way it used to be was a good tradeoff? Currently there is no extra work done after my change, I am struggeling to understand why you made the chance in the first place. To me it's equivalent and no tests are failing.", "author": "s1monw", "createdAt": "2020-04-06T12:57:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTk1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc5NjMyNQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404796325", "bodyText": "I am saying your change is the better tradeoff than the way it was before.", "author": "mikemccand", "createdAt": "2020-04-07T13:11:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTk1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMyNTYwMQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r405325601", "bodyText": "cool thanks for clarifying", "author": "s1monw", "createdAt": "2020-04-08T07:51:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTk1NA=="}], "type": "inlineReview", "revised_code": {"commit": "06e746931bad2e0a17c4291786d264813116d643", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\nindex 45eaa3778b6..965c10d87d0 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriter.java\n\n@@ -316,23 +319,18 @@ final class DocumentsWriter implements Closeable, Accountable {\n   }\n   \n   /** Returns how many documents were aborted. */\n-  private int abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n+  private void abortDocumentsWriterPerThread(final DocumentsWriterPerThread perThread) throws IOException {\n     assert perThread.isHeldByCurrentThread();\n     try {\n-      int abortedDocCount = perThread.getNumDocsInRAM();\n-      subtractFlushedNumDocs(abortedDocCount);\n+      subtractFlushedNumDocs(perThread.getNumDocsInRAM());\n       perThread.abort();\n-      return abortedDocCount;\n     } finally {\n       flushControl.doOnAbort(perThread);\n     }\n   }\n \n   /** returns the maximum sequence number for all previously completed operations */\n-  public long getMaxCompletedSequenceNumber() {\n-    // NOCOMMIT: speak to mikemccandless about this change https://github.com/apache/lucene-solr/commit/5a03216/\n-    // Returning the last seqNum is as good as the way we had before IMO. I tried to figure out why this is better but\n-    // failed.\n+  long getMaxCompletedSequenceNumber() {\n     return deleteQueue.getLastSequenceNumber();\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjY5Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702693", "bodyText": "Is it intentional that we are unlocking next even after returning it from checkOutForFlush(next)?  Shouldn't it remain locked until flush finishes?", "author": "mikemccand", "createdAt": "2020-04-05T13:34:18Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -380,52 +368,35 @@ DocumentsWriterPerThread nextPendingFlush() {\n       fullFlush = this.fullFlush;\n       numPending = this.numPending;\n     }\n-    if (numPending > 0 && !fullFlush) { // don't check if we are doing a full flush\n-      final int limit = perThreadPool.getActiveThreadStateCount();\n-      for (int i = 0; i < limit && numPending > 0; i++) {\n-        final ThreadState next = perThreadPool.getThreadState(i);\n-        if (next.flushPending) {\n-          final DocumentsWriterPerThread dwpt = tryCheckoutForFlush(next);\n-          if (dwpt != null) {\n-            return dwpt;\n+    if (numPending > 0 && fullFlush == false) { // don't check if we are doing a full flush\n+      for (final DocumentsWriterPerThread next : perThreadPool) {\n+        if (next.isFlushPending()) {\n+          if (next.tryLock()) {\n+            try {\n+              if (perThreadPool.isRegistered(next)) {\n+                return checkOutForFlush(next);\n+              }\n+            } finally {\n+              next.unlock();", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA2ODE5NA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404068194", "bodyText": "so far it's intentional that we are checking out the DWPT of the pool and unlock it. The reason is that others might block on it to check it out as well but then won't succeed since it's not part of the pool anymore. I can take another iteration here and make sure it's locked until flushed. I wonder if we should do this after the fact.", "author": "s1monw", "createdAt": "2020-04-06T12:56:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc5Njk1OA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404796958", "bodyText": "I was just worried that unlocking on return was not intended -- sometimes people think finally clauses are not executed on return ;)\nIf it is intentional that's great.", "author": "mikemccand", "createdAt": "2020-04-07T13:12:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgxMzc2MA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404813760", "bodyText": "I think this should release again. The way of use of finally here is my favourite use of finally. You can make very elegant methods body's with returns and still have finally executed.", "author": "uschindler", "createdAt": "2020-04-07T13:35:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjY5Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjg0Ng==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702846", "bodyText": "Woohoo!", "author": "mikemccand", "createdAt": "2020-04-05T13:35:40Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -543,59 +506,53 @@ long markForFullFlush() {\n   }\n   \n   private boolean assertActiveDeleteQueue(DocumentsWriterDeleteQueue queue) {\n-    final int limit = perThreadPool.getActiveThreadStateCount();\n-    for (int i = 0; i < limit; i++) {\n-      final ThreadState next = perThreadPool.getThreadState(i);\n-      next.lock();\n-      try {\n-        assert !next.isInitialized() || next.dwpt.deleteQueue == queue : \"isInitialized: \" + next.isInitialized() + \" numDocs: \" + (next.isInitialized() ? next.dwpt.getNumDocsInRAM() : 0) ;\n-      } finally {\n-        next.unlock();\n-      }\n+    for (final DocumentsWriterPerThread next : perThreadPool) {\n+        assert next.deleteQueue == queue : \"numDocs: \" + next.getNumDocsInRAM();\n     }\n     return true;\n   }\n \n   private final List<DocumentsWriterPerThread> fullFlushBuffer = new ArrayList<>();\n \n-  void addFlushableState(ThreadState perThread) {\n+  void addFlushableDWPT(DocumentsWriterPerThread dwpt) {\n     if (infoStream.isEnabled(\"DWFC\")) {\n-      infoStream.message(\"DWFC\", \"addFlushableState \" + perThread.dwpt);\n+      infoStream.message(\"DWFC\", \"addFlushableDWPT \" + dwpt);\n     }\n-    final DocumentsWriterPerThread dwpt = perThread.dwpt;\n-    assert perThread.isHeldByCurrentThread();\n-    assert perThread.isInitialized();\n+    assert dwpt.isHeldByCurrentThread();\n     assert fullFlush;\n     assert dwpt.deleteQueue != documentsWriter.deleteQueue;\n+    assert perThreadPool.isRegistered(dwpt);\n     if (dwpt.getNumDocsInRAM() > 0) {\n       synchronized(this) {\n-        if (!perThread.flushPending) {\n-          setFlushPending(perThread);\n+        if (dwpt.isFlushPending() == false) {", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk5NzkyNQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403997925", "bodyText": "<3", "author": "s1monw", "createdAt": "2020-04-06T10:48:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjg0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\nindex 3b9ae33332c..4b381d0359f 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n\n@@ -498,8 +526,8 @@ final class DocumentsWriterFlushControl implements Accountable, Closeable {\n       pruneBlockedQueue(flushingQueue);   \n       assert assertBlockedFlushes(documentsWriter.deleteQueue);\n       flushQueue.addAll(fullFlushBuffer);\n-      fullFlushBuffer.clear();\n       updateStallState();\n+      fullFlushMarkDone = true; // at this point we must have collected all DWPTs that belong to the old delete queue\n     }\n     assert assertActiveDeleteQueue(documentsWriter.deleteQueue);\n     return seqNo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMjk4Ng==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403702986", "bodyText": "Hmm why would we ever have nextRam > 0 but next.getNumDocsInRAM() == ?", "author": "mikemccand", "createdAt": "2020-04-05T13:37:06Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -717,51 +664,49 @@ public InfoStream getInfoStream() {\n     return infoStream;\n   }\n \n-  synchronized ThreadState findLargestNonPendingWriter() {\n-    ThreadState maxRamUsingThreadState = null;\n+  synchronized DocumentsWriterPerThread findLargestNonPendingWriter() {\n+    DocumentsWriterPerThread maxRamUsingWriter = null;\n     long maxRamSoFar = 0;\n-    Iterator<ThreadState> activePerThreadsIterator = allActiveThreadStates();\n+    Iterator<DocumentsWriterPerThread> activePerThreadsIterator = perThreadPool.iterator();\n     int count = 0;\n     while (activePerThreadsIterator.hasNext()) {\n-      ThreadState next = activePerThreadsIterator.next();\n-      if (!next.flushPending) {\n-        final long nextRam = next.bytesUsed;\n-        if (nextRam > 0 && next.dwpt.getNumDocsInRAM() > 0) {\n+      DocumentsWriterPerThread next = activePerThreadsIterator.next();\n+      if (!next.isFlushPending()) {\n+        final long nextRam = next.bytesUsed();\n+        if (nextRam > 0 && next.getNumDocsInRAM() > 0) {", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "163a839ca134326ae268735b3549fab7c1bcf417", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\nindex 3b9ae33332c..2c1a9358187 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n\n@@ -667,21 +668,17 @@ final class DocumentsWriterFlushControl implements Accountable, Closeable {\n   synchronized DocumentsWriterPerThread findLargestNonPendingWriter() {\n     DocumentsWriterPerThread maxRamUsingWriter = null;\n     long maxRamSoFar = 0;\n-    Iterator<DocumentsWriterPerThread> activePerThreadsIterator = perThreadPool.iterator();\n     int count = 0;\n-    while (activePerThreadsIterator.hasNext()) {\n-      DocumentsWriterPerThread next = activePerThreadsIterator.next();\n-      if (!next.isFlushPending()) {\n+    for (DocumentsWriterPerThread next : perThreadPool) {\n+      if (next.isFlushPending() == false && next.getNumDocsInRAM() > 0) {\n         final long nextRam = next.bytesUsed();\n-        if (nextRam > 0 && next.getNumDocsInRAM() > 0) {\n-          if (infoStream.isEnabled(\"FP\")) {\n-            infoStream.message(\"FP\", \"thread state has \" + nextRam + \" bytes; docInRAM=\" + next.getNumDocsInRAM());\n-          }\n-          count++;\n-          if (nextRam > maxRamSoFar) {\n-            maxRamSoFar = nextRam;\n-            maxRamUsingWriter = next;\n-          }\n+        if (infoStream.isEnabled(\"FP\")) {\n+          infoStream.message(\"FP\", \"thread state has \" + nextRam + \" bytes; docInRAM=\" + next.getNumDocsInRAM());\n+        }\n+        count++;\n+        if (nextRam > maxRamSoFar) {\n+          maxRamSoFar = nextRam;\n+          maxRamUsingWriter = next;\n         }\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzY4OA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703688", "bodyText": "s/DWPTs/DPWT's", "author": "mikemccand", "createdAt": "2020-04-05T13:42:43Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\nindex c0d77b67555..73b64f05f7a 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n\n@@ -654,7 +654,7 @@ final class DocumentsWriterPerThread {\n   }\n \n   /**\n-   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * Acquires the DWPT's lock only if it is not held by another thread at the time\n    * of invocation.\n    * @return true if the lock was acquired.\n    * @see ReentrantLock#tryLock()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzcxOA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703718", "bodyText": "s/DWPTs/DWPT's", "author": "mikemccand", "createdAt": "2020-04-05T13:42:57Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * of invocation.\n+   * @return true if the lock was acquired.\n+   * @see ReentrantLock#tryLock()\n+   */\n+  boolean tryLock() {\n+    return lock.tryLock();\n+  }\n+\n+  /**\n+   * Returns true if the DWPTs lock is held by the current thread", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\nindex c0d77b67555..73b64f05f7a 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n\n@@ -654,7 +654,7 @@ final class DocumentsWriterPerThread {\n   }\n \n   /**\n-   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * Acquires the DWPT's lock only if it is not held by another thread at the time\n    * of invocation.\n    * @return true if the lock was acquired.\n    * @see ReentrantLock#tryLock()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzczMA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703730", "bodyText": "Here too.", "author": "mikemccand", "createdAt": "2020-04-05T13:43:06Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -600,5 +608,81 @@ public String toString() {\n       + \", segment=\" + (segmentInfo != null ? segmentInfo.name : \"null\") + \", aborted=\" + aborted + \", numDocsInRAM=\"\n         + numDocsInRAM + \", deleteQueue=\" + deleteQueue + \"]\";\n   }\n-  \n+\n+\n+  /**\n+   * Returns true iff this DWPT is marked as flush pending\n+   */\n+  boolean isFlushPending() {\n+    return flushPending.get() == Boolean.TRUE;\n+  }\n+\n+  /**\n+   * Sets this DWPT as flush pending. This can only be set once.\n+   */\n+  void setFlushPending() {\n+    flushPending.set(Boolean.TRUE);\n+  }\n+\n+\n+  /**\n+   * Returns the last committed bytes for this DWPT. This method can be called\n+   * without acquiring the DWPTs lock.\n+   */\n+  long getLastCommittedBytesUsed() {\n+    return lastCommittedBytesUsed;\n+  }\n+\n+  /**\n+   * Commits the current {@link #bytesUsed()} and stores it's value for later reuse.\n+   * The last committed bytes used can be retrieved via {@link #getLastCommittedBytesUsed()}\n+   * @return the delta between the current {@link #bytesUsed()} and the current {@link #getLastCommittedBytesUsed()}\n+   */\n+  long commitLastBytesUsed() {\n+    assert isHeldByCurrentThread();\n+    long delta = bytesUsed() - lastCommittedBytesUsed;\n+    lastCommittedBytesUsed += delta;\n+    return delta;\n+  }\n+\n+  /**\n+   * Locks this DWPT for exclusive access.\n+   * @see ReentrantLock#lock()\n+   */\n+  void lock() {\n+    lock.lock();\n+  }\n+\n+  /**\n+   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * of invocation.\n+   * @return true if the lock was acquired.\n+   * @see ReentrantLock#tryLock()\n+   */\n+  boolean tryLock() {\n+    return lock.tryLock();\n+  }\n+\n+  /**\n+   * Returns true if the DWPTs lock is held by the current thread\n+   * @see ReentrantLock#isHeldByCurrentThread()\n+   */\n+  boolean isHeldByCurrentThread() {\n+    return lock.isHeldByCurrentThread();\n+  }\n+\n+  /**\n+   * Unlocks the DWPTs lock", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\nindex c0d77b67555..73b64f05f7a 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n\n@@ -654,7 +654,7 @@ final class DocumentsWriterPerThread {\n   }\n \n   /**\n-   * Acquires the DWPTs lock only if it is not held by another thread at the time\n+   * Acquires the DWPT's lock only if it is not held by another thread at the time\n    * of invocation.\n    * @return true if the lock was acquired.\n    * @see ReentrantLock#tryLock()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzg3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403703871", "bodyText": "Woo hoo!  I always thought it was kinda spooky that we were subclassing ReentrantLock instead of \"hasa\" that this change is switching to!", "author": "mikemccand", "createdAt": "2020-04-05T13:44:02Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk5ODQ3Ng==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403998476", "bodyText": "yeah ++", "author": "s1monw", "createdAt": "2020-04-06T10:49:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMzg3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "81bd46e212359bcacd99fdcef09ffd9140776a00", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\nindex 1c1227a7cc3..7b4c9917b3c 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n\n@@ -18,8 +18,10 @@ package org.apache.lucene.index;\n \n import java.io.Closeable;\n import java.io.IOException;\n+import java.util.ArrayDeque;\n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.Deque;\n import java.util.IdentityHashMap;\n import java.util.Iterator;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNDY1NQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403704655", "bodyText": "= 0 isn't needed -- it's Java's default already.", "author": "mikemccand", "createdAt": "2020-04-05T13:50:29Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java", "diffHunk": "@@ -156,6 +158,9 @@ void abort() throws IOException{\n   final BufferedUpdates pendingUpdates;\n   final SegmentInfo segmentInfo;     // Current segment we are working on\n   private boolean aborted = false;   // True if we aborted\n+  private SetOnce<Boolean> flushPending = new SetOnce<>();\n+  private volatile long lastCommittedBytesUsed = 0;", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDAwMzkxOQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404003919", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-04-06T10:59:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNDY1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\nindex c0d77b67555..73b64f05f7a 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread.java\n\n@@ -159,7 +159,7 @@ final class DocumentsWriterPerThread {\n   final SegmentInfo segmentInfo;     // Current segment we are working on\n   private boolean aborted = false;   // True if we aborted\n   private SetOnce<Boolean> flushPending = new SetOnce<>();\n-  private volatile long lastCommittedBytesUsed = 0;\n+  private volatile long lastCommittedBytesUsed;\n   private SetOnce<Boolean> hasFlushed = new SetOnce<>();\n \n   private final FieldInfos.Builder fieldInfos;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNDg0Ng==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403704846", "bodyText": "s/sine/since", "author": "mikemccand", "createdAt": "2020-04-05T13:51:59Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -458,74 +429,66 @@ public void setApplyAllDeletes() {\n     flushDeletes.set(true);\n   }\n   \n-  ThreadState obtainAndLock() {\n-    final ThreadState perThread = perThreadPool.getAndLock();\n-    boolean success = false;\n-    try {\n-      if (perThread.isInitialized() && perThread.dwpt.deleteQueue != documentsWriter.deleteQueue) {\n-        // There is a flush-all in process and this DWPT is\n-        // now stale -- enroll it for flush and try for\n-        // another DWPT:\n-        addFlushableState(perThread);\n-      }\n-      success = true;\n-      // simply return the ThreadState even in a flush all case sine we already hold the lock\n-      return perThread;\n-    } finally {\n-      if (!success) { // make sure we unlock if this fails\n-        perThreadPool.release(perThread);\n+  DocumentsWriterPerThread obtainAndLock() throws IOException {\n+    do {\n+      final DocumentsWriterPerThread perThread = perThreadPool.getAndLock();\n+      boolean unlock = true;\n+      try {\n+        if (perThread.deleteQueue != documentsWriter.deleteQueue) {\n+          // There is a flush-all in process and this DWPT is\n+          // now stale -- enroll it for flush and try for\n+          // another DWPT:\n+          addFlushableDWPT(perThread);\n+        } else {\n+          unlock = false;\n+          // simply return the DWPT even in a flush all case sine we already hold the lock", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\nindex 3b9ae33332c..f59da171823 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n\n@@ -441,7 +441,7 @@ final class DocumentsWriterFlushControl implements Accountable, Closeable {\n           addFlushableDWPT(perThread);\n         } else {\n           unlock = false;\n-          // simply return the DWPT even in a flush all case sine we already hold the lock\n+          // simply return the DWPT even in a flush all case sicne we already hold the lock\n           return perThread;\n         }\n       } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzc1MTUyOQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403751529", "bodyText": "unrelated change?", "author": "dnhatn", "createdAt": "2020-04-05T20:16:35Z", "path": "lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java", "diffHunk": "@@ -3774,6 +3768,9 @@ public void testRefreshAndRollbackConcurrently() throws Exception {\n       stopped.set(true);\n       indexer.join();\n       refresher.join();\n+      if (w.getTragicException() != null) {\n+        w.getTragicException().printStackTrace();", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDAwMTk2Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404001963", "bodyText": "yeah I ran into this multiple times. I fixed it for real this time.", "author": "s1monw", "createdAt": "2020-04-06T10:55:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzc1MTUyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java\nindex 924ad9a0ce7..0225f1eed9a 100644\n--- a/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java\n+++ b/lucene/core/src/test/org/apache/lucene/index/TestIndexWriter.java\n\n@@ -3768,10 +3770,19 @@ public class TestIndexWriter extends LuceneTestCase {\n       stopped.set(true);\n       indexer.join();\n       refresher.join();\n-      if (w.getTragicException() != null) {\n-        w.getTragicException().printStackTrace();\n-      }\n-      assertNull(\"should not consider ACE a tragedy on a closed IW\", w.getTragicException());\n+      Throwable e = w.getTragicException();\n+      IOSupplier<String> supplier = () -> {\n+        if (e != null) {\n+          StringWriter writer = new StringWriter();\n+          try (PrintWriter printWriter = new PrintWriter(writer)) {\n+            e.printStackTrace(printWriter);\n+          }\n+          return writer.toString();\n+        } else {\n+          return \"\";\n+        }\n+      };\n+      assertNull(\"should not consider ACE a tragedy on a closed IW: \" + supplier.get(), w.getTragicException());\n       IOUtils.close(sm, dir);\n     }\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzgxMjE5OQ==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r403812199", "bodyText": "state -> dwpt or perThread?", "author": "dnhatn", "createdAt": "2020-04-06T03:31:10Z", "path": "lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java", "diffHunk": "@@ -52,38 +50,38 @@\n \n   /**\n    * Called for each delete term. If this is a delete triggered due to an update\n-   * the given {@link ThreadState} is non-null.\n+   * the given {@link DocumentsWriterPerThread} is non-null.\n    * <p>\n    * Note: This method is called synchronized on the given\n    * {@link DocumentsWriterFlushControl} and it is guaranteed that the calling\n-   * thread holds the lock on the given {@link ThreadState}\n+   * thread holds the lock on the given {@link DocumentsWriterPerThread}\n    */\n   public abstract void onDelete(DocumentsWriterFlushControl control,\n-      ThreadState state);\n+                                DocumentsWriterPerThread state);", "originalCommit": "bd82f3193542de94f4c49726c3054c1fbe97e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDAwMzI3OA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404003278", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-04-06T10:58:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzgxMjE5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java b/lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java\nindex c0c27f30dfc..71402490afd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/FlushPolicy.java\n\n@@ -57,7 +57,7 @@ abstract class FlushPolicy {\n    * thread holds the lock on the given {@link DocumentsWriterPerThread}\n    */\n   public abstract void onDelete(DocumentsWriterFlushControl control,\n-                                DocumentsWriterPerThread state);\n+                                DocumentsWriterPerThread perThread);\n \n   /**\n    * Called for each document update on the given {@link DocumentsWriterPerThread}'s\n"}}, {"oid": "fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "url": "https://github.com/apache/lucene-solr/commit/fa8291ea6c9e8f1b9692aa1e308ae5288bdef912", "message": "address review comments", "committedDate": "2020-04-06T12:58:01Z", "type": "commit"}, {"oid": "06e746931bad2e0a17c4291786d264813116d643", "url": "https://github.com/apache/lucene-solr/commit/06e746931bad2e0a17c4291786d264813116d643", "message": "remove nocommit", "committedDate": "2020-04-06T13:06:44Z", "type": "commit"}, {"oid": "3b64ceabded6e9cab2bde69b4de196eff482c6ed", "url": "https://github.com/apache/lucene-solr/commit/3b64ceabded6e9cab2bde69b4de196eff482c6ed", "message": "Merge branch 'master' into pick_smallest_dwpt", "committedDate": "2020-04-06T19:08:57Z", "type": "commit"}, {"oid": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "url": "https://github.com/apache/lucene-solr/commit/51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "message": "more cleanups and documentation", "committedDate": "2020-04-06T20:05:55Z", "type": "commit"}, {"oid": "41acaa33990faaea6a52d1f0cec08c8cf2fbad03", "url": "https://github.com/apache/lucene-solr/commit/41acaa33990faaea6a52d1f0cec08c8cf2fbad03", "message": "simplify obtainAndLock logic", "committedDate": "2020-04-06T21:42:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDUzMTEzOA==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404531138", "bodyText": "nit: teh -> the", "author": "dnhatn", "createdAt": "2020-04-07T04:42:10Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java", "diffHunk": "@@ -52,12 +52,19 @@\n   private int numDocsSinceStalled = 0; // only with assert\n   final AtomicBoolean flushDeletes = new AtomicBoolean(false);\n   private boolean fullFlush = false;\n+  private boolean fullFlushMarkDone = false; // only for assertion that we don't get stale DWPTs from the pool\n+  // The flushQueue is used to concurrently distribute DWPTs that are ready to be flushed ie. when a full flush is in\n+  // progress. This might be triggered by a commit or NRT refresh. The trigger will only walk all eligible DWPTs and\n+  // mark them as flushable putting them in the flushQueue ready for other threads (ie. indexing threads) to help flushing\n   private final Queue<DocumentsWriterPerThread> flushQueue = new LinkedList<>();\n   // only for safety reasons if a DWPT is close to the RAM limit\n   private final Queue<DocumentsWriterPerThread> blockedFlushes = new LinkedList<>();\n+  // flushingWriters holds all currently flushing writers. There might be writers in this list that\n+  // are also in the flushQueue which means that writers in teh flushingWriters list are not necessarily", "originalCommit": "51c4d9e7b6c95d3e8cd9b8550aff290687df84d5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0bead669ed83297edbe342181db294df76bd04b7", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\nindex 4b381d0359f..c91cd41c0bf 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushControl.java\n\n@@ -60,7 +61,7 @@ final class DocumentsWriterFlushControl implements Accountable, Closeable {\n   // only for safety reasons if a DWPT is close to the RAM limit\n   private final Queue<DocumentsWriterPerThread> blockedFlushes = new LinkedList<>();\n   // flushingWriters holds all currently flushing writers. There might be writers in this list that\n-  // are also in the flushQueue which means that writers in teh flushingWriters list are not necessarily\n+  // are also in the flushQueue which means that writers in the flushingWriters list are not necessarily\n   // already actively flushing. They are only in the state of flushing and might be picked up in the future by\n   // polling the flushQueue\n   private final List<DocumentsWriterPerThread> flushingWriters = new ArrayList<>();\n"}}, {"oid": "0bead669ed83297edbe342181db294df76bd04b7", "url": "https://github.com/apache/lucene-solr/commit/0bead669ed83297edbe342181db294df76bd04b7", "message": "fix typo", "committedDate": "2020-04-07T06:56:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMDc3Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404610773", "bodyText": "Just an idea: Maybe use Deque<DocumentsWriterPerThread> freeList = new ArrayDeque<>(); here, as it allows to iterate in both directions (it has descendingIterator()). To me this also looks better, because the whole thing is mostly used as a deque (LIFO).", "author": "uschindler", "createdAt": "2020-04-07T07:57:45Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {\n-    DocumentsWriterPerThread dwpt;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    volatile boolean flushPending = false;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    long bytesUsed = 0;\n-\n-    // set by DocumentsWriter after each indexing op finishes\n-    volatile long lastSeqNo;\n-\n-    ThreadState(DocumentsWriterPerThread dpwt) {\n-      this.dwpt = dpwt;\n-    }\n-    \n-    private void reset() {\n-      assert this.isHeldByCurrentThread();\n-      this.dwpt = null;\n-      this.bytesUsed = 0;\n-      this.flushPending = false;\n-    }\n-    \n-    boolean isInitialized() {\n-      assert this.isHeldByCurrentThread();\n-      return dwpt != null;\n-    }\n-    \n-    /**\n-     * Returns the number of currently active bytes in this ThreadState's\n-     * {@link DocumentsWriterPerThread}\n-     */\n-    public long getBytesUsedPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return bytesUsed;\n-    }\n-    \n-    /**\n-     * Returns this {@link ThreadState}s {@link DocumentsWriterPerThread}\n-     */\n-    public DocumentsWriterPerThread getDocumentsWriterPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return dwpt;\n-    }\n-    \n-    /**\n-     * Returns <code>true</code> iff this {@link ThreadState} is marked as flush\n-     * pending otherwise <code>false</code>\n-     */\n-    public boolean isFlushPending() {\n-      return flushPending;\n-    }\n-  }\n+final class DocumentsWriterPerThreadPool implements Iterable<DocumentsWriterPerThread>, Closeable {\n \n-  private final List<ThreadState> threadStates = new ArrayList<>();\n+  private final Set<DocumentsWriterPerThread> dwpts = Collections.newSetFromMap(new IdentityHashMap<>());\n+  private final List<DocumentsWriterPerThread> freeList = new ArrayList<>();", "originalCommit": "0bead669ed83297edbe342181db294df76bd04b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYzNDQxMw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404634413", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-04-07T08:35:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMDc3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "81bd46e212359bcacd99fdcef09ffd9140776a00", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\nindex 1c1227a7cc3..7b4c9917b3c 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n\n@@ -18,8 +18,10 @@ package org.apache.lucene.index;\n \n import java.io.Closeable;\n import java.io.IOException;\n+import java.util.ArrayDeque;\n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.Deque;\n import java.util.IdentityHashMap;\n import java.util.Iterator;\n import java.util.List;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMTE1Mw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404611153", "bodyText": "Here you could use the descendingIterator() and iterate while just calling remove() on the iterator.", "author": "uschindler", "createdAt": "2020-04-07T07:58:21Z", "path": "lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java", "diffHunk": "@@ -16,228 +16,173 @@\n  */\n package org.apache.lucene.index;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.IdentityHashMap;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.concurrent.locks.ReentrantLock;\n+import java.util.Set;\n+import java.util.function.Predicate;\n \n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.lucene.util.IOSupplier;\n import org.apache.lucene.util.ThreadInterruptedException;\n \n /**\n- * {@link DocumentsWriterPerThreadPool} controls {@link ThreadState} instances\n- * and their thread assignments during indexing. Each {@link ThreadState} holds\n- * a reference to a {@link DocumentsWriterPerThread} that is once a\n- * {@link ThreadState} is obtained from the pool exclusively used for indexing a\n- * single document by the obtaining thread. Each indexing thread must obtain\n- * such a {@link ThreadState} to make progress. Depending on the\n- * {@link DocumentsWriterPerThreadPool} implementation {@link ThreadState}\n+ * {@link DocumentsWriterPerThreadPool} controls {@link DocumentsWriterPerThread} instances\n+ * and their thread assignments during indexing. Each {@link DocumentsWriterPerThread} is once a\n+ * obtained from the pool exclusively used for indexing a\n+ * single document or list of documents by the obtaining thread. Each indexing thread must obtain\n+ * such a {@link DocumentsWriterPerThread} to make progress. Depending on the\n+ * {@link DocumentsWriterPerThreadPool} implementation {@link DocumentsWriterPerThread}\n  * assignments might differ from document to document.\n  * <p>\n- * Once a {@link DocumentsWriterPerThread} is selected for flush the thread pool\n- * is reusing the flushing {@link DocumentsWriterPerThread}s ThreadState with a\n- * new {@link DocumentsWriterPerThread} instance.\n+ * Once a {@link DocumentsWriterPerThread} is selected for flush the {@link DocumentsWriterPerThread} will\n+ * be checked out of the thread pool and won't be reused for indexing. See {@link #checkout(DocumentsWriterPerThread)}.\n  * </p>\n  */\n-final class DocumentsWriterPerThreadPool {\n-  \n-  /**\n-   * {@link ThreadState} references and guards a\n-   * {@link DocumentsWriterPerThread} instance that is used during indexing to\n-   * build a in-memory index segment. {@link ThreadState} also holds all flush\n-   * related per-thread data controlled by {@link DocumentsWriterFlushControl}.\n-   * <p>\n-   * A {@link ThreadState}, its methods and members should only accessed by one\n-   * thread a time. Users must acquire the lock via {@link ThreadState#lock()}\n-   * and release the lock in a finally block via {@link ThreadState#unlock()}\n-   * before accessing the state.\n-   */\n-  @SuppressWarnings(\"serial\")\n-  final static class ThreadState extends ReentrantLock {\n-    DocumentsWriterPerThread dwpt;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    volatile boolean flushPending = false;\n-    // TODO this should really be part of DocumentsWriterFlushControl\n-    // write access guarded by DocumentsWriterFlushControl\n-    long bytesUsed = 0;\n-\n-    // set by DocumentsWriter after each indexing op finishes\n-    volatile long lastSeqNo;\n-\n-    ThreadState(DocumentsWriterPerThread dpwt) {\n-      this.dwpt = dpwt;\n-    }\n-    \n-    private void reset() {\n-      assert this.isHeldByCurrentThread();\n-      this.dwpt = null;\n-      this.bytesUsed = 0;\n-      this.flushPending = false;\n-    }\n-    \n-    boolean isInitialized() {\n-      assert this.isHeldByCurrentThread();\n-      return dwpt != null;\n-    }\n-    \n-    /**\n-     * Returns the number of currently active bytes in this ThreadState's\n-     * {@link DocumentsWriterPerThread}\n-     */\n-    public long getBytesUsedPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return bytesUsed;\n-    }\n-    \n-    /**\n-     * Returns this {@link ThreadState}s {@link DocumentsWriterPerThread}\n-     */\n-    public DocumentsWriterPerThread getDocumentsWriterPerThread() {\n-      assert this.isHeldByCurrentThread();\n-      // public for FlushPolicy\n-      return dwpt;\n-    }\n-    \n-    /**\n-     * Returns <code>true</code> iff this {@link ThreadState} is marked as flush\n-     * pending otherwise <code>false</code>\n-     */\n-    public boolean isFlushPending() {\n-      return flushPending;\n-    }\n-  }\n+final class DocumentsWriterPerThreadPool implements Iterable<DocumentsWriterPerThread>, Closeable {\n \n-  private final List<ThreadState> threadStates = new ArrayList<>();\n+  private final Set<DocumentsWriterPerThread> dwpts = Collections.newSetFromMap(new IdentityHashMap<>());\n+  private final List<DocumentsWriterPerThread> freeList = new ArrayList<>();\n+  private final IOSupplier<DocumentsWriterPerThread> dwptFactory;\n+  private int takenWriterPermits = 0;\n+  private boolean closed;\n \n-  private final List<ThreadState> freeList = new ArrayList<>();\n \n-  private int takenThreadStatePermits = 0;\n+  DocumentsWriterPerThreadPool(IOSupplier<DocumentsWriterPerThread> dwptFactory) {\n+    this.dwptFactory = dwptFactory;\n+  }\n \n   /**\n-   * Returns the active number of {@link ThreadState} instances.\n+   * Returns the active number of {@link DocumentsWriterPerThread} instances.\n    */\n-  synchronized int getActiveThreadStateCount() {\n-    return threadStates.size();\n+  synchronized int size() {\n+    return dwpts.size();\n   }\n \n-  synchronized void lockNewThreadStates() {\n-    // this is similar to a semaphore - we need to acquire all permits ie. takenThreadStatePermits must be == 0\n-    // any call to lockNewThreadStates() must be followed by unlockNewThreadStates() otherwise we will deadlock at some\n+  synchronized void lockNewWriters() {\n+    // this is similar to a semaphore - we need to acquire all permits ie. takenWriterPermits must be == 0\n+    // any call to lockNewWriters() must be followed by unlockNewWriters() otherwise we will deadlock at some\n     // point\n-    assert takenThreadStatePermits >= 0;\n-    takenThreadStatePermits++;\n+    assert takenWriterPermits >= 0;\n+    takenWriterPermits++;\n   }\n \n-  synchronized void unlockNewThreadStates() {\n-    assert takenThreadStatePermits > 0;\n-    takenThreadStatePermits--;\n-    if (takenThreadStatePermits == 0) {\n+  synchronized void unlockNewWriters() {\n+    assert takenWriterPermits > 0;\n+    takenWriterPermits--;\n+    if (takenWriterPermits == 0) {\n       notifyAll();\n     }\n   }\n+\n   /**\n-   * Returns a new {@link ThreadState} iff any new state is available otherwise\n-   * <code>null</code>.\n-   * <p>\n-   * NOTE: the returned {@link ThreadState} is already locked iff non-\n-   * <code>null</code>.\n-   * \n-   * @return a new {@link ThreadState} iff any new state is available otherwise\n-   *         <code>null</code>\n+   * Returns a new already locked {@link DocumentsWriterPerThread}\n+   *\n+   * @return a new {@link DocumentsWriterPerThread}\n    */\n-  private synchronized ThreadState newThreadState() {\n-    assert takenThreadStatePermits >= 0;\n-    while (takenThreadStatePermits > 0) {\n-      // we can't create new thread-states while not all permits are available\n+  private synchronized DocumentsWriterPerThread newWriter() throws IOException {\n+    assert takenWriterPermits >= 0;\n+    while (takenWriterPermits > 0) {\n+      // we can't create new DWPTs while not all permits are available\n       try {\n         wait();\n       } catch (InterruptedException ie) {\n         throw new ThreadInterruptedException(ie);\n       }\n     }\n-    ThreadState threadState = new ThreadState(null);\n-    threadState.lock(); // lock so nobody else will get this ThreadState\n-    threadStates.add(threadState);\n-    return threadState;\n-}\n-\n-  DocumentsWriterPerThread reset(ThreadState threadState) {\n-    assert threadState.isHeldByCurrentThread();\n-    final DocumentsWriterPerThread dwpt = threadState.dwpt;\n-    threadState.reset();\n+    DocumentsWriterPerThread dwpt = dwptFactory.get();\n+    dwpt.lock(); // lock so nobody else will get this DWPT\n+    dwpts.add(dwpt);\n     return dwpt;\n   }\n-  \n-  void recycle(DocumentsWriterPerThread dwpt) {\n-    // don't recycle DWPT by default\n-  }\n \n   // TODO: maybe we should try to do load leveling here: we want roughly even numbers\n   // of items (docs, deletes, DV updates) to most take advantage of concurrency while flushing\n \n-  /** This method is used by DocumentsWriter/FlushControl to obtain a ThreadState to do an indexing operation (add/updateDocument). */\n-  ThreadState getAndLock() {\n-    ThreadState threadState = null;\n+  /** This method is used by DocumentsWriter/FlushControl to obtain a DWPT to do an indexing operation (add/updateDocument). */\n+  DocumentsWriterPerThread getAndLock() throws IOException {\n     synchronized (this) {\n-      if (freeList.isEmpty()) {\n-        // ThreadState is already locked before return by this method:\n-        return newThreadState();\n-      } else {\n-        // Important that we are LIFO here! This way if number of concurrent indexing threads was once high, but has now reduced, we only use a\n-        // limited number of thread states:\n-        threadState = freeList.remove(freeList.size()-1);\n-\n-        if (threadState.dwpt == null) {\n-          // This thread-state is not initialized, e.g. it\n-          // was just flushed. See if we can instead find\n-          // another free thread state that already has docs\n-          // indexed. This way if incoming thread concurrency\n-          // has decreased, we don't leave docs\n-          // indefinitely buffered, tying up RAM.  This\n-          // will instead get those thread states flushed,\n-          // freeing up RAM for larger segment flushes:\n-          for(int i=0;i<freeList.size();i++) {\n-            ThreadState ts = freeList.get(i);\n-            if (ts.dwpt != null) {\n-              // Use this one instead, and swap it with\n-              // the un-initialized one:\n-              freeList.set(i, threadState);\n-              threadState = ts;\n-              break;\n-            }\n-          }\n+      if (closed) {\n+        throw new AlreadyClosedException(\"DWPTPool is already closed\");\n+      }\n+      // Important that we are LIFO here! This way if number of concurrent indexing threads was once high,\n+      // but has now reduced, we only use a limited number of DWPTs. This also guarantees that if we have suddenly\n+      // a single thread indexing\n+      for (int i = freeList.size()-1; i >= 0; i--) {", "originalCommit": "0bead669ed83297edbe342181db294df76bd04b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYzNDQ2Nw==", "url": "https://github.com/apache/lucene-solr/pull/1397#discussion_r404634467", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-04-07T08:35:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMTE1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "81bd46e212359bcacd99fdcef09ffd9140776a00", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\nindex 1c1227a7cc3..7b4c9917b3c 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThreadPool.java\n\n@@ -18,8 +18,10 @@ package org.apache.lucene.index;\n \n import java.io.Closeable;\n import java.io.IOException;\n+import java.util.ArrayDeque;\n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.Deque;\n import java.util.IdentityHashMap;\n import java.util.Iterator;\n import java.util.List;\n"}}, {"oid": "81bd46e212359bcacd99fdcef09ffd9140776a00", "url": "https://github.com/apache/lucene-solr/commit/81bd46e212359bcacd99fdcef09ffd9140776a00", "message": "apply feedback", "committedDate": "2020-04-07T08:36:08Z", "type": "commit"}, {"oid": "6621f103bab3f89fe8b0e847a4dbe3f8cc995bc1", "url": "https://github.com/apache/lucene-solr/commit/6621f103bab3f89fe8b0e847a4dbe3f8cc995bc1", "message": "fix removal and assertion", "committedDate": "2020-04-07T08:40:49Z", "type": "commit"}, {"oid": "163a839ca134326ae268735b3549fab7c1bcf417", "url": "https://github.com/apache/lucene-solr/commit/163a839ca134326ae268735b3549fab7c1bcf417", "message": "fix remaining review comments to be more clear", "committedDate": "2020-04-08T07:50:12Z", "type": "commit"}, {"oid": "03be7ab0ef2e129a3bb5eeff82c866ca27eba4ae", "url": "https://github.com/apache/lucene-solr/commit/03be7ab0ef2e129a3bb5eeff82c866ca27eba4ae", "message": "Merge branch 'master' into pick_smallest_dwpt", "committedDate": "2020-04-08T19:21:54Z", "type": "commit"}, {"oid": "07d2883d0e1f12e4c36c480473965e15f27c6730", "url": "https://github.com/apache/lucene-solr/commit/07d2883d0e1f12e4c36c480473965e15f27c6730", "message": "Merge branch 'master' into pick_smallest_dwpt", "committedDate": "2020-04-10T11:25:49Z", "type": "commit"}, {"oid": "26aaf40e6e3ada05eacbcd4acc834a2a73a1ed1d", "url": "https://github.com/apache/lucene-solr/commit/26aaf40e6e3ada05eacbcd4acc834a2a73a1ed1d", "message": "Merge branch 'master' into pick_smallest_dwpt", "committedDate": "2020-04-11T09:59:35Z", "type": "commit"}, {"oid": "5888db461df0222a97152c2f3973137a6caf8232", "url": "https://github.com/apache/lucene-solr/commit/5888db461df0222a97152c2f3973137a6caf8232", "message": "add changes", "committedDate": "2020-04-11T10:03:10Z", "type": "commit"}]}