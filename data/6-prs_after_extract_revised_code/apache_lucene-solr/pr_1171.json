{"pr_number": 1171, "pr_title": "SOLR-13892: Add 'top-level' docValues Join implementation", "pr_createdAt": "2020-01-15T14:56:55Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1171", "timeline": [{"oid": "45f19108cff9eff6a39868fe73b579d14aa1a2dc", "url": "https://github.com/apache/lucene-solr/commit/45f19108cff9eff6a39868fe73b579d14aa1a2dc", "message": "SOLR-13892: Add \"join\" postfilter implementation", "committedDate": "2020-01-15T14:46:38Z", "type": "commit"}, {"oid": "8251066c8ff37590cbd2908ce8f04ddcb508ac36", "url": "https://github.com/apache/lucene-solr/commit/8251066c8ff37590cbd2908ce8f04ddcb508ac36", "message": "SOLR-13892: Add TPI implementation for benchmarking\n\nIn some benchmarking it looks like the TPI implementation has the same\nperf benefits as the postfilter implementation, which was mostly\nexpected. The current implementation is very rough (lots of duplication\nand debug logging), but I'm sharing it to give context to performance\nresults I'm posting at the same time.", "committedDate": "2020-01-15T14:46:50Z", "type": "commit"}, {"oid": "bcc0b3f20c6e724efbfef82703304b74d2a34986", "url": "https://github.com/apache/lucene-solr/commit/bcc0b3f20c6e724efbfef82703304b74d2a34986", "message": "SOLR-13892: Remove postfilter join impl", "committedDate": "2020-01-15T15:09:36Z", "type": "commit"}, {"oid": "d7067a607bd932b5e1638442d23119fa479967f4", "url": "https://github.com/apache/lucene-solr/commit/d7067a607bd932b5e1638442d23119fa479967f4", "message": "SOLR-13892: Add 'method' localParam to JoinQParser", "committedDate": "2020-01-17T12:12:04Z", "type": "commit"}, {"oid": "989b0a5bce5fb70402a98012a7c2ab2a5f436703", "url": "https://github.com/apache/lucene-solr/commit/989b0a5bce5fb70402a98012a7c2ab2a5f436703", "message": "Extract TopLevelJoinQuery and helpers to its own class", "committedDate": "2020-01-17T19:39:42Z", "type": "commit"}, {"oid": "35b7fc26ab57ea1cda478fd0bcc6f1544573ae1d", "url": "https://github.com/apache/lucene-solr/commit/35b7fc26ab57ea1cda478fd0bcc6f1544573ae1d", "message": "SOLR-13892: Remove single-/multi-value duplication\n\nMuch of the the code for TopLevelJoinQuery was previously duplicated:\nonce to handle single-value fields (SortedDocValues objects) and once to\nhandle multi-value fields (SortedSetDocValues objects).  Most of the\ncode was actually the same, but since the DV objects didn't share any\nparent classes, it was impossible to take advantage of the fact that\nthey have mostly the same public methods and write helper methods etc\nthat operate on both object types.\n\nThis commit creates a wrapper object around these two types that allows\ncode to be written to handle either one.  This cut out a lot of\nthe duplication.", "committedDate": "2020-01-21T12:42:25Z", "type": "commit"}, {"oid": "e7bfc991472ff1f54e9056f1e236f6ffe23c10f5", "url": "https://github.com/apache/lucene-solr/commit/e7bfc991472ff1f54e9056f1e236f6ffe23c10f5", "message": "SOLR-13892: Update tests following postfilter removal", "committedDate": "2020-01-22T17:15:10Z", "type": "commit"}, {"oid": "ffd4d793bb6a3351c50affdb25e28df445b52de8", "url": "https://github.com/apache/lucene-solr/commit/ffd4d793bb6a3351c50affdb25e28df445b52de8", "message": "SOLR-13892: Replace DocValuesWrapper with existing lucene class", "committedDate": "2020-01-22T17:39:20Z", "type": "commit"}, {"oid": "3233fe03fbffaccff982022e98be09ec14308a90", "url": "https://github.com/apache/lucene-solr/commit/3233fe03fbffaccff982022e98be09ec14308a90", "message": "SOLR-13892: Remove SingletonSortedSetDocValues visibility change", "committedDate": "2020-01-22T17:44:30Z", "type": "commit"}, {"oid": "97488093e36684dfe0797037469d1c40f83c3147", "url": "https://github.com/apache/lucene-solr/commit/97488093e36684dfe0797037469d1c40f83c3147", "message": "SOLR-13892: Add JoinQParser 'method' docs", "committedDate": "2020-01-23T14:46:50Z", "type": "commit"}, {"oid": "c232d8d042b6fc86bba3b5be2672f2941cb8fb6f", "url": "https://github.com/apache/lucene-solr/commit/c232d8d042b6fc86bba3b5be2672f2941cb8fb6f", "message": "SOLR-13892: Rename method val for Score impl\n\nEarlier in this PR I'd named it 'indexWithScore', but it actually uses\ndocValues or uninverted structures.", "committedDate": "2020-01-23T14:50:06Z", "type": "commit"}, {"oid": "ac33c8efb5146a94347d7e340d199dfbf8548834", "url": "https://github.com/apache/lucene-solr/commit/ac33c8efb5146a94347d7e340d199dfbf8548834", "message": "SOLR-13892: Remove unwanted docs whitespace change", "committedDate": "2020-01-23T14:54:42Z", "type": "commit"}, {"oid": "73c13faf86144cf39c5ccb1e60fedad917e6b429", "url": "https://github.com/apache/lucene-solr/commit/73c13faf86144cf39c5ccb1e60fedad917e6b429", "message": "SOLR-13892: Fix precommit", "committedDate": "2020-01-23T14:59:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI4MTE0OQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370281149", "bodyText": "Use QueryParsing.V  thus also signals this isn't special", "author": "dsmiley", "createdAt": "2020-01-23T18:24:12Z", "path": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java", "diffHunk": "@@ -59,67 +60,124 @@\n import org.apache.solr.search.join.ScoreJoinQParserPlugin;\n import org.apache.solr.util.RTimer;\n import org.apache.solr.util.RefCounted;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n public class JoinQParserPlugin extends QParserPlugin {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   public static final String NAME = \"join\";\n+  /** Choose the internal algorithm */\n+  private static final String METHOD = \"method\";\n+\n+  private static class JoinParams {\n+    final String fromField;\n+    final String fromCore;\n+    final Query fromQuery;\n+    final long fromCoreOpenTime;\n+    final String toField;\n+\n+    public JoinParams(String fromField, String fromCore, Query fromQuery, long fromCoreOpenTime, String toField) {\n+      this.fromField = fromField;\n+      this.fromCore = fromCore;\n+      this.fromQuery = fromQuery;\n+      this.fromCoreOpenTime = fromCoreOpenTime;\n+      this.toField = toField;\n+    }\n+  }\n+\n+  private enum Method {\n+    index {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new JoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    },\n+    dvWithScore {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        return new ScoreJoinQParserPlugin().createParser(qparser.qstr, qparser.localParams, qparser.params, qparser.req).parse();\n+      }\n+    },\n+    topLevelDV {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new TopLevelJoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    };\n+\n+    abstract Query makeFilter(QParser qparser) throws SyntaxError;\n+\n+    JoinParams parseJoin(QParser qparser) throws SyntaxError {\n+      final String fromField = qparser.getParam(\"from\");\n+      final String fromIndex = qparser.getParam(\"fromIndex\");\n+      final String toField = qparser.getParam(\"to\");\n+      final String v = qparser.localParams.get(\"v\");", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\nindex 40959885345..8622d84b0fa 100644\n--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n\n@@ -118,7 +118,7 @@ public class JoinQParserPlugin extends QParserPlugin {\n       final String fromField = qparser.getParam(\"from\");\n       final String fromIndex = qparser.getParam(\"fromIndex\");\n       final String toField = qparser.getParam(\"to\");\n-      final String v = qparser.localParams.get(\"v\");\n+      final String v = qparser.localParams.get(QueryParsing.V);\n       final String coreName;\n \n       Query fromQuery;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI4MjU5Mg==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370282592", "bodyText": "Can you use try-with-resources style for SolrCore and otherReq?  You might need to create a static method that gets the core and throws if non-null so that you are able to have a one-liner fetch of the core in the \"try\".  I generally like to use try-with-resources when possible as it's easier to reason to guarantee things get closed, and it's sometimes less code.", "author": "dsmiley", "createdAt": "2020-01-23T18:27:27Z", "path": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java", "diffHunk": "@@ -59,67 +60,124 @@\n import org.apache.solr.search.join.ScoreJoinQParserPlugin;\n import org.apache.solr.util.RTimer;\n import org.apache.solr.util.RefCounted;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n public class JoinQParserPlugin extends QParserPlugin {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   public static final String NAME = \"join\";\n+  /** Choose the internal algorithm */\n+  private static final String METHOD = \"method\";\n+\n+  private static class JoinParams {\n+    final String fromField;\n+    final String fromCore;\n+    final Query fromQuery;\n+    final long fromCoreOpenTime;\n+    final String toField;\n+\n+    public JoinParams(String fromField, String fromCore, Query fromQuery, long fromCoreOpenTime, String toField) {\n+      this.fromField = fromField;\n+      this.fromCore = fromCore;\n+      this.fromQuery = fromQuery;\n+      this.fromCoreOpenTime = fromCoreOpenTime;\n+      this.toField = toField;\n+    }\n+  }\n+\n+  private enum Method {\n+    index {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new JoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    },\n+    dvWithScore {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        return new ScoreJoinQParserPlugin().createParser(qparser.qstr, qparser.localParams, qparser.params, qparser.req).parse();\n+      }\n+    },\n+    topLevelDV {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new TopLevelJoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    };\n+\n+    abstract Query makeFilter(QParser qparser) throws SyntaxError;\n+\n+    JoinParams parseJoin(QParser qparser) throws SyntaxError {\n+      final String fromField = qparser.getParam(\"from\");\n+      final String fromIndex = qparser.getParam(\"fromIndex\");\n+      final String toField = qparser.getParam(\"to\");\n+      final String v = qparser.localParams.get(\"v\");\n+      final String coreName;\n+\n+      Query fromQuery;\n+      long fromCoreOpenTime = 0;\n+\n+      if (fromIndex != null && !fromIndex.equals(qparser.req.getCore().getCoreDescriptor().getName()) ) {\n+        CoreContainer container = qparser.req.getCore().getCoreContainer();\n+\n+        // if in SolrCloud mode, fromIndex should be the name of a single-sharded collection\n+        coreName = ScoreJoinQParserPlugin.getCoreName(fromIndex, container);\n+\n+        final SolrCore fromCore = container.getCore(coreName);\n+        if (fromCore == null) {\n+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+              \"Cross-core join: no such core \" + coreName);\n+        }\n+\n+        RefCounted<SolrIndexSearcher> fromHolder = null;\n+        LocalSolrQueryRequest otherReq = new LocalSolrQueryRequest(fromCore, qparser.params);\n+        try {", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI4Njg2Ng==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r371286866", "bodyText": "Totally agree - should be using try-with-resources here.\nBut I'm reluctant to introduce changes here that aren't strictly necessary.  (Github shows this section as \"added\", but really it was just moved from elsewhere in the file.)\nMy opinion on this changes, but I've been burned too many times recently by adding a \"harmless\" refactor into a related commit, only for that to cause issues later that force a revert.", "author": "gerlowskija", "createdAt": "2020-01-27T14:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI4MjU5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\nindex 40959885345..8622d84b0fa 100644\n--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n\n@@ -118,7 +118,7 @@ public class JoinQParserPlugin extends QParserPlugin {\n       final String fromField = qparser.getParam(\"from\");\n       final String fromIndex = qparser.getParam(\"fromIndex\");\n       final String toField = qparser.getParam(\"to\");\n-      final String v = qparser.localParams.get(\"v\");\n+      final String v = qparser.localParams.get(QueryParsing.V);\n       final String coreName;\n \n       Query fromQuery;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNDAwNw==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370304007", "bodyText": "Perhaps these two lines, setting is filter on the QParser and calling getQuery should be pulled out of the block as it is (or should be) in common with the positive side of the if-else?", "author": "dsmiley", "createdAt": "2020-01-23T19:13:06Z", "path": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java", "diffHunk": "@@ -59,67 +60,124 @@\n import org.apache.solr.search.join.ScoreJoinQParserPlugin;\n import org.apache.solr.util.RTimer;\n import org.apache.solr.util.RefCounted;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n public class JoinQParserPlugin extends QParserPlugin {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   public static final String NAME = \"join\";\n+  /** Choose the internal algorithm */\n+  private static final String METHOD = \"method\";\n+\n+  private static class JoinParams {\n+    final String fromField;\n+    final String fromCore;\n+    final Query fromQuery;\n+    final long fromCoreOpenTime;\n+    final String toField;\n+\n+    public JoinParams(String fromField, String fromCore, Query fromQuery, long fromCoreOpenTime, String toField) {\n+      this.fromField = fromField;\n+      this.fromCore = fromCore;\n+      this.fromQuery = fromQuery;\n+      this.fromCoreOpenTime = fromCoreOpenTime;\n+      this.toField = toField;\n+    }\n+  }\n+\n+  private enum Method {\n+    index {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new JoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    },\n+    dvWithScore {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        return new ScoreJoinQParserPlugin().createParser(qparser.qstr, qparser.localParams, qparser.params, qparser.req).parse();\n+      }\n+    },\n+    topLevelDV {\n+      @Override\n+      Query makeFilter(QParser qparser) throws SyntaxError {\n+        final JoinParams jParams = parseJoin(qparser);\n+        final JoinQuery q = new TopLevelJoinQuery(jParams.fromField, jParams.toField, jParams.fromCore, jParams.fromQuery);\n+        q.fromCoreOpenTime = jParams.fromCoreOpenTime;\n+        return q;\n+      }\n+    };\n+\n+    abstract Query makeFilter(QParser qparser) throws SyntaxError;\n+\n+    JoinParams parseJoin(QParser qparser) throws SyntaxError {\n+      final String fromField = qparser.getParam(\"from\");\n+      final String fromIndex = qparser.getParam(\"fromIndex\");\n+      final String toField = qparser.getParam(\"to\");\n+      final String v = qparser.localParams.get(\"v\");\n+      final String coreName;\n+\n+      Query fromQuery;\n+      long fromCoreOpenTime = 0;\n+\n+      if (fromIndex != null && !fromIndex.equals(qparser.req.getCore().getCoreDescriptor().getName()) ) {\n+        CoreContainer container = qparser.req.getCore().getCoreContainer();\n+\n+        // if in SolrCloud mode, fromIndex should be the name of a single-sharded collection\n+        coreName = ScoreJoinQParserPlugin.getCoreName(fromIndex, container);\n+\n+        final SolrCore fromCore = container.getCore(coreName);\n+        if (fromCore == null) {\n+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+              \"Cross-core join: no such core \" + coreName);\n+        }\n+\n+        RefCounted<SolrIndexSearcher> fromHolder = null;\n+        LocalSolrQueryRequest otherReq = new LocalSolrQueryRequest(fromCore, qparser.params);\n+        try {\n+          QParser parser = QParser.getParser(v, otherReq);\n+          fromQuery = parser.getQuery();\n+          fromHolder = fromCore.getRegisteredSearcher();\n+          if (fromHolder != null) fromCoreOpenTime = fromHolder.get().getOpenNanoTime();\n+        } finally {\n+          otherReq.close();\n+          fromCore.close();\n+          if (fromHolder != null) fromHolder.decref();\n+        }\n+      } else {\n+        coreName = null;\n+        QParser fromQueryParser = qparser.subQuery(v, null);\n+        fromQueryParser.setIsFilter(true);", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\nindex 40959885345..8622d84b0fa 100644\n--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n\n@@ -118,7 +118,7 @@ public class JoinQParserPlugin extends QParserPlugin {\n       final String fromField = qparser.getParam(\"from\");\n       final String fromIndex = qparser.getParam(\"fromIndex\");\n       final String toField = qparser.getParam(\"to\");\n-      final String v = qparser.localParams.get(\"v\");\n+      final String v = qparser.localParams.get(QueryParsing.V);\n       final String coreName;\n \n       Query fromQuery;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNDkwMA==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370304900", "bodyText": "Not used?", "author": "dsmiley", "createdAt": "2020-01-23T19:14:55Z", "path": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java", "diffHunk": "@@ -139,11 +197,16 @@ public static Query createJoinQuery(Query subQuery, String fromField, String toF\n \n \n class JoinQuery extends Query {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\nindex 40959885345..8622d84b0fa 100644\n--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n\n@@ -197,16 +197,11 @@ public class JoinQParserPlugin extends QParserPlugin {\n \n \n class JoinQuery extends Query {\n-  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n-\n   String fromField;\n   String toField;\n   String fromIndex; // TODO: name is missleading here compared to JoinQParserPlugin usage - here it must be a core name\n   Query q;\n   long fromCoreOpenTime;\n-  private boolean cache;\n-  private boolean cacheSep;\n-  private int cost;\n \n   public JoinQuery(String fromField, String toField, String coreName, Query subQuery) {\n     assert null != fromField;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNDk3Ng==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370304976", "bodyText": "Not used?", "author": "dsmiley", "createdAt": "2020-01-23T19:15:06Z", "path": "solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java", "diffHunk": "@@ -139,11 +197,16 @@ public static Query createJoinQuery(Query subQuery, String fromField, String toF\n \n \n class JoinQuery extends Query {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n   String fromField;\n   String toField;\n   String fromIndex; // TODO: name is missleading here compared to JoinQParserPlugin usage - here it must be a core name\n   Query q;\n   long fromCoreOpenTime;\n+  private boolean cache;", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\nindex 40959885345..8622d84b0fa 100644\n--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java\n\n@@ -197,16 +197,11 @@ public class JoinQParserPlugin extends QParserPlugin {\n \n \n class JoinQuery extends Query {\n-  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n-\n   String fromField;\n   String toField;\n   String fromIndex; // TODO: name is missleading here compared to JoinQParserPlugin usage - here it must be a core name\n   Query q;\n   long fromCoreOpenTime;\n-  private boolean cache;\n-  private boolean cacheSep;\n-  private int cost;\n \n   public JoinQuery(String fromField, String toField, String coreName, Query subQuery) {\n     assert null != fromField;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwNzM2NQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370307365", "bodyText": "Couldn't you rename the method and it's variables to remove \"From\" and it would be just as valid?  Okay I see why not; this is an instance method that refers to 'fromField' but if that's the only distinction then maybe it should be a static method and take that argument?", "author": "dsmiley", "createdAt": "2020-01-23T19:20:03Z", "path": "solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.Collector;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.schema.IndexSchema;\n+import org.apache.solr.schema.SchemaField;\n+import org.apache.solr.search.join.MultiValueTermOrdinalCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class TopLevelJoinQuery extends JoinQuery {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  public TopLevelJoinQuery(String fromField, String toField, String coreName, Query subQuery) {\n+    super(fromField, toField, coreName, subQuery);\n+  }\n+\n+  @Override\n+  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n+    if (! (searcher instanceof SolrIndexSearcher)) {\n+      log.debug(\"Falling back to JoinQueryWeight because searcher [{}] is not the required SolrIndexSearcher\", searcher);\n+      return super.createWeight(searcher, scoreMode, boost);\n+    }\n+\n+    final SolrIndexSearcher solrSearcher = (SolrIndexSearcher) searcher;\n+    final JoinQueryWeight weight = new JoinQueryWeight(solrSearcher, ScoreMode.COMPLETE_NO_SCORES, 1.0f);\n+    final SolrIndexSearcher fromSearcher = weight.fromSearcher;\n+    final SolrIndexSearcher toSearcher = weight.toSearcher;\n+\n+    try {\n+      final SortedSetDocValues topLevelFromDocValues = validateAndFetchDocValues(fromSearcher, fromField, \"from\");\n+      final SortedSetDocValues topLevelToDocValues = validateAndFetchDocValues(toSearcher, toField, \"to\");\n+      if (topLevelFromDocValues.getValueCount() == 0 || topLevelToDocValues.getValueCount() == 0) {\n+        return createNoMatchesWeight(boost);\n+      }\n+\n+      final LongBitSet fromOrdBitSet = findOrdinalsMatchingFromQuery(fromSearcher, topLevelFromDocValues);\n+      final LongBitSet toOrdBitSet = new LongBitSet(topLevelToDocValues.getValueCount());\n+      final BitsetBounds toBitsetBounds = convertFromOrdinalsIntoToField(fromOrdBitSet, topLevelFromDocValues, toOrdBitSet, topLevelToDocValues);\n+\n+      final boolean toMultivalued = toSearcher.getSchema().getFieldOrNull(toField).multiValued();\n+      return new ConstantScoreWeight(this, boost) {\n+        public Scorer scorer(LeafReaderContext context) throws IOException {\n+          if (toBitsetBounds.lower == BitsetBounds.NO_MATCHES) {\n+            return null;\n+          }\n+\n+          final DocIdSetIterator toApproximation = (toMultivalued) ? context.reader().getSortedSetDocValues(toField) :\n+              context.reader().getSortedDocValues(toField);\n+          if (toApproximation == null) {\n+            return null;\n+          }\n+\n+          final int docBase = context.docBase;\n+          return new ConstantScoreScorer(this, this.score(), scoreMode, new TwoPhaseIterator(toApproximation) {\n+            public boolean matches() throws IOException {\n+              final boolean hasDoc = topLevelToDocValues.advanceExact(docBase + approximation.docID());\n+              if (hasDoc) {\n+                for (long ord = topLevelToDocValues.nextOrd(); ord != -1L; ord = topLevelToDocValues.nextOrd()) {\n+                  if (toOrdBitSet.get(ord)) {\n+                    return true;\n+                  }\n+                }\n+              }\n+              return false;\n+            }\n+\n+            public float matchCost() {\n+              return 10.0F;\n+            }\n+          });\n+\n+        }\n+\n+        public boolean isCacheable(LeafReaderContext ctx) {\n+          return false;\n+        }\n+      };\n+    } catch (IOException e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  private Weight createNoMatchesWeight(float boost) {\n+    return new ConstantScoreWeight(this, boost) {\n+      @Override\n+      public Scorer scorer(LeafReaderContext context) throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public boolean isCacheable(LeafReaderContext ctx) {\n+        return false;\n+      }\n+    };\n+  }\n+\n+  private SortedSetDocValues validateAndFetchDocValues(SolrIndexSearcher solrSearcher, String fieldName, String querySide) throws IOException {\n+    final IndexSchema schema = solrSearcher.getSchema();\n+    final SchemaField field = schema.getFieldOrNull(fieldName);\n+    if (field == null) {\n+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, querySide + \" field '\" + fieldName + \"' does not exist\");\n+    }\n+\n+    if (!field.hasDocValues()) {\n+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n+          \"'top-level' join queries require both 'from' and 'to' fields to have docValues, but \" + querySide +\n+              \" field [\" + fieldName +  \"] does not.\");\n+    }\n+\n+    final LeafReader leafReader = solrSearcher.getSlowAtomicReader();\n+    if (field.multiValued()) {\n+      return DocValues.getSortedSet(leafReader, fieldName);\n+    }\n+    return DocValues.singleton(DocValues.getSorted(leafReader, fieldName));\n+  }\n+\n+  private LongBitSet findOrdinalsMatchingFromQuery(SolrIndexSearcher fromSearcher, SortedSetDocValues fromDocValues) throws IOException {", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java b/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\nindex 978b73806f5..20032754523 100644\n--- a/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\n+++ b/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\n\n@@ -69,7 +69,7 @@ public class TopLevelJoinQuery extends JoinQuery {\n         return createNoMatchesWeight(boost);\n       }\n \n-      final LongBitSet fromOrdBitSet = findOrdinalsMatchingFromQuery(fromSearcher, topLevelFromDocValues);\n+      final LongBitSet fromOrdBitSet = findFieldOrdinalsMatchingQuery(q, fromField, fromSearcher, topLevelFromDocValues);\n       final LongBitSet toOrdBitSet = new LongBitSet(topLevelToDocValues.getValueCount());\n       final BitsetBounds toBitsetBounds = convertFromOrdinalsIntoToField(fromOrdBitSet, topLevelFromDocValues, toOrdBitSet, topLevelToDocValues);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwOTg3NQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370309875", "bodyText": "Why extend DelegatingCollector?", "author": "dsmiley", "createdAt": "2020-01-23T19:25:23Z", "path": "solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search.join;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.search.DelegatingCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Populates a bitset of (top-level) ordinals based on field values in a multi-valued field.\n+ */\n+public class MultiValueTermOrdinalCollector extends DelegatingCollector {", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI5NjE3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r371296171", "bodyText": "Because it saves me from reimplementing getLeafCollector() and some other methods.  If you're wondering why DelegatingCollector as opposed to SimpleCollector or other options, there's not a great answer - DelegatingCollector was needed in some earlier revision when things were postfilter based.  I've changed it to use SimpleCollector; hopefully that addresses your concern.", "author": "gerlowskija", "createdAt": "2020-01-27T15:11:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMwOTg3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\nindex 64f07e0c03c..45ceaa58abf 100644\n--- a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n+++ b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n\n@@ -23,6 +23,7 @@ import java.lang.invoke.MethodHandles;\n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.SimpleCollector;\n import org.apache.lucene.util.LongBitSet;\n import org.apache.solr.search.DelegatingCollector;\n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxMTcyNg==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370311726", "bodyText": "What's this for?  Looks old/legacy before needsScores became scoreMode yet you just wrote this code.", "author": "dsmiley", "createdAt": "2020-01-23T19:29:08Z", "path": "solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search.join;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.search.DelegatingCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Populates a bitset of (top-level) ordinals based on field values in a multi-valued field.\n+ */\n+public class MultiValueTermOrdinalCollector extends DelegatingCollector {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  private int docBase;\n+  private SortedSetDocValues topLevelDocValues;\n+  private final String fieldName;\n+  private final LongBitSet topLevelDocValuesBitSet;\n+\n+  public MultiValueTermOrdinalCollector(String fieldName, SortedSetDocValues topLevelDocValues, LongBitSet topLevelDocValuesBitSet) {\n+    this.fieldName = fieldName;\n+    this.topLevelDocValues = topLevelDocValues;\n+    this.topLevelDocValuesBitSet = topLevelDocValuesBitSet;\n+  }\n+\n+  public ScoreMode scoreMode() {\n+    return ScoreMode.COMPLETE_NO_SCORES;\n+  }\n+\n+  public boolean needsScores(){", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\nindex 64f07e0c03c..45ceaa58abf 100644\n--- a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n+++ b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n\n@@ -23,6 +23,7 @@ import java.lang.invoke.MethodHandles;\n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.SimpleCollector;\n import org.apache.lucene.util.LongBitSet;\n import org.apache.solr.search.DelegatingCollector;\n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxMTk0Mw==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370311943", "bodyText": "Nothing to log", "author": "dsmiley", "createdAt": "2020-01-23T19:29:35Z", "path": "solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search.join;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.search.DelegatingCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Populates a bitset of (top-level) ordinals based on field values in a multi-valued field.\n+ */\n+public class MultiValueTermOrdinalCollector extends DelegatingCollector {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\nindex 64f07e0c03c..45ceaa58abf 100644\n--- a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n+++ b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n\n@@ -23,6 +23,7 @@ import java.lang.invoke.MethodHandles;\n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.SimpleCollector;\n import org.apache.lucene.util.LongBitSet;\n import org.apache.solr.search.DelegatingCollector;\n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxMzE0OQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370313149", "bodyText": "document this is the outgoing data structure expressing the results.  Could be a trivial comment", "author": "dsmiley", "createdAt": "2020-01-23T19:32:13Z", "path": "solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search.join;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.search.DelegatingCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Populates a bitset of (top-level) ordinals based on field values in a multi-valued field.\n+ */\n+public class MultiValueTermOrdinalCollector extends DelegatingCollector {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  private int docBase;\n+  private SortedSetDocValues topLevelDocValues;\n+  private final String fieldName;\n+  private final LongBitSet topLevelDocValuesBitSet;", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\nindex 64f07e0c03c..45ceaa58abf 100644\n--- a/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n+++ b/solr/core/src/java/org/apache/solr/search/join/MultiValueTermOrdinalCollector.java\n\n@@ -23,6 +23,7 @@ import java.lang.invoke.MethodHandles;\n import org.apache.lucene.index.LeafReaderContext;\n import org.apache.lucene.index.SortedSetDocValues;\n import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.SimpleCollector;\n import org.apache.lucene.util.LongBitSet;\n import org.apache.solr.search.DelegatingCollector;\n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODE0OQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370318149", "bodyText": "This class seems unused; no?", "author": "dsmiley", "createdAt": "2020-01-23T19:43:03Z", "path": "solr/core/src/java/org/apache/solr/search/join/TopLevelDVTermsCollector.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search.join;\n+\n+import java.io.IOException;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.LeafCollector;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.search.DelegatingCollector;\n+\n+/**\n+ * Collects all documents with a field value matching a set value in an ordinal bitset.\n+ *\n+ * Implementation is similar to {@link org.apache.lucene.search.join.TermsCollector}, but uses top-level ordinals\n+ * explicitly and has wider visibility.\n+ */\n+public class TopLevelDVTermsCollector extends DelegatingCollector {", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/join/TopLevelDVTermsCollector.java b/solr/core/src/java/org/apache/solr/search/join/TopLevelDVTermsCollector.java\ndeleted file mode 100644\nindex a699f255163..00000000000\n--- a/solr/core/src/java/org/apache/solr/search/join/TopLevelDVTermsCollector.java\n+++ /dev/null\n\n@@ -1,78 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.solr.search.join;\n-\n-import java.io.IOException;\n-\n-import org.apache.lucene.index.LeafReaderContext;\n-import org.apache.lucene.index.SortedSetDocValues;\n-import org.apache.lucene.search.LeafCollector;\n-import org.apache.lucene.search.Scorable;\n-import org.apache.lucene.util.LongBitSet;\n-import org.apache.solr.search.DelegatingCollector;\n-\n-/**\n- * Collects all documents with a field value matching a set value in an ordinal bitset.\n- *\n- * Implementation is similar to {@link org.apache.lucene.search.join.TermsCollector}, but uses top-level ordinals\n- * explicitly and has wider visibility.\n- */\n-public class TopLevelDVTermsCollector extends DelegatingCollector {\n-  private LeafCollector leafCollector;\n-  private int docBase;\n-  private SortedSetDocValues topLevelDocValues;\n-  private LongBitSet topLevelDocValuesBitSet;\n-  private long firstOrd;\n-  private long lastOrd;\n-\n-  public TopLevelDVTermsCollector(SortedSetDocValues topLevelDocValues, LongBitSet topLevelDocValuesBitSet, long firstOrd, long lastOrd) {\n-    this.topLevelDocValues = topLevelDocValues;\n-    this.topLevelDocValuesBitSet = topLevelDocValuesBitSet;\n-    this.firstOrd = firstOrd;\n-    this.lastOrd = lastOrd;\n-  }\n-\n-  @Override\n-  public void setScorer(Scorable scorer) throws IOException {\n-    leafCollector.setScorer(scorer);\n-  }\n-\n-  @Override\n-  public void doSetNextReader(LeafReaderContext context) throws IOException {\n-    this.leafCollector = delegate.getLeafCollector(context);\n-    this.docBase = context.docBase;\n-  }\n-\n-  @Override\n-  public void collect(int doc) throws IOException {\n-    final int globalDoc = doc + docBase;\n-\n-    if (topLevelDocValues.advanceExact(globalDoc)) {\n-      while (true) {\n-        final long ord = topLevelDocValues.nextOrd();\n-        if (ord == SortedSetDocValues.NO_MORE_ORDS) break;\n-        if (ord > lastOrd) break;\n-        if (ord < firstOrd) continue;\n-        if (topLevelDocValuesBitSet.get(ord)) {\n-          leafCollector.collect(doc);\n-          break;\n-        }\n-      }\n-    }\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU0NzIxMg==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370547212", "bodyText": "How long does it take to run? Souldn't it be @slow?", "author": "mkhludnev", "createdAt": "2020-01-24T09:47:00Z", "path": "solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.BufferedReader;\n+import java.io.FileReader;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.impl.HttpSolrClient;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+\n+public class TestJoinQueryPerformance extends SolrTestCaseJ4 {", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java b/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\ndeleted file mode 100644\nindex f7666cf1063..00000000000\n--- a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\n+++ /dev/null\n\n@@ -1,235 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.solr.search;\n-\n-import java.io.BufferedReader;\n-import java.io.FileReader;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.UUID;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.solr.SolrTestCaseJ4;\n-import org.apache.solr.client.solrj.SolrQuery;\n-import org.apache.solr.client.solrj.SolrRequest;\n-import org.apache.solr.client.solrj.impl.HttpSolrClient;\n-import org.apache.solr.client.solrj.response.QueryResponse;\n-import org.apache.solr.common.SolrInputDocument;\n-import org.junit.BeforeClass;\n-import org.junit.Test;\n-\n-\n-public class TestJoinQueryPerformance extends SolrTestCaseJ4 {\n-  // Dictionary used to load String data\n-  private static final String DICT_PATH = \"/usr/share/dict/words\";\n-  private static final int NUM_DICT_TERMS = 235886;\n-  private static final String[] LOADED_DICTIONARY = new String[NUM_DICT_TERMS];\n-\n-  // Performance run parameters: Indexing\n-  private static final String FROM_COLLECTION_NAME = \"user_acls\";\n-  private static final int NUM_FROM_DOCS = 5050; // 1 + 2 + 3 + 4 + ...  + 100\n-  private static final String TO_COLLECTION_NAME = \"products\";\n-  private static final int NUM_TO_DOCS = 500000;\n-  private static final int PERMISSION_CARDINALITY = 50000; // 50K unique groups/roles/whatever\n-  private static int BATCH_SIZE = 500;\n-  private static int NUM_COMMITS = 500;\n-  private static final int VAL_MAX = 1000;\n-  private static final int USER_MAX = 100;\n-\n-  private static String COLLECTION_NAME= \"foo\";\n-\n-  /*\n-   * As I start out here, I think I'll want a few different axes.\n-   *  - \"from\" collection matches (with \"to\" matches held constant)\n-   *  - \"to\" collection matches (with \"from\" matches held constant)\n-   *\n-   * So I think I should index a finite number of docs\n-   */\n-\n-  @BeforeClass\n-  public static void setUpCluster() throws Exception {\n-    loadDictionary();\n-    //loadCollectionData(DType.USER);\n-    //loadCollectionData(DType.DATA);\n-  }\n-\n-  private static void loadDictionary() throws Exception {\n-    try (BufferedReader reader = new BufferedReader(new FileReader(DICT_PATH))) {\n-      for (int i = 0; i < NUM_DICT_TERMS; i++) {\n-        LOADED_DICTIONARY[i] = reader.readLine();\n-      }\n-    }\n-  }\n-\n-  public enum DType {\n-    USER(NUM_FROM_DOCS, FROM_COLLECTION_NAME) {\n-      // id - unique string\n-      // userid_s - username (user# from 1-100)...each user appears in # entries\n-      // permissions_ss - set of 300 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        if (userRecordCounts[currentUser - 1] == currentUser) {\n-          currentUser++;\n-        } else {\n-          userRecordCounts[currentUser -1]++;\n-        }\n-\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final String userString = \"user\" + currentUser;\n-        final String[] permissions = getAFewDictionaryWords(300, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"userid_s\", userString);\n-        newDoc.addField(\"permissions_ss\", permissions);\n-\n-        return newDoc;\n-      }\n-    },\n-    DATA(NUM_TO_DOCS, TO_COLLECTION_NAME) {\n-      // id - unique string\n-      // val_i - random int between 1-1000\n-      // cost_d - random cost between 1-1000\n-      // body_txt - random text string between 100 - 10000 words\n-      // acl_ss - set of 100-3000 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final int val = random().nextInt(1000) + 1;\n-        final double cost = random().nextDouble() * 1000d;\n-        final String body = String.join(\" \", getAFewDictionaryWords(random().nextInt(9900) + 100));\n-        final String[] acls = getAFewDictionaryWords(random().nextInt(2900) + 100, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"val_i\", val);\n-        newDoc.addField(\"cost_d\", cost);\n-        newDoc.addField(\"body_txt\", body);\n-        newDoc.addField(\"acl_ss\", acls);\n-\n-        return newDoc;\n-      }\n-    };\n-\n-    private int numDocs;\n-    private String collName;\n-    private static int[] userRecordCounts = new int[100];\n-    private static int currentUser = 1;\n-\n-    private DType(int numDocs, String collectionName) {\n-      this.numDocs = numDocs;\n-      this.collName = collectionName;\n-    }\n-\n-    abstract SolrInputDocument buildDoc();\n-  }\n-\n-  private static void loadCollectionData(DType type) throws Exception {\n-    int numDocs = type.numDocs;\n-    String collectionName = type.collName;\n-    int numLoaded = 0;\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      final int numBatches = numDocs / BATCH_SIZE + 1;\n-      final int commitEveryBatches = NUM_COMMITS > 0 ? numBatches / NUM_COMMITS : Integer.MAX_VALUE;\n-      int batchCount = 0;\n-      while (numLoaded < numDocs) {\n-        final int sizeOfBatch = numLoaded + BATCH_SIZE > numDocs ? numDocs - numLoaded : BATCH_SIZE;\n-        final Collection<SolrInputDocument> batch = buildBatch(type, sizeOfBatch);\n-        client.add(collectionName, batch);\n-        batchCount++;\n-        numLoaded+=sizeOfBatch;\n-\n-        if (batchCount == commitEveryBatches) {\n-          client.commit(collectionName);\n-          batchCount = 0;\n-        }\n-      }\n-      client.commit(collectionName);\n-    }\n-\n-  }\n-\n-  private static Collection<SolrInputDocument> buildBatch(DType type, int sizeOfBatch) {\n-    final List<SolrInputDocument> batch = Lists.newArrayList();\n-    for (int i = 0; i < sizeOfBatch; i++) {\n-      batch.add(type.buildDoc());\n-    }\n-    return batch;\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords) {\n-    return getAFewDictionaryWords(numWords, NUM_DICT_TERMS);\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords, int onlyFirstN) {\n-    final String[] words = new String[numWords];\n-    for (int i = 0; i < numWords; i++) {\n-      words[i] = LOADED_DICTIONARY[random().nextInt(onlyFirstN)];\n-    }\n-\n-    return words;\n-  }\n-\n-\n-  @Test\n-  public void testJoinPerformanceAsMainQueryHitsIncrease() throws Exception {\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-    final String fromQuery = \"userid_s:user25\"; // The higher the user number, the more permissions he has attached to his name (1-100)\n-    final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-    final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-    final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 0; i < VAL_MAX; i+=20) {\n-        final String mainQuery = \"val_i:[1 TO \" + (i+1) + \"]\";\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  @Test\n-  public void testJoinPerformanceAsFromQueryHitsIncrease() throws Exception {\n-    final String mainQuery = \"val_i:[1 TO 250]\"; // Half the docs match the query (250K)\n-\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 1; i <= USER_MAX; i++) {\n-        final String fromQuery = \"userid_s:user\" + i;\n-        final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-        final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-        final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  private static String buildTermsQueryString(int numTerms) {\n-    final String[] terms = getAFewDictionaryWords(numTerms);\n-    return String.join(\",\", terms);\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU0Nzc2MQ==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370547761", "bodyText": "Printing to stdout is prosecuted.", "author": "mkhludnev", "createdAt": "2020-01-24T09:48:21Z", "path": "solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.BufferedReader;\n+import java.io.FileReader;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.impl.HttpSolrClient;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+\n+public class TestJoinQueryPerformance extends SolrTestCaseJ4 {\n+  // Dictionary used to load String data\n+  private static final String DICT_PATH = \"/usr/share/dict/words\";\n+  private static final int NUM_DICT_TERMS = 235886;\n+  private static final String[] LOADED_DICTIONARY = new String[NUM_DICT_TERMS];\n+\n+  // Performance run parameters: Indexing\n+  private static final String FROM_COLLECTION_NAME = \"user_acls\";\n+  private static final int NUM_FROM_DOCS = 5050; // 1 + 2 + 3 + 4 + ...  + 100\n+  private static final String TO_COLLECTION_NAME = \"products\";\n+  private static final int NUM_TO_DOCS = 500000;\n+  private static final int PERMISSION_CARDINALITY = 50000; // 50K unique groups/roles/whatever\n+  private static int BATCH_SIZE = 500;\n+  private static int NUM_COMMITS = 500;\n+  private static final int VAL_MAX = 1000;\n+  private static final int USER_MAX = 100;\n+\n+  private static String COLLECTION_NAME= \"foo\";\n+\n+  /*\n+   * As I start out here, I think I'll want a few different axes.\n+   *  - \"from\" collection matches (with \"to\" matches held constant)\n+   *  - \"to\" collection matches (with \"from\" matches held constant)\n+   *\n+   * So I think I should index a finite number of docs\n+   */\n+\n+  @BeforeClass\n+  public static void setUpCluster() throws Exception {\n+    loadDictionary();\n+    //loadCollectionData(DType.USER);\n+    //loadCollectionData(DType.DATA);\n+  }\n+\n+  private static void loadDictionary() throws Exception {\n+    try (BufferedReader reader = new BufferedReader(new FileReader(DICT_PATH))) {\n+      for (int i = 0; i < NUM_DICT_TERMS; i++) {\n+        LOADED_DICTIONARY[i] = reader.readLine();\n+      }\n+    }\n+  }\n+\n+  public enum DType {\n+    USER(NUM_FROM_DOCS, FROM_COLLECTION_NAME) {\n+      // id - unique string\n+      // userid_s - username (user# from 1-100)...each user appears in # entries\n+      // permissions_ss - set of 300 string permissions (cardinality 50K)\n+      @Override\n+      SolrInputDocument buildDoc() {\n+        if (userRecordCounts[currentUser - 1] == currentUser) {\n+          currentUser++;\n+        } else {\n+          userRecordCounts[currentUser -1]++;\n+        }\n+\n+        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n+        final String userString = \"user\" + currentUser;\n+        final String[] permissions = getAFewDictionaryWords(300, PERMISSION_CARDINALITY);\n+\n+        newDoc.addField(\"userid_s\", userString);\n+        newDoc.addField(\"permissions_ss\", permissions);\n+\n+        return newDoc;\n+      }\n+    },\n+    DATA(NUM_TO_DOCS, TO_COLLECTION_NAME) {\n+      // id - unique string\n+      // val_i - random int between 1-1000\n+      // cost_d - random cost between 1-1000\n+      // body_txt - random text string between 100 - 10000 words\n+      // acl_ss - set of 100-3000 string permissions (cardinality 50K)\n+      @Override\n+      SolrInputDocument buildDoc() {\n+        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n+        final int val = random().nextInt(1000) + 1;\n+        final double cost = random().nextDouble() * 1000d;\n+        final String body = String.join(\" \", getAFewDictionaryWords(random().nextInt(9900) + 100));\n+        final String[] acls = getAFewDictionaryWords(random().nextInt(2900) + 100, PERMISSION_CARDINALITY);\n+\n+        newDoc.addField(\"val_i\", val);\n+        newDoc.addField(\"cost_d\", cost);\n+        newDoc.addField(\"body_txt\", body);\n+        newDoc.addField(\"acl_ss\", acls);\n+\n+        return newDoc;\n+      }\n+    };\n+\n+    private int numDocs;\n+    private String collName;\n+    private static int[] userRecordCounts = new int[100];\n+    private static int currentUser = 1;\n+\n+    private DType(int numDocs, String collectionName) {\n+      this.numDocs = numDocs;\n+      this.collName = collectionName;\n+    }\n+\n+    abstract SolrInputDocument buildDoc();\n+  }\n+\n+  private static void loadCollectionData(DType type) throws Exception {\n+    int numDocs = type.numDocs;\n+    String collectionName = type.collName;\n+    int numLoaded = 0;\n+    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n+      final int numBatches = numDocs / BATCH_SIZE + 1;\n+      final int commitEveryBatches = NUM_COMMITS > 0 ? numBatches / NUM_COMMITS : Integer.MAX_VALUE;\n+      int batchCount = 0;\n+      while (numLoaded < numDocs) {\n+        final int sizeOfBatch = numLoaded + BATCH_SIZE > numDocs ? numDocs - numLoaded : BATCH_SIZE;\n+        final Collection<SolrInputDocument> batch = buildBatch(type, sizeOfBatch);\n+        client.add(collectionName, batch);\n+        batchCount++;\n+        numLoaded+=sizeOfBatch;\n+\n+        if (batchCount == commitEveryBatches) {\n+          client.commit(collectionName);\n+          batchCount = 0;\n+        }\n+      }\n+      client.commit(collectionName);\n+    }\n+\n+  }\n+\n+  private static Collection<SolrInputDocument> buildBatch(DType type, int sizeOfBatch) {\n+    final List<SolrInputDocument> batch = Lists.newArrayList();\n+    for (int i = 0; i < sizeOfBatch; i++) {\n+      batch.add(type.buildDoc());\n+    }\n+    return batch;\n+  }\n+\n+  private static String[] getAFewDictionaryWords(int numWords) {\n+    return getAFewDictionaryWords(numWords, NUM_DICT_TERMS);\n+  }\n+\n+  private static String[] getAFewDictionaryWords(int numWords, int onlyFirstN) {\n+    final String[] words = new String[numWords];\n+    for (int i = 0; i < numWords; i++) {\n+      words[i] = LOADED_DICTIONARY[random().nextInt(onlyFirstN)];\n+    }\n+\n+    return words;\n+  }\n+\n+\n+  @Test\n+  public void testJoinPerformanceAsMainQueryHitsIncrease() throws Exception {\n+    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n+    final String fromQuery = \"userid_s:user25\"; // The higher the user number, the more permissions he has attached to his name (1-100)\n+    final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n+    final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n+    final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n+\n+    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n+      for ( int i = 0; i < VAL_MAX; i+=20) {\n+        final String mainQuery = \"val_i:[1 TO \" + (i+1) + \"]\";\n+        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n+        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n+        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n+        final long numFound = tpiJoinRsp.getResults().getNumFound();\n+\n+        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testJoinPerformanceAsFromQueryHitsIncrease() throws Exception {\n+    final String mainQuery = \"val_i:[1 TO 250]\"; // Half the docs match the query (250K)\n+\n+    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n+\n+\n+    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n+      for ( int i = 1; i <= USER_MAX; i++) {\n+        final String fromQuery = \"userid_s:user\" + i;\n+        final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n+        final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n+        final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n+\n+        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n+        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n+        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n+        final long numFound = tpiJoinRsp.getResults().getNumFound();\n+\n+        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDkxMDEwMg==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370910102", "bodyText": "Hey Mikhail, thanks for the review.  I have no intentions of committing this file.  I kept it in the PR up to this point so that people could reproduce/tweak the perf test I ran.  But I'm going to remove it prior to commit.\n(In fact, I thought I already had removed it, but there was one last \"cleanup\" commit I'd neglected to push until right now.  You should see this file gone from the PR now.)", "author": "gerlowskija", "createdAt": "2020-01-25T03:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU0Nzc2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java b/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\ndeleted file mode 100644\nindex f7666cf1063..00000000000\n--- a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\n+++ /dev/null\n\n@@ -1,235 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.solr.search;\n-\n-import java.io.BufferedReader;\n-import java.io.FileReader;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.UUID;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.solr.SolrTestCaseJ4;\n-import org.apache.solr.client.solrj.SolrQuery;\n-import org.apache.solr.client.solrj.SolrRequest;\n-import org.apache.solr.client.solrj.impl.HttpSolrClient;\n-import org.apache.solr.client.solrj.response.QueryResponse;\n-import org.apache.solr.common.SolrInputDocument;\n-import org.junit.BeforeClass;\n-import org.junit.Test;\n-\n-\n-public class TestJoinQueryPerformance extends SolrTestCaseJ4 {\n-  // Dictionary used to load String data\n-  private static final String DICT_PATH = \"/usr/share/dict/words\";\n-  private static final int NUM_DICT_TERMS = 235886;\n-  private static final String[] LOADED_DICTIONARY = new String[NUM_DICT_TERMS];\n-\n-  // Performance run parameters: Indexing\n-  private static final String FROM_COLLECTION_NAME = \"user_acls\";\n-  private static final int NUM_FROM_DOCS = 5050; // 1 + 2 + 3 + 4 + ...  + 100\n-  private static final String TO_COLLECTION_NAME = \"products\";\n-  private static final int NUM_TO_DOCS = 500000;\n-  private static final int PERMISSION_CARDINALITY = 50000; // 50K unique groups/roles/whatever\n-  private static int BATCH_SIZE = 500;\n-  private static int NUM_COMMITS = 500;\n-  private static final int VAL_MAX = 1000;\n-  private static final int USER_MAX = 100;\n-\n-  private static String COLLECTION_NAME= \"foo\";\n-\n-  /*\n-   * As I start out here, I think I'll want a few different axes.\n-   *  - \"from\" collection matches (with \"to\" matches held constant)\n-   *  - \"to\" collection matches (with \"from\" matches held constant)\n-   *\n-   * So I think I should index a finite number of docs\n-   */\n-\n-  @BeforeClass\n-  public static void setUpCluster() throws Exception {\n-    loadDictionary();\n-    //loadCollectionData(DType.USER);\n-    //loadCollectionData(DType.DATA);\n-  }\n-\n-  private static void loadDictionary() throws Exception {\n-    try (BufferedReader reader = new BufferedReader(new FileReader(DICT_PATH))) {\n-      for (int i = 0; i < NUM_DICT_TERMS; i++) {\n-        LOADED_DICTIONARY[i] = reader.readLine();\n-      }\n-    }\n-  }\n-\n-  public enum DType {\n-    USER(NUM_FROM_DOCS, FROM_COLLECTION_NAME) {\n-      // id - unique string\n-      // userid_s - username (user# from 1-100)...each user appears in # entries\n-      // permissions_ss - set of 300 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        if (userRecordCounts[currentUser - 1] == currentUser) {\n-          currentUser++;\n-        } else {\n-          userRecordCounts[currentUser -1]++;\n-        }\n-\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final String userString = \"user\" + currentUser;\n-        final String[] permissions = getAFewDictionaryWords(300, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"userid_s\", userString);\n-        newDoc.addField(\"permissions_ss\", permissions);\n-\n-        return newDoc;\n-      }\n-    },\n-    DATA(NUM_TO_DOCS, TO_COLLECTION_NAME) {\n-      // id - unique string\n-      // val_i - random int between 1-1000\n-      // cost_d - random cost between 1-1000\n-      // body_txt - random text string between 100 - 10000 words\n-      // acl_ss - set of 100-3000 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final int val = random().nextInt(1000) + 1;\n-        final double cost = random().nextDouble() * 1000d;\n-        final String body = String.join(\" \", getAFewDictionaryWords(random().nextInt(9900) + 100));\n-        final String[] acls = getAFewDictionaryWords(random().nextInt(2900) + 100, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"val_i\", val);\n-        newDoc.addField(\"cost_d\", cost);\n-        newDoc.addField(\"body_txt\", body);\n-        newDoc.addField(\"acl_ss\", acls);\n-\n-        return newDoc;\n-      }\n-    };\n-\n-    private int numDocs;\n-    private String collName;\n-    private static int[] userRecordCounts = new int[100];\n-    private static int currentUser = 1;\n-\n-    private DType(int numDocs, String collectionName) {\n-      this.numDocs = numDocs;\n-      this.collName = collectionName;\n-    }\n-\n-    abstract SolrInputDocument buildDoc();\n-  }\n-\n-  private static void loadCollectionData(DType type) throws Exception {\n-    int numDocs = type.numDocs;\n-    String collectionName = type.collName;\n-    int numLoaded = 0;\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      final int numBatches = numDocs / BATCH_SIZE + 1;\n-      final int commitEveryBatches = NUM_COMMITS > 0 ? numBatches / NUM_COMMITS : Integer.MAX_VALUE;\n-      int batchCount = 0;\n-      while (numLoaded < numDocs) {\n-        final int sizeOfBatch = numLoaded + BATCH_SIZE > numDocs ? numDocs - numLoaded : BATCH_SIZE;\n-        final Collection<SolrInputDocument> batch = buildBatch(type, sizeOfBatch);\n-        client.add(collectionName, batch);\n-        batchCount++;\n-        numLoaded+=sizeOfBatch;\n-\n-        if (batchCount == commitEveryBatches) {\n-          client.commit(collectionName);\n-          batchCount = 0;\n-        }\n-      }\n-      client.commit(collectionName);\n-    }\n-\n-  }\n-\n-  private static Collection<SolrInputDocument> buildBatch(DType type, int sizeOfBatch) {\n-    final List<SolrInputDocument> batch = Lists.newArrayList();\n-    for (int i = 0; i < sizeOfBatch; i++) {\n-      batch.add(type.buildDoc());\n-    }\n-    return batch;\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords) {\n-    return getAFewDictionaryWords(numWords, NUM_DICT_TERMS);\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords, int onlyFirstN) {\n-    final String[] words = new String[numWords];\n-    for (int i = 0; i < numWords; i++) {\n-      words[i] = LOADED_DICTIONARY[random().nextInt(onlyFirstN)];\n-    }\n-\n-    return words;\n-  }\n-\n-\n-  @Test\n-  public void testJoinPerformanceAsMainQueryHitsIncrease() throws Exception {\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-    final String fromQuery = \"userid_s:user25\"; // The higher the user number, the more permissions he has attached to his name (1-100)\n-    final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-    final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-    final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 0; i < VAL_MAX; i+=20) {\n-        final String mainQuery = \"val_i:[1 TO \" + (i+1) + \"]\";\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  @Test\n-  public void testJoinPerformanceAsFromQueryHitsIncrease() throws Exception {\n-    final String mainQuery = \"val_i:[1 TO 250]\"; // Half the docs match the query (250K)\n-\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 1; i <= USER_MAX; i++) {\n-        final String fromQuery = \"userid_s:user\" + i;\n-        final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-        final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-        final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  private static String buildTermsQueryString(int numTerms) {\n-    final String[] terms = getAFewDictionaryWords(numTerms);\n-    return String.join(\",\", terms);\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU0ODc5MA==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r370548790", "bodyText": "Shouldn't it load at least anything?", "author": "mkhludnev", "createdAt": "2020-01-24T09:50:40Z", "path": "solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.BufferedReader;\n+import java.io.FileReader;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest;\n+import org.apache.solr.client.solrj.impl.HttpSolrClient;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+\n+public class TestJoinQueryPerformance extends SolrTestCaseJ4 {\n+  // Dictionary used to load String data\n+  private static final String DICT_PATH = \"/usr/share/dict/words\";\n+  private static final int NUM_DICT_TERMS = 235886;\n+  private static final String[] LOADED_DICTIONARY = new String[NUM_DICT_TERMS];\n+\n+  // Performance run parameters: Indexing\n+  private static final String FROM_COLLECTION_NAME = \"user_acls\";\n+  private static final int NUM_FROM_DOCS = 5050; // 1 + 2 + 3 + 4 + ...  + 100\n+  private static final String TO_COLLECTION_NAME = \"products\";\n+  private static final int NUM_TO_DOCS = 500000;\n+  private static final int PERMISSION_CARDINALITY = 50000; // 50K unique groups/roles/whatever\n+  private static int BATCH_SIZE = 500;\n+  private static int NUM_COMMITS = 500;\n+  private static final int VAL_MAX = 1000;\n+  private static final int USER_MAX = 100;\n+\n+  private static String COLLECTION_NAME= \"foo\";\n+\n+  /*\n+   * As I start out here, I think I'll want a few different axes.\n+   *  - \"from\" collection matches (with \"to\" matches held constant)\n+   *  - \"to\" collection matches (with \"from\" matches held constant)\n+   *\n+   * So I think I should index a finite number of docs\n+   */\n+\n+  @BeforeClass\n+  public static void setUpCluster() throws Exception {\n+    loadDictionary();\n+    //loadCollectionData(DType.USER);", "originalCommit": "ac33c8efb5146a94347d7e340d199dfbf8548834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "chunk": "diff --git a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java b/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\ndeleted file mode 100644\nindex f7666cf1063..00000000000\n--- a/solr/core/src/test/org/apache/solr/search/TestJoinQueryPerformance.java\n+++ /dev/null\n\n@@ -1,235 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.solr.search;\n-\n-import java.io.BufferedReader;\n-import java.io.FileReader;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.UUID;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.solr.SolrTestCaseJ4;\n-import org.apache.solr.client.solrj.SolrQuery;\n-import org.apache.solr.client.solrj.SolrRequest;\n-import org.apache.solr.client.solrj.impl.HttpSolrClient;\n-import org.apache.solr.client.solrj.response.QueryResponse;\n-import org.apache.solr.common.SolrInputDocument;\n-import org.junit.BeforeClass;\n-import org.junit.Test;\n-\n-\n-public class TestJoinQueryPerformance extends SolrTestCaseJ4 {\n-  // Dictionary used to load String data\n-  private static final String DICT_PATH = \"/usr/share/dict/words\";\n-  private static final int NUM_DICT_TERMS = 235886;\n-  private static final String[] LOADED_DICTIONARY = new String[NUM_DICT_TERMS];\n-\n-  // Performance run parameters: Indexing\n-  private static final String FROM_COLLECTION_NAME = \"user_acls\";\n-  private static final int NUM_FROM_DOCS = 5050; // 1 + 2 + 3 + 4 + ...  + 100\n-  private static final String TO_COLLECTION_NAME = \"products\";\n-  private static final int NUM_TO_DOCS = 500000;\n-  private static final int PERMISSION_CARDINALITY = 50000; // 50K unique groups/roles/whatever\n-  private static int BATCH_SIZE = 500;\n-  private static int NUM_COMMITS = 500;\n-  private static final int VAL_MAX = 1000;\n-  private static final int USER_MAX = 100;\n-\n-  private static String COLLECTION_NAME= \"foo\";\n-\n-  /*\n-   * As I start out here, I think I'll want a few different axes.\n-   *  - \"from\" collection matches (with \"to\" matches held constant)\n-   *  - \"to\" collection matches (with \"from\" matches held constant)\n-   *\n-   * So I think I should index a finite number of docs\n-   */\n-\n-  @BeforeClass\n-  public static void setUpCluster() throws Exception {\n-    loadDictionary();\n-    //loadCollectionData(DType.USER);\n-    //loadCollectionData(DType.DATA);\n-  }\n-\n-  private static void loadDictionary() throws Exception {\n-    try (BufferedReader reader = new BufferedReader(new FileReader(DICT_PATH))) {\n-      for (int i = 0; i < NUM_DICT_TERMS; i++) {\n-        LOADED_DICTIONARY[i] = reader.readLine();\n-      }\n-    }\n-  }\n-\n-  public enum DType {\n-    USER(NUM_FROM_DOCS, FROM_COLLECTION_NAME) {\n-      // id - unique string\n-      // userid_s - username (user# from 1-100)...each user appears in # entries\n-      // permissions_ss - set of 300 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        if (userRecordCounts[currentUser - 1] == currentUser) {\n-          currentUser++;\n-        } else {\n-          userRecordCounts[currentUser -1]++;\n-        }\n-\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final String userString = \"user\" + currentUser;\n-        final String[] permissions = getAFewDictionaryWords(300, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"userid_s\", userString);\n-        newDoc.addField(\"permissions_ss\", permissions);\n-\n-        return newDoc;\n-      }\n-    },\n-    DATA(NUM_TO_DOCS, TO_COLLECTION_NAME) {\n-      // id - unique string\n-      // val_i - random int between 1-1000\n-      // cost_d - random cost between 1-1000\n-      // body_txt - random text string between 100 - 10000 words\n-      // acl_ss - set of 100-3000 string permissions (cardinality 50K)\n-      @Override\n-      SolrInputDocument buildDoc() {\n-        final SolrInputDocument newDoc = new SolrInputDocument(\"id\", UUID.randomUUID().toString());\n-        final int val = random().nextInt(1000) + 1;\n-        final double cost = random().nextDouble() * 1000d;\n-        final String body = String.join(\" \", getAFewDictionaryWords(random().nextInt(9900) + 100));\n-        final String[] acls = getAFewDictionaryWords(random().nextInt(2900) + 100, PERMISSION_CARDINALITY);\n-\n-        newDoc.addField(\"val_i\", val);\n-        newDoc.addField(\"cost_d\", cost);\n-        newDoc.addField(\"body_txt\", body);\n-        newDoc.addField(\"acl_ss\", acls);\n-\n-        return newDoc;\n-      }\n-    };\n-\n-    private int numDocs;\n-    private String collName;\n-    private static int[] userRecordCounts = new int[100];\n-    private static int currentUser = 1;\n-\n-    private DType(int numDocs, String collectionName) {\n-      this.numDocs = numDocs;\n-      this.collName = collectionName;\n-    }\n-\n-    abstract SolrInputDocument buildDoc();\n-  }\n-\n-  private static void loadCollectionData(DType type) throws Exception {\n-    int numDocs = type.numDocs;\n-    String collectionName = type.collName;\n-    int numLoaded = 0;\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      final int numBatches = numDocs / BATCH_SIZE + 1;\n-      final int commitEveryBatches = NUM_COMMITS > 0 ? numBatches / NUM_COMMITS : Integer.MAX_VALUE;\n-      int batchCount = 0;\n-      while (numLoaded < numDocs) {\n-        final int sizeOfBatch = numLoaded + BATCH_SIZE > numDocs ? numDocs - numLoaded : BATCH_SIZE;\n-        final Collection<SolrInputDocument> batch = buildBatch(type, sizeOfBatch);\n-        client.add(collectionName, batch);\n-        batchCount++;\n-        numLoaded+=sizeOfBatch;\n-\n-        if (batchCount == commitEveryBatches) {\n-          client.commit(collectionName);\n-          batchCount = 0;\n-        }\n-      }\n-      client.commit(collectionName);\n-    }\n-\n-  }\n-\n-  private static Collection<SolrInputDocument> buildBatch(DType type, int sizeOfBatch) {\n-    final List<SolrInputDocument> batch = Lists.newArrayList();\n-    for (int i = 0; i < sizeOfBatch; i++) {\n-      batch.add(type.buildDoc());\n-    }\n-    return batch;\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords) {\n-    return getAFewDictionaryWords(numWords, NUM_DICT_TERMS);\n-  }\n-\n-  private static String[] getAFewDictionaryWords(int numWords, int onlyFirstN) {\n-    final String[] words = new String[numWords];\n-    for (int i = 0; i < numWords; i++) {\n-      words[i] = LOADED_DICTIONARY[random().nextInt(onlyFirstN)];\n-    }\n-\n-    return words;\n-  }\n-\n-\n-  @Test\n-  public void testJoinPerformanceAsMainQueryHitsIncrease() throws Exception {\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-    final String fromQuery = \"userid_s:user25\"; // The higher the user number, the more permissions he has attached to his name (1-100)\n-    final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-    final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-    final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 0; i < VAL_MAX; i+=20) {\n-        final String mainQuery = \"val_i:[1 TO \" + (i+1) + \"]\";\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  @Test\n-  public void testJoinPerformanceAsFromQueryHitsIncrease() throws Exception {\n-    final String mainQuery = \"val_i:[1 TO 250]\"; // Half the docs match the query (250K)\n-\n-    final String joinQueryBase = \"{!join fromIndex=\" + FROM_COLLECTION_NAME + \" from=permissions_ss to=acl_ss cache=false\";\n-\n-\n-    try (HttpSolrClient client = new HttpSolrClient.Builder(\"http://localhost:8983/solr\").build()) {\n-      for ( int i = 1; i <= USER_MAX; i++) {\n-        final String fromQuery = \"userid_s:user\" + i;\n-        final String standardJoin = joinQueryBase + \"}\" + fromQuery;\n-        final String noScoreJoin = joinQueryBase + \" score=none}\" + fromQuery;\n-        final String tpiJoin = joinQueryBase + \" toplevel=true}\" + fromQuery;\n-\n-        final QueryResponse standardJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", standardJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse tpiJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", tpiJoin), SolrRequest.METHOD.POST);\n-        final QueryResponse noScoreJoinRsp = client.query(TO_COLLECTION_NAME, new SolrQuery(\"q\", mainQuery, \"fq\", noScoreJoin), SolrRequest.METHOD.POST);\n-        final long numFound = tpiJoinRsp.getResults().getNumFound();\n-\n-        System.out.println(i + \",\" + numFound + \",\" + standardJoinRsp.getQTime() + \",\" + noScoreJoinRsp.getQTime() + \",\" + tpiJoinRsp.getQTime());\n-      }\n-    }\n-  }\n-\n-  private static String buildTermsQueryString(int numTerms) {\n-    final String[] terms = getAFewDictionaryWords(numTerms);\n-    return String.join(\",\", terms);\n-  }\n-}\n"}}, {"oid": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "url": "https://github.com/apache/lucene-solr/commit/955bfbe76a05e98ac1614d30fdacb14eb0421f41", "message": "SOLR-13892: Address review feedback, round 1", "committedDate": "2020-01-27T15:18:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM3Njc0OA==", "url": "https://github.com/apache/lucene-solr/pull/1171#discussion_r371376748", "bodyText": "Always add at least one sentence javadoc for a class", "author": "dsmiley", "createdAt": "2020-01-27T17:25:52Z", "path": "solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+\n+import org.apache.lucene.index.DocValues;\n+import org.apache.lucene.index.LeafReader;\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.index.SortedSetDocValues;\n+import org.apache.lucene.search.Collector;\n+import org.apache.lucene.search.ConstantScoreScorer;\n+import org.apache.lucene.search.ConstantScoreWeight;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.ScoreMode;\n+import org.apache.lucene.search.Scorer;\n+import org.apache.lucene.search.TwoPhaseIterator;\n+import org.apache.lucene.search.Weight;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.LongBitSet;\n+import org.apache.solr.common.SolrException;\n+import org.apache.solr.schema.IndexSchema;\n+import org.apache.solr.schema.SchemaField;\n+import org.apache.solr.search.join.MultiValueTermOrdinalCollector;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class TopLevelJoinQuery extends JoinQuery {", "originalCommit": "955bfbe76a05e98ac1614d30fdacb14eb0421f41", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2e1795f1e261345544bdde949400ce8a4dd4c51b", "chunk": "diff --git a/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java b/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\nindex 20032754523..428c229b0d2 100644\n--- a/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\n+++ b/solr/core/src/java/org/apache/solr/search/TopLevelJoinQuery.java\n\n@@ -43,6 +43,9 @@ import org.apache.solr.search.join.MultiValueTermOrdinalCollector;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+/**\n+ * {@link JoinQuery} implementation using global (top-level) DocValues ordinals to efficiently compare values in the \"from\" and \"to\" fields.\n+ */\n public class TopLevelJoinQuery extends JoinQuery {\n   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n \n"}}, {"oid": "2e1795f1e261345544bdde949400ce8a4dd4c51b", "url": "https://github.com/apache/lucene-solr/commit/2e1795f1e261345544bdde949400ce8a4dd4c51b", "message": "SOLR-13892: Address review feedback, round 2", "committedDate": "2020-01-28T03:10:05Z", "type": "commit"}, {"oid": "5a75475ffecfc4cbe05adf3f0fb7cbbcdcbe88f5", "url": "https://github.com/apache/lucene-solr/commit/5a75475ffecfc4cbe05adf3f0fb7cbbcdcbe88f5", "message": "Merge branch 'master' into jira/solr-13892", "committedDate": "2020-01-28T03:12:55Z", "type": "commit"}, {"oid": "99c336b6ef3274ec8572813b79bdd0fdea25ca57", "url": "https://github.com/apache/lucene-solr/commit/99c336b6ef3274ec8572813b79bdd0fdea25ca57", "message": "Remove unused imports", "committedDate": "2020-01-29T13:26:27Z", "type": "commit"}, {"oid": "1d615522c0075b39208801da0d13509961a2e787", "url": "https://github.com/apache/lucene-solr/commit/1d615522c0075b39208801da0d13509961a2e787", "message": "Address review feedback, rd #3", "committedDate": "2020-01-30T18:18:11Z", "type": "commit"}, {"oid": "4a83816e51189f0963cf4247a4fcfa6224f61951", "url": "https://github.com/apache/lucene-solr/commit/4a83816e51189f0963cf4247a4fcfa6224f61951", "message": "SOLR-13892: CHANGES.txt entry", "committedDate": "2020-01-31T12:54:06Z", "type": "commit"}]}