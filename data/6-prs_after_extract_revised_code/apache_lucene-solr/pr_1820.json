{"pr_number": 1820, "pr_title": "LUCENE-9464: Add high(er)-level hit highlighter example that demonstrates and uses low-level components", "pr_createdAt": "2020-09-02T10:17:08Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1820", "timeline": [{"oid": "096faa6de18739f8ef98c818798a96e138000c76", "url": "https://github.com/apache/lucene-solr/commit/096faa6de18739f8ef98c818798a96e138000c76", "message": "Initial.", "committedDate": "2020-09-01T12:38:45Z", "type": "commit"}, {"oid": "62d6ed3fe4200ccb41ae0baa88fe152be9e539b6", "url": "https://github.com/apache/lucene-solr/commit/62d6ed3fe4200ccb41ae0baa88fe152be9e539b6", "message": "More cleanups and a verbose test showcasing the highlighter.:", "committedDate": "2020-09-02T09:59:33Z", "type": "commit"}, {"oid": "1452116478af4b814871423450cfc9cc99b28da4", "url": "https://github.com/apache/lucene-solr/commit/1452116478af4b814871423450cfc9cc99b28da4", "message": "Add javadoc, move default implementations to main code.", "committedDate": "2020-09-02T10:05:55Z", "type": "commit"}, {"oid": "a5d18a014aeae84f40afa66111bc1ac172010cfc", "url": "https://github.com/apache/lucene-solr/commit/a5d18a014aeae84f40afa66111bc1ac172010cfc", "message": "Follow-up: use word break iterator adjuster by default. Add a synonym highlighting test.", "committedDate": "2020-09-02T10:48:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDg5MTA1NA==", "url": "https://github.com/apache/lucene-solr/pull/1820#discussion_r484891054", "bodyText": "Just out of interest, what happens if you don't add a skipRemaining() highlighter to the end?  If it's necessary, maybe we should convert to a Builder pattern and automatically add it to the end of the highlighters list before returning the MatchHighlighter?", "author": "romseygeek", "createdAt": "2020-09-08T12:52:36Z", "path": "lucene/highlighter/src/test/org/apache/lucene/search/matchhighlight/TestMatchHighlighter.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.search.matchhighlight;\n+\n+import com.carrotsearch.randomizedtesting.RandomizedTest;\n+import org.apache.lucene.analysis.Analyzer;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.Tokenizer;\n+import org.apache.lucene.analysis.core.WhitespaceTokenizer;\n+import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper;\n+import org.apache.lucene.analysis.synonym.SynonymGraphFilter;\n+import org.apache.lucene.analysis.synonym.SynonymMap;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.FieldType;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.IndexOptions;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.Term;\n+import org.apache.lucene.queries.intervals.IntervalQuery;\n+import org.apache.lucene.queries.intervals.Intervals;\n+import org.apache.lucene.search.BooleanClause;\n+import org.apache.lucene.search.BooleanQuery;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.PhraseQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.TermQuery;\n+import org.apache.lucene.search.TopDocs;\n+import org.apache.lucene.util.CharsRef;\n+import org.apache.lucene.util.LuceneTestCase;\n+import org.hamcrest.Matchers;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class TestMatchHighlighter extends LuceneTestCase {\n+  private static final String FLD_ID = \"id\";\n+  private static final String FLD_TEXT1 = \"text1\";\n+  private static final String FLD_TEXT2 = \"text2\";\n+\n+  private FieldType TYPE_TEXT_POSITIONS_OFFSETS;\n+  private FieldType TYPE_TEXT_POSITIONS;\n+\n+  private PerFieldAnalyzerWrapper analyzer;\n+\n+  @Before\n+  public void setup() throws IOException {\n+    TYPE_TEXT_POSITIONS = TextField.TYPE_STORED;\n+\n+    TYPE_TEXT_POSITIONS_OFFSETS = new FieldType(TextField.TYPE_STORED);\n+    TYPE_TEXT_POSITIONS_OFFSETS.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n+    TYPE_TEXT_POSITIONS_OFFSETS.freeze();\n+\n+    Map<String, Analyzer> fieldAnalyzers = new HashMap<>();\n+\n+    // Create an analyzer with some synonyms, just to showcase them.\n+    SynonymMap synonymMap = buildSynonymMap(new String[][]{\n+        {\"moon\\u0000shine\", \"firewater\"},\n+        {\"firewater\", \"moon\\u0000shine\"},\n+    });\n+\n+    // Make a non-empty offset gap so that break iterator doesn't go haywire on multivalues\n+    // glued together.\n+    final int offsetGap = RandomizedTest.randomIntBetween(1, 2);\n+    final int positionGap = RandomizedTest.randomFrom(new int[]{0, 1, 100});\n+    Analyzer synonymsAnalyzer =\n+        new AnalyzerWithGaps(offsetGap, positionGap, new Analyzer() {\n+          @Override\n+          protected TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new WhitespaceTokenizer();\n+            TokenStream tokenStream = new SynonymGraphFilter(tokenizer, synonymMap, true);\n+            return new TokenStreamComponents(tokenizer, tokenStream);\n+          }\n+        });\n+\n+    fieldAnalyzers.put(FLD_TEXT1, synonymsAnalyzer);\n+    fieldAnalyzers.put(FLD_TEXT2, synonymsAnalyzer);\n+\n+    analyzer = new PerFieldAnalyzerWrapper(new MissingAnalyzer(), fieldAnalyzers);\n+  }\n+\n+  static SynonymMap buildSynonymMap(String[][] synonyms) throws IOException {\n+    SynonymMap.Builder builder = new SynonymMap.Builder();\n+    for (String[] pair : synonyms) {\n+      assertThat(pair.length, Matchers.equalTo(2));\n+      builder.add(new CharsRef(pair[0]), new CharsRef(pair[1]), true);\n+    }\n+    return builder.build();\n+  }\n+\n+  @Test\n+  public void testBasicUsage() throws IOException {\n+    new IndexBuilder(this::toField)\n+        .doc(FLD_TEXT1, \"foo bar baz\")\n+        .doc(FLD_TEXT1, \"bar foo baz\")\n+        .doc(fields -> {\n+          fields.add(FLD_TEXT1, \"Very long content but not matching anything.\");\n+          fields.add(FLD_TEXT2, \"no foo but bar\");\n+        })\n+        .build(analyzer, reader -> {\n+          Query query = new BooleanQuery.Builder()\n+              .add(new TermQuery(new Term(FLD_TEXT1, \"foo\")), BooleanClause.Occur.SHOULD)\n+              .add(new TermQuery(new Term(FLD_TEXT2, \"bar\")), BooleanClause.Occur.SHOULD)\n+              .build();\n+\n+          // In the most basic scenario, we run a search against a query, retrieve\n+          // top docs...\n+          IndexSearcher searcher = new IndexSearcher(reader);\n+          Sort sortOrder = Sort.INDEXORDER; // So that results are consistently ordered.\n+          TopDocs topDocs = searcher.search(query, 10, sortOrder);\n+\n+          // ...and would want a fixed set of fields from those documents, some of them\n+          // possibly highlighted if they matched the query.\n+          //\n+          // This configures the highlighter so that the FLD_ID field is always returned verbatim,\n+          // and FLD_TEXT1 is returned *only if it contained a query match*.\n+          MatchHighlighter highlighter =\n+              new MatchHighlighter(searcher, analyzer)\n+                .appendFieldHighlighter(FieldValueHighlighters.verbatimValue(FLD_ID))\n+                .appendFieldHighlighter(FieldValueHighlighters.highlighted(\n+                    80 * 3, 1, new PassageFormatter(\"...\", \">\", \"<\"), FLD_TEXT1::equals))\n+                .appendFieldHighlighter(FieldValueHighlighters.skipRemaining());", "originalCommit": "a5d18a014aeae84f40afa66111bc1ac172010cfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkwMDE1Ng==", "url": "https://github.com/apache/lucene-solr/pull/1820#discussion_r484900156", "bodyText": "These field highlighters can apply to more than one field and the highlighter may receive fields it wasn't prepared to process (because they were part of the query). I opted to be explicit - if no field highlighter \"accepts\" a field, the entire highlighting process fails. The \"skip remaining\" is essentially a rule that does nothing for any field that wasn't consumed before.\nPerformance-wise I admit I wasn't too keen on optimizing things too early. This thing, even if slower, just works for me in\nso many more scenarios than any of the approaches I've tried with other highlighters in Lucene. That \"two queries at once\" example isn't entirely out of thin air... we actually do use something like this to highlight queries originating from different sources.", "author": "dweiss", "createdAt": "2020-09-08T13:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDg5MTA1NA=="}], "type": "inlineReview", "revised_code": null}]}