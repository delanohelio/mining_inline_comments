{"pr_number": 1623, "pr_title": "LUCENE-8962: Merge segments on getReader", "pr_createdAt": "2020-06-27T22:11:26Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1623", "timeline": [{"oid": "b479442c04849f374899ce057db5b5e8f1a9f4c5", "url": "https://github.com/apache/lucene-solr/commit/b479442c04849f374899ce057db5b5e8f1a9f4c5", "message": "can it be that simple?", "committedDate": "2020-06-27T22:09:26Z", "type": "commit"}, {"oid": "419f309435c77d9b816628f56c9a533d0799128c", "url": "https://github.com/apache/lucene-solr/commit/419f309435c77d9b816628f56c9a533d0799128c", "message": "LUCENE-8962: fix test case to use no merge policy since it wants explicit segments", "committedDate": "2020-06-29T14:47:40Z", "type": "commit"}, {"oid": "65e335e0c8ac9a076edbef838489b732cfaf419c", "url": "https://github.com/apache/lucene-solr/commit/65e335e0c8ac9a076edbef838489b732cfaf419c", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-10T12:13:38Z", "type": "commit"}, {"oid": "e83ceebbb83837228ad0a38f1590fb79f4cb8945", "url": "https://github.com/apache/lucene-solr/commit/e83ceebbb83837228ad0a38f1590fb79f4cb8945", "message": "different approach", "committedDate": "2020-08-12T19:14:50Z", "type": "commit"}, {"oid": "84cdc5a3a9ad7b78eac9170c7842feed70ed0692", "url": "https://github.com/apache/lucene-solr/commit/84cdc5a3a9ad7b78eac9170c7842feed70ed0692", "message": "improve error handling", "committedDate": "2020-08-12T20:09:07Z", "type": "commit"}, {"oid": "4791e050d9547caf8b37068f6ee4797713ea65ec", "url": "https://github.com/apache/lucene-solr/commit/4791e050d9547caf8b37068f6ee4797713ea65ec", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-12T20:18:14Z", "type": "commit"}, {"oid": "b701264ff304a4c0483b36b6dbc36d3cc8ed1075", "url": "https://github.com/apache/lucene-solr/commit/b701264ff304a4c0483b36b6dbc36d3cc8ed1075", "message": "beef up tests to also cover getReader", "committedDate": "2020-08-13T15:20:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI3NDA2Nw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470274067", "bodyText": "This Javadoc will need to be updated to reflect the broader use of this method.\nAlso, is preparePointInTimeMerge (without the on) a better name?", "author": "msfroh", "createdAt": "2020-08-13T22:03:08Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -3321,8 +3395,11 @@ private long prepareCommitInternal() throws IOException {\n    * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise\n    * we could see concurrent deletions/updates applied that do not belong to the segment.", "originalCommit": "b701264ff304a4c0483b36b6dbc36d3cc8ed1075", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "888d9a000dfac7e46c93203fa72569499e073848", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a7643efdb2d..2a04e471c2f 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -3386,24 +3386,24 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n   }\n \n   /**\n-   * This optimization allows a commit to wait for merges on smallish segments to\n-   * reduce the eventual number of tiny segments in the commit point.  We wrap a {@code OneMerge} to\n-   * update the {@code committingSegmentInfos} once the merge has finished.  We replace the source segments\n-   * in the SIS that we are going to commit with the freshly merged segment, but ignore all deletions and updates\n-   * that are made to documents in the merged segment while it was merging.  The updates that are made do not belong to\n-   * the point-in-time commit point and should therefore not be included. See the clone call in {@code onMergeComplete}\n+   * This optimization allows a commit/getReader to wait for merges on smallish segments to\n+   * reduce the eventual number of tiny segments in the commit point / NRT Reader.  We wrap a {@code OneMerge} to\n+   * update the {@code mergingSegmentInfos} once the merge has finished. We replace the source segments\n+   * in the SIS that we are going to commit / open the reader on with the freshly merged segment, but ignore all deletions and updates\n+   * that are made to documents in the merged segment while it was merging. The updates that are made do not belong to\n+   * the point-in-time commit point / NRT READER and should therefore not be included. See the clone call in {@code onMergeComplete}\n    * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise\n    * we could see concurrent deletions/updates applied that do not belong to the segment.\n    */\n-  private MergePolicy.MergeSpecification prepareOnPointInTimeMerge(SegmentInfos mergeingSegmentInfos, AtomicBoolean includeMergeResult,\n-                                                                   MergeTrigger trigger,\n-                                                                   IOUtils.IOConsumer<SegmentCommitInfo> mergeFinished) throws IOException {\n+  private MergePolicy.MergeSpecification preparePointInTimeMerge(SegmentInfos mergingSegmentInfos, AtomicBoolean includeMergeResult,\n+                                                                 MergeTrigger trigger,\n+                                                                 IOUtils.IOConsumer<SegmentCommitInfo> mergeFinished) throws IOException {\n     assert Thread.holdsLock(this);\n     assert trigger == MergeTrigger.GET_READER || trigger == MergeTrigger.COMMIT : \"illegal trigger: \" + trigger;\n     MergePolicy.MergeSpecification onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n         new MergePolicy.OneMerge(toWrap.segments) {\n           SegmentCommitInfo origInfo;\n-          AtomicBoolean onlyOnce = new AtomicBoolean(false);\n+          final AtomicBoolean onlyOnce = new AtomicBoolean(false);\n \n           @Override\n           public void mergeFinished(boolean committed, boolean segmentDropped) throws IOException {\n"}}, {"oid": "118fc61d593cd51be67ac42249a07c05daa78f10", "url": "https://github.com/apache/lucene-solr/commit/118fc61d593cd51be67ac42249a07c05daa78f10", "message": "never open a merged reader if it's dropped", "committedDate": "2020-08-14T09:29:27Z", "type": "commit"}, {"oid": "888d9a000dfac7e46c93203fa72569499e073848", "url": "https://github.com/apache/lucene-solr/commit/888d9a000dfac7e46c93203fa72569499e073848", "message": "Appy feedback and update javadoc", "committedDate": "2020-08-14T09:33:07Z", "type": "commit"}, {"oid": "a2f392c65f5ef5a1423543ed84e950a53a331928", "url": "https://github.com/apache/lucene-solr/commit/a2f392c65f5ef5a1423543ed84e950a53a331928", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-14T11:30:11Z", "type": "commit"}, {"oid": "4a4d6fa0b30eb0234aedbb03032efa7c0149054f", "url": "https://github.com/apache/lucene-solr/commit/4a4d6fa0b30eb0234aedbb03032efa7c0149054f", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-14T13:45:30Z", "type": "commit"}, {"oid": "1f885db34aa97d98b2196885471200ef7fa05e10", "url": "https://github.com/apache/lucene-solr/commit/1f885db34aa97d98b2196885471200ef7fa05e10", "message": "Ensure we hold a valid ref to every SR while we merge them in the background", "committedDate": "2020-08-14T14:04:32Z", "type": "commit"}, {"oid": "6d8c601789501d5880847cef13d7cacc402fcd0c", "url": "https://github.com/apache/lucene-solr/commit/6d8c601789501d5880847cef13d7cacc402fcd0c", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-14T14:06:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzAzMA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471017030", "bodyText": "There's no need to check whether we timed out here, since we effectively abort all of the point-in-time merges we created by setting includeMergeReader to false below, right? I wonder if it would be cleaner to eliminate this AtomicBoolean that is shared with this and the merge threads, and instead using the existing merge abort technique that we have? OTOH IDK how that other mechanism works - is it aborting all outstanding merges?", "author": "msokolov", "createdAt": "2020-08-15T17:33:32Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE0NTk5NQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471145995", "bodyText": "we actually never abort these merges. there is no reason why we should do that. we might have done most of the work, we only abort merges if we shutdown our writers. I hope that makes sense?", "author": "s1monw", "createdAt": "2020-08-16T18:54:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzAzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE3NDI5OA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471174298", "bodyText": "OK, I misunderstood the usage of includeMergeReader. I guess the idea is that we let them continue, but keep the original (merging) segments in the reader we're opening, so we do need a separate condition for that", "author": "msokolov", "createdAt": "2020-08-16T23:42:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzAzMA=="}], "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzM3Mg==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471017372", "bodyText": "and this one, closeMergedReaders?", "author": "msokolov", "createdAt": "2020-08-15T17:37:51Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+          assert openingSegmentInfos != null;\n+          synchronized (this) {\n+            includeMergeReader.set(false);\n+            boolean openNewReader = mergedReaders.isEmpty() == false;\n+            if (openNewReader) {\n+              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n+                  sci -> {\n+                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n+                    // will take care of closing it. We only need to handle the readers that remain in the\n+                    // mergedReaders map and close them.\n+                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n+                    if (remove == null) {\n+                      remove = openedReadOnlyClones.remove(sci.info.name);\n+                      assert remove != null;\n+                      // each of the readers we reuse from the previous reader needs to be refInced\n+                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n+                      remove.incRef();\n+                    }\n+                    return remove;\n+                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n+              try {\n+                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n+              } finally {\n+                r = mergedReader;\n+              }\n+            }\n+          }\n+          replaceReaderSuccess = true;\n+        } finally {\n+          synchronized (this) {", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzQwNA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471017404", "bodyText": "This method is getting pretty big, and it might help readability if we named these synchronized blocks as functions. This one could be replaceReader()? OTOH maybe it requires too many parameters - it's hard to tell in code review", "author": "msokolov", "createdAt": "2020-08-15T17:38:31Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+          assert openingSegmentInfos != null;\n+          synchronized (this) {", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE0NjgyOA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471146828", "bodyText": "I added one new method. I don't think we should extract more WDYT", "author": "s1monw", "createdAt": "2020-08-16T19:03:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTAxNzQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"oid": "262c1937668af4923aa3b526bc29e22769fc1a94", "url": "https://github.com/apache/lucene-solr/commit/262c1937668af4923aa3b526bc29e22769fc1a94", "message": "don't use on commit merge if we assert on no deletion of open files", "committedDate": "2020-08-16T18:53:33Z", "type": "commit"}, {"oid": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "url": "https://github.com/apache/lucene-solr/commit/d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "message": "extract method to reopen segment reader on getReader merge", "committedDate": "2020-08-16T19:02:26Z", "type": "commit"}, {"oid": "c1668b7ff3738c899b81fc1e66e7ceb8a4c5098a", "url": "https://github.com/apache/lucene-solr/commit/c1668b7ff3738c899b81fc1e66e7ceb8a4c5098a", "message": "fix reopen code", "committedDate": "2020-08-16T19:15:22Z", "type": "commit"}, {"oid": "9c0f5ca5f9671e610ff00e0236c06f1f880e2585", "url": "https://github.com/apache/lucene-solr/commit/9c0f5ca5f9671e610ff00e0236c06f1f880e2585", "message": "Rename method", "committedDate": "2020-08-16T19:15:51Z", "type": "commit"}, {"oid": "15d030d983af0a1ed18335d69f1aa025512bdf5b", "url": "https://github.com/apache/lucene-solr/commit/15d030d983af0a1ed18335d69f1aa025512bdf5b", "message": "factory out finish method", "committedDate": "2020-08-16T20:34:43Z", "type": "commit"}, {"oid": "73d5c70ca4736f2a091dc8be789603de7b4a2be9", "url": "https://github.com/apache/lucene-solr/commit/73d5c70ca4736f2a091dc8be789603de7b4a2be9", "message": "add a high level explain how getReader works and what locks need to be hold when to allow folks to understand the code more easily", "committedDate": "2020-08-17T07:39:46Z", "type": "commit"}, {"oid": "2e7e822f98d8f30726155ae7e99ce09794442aad", "url": "https://github.com/apache/lucene-solr/commit/2e7e822f98d8f30726155ae7e99ce09794442aad", "message": "fix settings naming", "committedDate": "2020-08-17T08:16:38Z", "type": "commit"}, {"oid": "e4a1ba92e805573b47262ebe3d3e9b2e04ebe964", "url": "https://github.com/apache/lucene-solr/commit/e4a1ba92e805573b47262ebe3d3e9b2e04ebe964", "message": "better name for the wait condition", "committedDate": "2020-08-17T08:16:44Z", "type": "commit"}, {"oid": "3508c0c9099186d033d31cc38da46074a9707b6b", "url": "https://github.com/apache/lucene-solr/commit/3508c0c9099186d033d31cc38da46074a9707b6b", "message": "don't leak the atomic boolean", "committedDate": "2020-08-17T08:30:00Z", "type": "commit"}, {"oid": "a0bbf1a15236d587e5e84c5eb112752594659c77", "url": "https://github.com/apache/lucene-solr/commit/a0bbf1a15236d587e5e84c5eb112752594659c77", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-17T09:07:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2OTg4MA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470869880", "bodyText": "Thank you for good success variable naming instead of the usual success1 and success2 etc.!", "author": "mikemccand", "createdAt": "2020-08-14T21:19:19Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk1NTk4MA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471955980", "bodyText": "\ud83d\udc4d", "author": "s1monw", "createdAt": "2020-08-18T06:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2OTg4MA=="}], "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MTE0Ng==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470871146", "bodyText": "Maybe we need to rename this IWC option and variables?  Maybe we need two timeouts, one for commit, one for getReader?  Or, maybe we somehow make this a property of the MergeSpecification so MergePolicy can decide case by case what the timeout should be?", "author": "mikemccand", "createdAt": "2020-08-14T21:22:47Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk5MTY2NQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471991665", "bodyText": "I'd not want to add another option to IWC unless absolutely necessary. Maybe we can just keep one for now and if somebody has a good usecase we can still add? I think we have the ability to disable it entirely for one or the other trigger which should be enough in most cases?", "author": "s1monw", "createdAt": "2020-08-18T08:02:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MTE0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjE2MjYxMA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472162610", "bodyText": "OK let's leave this be for now.", "author": "mikemccand", "createdAt": "2020-08-18T12:54:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MTE0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MDcxNQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470880715", "bodyText": "Good name!  Maybe rename onCommitMerges to pointInTimeMerges?", "author": "mikemccand", "createdAt": "2020-08-14T21:52:37Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -3244,7 +3322,7 @@ private long prepareCommitInternal() throws IOException {\n               if (anyChanges && maxCommitMergeWaitMillis > 0) {\n                 // we can safely call prepareOnCommitMerge since writeReaderPool(true) above wrote all\n                 // necessary files to disk and checkpointed them.\n-                onCommitMerges = prepareOnCommitMerge(toCommit, includeInCommit);\n+                onCommitMerges = preparePointInTimeMerge(toCommit, includeInCommit, MergeTrigger.COMMIT, sci->{});", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e4a1ba92e805573b47262ebe3d3e9b2e04ebe964", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..270fdd023f6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -3322,7 +3366,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n               if (anyChanges && maxCommitMergeWaitMillis > 0) {\n                 // we can safely call prepareOnCommitMerge since writeReaderPool(true) above wrote all\n                 // necessary files to disk and checkpointed them.\n-                onCommitMerges = preparePointInTimeMerge(toCommit, includeInCommit, MergeTrigger.COMMIT, sci->{});\n+                onCommitMerges = preparePointInTimeMerge(toCommit, hasTimedOut, MergeTrigger.COMMIT, sci->{});\n               }\n             }\n             success = true;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MTA5Mg==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470881092", "bodyText": "Hmm why don't we need to deleter.incRef for NRT reader case?  I guess the NRT reader we opened holds a reference already?", "author": "mikemccand", "createdAt": "2020-08-14T21:53:59Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -3335,49 +3416,60 @@ public void mergeFinished(boolean committed, boolean segmentDropped) throws IOEx\n             // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock\n             // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout\n             // and will not commit our merge to the to-be-commited SegmentInfos\n-            \n             if (segmentDropped == false\n                 && committed\n-                && includeInCommit.get()) {\n+                && includeMergeResult.get()) {\n+\n+              // make sure onMergeComplete really was called:\n+              assert origInfo != null;\n \n               if (infoStream.isEnabled(\"IW\")) {\n                 infoStream.message(\"IW\", \"now apply merge during commit: \" + toWrap.segString());\n               }\n \n-              // make sure onMergeComplete really was called:\n-              assert origInfo != null;\n-\n-              deleter.incRef(origInfo.files());\n+              if (trigger == MergeTrigger.COMMIT) { // if we do this in a getReader call here this is obsolete\n+                deleter.incRef(origInfo.files());", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk1NzcxMw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471957713", "bodyText": "I extended the comment", "author": "s1monw", "createdAt": "2020-08-18T07:02:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MTA5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e4a1ba92e805573b47262ebe3d3e9b2e04ebe964", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..270fdd023f6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -3418,7 +3462,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n             // and will not commit our merge to the to-be-commited SegmentInfos\n             if (segmentDropped == false\n                 && committed\n-                && includeMergeResult.get()) {\n+                && hasTimedOut.get() == false) {\n \n               // make sure onMergeComplete really was called:\n               assert origInfo != null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MTUxMw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470881513", "bodyText": "Re-indent?", "author": "mikemccand", "createdAt": "2020-08-14T21:55:24Z", "path": "lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader.java", "diffHunk": "@@ -82,7 +82,8 @@ protected DirectoryReader doBody(String segmentFileName) throws IOException {\n   }\n \n   /** Used by near real-time search */\n-  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n+  static StandardDirectoryReader open(IndexWriter writer, IOUtils.IOFunction<SegmentCommitInfo, SegmentReader> readerFunction,\n+                              SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader.java b/lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader.java\nindex 3bc1a7af1d3..1003acfddf4 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader.java\n\n@@ -83,7 +83,7 @@ public final class StandardDirectoryReader extends DirectoryReader {\n \n   /** Used by near real-time search */\n   static StandardDirectoryReader open(IndexWriter writer, IOUtils.IOFunction<SegmentCommitInfo, SegmentReader> readerFunction,\n-                              SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n+                                      SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n     // IndexWriter synchronizes externally before calling\n     // us, which ensures infos will not change; so there's\n     // no need to process segments in reverse order\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MjE3OQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470882179", "bodyText": "Maybe move the assert to top of the method?  We should always hold IW's monitor lock on entry?", "author": "mikemccand", "createdAt": "2020-08-14T21:57:25Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -3335,49 +3416,60 @@ public void mergeFinished(boolean committed, boolean segmentDropped) throws IOEx\n             // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock\n             // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout\n             // and will not commit our merge to the to-be-commited SegmentInfos\n-            \n             if (segmentDropped == false\n                 && committed\n-                && includeInCommit.get()) {\n+                && includeMergeResult.get()) {\n+\n+              // make sure onMergeComplete really was called:\n+              assert origInfo != null;\n \n               if (infoStream.isEnabled(\"IW\")) {\n                 infoStream.message(\"IW\", \"now apply merge during commit: \" + toWrap.segString());\n               }\n \n-              // make sure onMergeComplete really was called:\n-              assert origInfo != null;\n-\n-              deleter.incRef(origInfo.files());\n+              if (trigger == MergeTrigger.COMMIT) { // if we do this in a getReader call here this is obsolete\n+                deleter.incRef(origInfo.files());\n+              }\n               Set<String> mergedSegmentNames = new HashSet<>();\n               for (SegmentCommitInfo sci : segments) {\n                 mergedSegmentNames.add(sci.info.name);\n               }\n               List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n-              for (SegmentCommitInfo sci : committingSegmentInfos) {\n+              for (SegmentCommitInfo sci : mergingSegmentInfos) {\n                 if (mergedSegmentNames.contains(sci.info.name)) {\n                   toCommitMergedAwaySegments.add(sci);\n-                  deleter.decRef(sci.files());\n+                  if (trigger == MergeTrigger.COMMIT) { // if we do this in a getReader call here this is obsolete\n+                    deleter.decRef(sci.files());\n+                  }\n                 }\n               }\n               // Construct a OneMerge that applies to toCommit\n               MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n               applicableMerge.info = origInfo;\n               long segmentCounter = Long.parseLong(origInfo.info.name.substring(1), Character.MAX_RADIX);\n-              committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);\n-              committingSegmentInfos.applyMergeChanges(applicableMerge, false);\n+              mergingSegmentInfos.counter = Math.max(mergingSegmentInfos.counter, segmentCounter + 1);\n+              mergingSegmentInfos.applyMergeChanges(applicableMerge, false);\n             } else {\n               if (infoStream.isEnabled(\"IW\")) {\n                 infoStream.message(\"IW\", \"skip apply merge during commit: \" + toWrap.segString());\n               }\n             }\n-            toWrap.mergeFinished(committed, false);\n+            toWrap.mergeFinished(committed, segmentDropped);\n             super.mergeFinished(committed, segmentDropped);\n           }\n \n           @Override\n-          void onMergeComplete() {\n-            // clone the target info to make sure we have the original info without the updated del and update gens\n-            origInfo = info.clone();\n+          void onMergeComplete() throws IOException {\n+            if (includeMergeResult.get()\n+                && isAborted() == false\n+                && info.info.maxDoc() > 0/* never do this if the segment if dropped / empty */) {\n+              assert Thread.holdsLock(IndexWriter.this);", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e4a1ba92e805573b47262ebe3d3e9b2e04ebe964", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..270fdd023f6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -3418,7 +3462,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n             // and will not commit our merge to the to-be-commited SegmentInfos\n             if (segmentDropped == false\n                 && committed\n-                && includeMergeResult.get()) {\n+                && hasTimedOut.get() == false) {\n \n               // make sure onMergeComplete really was called:\n               assert origInfo != null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4MjY5Nw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470882697", "bodyText": "s/refInced/incRef'd?", "author": "mikemccand", "createdAt": "2020-08-14T21:59:03Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+          assert openingSegmentInfos != null;\n+          synchronized (this) {\n+            includeMergeReader.set(false);\n+            boolean openNewReader = mergedReaders.isEmpty() == false;\n+            if (openNewReader) {\n+              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n+                  sci -> {\n+                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n+                    // will take care of closing it. We only need to handle the readers that remain in the\n+                    // mergedReaders map and close them.\n+                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n+                    if (remove == null) {\n+                      remove = openedReadOnlyClones.remove(sci.info.name);\n+                      assert remove != null;\n+                      // each of the readers we reuse from the previous reader needs to be refInced", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4Mjc2NQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r470882765", "bodyText": "s/refInc/incRef?", "author": "mikemccand", "createdAt": "2020-08-14T21:59:19Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -607,6 +633,57 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n           }\n         }\n       }\n+      if (onCommitMerges != null) { // only relevant if we do merge on getReader\n+        boolean replaceReaderSuccess = false;\n+        try {\n+          mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+          onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+          assert openingSegmentInfos != null;\n+          synchronized (this) {\n+            includeMergeReader.set(false);\n+            boolean openNewReader = mergedReaders.isEmpty() == false;\n+            if (openNewReader) {\n+              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n+                  sci -> {\n+                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n+                    // will take care of closing it. We only need to handle the readers that remain in the\n+                    // mergedReaders map and close them.\n+                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n+                    if (remove == null) {\n+                      remove = openedReadOnlyClones.remove(sci.info.name);\n+                      assert remove != null;\n+                      // each of the readers we reuse from the previous reader needs to be refInced\n+                      // since we reuse them but don't have an implicit refInc in the SDR:open call", "originalCommit": "6d8c601789501d5880847cef13d7cacc402fcd0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6a99a38c06e2eaa1065040bdcb2e599ec3ed8e4", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9a301e16797..84426a07acd 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -641,29 +641,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n           assert openingSegmentInfos != null;\n           synchronized (this) {\n             includeMergeReader.set(false);\n-            boolean openNewReader = mergedReaders.isEmpty() == false;\n-            if (openNewReader) {\n-              StandardDirectoryReader mergedReader = StandardDirectoryReader.open(this,\n-                  sci -> {\n-                    // as soon as we remove the reader and return it the StandardDirectoryReader#open\n-                    // will take care of closing it. We only need to handle the readers that remain in the\n-                    // mergedReaders map and close them.\n-                    SegmentReader remove = mergedReaders.remove(sci.info.name);\n-                    if (remove == null) {\n-                      remove = openedReadOnlyClones.remove(sci.info.name);\n-                      assert remove != null;\n-                      // each of the readers we reuse from the previous reader needs to be refInced\n-                      // since we reuse them but don't have an implicit refInc in the SDR:open call\n-                      remove.incRef();\n-                    }\n-                    return remove;\n-                  }, openingSegmentInfos, applyAllDeletes, writeAllDeletes);\n-              try {\n-                r.close(); // close and swap in the new reader... close is cool here since we didn't leak this reader yet\n-              } finally {\n-                r = mergedReader;\n-              }\n-            }\n+            r = reopenMergedNRTReader(r, mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n+                applyAllDeletes, writeAllDeletes);\n           }\n           replaceReaderSuccess = true;\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcyOTU3OA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471729578", "bodyText": "s/do/to?", "author": "mikemccand", "createdAt": "2020-08-17T19:31:58Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -545,18 +546,54 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n     // obtained during this flush are pooled, the first time\n     // this method is called:\n     readerPool.enableReaderPooling();\n-    DirectoryReader r = null;\n+    StandardDirectoryReader r = null;\n     doBeforeFlush();\n-    boolean anyChanges = false;\n+    boolean anyChanges;\n     /*\n      * for releasing a NRT reader we must ensure that \n      * DW doesn't add any segments or deletes until we are\n      * done with creating the NRT DirectoryReader. \n      * We release the two stage full flush after we are done opening the\n      * directory reader!\n      */\n+    MergePolicy.MergeSpecification onGetReaderMerges = null;\n+    AtomicBoolean hasTimedOut = new AtomicBoolean(false);\n+    Map<String, SegmentReader> mergedReaders = new HashMap<>();\n+    Map<String, SegmentReader> openedReadOnlyClones = new HashMap<>();\n+    // this function is used to control which SR are opened in order to keep track of them\n+    // and to reuse them in the case we wait for merges in this getReader call.\n+    IOUtils.IOFunction<SegmentCommitInfo, SegmentReader> readerFactory = sci -> {\n+      final ReadersAndUpdates rld = getPooledInstance(sci, true);\n+      try {\n+        assert Thread.holdsLock(IndexWriter.this);\n+        SegmentReader segmentReader = rld.getReadOnlyClone(IOContext.READ);\n+        openedReadOnlyClones.put(sci.info.name, segmentReader);\n+        return segmentReader;\n+      } finally {\n+        release(rld);\n+      }\n+    };\n+    SegmentInfos openingSegmentInfos = null;\n+    final long maxFullFlushMergeWaitMillis = config.getMaxFullFlushMergeWaitMillis();\n     boolean success2 = false;\n     try {\n+      /* this is the essential part of the getReader method. We need to take care of the following things:\n+       *  - flush all currently in-memory DWPTs to disk\n+       *  - apply all deletes & updates to new and to the existing DWPTs\n+       *  - prevent flushes and applying deletes of concurrently indexing DWPTs to be applied\n+       *  - open a SDR on the updated SIS\n+       *\n+       * in order do prevent concurrent flushes we call DocumentsWriter#flushAllThreads that swaps out the deleteQueue", "originalCommit": "a0bbf1a15236d587e5e84c5eb112752594659c77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a09c3542936..4b2380ac5b6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -557,7 +557,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n      * directory reader!\n      */\n     MergePolicy.MergeSpecification onGetReaderMerges = null;\n-    AtomicBoolean hasTimedOut = new AtomicBoolean(false);\n+    AtomicBoolean stopCollectingMergedReaders = new AtomicBoolean(false);\n     Map<String, SegmentReader> mergedReaders = new HashMap<>();\n     Map<String, SegmentReader> openedReadOnlyClones = new HashMap<>();\n     // this function is used to control which SR are opened in order to keep track of them\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcyOTcxMw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471729713", "bodyText": "Thank you for these awesome details!!", "author": "mikemccand", "createdAt": "2020-08-17T19:32:17Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -545,18 +546,54 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n     // obtained during this flush are pooled, the first time\n     // this method is called:\n     readerPool.enableReaderPooling();\n-    DirectoryReader r = null;\n+    StandardDirectoryReader r = null;\n     doBeforeFlush();\n-    boolean anyChanges = false;\n+    boolean anyChanges;\n     /*\n      * for releasing a NRT reader we must ensure that \n      * DW doesn't add any segments or deletes until we are\n      * done with creating the NRT DirectoryReader. \n      * We release the two stage full flush after we are done opening the\n      * directory reader!\n      */\n+    MergePolicy.MergeSpecification onGetReaderMerges = null;\n+    AtomicBoolean hasTimedOut = new AtomicBoolean(false);\n+    Map<String, SegmentReader> mergedReaders = new HashMap<>();\n+    Map<String, SegmentReader> openedReadOnlyClones = new HashMap<>();\n+    // this function is used to control which SR are opened in order to keep track of them\n+    // and to reuse them in the case we wait for merges in this getReader call.\n+    IOUtils.IOFunction<SegmentCommitInfo, SegmentReader> readerFactory = sci -> {\n+      final ReadersAndUpdates rld = getPooledInstance(sci, true);\n+      try {\n+        assert Thread.holdsLock(IndexWriter.this);\n+        SegmentReader segmentReader = rld.getReadOnlyClone(IOContext.READ);\n+        openedReadOnlyClones.put(sci.info.name, segmentReader);\n+        return segmentReader;\n+      } finally {\n+        release(rld);\n+      }\n+    };\n+    SegmentInfos openingSegmentInfos = null;\n+    final long maxFullFlushMergeWaitMillis = config.getMaxFullFlushMergeWaitMillis();\n     boolean success2 = false;\n     try {\n+      /* this is the essential part of the getReader method. We need to take care of the following things:", "originalCommit": "a0bbf1a15236d587e5e84c5eb112752594659c77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk1ODg0Nw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471958847", "bodyText": "yeah I think it makes sense to have these details in these complex methods", "author": "s1monw", "createdAt": "2020-08-18T07:04:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcyOTcxMw=="}], "type": "inlineReview", "revised_code": {"commit": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a09c3542936..4b2380ac5b6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -557,7 +557,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n      * directory reader!\n      */\n     MergePolicy.MergeSpecification onGetReaderMerges = null;\n-    AtomicBoolean hasTimedOut = new AtomicBoolean(false);\n+    AtomicBoolean stopCollectingMergedReaders = new AtomicBoolean(false);\n     Map<String, SegmentReader> mergedReaders = new HashMap<>();\n     Map<String, SegmentReader> openedReadOnlyClones = new HashMap<>();\n     // this function is used to control which SR are opened in order to keep track of them\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTc4NzY2NQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471787665", "bodyText": "Maybe move this assert to top of method?", "author": "mikemccand", "createdAt": "2020-08-17T21:34:19Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -630,6 +694,64 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n     return r;\n   }\n \n+  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean hasTimedOut, Map<String, SegmentReader> mergedReaders,\n+                                                       Map<String, SegmentReader> openedReadOnlyClones, SegmentInfos openingSegmentInfos,\n+                                                       boolean applyAllDeletes, boolean writeAllDeletes,\n+                                                       MergePolicy.MergeSpecification onCommitMerges, long maxCommitMergeWaitMillis) throws IOException {\n+    boolean replaceReaderSuccess = false;\n+    try {\n+      mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+      onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+      assert openingSegmentInfos != null;", "originalCommit": "a0bbf1a15236d587e5e84c5eb112752594659c77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a09c3542936..4b2380ac5b6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -694,17 +694,17 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n     return r;\n   }\n \n-  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean hasTimedOut, Map<String, SegmentReader> mergedReaders,\n+  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean stopCollectingMergedReaders, Map<String, SegmentReader> mergedReaders,\n                                                        Map<String, SegmentReader> openedReadOnlyClones, SegmentInfos openingSegmentInfos,\n                                                        boolean applyAllDeletes, boolean writeAllDeletes,\n-                                                       MergePolicy.MergeSpecification onCommitMerges, long maxCommitMergeWaitMillis) throws IOException {\n+                                                       MergePolicy.MergeSpecification pointInTimeMerges, long maxCommitMergeWaitMillis) throws IOException {\n+    assert openingSegmentInfos != null;\n     boolean replaceReaderSuccess = false;\n     try {\n       mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n-      onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n-      assert openingSegmentInfos != null;\n+      pointInTimeMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n       synchronized (this) {\n-        hasTimedOut.set(true);\n+        stopCollectingMergedReaders.set(true);\n         StandardDirectoryReader reader = maybeReopenMergedNRTReader(mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n             applyAllDeletes, writeAllDeletes);\n         replaceReaderSuccess = true;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTc4ODEyMw==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471788123", "bodyText": "Hmm, what if the merges finished before the timeout?  The await would return early, and return true if it did not timeout (I think?).  Maybe we do not need/care to distinguish that?  In which case maybe renamed hasTimedOut to something else (mergesFinished?).", "author": "mikemccand", "createdAt": "2020-08-17T21:35:22Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -630,6 +694,64 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n     return r;\n   }\n \n+  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean hasTimedOut, Map<String, SegmentReader> mergedReaders,\n+                                                       Map<String, SegmentReader> openedReadOnlyClones, SegmentInfos openingSegmentInfos,\n+                                                       boolean applyAllDeletes, boolean writeAllDeletes,\n+                                                       MergePolicy.MergeSpecification onCommitMerges, long maxCommitMergeWaitMillis) throws IOException {\n+    boolean replaceReaderSuccess = false;\n+    try {\n+      mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n+      onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n+      assert openingSegmentInfos != null;\n+      synchronized (this) {\n+        hasTimedOut.set(true);", "originalCommit": "a0bbf1a15236d587e5e84c5eb112752594659c77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk2MDI3Ng==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r471960276", "bodyText": "I renamed it to stopCollectingMergedReaders", "author": "s1monw", "createdAt": "2020-08-18T07:07:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTc4ODEyMw=="}], "type": "inlineReview", "revised_code": {"commit": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a09c3542936..4b2380ac5b6 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -694,17 +694,17 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n     return r;\n   }\n \n-  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean hasTimedOut, Map<String, SegmentReader> mergedReaders,\n+  private StandardDirectoryReader finishGetReaderMerge(AtomicBoolean stopCollectingMergedReaders, Map<String, SegmentReader> mergedReaders,\n                                                        Map<String, SegmentReader> openedReadOnlyClones, SegmentInfos openingSegmentInfos,\n                                                        boolean applyAllDeletes, boolean writeAllDeletes,\n-                                                       MergePolicy.MergeSpecification onCommitMerges, long maxCommitMergeWaitMillis) throws IOException {\n+                                                       MergePolicy.MergeSpecification pointInTimeMerges, long maxCommitMergeWaitMillis) throws IOException {\n+    assert openingSegmentInfos != null;\n     boolean replaceReaderSuccess = false;\n     try {\n       mergeScheduler.merge(mergeSource, MergeTrigger.GET_READER);\n-      onCommitMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n-      assert openingSegmentInfos != null;\n+      pointInTimeMerges.await(maxCommitMergeWaitMillis, TimeUnit.MILLISECONDS);\n       synchronized (this) {\n-        hasTimedOut.set(true);\n+        stopCollectingMergedReaders.set(true);\n         StandardDirectoryReader reader = maybeReopenMergedNRTReader(mergedReaders, openedReadOnlyClones, openingSegmentInfos,\n             applyAllDeletes, writeAllDeletes);\n         replaceReaderSuccess = true;\n"}}, {"oid": "2742d616216dac2817de257d353064a95b727069", "url": "https://github.com/apache/lucene-solr/commit/2742d616216dac2817de257d353064a95b727069", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-18T06:58:45Z", "type": "commit"}, {"oid": "2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "url": "https://github.com/apache/lucene-solr/commit/2f610ebe8c276a9d9740d17de4e8076ab0f276fe", "message": "Apply feedback", "committedDate": "2020-08-18T07:07:44Z", "type": "commit"}, {"oid": "55106f69e0a05bfe190743c69b35baa02e1cb7fc", "url": "https://github.com/apache/lucene-solr/commit/55106f69e0a05bfe190743c69b35baa02e1cb7fc", "message": "move assert", "committedDate": "2020-08-18T07:11:05Z", "type": "commit"}, {"oid": "0ade49d5fb05cb811404f025053b8c5bc1d5a55f", "url": "https://github.com/apache/lucene-solr/commit/0ade49d5fb05cb811404f025053b8c5bc1d5a55f", "message": "beef up test to cover more reopen/commits", "committedDate": "2020-08-18T07:46:44Z", "type": "commit"}, {"oid": "32d2cfa0a2b0571d17965bb4ae3a094b5bbb2754", "url": "https://github.com/apache/lucene-solr/commit/32d2cfa0a2b0571d17965bb4ae3a094b5bbb2754", "message": "fix javadocs", "committedDate": "2020-08-18T07:57:10Z", "type": "commit"}, {"oid": "d235b46222d39b8f62418d86e192c68f5675d7ce", "url": "https://github.com/apache/lucene-solr/commit/d235b46222d39b8f62418d86e192c68f5675d7ce", "message": "fix test to finish on failure:", "committedDate": "2020-08-18T08:09:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjE1NDY4Mg==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472154682", "bodyText": "I love seeing diffs like this one, adding a String message to an otherwise cryptic assert!  It makes me realize you must have had a hellacious debugging session!", "author": "mikemccand", "createdAt": "2020-08-18T12:46:33Z", "path": "lucene/core/src/java/org/apache/lucene/index/ReaderPool.java", "diffHunk": "@@ -404,7 +404,7 @@ private PendingDeletes newPendingDeletes(SegmentReader reader, SegmentCommitInfo\n   private boolean noDups() {\n     Set<String> seen = new HashSet<>();\n     for(SegmentCommitInfo info : readerMap.keySet()) {\n-      assert !seen.contains(info.info.name);\n+      assert !seen.contains(info.info.name) : \"seen twice: \" + info.info.name ;", "originalCommit": "0ade49d5fb05cb811404f025053b8c5bc1d5a55f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxNDQ1OA==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472314458", "bodyText": "many fun issues in this PR to be honest. IW is tricky as hell in some places like we are incRefing files in StandardDirectoryReader but not in IW for NRT readers is mindblowing :D", "author": "s1monw", "createdAt": "2020-08-18T16:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjE1NDY4Mg=="}], "type": "inlineReview", "revised_code": null}, {"oid": "34d4f40242bdbae279f58449d3d9704c94710128", "url": "https://github.com/apache/lucene-solr/commit/34d4f40242bdbae279f58449d3d9704c94710128", "message": "make sure we incRef the merged reader for the time being", "committedDate": "2020-08-18T16:08:29Z", "type": "commit"}, {"oid": "83d666eb9702949f11b5195a4a7ce81145750495", "url": "https://github.com/apache/lucene-solr/commit/83d666eb9702949f11b5195a4a7ce81145750495", "message": "add test to simulate that a segment that just merged already got merged away before we can reopen the reader on it", "committedDate": "2020-08-18T16:23:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI4NjE0MQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472286141", "bodyText": "Should we keep track the clones iff maxFullFlushMergeWaitMillis is positive? I know this is not expensive.", "author": "dnhatn", "createdAt": "2020-08-18T15:30:03Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -545,18 +546,54 @@ DirectoryReader getReader(boolean applyAllDeletes, boolean writeAllDeletes) thro\n     // obtained during this flush are pooled, the first time\n     // this method is called:\n     readerPool.enableReaderPooling();\n-    DirectoryReader r = null;\n+    StandardDirectoryReader r = null;\n     doBeforeFlush();\n-    boolean anyChanges = false;\n+    boolean anyChanges;\n     /*\n      * for releasing a NRT reader we must ensure that \n      * DW doesn't add any segments or deletes until we are\n      * done with creating the NRT DirectoryReader. \n      * We release the two stage full flush after we are done opening the\n      * directory reader!\n      */\n+    MergePolicy.MergeSpecification onGetReaderMerges = null;\n+    AtomicBoolean stopCollectingMergedReaders = new AtomicBoolean(false);\n+    Map<String, SegmentReader> mergedReaders = new HashMap<>();\n+    Map<String, SegmentReader> openedReadOnlyClones = new HashMap<>();\n+    // this function is used to control which SR are opened in order to keep track of them\n+    // and to reuse them in the case we wait for merges in this getReader call.\n+    IOUtils.IOFunction<SegmentCommitInfo, SegmentReader> readerFactory = sci -> {\n+      final ReadersAndUpdates rld = getPooledInstance(sci, true);\n+      try {\n+        assert Thread.holdsLock(IndexWriter.this);\n+        SegmentReader segmentReader = rld.getReadOnlyClone(IOContext.READ);\n+        openedReadOnlyClones.put(sci.info.name, segmentReader);", "originalCommit": "0ade49d5fb05cb811404f025053b8c5bc1d5a55f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNzgzOQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472337839", "bodyText": "++", "author": "s1monw", "createdAt": "2020-08-18T16:48:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjI4NjE0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6d2ee80b9d472f698cc55f438251db7787dd5771", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex 9cc625acf56..c8df3e45112 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -549,6 +549,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n     StandardDirectoryReader r = null;\n     doBeforeFlush();\n     boolean anyChanges;\n+    final long maxFullFlushMergeWaitMillis = config.getMaxFullFlushMergeWaitMillis();\n     /*\n      * for releasing a NRT reader we must ensure that \n      * DW doesn't add any segments or deletes until we are\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzMjY3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472332671", "bodyText": "Should we rename this to stopCollectingMergedReaders? I find that name better.", "author": "dnhatn", "createdAt": "2020-08-18T16:39:42Z", "path": "lucene/core/src/java/org/apache/lucene/index/IndexWriter.java", "diffHunk": "@@ -3179,9 +3317,9 @@ private long prepareCommitInternal() throws IOException {\n       SegmentInfos toCommit = null;\n       boolean anyChanges = false;\n       long seqNo;\n-      MergePolicy.MergeSpecification onCommitMerges = null;\n-      AtomicBoolean includeInCommit = new AtomicBoolean(true);\n-      final long maxCommitMergeWaitMillis = config.getMaxCommitMergeWaitMillis();\n+      MergePolicy.MergeSpecification pointInTimeMerges = null;\n+      AtomicBoolean hasTimedOut = new AtomicBoolean(false);", "originalCommit": "83d666eb9702949f11b5195a4a7ce81145750495", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNjQ1Ng==", "url": "https://github.com/apache/lucene-solr/pull/1623#discussion_r472336456", "bodyText": "++ I change it to a better name", "author": "s1monw", "createdAt": "2020-08-18T16:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzMjY3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "30c11de82e5be0a907d44d9de47977d5f93026d0", "chunk": "diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\nindex a56f4a61e82..7f752fbe696 100644\n--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java\n\n@@ -3318,7 +3318,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable,\n       boolean anyChanges = false;\n       long seqNo;\n       MergePolicy.MergeSpecification pointInTimeMerges = null;\n-      AtomicBoolean hasTimedOut = new AtomicBoolean(false);\n+      AtomicBoolean stopAddingMergedSegments = new AtomicBoolean(false);\n       final long maxCommitMergeWaitMillis = config.getMaxFullFlushMergeWaitMillis();\n       // This is copied from doFlush, except it's modified to\n       // clone & incRef the flushed SegmentInfos inside the\n"}}, {"oid": "30c11de82e5be0a907d44d9de47977d5f93026d0", "url": "https://github.com/apache/lucene-solr/commit/30c11de82e5be0a907d44d9de47977d5f93026d0", "message": "rename var", "committedDate": "2020-08-18T16:46:09Z", "type": "commit"}, {"oid": "6d2ee80b9d472f698cc55f438251db7787dd5771", "url": "https://github.com/apache/lucene-solr/commit/6d2ee80b9d472f698cc55f438251db7787dd5771", "message": "apply feedback", "committedDate": "2020-08-18T16:47:58Z", "type": "commit"}, {"oid": "14c6f54f680cc7dd4b2ec675a459c5b23b46cec8", "url": "https://github.com/apache/lucene-solr/commit/14c6f54f680cc7dd4b2ec675a459c5b23b46cec8", "message": "make vars final", "committedDate": "2020-08-18T18:42:42Z", "type": "commit"}, {"oid": "efb5f4f32adc5ba9b198d8593c284cf49f7a05f7", "url": "https://github.com/apache/lucene-solr/commit/efb5f4f32adc5ba9b198d8593c284cf49f7a05f7", "message": "fix resource release handling on excepiton that happens between merge register and merge execution", "committedDate": "2020-08-18T22:00:53Z", "type": "commit"}, {"oid": "9e4f63b33adb2c80394a13e295ab5c26554b15c2", "url": "https://github.com/apache/lucene-solr/commit/9e4f63b33adb2c80394a13e295ab5c26554b15c2", "message": "make sure we finish merge if we abort it", "committedDate": "2020-08-18T22:21:28Z", "type": "commit"}, {"oid": "acb93be4bf6904083481f463097abcbe385f5a3c", "url": "https://github.com/apache/lucene-solr/commit/acb93be4bf6904083481f463097abcbe385f5a3c", "message": "fix visibility", "committedDate": "2020-08-19T07:12:32Z", "type": "commit"}, {"oid": "dfdc5c7a2dbb3ba7151c79d26c4f2f84ea22dc33", "url": "https://github.com/apache/lucene-solr/commit/dfdc5c7a2dbb3ba7151c79d26c4f2f84ea22dc33", "message": "fix warnings", "committedDate": "2020-08-19T09:51:16Z", "type": "commit"}, {"oid": "6fab977c6643a50a42c2642dad9ce69ecf3026f1", "url": "https://github.com/apache/lucene-solr/commit/6fab977c6643a50a42c2642dad9ce69ecf3026f1", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-20T07:08:17Z", "type": "commit"}, {"oid": "1a88aa2653f14255bbc01df8120e9ede447a0f4f", "url": "https://github.com/apache/lucene-solr/commit/1a88aa2653f14255bbc01df8120e9ede447a0f4f", "message": "don\n't merge unexpectedly", "committedDate": "2020-08-20T07:11:21Z", "type": "commit"}, {"oid": "84c1aeee07c269fd47de12662b3dee8b4551fd87", "url": "https://github.com/apache/lucene-solr/commit/84c1aeee07c269fd47de12662b3dee8b4551fd87", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-24T07:20:18Z", "type": "commit"}, {"oid": "6976f896711560e714d679b438d8238b20d0cec1", "url": "https://github.com/apache/lucene-solr/commit/6976f896711560e714d679b438d8238b20d0cec1", "message": "Merge branch 'master' into jira/lucene-8962", "committedDate": "2020-08-24T15:35:58Z", "type": "commit"}, {"oid": "77c9c6c269f019dbce3be1a9d719662f52507c9d", "url": "https://github.com/apache/lucene-solr/commit/77c9c6c269f019dbce3be1a9d719662f52507c9d", "message": "add changes entry", "committedDate": "2020-08-24T15:37:49Z", "type": "commit"}]}