{"pr_number": 684, "pr_title": "Spawn threads to stop tasks during the onAssignmentChange() code path  in AbstractKafkaConnector", "pr_createdAt": "2020-02-11T01:32:53Z", "pr_url": "https://github.com/linkedin/brooklin/pull/684", "timeline": [{"oid": "6ae7119042059bb6b146d36ae0dbce4693fa3a9e", "url": "https://github.com/linkedin/brooklin/commit/6ae7119042059bb6b146d36ae0dbce4693fa3a9e", "message": "Spawn threads to stop tasks during the onAssignmentChange() code path in AbstractKafkaConnector", "committedDate": "2020-02-11T01:30:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzc4MTg5OQ==", "url": "https://github.com/linkedin/brooklin/pull/684#discussion_r377781899", "bodyText": "This will throw ConcurrentModificationException while iterating the loop.", "author": "vmaheshw", "createdAt": "2020-02-11T17:22:20Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -142,6 +151,7 @@ public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n           // Make sure to replace the DatastreamTask with most up to date info\n           // This is necessary because DatastreamTaskImpl.hashCode() does not take into account all the\n           // fields/properties of the DatastreamTask (e.g. dependencies).\n+          _runningTasks.remove(task);", "originalCommit": "6ae7119042059bb6b146d36ae0dbce4693fa3a9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgyMTU0NQ==", "url": "https://github.com/linkedin/brooklin/pull/684#discussion_r377821545", "bodyText": "This is not a problem. We are not iterating through the map that we are removing things from. We are iterating over the tasks list, which we don't modify at all.\n  **for (DatastreamTask task : tasks) {**\n    ConnectorTaskEntry connectorTaskEntry = _runningTasks.get(task);\n    if (connectorTaskEntry != null) {\n      AbstractKafkaBasedConnectorTask kafkaBasedConnectorTask = connectorTaskEntry.getConnectorTask();\n      kafkaBasedConnectorTask.checkForUpdateTask(task);\n      // Make sure to replace the DatastreamTask with most up to date info\n      // This is necessary because DatastreamTaskImpl.hashCode() does not take into account all the\n      // fields/properties of the DatastreamTask (e.g. dependencies).\n      **_runningTasks.remove(task);**\n      _runningTasks.put(task, connectorTaskEntry);\n      continue; // already running\n    }\n\n    _runningTasks.put(task, createKafkaConnectorTask(task));\n  }", "author": "somandal", "createdAt": "2020-02-11T18:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzc4MTg5OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgzMDM1NA==", "url": "https://github.com/linkedin/brooklin/pull/684#discussion_r377830354", "bodyText": "typo: This will force cleanup", "author": "DEEPTHIKORAT", "createdAt": "2020-02-11T18:52:32Z", "path": "datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java", "diffHunk": "@@ -128,10 +133,14 @@ public synchronized void onAssignmentChange(List<DatastreamTask> tasks) {\n \n       for (DatastreamTask task : toCancel) {\n         ConnectorTaskEntry connectorTaskEntry = _runningTasks.remove(task);\n-        // Stopping the connectorTask. This only marks the connector task as shutdown and does not actually wait for\n-        // the connector task to stop. onAssignmentChange() must be completed quickly, otherwise the Coordinator\n-        // kills the assignment threads.\n-        connectorTaskEntry.getConnectorTask().stop();\n+        // Spawn a separate thread to attempt stopping the connectorTask. The connectorTask will be canceled if it\n+        // does not stop within a certain amount of time. This is force cleanup of connectorTasks which take too long", "originalCommit": "6ae7119042059bb6b146d36ae0dbce4693fa3a9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgzNTY3MA==", "url": "https://github.com/linkedin/brooklin/pull/684#discussion_r377835670", "bodyText": "done", "author": "somandal", "createdAt": "2020-02-11T19:02:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgzMDM1NA=="}], "type": "inlineReview", "revised_code": {"commit": "fe2876dcd0c7ab55d292f091189e384b7ea76c37", "chunk": "diff --git a/datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java b/datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java\nindex e093a532..ee1f7c5a 100644\n--- a/datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java\n+++ b/datastream-kafka-connector/src/main/java/com/linkedin/datastream/connectors/kafka/AbstractKafkaConnector.java\n\n@@ -134,7 +134,7 @@ public abstract class AbstractKafkaConnector implements Connector, DiagnosticsAw\n       for (DatastreamTask task : toCancel) {\n         ConnectorTaskEntry connectorTaskEntry = _runningTasks.remove(task);\n         // Spawn a separate thread to attempt stopping the connectorTask. The connectorTask will be canceled if it\n-        // does not stop within a certain amount of time. This is force cleanup of connectorTasks which take too long\n+        // does not stop within a certain amount of time. This will force cleanup of connectorTasks which take too long\n         // to stop, or are stuck indefinitely. A separate thread is spawned to handle this because the Coordinator\n         // requires that onAssignmentChange() must complete quickly, and will kill the assignment threads if they take\n         // too long.\n"}}, {"oid": "fe2876dcd0c7ab55d292f091189e384b7ea76c37", "url": "https://github.com/linkedin/brooklin/commit/fe2876dcd0c7ab55d292f091189e384b7ea76c37", "message": "Fix typo", "committedDate": "2020-02-11T19:01:18Z", "type": "commit"}]}