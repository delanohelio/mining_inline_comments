{"pr_number": 1454, "pr_title": "move batching to trace processor to ease memory buffer reuse", "pr_createdAt": "2020-05-13T10:23:13Z", "pr_url": "https://github.com/DataDog/dd-trace-java/pull/1454", "timeline": [{"oid": "5fb0c4e837d8b2e3d48fe9095370ee32a6e79f56", "url": "https://github.com/DataDog/dd-trace-java/commit/5fb0c4e837d8b2e3d48fe9095370ee32a6e79f56", "message": "move batching to trace processor to ease memory buffer reuse\n\n Date:      Wed May 13 11:00:00 2020 +0100", "committedDate": "2020-05-13T10:47:32Z", "type": "forcePushed"}, {"oid": "21cf41bfa85f5e807c696972dd41e702ff0a865b", "url": "https://github.com/DataDog/dd-trace-java/commit/21cf41bfa85f5e807c696972dd41e702ff0a865b", "message": "accept api breaks", "committedDate": "2020-05-13T13:26:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDQ0MzM2Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r424443366", "bodyText": "Yes, I'm in agreement with removing this.  Even prior to this change, I was little concerned that it was creating some unnecessary complexity.", "author": "dougqh", "createdAt": "2020-05-13T13:37:08Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/AbstractDisruptor.java", "diffHunk": "@@ -1,96 +0,0 @@\n-package datadog.trace.common.writer.ddagent;\n-\n-import com.lmax.disruptor.EventHandler;\n-import com.lmax.disruptor.SleepingWaitStrategy;\n-import com.lmax.disruptor.dsl.Disruptor;\n-import com.lmax.disruptor.dsl.ProducerType;\n-import datadog.common.exec.DaemonThreadFactory;\n-import java.io.Closeable;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n-import lombok.extern.slf4j.Slf4j;\n-\n-@Slf4j\n-abstract class AbstractDisruptor<T> implements Closeable {", "originalCommit": "21cf41bfa85f5e807c696972dd41e702ff0a865b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "1051e41a075afdce72325392773d697fd95a44de", "url": "https://github.com/DataDog/dd-trace-java/commit/1051e41a075afdce72325392773d697fd95a44de", "message": "run revapi", "committedDate": "2020-05-13T20:38:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyMDgzMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425120833", "bodyText": "This spams the logs quite a bit \ud83d\ude09", "author": "bantonsson", "createdAt": "2020-05-14T13:06:23Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n+              .put(new MsgPackRequestBody(traces))\n               .build();\n-\n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n         if (response.code() != 200) {\n           if (log.isDebugEnabled()) {\n             log.debug(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {}, Response: {}, Body: {}\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 response.body().string());\n           } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n             nextAllowedLogTime = System.currentTimeMillis() + MILLISECONDS_BETWEEN_ERROR_LOG;\n             log.warn(\n                 \"Error while sending {} of {} traces to the DD agent. Status: {} {} (going silent for {} minutes)\",\n-                traces.size(),\n-                representativeCount,\n+                traces.traceCount(),\n+                traces.representativeCount(),\n                 response.code(),\n                 response.message(),\n                 TimeUnit.MILLISECONDS.toMinutes(MILLISECONDS_BETWEEN_ERROR_LOG));\n           }\n           return Response.failed(response.code());\n         }\n-\n-        log.debug(\n-            \"Successfully sent {} of {} traces to the DD agent.\",\n-            traces.size(),\n-            representativeCount);\n-\n+        if (log.isDebugEnabled()) {\n+          log.debug(\n+              \"Successfully sent {} of {} traces to the DD agent.\",\n+              traces.traceCount(),\n+              traces.representativeCount());\n+        }\n         final String responseString = response.body().string().trim();\n         try {\n           if (!\"\".equals(responseString) && !\"OK\".equalsIgnoreCase(responseString)) {\n             final Map<String, Map<String, Number>> parsedResponse =\n                 RESPONSE_ADAPTER.fromJson(responseString);\n             final String endpoint = tracesUrl.toString();\n-\n             for (final DDAgentResponseListener listener : responseListeners) {\n               listener.onResponse(endpoint, parsedResponse);\n             }\n           }\n           return Response.success(response.code());\n         } catch (final IOException e) {\n           log.debug(\"Failed to parse DD agent response: \" + responseString, e);\n-\n           return Response.success(response.code(), e);\n         }\n       }\n     } catch (final IOException e) {\n       if (log.isDebugEnabled()) {\n         log.debug(\n             \"Error while sending \"\n-                + traces.size()\n+                + traces.traceCount()\n                 + \" of \"\n-                + representativeCount\n+                + traces.representativeCount()\n+                + \" (size=\"\n+                + (traces.sizeInBytes() / 1024)\n+                + \"KB)\"\n                 + \" traces to the DD agent.\",\n             e);\n-      } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n+      } else { // if (nextAllowedLogTime < System.currentTimeMillis()) {", "originalCommit": "1051e41a075afdce72325392773d697fd95a44de", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyOTc4Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425129783", "bodyText": "Good catch, that was for debugging purposes.", "author": "richardstartin", "createdAt": "2020-05-14T13:19:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEyMDgzMw=="}], "type": "inlineReview", "revised_code": {"commit": "3ab72b1480169a72df1395802086b2a2b9af2fa6", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\nindex b349bed2ee..32fdbc6483 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n\n@@ -140,7 +140,7 @@ public class DDAgentApi {\n                 + \"KB)\"\n                 + \" traces to the DD agent.\",\n             e);\n-      } else { // if (nextAllowedLogTime < System.currentTimeMillis()) {\n+      } else if (nextAllowedLogTime < System.currentTimeMillis()) {\n         nextAllowedLogTime = System.currentTimeMillis() + MILLISECONDS_BETWEEN_ERROR_LOG;\n         log.warn(\n             \"Error while sending {} of {} (size={}KB, bufferId={}) traces to the DD agent. {}: {} (going silent for {} minutes)\",\n"}}, {"oid": "3ab72b1480169a72df1395802086b2a2b9af2fa6", "url": "https://github.com/DataDog/dd-trace-java/commit/3ab72b1480169a72df1395802086b2a2b9af2fa6", "message": "move batching to trace processor to ease memory buffer reuse\n\n Date:      Wed May 13 11:00:00 2020 +0100", "committedDate": "2020-05-14T21:18:43Z", "type": "forcePushed"}, {"oid": "1c3a5935879f7a8c2ec047504b6136e3842dae6e", "url": "https://github.com/DataDog/dd-trace-java/commit/1c3a5935879f7a8c2ec047504b6136e3842dae6e", "message": "move batching to trace processor to ease memory buffer reuse\n\n Date:      Wed May 13 11:00:00 2020 +0100", "committedDate": "2020-05-14T21:23:35Z", "type": "forcePushed"}, {"oid": "dc357372e2c43d2580e297c2ddab0294420e79d8", "url": "https://github.com/DataDog/dd-trace-java/commit/dc357372e2c43d2580e297c2ddab0294420e79d8", "message": "move batching to trace processor to ease memory buffer reuse\n\n Date:      Wed May 13 11:00:00 2020 +0100", "committedDate": "2020-05-14T21:27:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425860539", "bodyText": "From looking at the code it seems that we are running this on every HeartBeat which is every 100 ms. I'm not sure what this does or accomplishes. I would need to get a walk-through of the code.", "author": "bantonsson", "createdAt": "2020-05-15T14:59:05Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n+            beginTransaction();", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3NjM1OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425876358", "bodyText": "I'm trying to keep semantic equivalence with the old code, which had a heartbeat to ensure timely flushing of traces in applications which don't generate traces very quickly.", "author": "richardstartin", "createdAt": "2020-05-15T15:23:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4Mzg1NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425883855", "bodyText": "So I'm probably confused by the code, but I can't see that the heartbeat did anything in the old code, since both data and flushLatch are null it just skips right through.", "author": "bantonsson", "createdAt": "2020-05-15T15:35:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MDUzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex 71ecbe13ab..c88a0fee6f 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,29 +145,27 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        try {\n-          if (event.force\n-              || (representativeCount > 0 && serializer.shouldFlush())\n-              || event.flushLatch != null) {\n-            commitTransaction(event.flushLatch);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n             beginTransaction();\n-          } else if (doTimeFlush && representativeCount > 0) {\n-            long now = millisecondTime();\n-            if (now >= nextFlushMillis) {\n-              commitTransaction();\n-              beginTransaction();\n-              scheduleNextTimeFlush(now);\n-            }\n+            scheduleNextTimeFlush(now);\n           }\n-          if (event.data != null) {\n-            serialize(event.data, event.representativeCount);\n-          }\n-        } catch (final Throwable e) {\n-          if (log.isDebugEnabled()) {\n-            log.debug(\"Error while serializing trace\", e);\n-          }\n-          monitor.onFailedSerialize(writer, event.data, e);\n         }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n+        }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425848417", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n          \n          \n            \n                          .addHeader(X_DATADOG_TRACE_COUNT, Integer.toString(traces.representativeCount()))", "author": "jbachorik", "createdAt": "2020-05-15T14:41:01Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -75,83 +73,81 @@ public void addResponseListener(final DDAgentResponseListener listener) {\n     }\n   }\n \n-  Response sendSerializedTraces(\n-      final int representativeCount,\n-      final int traceCount,\n-      final int sizeInBytes,\n-      final List<TraceBuffer> traces) {\n+  Response sendSerializedTraces(final TraceBuffer traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n+              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNTAwMg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425905002", "bodyText": "in fact I made the change to reduce the number of characters so it all fits on one line", "author": "richardstartin", "createdAt": "2020-05-15T16:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMzYzNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425913636", "bodyText": ":)\nYeah, but that will instantiate StringBuilder to do the concatenation :/\nMaybe this time readability will have to be sacrificed.", "author": "jbachorik", "createdAt": "2020-05-15T16:27:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxODg1Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425918853", "bodyText": "Depends on the JDK version.", "author": "richardstartin", "createdAt": "2020-05-15T16:35:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyMTQwMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425921403", "bodyText": "True. But since we are targeting JDK 7 as the lowest common denominator we need to consider that.", "author": "jbachorik", "createdAt": "2020-05-15T16:40:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg0ODQxNw=="}], "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\nindex 32fdbc6483..4608054277 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n\n@@ -81,7 +81,7 @@ public class DDAgentApi {\n     try {\n       final Request request =\n           prepareRequest(tracesUrl)\n-              .addHeader(X_DATADOG_TRACE_COUNT, traces.representativeCount() + \"\")\n+              .addHeader(X_DATADOG_TRACE_COUNT, Integer.toString(traces.representativeCount()))\n               .put(new MsgPackRequestBody(traces))\n               .build();\n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg1NzgyOA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425857828", "bodyText": "These could perhaps be package private?", "author": "jbachorik", "createdAt": "2020-05-15T14:55:08Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Disruptor that takes serialized traces and dispatches them to the DD agent\n+ *\n+ * <p>publishing to the buffer will block if the buffer is full.\n+ */\n+@Slf4j\n+public class DispatchingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<TraceBuffer> disruptor;\n+\n+  public DispatchingDisruptor(\n+      int disruptorSize,\n+      EventFactory<TraceBuffer> eventFactory,\n+      DDAgentApi api,\n+      Monitor monitor,\n+      DDAgentWriter writer) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            eventFactory,\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_WRITER,\n+            ProducerType.SINGLE,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(new TraceDispatchingHandler(api, monitor, writer));\n+  }\n+\n+  public void start() {\n+    disruptor.start();\n+  }\n+\n+  @Override\n+  public void close() {\n+    disruptor.halt();\n+  }\n+\n+  public long beginTransaction() {\n+    return disruptor.getRingBuffer().next();\n+  }\n+\n+  public TraceBuffer getTraceBuffer(long sequence) {\n+    return disruptor.getRingBuffer().get(sequence);\n+  }\n+\n+  public void commit(long sequence) {\n+    disruptor.getRingBuffer().publish(sequence);\n+  }", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\nindex b744da43c2..f87c13d62a 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\n\n@@ -86,6 +86,7 @@ public class DispatchingDisruptor implements AutoCloseable {\n       try {\n         if (traces.traceCount() > 0) {\n           final DDAgentApi.Response response = api.sendSerializedTraces(traces);\n+          monitor.onSend(writer, traces.traceCount(), traces.sizeInBytes());\n           if (response.success()) {\n             if (log.isDebugEnabled()) {\n               log.debug(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2MTcyMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425861723", "bodyText": "Wouldn't it be useful to have also the stacktrace?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.debug(\"Failed to send traces to the API: {}\", e.getMessage());\n          \n          \n            \n                    log.debug(\"Failed to send traces to the API: {}\", e.getMessage(), e);", "author": "jbachorik", "createdAt": "2020-05-15T15:00:46Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Disruptor that takes serialized traces and dispatches them to the DD agent\n+ *\n+ * <p>publishing to the buffer will block if the buffer is full.\n+ */\n+@Slf4j\n+public class DispatchingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<TraceBuffer> disruptor;\n+\n+  public DispatchingDisruptor(\n+      int disruptorSize,\n+      EventFactory<TraceBuffer> eventFactory,\n+      DDAgentApi api,\n+      Monitor monitor,\n+      DDAgentWriter writer) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            eventFactory,\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_WRITER,\n+            ProducerType.SINGLE,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(new TraceDispatchingHandler(api, monitor, writer));\n+  }\n+\n+  public void start() {\n+    disruptor.start();\n+  }\n+\n+  @Override\n+  public void close() {\n+    disruptor.halt();\n+  }\n+\n+  public long beginTransaction() {\n+    return disruptor.getRingBuffer().next();\n+  }\n+\n+  public TraceBuffer getTraceBuffer(long sequence) {\n+    return disruptor.getRingBuffer().get(sequence);\n+  }\n+\n+  public void commit(long sequence) {\n+    disruptor.getRingBuffer().publish(sequence);\n+  }\n+\n+  // Intentionally not thread safe.\n+  private static class TraceDispatchingHandler implements EventHandler<TraceBuffer> {\n+\n+    private final DDAgentApi api;\n+    private final Monitor monitor;\n+    private final DDAgentWriter writer;\n+\n+    private TraceDispatchingHandler(\n+        final DDAgentApi api, final Monitor monitor, final DDAgentWriter writer) {\n+      this.api = api;\n+      this.monitor = monitor;\n+      this.writer = writer;\n+    }\n+\n+    @Override\n+    public void onEvent(final TraceBuffer event, final long sequence, final boolean endOfBatch) {\n+      sendData(event);\n+    }\n+\n+    private void sendData(TraceBuffer traces) {\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"receive id={}, rc={}, tc={}\",\n+            traces.id(),\n+            traces.representativeCount(),\n+            traces.traceCount());\n+      }\n+      try {\n+        if (traces.traceCount() > 0) {\n+          final DDAgentApi.Response response = api.sendSerializedTraces(traces);\n+          if (response.success()) {\n+            if (log.isDebugEnabled()) {\n+              log.debug(\n+                  \"Successfully sent {} traces {} to the API\", traces.traceCount(), traces.id());\n+            }\n+            monitor.onSend(writer, traces.representativeCount(), traces.sizeInBytes(), response);\n+          } else {\n+            if (log.isDebugEnabled()) {\n+              log.debug(\n+                  \"Failed to send {} traces (representing {}) of size {} bytes to the API\",\n+                  traces.traceCount(),\n+                  traces.representativeCount(),\n+                  traces.sizeInBytes());\n+            }\n+            monitor.onFailedSend(\n+                writer, traces.representativeCount(), traces.sizeInBytes(), response);\n+          }\n+        } else if (log.isDebugEnabled()) {\n+          log.debug(\"buffer {} was empty\", traces.id());\n+        }\n+      } catch (final Throwable e) {\n+        log.debug(\"Failed to send traces to the API: {}\", e.getMessage());", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\nindex b744da43c2..f87c13d62a 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DispatchingDisruptor.java\n\n@@ -86,6 +86,7 @@ public class DispatchingDisruptor implements AutoCloseable {\n       try {\n         if (traces.traceCount() > 0) {\n           final DDAgentApi.Response response = api.sendSerializedTraces(traces);\n+          monitor.onSend(writer, traces.traceCount(), traces.sizeInBytes());\n           if (response.success()) {\n             if (log.isDebugEnabled()) {\n               log.debug(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg2NTc0NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425865745", "bodyText": "Nit: Could be final?", "author": "jbachorik", "createdAt": "2020-05-15T15:07:08Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventFactory;\n+import com.lmax.disruptor.WaitStrategy;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import java.util.concurrent.ThreadFactory;\n+\n+public class DisruptorUtils {", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java\nindex 0f851abbbb..4a2a79e55a 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DisruptorUtils.java\n\n@@ -6,7 +6,7 @@ import com.lmax.disruptor.dsl.Disruptor;\n import com.lmax.disruptor.dsl.ProducerType;\n import java.util.concurrent.ThreadFactory;\n \n-public class DisruptorUtils {\n+public final class DisruptorUtils {\n \n   public static <T> Disruptor<T> create(\n       EventFactory<T> factory,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3MTY3NA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425871674", "bodyText": "Can you add a comment here explaining why both clear() and flush() must be called?", "author": "jbachorik", "createdAt": "2020-05-15T15:16:19Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\nindex 431b938c8b..0c025b88b2 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n\n@@ -87,7 +86,7 @@ public class MsgPackStatefulSerializer implements StatefulSerializer {\n   }\n \n   @Override\n-  public boolean shouldFlush() {\n+  public boolean isAtCapacity() {\n     // Return true if could not take another average trace without allocating.\n     // There are many cases where this will lead to some amount of over allocation,\n     // e.g. a very large trace after many very small traces, but it's a best effort\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425877849", "bodyText": "Can this be combined with a call to headerSize()?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  if (traceCount < (1 << 4)) {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(1);\n          \n          \n            \n                    buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  } else if (traceCount < (1 << 16)) {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(3);\n          \n          \n            \n                    buffer.put(0, ARRAY16);\n          \n          \n            \n                    buffer.putShort(1, (short) traceCount);\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  } else {\n          \n          \n            \n                    ByteBuffer buffer = ByteBuffer.allocate(5);\n          \n          \n            \n                    buffer.put(0, ARRAY32);\n          \n          \n            \n                    buffer.putInt(1, traceCount);\n          \n          \n            \n                    channel.write(buffer);\n          \n          \n            \n                  }\n          \n          \n            \n                  int headerSize = headerSize();\n          \n          \n            \n                  ByteBuffer buffer = ByteBuffer.allocate(headerSize);\n          \n          \n            \n                  switch (headerSize) {\n          \n          \n            \n                  if (traceCount < (1 << 4)) {\n          \n          \n            \n                    case 1:\n          \n          \n            \n                      buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n          \n          \n            \n                      break;\n          \n          \n            \n                    case 3:\n          \n          \n            \n                      buffer.put(0, ARRAY16);\n          \n          \n            \n                      buffer.putShort(1, (short) traceCount);\n          \n          \n            \n                      break;\n          \n          \n            \n                    case 5:\n          \n          \n            \n                      buffer.put(0, ARRAY32);\n          \n          \n            \n                      buffer.putInt(1, traceCount);\n          \n          \n            \n                      break;\n          \n          \n            \n                    default:\n          \n          \n            \n                      throw new IOException(\"Unsupported header size {}\", headerSize);\n          \n          \n            \n                  }\n          \n          \n            \n                  channel.write(buffer);", "author": "jbachorik", "createdAt": "2020-05-15T15:25:45Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkzNjgwNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425936806", "bodyText": "I'm not sure this is more succinct, whereas it's already inlining some logic from message pack so divergence here may not be the primary concern. I will think about it.", "author": "richardstartin", "createdAt": "2020-05-15T17:09:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjE3NDI5Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426174293", "bodyText": "ok", "author": "jbachorik", "createdAt": "2020-05-16T17:42:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3Nzg0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\nindex 431b938c8b..0c025b88b2 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n\n@@ -87,7 +86,7 @@ public class MsgPackStatefulSerializer implements StatefulSerializer {\n   }\n \n   @Override\n-  public boolean shouldFlush() {\n+  public boolean isAtCapacity() {\n     // Return true if could not take another average trace without allocating.\n     // There are many cases where this will lead to some amount of over allocation,\n     // e.g. a very large trace after many very small traces, but it's a best effort\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3OTk3OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425879978", "bodyText": "Would it be possible to change this to accept a Runnable or a custom Callback interface instead?\nWould be nice if CountdownLatch choice is not imposed on the API caller.\nAlso, can this method be called concurrently with onDispatched()?", "author": "jbachorik", "createdAt": "2020-05-15T15:29:15Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +44,192 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean shouldFlush() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);\n   }\n \n-  private int traceBufferSize() {\n-    // round up to next KB, assumes for now that there will be one trace per buffer\n-    return ((lastTracesPerBuffer * traceSizeSum / TRACE_HISTORY_SIZE) + 1023) / 1024;\n+  private int avgTraceSize() {\n+    return traceSizeSum / TRACE_HISTORY_SIZE;\n   }\n \n-  public static class MsgPackTraceBuffer implements TraceBuffer {\n+  static class MsgPackTraceBuffer implements TraceBuffer {\n+\n+    private static final AtomicInteger BUFFER_ID = new AtomicInteger(0);\n \n-    private ArrayBufferOutput buffer;\n+    private final ArrayBufferOutput buffer;\n+    final int id;\n     private int length;\n     private int traceCount;\n+    private int representativeCount;\n+    private CountDownLatch flushLatch;\n+\n+    public MsgPackTraceBuffer(ArrayBufferOutput buffer) {\n+      this.buffer = buffer;\n+      this.id = BUFFER_ID.getAndIncrement();\n+    }\n \n     @Override\n     public void writeTo(WritableByteChannel channel) throws IOException {\n+      writeHeader(channel);\n       int remaining = length;\n       for (MessageBuffer messageBuffer : buffer.toBufferList()) {\n         int size = messageBuffer.size();\n-        ByteBuffer buffer =\n-            size > remaining\n-                ? messageBuffer.sliceAsByteBuffer(0, remaining)\n-                : messageBuffer.sliceAsByteBuffer();\n+        ByteBuffer buffer = messageBuffer.sliceAsByteBuffer(0, Math.min(size, remaining));\n         while (buffer.hasRemaining()) {\n-          channel.write(buffer);\n+          remaining -= channel.write(buffer);\n         }\n-        remaining -= size;\n       }\n       assert remaining == 0;\n     }\n \n+    private void writeHeader(WritableByteChannel channel) throws IOException {\n+      // inlines behaviour from MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(1);\n+        buffer.put(0, (byte) (traceCount | FIXARRAY_PREFIX));\n+        channel.write(buffer);\n+      } else if (traceCount < (1 << 16)) {\n+        ByteBuffer buffer = ByteBuffer.allocate(3);\n+        buffer.put(0, ARRAY16);\n+        buffer.putShort(1, (short) traceCount);\n+        channel.write(buffer);\n+      } else {\n+        ByteBuffer buffer = ByteBuffer.allocate(5);\n+        buffer.put(0, ARRAY32);\n+        buffer.putInt(1, traceCount);\n+        channel.write(buffer);\n+      }\n+    }\n+\n     @Override\n     public int sizeInBytes() {\n       return length;\n     }\n \n+    @Override\n+    public int headerSize() {\n+      // Need to allocate additional to handle MessagePacker.packArrayHeader\n+      if (traceCount < (1 << 4)) {\n+        return 1;\n+      } else if (traceCount < (1 << 16)) {\n+        return 3;\n+      } else {\n+        return 5;\n+      }\n+    }\n+\n     @Override\n     public int traceCount() {\n       return traceCount;\n     }\n+\n+    @Override\n+    public int representativeCount() {\n+      return representativeCount;\n+    }\n+\n+    @Override\n+    public void setRepresentativeCount(int representativeCount) {\n+      this.representativeCount = representativeCount;\n+    }\n+\n+    @Override\n+    public int id() {\n+      return id;\n+    }\n+\n+    @Override\n+    public void setLatch(CountDownLatch latch) {", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMzA2Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425903066", "bodyText": "yes I agree, runnable is more general.\nno, it can't, but we're relying on the disruptor to coordinate that.", "author": "richardstartin", "createdAt": "2020-05-15T16:08:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg3OTk3OA=="}], "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\nindex 431b938c8b..0c025b88b2 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n\n@@ -87,7 +86,7 @@ public class MsgPackStatefulSerializer implements StatefulSerializer {\n   }\n \n   @Override\n-  public boolean shouldFlush() {\n+  public boolean isAtCapacity() {\n     // Return true if could not take another average trace without allocating.\n     // There are many cases where this will lead to some amount of over allocation,\n     // e.g. a very large trace after many very small traces, but it's a best effort\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4MTA1Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425881056", "bodyText": "If I get this right if shouldFlush() returns true the caller should get the buffer contents and reset the buffer. The name then does not sound right - perhaps shouldReset or isCapacityExceeded()? Or something even better fitting the method purpose?", "author": "jbachorik", "createdAt": "2020-05-15T15:31:02Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java", "diffHunk": "@@ -10,17 +10,32 @@\n    * Serialises the trace into a trace buffer.\n    *\n    * @param trace a list of spans making up a trace\n+   * @return how many bytes were serialized\n    * @throws IOException\n    */\n-  void serialize(List<DDSpan> trace) throws IOException;\n+  int serialize(List<DDSpan> trace) throws IOException;\n+\n+  void dropBuffer() throws IOException;\n \n   /**\n-   * Returns a buffer containing all traces written since the last call to this method. The buffer\n-   * belongs to the caller and should no longer be referenced by the serializer after being\n-   * released.\n+   * returns a newly allocated buffer\n    *\n-   * @return the buffer into which traces have been serialized.\n-   * @throws IOException\n+   * @return a new buffer\n+   */\n+  TraceBuffer newBuffer();\n+\n+  /**\n+   * Returns true if the current buffer is near or exceeding capacity. This is advice to claim the\n+   * buffer and reset.\n+   *\n+   * @return true if the buffer should be reset", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk0MDQ2OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425940468", "bodyText": "I've changed the name, but it's not an easy method to name. How do you feel about shouldGetTheBufferNowOrTheNextTraceMayCauseAnAllocationOrThatMayAlreadyHaveHappenedButItWasMostlyUnavoidable? I went with isAtCapacity, but that doesn't describe the semantics of the only implementation.", "author": "richardstartin", "createdAt": "2020-05-15T17:17:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4MTA1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java\nindex 9ff9fe7459..df4b275a6d 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/StatefulSerializer.java\n\n@@ -30,7 +30,7 @@ public interface StatefulSerializer {\n    *\n    * @return true if the buffer should be reset\n    */\n-  boolean shouldFlush();\n+  boolean isAtCapacity();\n \n   /**\n    * Resets the buffer to use\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4NjkzMg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425886932", "bodyText": "Probably the nested try is not necessary here.", "author": "jbachorik", "createdAt": "2020-05-15T15:41:01Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,227 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        try {", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex 71ecbe13ab..c88a0fee6f 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,29 +145,27 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        try {\n-          if (event.force\n-              || (representativeCount > 0 && serializer.shouldFlush())\n-              || event.flushLatch != null) {\n-            commitTransaction(event.flushLatch);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n             beginTransaction();\n-          } else if (doTimeFlush && representativeCount > 0) {\n-            long now = millisecondTime();\n-            if (now >= nextFlushMillis) {\n-              commitTransaction();\n-              beginTransaction();\n-              scheduleNextTimeFlush(now);\n-            }\n+            scheduleNextTimeFlush(now);\n           }\n-          if (event.data != null) {\n-            serialize(event.data, event.representativeCount);\n-          }\n-        } catch (final Throwable e) {\n-          if (log.isDebugEnabled()) {\n-            log.debug(\"Error while serializing trace\", e);\n-          }\n-          monitor.onFailedSerialize(writer, event.data, e);\n         }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n+        }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4OTMyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425889327", "bodyText": "Is this change related to the disruptor changes?", "author": "jbachorik", "createdAt": "2020-05-15T15:45:07Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/FormatWriter.java", "diffHunk": "@@ -85,7 +85,7 @@ public void writeStringMap(\n     writeKey(key, destination);\n     writeMapHeader(value.size(), destination);\n     for (final Map.Entry<String, String> entry : value.entrySet()) {\n-      writeString(entry.getKey(), entry.getValue(), destination);\n+      writeTag(entry.getKey(), entry.getValue(), destination);", "originalCommit": "bbac1ed124fe0bf03b5017a572b2bc2dafebbbc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk1MzAwNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425953004", "bodyText": "True, but this caused a small regression when changed with the last change to this area of the code (perhaps shouldn't have been changed then) so just undoing it now.", "author": "richardstartin", "createdAt": "2020-05-15T17:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg4OTMyNw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4Mzc1Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425983756", "bodyText": "Do we want to wait for flushing at all?", "author": "tylerbenson", "createdAt": "2020-05-15T18:43:50Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjUxNjI5Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426516293", "bodyText": "Only DDAgentWriter calls this method, but does a flush with a timeout before doing so. So it shouldn't matter in practice, but this class isn't taking responsibility for flushing data. All that's done before halting the disruptor is we make sure no more heartbeats are sent. This may need some more thought, but I'm working on the principle that losing some traces at shutdown is preferable to delaying shutdown.", "author": "richardstartin", "createdAt": "2020-05-18T10:09:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4Mzc1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex c88a0fee6f..71ecbe13ab 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,27 +145,29 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        if (event.force\n-            || (representativeCount > 0 && serializer.isAtCapacity())\n-            || event.flushLatch != null) {\n-          commitTransaction(event.flushLatch);\n-          beginTransaction();\n-        } else if (doTimeFlush && representativeCount > 0) {\n-          long now = millisecondTime();\n-          if (now >= nextFlushMillis) {\n-            commitTransaction();\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n             beginTransaction();\n-            scheduleNextTimeFlush(now);\n+          } else if (doTimeFlush && representativeCount > 0) {\n+            long now = millisecondTime();\n+            if (now >= nextFlushMillis) {\n+              commitTransaction();\n+              beginTransaction();\n+              scheduleNextTimeFlush(now);\n+            }\n           }\n+          if (event.data != null) {\n+            serialize(event.data, event.representativeCount);\n+          }\n+        } catch (final Throwable e) {\n+          if (log.isDebugEnabled()) {\n+            log.debug(\"Error while serializing trace\", e);\n+          }\n+          monitor.onFailedSerialize(writer, event.data, e);\n         }\n-        if (event.data != null) {\n-          serialize(event.data, event.representativeCount);\n-        }\n-      } catch (final Throwable e) {\n-        if (log.isDebugEnabled()) {\n-          log.debug(\"Error while serializing trace\", e);\n-        }\n-        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425988110", "bodyText": "Something that seems to have been changed, and maybe it was intentional, but in the previous version, if there was enough flushing due to size, then the heartbeat would never actually trigger a flush.  the timeout for the flush delay was reset every flush.  With the current design, it seems you could send a bunch of large payloads, but then occasionally you'll see a smaller one.\nAn additional reason to keep a \"time since last flush\" timestamp and not just since the last heartbeat flush is I think that would make an interesting health metric to report... (how frequent are we actually flushing).", "author": "tylerbenson", "createdAt": "2020-05-15T18:52:44Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ4ODA2OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426488068", "bodyText": "I agree, this was moved over at the end and probably needs more thought.", "author": "richardstartin", "createdAt": "2020-05-18T09:23:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU0MTM1OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426541358", "bodyText": "I have attempted to address this. Please let me know what you think.", "author": "richardstartin", "createdAt": "2020-05-18T10:56:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY2OTY0OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426669649", "bodyText": "Looks better. Thanks!", "author": "tylerbenson", "createdAt": "2020-05-18T14:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODExMA=="}], "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex c88a0fee6f..71ecbe13ab 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,27 +145,29 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        if (event.force\n-            || (representativeCount > 0 && serializer.isAtCapacity())\n-            || event.flushLatch != null) {\n-          commitTransaction(event.flushLatch);\n-          beginTransaction();\n-        } else if (doTimeFlush && representativeCount > 0) {\n-          long now = millisecondTime();\n-          if (now >= nextFlushMillis) {\n-            commitTransaction();\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n             beginTransaction();\n-            scheduleNextTimeFlush(now);\n+          } else if (doTimeFlush && representativeCount > 0) {\n+            long now = millisecondTime();\n+            if (now >= nextFlushMillis) {\n+              commitTransaction();\n+              beginTransaction();\n+              scheduleNextTimeFlush(now);\n+            }\n           }\n+          if (event.data != null) {\n+            serialize(event.data, event.representativeCount);\n+          }\n+        } catch (final Throwable e) {\n+          if (log.isDebugEnabled()) {\n+            log.debug(\"Error while serializing trace\", e);\n+          }\n+          monitor.onFailedSerialize(writer, event.data, e);\n         }\n-        if (event.data != null) {\n-          serialize(event.data, event.representativeCount);\n-        }\n-      } catch (final Throwable e) {\n-        if (log.isDebugEnabled()) {\n-          log.debug(\"Error while serializing trace\", e);\n-        }\n-        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425988870", "bodyText": "Why not keep all units in nano?", "author": "tylerbenson", "createdAt": "2020-05-15T18:54:18Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ4ODIyMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426488223", "bodyText": "arithmetic overflow", "author": "richardstartin", "createdAt": "2020-05-18T09:23:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY2NzcyNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426667724", "bodyText": "consider adding a comment with this rationalization.", "author": "tylerbenson", "createdAt": "2020-05-18T14:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4ODg3MA=="}], "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex c88a0fee6f..71ecbe13ab 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,27 +145,29 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        if (event.force\n-            || (representativeCount > 0 && serializer.isAtCapacity())\n-            || event.flushLatch != null) {\n-          commitTransaction(event.flushLatch);\n-          beginTransaction();\n-        } else if (doTimeFlush && representativeCount > 0) {\n-          long now = millisecondTime();\n-          if (now >= nextFlushMillis) {\n-            commitTransaction();\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n             beginTransaction();\n-            scheduleNextTimeFlush(now);\n+          } else if (doTimeFlush && representativeCount > 0) {\n+            long now = millisecondTime();\n+            if (now >= nextFlushMillis) {\n+              commitTransaction();\n+              beginTransaction();\n+              scheduleNextTimeFlush(now);\n+            }\n           }\n+          if (event.data != null) {\n+            serialize(event.data, event.representativeCount);\n+          }\n+        } catch (final Throwable e) {\n+          if (log.isDebugEnabled()) {\n+            log.debug(\"Error while serializing trace\", e);\n+          }\n+          monitor.onFailedSerialize(writer, event.data, e);\n         }\n-        if (event.data != null) {\n-          serialize(event.data, event.representativeCount);\n-        }\n-      } catch (final Throwable e) {\n-        if (log.isDebugEnabled()) {\n-          log.debug(\"Error while serializing trace\", e);\n-        }\n-        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4OTg2MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425989861", "bodyText": "I generally prefer to let TimeUnit do my conversions to avoid silly arithmetic errors.", "author": "tylerbenson", "createdAt": "2020-05-15T18:56:15Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();\n+        } else if (doTimeFlush && representativeCount > 0) {\n+          long now = millisecondTime();\n+          if (now >= nextFlushMillis) {\n+            commitTransaction();\n+            beginTransaction();\n+            scheduleNextTimeFlush(now);\n           }\n         }\n-\n-        if (event.flushLatch != null) {\n-          if (batchWritingDisruptor.running) {\n-            // propagate the flush.\n-            batchWritingDisruptor.flush(event.representativeCount, event.flushLatch);\n-          }\n-          if (!batchWritingDisruptor.running) { // check again to protect against race condition.\n-            // got shutdown early somehow?\n-            event.flushLatch.countDown();\n-          }\n+        if (event.data != null) {\n+          serialize(event.data, event.representativeCount);\n+        }\n+      } catch (final Throwable e) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Error while serializing trace\", e);\n         }\n+        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n     }\n+\n+    private void serialize(List<DDSpan> trace, int representativeCount) throws IOException {\n+      // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n+      this.representativeCount += representativeCount;\n+      trace = processor.onTraceComplete(trace);\n+      int sizeInBytes = serializer.serialize(trace);\n+      monitor.onSerialize(writer, trace, sizeInBytes);\n+    }\n+\n+    private void commitTransaction() throws IOException {\n+      commitTransaction(null);\n+    }\n+\n+    private void commitTransaction(final CountDownLatch flushLatch) throws IOException {\n+      serializer.dropBuffer();\n+      TraceBuffer buffer = dispatchingDisruptor.getTraceBuffer(publicationTxn);\n+      if (null != flushLatch) {\n+        buffer.setDispatchRunnable(\n+            new Runnable() {\n+              @Override\n+              public void run() {\n+                flushLatch.countDown();\n+              }\n+            });\n+      }\n+      buffer.setRepresentativeCount(representativeCount);\n+      if (log.isDebugEnabled()) {\n+        log.debug(\n+            \"publish id={}, rc={}, tc={}\",\n+            buffer.id(),\n+            buffer.representativeCount(),\n+            buffer.traceCount());\n+      }\n+      dispatchingDisruptor.commit(publicationTxn);\n+    }\n+\n+    private void beginTransaction() {\n+      this.publicationTxn = dispatchingDisruptor.beginTransaction();\n+      this.representativeCount = 0;\n+      serializer.reset(dispatchingDisruptor.getTraceBuffer(publicationTxn));\n+    }\n+\n+    private void scheduleNextTimeFlush(long now) {\n+      nextFlushMillis = now + flushIntervalMillis;\n+    }\n+\n+    private long millisecondTime() {\n+      // important: nanoTime is monotonic, currentTimeMillis is not\n+      return System.nanoTime() / 1_000_000L;", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU0MTEzNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426541137", "bodyText": "Done.", "author": "richardstartin", "createdAt": "2020-05-18T10:56:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk4OTg2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex c88a0fee6f..71ecbe13ab 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,27 +145,29 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        if (event.force\n-            || (representativeCount > 0 && serializer.isAtCapacity())\n-            || event.flushLatch != null) {\n-          commitTransaction(event.flushLatch);\n-          beginTransaction();\n-        } else if (doTimeFlush && representativeCount > 0) {\n-          long now = millisecondTime();\n-          if (now >= nextFlushMillis) {\n-            commitTransaction();\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n             beginTransaction();\n-            scheduleNextTimeFlush(now);\n+          } else if (doTimeFlush && representativeCount > 0) {\n+            long now = millisecondTime();\n+            if (now >= nextFlushMillis) {\n+              commitTransaction();\n+              beginTransaction();\n+              scheduleNextTimeFlush(now);\n+            }\n           }\n+          if (event.data != null) {\n+            serialize(event.data, event.representativeCount);\n+          }\n+        } catch (final Throwable e) {\n+          if (log.isDebugEnabled()) {\n+            log.debug(\"Error while serializing trace\", e);\n+          }\n+          monitor.onFailedSerialize(writer, event.data, e);\n         }\n-        if (event.data != null) {\n-          serialize(event.data, event.representativeCount);\n-        }\n-      } catch (final Throwable e) {\n-        if (log.isDebugEnabled()) {\n-          log.debug(\"Error while serializing trace\", e);\n-        }\n-        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk5Njg4OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r425996888", "bodyText": "beginTransaction() is always called after commitTransaction.  Perhaps the begin should be implicit (called inside commit)?", "author": "tylerbenson", "createdAt": "2020-05-15T19:09:18Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,233 @@\n package datadog.trace.common.writer.ddagent;\n \n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, TimeUnit.MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush(millisecondTime());\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }\n       try {\n-        if (event.data != null) {\n-          // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n-          try {\n-            event.data = processor.onTraceComplete(event.data);\n-            // the intention is that batching ends up being handled here,\n-            // rather than on the BatchWritingDisruptor, which would\n-            // be responsible for sending trace buffers to the agent\n-            // synchronously, before returning the trace buffer for\n-            // reuse.\n-            serializer.serialize(event.data);\n-            TraceBuffer serializedTrace = serializer.getBuffer();\n-            int sizeInBytes = serializedTrace.sizeInBytes();\n-            batchWritingDisruptor.publish(serializedTrace, event.representativeCount);\n-            monitor.onSerialize(writer, event.data, sizeInBytes);\n-            event.representativeCount = 0; // reset in case flush is invoked below.\n-          } catch (final Throwable e) {\n-            log.debug(\"Error while serializing trace\", e);\n-            monitor.onFailedSerialize(writer, event.data, e);\n+        if (event.force\n+            || (representativeCount > 0 && serializer.isAtCapacity())\n+            || event.flushLatch != null) {\n+          commitTransaction(event.flushLatch);\n+          beginTransaction();", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex c88a0fee6f..71ecbe13ab 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -145,27 +145,29 @@ public class TraceProcessingDisruptor implements AutoCloseable {\n         beginTransaction();\n       }\n       try {\n-        if (event.force\n-            || (representativeCount > 0 && serializer.isAtCapacity())\n-            || event.flushLatch != null) {\n-          commitTransaction(event.flushLatch);\n-          beginTransaction();\n-        } else if (doTimeFlush && representativeCount > 0) {\n-          long now = millisecondTime();\n-          if (now >= nextFlushMillis) {\n-            commitTransaction();\n+        try {\n+          if (event.force\n+              || (representativeCount > 0 && serializer.shouldFlush())\n+              || event.flushLatch != null) {\n+            commitTransaction(event.flushLatch);\n             beginTransaction();\n-            scheduleNextTimeFlush(now);\n+          } else if (doTimeFlush && representativeCount > 0) {\n+            long now = millisecondTime();\n+            if (now >= nextFlushMillis) {\n+              commitTransaction();\n+              beginTransaction();\n+              scheduleNextTimeFlush(now);\n+            }\n           }\n+          if (event.data != null) {\n+            serialize(event.data, event.representativeCount);\n+          }\n+        } catch (final Throwable e) {\n+          if (log.isDebugEnabled()) {\n+            log.debug(\"Error while serializing trace\", e);\n+          }\n+          monitor.onFailedSerialize(writer, event.data, e);\n         }\n-        if (event.data != null) {\n-          serialize(event.data, event.representativeCount);\n-        }\n-      } catch (final Throwable e) {\n-        if (log.isDebugEnabled()) {\n-          log.debug(\"Error while serializing trace\", e);\n-        }\n-        monitor.onFailedSerialize(writer, event.data, e);\n       } finally {\n         event.reset();\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426004782", "bodyText": "Can you add a comment somewhere explaining how this estimation method works?", "author": "tylerbenson", "createdAt": "2020-05-15T19:27:05Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,193 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n   private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n   private int traceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizes, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.traceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }\n+    // reset the packer's position to zero\n+    messagePacker.clear();\n     try {\n-      messagePacker.flush();\n-      return lastBuffer;\n-    } finally {\n-      lastTracesPerBuffer = tracesPerBuffer;\n-      tracesPerBuffer = 0;\n-      lastBuffer = null;\n+      messagePacker.reset(traceBuffer.buffer);\n+    } catch (IOException e) { // don't expect this to happen\n+      log.error(\"Unexpected exception resetting MessagePacker buffer\", e);\n     }\n   }\n \n-  private MsgPackTraceBuffer newBuffer() {\n-    MsgPackTraceBuffer buffer = new MsgPackTraceBuffer();\n-    int traceBufferSize = traceBufferSize();\n-    buffer.buffer = new ArrayBufferOutput(traceBufferSize);\n-    return buffer;\n+  @Override\n+  public MsgPackTraceBuffer newBuffer() {\n+    return new MsgPackTraceBuffer(new ArrayBufferOutput(bufferSize));\n   }\n \n-  private void updateTraceSize(int traceSize) {\n+  private void updateTraceSizeEstimate(int traceSize) {\n     traceSizeSum = (traceSizeSum - traceSizes[position] + traceSize);\n     traceSizes[position] = traceSize;\n     position = (position + 1) & (traceSizes.length - 1);", "originalCommit": "336bec7e307043d5abfe428d69b48c4f1cba1ce3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5ODgyMg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426498822", "bodyText": "Sure, but it's just a moving average of trace size, using a ring buffer to store history, with constant update/calculation time.", "author": "richardstartin", "createdAt": "2020-05-18T09:41:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5OTQzMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426499431", "bodyText": "To simplify the calculation, the ring buffer is filled with an estimate at the start, but once 16 traces have been seen, it's a real moving average of trace sizes.", "author": "richardstartin", "createdAt": "2020-05-18T09:42:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAwNDc4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\nindex 0c025b88b2..431b938c8b 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java\n\n@@ -86,7 +87,7 @@ public class MsgPackStatefulSerializer implements StatefulSerializer {\n   }\n \n   @Override\n-  public boolean isAtCapacity() {\n+  public boolean shouldFlush() {\n     // Return true if could not take another average trace without allocating.\n     // There are many cases where this will lead to some amount of over allocation,\n     // e.g. a very large trace after many very small traces, but it's a best effort\n"}}, {"oid": "749a8833bcfe5a0e48547801924e25b1eb8175cf", "url": "https://github.com/DataDog/dd-trace-java/commit/749a8833bcfe5a0e48547801924e25b1eb8175cf", "message": "move batching to trace processor to ease memory buffer reuse\n\n Date:      Wed May 13 11:00:00 2020 +0100", "committedDate": "2020-05-18T11:29:27Z", "type": "commit"}, {"oid": "3c2adca9b3842c4a5904a52c0f65b549e2290831", "url": "https://github.com/DataDog/dd-trace-java/commit/3c2adca9b3842c4a5904a52c0f65b549e2290831", "message": "make revapi happy", "committedDate": "2020-05-18T11:30:25Z", "type": "commit"}, {"oid": "03a8c83bf0daf377859bf7112a584db891fedc65", "url": "https://github.com/DataDog/dd-trace-java/commit/03a8c83bf0daf377859bf7112a584db891fedc65", "message": "make verifyGoogleJavaFormat happy", "committedDate": "2020-05-18T11:30:35Z", "type": "commit"}, {"oid": "92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "url": "https://github.com/DataDog/dd-trace-java/commit/92aa000eb91a5beb0a5bf10efe903aa99ab86de0", "message": "review comments", "committedDate": "2020-05-18T11:30:35Z", "type": "commit"}, {"oid": "e8d28480c7eacd11d35e5ce3c15a6128fb94a13a", "url": "https://github.com/DataDog/dd-trace-java/commit/e8d28480c7eacd11d35e5ce3c15a6128fb94a13a", "message": "restore heartbeat semantics (don't force a flush unless the time threshold has been breached)", "committedDate": "2020-05-18T11:30:35Z", "type": "commit"}, {"oid": "a5209f82714f66f1f91889c7f05032c295900f07", "url": "https://github.com/DataDog/dd-trace-java/commit/a5209f82714f66f1f91889c7f05032c295900f07", "message": "document the trace size moving average calculation", "committedDate": "2020-05-18T11:30:35Z", "type": "commit"}, {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "url": "https://github.com/DataDog/dd-trace-java/commit/3d4b102be3893746448bcbd7c6e4e6ae468f4178", "message": "rebase revapi breaks", "committedDate": "2020-05-18T11:35:17Z", "type": "commit"}, {"oid": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "url": "https://github.com/DataDog/dd-trace-java/commit/3d4b102be3893746448bcbd7c6e4e6ae468f4178", "message": "rebase revapi breaks", "committedDate": "2020-05-18T11:35:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MTgxNQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426691815", "bodyText": "I wonder if we should limit this to 4 instead... 8 fully serialized buffers seems like a significant backlog.", "author": "tylerbenson", "createdAt": "2020-05-18T15:01:46Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -34,12 +37,14 @@\n public class DDAgentWriter implements Writer {\n \n   private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n+  private static final int OUTSTANDING_REQUESTS = 8;", "originalCommit": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NTkzMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426765930", "bodyText": "I agree. Decreases RSS too.", "author": "richardstartin", "createdAt": "2020-05-18T16:53:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MTgxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "c3f8b6ec05ec24e43edc953b522286fca3e1e065", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\nindex bbd7c19ca2..88a20e2782 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\n\n@@ -37,7 +37,7 @@ import lombok.extern.slf4j.Slf4j;\n public class DDAgentWriter implements Writer {\n \n   private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n-  private static final int OUTSTANDING_REQUESTS = 8;\n+  private static final int OUTSTANDING_REQUESTS = 4;\n \n   private final DDAgentApi api;\n   private final TraceProcessingDisruptor traceProcessingDisruptor;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5MzMwNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426693304", "bodyText": "Do we want to check the closed state at all in here?", "author": "tylerbenson", "createdAt": "2020-05-18T15:03:53Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -166,20 +183,21 @@ public DDAgentApi getApi() {\n \n   @Override\n   public void start() {\n-    batchWritingDisruptor.start();\n+    dispatchingDisruptor.start();\n     traceProcessingDisruptor.start();\n     monitor.onStart(this);\n   }", "originalCommit": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c3f8b6ec05ec24e43edc953b522286fca3e1e065", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\nindex bbd7c19ca2..88a20e2782 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/DDAgentWriter.java\n\n@@ -183,9 +182,11 @@ public class DDAgentWriter implements Writer {\n \n   @Override\n   public void start() {\n-    dispatchingDisruptor.start();\n-    traceProcessingDisruptor.start();\n-    monitor.onStart(this);\n+    if (!closed) {\n+      dispatchingDisruptor.start();\n+      traceProcessingDisruptor.start();\n+      monitor.onStart(this);\n+    }\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY5OTY4OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426699689", "bodyText": "Would it be better to shift the heartbeat logic into the constructor instead of exposing as a parameter?", "author": "tylerbenson", "createdAt": "2020-05-18T15:12:42Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,234 @@\n package datadog.trace.common.writer.ddagent;\n \n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator<>();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {", "originalCommit": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc0NjU2OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426746569", "bodyText": "Should this be called in the constructor instead?", "author": "tylerbenson", "createdAt": "2020-05-18T16:21:01Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -1,103 +1,234 @@\n package datadog.trace.common.writer.ddagent;\n \n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+\n+import com.lmax.disruptor.BlockingWaitStrategy;\n import com.lmax.disruptor.EventHandler;\n+import com.lmax.disruptor.dsl.Disruptor;\n+import com.lmax.disruptor.dsl.ProducerType;\n+import datadog.common.exec.CommonTaskExecutor;\n import datadog.common.exec.DaemonThreadFactory;\n import datadog.trace.common.writer.DDAgentWriter;\n import datadog.trace.core.DDSpan;\n import datadog.trace.core.processor.TraceProcessor;\n+import java.io.IOException;\n import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n  * Disruptor that takes completed traces and applies processing to them. Upon completion, the\n- * serialized trace is published to {@link BatchWritingDisruptor}.\n+ * serialized trace is published to {@link DispatchingDisruptor}.\n  *\n  * <p>publishing to the buffer will not block the calling thread, but instead will return false if\n  * the buffer is full. This is to avoid impacting an application thread.\n  */\n @Slf4j\n-public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+public class TraceProcessingDisruptor implements AutoCloseable {\n+\n+  private final Disruptor<DisruptorEvent<List<DDSpan>>> disruptor;\n+  private final DisruptorEvent.DataTranslator<List<DDSpan>> dataTranslator;\n+  private final DisruptorEvent.FlushTranslator<List<DDSpan>> flushTranslator;\n+  private final DisruptorEvent.HeartbeatTranslator<List<DDSpan>> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator<>();\n+  private final boolean doHeartbeat;\n+\n+  private volatile ScheduledFuture<?> heartbeat;\n \n   public TraceProcessingDisruptor(\n       final int disruptorSize,\n-      final BatchWritingDisruptor batchWritingDisruptor,\n+      final DispatchingDisruptor dispatchingDisruptor,\n       final Monitor monitor,\n       final DDAgentWriter writer,\n-      final StatefulSerializer serializer) {\n-    // TODO: add config to enable control over serialization overhead.\n-    super(\n-        disruptorSize,\n-        new TraceSerializingHandler(batchWritingDisruptor, monitor, writer, serializer));\n+      final StatefulSerializer serializer,\n+      final long flushInterval,\n+      final TimeUnit timeUnit,\n+      final boolean heartbeat) {\n+    this.disruptor =\n+        DisruptorUtils.create(\n+            new DisruptorEvent.Factory<List<DDSpan>>(),\n+            disruptorSize,\n+            DaemonThreadFactory.TRACE_PROCESSOR,\n+            ProducerType.MULTI,\n+            new BlockingWaitStrategy());\n+    disruptor.handleEventsWith(\n+        new TraceSerializingHandler(\n+            dispatchingDisruptor, monitor, writer, serializer, flushInterval, timeUnit));\n+    this.dataTranslator = new DisruptorEvent.DataTranslator<>();\n+    this.flushTranslator = new DisruptorEvent.FlushTranslator<>();\n+    this.doHeartbeat = heartbeat;\n   }\n \n-  @Override\n-  protected DaemonThreadFactory getThreadFactory() {\n-    return DaemonThreadFactory.TRACE_PROCESSOR;\n+  public void start() {\n+    if (doHeartbeat) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      heartbeat =\n+          CommonTaskExecutor.INSTANCE.scheduleAtFixedRate(\n+              new HeartbeatTask(), this, 100, 100, MILLISECONDS, \"disruptor heartbeat\");\n+    }\n+    disruptor.start();\n+  }\n+\n+  public boolean flush(long timeout, TimeUnit timeUnit) {\n+    CountDownLatch latch = new CountDownLatch(1);\n+    disruptor.publishEvent(flushTranslator, 0, latch);\n+    try {\n+      return latch.await(timeout, timeUnit);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      return false;\n+    }\n   }\n \n   @Override\n+  public void close() {\n+    if (null != heartbeat) {\n+      heartbeat.cancel(true);\n+    }\n+    disruptor.halt();\n+  }\n+\n   public boolean publish(final List<DDSpan> data, final int representativeCount) {\n     return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n   }\n \n-  // This class is threadsafe if we want to enable more processors.\n+  void heartbeat() {\n+    disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+  }\n+\n+  public int getDisruptorCapacity() {\n+    return disruptor.getRingBuffer().getBufferSize();\n+  }\n+\n+  public long getDisruptorRemainingCapacity() {\n+    return disruptor.getRingBuffer().remainingCapacity();\n+  }\n+\n   public static class TraceSerializingHandler\n       implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n     private final TraceProcessor processor = new TraceProcessor();\n-    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final DispatchingDisruptor dispatchingDisruptor;\n     private final Monitor monitor;\n     private final DDAgentWriter writer;\n     private final StatefulSerializer serializer;\n+    private final long flushIntervalMillis;\n+    private final boolean doTimeFlush;\n+\n+    private long publicationTxn = -1;\n+    private int representativeCount = 0;\n+    private long nextFlushMillis;\n \n     public TraceSerializingHandler(\n-        final BatchWritingDisruptor batchWritingDisruptor,\n+        final DispatchingDisruptor dispatchingDisruptor,\n         final Monitor monitor,\n         final DDAgentWriter writer,\n-        final StatefulSerializer serializer) {\n-      this.batchWritingDisruptor = batchWritingDisruptor;\n+        final StatefulSerializer serializer,\n+        final long flushInterval,\n+        final TimeUnit timeUnit) {\n+      this.dispatchingDisruptor = dispatchingDisruptor;\n       this.monitor = monitor;\n       this.writer = writer;\n       this.serializer = serializer;\n+      this.doTimeFlush = flushInterval > 0;\n+      if (doTimeFlush) {\n+        this.flushIntervalMillis = timeUnit.toMillis(flushInterval);\n+        scheduleNextTimeFlush();\n+      } else {\n+        this.flushIntervalMillis = Long.MAX_VALUE;\n+      }\n     }\n \n     @Override\n     public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      if (-1L == publicationTxn) {\n+        beginTransaction();\n+      }", "originalCommit": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NTYzMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426765630", "bodyText": "no, I'm not 100% sure but I don't think it's safe to.", "author": "richardstartin", "createdAt": "2020-05-18T16:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc0NjU2OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1MjQ0Nw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426752447", "bodyText": "Should this class be made generic instead to ensure the proper argument type?", "author": "tylerbenson", "createdAt": "2020-05-18T16:30:29Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/MsgPackStatefulSerializer.java", "diffHunk": "@@ -37,99 +43,205 @@\n \n   // reusing this within the context of each thread is handy because it\n   // caches an Encoder\n-  private final MessagePacker messagePacker =\n-      MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n+  private final MessagePacker messagePacker;\n \n-  private final int[] traceSizes = new int[TRACE_HISTORY_SIZE];\n+  private final int[] traceSizeHistory = new int[TRACE_HISTORY_SIZE];\n+  private final int sizeThresholdBytes;\n+  private final int bufferSize;\n \n-  private int traceSizeSum;\n+  private int runningTraceSizeSum;\n   private int position;\n-  private MsgPackTraceBuffer lastBuffer;\n+  private MsgPackTraceBuffer traceBuffer;\n \n-  private int lastTracesPerBuffer = 1;\n-  private int tracesPerBuffer;\n+  private int currentSerializedBytes = 0;\n \n   public MsgPackStatefulSerializer() {\n-    Arrays.fill(traceSizes, INITIAL_BUFFER_SIZE);\n-    this.traceSizeSum = INITIAL_BUFFER_SIZE * TRACE_HISTORY_SIZE;\n+    this(DEFAULT_BUFFER_THRESHOLD, DEFAULT_BUFFER_THRESHOLD * 3 / 2); // 1MB\n+  }\n+\n+  public MsgPackStatefulSerializer(int sizeThresholdBytes, int bufferSize) {\n+    Arrays.fill(traceSizeHistory, INITIAL_TRACE_SIZE_ESTIMATE);\n+    this.runningTraceSizeSum = INITIAL_TRACE_SIZE_ESTIMATE * TRACE_HISTORY_SIZE;\n+    this.sizeThresholdBytes = sizeThresholdBytes;\n+    this.bufferSize = bufferSize;\n+    this.messagePacker = MESSAGE_PACKER_CONFIG.newPacker(new ArrayBufferOutput(0));\n   }\n \n   @Override\n-  public void serialize(List<DDSpan> trace) throws IOException {\n-    if (null == lastBuffer) {\n-      lastBuffer = newBuffer();\n-      messagePacker.reset(lastBuffer.buffer);\n-      messagePacker.clear();\n-    }\n+  public int serialize(List<DDSpan> trace) throws IOException {\n     MSGPACK_WRITER.writeTrace(trace, messagePacker);\n-    int serializedSize = (int) messagePacker.getTotalWrittenBytes();\n-    updateTraceSize(serializedSize);\n-    lastBuffer.length += serializedSize;\n-    ++lastBuffer.traceCount;\n-    ++tracesPerBuffer;\n+    int newSerializedSize = (int) messagePacker.getTotalWrittenBytes();\n+    int serializedSize = newSerializedSize - currentSerializedBytes;\n+    currentSerializedBytes = newSerializedSize;\n+    updateTraceSizeEstimate(serializedSize);\n+    ++traceBuffer.traceCount;\n+    traceBuffer.length = newSerializedSize;\n+    return serializedSize;\n+  }\n+\n+  @Override\n+  public void dropBuffer() throws IOException {\n+    messagePacker.flush();\n+    traceBuffer = null;\n+  }\n+\n+  @Override\n+  public boolean isAtCapacity() {\n+    // Return true if could not take another average trace without allocating.\n+    // There are many cases where this will lead to some amount of over allocation,\n+    // e.g. a very large trace after many very small traces, but it's a best effort\n+    // strategy to avoid buffer growth eventually.\n+    return currentSerializedBytes + avgTraceSize() >= sizeThresholdBytes;\n   }\n \n   @Override\n-  public TraceBuffer getBuffer() throws IOException {\n+  public void reset(TraceBuffer buffer) {\n+    if (buffer instanceof MsgPackTraceBuffer) {\n+      this.traceBuffer = (MsgPackTraceBuffer) buffer;\n+      this.traceBuffer.reset();\n+    } else { // i.e. if (null == buffer || unuseable)\n+      this.traceBuffer = newBuffer();\n+    }", "originalCommit": "3d4b102be3893746448bcbd7c6e4e6ae468f4178", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc2NzgxMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1454#discussion_r426767811", "bodyText": "I would like to, but it ripples out a long way, and I don't want to make the change now. At the back of my mind is keeping message pack abstracted to some extent. It would be nice to easily swap out for another codec but keep the same mechanisms in place, and not hardcode to StatefulSerializer<MsgPack> or similar in DDAgentWriter. I will add a comment that this can be made generic.", "author": "richardstartin", "createdAt": "2020-05-18T16:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1MjQ0Nw=="}], "type": "inlineReview", "revised_code": null}, {"oid": "c3f8b6ec05ec24e43edc953b522286fca3e1e065", "url": "https://github.com/DataDog/dd-trace-java/commit/c3f8b6ec05ec24e43edc953b522286fca3e1e065", "message": "review comments", "committedDate": "2020-05-18T17:08:56Z", "type": "commit"}]}