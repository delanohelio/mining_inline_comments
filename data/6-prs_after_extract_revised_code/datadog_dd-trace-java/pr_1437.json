{"pr_number": 1437, "pr_title": "Reduce copy/allocation in trace serialization pipeline", "pr_createdAt": "2020-05-07T15:19:52Z", "pr_url": "https://github.com/DataDog/dd-trace-java/pull/1437", "timeline": [{"oid": "844be383d19af7fd6314b811cfe14e77c86a35ec", "url": "https://github.com/DataDog/dd-trace-java/commit/844be383d19af7fd6314b811cfe14e77c86a35ec", "message": "replace byte[] with ByteBuffer to reduce copy/allocation", "committedDate": "2020-05-07T15:18:24Z", "type": "commit"}, {"oid": "894b1e303a558e7cee3b0d12e31e49a859060d9b", "url": "https://github.com/DataDog/dd-trace-java/commit/894b1e303a558e7cee3b0d12e31e49a859060d9b", "message": "return null from StringTables when no entry is present", "committedDate": "2020-05-08T06:57:17Z", "type": "commit"}, {"oid": "a7da77bc24e2fbf245f9c1dbeaa3bd02c0236aeb", "url": "https://github.com/DataDog/dd-trace-java/commit/a7da77bc24e2fbf245f9c1dbeaa3bd02c0236aeb", "message": "Merge branch 'master' into richardstartin/bytebuff-events", "committedDate": "2020-05-08T07:00:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE3MjQ0OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r422172449", "bodyText": "For the sake of seeing the difference between this and the next check, it might make sense to change the 16 to 0x100", "author": "devinsba", "createdAt": "2020-05-08T14:23:24Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -147,14 +151,18 @@ public long contentLength() {\n \n             @Override\n             public void writeTo(final BufferedSink sink) throws IOException {\n-              final OutputStream out = sink.outputStream();\n-              final MessagePacker packer = MessagePack.newDefaultPacker(out);\n-              packer.packArrayHeader(traces.size());\n-              for (final byte[] trace : traces) {\n-                packer.writePayload(trace);\n+              if (traces.size() < 16) {", "originalCommit": "a7da77bc24e2fbf245f9c1dbeaa3bd02c0236aeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg4NzAzMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r422887031", "bodyText": "It's been inlined from MessagePacker so I will leave it exactly as it is there, I just don't like numbers written as shifts.", "author": "richardstartin", "createdAt": "2020-05-11T08:54:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE3MjQ0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "de740e62f3eabad366003518e2882e9dca641773", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\nindex f562b58741..10c64616e7 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n\n@@ -87,88 +75,20 @@ public class DDAgentApi {\n     }\n   }\n \n-  /**\n-   * Send traces to the DD agent\n-   *\n-   * @param traces the traces to be sent\n-   * @return a Response object -- encapsulating success of communication, sending, and result\n-   *     parsing\n-   */\n-  Response sendTraces(final List<List<DDSpan>> traces) {\n-    final List<ByteBuffer> serializedTraces = new ArrayList<>(traces.size());\n-    int sizeInBytes = 0;\n-    for (final List<DDSpan> trace : traces) {\n-      try {\n-        final ByteBuffer serializedTrace = serializeTrace(trace);\n-        sizeInBytes += serializedTrace.limit();\n-        serializedTraces.add(serializedTrace);\n-      } catch (final IOException e) {\n-        log.warn(\"Error serializing trace\", e);\n-\n-        // TODO: DQH - Incorporate the failed serialization into the Response object???\n-      }\n-    }\n-\n-    return sendSerializedTraces(serializedTraces.size(), sizeInBytes, serializedTraces);\n-  }\n-\n-  ByteBuffer serializeTrace(final List<DDSpan> trace) throws IOException {\n-    // TODO: reuse byte array buffer\n-    final ArrayBufferOutput output = new ArrayBufferOutput();\n-    final MessagePacker packer = MESSAGE_PACKER_CONFIG.newPacker(output);\n-    MSGPACK_WRITER.writeTrace(trace, packer);\n-    packer.flush();\n-    int limit = (int) packer.getTotalWrittenBytes();\n-    return output.toMessageBuffer().sliceAsByteBuffer(0, limit);\n-  }\n-\n   Response sendSerializedTraces(\n-      final int representativeCount, final Integer sizeInBytes, final List<ByteBuffer> traces) {\n+      final int representativeCount,\n+      final int traceCount,\n+      final int sizeInBytes,\n+      final List<TraceBuffer> traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n-      final RequestBody body =\n-          new RequestBody() {\n-            @Override\n-            public MediaType contentType() {\n-              return MSGPACK;\n-            }\n-\n-            @Override\n-            public long contentLength() {\n-              final int traceCount = traces.size();\n-              // Need to allocate additional to handle MessagePacker.packArrayHeader\n-              if (traceCount < (1 << 4)) {\n-                return sizeInBytes + 1; // byte\n-              } else if (traceCount < (1 << 16)) {\n-                return sizeInBytes + 3; // byte + short\n-              } else {\n-                return sizeInBytes + 5; // byte + int\n-              }\n-            }\n-\n-            @Override\n-            public void writeTo(final BufferedSink sink) throws IOException {\n-              if (traces.size() < 16) {\n-                sink.writeByte((byte) (traces.size() | FIXARRAY_PREFIX));\n-              } else if (traces.size() < 0x10000) {\n-                sink.writeByte(ARRAY16);\n-                sink.writeShort(traces.size());\n-              } else {\n-                sink.writeByte(ARRAY32);\n-                sink.writeInt(traces.size());\n-              }\n-              for (ByteBuffer trace : traces) {\n-                sink.write(trace);\n-              }\n-            }\n-          };\n       final Request request =\n           prepareRequest(tracesUrl)\n               .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(body)\n+              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n               .build();\n \n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4OTc5MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r421589790", "bodyText": "This is where the primary benefit is, right?  Perhaps you could update the PR description to describe how this change achieves its' benefits.", "author": "tylerbenson", "createdAt": "2020-05-07T15:22:12Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -141,14 +145,18 @@ public long contentLength() {\n \n             @Override\n             public void writeTo(final BufferedSink sink) throws IOException {\n-              final OutputStream out = sink.outputStream();\n-              final MessagePacker packer = MessagePack.newDefaultPacker(out);\n-              packer.packArrayHeader(traces.size());\n-              for (final byte[] trace : traces) {\n-                packer.writePayload(trace);\n+              if (traces.size() < 16) {\n+                sink.writeByte((byte) (traces.size() | FIXARRAY_PREFIX));\n+              } else if (traces.size() < 0x10000) {\n+                sink.writeByte(ARRAY16);\n+                sink.writeShort(traces.size());\n+              } else {\n+                sink.writeByte(ARRAY32);\n+                sink.writeInt(traces.size());\n+              }\n+              for (ByteBuffer trace : traces) {\n+                sink.write(trace);", "originalCommit": "844be383d19af7fd6314b811cfe14e77c86a35ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg4ODI3Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r422888276", "bodyText": "There may be some benefit here, especially once the buffers get large, but the motivation is that slicing as a ByteBuffer might not reallocate/copy the buffer. In any case, I have moved this on from here, to adaptively size the buffers to avoid needing to copy.", "author": "richardstartin", "createdAt": "2020-05-11T08:56:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4OTc5MA=="}], "type": "inlineReview", "revised_code": {"commit": "de740e62f3eabad366003518e2882e9dca641773", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\nindex 836b082db9..10c64616e7 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n\n@@ -81,88 +75,20 @@ public class DDAgentApi {\n     }\n   }\n \n-  /**\n-   * Send traces to the DD agent\n-   *\n-   * @param traces the traces to be sent\n-   * @return a Response object -- encapsulating success of communication, sending, and result\n-   *     parsing\n-   */\n-  Response sendTraces(final List<List<DDSpan>> traces) {\n-    final List<ByteBuffer> serializedTraces = new ArrayList<>(traces.size());\n-    int sizeInBytes = 0;\n-    for (final List<DDSpan> trace : traces) {\n-      try {\n-        final ByteBuffer serializedTrace = serializeTrace(trace);\n-        sizeInBytes += serializedTrace.limit();\n-        serializedTraces.add(serializedTrace);\n-      } catch (final IOException e) {\n-        log.warn(\"Error serializing trace\", e);\n-\n-        // TODO: DQH - Incorporate the failed serialization into the Response object???\n-      }\n-    }\n-\n-    return sendSerializedTraces(serializedTraces.size(), sizeInBytes, serializedTraces);\n-  }\n-\n-  ByteBuffer serializeTrace(final List<DDSpan> trace) throws IOException {\n-    // TODO: reuse byte array buffer\n-    final ArrayBufferOutput output = new ArrayBufferOutput();\n-    final MessagePacker packer = MessagePack.newDefaultPacker(output);\n-    MSGPACK_WRITER.writeTrace(trace, packer);\n-    packer.flush();\n-    int limit = (int) packer.getTotalWrittenBytes();\n-    return output.toMessageBuffer().sliceAsByteBuffer(0, limit);\n-  }\n-\n   Response sendSerializedTraces(\n-      final int representativeCount, final Integer sizeInBytes, final List<ByteBuffer> traces) {\n+      final int representativeCount,\n+      final int traceCount,\n+      final int sizeInBytes,\n+      final List<TraceBuffer> traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n-      final RequestBody body =\n-          new RequestBody() {\n-            @Override\n-            public MediaType contentType() {\n-              return MSGPACK;\n-            }\n-\n-            @Override\n-            public long contentLength() {\n-              final int traceCount = traces.size();\n-              // Need to allocate additional to handle MessagePacker.packArrayHeader\n-              if (traceCount < (1 << 4)) {\n-                return sizeInBytes + 1; // byte\n-              } else if (traceCount < (1 << 16)) {\n-                return sizeInBytes + 3; // byte + short\n-              } else {\n-                return sizeInBytes + 5; // byte + int\n-              }\n-            }\n-\n-            @Override\n-            public void writeTo(final BufferedSink sink) throws IOException {\n-              if (traces.size() < 16) {\n-                sink.writeByte((byte) (traces.size() | FIXARRAY_PREFIX));\n-              } else if (traces.size() < 0x10000) {\n-                sink.writeByte(ARRAY16);\n-                sink.writeShort(traces.size());\n-              } else {\n-                sink.writeByte(ARRAY32);\n-                sink.writeInt(traces.size());\n-              }\n-              for (ByteBuffer trace : traces) {\n-                sink.write(trace);\n-              }\n-            }\n-          };\n       final Request request =\n           prepareRequest(tracesUrl)\n               .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(body)\n+              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n               .build();\n \n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MTE0MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r421591141", "bodyText": "Perhaps a comment here that you are inlining the MessagePacker.packArrayHeader behavior?", "author": "tylerbenson", "createdAt": "2020-05-07T15:24:05Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -141,14 +145,18 @@ public long contentLength() {\n \n             @Override\n             public void writeTo(final BufferedSink sink) throws IOException {\n-              final OutputStream out = sink.outputStream();\n-              final MessagePacker packer = MessagePack.newDefaultPacker(out);\n-              packer.packArrayHeader(traces.size());\n-              for (final byte[] trace : traces) {\n-                packer.writePayload(trace);\n+              if (traces.size() < 16) {\n+                sink.writeByte((byte) (traces.size() | FIXARRAY_PREFIX));\n+              } else if (traces.size() < 0x10000) {\n+                sink.writeByte(ARRAY16);\n+                sink.writeShort(traces.size());\n+              } else {\n+                sink.writeByte(ARRAY32);\n+                sink.writeInt(traces.size());\n+              }", "originalCommit": "844be383d19af7fd6314b811cfe14e77c86a35ec", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "de740e62f3eabad366003518e2882e9dca641773", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\nindex 836b082db9..10c64616e7 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java\n\n@@ -81,88 +75,20 @@ public class DDAgentApi {\n     }\n   }\n \n-  /**\n-   * Send traces to the DD agent\n-   *\n-   * @param traces the traces to be sent\n-   * @return a Response object -- encapsulating success of communication, sending, and result\n-   *     parsing\n-   */\n-  Response sendTraces(final List<List<DDSpan>> traces) {\n-    final List<ByteBuffer> serializedTraces = new ArrayList<>(traces.size());\n-    int sizeInBytes = 0;\n-    for (final List<DDSpan> trace : traces) {\n-      try {\n-        final ByteBuffer serializedTrace = serializeTrace(trace);\n-        sizeInBytes += serializedTrace.limit();\n-        serializedTraces.add(serializedTrace);\n-      } catch (final IOException e) {\n-        log.warn(\"Error serializing trace\", e);\n-\n-        // TODO: DQH - Incorporate the failed serialization into the Response object???\n-      }\n-    }\n-\n-    return sendSerializedTraces(serializedTraces.size(), sizeInBytes, serializedTraces);\n-  }\n-\n-  ByteBuffer serializeTrace(final List<DDSpan> trace) throws IOException {\n-    // TODO: reuse byte array buffer\n-    final ArrayBufferOutput output = new ArrayBufferOutput();\n-    final MessagePacker packer = MessagePack.newDefaultPacker(output);\n-    MSGPACK_WRITER.writeTrace(trace, packer);\n-    packer.flush();\n-    int limit = (int) packer.getTotalWrittenBytes();\n-    return output.toMessageBuffer().sliceAsByteBuffer(0, limit);\n-  }\n-\n   Response sendSerializedTraces(\n-      final int representativeCount, final Integer sizeInBytes, final List<ByteBuffer> traces) {\n+      final int representativeCount,\n+      final int traceCount,\n+      final int sizeInBytes,\n+      final List<TraceBuffer> traces) {\n     if (httpClient == null) {\n       detectEndpointAndBuildClient();\n     }\n \n     try {\n-      final RequestBody body =\n-          new RequestBody() {\n-            @Override\n-            public MediaType contentType() {\n-              return MSGPACK;\n-            }\n-\n-            @Override\n-            public long contentLength() {\n-              final int traceCount = traces.size();\n-              // Need to allocate additional to handle MessagePacker.packArrayHeader\n-              if (traceCount < (1 << 4)) {\n-                return sizeInBytes + 1; // byte\n-              } else if (traceCount < (1 << 16)) {\n-                return sizeInBytes + 3; // byte + short\n-              } else {\n-                return sizeInBytes + 5; // byte + int\n-              }\n-            }\n-\n-            @Override\n-            public void writeTo(final BufferedSink sink) throws IOException {\n-              if (traces.size() < 16) {\n-                sink.writeByte((byte) (traces.size() | FIXARRAY_PREFIX));\n-              } else if (traces.size() < 0x10000) {\n-                sink.writeByte(ARRAY16);\n-                sink.writeShort(traces.size());\n-              } else {\n-                sink.writeByte(ARRAY32);\n-                sink.writeInt(traces.size());\n-              }\n-              for (ByteBuffer trace : traces) {\n-                sink.write(trace);\n-              }\n-            }\n-          };\n       final Request request =\n           prepareRequest(tracesUrl)\n               .addHeader(X_DATADOG_TRACE_COUNT, String.valueOf(representativeCount))\n-              .put(body)\n+              .put(new MsgPackRequestBody(traceCount, sizeInBytes, traces))\n               .build();\n \n       try (final okhttp3.Response response = httpClient.newCall(request).execute()) {\n"}}, {"oid": "de740e62f3eabad366003518e2882e9dca641773", "url": "https://github.com/DataDog/dd-trace-java/commit/de740e62f3eabad366003518e2882e9dca641773", "message": "allow adapative sizing of message buffers based on moving average, allow buffer to be shared between multiple traces (without enabling batching yet).", "committedDate": "2020-05-11T09:26:12Z", "type": "forcePushed"}, {"oid": "e76e0ed817260e518250bb280157e3d400fa0121", "url": "https://github.com/DataDog/dd-trace-java/commit/e76e0ed817260e518250bb280157e3d400fa0121", "message": "update ddagent api integration test", "committedDate": "2020-05-11T10:00:38Z", "type": "forcePushed"}, {"oid": "310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "url": "https://github.com/DataDog/dd-trace-java/commit/310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "message": "allow adapative sizing of message buffers based on moving average, allow buffer to be shared between multiple traces (without enabling batching yet).", "committedDate": "2020-05-11T10:10:23Z", "type": "commit"}, {"oid": "310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "url": "https://github.com/DataDog/dd-trace-java/commit/310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "message": "allow adapative sizing of message buffers based on moving average, allow buffer to be shared between multiple traces (without enabling batching yet).", "committedDate": "2020-05-11T10:10:23Z", "type": "forcePushed"}, {"oid": "e55175329d6b93fc6cf4b6c91c695ea413c1c394", "url": "https://github.com/DataDog/dd-trace-java/commit/e55175329d6b93fc6cf4b6c91c695ea413c1c394", "message": "don't read tags from the string table because we don't know many of their values, add some documentation about the intent behind TraceBuffer", "committedDate": "2020-05-11T18:13:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE5MjQ5Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r423192492", "bodyText": "Can you add a comment here giving insight on the future direction of this?", "author": "tylerbenson", "createdAt": "2020-05-11T17:13:41Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -83,10 +84,11 @@ private BatchWritingHandler(\n     // TODO: reduce byte[] garbage by keeping the byte[] on the event and copy before returning.\n     @Override\n     public void onEvent(\n-        final DisruptorEvent<byte[]> event, final long sequence, final boolean endOfBatch) {\n+        final DisruptorEvent<TraceBuffer> event, final long sequence, final boolean endOfBatch) {\n       try {\n         if (event.data != null) {\n-          sizeInBytes += event.data.length;\n+          sizeInBytes += event.data.sizeInBytes();\n+          traceCount += event.data.traceCount();\n           serializedTraces.add(event.data);\n         }", "originalCommit": "310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI2MTg3NA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r423261874", "bodyText": "Done.", "author": "richardstartin", "createdAt": "2020-05-11T19:16:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE5MjQ5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "fe75c087f2da4ffb8c5566add53fff393f01673a", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java\nindex 1d945707a2..3af7b44150 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java\n\n@@ -87,6 +87,12 @@ public class BatchWritingDisruptor extends AbstractDisruptor<TraceBuffer> {\n         final DisruptorEvent<TraceBuffer> event, final long sequence, final boolean endOfBatch) {\n       try {\n         if (event.data != null) {\n+          // the intention here is that the batching is done on the serialization thread\n+          // directly into trace buffers pooled by the disruptor. The BatchWritingDisruptor\n+          // will eventually not do any batching, but claim a trace buffer from the disruptor,\n+          // publish it synchronously to the agent, and return it to the disruptor for reuse.\n+          // This is an incremental step towards moving away from the status quo, where we\n+          // could support a hybrid approach rather than refactor in one go.\n           sizeInBytes += event.data.sizeInBytes();\n           traceCount += event.data.traceCount();\n           serializedTraces.add(event.data);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzIwNTgwMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r423205803", "bodyText": "A little insight on future direction would also be nice here.", "author": "tylerbenson", "createdAt": "2020-05-11T17:35:43Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -66,9 +68,11 @@ public void onEvent(\n           // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n           try {\n             event.data = processor.onTraceComplete(event.data);\n-            final byte[] serializedTrace = api.serializeTrace(event.data);\n+            serializer.serialize(event.data);\n+            TraceBuffer serializedTrace = serializer.getBuffer();\n+            int sizeInBytes = serializedTrace.sizeInBytes();", "originalCommit": "310fae50d50422fa7c0df6c8ba65eb6aa3cd5cc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI2MTkyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1437#discussion_r423261927", "bodyText": "Done", "author": "richardstartin", "createdAt": "2020-05-11T19:16:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzIwNTgwMw=="}], "type": "inlineReview", "revised_code": {"commit": "90a3d234ac183541ca8aba62a6f7b83d6f12ceaa", "chunk": "diff --git a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\nindex e140d2f56e..13b1ae36d4 100644\n--- a/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n+++ b/dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java\n\n@@ -68,6 +68,11 @@ public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n           // TODO populate `_sample_rate` metric in a way that accounts for lost/dropped traces\n           try {\n             event.data = processor.onTraceComplete(event.data);\n+            // the intention is that batching ends up being handled here,\n+            // rather than on the BatchWritingDisruptor, which would\n+            // be responsible for sending trace buffers to the agent\n+            // synchronously, before returning the trace buffer for\n+            // reuse.\n             serializer.serialize(event.data);\n             TraceBuffer serializedTrace = serializer.getBuffer();\n             int sizeInBytes = serializedTrace.sizeInBytes();\n"}}, {"oid": "fe75c087f2da4ffb8c5566add53fff393f01673a", "url": "https://github.com/DataDog/dd-trace-java/commit/fe75c087f2da4ffb8c5566add53fff393f01673a", "message": "don't read tags from the string table because we don't know many of their values, add some documentation about the intent behind TraceBuffer", "committedDate": "2020-05-11T18:21:04Z", "type": "forcePushed"}, {"oid": "90a3d234ac183541ca8aba62a6f7b83d6f12ceaa", "url": "https://github.com/DataDog/dd-trace-java/commit/90a3d234ac183541ca8aba62a6f7b83d6f12ceaa", "message": "don't read tags from the string table because we don't know many of their values, add some documentation about the intent behind TraceBuffer", "committedDate": "2020-05-11T18:24:08Z", "type": "commit"}, {"oid": "90a3d234ac183541ca8aba62a6f7b83d6f12ceaa", "url": "https://github.com/DataDog/dd-trace-java/commit/90a3d234ac183541ca8aba62a6f7b83d6f12ceaa", "message": "don't read tags from the string table because we don't know many of their values, add some documentation about the intent behind TraceBuffer", "committedDate": "2020-05-11T18:24:08Z", "type": "forcePushed"}]}