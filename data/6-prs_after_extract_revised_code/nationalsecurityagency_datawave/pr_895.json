{"pr_number": 895, "pr_title": "FacetHandler improvements and additional unit tests", "pr_createdAt": "2020-08-14T17:21:09Z", "pr_url": "https://github.com/NationalSecurityAgency/datawave/pull/895", "timeline": [{"oid": "fc8bda1b133bf5917a19d212979bb4997677a431", "url": "https://github.com/NationalSecurityAgency/datawave/commit/fc8bda1b133bf5917a19d212979bb4997677a431", "message": "Adds CardinalityAggregator to properly merge facet table values (#895)\n\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.", "committedDate": "2020-08-14T17:21:23Z", "type": "forcePushed"}, {"oid": "9741d49bca6b2c98ac441030aed5c23c64552b23", "url": "https://github.com/NationalSecurityAgency/datawave/commit/9741d49bca6b2c98ac441030aed5c23c64552b23", "message": "Adds CardinalityAggregator to properly merge facet table values (#895)\n\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.", "committedDate": "2020-08-17T15:03:17Z", "type": "forcePushed"}, {"oid": "4a30efce41be98e041d6783d825029273f10b41e", "url": "https://github.com/NationalSecurityAgency/datawave/commit/4a30efce41be98e041d6783d825029273f10b41e", "message": "Adds CardinalityAggregator to properly merge facet table values (#895)\n\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.", "committedDate": "2020-08-17T17:37:33Z", "type": "forcePushed"}, {"oid": "6422fa14a21274c480cc33435de86e8741c03df5", "url": "https://github.com/NationalSecurityAgency/datawave/commit/6422fa14a21274c480cc33435de86e8741c03df5", "message": "Adds CardinalityAggregator to properly merge facet table values (#895)\n\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.", "committedDate": "2020-08-18T14:33:13Z", "type": "forcePushed"}, {"oid": "1d22bdea4ef36c38e19783de3d3530bcd1577e44", "url": "https://github.com/NationalSecurityAgency/datawave/commit/1d22bdea4ef36c38e19783de3d3530bcd1577e44", "message": "FacetHandler private constants refactored to protected for subclassing", "committedDate": "2020-08-21T19:20:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MDE3Mw==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480250173", "bodyText": "should this be looking at the Type to decide if this field is tokenized?", "author": "FineAndDandy", "createdAt": "2020-08-31T16:37:44Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java", "diffHunk": "@@ -332,7 +485,6 @@ public FacetValue estimate(RawRecordContainer input) {\n     }\n     \n     /** A predicate used to ignore values that are generated via tokenization */\n-    // TODO: make configurable\n     public static class TokenPredicate implements Predicate<String> {\n         @Override\n         public boolean test(String input) {", "originalCommit": "52aea70e4e722b603b4b6c348f6e646adc926389", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExNDU0OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r485114548", "bodyText": "Yes. Not quite ready to tackle this here, yet. This bit is largely unchanged from the inherited codebase.", "author": "drewfarris", "createdAt": "2020-09-08T18:26:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MDE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4NTA0OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r491085049", "bodyText": "Going to punt on this until the next round of work here.", "author": "drewfarris", "createdAt": "2020-09-18T17:14:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MDE3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "33ce289b94f8b69014a4be701c55eb7920873de9", "chunk": "diff --git a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\nindex c6966e78c..57c47bfef 100644\n--- a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n+++ b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n\n@@ -478,8 +483,9 @@ public class FacetHandler<KEYIN,KEYOUT,VALUEOUT> implements ExtendedDataTypeHand\n     @Override\n     public FacetValue estimate(RawRecordContainer input) {\n         // precision value: 10, sparse set disabled.\n-        HyperLogLogPlus card = new HyperLogLogPlus(10);\n-        card.offer(input.getId().toString());\n+        final HyperLogLogPlus card = new HyperLogLogPlus(10);\n+        final String id = shardIdFactory.getShardId(input) + \"/\" + input.getDataType() + \"/\" + input.getId().toString();\n+        card.offer(id);\n         \n         return new FacetValue(card, new CountMinSketch(10, 1, 1));\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MjkwMA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480252900", "bodyText": "should we filter before doing any of the work?", "author": "FineAndDandy", "createdAt": "2020-08-31T16:42:50Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java", "diffHunk": "@@ -221,72 +200,149 @@ public long process(KEYIN key, RawRecordContainer event, Multimap<String,Normali\n         final String shardDate = ShardIdFactory.getDateString(shardId);\n         Text dateColumnQualifier = new Text(shardDate);\n         \n-        HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n-        cardinality.offer(event.getId().toString());\n-        \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n-        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(contextWriter, context, facetHashTableName, facetHashThreshold,\n-                        event.getDate());\n-        Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // fields with a large number of values are hashed. See HashTableFunction for details\n+        // @formatter:off\n+        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n+                contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n+        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // @formatter:on\n         \n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(new TokenPredicate());\n-        if (fieldFilter != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilter);\n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);", "originalCommit": "52aea70e4e722b603b4b6c348f6e646adc926389", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExNTI5Mg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r485115292", "bodyText": "Yes, I should move the filtering bit to show up prior to the HashTablefunction bit, specifically the call to hashEventFields.", "author": "drewfarris", "createdAt": "2020-09-08T18:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MjkwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4NDc2Mg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r491084762", "bodyText": "This has been addressed in the latest version", "author": "drewfarris", "createdAt": "2020-09-18T17:14:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI1MjkwMA=="}], "type": "inlineReview", "revised_code": {"commit": "33ce289b94f8b69014a4be701c55eb7920873de9", "chunk": "diff --git a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\nindex c6966e78c..57c47bfef 100644\n--- a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n+++ b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n\n@@ -202,22 +202,22 @@ public class FacetHandler<KEYIN,KEYOUT,VALUEOUT> implements ExtendedDataTypeHand\n         \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> fieldKeyStream = fields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            fieldKeyStream = fieldKeyStream.filter(fieldFilterPredicate);\n+        }\n+        final Set<String> filteredFieldSet = fieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(filteredFieldSet);\n+        Set<String> facetFieldSet = new HashSet<>(filteredFieldSet);\n+        \n         // fields with a large number of values are hashed. See HashTableFunction for details\n         // @formatter:off\n         final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n                 contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n-        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        final Multimap<String,NormalizedContentInterface> eventFields = filterAndHashEventFields(fields, filteredFieldSet, func);\n         // @formatter:on\n         \n-        // filter out event fields that are generated as the result of tokenization.\n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);\n-        if (fieldFilterPredicate != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilterPredicate);\n-        }\n-        final Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        Set<String> pivotFieldSet = new HashSet<>(keySet);\n-        Set<String> facetFieldSet = new HashSet<>(keySet);\n-        \n         long countWritten = 0;\n         \n         // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2NjA2Mg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480266062", "bodyText": "Is creating this right? Down below we create the pivotType/facetType. Why create pivotType/pivotType here?", "author": "FineAndDandy", "createdAt": "2020-08-31T17:05:27Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java", "diffHunk": "@@ -221,72 +200,149 @@ public long process(KEYIN key, RawRecordContainer event, Multimap<String,Normali\n         final String shardDate = ShardIdFactory.getDateString(shardId);\n         Text dateColumnQualifier = new Text(shardDate);\n         \n-        HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n-        cardinality.offer(event.getId().toString());\n-        \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n-        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(contextWriter, context, facetHashTableName, facetHashThreshold,\n-                        event.getDate());\n-        Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // fields with a large number of values are hashed. See HashTableFunction for details\n+        // @formatter:off\n+        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n+                contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n+        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // @formatter:on\n         \n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(new TokenPredicate());\n-        if (fieldFilter != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilter);\n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilterPredicate);\n         }\n-        Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        List<Set<String>> keySetList = Lists.newArrayList();\n-        keySetList.add(keySet);\n-        keySetList.add(keySet);\n+        final Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(keySet);\n+        Set<String> facetFieldSet = new HashSet<>(keySet);\n         \n         long countWritten = 0;\n         \n-        Value sharedValue = new Value(cardinality.getBytes());\n-        Multimap<BulkIngestKey,Value> results = ArrayListMultimap.create();\n+        // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n+        // so it's helpful to have that around for debugging when logging about the\n+        // facet keys that are created.\n+        String eventId = null;\n+        if (log.isDebugEnabled()) {\n+            StringBuilder b = new StringBuilder();\n+            for (NormalizedContentInterface f : eventFields.get(\"EVENT_ID\")) {\n+                b.append(f.getEventFieldValue());\n+            }\n+            eventId = b.toString();\n+        }\n+        \n+        // compute the cardinality based on the uid, this becomes the value shared\n+        // across each facet row generated.\n+        final HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n+        cardinality.offer(event.getId().toString());\n+        final Value sharedValue = new Value(cardinality.getBytes());\n+        \n+        final Multimap<BulkIngestKey,Value> results = ArrayListMultimap.create();\n         \n         for (String pivotFieldName : pivotMap.keySet()) {\n-            Text reflexiveCf = createColumnFamily(pivotFieldName, pivotFieldName);\n+            if (!pivotFieldSet.contains(pivotFieldName))\n+                continue;\n+            \n+            final Text reflexiveCf = createColumnFamily(pivotFieldName, pivotFieldName);\n+            \n             for (NormalizedContentInterface pivotTypes : eventFields.get(pivotFieldName)) {\n                 if (HashTableFunction.isReduced(pivotTypes))\n                     continue;\n                 \n+                // Generate the pivot entry.\n+                // @formatter:off\n+                final BulkIngestKey pivotIngestKey = generateFacetIngestKey(\n+                        pivotTypes.getIndexedFieldValue(),\n+                        pivotTypes.getIndexedFieldValue(),\n+                        event.getDataType(),\n+                        reflexiveCf,\n+                        dateColumnQualifier,\n+                        cv,\n+                        event.getDate());", "originalCommit": "52aea70e4e722b603b4b6c348f6e646adc926389", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTE2NjE4MA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r481166180", "bodyText": "I am guessing for cardinality computation?", "author": "ivakegg", "createdAt": "2020-09-01T14:09:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2NjA2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExNTg1MQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r485115851", "bodyText": "yes, this is for the cardinality calculation for the pivot field itself. We retain document counts for the pivot in addition to each of the facets related to that pivot.", "author": "drewfarris", "createdAt": "2020-09-08T18:28:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2NjA2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "33ce289b94f8b69014a4be701c55eb7920873de9", "chunk": "diff --git a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\nindex c6966e78c..57c47bfef 100644\n--- a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n+++ b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n\n@@ -202,22 +202,22 @@ public class FacetHandler<KEYIN,KEYOUT,VALUEOUT> implements ExtendedDataTypeHand\n         \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> fieldKeyStream = fields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            fieldKeyStream = fieldKeyStream.filter(fieldFilterPredicate);\n+        }\n+        final Set<String> filteredFieldSet = fieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(filteredFieldSet);\n+        Set<String> facetFieldSet = new HashSet<>(filteredFieldSet);\n+        \n         // fields with a large number of values are hashed. See HashTableFunction for details\n         // @formatter:off\n         final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n                 contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n-        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        final Multimap<String,NormalizedContentInterface> eventFields = filterAndHashEventFields(fields, filteredFieldSet, func);\n         // @formatter:on\n         \n-        // filter out event fields that are generated as the result of tokenization.\n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);\n-        if (fieldFilterPredicate != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilterPredicate);\n-        }\n-        final Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        Set<String> pivotFieldSet = new HashSet<>(keySet);\n-        Set<String> facetFieldSet = new HashSet<>(keySet);\n-        \n         long countWritten = 0;\n         \n         // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2ODA4OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480268089", "bodyText": "what happens if we see this event id multiple times?", "author": "FineAndDandy", "createdAt": "2020-08-31T17:09:21Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java", "diffHunk": "@@ -221,72 +200,149 @@ public long process(KEYIN key, RawRecordContainer event, Multimap<String,Normali\n         final String shardDate = ShardIdFactory.getDateString(shardId);\n         Text dateColumnQualifier = new Text(shardDate);\n         \n-        HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n-        cardinality.offer(event.getId().toString());\n-        \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n-        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(contextWriter, context, facetHashTableName, facetHashThreshold,\n-                        event.getDate());\n-        Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // fields with a large number of values are hashed. See HashTableFunction for details\n+        // @formatter:off\n+        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n+                contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n+        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        // @formatter:on\n         \n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(new TokenPredicate());\n-        if (fieldFilter != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilter);\n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilterPredicate);\n         }\n-        Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        List<Set<String>> keySetList = Lists.newArrayList();\n-        keySetList.add(keySet);\n-        keySetList.add(keySet);\n+        final Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(keySet);\n+        Set<String> facetFieldSet = new HashSet<>(keySet);\n         \n         long countWritten = 0;\n         \n-        Value sharedValue = new Value(cardinality.getBytes());\n-        Multimap<BulkIngestKey,Value> results = ArrayListMultimap.create();\n+        // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n+        // so it's helpful to have that around for debugging when logging about the\n+        // facet keys that are created.\n+        String eventId = null;\n+        if (log.isDebugEnabled()) {\n+            StringBuilder b = new StringBuilder();\n+            for (NormalizedContentInterface f : eventFields.get(\"EVENT_ID\")) {\n+                b.append(f.getEventFieldValue());\n+            }\n+            eventId = b.toString();\n+        }\n+        \n+        // compute the cardinality based on the uid, this becomes the value shared\n+        // across each facet row generated.\n+        final HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n+        cardinality.offer(event.getId().toString());", "originalCommit": "52aea70e4e722b603b4b6c348f6e646adc926389", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDMxODc2NQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480318765", "bodyText": "specifically does this throw off counts later if we see the same event_id multiple times?", "author": "FineAndDandy", "createdAt": "2020-08-31T18:44:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2ODA4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTE2NTM3OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r481165379", "bodyText": "We guarentee (with high probability) that a document has a unique record id which is a combination of the shardid, datatype, and uid.  I think we need to add shardid and datatype to this offer.", "author": "ivakegg", "createdAt": "2020-09-01T14:08:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2ODA4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEyMDMzOA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r485120338", "bodyText": "If we see the same event id multiple times, it does not increase the count (cardinality) for that facet. You can see a good example of that in ApproximateAlgorithmsTest for example.\nGood catch @ivakegg - I will look more closely at what event.getId().toString() is returning to ensure it is sufficiently unique. As you point out, I suspect it isn't.", "author": "drewfarris", "createdAt": "2020-09-08T18:37:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2ODA4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4NDU1MQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r491084551", "bodyText": "Ivan's comment has been addressed in the latest version (and yes, he identified a bug - hence the unit test updates)", "author": "drewfarris", "createdAt": "2020-09-18T17:13:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI2ODA4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "33ce289b94f8b69014a4be701c55eb7920873de9", "chunk": "diff --git a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\nindex c6966e78c..57c47bfef 100644\n--- a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n+++ b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n\n@@ -202,22 +202,22 @@ public class FacetHandler<KEYIN,KEYOUT,VALUEOUT> implements ExtendedDataTypeHand\n         \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> fieldKeyStream = fields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            fieldKeyStream = fieldKeyStream.filter(fieldFilterPredicate);\n+        }\n+        final Set<String> filteredFieldSet = fieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(filteredFieldSet);\n+        Set<String> facetFieldSet = new HashSet<>(filteredFieldSet);\n+        \n         // fields with a large number of values are hashed. See HashTableFunction for details\n         // @formatter:off\n         final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n                 contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n-        final Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n+        final Multimap<String,NormalizedContentInterface> eventFields = filterAndHashEventFields(fields, filteredFieldSet, func);\n         // @formatter:on\n         \n-        // filter out event fields that are generated as the result of tokenization.\n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(fieldSelectionPredicate);\n-        if (fieldFilterPredicate != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilterPredicate);\n-        }\n-        final Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        Set<String> pivotFieldSet = new HashSet<>(keySet);\n-        Set<String> facetFieldSet = new HashSet<>(keySet);\n-        \n         long countWritten = 0;\n         \n         // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDMxNzAyOA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r480317028", "bodyText": "implement TODOs?", "author": "FineAndDandy", "createdAt": "2020-08-31T18:41:28Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/table/config/FacetTableConfigHelper.java", "diffHunk": "@@ -73,7 +75,13 @@ public void configure(TableOperations tops) throws AccumuloException, AccumuloSe\n     }\n     \n     protected void configureFacetTable(TableOperations tops) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {\n-        // TODO:\n+        // Add the facet cardinality aggregator\n+        for (IteratorUtil.IteratorScope scope : IteratorUtil.IteratorScope.values()) {\n+            String stem = String.format(\"%s%s.%s\", Property.TABLE_ITERATOR_PREFIX, scope.name(), \"UIDAggregator\");\n+            setPropertyIfNecessary(tableName, stem, \"19,datawave.iterators.TotalAggregatingIterator\", tops, log);\n+            stem += \".opt.\";\n+            setPropertyIfNecessary(tableName, stem + \"*\", \"datawave.ingest.table.aggregator.CardinalityAggregator\", tops, log);\n+        }\n     }\n     \n     protected void configureFacetMetadataTable(TableOperations tops) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {", "originalCommit": "52aea70e4e722b603b4b6c348f6e646adc926389", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "906ad5f6f3cb2958c47a2c80f638c0d01e86ec36", "url": "https://github.com/NationalSecurityAgency/datawave/commit/906ad5f6f3cb2958c47a2c80f638c0d01e86ec36", "message": "FacetHandler and FacetHandlerTest improvements (#895)\n\n* Adds `CardinalityAggregator` to properly merge facet table values on ingest.\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.\n* `FacetHandler` private constants refactored to protected for subclassing.\n* Fixed predicate-based field filtering (to defeat facet generation for a configured set of field names).\n* Added configurable predicate for use in subclasses to override TokenPredicate.\n* Fixed multi-document unit test to check for missed keys.\n* Cleaned up warnings.\n* Added test for configurable predicates, this identified an\n  issue related to metadata generation which was fixed.\n* Fixed incomplete facet hashing and implemented unit test for validation.", "committedDate": "2020-09-08T18:42:26Z", "type": "forcePushed"}, {"oid": "b5579cab9bea5c358a929e41973a23a1da9a9212", "url": "https://github.com/NationalSecurityAgency/datawave/commit/b5579cab9bea5c358a929e41973a23a1da9a9212", "message": "FacetHandler and FacetHandlerTest improvements (#895)\n\n* Adds `CardinalityAggregator` to properly merge facet table values on ingest.\n* `CardinalityAggregator` is a `PropogatingCombiner` that is configured\n  for the facet table via the `FacetTableConfigHelper`.\n* Included unit test for `CardinalityAggregator`.\n* Updated `FacetedQueryLogicTest` to properly exercise and validate\n  cardinality aggregation. Also updated this test to perform fine\n  grained results evaluation.\n* `FacetHandler` private constants refactored to protected for subclassing.\n* Fixed predicate-based field filtering (to defeat facet generation for a configured set of field names).\n* Added configurable predicate for use in subclasses to override TokenPredicate.\n* Fixed multi-document unit test to check for missed keys.\n* Cleaned up warnings.\n* Added test for configurable predicates, this identified an\n  issue related to metadata generation which was fixed.\n* Fixed incomplete facet hashing and implemented unit test for validation.", "committedDate": "2020-09-16T14:04:10Z", "type": "commit"}, {"oid": "33ce289b94f8b69014a4be701c55eb7920873de9", "url": "https://github.com/NationalSecurityAgency/datawave/commit/33ce289b94f8b69014a4be701c55eb7920873de9", "message": "FacetHandler improvements based on code review (#895)", "committedDate": "2020-09-16T14:04:10Z", "type": "commit"}, {"oid": "48d23dd247c16d86ba0d6bd68b952269a750eda4", "url": "https://github.com/NationalSecurityAgency/datawave/commit/48d23dd247c16d86ba0d6bd68b952269a750eda4", "message": "Updated unit test expectations for FacetedQueryLogicTest (#895)\n\n* Differentiated event ids by datatype, hence higher cardinality.", "committedDate": "2020-09-16T14:04:10Z", "type": "commit"}, {"oid": "48d23dd247c16d86ba0d6bd68b952269a750eda4", "url": "https://github.com/NationalSecurityAgency/datawave/commit/48d23dd247c16d86ba0d6bd68b952269a750eda4", "message": "Updated unit test expectations for FacetedQueryLogicTest (#895)\n\n* Differentiated event ids by datatype, hence higher cardinality.", "committedDate": "2020-09-16T14:04:10Z", "type": "forcePushed"}, {"oid": "21fa4d6be21727dc672b3756bd23005455e1080a", "url": "https://github.com/NationalSecurityAgency/datawave/commit/21fa4d6be21727dc672b3756bd23005455e1080a", "message": "Merge branch 'master' into facet-cardinality-aggregator", "committedDate": "2020-09-16T20:01:54Z", "type": "commit"}, {"oid": "f321d151dba197af7ae54a2d6b33e363f396a4e2", "url": "https://github.com/NationalSecurityAgency/datawave/commit/f321d151dba197af7ae54a2d6b33e363f396a4e2", "message": "Merge branch 'master' into facet-cardinality-aggregator", "committedDate": "2020-09-18T17:22:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4ODM0OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r491088349", "bodyText": "do we still need this? should the use of id below (shard/datatype/uid) replace this?", "author": "FineAndDandy", "createdAt": "2020-09-18T17:21:45Z", "path": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java", "diffHunk": "@@ -221,118 +200,297 @@ public long process(KEYIN key, RawRecordContainer event, Multimap<String,Normali\n         final String shardDate = ShardIdFactory.getDateString(shardId);\n         Text dateColumnQualifier = new Text(shardDate);\n         \n-        HyperLogLogPlus cardinality = new HyperLogLogPlus(10);\n-        cardinality.offer(event.getId().toString());\n-        \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n-        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(contextWriter, context, facetHashTableName, facetHashThreshold,\n-                        event.getDate());\n-        Multimap<String,NormalizedContentInterface> eventFields = hashEventFields(fields, func);\n-        \n-        Stream<String> eventFieldKeyStream = eventFields.keySet().stream().filter(new TokenPredicate());\n-        if (fieldFilter != null) {\n-            eventFieldKeyStream = eventFieldKeyStream.filter(fieldFilter);\n+        // filter out event fields that are generated as the result of tokenization.\n+        Stream<String> fieldKeyStream = fields.keySet().stream().filter(fieldSelectionPredicate);\n+        if (fieldFilterPredicate != null) {\n+            fieldKeyStream = fieldKeyStream.filter(fieldFilterPredicate);\n         }\n-        Set<String> keySet = eventFieldKeyStream.collect(Collectors.toSet());\n-        List<Set<String>> keySetList = Lists.newArrayList();\n-        keySetList.add(keySet);\n-        keySetList.add(keySet);\n+        final Set<String> filteredFieldSet = fieldKeyStream.collect(Collectors.toSet());\n+        Set<String> pivotFieldSet = new HashSet<>(filteredFieldSet);\n+        Set<String> facetFieldSet = new HashSet<>(filteredFieldSet);\n+        \n+        // fields with a large number of values are hashed. See HashTableFunction for details\n+        // @formatter:off\n+        final HashTableFunction<KEYIN,KEYOUT,VALUEOUT> func = new HashTableFunction<>(\n+                contextWriter, context, facetHashTableName, facetHashThreshold, event.getDate());\n+        final Multimap<String,NormalizedContentInterface> eventFields = filterAndHashEventFields(fields, filteredFieldSet, func);\n+        // @formatter:on\n         \n         long countWritten = 0;\n         \n-        Value sharedValue = new Value(cardinality.getBytes());\n-        Multimap<BulkIngestKey,Value> results = ArrayListMultimap.create();\n+        // the event id offered to the cardinality is a uid based on the 'EVENT_ID',\n+        // so it's helpful to have that around for debugging when logging about the\n+        // facet keys that are created.\n+        String eventId = null;", "originalCommit": "21fa4d6be21727dc672b3756bd23005455e1080a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNTM5OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r495015398", "bodyText": "It appears that eventId is needed to find the document if we failed to ingest.  May still be needed, but perhaps as trace and not debug?", "author": "ivakegg", "createdAt": "2020-09-25T14:11:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4ODM0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxODgzNA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/895#discussion_r495018834", "bodyText": "In this particular case, I needed the identifier that was on the original piece of content that was ingested in order to troubleshoot the problem, not the uid that was being generated because I could not tie that back to the original piece of data e.g via the shard table.", "author": "drewfarris", "createdAt": "2020-09-25T14:16:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA4ODM0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "728c7979d35b9515efb5f128b73a4aba9b6a229d", "chunk": "diff --git a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\nindex 57c47bfef..84fea095a 100644\n--- a/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n+++ b/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/handler/facet/FacetHandler.java\n\n@@ -197,8 +200,10 @@ public class FacetHandler<KEYIN,KEYOUT,VALUEOUT> implements ExtendedDataTypeHand\n                     throws IOException, InterruptedException {\n         \n         final String shardId = shardIdFactory.getShardId(event);\n-        final String shardDate = ShardIdFactory.getDateString(shardId);\n-        Text dateColumnQualifier = new Text(shardDate);\n+        final String shardDateString = ShardIdFactory.getDateString(shardId);\n+        final Text dateColumnQualifier = new Text(shardDateString);\n+        final Date shardDate = DateHelper.parse(shardDateString);\n+        final long timestamp = shardDate.getTime();\n         \n         Text cv = new Text(flatten(event.getVisibility()));\n         \n"}}, {"oid": "52fcc7c6470e3a5365b15b50187528f890f373f8", "url": "https://github.com/NationalSecurityAgency/datawave/commit/52fcc7c6470e3a5365b15b50187528f890f373f8", "message": "Merge branch 'master' into facet-cardinality-aggregator", "committedDate": "2020-09-22T19:48:23Z", "type": "commit"}, {"oid": "728c7979d35b9515efb5f128b73a4aba9b6a229d", "url": "https://github.com/NationalSecurityAgency/datawave/commit/728c7979d35b9515efb5f128b73a4aba9b6a229d", "message": "FacetHandler now uses shard date for all Key timestamps  (#895)", "committedDate": "2020-09-25T15:16:16Z", "type": "forcePushed"}, {"oid": "0d9ce6cb8e5782cfe5855e3469b9e3794111f897", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0d9ce6cb8e5782cfe5855e3469b9e3794111f897", "message": "FacetHandler now uses shard date for all Key timestamps  (#895)", "committedDate": "2020-09-28T15:05:29Z", "type": "commit"}, {"oid": "0d9ce6cb8e5782cfe5855e3469b9e3794111f897", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0d9ce6cb8e5782cfe5855e3469b9e3794111f897", "message": "FacetHandler now uses shard date for all Key timestamps  (#895)", "committedDate": "2020-09-28T15:05:29Z", "type": "forcePushed"}, {"oid": "6464b009be3ec7f47faa9a9e820f2f533071b224", "url": "https://github.com/NationalSecurityAgency/datawave/commit/6464b009be3ec7f47faa9a9e820f2f533071b224", "message": "Merge branch 'master' into facet-cardinality-aggregator", "committedDate": "2020-09-28T15:43:11Z", "type": "commit"}]}