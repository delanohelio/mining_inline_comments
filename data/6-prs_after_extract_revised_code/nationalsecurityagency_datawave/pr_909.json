{"pr_number": 909, "pr_title": "fixes #858 repost", "pr_createdAt": "2020-08-31T12:19:51Z", "pr_url": "https://github.com/NationalSecurityAgency/datawave/pull/909", "timeline": [{"oid": "84ddeefe1e3915fd252efadfa66dd146227288dc", "url": "https://github.com/NationalSecurityAgency/datawave/commit/84ddeefe1e3915fd252efadfa66dd146227288dc", "message": "fixes #858 Add EventFieldIterator to merge values with tf iterator for document ranges", "committedDate": "2020-08-24T19:34:06Z", "type": "commit"}, {"oid": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "message": "fixes #858 Add normalize support for EventFieldIterator", "committedDate": "2020-08-27T13:13:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDA0NQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480240045", "bodyText": "How do we know everything in the document was pulled as a result of this aggregator?", "author": "ivakegg", "createdAt": "2020-08-31T16:20:03Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,67 @@\n+package datawave.query.jexl.functions;\n+\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+    }\n+    \n+    @Override\n+    protected Tuple2<String,String> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        return new Tuple2<>(field, value);\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);\n+        final int startFv = nulls.get(0) + 1;\n+        final int stopFn = nulls.get(0);\n+        \n+        byte[] fnFv = new byte[cq.length()];\n+        System.arraycopy(cq.getBackingArray(), 0, fnFv, 0, stopFn);\n+        System.arraycopy(cq.getBackingArray(), startFv, fnFv, stopFn + 1, cq.length() - startFv);\n+        \n+        return new ArrayByteSequence(fnFv);\n+    }\n+    \n+    @Override\n+    protected ByteSequence getPointerData(Key key) {\n+        return key.getColumnFamilyData();\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        return columnFamily;\n+    }\n+    \n+    @Override\n+    public Key apply(SortedKeyValueIterator<Key,Value> itr, Document doc, AttributeFactory attrs) throws IOException {\n+        Key result = super.apply(itr, doc, attrs);\n+        \n+        // for each thing in the doc, mark it as to-keep false because it will ultimately come from the document aggregation, otherwise there will be duplicates\n+        for (Attribute<?> attr : doc.getDictionary().values()) {\n+            attr.setToKeep(false);", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5MjY1NQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481092655", "bodyText": "that's fair, I will create a new document that I pass to apply() then merge it into doc.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:16:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDA0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\nindex 0302df9d5..d039d4f49 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n\n@@ -1,11 +1,16 @@\n package datawave.query.jexl.functions;\n \n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n import datawave.query.attributes.Attribute;\n import datawave.query.attributes.AttributeFactory;\n import datawave.query.attributes.Document;\n import datawave.query.predicate.EventDataQueryFilter;\n import datawave.query.tld.TLD;\n import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n import org.apache.accumulo.core.data.ArrayByteSequence;\n import org.apache.accumulo.core.data.ByteSequence;\n import org.apache.accumulo.core.data.Key;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDg1NA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480240854", "bodyText": "Hard coded 1 hour... hmm....", "author": "ivakegg", "createdAt": "2020-08-31T16:21:23Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5MzEzOQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481093139", "bodyText": "This is the same hard coded value as the AttributeFactory cache.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:17:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI0MDg1NA=="}], "type": "inlineReview", "revised_code": {"commit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java b/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\ndeleted file mode 100644\nindex 61d7a5a53..000000000\n--- a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\n+++ /dev/null\n\n@@ -1,248 +0,0 @@\n-package datawave.query.iterator.logic;\n-\n-import com.google.common.cache.CacheBuilder;\n-import com.google.common.cache.CacheLoader;\n-import com.google.common.cache.LoadingCache;\n-import datawave.data.type.NoOpType;\n-import datawave.data.type.Type;\n-import datawave.query.jexl.JexlASTHelper;\n-import datawave.query.util.Tuple1;\n-import datawave.query.util.Tuple2;\n-import datawave.query.util.TypeMetadata;\n-import org.apache.accumulo.core.data.ByteSequence;\n-import org.apache.accumulo.core.data.Key;\n-import org.apache.accumulo.core.data.PartialKey;\n-import org.apache.accumulo.core.data.Range;\n-import org.apache.accumulo.core.data.Value;\n-import org.apache.accumulo.core.iterators.IteratorEnvironment;\n-import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n-import org.apache.hadoop.io.Text;\n-\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.SortedSet;\n-import java.util.TreeSet;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-\n-/**\n- * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n- * applied to a field\n- */\n-public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n-    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n-    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n-                    .build(new CacheLoader<String,Type<?>>() {\n-                        @Override\n-                        public Type<?> load(String clazz) throws Exception {\n-                            Class<?> c = Class.forName(clazz);\n-                            return (Type<?>) c.newInstance();\n-                        }\n-                    });\n-    \n-    private final String field;\n-    private final TypeMetadata typeMetadata;\n-    \n-    private SortedKeyValueIterator<Key,Value> delegate;\n-    private IteratorEnvironment environment;\n-    \n-    // sorted cache for normalized key/value pairs sorted by Key\n-    private SortedSet<Tuple2<Key,Value>> sorted = new TreeSet<>(Comparator.comparing(Tuple1::first));\n-    private String defaultTypeClass = NoOpType.class.getName();\n-    \n-    private boolean initialized = false;\n-    \n-    public EventFieldNormalizingIterator(String field, SortedKeyValueIterator<Key,Value> delegate, TypeMetadata typeMetadata, String defaultTypeClass) {\n-        this.field = field;\n-        this.delegate = delegate;\n-        this.typeMetadata = typeMetadata;\n-        this.defaultTypeClass = defaultTypeClass;\n-    }\n-    \n-    public EventFieldNormalizingIterator(EventFieldNormalizingIterator clone) {\n-        field = clone.field;\n-        typeMetadata = clone.typeMetadata;\n-        delegate = clone.delegate.deepCopy(clone.environment);\n-        environment = clone.environment;\n-        \n-        // sorted should not need to be copied since the new object must be seeked\n-    }\n-    \n-    @Override\n-    public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> options, IteratorEnvironment env) throws IOException {\n-        delegate.init(source, options, env);\n-        environment = env;\n-    }\n-    \n-    @Override\n-    public boolean hasTop() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // if the sorted set has more than one element in it there is always more\n-        if (sorted.size() > 0) {\n-            return true;\n-        } else {\n-            fillSorted();\n-            \n-            return sorted.size() > 0;\n-        }\n-    }\n-    \n-    @Override\n-    public void next() throws IOException {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // make sure we are exhausted\n-        if (sorted.size() == 0) {\n-            fillSorted();\n-        }\n-        \n-        if (sorted.size() == 0) {\n-            throw new NoSuchElementException(\"called next after exhausting all elements\");\n-        }\n-        \n-        sorted.remove(sorted.first());\n-    }\n-    \n-    @Override\n-    public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n-        // clear whatever is cached\n-        sorted.clear();\n-        \n-        delegate.seek(range, columnFamilies, inclusive);\n-        \n-        initialized = true;\n-        \n-        // populate sorted\n-        fillSorted();\n-    }\n-    \n-    @Override\n-    public Key getTopKey() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().first();\n-    }\n-    \n-    @Override\n-    public Value getTopValue() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().second();\n-    }\n-    \n-    @Override\n-    public SortedKeyValueIterator<Key,Value> deepCopy(IteratorEnvironment env) {\n-        return new EventFieldNormalizingIterator(this);\n-    }\n-    \n-    private void fillSorted() {\n-        Key baseKey = null;\n-        String dataType = null;\n-        \n-        // need to fill look ahead and fill the sorted set before answering. In order to guarantee ordering must grab all matching Key's for a given\n-        // cf/field, inserting the modified keys into sorted\n-        while (delegate.hasTop()) {\n-            // grab the first key for comparisons to know when its safe to stop\n-            if (baseKey == null) {\n-                baseKey = delegate.getTopKey();\n-            }\n-            \n-            Key current = delegate.getTopKey();\n-            \n-            // if this key has a different row/cf than the baseKey we have looked ahead far enough to guarantee sorted order.\n-            if (current.compareTo(baseKey, PartialKey.ROW_COLFAM) != 0) {\n-                // if sorted contains more than 1 key we have looked ahead far enough to find more keys and can stop, otherwise reset the baseKey and type\n-                // and continue to look\n-                if (sorted.size() > 0) {\n-                    break;\n-                } else {\n-                    // since there are no keys yet keep looking, clear assumptions about key and reset stop condition\n-                    baseKey = null;\n-                    dataType = null;\n-                }\n-            }\n-            \n-            // test if current matches the target field\n-            int fieldNameEnd = -1;\n-            ByteSequence cq = current.getColumnQualifierData();\n-            for (int i = 0; i < cq.getBackingArray().length; i++) {\n-                if (cq.byteAt(i) == '\\u0000') {\n-                    fieldNameEnd = i;\n-                    break;\n-                }\n-            }\n-            \n-            String fieldName = null;\n-            // there are sometimes strange keys, make sure this one is well formed\n-            if (fieldNameEnd > 0) {\n-                fieldName = cq.subSequence(0, fieldNameEnd).toString();\n-                \n-                // remove any grouping context\n-                fieldName = JexlASTHelper.removeGroupingContext(fieldName);\n-            }\n-            \n-            // this matches the target field, normalize and add to sorted\n-            if (fieldName != null && field.equals(fieldName)) {\n-                // first get the data type from the key if we don't have it already\n-                if (dataType == null) {\n-                    int dataTypeEnd = -1;\n-                    ByteSequence cf = current.getColumnFamilyData();\n-                    for (int i = 0; i < cf.getBackingArray().length; i++) {\n-                        if (cf.byteAt(i) == '\\u0000') {\n-                            dataTypeEnd = i;\n-                        }\n-                    }\n-                    \n-                    if (dataTypeEnd <= 0) {\n-                        throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n-                    }\n-                    \n-                    dataType = cf.subSequence(0, dataTypeEnd).toString();\n-                }\n-                \n-                // parse the value from the cq which should be fieldNameEnd + 1 to the end\n-                String fieldValue = cq.subSequence(fieldNameEnd + 1, cq.length()).toString();\n-                \n-                // fetch all Types for the field/dataType combination\n-                Collection<String> typeClasses = typeMetadata.getTypeMetadata(fieldName, dataType);\n-                \n-                // if its not found add the default\n-                if (typeClasses.size() == 0) {\n-                    typeClasses.add(defaultTypeClass);\n-                }\n-                \n-                // transform the key for each type and add it to sorted\n-                for (String typeClass : typeClasses) {\n-                    try {\n-                        Type<?> type = typeCache.get(typeClass);\n-                        String normalizedValue = type.normalize(fieldValue);\n-                        \n-                        // construct a new Key with the normalized value and put it into sorted\n-                        sorted.add(new Tuple2<>(new Key(current.getRow(), current.getColumnFamily(), new Text(fieldName + '\\u0000' + normalizedValue)),\n-                                        delegate.getTopValue()));\n-                    } catch (ExecutionException e) {\n-                        throw new RuntimeException(\"cannot instantiate class '\" + typeClass + \"'\", e);\n-                    }\n-                }\n-            }\n-            \n-            try {\n-                delegate.next();\n-            } catch (IOException e) {\n-                throw new RuntimeException(\"Could not get next from delegate\");\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r480272798", "bodyText": "It seems to me that we are doing a lot of work to try and keep things sorted when all we are doing is aggregating these into a Document.  Would a better approach be to modify the aggregator to simply do the normalization?", "author": "ivakegg", "createdAt": "2020-08-31T17:18:46Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5NDE3OA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481094178", "bodyText": "I originally started there, but because it has a 1:many relationship due to normalizers it was going to require interface changes to IdentityAggregator. We can still go with that if you prefer.", "author": "FineAndDandy", "createdAt": "2020-09-01T12:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTExNDc0Mg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481114742", "bodyText": "If it makes the code simpler, then I am all for it.  We have added several new classes here whereas an api change and one simpler extension would be easier to understand and maintain.  I guess the question is how many other places will this affect my changing the interface to return 1:many relationships.", "author": "ivakegg", "createdAt": "2020-09-01T12:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTEyNTEyNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481125126", "bodyText": "It requires changing the parserFieldValues() to return a list rather than a single value, then updating all current methods to return singletons.", "author": "FineAndDandy", "createdAt": "2020-09-01T13:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI3Mjc5OA=="}], "type": "inlineReview", "revised_code": {"commit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java b/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\ndeleted file mode 100644\nindex 61d7a5a53..000000000\n--- a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\n+++ /dev/null\n\n@@ -1,248 +0,0 @@\n-package datawave.query.iterator.logic;\n-\n-import com.google.common.cache.CacheBuilder;\n-import com.google.common.cache.CacheLoader;\n-import com.google.common.cache.LoadingCache;\n-import datawave.data.type.NoOpType;\n-import datawave.data.type.Type;\n-import datawave.query.jexl.JexlASTHelper;\n-import datawave.query.util.Tuple1;\n-import datawave.query.util.Tuple2;\n-import datawave.query.util.TypeMetadata;\n-import org.apache.accumulo.core.data.ByteSequence;\n-import org.apache.accumulo.core.data.Key;\n-import org.apache.accumulo.core.data.PartialKey;\n-import org.apache.accumulo.core.data.Range;\n-import org.apache.accumulo.core.data.Value;\n-import org.apache.accumulo.core.iterators.IteratorEnvironment;\n-import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n-import org.apache.hadoop.io.Text;\n-\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.SortedSet;\n-import java.util.TreeSet;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-\n-/**\n- * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n- * applied to a field\n- */\n-public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n-    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n-    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n-                    .build(new CacheLoader<String,Type<?>>() {\n-                        @Override\n-                        public Type<?> load(String clazz) throws Exception {\n-                            Class<?> c = Class.forName(clazz);\n-                            return (Type<?>) c.newInstance();\n-                        }\n-                    });\n-    \n-    private final String field;\n-    private final TypeMetadata typeMetadata;\n-    \n-    private SortedKeyValueIterator<Key,Value> delegate;\n-    private IteratorEnvironment environment;\n-    \n-    // sorted cache for normalized key/value pairs sorted by Key\n-    private SortedSet<Tuple2<Key,Value>> sorted = new TreeSet<>(Comparator.comparing(Tuple1::first));\n-    private String defaultTypeClass = NoOpType.class.getName();\n-    \n-    private boolean initialized = false;\n-    \n-    public EventFieldNormalizingIterator(String field, SortedKeyValueIterator<Key,Value> delegate, TypeMetadata typeMetadata, String defaultTypeClass) {\n-        this.field = field;\n-        this.delegate = delegate;\n-        this.typeMetadata = typeMetadata;\n-        this.defaultTypeClass = defaultTypeClass;\n-    }\n-    \n-    public EventFieldNormalizingIterator(EventFieldNormalizingIterator clone) {\n-        field = clone.field;\n-        typeMetadata = clone.typeMetadata;\n-        delegate = clone.delegate.deepCopy(clone.environment);\n-        environment = clone.environment;\n-        \n-        // sorted should not need to be copied since the new object must be seeked\n-    }\n-    \n-    @Override\n-    public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> options, IteratorEnvironment env) throws IOException {\n-        delegate.init(source, options, env);\n-        environment = env;\n-    }\n-    \n-    @Override\n-    public boolean hasTop() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // if the sorted set has more than one element in it there is always more\n-        if (sorted.size() > 0) {\n-            return true;\n-        } else {\n-            fillSorted();\n-            \n-            return sorted.size() > 0;\n-        }\n-    }\n-    \n-    @Override\n-    public void next() throws IOException {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // make sure we are exhausted\n-        if (sorted.size() == 0) {\n-            fillSorted();\n-        }\n-        \n-        if (sorted.size() == 0) {\n-            throw new NoSuchElementException(\"called next after exhausting all elements\");\n-        }\n-        \n-        sorted.remove(sorted.first());\n-    }\n-    \n-    @Override\n-    public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n-        // clear whatever is cached\n-        sorted.clear();\n-        \n-        delegate.seek(range, columnFamilies, inclusive);\n-        \n-        initialized = true;\n-        \n-        // populate sorted\n-        fillSorted();\n-    }\n-    \n-    @Override\n-    public Key getTopKey() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().first();\n-    }\n-    \n-    @Override\n-    public Value getTopValue() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().second();\n-    }\n-    \n-    @Override\n-    public SortedKeyValueIterator<Key,Value> deepCopy(IteratorEnvironment env) {\n-        return new EventFieldNormalizingIterator(this);\n-    }\n-    \n-    private void fillSorted() {\n-        Key baseKey = null;\n-        String dataType = null;\n-        \n-        // need to fill look ahead and fill the sorted set before answering. In order to guarantee ordering must grab all matching Key's for a given\n-        // cf/field, inserting the modified keys into sorted\n-        while (delegate.hasTop()) {\n-            // grab the first key for comparisons to know when its safe to stop\n-            if (baseKey == null) {\n-                baseKey = delegate.getTopKey();\n-            }\n-            \n-            Key current = delegate.getTopKey();\n-            \n-            // if this key has a different row/cf than the baseKey we have looked ahead far enough to guarantee sorted order.\n-            if (current.compareTo(baseKey, PartialKey.ROW_COLFAM) != 0) {\n-                // if sorted contains more than 1 key we have looked ahead far enough to find more keys and can stop, otherwise reset the baseKey and type\n-                // and continue to look\n-                if (sorted.size() > 0) {\n-                    break;\n-                } else {\n-                    // since there are no keys yet keep looking, clear assumptions about key and reset stop condition\n-                    baseKey = null;\n-                    dataType = null;\n-                }\n-            }\n-            \n-            // test if current matches the target field\n-            int fieldNameEnd = -1;\n-            ByteSequence cq = current.getColumnQualifierData();\n-            for (int i = 0; i < cq.getBackingArray().length; i++) {\n-                if (cq.byteAt(i) == '\\u0000') {\n-                    fieldNameEnd = i;\n-                    break;\n-                }\n-            }\n-            \n-            String fieldName = null;\n-            // there are sometimes strange keys, make sure this one is well formed\n-            if (fieldNameEnd > 0) {\n-                fieldName = cq.subSequence(0, fieldNameEnd).toString();\n-                \n-                // remove any grouping context\n-                fieldName = JexlASTHelper.removeGroupingContext(fieldName);\n-            }\n-            \n-            // this matches the target field, normalize and add to sorted\n-            if (fieldName != null && field.equals(fieldName)) {\n-                // first get the data type from the key if we don't have it already\n-                if (dataType == null) {\n-                    int dataTypeEnd = -1;\n-                    ByteSequence cf = current.getColumnFamilyData();\n-                    for (int i = 0; i < cf.getBackingArray().length; i++) {\n-                        if (cf.byteAt(i) == '\\u0000') {\n-                            dataTypeEnd = i;\n-                        }\n-                    }\n-                    \n-                    if (dataTypeEnd <= 0) {\n-                        throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n-                    }\n-                    \n-                    dataType = cf.subSequence(0, dataTypeEnd).toString();\n-                }\n-                \n-                // parse the value from the cq which should be fieldNameEnd + 1 to the end\n-                String fieldValue = cq.subSequence(fieldNameEnd + 1, cq.length()).toString();\n-                \n-                // fetch all Types for the field/dataType combination\n-                Collection<String> typeClasses = typeMetadata.getTypeMetadata(fieldName, dataType);\n-                \n-                // if its not found add the default\n-                if (typeClasses.size() == 0) {\n-                    typeClasses.add(defaultTypeClass);\n-                }\n-                \n-                // transform the key for each type and add it to sorted\n-                for (String typeClass : typeClasses) {\n-                    try {\n-                        Type<?> type = typeCache.get(typeClass);\n-                        String normalizedValue = type.normalize(fieldValue);\n-                        \n-                        // construct a new Key with the normalized value and put it into sorted\n-                        sorted.add(new Tuple2<>(new Key(current.getRow(), current.getColumnFamily(), new Text(fieldName + '\\u0000' + normalizedValue)),\n-                                        delegate.getTopValue()));\n-                    } catch (ExecutionException e) {\n-                        throw new RuntimeException(\"cannot instantiate class '\" + typeClass + \"'\", e);\n-                    }\n-                }\n-            }\n-            \n-            try {\n-                delegate.next();\n-            } catch (IOException e) {\n-                throw new RuntimeException(\"Could not get next from delegate\");\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MDY3OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481060679", "bodyText": "Should be compareTo() < 0", "author": "apmoriarty", "createdAt": "2020-09-01T11:14:48Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java", "diffHunk": "@@ -0,0 +1,163 @@\n+package datawave.query.iterator;\n+\n+import datawave.data.type.NoOpType;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.iterator.logic.EventFieldNormalizingIterator;\n+import datawave.query.jexl.functions.IdentityAggregator;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+\n+/**\n+ * Iterate over a document range aggregating fields in their normalized form.\n+ */\n+public class EventFieldIterator implements NestedIterator<Key> {\n+    private final Range range;\n+    private final SortedKeyValueIterator<Key,Value> source;\n+    private final String field;\n+    private final AttributeFactory attributeFactory;\n+    private final TypeMetadata typeMetadata;\n+    private final IdentityAggregator aggregator;\n+    private Key key;\n+    private Document document;\n+    private boolean initialized = false;\n+    private EventFieldNormalizingIterator normalizingIterator;\n+    \n+    public EventFieldIterator(Range range, SortedKeyValueIterator<Key,Value> source, String field, AttributeFactory attributeFactory,\n+                    TypeMetadata typeMetadata, IdentityAggregator aggregator) {\n+        this.range = range;\n+        this.source = source;\n+        this.field = field;\n+        this.attributeFactory = attributeFactory;\n+        this.typeMetadata = typeMetadata;\n+        this.aggregator = aggregator;\n+    }\n+    \n+    @Override\n+    public void initialize() {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public Key move(Key minimum) {\n+        // simple sanity check that is free\n+        if (!range.contains(minimum)) {\n+            return null;\n+        }\n+        \n+        // test current source key to determine state\n+        if (!source.hasTop()) {\n+            // no key can match the underlying source is empty\n+            return null;\n+        }\n+        \n+        Key top = source.getTopKey();\n+        \n+        if (minimum.compareTo(top) < -1) {", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA5NDQyMQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481094421", "bodyText": "yep", "author": "FineAndDandy", "createdAt": "2020-09-01T12:19:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MDY3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java b/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\nindex 97a500637..e759d99b4 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\n\n@@ -1,11 +1,9 @@\n package datawave.query.iterator;\n \n-import datawave.data.type.NoOpType;\n import datawave.query.attributes.AttributeFactory;\n import datawave.query.attributes.Document;\n-import datawave.query.iterator.logic.EventFieldNormalizingIterator;\n+import datawave.query.jexl.JexlASTHelper;\n import datawave.query.jexl.functions.IdentityAggregator;\n-import datawave.query.util.TypeMetadata;\n import org.apache.accumulo.core.data.Key;\n import org.apache.accumulo.core.data.Range;\n import org.apache.accumulo.core.data.Value;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTA2MjQzNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r481062436", "bodyText": "the consistency in these two constructors is killing me.", "author": "apmoriarty", "createdAt": "2020-09-01T11:18:14Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java", "diffHunk": "@@ -0,0 +1,248 @@\n+package datawave.query.iterator.logic;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.NoOpType;\n+import datawave.data.type.Type;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.util.Tuple1;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.PartialKey;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+import org.apache.hadoop.io.Text;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.SortedSet;\n+import java.util.TreeSet;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n+ * applied to a field\n+ */\n+public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private final String field;\n+    private final TypeMetadata typeMetadata;\n+    \n+    private SortedKeyValueIterator<Key,Value> delegate;\n+    private IteratorEnvironment environment;\n+    \n+    // sorted cache for normalized key/value pairs sorted by Key\n+    private SortedSet<Tuple2<Key,Value>> sorted = new TreeSet<>(Comparator.comparing(Tuple1::first));\n+    private String defaultTypeClass = NoOpType.class.getName();\n+    \n+    private boolean initialized = false;\n+    \n+    public EventFieldNormalizingIterator(String field, SortedKeyValueIterator<Key,Value> delegate, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        this.field = field;\n+        this.delegate = delegate;\n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    ", "originalCommit": "0f9a3c84d1d7b0b5896e62b15a3afbb2751f5b0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java b/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\ndeleted file mode 100644\nindex 61d7a5a53..000000000\n--- a/warehouse/query-core/src/main/java/datawave/query/iterator/logic/EventFieldNormalizingIterator.java\n+++ /dev/null\n\n@@ -1,248 +0,0 @@\n-package datawave.query.iterator.logic;\n-\n-import com.google.common.cache.CacheBuilder;\n-import com.google.common.cache.CacheLoader;\n-import com.google.common.cache.LoadingCache;\n-import datawave.data.type.NoOpType;\n-import datawave.data.type.Type;\n-import datawave.query.jexl.JexlASTHelper;\n-import datawave.query.util.Tuple1;\n-import datawave.query.util.Tuple2;\n-import datawave.query.util.TypeMetadata;\n-import org.apache.accumulo.core.data.ByteSequence;\n-import org.apache.accumulo.core.data.Key;\n-import org.apache.accumulo.core.data.PartialKey;\n-import org.apache.accumulo.core.data.Range;\n-import org.apache.accumulo.core.data.Value;\n-import org.apache.accumulo.core.iterators.IteratorEnvironment;\n-import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n-import org.apache.hadoop.io.Text;\n-\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.Comparator;\n-import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.SortedSet;\n-import java.util.TreeSet;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-\n-/**\n- * Iterator expects Event Key/Value pairs and will filter to only matching field and apply normalizations. This will result in one Key generated per normalizer\n- * applied to a field\n- */\n-public class EventFieldNormalizingIterator implements SortedKeyValueIterator<Key,Value> {\n-    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n-    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n-                    .build(new CacheLoader<String,Type<?>>() {\n-                        @Override\n-                        public Type<?> load(String clazz) throws Exception {\n-                            Class<?> c = Class.forName(clazz);\n-                            return (Type<?>) c.newInstance();\n-                        }\n-                    });\n-    \n-    private final String field;\n-    private final TypeMetadata typeMetadata;\n-    \n-    private SortedKeyValueIterator<Key,Value> delegate;\n-    private IteratorEnvironment environment;\n-    \n-    // sorted cache for normalized key/value pairs sorted by Key\n-    private SortedSet<Tuple2<Key,Value>> sorted = new TreeSet<>(Comparator.comparing(Tuple1::first));\n-    private String defaultTypeClass = NoOpType.class.getName();\n-    \n-    private boolean initialized = false;\n-    \n-    public EventFieldNormalizingIterator(String field, SortedKeyValueIterator<Key,Value> delegate, TypeMetadata typeMetadata, String defaultTypeClass) {\n-        this.field = field;\n-        this.delegate = delegate;\n-        this.typeMetadata = typeMetadata;\n-        this.defaultTypeClass = defaultTypeClass;\n-    }\n-    \n-    public EventFieldNormalizingIterator(EventFieldNormalizingIterator clone) {\n-        field = clone.field;\n-        typeMetadata = clone.typeMetadata;\n-        delegate = clone.delegate.deepCopy(clone.environment);\n-        environment = clone.environment;\n-        \n-        // sorted should not need to be copied since the new object must be seeked\n-    }\n-    \n-    @Override\n-    public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> options, IteratorEnvironment env) throws IOException {\n-        delegate.init(source, options, env);\n-        environment = env;\n-    }\n-    \n-    @Override\n-    public boolean hasTop() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // if the sorted set has more than one element in it there is always more\n-        if (sorted.size() > 0) {\n-            return true;\n-        } else {\n-            fillSorted();\n-            \n-            return sorted.size() > 0;\n-        }\n-    }\n-    \n-    @Override\n-    public void next() throws IOException {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        // make sure we are exhausted\n-        if (sorted.size() == 0) {\n-            fillSorted();\n-        }\n-        \n-        if (sorted.size() == 0) {\n-            throw new NoSuchElementException(\"called next after exhausting all elements\");\n-        }\n-        \n-        sorted.remove(sorted.first());\n-    }\n-    \n-    @Override\n-    public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {\n-        // clear whatever is cached\n-        sorted.clear();\n-        \n-        delegate.seek(range, columnFamilies, inclusive);\n-        \n-        initialized = true;\n-        \n-        // populate sorted\n-        fillSorted();\n-    }\n-    \n-    @Override\n-    public Key getTopKey() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().first();\n-    }\n-    \n-    @Override\n-    public Value getTopValue() {\n-        if (!initialized) {\n-            throw new IllegalStateException(\"must call seek before hasTop()\");\n-        }\n-        \n-        return sorted.first().second();\n-    }\n-    \n-    @Override\n-    public SortedKeyValueIterator<Key,Value> deepCopy(IteratorEnvironment env) {\n-        return new EventFieldNormalizingIterator(this);\n-    }\n-    \n-    private void fillSorted() {\n-        Key baseKey = null;\n-        String dataType = null;\n-        \n-        // need to fill look ahead and fill the sorted set before answering. In order to guarantee ordering must grab all matching Key's for a given\n-        // cf/field, inserting the modified keys into sorted\n-        while (delegate.hasTop()) {\n-            // grab the first key for comparisons to know when its safe to stop\n-            if (baseKey == null) {\n-                baseKey = delegate.getTopKey();\n-            }\n-            \n-            Key current = delegate.getTopKey();\n-            \n-            // if this key has a different row/cf than the baseKey we have looked ahead far enough to guarantee sorted order.\n-            if (current.compareTo(baseKey, PartialKey.ROW_COLFAM) != 0) {\n-                // if sorted contains more than 1 key we have looked ahead far enough to find more keys and can stop, otherwise reset the baseKey and type\n-                // and continue to look\n-                if (sorted.size() > 0) {\n-                    break;\n-                } else {\n-                    // since there are no keys yet keep looking, clear assumptions about key and reset stop condition\n-                    baseKey = null;\n-                    dataType = null;\n-                }\n-            }\n-            \n-            // test if current matches the target field\n-            int fieldNameEnd = -1;\n-            ByteSequence cq = current.getColumnQualifierData();\n-            for (int i = 0; i < cq.getBackingArray().length; i++) {\n-                if (cq.byteAt(i) == '\\u0000') {\n-                    fieldNameEnd = i;\n-                    break;\n-                }\n-            }\n-            \n-            String fieldName = null;\n-            // there are sometimes strange keys, make sure this one is well formed\n-            if (fieldNameEnd > 0) {\n-                fieldName = cq.subSequence(0, fieldNameEnd).toString();\n-                \n-                // remove any grouping context\n-                fieldName = JexlASTHelper.removeGroupingContext(fieldName);\n-            }\n-            \n-            // this matches the target field, normalize and add to sorted\n-            if (fieldName != null && field.equals(fieldName)) {\n-                // first get the data type from the key if we don't have it already\n-                if (dataType == null) {\n-                    int dataTypeEnd = -1;\n-                    ByteSequence cf = current.getColumnFamilyData();\n-                    for (int i = 0; i < cf.getBackingArray().length; i++) {\n-                        if (cf.byteAt(i) == '\\u0000') {\n-                            dataTypeEnd = i;\n-                        }\n-                    }\n-                    \n-                    if (dataTypeEnd <= 0) {\n-                        throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n-                    }\n-                    \n-                    dataType = cf.subSequence(0, dataTypeEnd).toString();\n-                }\n-                \n-                // parse the value from the cq which should be fieldNameEnd + 1 to the end\n-                String fieldValue = cq.subSequence(fieldNameEnd + 1, cq.length()).toString();\n-                \n-                // fetch all Types for the field/dataType combination\n-                Collection<String> typeClasses = typeMetadata.getTypeMetadata(fieldName, dataType);\n-                \n-                // if its not found add the default\n-                if (typeClasses.size() == 0) {\n-                    typeClasses.add(defaultTypeClass);\n-                }\n-                \n-                // transform the key for each type and add it to sorted\n-                for (String typeClass : typeClasses) {\n-                    try {\n-                        Type<?> type = typeCache.get(typeClass);\n-                        String normalizedValue = type.normalize(fieldValue);\n-                        \n-                        // construct a new Key with the normalized value and put it into sorted\n-                        sorted.add(new Tuple2<>(new Key(current.getRow(), current.getColumnFamily(), new Text(fieldName + '\\u0000' + normalizedValue)),\n-                                        delegate.getTopValue()));\n-                    } catch (ExecutionException e) {\n-                        throw new RuntimeException(\"cannot instantiate class '\" + typeClass + \"'\", e);\n-                    }\n-                }\n-            }\n-            \n-            try {\n-                delegate.next();\n-            } catch (IOException e) {\n-                throw new RuntimeException(\"Could not get next from delegate\");\n-            }\n-        }\n-    }\n-}\n"}}, {"oid": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "url": "https://github.com/NationalSecurityAgency/datawave/commit/46772adfeb1b4aba9430ddd9e8d19cf754db823b", "message": "fixes #858 Remove EventFieldNormalizingIterator and push functionality into EventFieldAggregator", "committedDate": "2020-09-01T17:41:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3NDk0Ng==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482974946", "bodyText": "be -> been", "author": "ivakegg", "createdAt": "2020-09-03T13:25:05Z", "path": "warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java", "diffHunk": "@@ -0,0 +1,176 @@\n+package datawave.query.iterator;\n+\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.jexl.JexlASTHelper;\n+import datawave.query.jexl.functions.IdentityAggregator;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Range;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.Collections;\n+\n+/**\n+ * Iterate over a document range aggregating fields in their normalized form.\n+ */\n+public class EventFieldIterator implements NestedIterator<Key> {\n+    private final Range range;\n+    private final SortedKeyValueIterator<Key,Value> source;\n+    private final String field;\n+    private final IdentityAggregator aggregator;\n+    private final AttributeFactory attributeFactory;\n+    private Key key;\n+    private Document document;\n+    private boolean initialized = false;\n+    \n+    public EventFieldIterator(Range range, SortedKeyValueIterator<Key,Value> source, String field, AttributeFactory attributeFactory,\n+                    IdentityAggregator aggregator) {\n+        this.range = range;\n+        this.source = source;\n+        this.field = field;\n+        this.attributeFactory = attributeFactory;\n+        this.aggregator = aggregator;\n+    }\n+    \n+    @Override\n+    public void initialize() {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public Key move(Key minimum) {\n+        // simple sanity check that is free\n+        if (!range.contains(minimum)) {\n+            return null;\n+        }\n+        \n+        // test current source key to determine state\n+        if (!source.hasTop()) {\n+            // no key can match the underlying source is empty\n+            return null;\n+        }\n+        \n+        Key top = source.getTopKey();\n+        \n+        if (minimum.compareTo(top) < 0) {\n+            throw new IllegalStateException(\"cannot move iterator backwards to \" + minimum);\n+        }\n+        \n+        // update the range to start a minimum\n+        Range newRange = new Range(minimum, true, range.getEndKey(), range.isEndKeyInclusive());\n+        \n+        try {\n+            if (!initialized) {\n+                init(newRange);\n+            } else {\n+                // just seek\n+                source.seek(newRange, Collections.emptyList(), false);\n+                getNext();\n+            }\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+        \n+        return next();\n+    }\n+    \n+    @Override\n+    public Collection<NestedIterator<Key>> leaves() {\n+        return Collections.emptySet();\n+    }\n+    \n+    @Override\n+    public Collection<NestedIterator<Key>> children() {\n+        return Collections.emptySet();\n+    }\n+    \n+    @Override\n+    public Document document() {\n+        return document;\n+    }\n+    \n+    @Override\n+    public boolean isContextRequired() {\n+        return false;\n+    }\n+    \n+    @Override\n+    public void setContext(Key context) {\n+        // no-op\n+    }\n+    \n+    @Override\n+    public boolean hasNext() {\n+        // do the actual seeking now if it hasn't be done yet", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5Mzg3NA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492293874", "bodyText": "got it", "author": "FineAndDandy", "createdAt": "2020-09-21T19:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3NDk0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "c0979add93eaae8791ff33814d35b4c528b706ac", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java b/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\nindex e759d99b4..b9db29c54 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/iterator/EventFieldIterator.java\n\n@@ -104,7 +104,7 @@ public class EventFieldIterator implements NestedIterator<Key> {\n     \n     @Override\n     public boolean hasNext() {\n-        // do the actual seeking now if it hasn't be done yet\n+        // do the actual seeking now if it hasn't been done yet\n         try {\n             if (!initialized) {\n                 init(range);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3OTI4Mw==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482979283", "bodyText": "The valid bytes in cf.getBackingArray() only go through cf.length().  The backing array could be longer.", "author": "ivakegg", "createdAt": "2020-09-03T13:30:58Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NDEyMQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492294121", "bodyText": "good catch", "author": "FineAndDandy", "createdAt": "2020-09-21T19:24:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk3OTI4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "c0979add93eaae8791ff33814d35b4c528b706ac", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\nindex d039d4f49..44aeeeba9 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n\n@@ -57,7 +57,7 @@ public class EventFieldAggregator extends IdentityAggregator {\n         \n         int dataTypeEnd = -1;\n         ByteSequence cf = topKey.getColumnFamilyData();\n-        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+        for (int i = 0; i < cf.length(); i++) {\n             if (cf.byteAt(i) == '\\u0000') {\n                 dataTypeEnd = i;\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4ODAxNg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482988016", "bodyText": "Seems to me this whole method could be replaced with simply returning cq.  If you need a copy of the bytes then return new ArrayByteSequence(Arrays.copyOf(cq.getBackingArray(), cq.length()), 0, cq.length()).", "author": "ivakegg", "createdAt": "2020-09-03T13:43:49Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+            if (cf.byteAt(i) == '\\u0000') {\n+                dataTypeEnd = i;\n+            }\n+        }\n+        \n+        if (dataTypeEnd <= 0) {\n+            throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n+        }\n+        \n+        String dataType = cf.subSequence(0, dataTypeEnd).toString();\n+        \n+        Set<String> normalizedValues = getNormalizedValues(dataType, field, value);\n+        List<Tuple2<String,String>> fieldValuePairs = new ArrayList<>(normalizedValues.size());\n+        for (String normalizedValue : normalizedValues) {\n+            fieldValuePairs.add(new Tuple2<>(field, normalizedValue));\n+        }\n+        \n+        return fieldValuePairs;\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NTMxMg==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492295312", "bodyText": "you are right, there is no reason to do this. I don't think there is any reason not to just return the cq.", "author": "FineAndDandy", "createdAt": "2020-09-21T19:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4ODAxNg=="}], "type": "inlineReview", "revised_code": {"commit": "c0979add93eaae8791ff33814d35b4c528b706ac", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\nindex d039d4f49..44aeeeba9 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n\n@@ -57,7 +57,7 @@ public class EventFieldAggregator extends IdentityAggregator {\n         \n         int dataTypeEnd = -1;\n         ByteSequence cf = topKey.getColumnFamilyData();\n-        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+        for (int i = 0; i < cf.length(); i++) {\n             if (cf.byteAt(i) == '\\u0000') {\n                 dataTypeEnd = i;\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5Mzc1OQ==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r482993759", "bodyText": "This is not actually doing any sorting.", "author": "ivakegg", "createdAt": "2020-09-03T13:51:42Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package datawave.query.jexl.functions;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import datawave.data.type.Type;\n+import datawave.query.attributes.Attribute;\n+import datawave.query.attributes.AttributeFactory;\n+import datawave.query.attributes.Document;\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.Tuple2;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n+import org.apache.accumulo.core.data.ByteSequence;\n+import org.apache.accumulo.core.data.Key;\n+import org.apache.accumulo.core.data.Value;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+public class EventFieldAggregator extends IdentityAggregator {\n+    // speedy cache loading for types, duplicated from AttributeFactory with caching of types rather than classes\n+    protected static LoadingCache<String,Type<?>> typeCache = CacheBuilder.newBuilder().maximumSize(128).expireAfterAccess(1, TimeUnit.HOURS)\n+                    .build(new CacheLoader<String,Type<?>>() {\n+                        @Override\n+                        public Type<?> load(String clazz) throws Exception {\n+                            Class<?> c = Class.forName(clazz);\n+                            return (Type<?>) c.newInstance();\n+                        }\n+                    });\n+    \n+    private TypeMetadata typeMetadata;\n+    private String defaultTypeClass;\n+    \n+    public EventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(Collections.singleton(field), filter, maxNextCount);\n+        \n+        this.typeMetadata = typeMetadata;\n+        this.defaultTypeClass = defaultTypeClass;\n+    }\n+    \n+    @Override\n+    protected List<Tuple2<String,String>> parserFieldNameValue(Key topKey) {\n+        String cq = topKey.getColumnQualifier().toString();\n+        int nullIndex1 = cq.indexOf('\\u0000');\n+        String field = cq.substring(0, nullIndex1);\n+        String value = cq.substring(nullIndex1 + 1);\n+        \n+        int dataTypeEnd = -1;\n+        ByteSequence cf = topKey.getColumnFamilyData();\n+        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+            if (cf.byteAt(i) == '\\u0000') {\n+                dataTypeEnd = i;\n+            }\n+        }\n+        \n+        if (dataTypeEnd <= 0) {\n+            throw new RuntimeException(\"malformed key, cannot parse data type from event\");\n+        }\n+        \n+        String dataType = cf.subSequence(0, dataTypeEnd).toString();\n+        \n+        Set<String> normalizedValues = getNormalizedValues(dataType, field, value);\n+        List<Tuple2<String,String>> fieldValuePairs = new ArrayList<>(normalizedValues.size());\n+        for (String normalizedValue : normalizedValues) {\n+            fieldValuePairs.add(new Tuple2<>(field, normalizedValue));\n+        }\n+        \n+        return fieldValuePairs;\n+    }\n+    \n+    @Override\n+    protected ByteSequence parseFieldNameValue(ByteSequence cf, ByteSequence cq) {\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, cq, 1);\n+        final int startFv = nulls.get(0) + 1;\n+        final int stopFn = nulls.get(0);\n+        \n+        byte[] fnFv = new byte[cq.length()];\n+        System.arraycopy(cq.getBackingArray(), 0, fnFv, 0, stopFn);\n+        System.arraycopy(cq.getBackingArray(), startFv, fnFv, stopFn + 1, cq.length() - startFv);\n+        \n+        return new ArrayByteSequence(fnFv);\n+    }\n+    \n+    @Override\n+    protected ByteSequence getPointerData(Key key) {\n+        return key.getColumnFamilyData();\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        return columnFamily;\n+    }\n+    \n+    @Override\n+    public Key apply(SortedKeyValueIterator<Key,Value> itr, Document doc, AttributeFactory attrs) throws IOException {\n+        Document d = new Document();\n+        Key result = super.apply(itr, d, attrs);\n+        \n+        // for each thing in the doc, mark it as to-keep false because it will ultimately come from the document aggregation, otherwise there will be duplicates\n+        for (Attribute<?> attr : d.getDictionary().values()) {\n+            attr.setToKeep(false);\n+        }\n+        \n+        doc.putAll(d, false);\n+        \n+        return result;\n+    }\n+    \n+    private Set<String> getNormalizedValues(String dataType, String fieldName, String fieldValue) {\n+        Set<String> normalizedValues = new HashSet<>();\n+        \n+        // fetch all Types for the field/dataType combination\n+        Collection<String> typeClasses = typeMetadata.getTypeMetadata(fieldName, dataType);\n+        \n+        // if its not found add the default\n+        if (typeClasses.size() == 0) {\n+            typeClasses.add(defaultTypeClass);\n+        }\n+        \n+        // transform the key for each type and add it to sorted", "originalCommit": "46772adfeb1b4aba9430ddd9e8d19cf754db823b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI5NTczMA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r492295730", "bodyText": "fixed docs", "author": "FineAndDandy", "createdAt": "2020-09-21T19:27:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5Mzc1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c0979add93eaae8791ff33814d35b4c528b706ac", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\nindex d039d4f49..44aeeeba9 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/EventFieldAggregator.java\n\n@@ -57,7 +57,7 @@ public class EventFieldAggregator extends IdentityAggregator {\n         \n         int dataTypeEnd = -1;\n         ByteSequence cf = topKey.getColumnFamilyData();\n-        for (int i = 0; i < cf.getBackingArray().length; i++) {\n+        for (int i = 0; i < cf.length(); i++) {\n             if (cf.byteAt(i) == '\\u0000') {\n                 dataTypeEnd = i;\n             }\n"}}, {"oid": "c0979add93eaae8791ff33814d35b4c528b706ac", "url": "https://github.com/NationalSecurityAgency/datawave/commit/c0979add93eaae8791ff33814d35b4c528b706ac", "message": "fixes #858 Update comments and simplify parseFieldNameValue()", "committedDate": "2020-09-21T19:44:54Z", "type": "commit"}, {"oid": "2d34b0b293a14406a7d5dd87494da44c06a99c64", "url": "https://github.com/NationalSecurityAgency/datawave/commit/2d34b0b293a14406a7d5dd87494da44c06a99c64", "message": "Merge branch 'release/version2.9' into 858", "committedDate": "2020-10-22T18:12:55Z", "type": "commit"}, {"oid": "0f240ddf5159aa30581635576ba223807f58ea2f", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0f240ddf5159aa30581635576ba223807f58ea2f", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-02-24T13:01:27Z", "type": "commit"}, {"oid": "0198b02b93b7eb7f8f515d2c2bd45c5ffb2e6097", "url": "https://github.com/NationalSecurityAgency/datawave/commit/0198b02b93b7eb7f8f515d2c2bd45c5ffb2e6097", "message": "fixes #858: Copy map into modifiable HashSet add minor efficiency", "committedDate": "2021-02-24T14:39:46Z", "type": "commit"}, {"oid": "79a40342ebfe032bd680c075ed379f84973d048c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/79a40342ebfe032bd680c075ed379f84973d048c", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-09T14:33:59Z", "type": "commit"}, {"oid": "19e62ea56e0c5891628489cd59dcf3a582f93598", "url": "https://github.com/NationalSecurityAgency/datawave/commit/19e62ea56e0c5891628489cd59dcf3a582f93598", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-09T18:50:37Z", "type": "commit"}, {"oid": "a55adb7db28e854ce4e209c6780fc45e83f9ae8d", "url": "https://github.com/NationalSecurityAgency/datawave/commit/a55adb7db28e854ce4e209c6780fc45e83f9ae8d", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-10T13:11:45Z", "type": "commit"}, {"oid": "441b369adfc3fd5bbbcd4885b9d336b93a23530a", "url": "https://github.com/NationalSecurityAgency/datawave/commit/441b369adfc3fd5bbbcd4885b9d336b93a23530a", "message": "fixes #858: spotbugs fix", "committedDate": "2021-03-10T16:26:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592386243", "bodyText": "I think this is making an assumption about how we create UIDs.  If we turned on the timestamp portion of the UID then this would break or if we decide to substitute an alternate UID mechanism as it is currently pluggable.  Can we simply look for the last dot and strip that off?", "author": "ivakegg", "createdAt": "2021-03-11T14:05:03Z", "path": "warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package datawave.query.jexl.functions;\n+\n+import datawave.query.predicate.EventDataQueryFilter;\n+import datawave.query.tld.TLD;\n+import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ByteSequence;\n+\n+import java.util.ArrayList;\n+\n+public class TLDEventFieldAggregator extends EventFieldAggregator {\n+    public TLDEventFieldAggregator(String field, EventDataQueryFilter filter, int maxNextCount, TypeMetadata typeMetadata, String defaultTypeClass) {\n+        super(field, filter, maxNextCount, typeMetadata, defaultTypeClass);\n+    }\n+    \n+    @Override\n+    protected ByteSequence parsePointer(ByteSequence columnFamily) {\n+        // find the null between the dataType and Uid\n+        ArrayList<Integer> nulls = TLD.instancesOf(0, columnFamily, 1);\n+        final int start = nulls.get(0) + 1;\n+        \n+        // uid is from the null byte to the end of the cf\n+        ByteSequence uid = columnFamily.subSequence(start, columnFamily.length());\n+        \n+        // find the end of the tld if it exists\n+        ArrayList<Integer> dots = TLD.instancesOf('.', uid);\n+        if (dots.size() > 2) {\n+            // reduce to the TLD\n+            return columnFamily.subSequence(0, start + dots.get(2));", "originalCommit": "441b369adfc3fd5bbbcd4885b9d336b93a23530a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM5ODE5Ng==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592398196", "bodyText": "What if there's more than one dot, for example uid.1.1.2", "author": "apmoriarty", "createdAt": "2021-03-11T14:19:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjUyOTMxOA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592529318", "bodyText": "I updated the code to use UID to get the base UID", "author": "FineAndDandy", "createdAt": "2021-03-11T16:51:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjUyOTY5MA==", "url": "https://github.com/NationalSecurityAgency/datawave/pull/909#discussion_r592529690", "bodyText": "Generally this query logic is probably not configured right if the UID scheme changes", "author": "FineAndDandy", "createdAt": "2021-03-11T16:52:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MjM4NjI0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7d3d25df5154fc8738b9901ea09c77e3eca2602a", "chunk": "diff --git a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java\nindex 6315b85f1..9c975833d 100644\n--- a/warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java\n+++ b/warehouse/query-core/src/main/java/datawave/query/jexl/functions/TLDEventFieldAggregator.java\n\n@@ -1,8 +1,10 @@\n package datawave.query.jexl.functions;\n \n+import datawave.data.hash.UID;\n import datawave.query.predicate.EventDataQueryFilter;\n import datawave.query.tld.TLD;\n import datawave.query.util.TypeMetadata;\n+import org.apache.accumulo.core.data.ArrayByteSequence;\n import org.apache.accumulo.core.data.ByteSequence;\n \n import java.util.ArrayList;\n"}}, {"oid": "7d3d25df5154fc8738b9901ea09c77e3eca2602a", "url": "https://github.com/NationalSecurityAgency/datawave/commit/7d3d25df5154fc8738b9901ea09c77e3eca2602a", "message": "fixes #858: Use UID to parse base UID", "committedDate": "2021-03-11T16:49:10Z", "type": "commit"}, {"oid": "2fa97d2969b96ea66d4d203928916b4d5323344c", "url": "https://github.com/NationalSecurityAgency/datawave/commit/2fa97d2969b96ea66d4d203928916b4d5323344c", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-17T12:18:55Z", "type": "commit"}, {"oid": "ba0b3fe659c5d5915b9b58b0098651f331975392", "url": "https://github.com/NationalSecurityAgency/datawave/commit/ba0b3fe659c5d5915b9b58b0098651f331975392", "message": "Merge branch 'release/version3.2' into 858", "committedDate": "2021-03-17T13:38:48Z", "type": "commit"}]}