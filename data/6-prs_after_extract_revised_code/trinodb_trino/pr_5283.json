{"pr_number": 5283, "pr_title": "Variable precision timestamp support for Hive write operations", "pr_createdAt": "2020-09-24T04:47:02Z", "pr_url": "https://github.com/trinodb/trino/pull/5283", "timeline": [{"oid": "83da8532cace3eee3bb5db13e6495e381240c0e5", "url": "https://github.com/trinodb/trino/commit/83da8532cace3eee3bb5db13e6495e381240c0e5", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-09-25T13:20:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwODEzMg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495008132", "bodyText": "compare with TIMESTAMP_MILLIS using ==\n(this is intentionally supported; reads better)", "author": "findepi", "createdAt": "2020-09-25T14:00:42Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now\n+                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType().equals(TIMESTAMP_MILLIS))", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\nindex 63f1c91f04..6b9bbe04b4 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n\n@@ -2379,8 +2381,8 @@ public class HiveMetadata\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n-                // we only support stats collection at default precision for now\n-                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType().equals(TIMESTAMP_MILLIS))\n+                // TODO: we only support stats collection at millis precision for now (https://github.com/prestosql/presto/issues/5170)\n+                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType() == TIMESTAMP_MILLIS)\n                 .map(this::getColumnStatisticMetadata)\n                 .flatMap(List::stream)\n                 .collect(toImmutableSet());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwOTA2NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495009065", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            // we only support stats collection at default precision for now\n          \n          \n            \n                            // TODO we only support stats collection at default precision for now", "author": "findepi", "createdAt": "2020-09-25T14:02:07Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\nindex 63f1c91f04..6b9bbe04b4 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n\n@@ -2379,8 +2381,8 @@ public class HiveMetadata\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n-                // we only support stats collection at default precision for now\n-                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType().equals(TIMESTAMP_MILLIS))\n+                // TODO: we only support stats collection at millis precision for now (https://github.com/prestosql/presto/issues/5170)\n+                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType() == TIMESTAMP_MILLIS)\n                 .map(this::getColumnStatisticMetadata)\n                 .flatMap(List::stream)\n                 .collect(toImmutableSet());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNjg4MA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495016880", "bodyText": "IntSupplier -> int", "author": "findepi", "createdAt": "2020-09-25T14:13:20Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex 376f1a4687..d9590c3ce9 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -375,61 +366,50 @@ public final class FieldSetterFactory\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final TimestampType type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n-            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            // no rounding since the the data has nanosecond precision, at most\n+            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n             value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-    }\n \n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n         {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp::getPicosOfMicro);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            return epochMillis / MILLISECONDS_PER_SECOND;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNzkwNw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495017907", "bodyText": "This should be using actual type, not \"best type\"\npass the type from io.prestosql.plugin.hive.util.FieldSetterFactory#create here and use it", "author": "findepi", "createdAt": "2020-09-25T14:14:48Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex 376f1a4687..d9590c3ce9 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -375,61 +366,50 @@ public final class FieldSetterFactory\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final TimestampType type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n-            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            // no rounding since the the data has nanosecond precision, at most\n+            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n             value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-    }\n \n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n         {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp::getPicosOfMicro);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            return epochMillis / MILLISECONDS_PER_SECOND;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495019719", "bodyText": "up to millis precision is covered by epochMillis parameter, so\nmod MICROSECONDS_PER_SECOND should probably be mod MICROSECONDS_PER_MILLISECOND", "author": "findepi", "createdAt": "2020-09-25T14:17:32Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA0NjE1Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495046152", "bodyText": "It's definitely no clear what's happening here, but the Timestamp we are returning is constructed from epoch millis and nanos of second (since it's using a java.time.LocalDateTime under the covers).  Pretty intuitive API, right?  I'll try to make this explicit.", "author": "aalbu", "createdAt": "2020-09-25T14:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex 376f1a4687..d9590c3ce9 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -375,61 +366,50 @@ public final class FieldSetterFactory\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final TimestampType type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n-            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            // no rounding since the the data has nanosecond precision, at most\n+            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n             value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-    }\n \n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n         {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp::getPicosOfMicro);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            return epochMillis / MILLISECONDS_PER_SECOND;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMjg4Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495022883", "bodyText": "This should be using actual type, not \"best type\"", "author": "findepi", "createdAt": "2020-09-25T14:22:17Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);\n+            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            value.set(timestamp);\n+            rowInspector.setStructFieldData(row, field, value);\n+        }\n+    }\n+\n+    private static class LongTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex 376f1a4687..d9590c3ce9 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -375,61 +366,50 @@ public final class FieldSetterFactory\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final TimestampType type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n-            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            // no rounding since the the data has nanosecond precision, at most\n+            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n             value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-    }\n \n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n         {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp::getPicosOfMicro);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            return epochMillis / MILLISECONDS_PER_SECOND;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495023506", "bodyText": "should we have this for other formats in this class?", "author": "findepi", "createdAt": "2020-09-25T14:23:14Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java", "diffHunk": "@@ -291,16 +294,15 @@ public void testRcBinaryOptimizedWriter(int rowCount)\n     public void testOrc(int rowCount, long fileSizePadding)\n             throws Exception\n     {\n-        // Hive binary writers are broken for timestamps\n-        List<TestColumn> testColumns = TEST_COLUMNS.stream()\n-                .filter(TestHiveFileFormats::withoutTimestamps)\n-                .collect(toImmutableList());\n-\n-        assertThatFileFormat(ORC)\n-                .withColumns(testColumns)\n-                .withRowsCount(rowCount)\n-                .withFileSizePadding(fileSizePadding)\n-                .isReadableByPageSource(new OrcPageSourceFactory(new OrcReaderOptions(), HDFS_ENVIRONMENT, STATS, UTC));\n+        for (HiveTimestampPrecision timestampPrecision : List.of(MILLISECONDS, MICROSECONDS, NANOSECONDS)) {", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNzQxMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495037410", "bodyText": "I'll add more.", "author": "aalbu", "createdAt": "2020-09-25T14:44:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java\nindex c536c8e554..dbf0c221a4 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java\n\n@@ -294,15 +291,11 @@ public class TestHiveFileFormats\n     public void testOrc(int rowCount, long fileSizePadding)\n             throws Exception\n     {\n-        for (HiveTimestampPrecision timestampPrecision : List.of(MILLISECONDS, MICROSECONDS, NANOSECONDS)) {\n-            ConnectorSession session = getHiveSession(new HiveConfig().setTimestampPrecision(timestampPrecision));\n-            assertThatFileFormat(ORC)\n-                    .withColumns(TEST_COLUMNS)\n-                    .withRowsCount(rowCount)\n-                    .withFileSizePadding(fileSizePadding)\n-                    .withSession(session)\n-                    .isReadableByPageSource(new OrcPageSourceFactory(new OrcReaderOptions(), HDFS_ENVIRONMENT, STATS, UTC));\n-        }\n+        assertThatFileFormat(ORC)\n+                .withColumns(TEST_COLUMNS)\n+                .withRowsCount(rowCount)\n+                .withFileSizePadding(fileSizePadding)\n+                .isReadableByPageSource(new OrcPageSourceFactory(new OrcReaderOptions(), HDFS_ENVIRONMENT, STATS, UTC));\n     }\n \n     @Test(dataProvider = \"validRowAndFileSizePadding\")\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024048", "bodyText": "Is this relevant? or did you disable stats collection for timestamp != 3 for now?", "author": "findepi", "createdAt": "2020-09-25T14:24:04Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7238,6 +7261,8 @@ private Session withTimestampPrecision(Session session, String precision)\n     {\n         return Session.builder(session)\n                 .setCatalogSessionProperty(catalog, \"timestamp_precision\", precision)\n+                // TODO: remove when implementing https://github.com/prestosql/presto/issues/5170\n+                .setCatalogSessionProperty(catalog, \"collect_column_statistics_on_write\", \"false\")", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNTM4OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495035389", "bodyText": "Shouldn't be needed.  I missed it when I was cleaning up my code.", "author": "aalbu", "createdAt": "2020-09-25T14:40:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA=="}], "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\nindex 4a5c20d5ff..7919b20ebd 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n\n@@ -7257,12 +7419,10 @@ public class TestHiveIntegrationSmokeTest\n                 {HiveTimestampPrecision.NANOSECONDS}};\n     }\n \n-    private Session withTimestampPrecision(Session session, String precision)\n+    private Session withTimestampPrecision(Session session, HiveTimestampPrecision precision)\n     {\n         return Session.builder(session)\n-                .setCatalogSessionProperty(catalog, \"timestamp_precision\", precision)\n-                // TODO: remove when implementing https://github.com/prestosql/presto/issues/5170\n-                .setCatalogSessionProperty(catalog, \"collect_column_statistics_on_write\", \"false\")\n+                .setCatalogSessionProperty(catalog, \"timestamp_precision\", precision.name())\n                 .build();\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDIyOA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024228", "bodyText": "debug?", "author": "findepi", "createdAt": "2020-09-25T14:24:19Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,269 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n+    public void testTimestampCreatedFromPresto(StorageFormat storageFormat)\n+            throws Exception\n+    {\n+        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n+        setupTimestampData(tableName, storageFormat);\n+\n+        // commenting out pre-epoch timestamps until https://github.com/prestosql/presto-hive-apache/pull/17 becomes available\n+        List<TimestampAndPrecision> data = ImmutableList.of(\n+//                new TimestampAndPrecision(\n+//                        \"MILLISECONDS\",\n+//                        \"1967-01-02 12:34:56.123\",\n+//                        ImmutableMap.of(", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java b/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\nindex 5841cebbec..4c1e09e519 100644\n--- a/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\n+++ b/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\n\n@@ -454,15 +454,7 @@ public class TestHiveStorageFormats\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n         setupTimestampData(tableName, storageFormat);\n \n-        // commenting out pre-epoch timestamps until https://github.com/prestosql/presto-hive-apache/pull/17 becomes available\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-//                new TimestampAndPrecision(\n-//                        \"MILLISECONDS\",\n-//                        \"1967-01-02 12:34:56.123\",\n-//                        ImmutableMap.of(\n-//                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-//                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n-//                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n                 new TimestampAndPrecision(\n                         \"MILLISECONDS\",\n                         \"2020-01-02 12:34:56.123\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495025733", "bodyText": "Avoid java.time's objectful representation.\nCan we use LongTimestamp or something like DecodedTimestamp (rename to HiveTimestamp?)", "author": "findepi", "createdAt": "2020-09-25T14:26:30Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNjk5OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495036999", "bodyText": "I use this to format a timestamp with precision > milliseconds.  Since Joda only supports millisecond precision, I have to use java.time.", "author": "aalbu", "createdAt": "2020-09-25T14:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw=="}], "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java b/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\nindex b5727d6f21..1bcf9f2964 100644\n--- a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\n+++ b/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\n\n@@ -21,11 +21,11 @@ import java.time.LocalDateTime;\n import java.time.ZoneOffset;\n \n import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n-import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n-import static io.prestosql.spi.type.Timestamps.roundDiv;\n import static java.lang.Math.floorDiv;\n import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n \n public final class TimestampUtils\n {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495026134", "bodyText": "micros floorMod  MICROSECONDS_PER_SECOND ?", "author": "findepi", "createdAt": "2020-09-25T14:27:07Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (type.isShort()) {\n+            long micros = type.getLong(block, position);\n+            long epochSeconds = floorDiv(micros, MICROSECONDS_PER_SECOND);\n+            // we know this fits in an int\n+            int nanosFraction = (int) ((micros - epochSeconds * MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA3MTA0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495071047", "bodyText": "I was just trying to avoid re-executing floorDiv(micros, MICROSECONDS_PER_SECOND), but it's the second or third time I'm getting a similar review comment, so I'll stop trying to micro-optimize \ud83d\ude09", "author": "aalbu", "createdAt": "2020-09-25T15:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA=="}], "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java b/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\nindex b5727d6f21..1bcf9f2964 100644\n--- a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\n+++ b/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\n\n@@ -21,11 +21,11 @@ import java.time.LocalDateTime;\n import java.time.ZoneOffset;\n \n import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n-import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n-import static io.prestosql.spi.type.Timestamps.roundDiv;\n import static java.lang.Math.floorDiv;\n import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n \n public final class TimestampUtils\n {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyODA4Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495028087", "bodyText": "nit: we could add int roundDiv(int,long) overload for cases iike this one\nyou can take https://github.com/findepi/presto/commits/round-div is you want to", "author": "findepi", "createdAt": "2020-09-25T14:29:54Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex 376f1a4687..d9590c3ce9 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -375,61 +366,50 @@ public final class FieldSetterFactory\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final TimestampType type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n-            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            // no rounding since the the data has nanosecond precision, at most\n+            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n             value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-    }\n \n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n         {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp::getPicosOfMicro);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            return epochMillis / MILLISECONDS_PER_SECOND;\n         }\n     }\n \n"}}, {"oid": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "url": "https://github.com/trinodb/trino/commit/1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "message": "Minor ORC cleanup", "committedDate": "2020-09-30T00:37:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497484911", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return (int) roundDiv((long) value, factor);\n          \n          \n            \n                    //noinspection NumericCastThatLosesPrecision\n          \n          \n            \n                    return (int) roundDiv((long) value, factor);", "author": "findepi", "createdAt": "2020-09-30T12:53:22Z", "path": "presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java", "diffHunk": "@@ -102,6 +102,11 @@ private static long scaleFactor(int fromPrecision, int toPrecision)\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    public static int roundDiv(int value, long factor)\n+    {\n+        return (int) roundDiv((long) value, factor);", "originalCommit": "c5ac163b6c06959713acfbe6c88bcaa4596d14eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxMzYyMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497813623", "bodyText": "I've added the inspection to my IDE \ud83d\ude00", "author": "aalbu", "createdAt": "2020-09-30T21:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java b/presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java\nindex 10a2beacb4..0671d9bece 100644\n--- a/presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java\n+++ b/presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java\n\n@@ -102,6 +102,7 @@ public class Timestamps\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    @SuppressWarnings(\"NumericCastThatLosesPrecision\")\n     public static int roundDiv(int value, long factor)\n     {\n         return (int) roundDiv((long) value, factor);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NjI0MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497486241", "bodyText": "Add a\n// TODO validate timestamps in structural types\n\n+ issue", "author": "findepi", "createdAt": "2020-09-30T12:55:19Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2596,13 +2597,13 @@ private static void validateColumns(ConnectorTableMetadata tableMetadata)\n     }\n \n     // temporary, until variable precision timestamps are supported on write\n-    private static void validateTimestampColumns(List<ColumnMetadata> columns)\n+    private static void validateTimestampColumns(List<ColumnMetadata> columns, HiveTimestampPrecision timestampPrecision)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\nindex 6b9bbe04b4..716ca448c2 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java\n\n@@ -2597,13 +2721,13 @@ public class HiveMetadata\n     }\n \n     // temporary, until variable precision timestamps are supported on write\n-    private static void validateTimestampColumns(List<ColumnMetadata> columns, HiveTimestampPrecision timestampPrecision)\n+    private static void validateTimestampColumns(List<ColumnMetadata> columns)\n     {\n         for (ColumnMetadata column : columns) {\n             Type type = column.getType();\n             if (type instanceof TimestampType) {\n-                if (((TimestampType) type).getPrecision() != timestampPrecision.getPrecision()) {\n-                    throw new PrestoException(NOT_SUPPORTED, \"Incorrect timestamp precision for \" + type + \"; the configured precision is: \" + timestampPrecision);\n+                if (type != TIMESTAMP_MILLIS) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"CREATE TABLE, INSERT and ANALYZE are not supported with requested timestamp precision: \" + type);\n                 }\n             }\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4ODA3NA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497488074", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        long epochMicros;\n          \n          \n            \n                        long epochSeconds;\n          \n      \n    \n    \n  \n\ndeclare epochSeconds and picosOfSecond outside and declare epochMicros separately inside of both branches\nthis will make the conversion easier to follow and verify correctness (micros, picosOfMicro, picosOfSecond), at the cost of writing epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND); twice", "author": "findepi", "createdAt": "2020-09-30T12:58:05Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +370,47 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochMicros;", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\nindex d9590c3ce9..821b85f745 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java\n\n@@ -370,47 +365,22 @@ public final class FieldSetterFactory\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n-        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n-            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMicros;\n-            long picosOfSecond;\n-            if (type.isShort()) {\n-                epochMicros = type.getLong(block, position);\n-                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n-            }\n-            else {\n-                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n-                epochMicros = longTimestamp.getEpochMicros();\n-                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n-                        longTimestamp.getPicosOfMicro();\n-            }\n-            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n-            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n-            // no rounding since the the data has nanosecond precision, at most\n-            int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n-\n-            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n-            value.set(timestamp);\n+            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n+            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n+            value.set(Timestamp.ofEpochMilli(epochMilli));\n             rowInspector.setStructFieldData(row, field, value);\n         }\n-\n-        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n-        {\n-            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            return epochMillis / MILLISECONDS_PER_SECOND;\n-        }\n     }\n \n     private static class DecimalFieldSetter\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU0ODk0OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497548949", "bodyText": "since it's always used together with TIMESTAMP '%s', it would be more convenient to define\nprivate static String formatTimestamp(LocalDateTime) \n\nthe formatter can be inline in that method (or a const) -- perf doesnt matter", "author": "findepi", "createdAt": "2020-09-30T14:20:43Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -161,6 +160,7 @@\n public class TestHiveIntegrationSmokeTest\n         extends AbstractTestIntegrationSmokeTest\n {\n+    private static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSSSSSSSS\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\nindex 7919b20ebd..357f870328 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n\n@@ -160,7 +161,6 @@ import static org.testng.FileAssert.assertFile;\n public class TestHiveIntegrationSmokeTest\n         extends AbstractTestIntegrationSmokeTest\n {\n-    private static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSSSSSSSS\");\n     private final String catalog;\n     private final Session bucketedSession;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDU1Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550556", "bodyText": "co we have correctness tests ensure\nWHERE col < actual_value + 1 nanosecond\n\ndoesn't filter out col = actual_value (for col being full millis .... h:m:s.001000000 or not: .... h:m:s.001000001)", "author": "findepi", "createdAt": "2020-09-30T14:22:47Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\nindex 7919b20ebd..357f870328 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n\n@@ -4206,44 +4212,7 @@ public class TestHiveIntegrationSmokeTest\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n-            sleeper.sleep();\n-            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n-        });\n-    }\n-\n-    @Test(dataProvider = \"timestampPrecisionAndValues\")\n-    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n-    {\n-        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n-        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n-        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n-        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n-        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n-\n-        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n-        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n-        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n-        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n-                session,\n-                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.minusNanos(MILLISECONDS.toNanos(1)))));\n-        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n-\n-        queryResult = queryRunner.executeWithQueryId(\n-                session,\n-                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.plusNanos(MILLISECONDS.toNanos(1)))));\n-        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n-\n-        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied\n-        ExponentialSleeper sleeper = new ExponentialSleeper(\n-                new Duration(0, SECONDS),\n-                new Duration(5, SECONDS),\n-                new Duration(100, MILLISECONDS),\n-                2.0);\n-        assertEventually(new Duration(30, SECONDS), () -> {\n-            ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n-                    session,\n-                    format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n             sleeper.sleep();\n             assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDgyOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550829", "bodyText": "link to gh issue about that (#5172 right?)", "author": "findepi", "createdAt": "2020-09-30T14:23:08Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n+        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n+        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.minusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.plusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\nindex 7919b20ebd..357f870328 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n\n@@ -4206,44 +4212,7 @@ public class TestHiveIntegrationSmokeTest\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n-            sleeper.sleep();\n-            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n-        });\n-    }\n-\n-    @Test(dataProvider = \"timestampPrecisionAndValues\")\n-    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n-    {\n-        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n-        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n-        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n-        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n-        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n-\n-        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n-        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n-        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n-        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n-                session,\n-                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.minusNanos(MILLISECONDS.toNanos(1)))));\n-        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n-\n-        queryResult = queryRunner.executeWithQueryId(\n-                session,\n-                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.plusNanos(MILLISECONDS.toNanos(1)))));\n-        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n-\n-        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied\n-        ExponentialSleeper sleeper = new ExponentialSleeper(\n-                new Duration(0, SECONDS),\n-                new Duration(5, SECONDS),\n-                new Duration(100, MILLISECONDS),\n-                2.0);\n-        assertEventually(new Duration(30, SECONDS), () -> {\n-            ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n-                    session,\n-                    format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n             sleeper.sleep();\n             assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MTYzMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497551631", "bodyText": "nit \"\\\\E\" is probably redundant", "author": "findepi", "createdAt": "2020-09-30T14:24:07Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7078,6 +7092,148 @@ public void testUnsupportedCsvTable()\n                 \"\\\\QHive CSV storage format only supports VARCHAR (unbounded). Unsupported columns: i integer, bound varchar(10)\\\\E\");\n     }\n \n+    @Test\n+    public void testWriteInvalidPrecisionTimestamp()\n+    {\n+        Session session = withTimestampPrecision(getSession(), HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123456789'\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\nindex 7919b20ebd..357f870328 100644\n--- a/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n+++ b/presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java\n\n@@ -7092,148 +7081,6 @@ public class TestHiveIntegrationSmokeTest\n                 \"\\\\QHive CSV storage format only supports VARCHAR (unbounded). Unsupported columns: i integer, bound varchar(10)\\\\E\");\n     }\n \n-    @Test\n-    public void testWriteInvalidPrecisionTimestamp()\n-    {\n-        Session session = withTimestampPrecision(getSession(), HiveTimestampPrecision.MICROSECONDS);\n-        assertQueryFails(\n-                session,\n-                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123456789'\",\n-                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");\n-        assertQueryFails(\n-                session,\n-                \"CREATE TABLE test_invalid_precision_timestamp (ts TIMESTAMP(9))\",\n-                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");\n-        assertQueryFails(\n-                session,\n-                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123'\",\n-                \"\\\\QIncorrect timestamp precision for timestamp(3); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");\n-        assertQueryFails(\n-                session,\n-                \"CREATE TABLE test_invalid_precision_timestamp (ts TIMESTAMP(3))\",\n-                \"\\\\QIncorrect timestamp precision for timestamp(3); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");\n-    }\n-\n-    @Test\n-    public void testTimestampPrecisionInsert()\n-    {\n-        testWithAllStorageFormats(this::testTimestampPrecisionInsert);\n-    }\n-\n-    private void testTimestampPrecisionInsert(Session session, HiveStorageFormat storageFormat)\n-    {\n-        if (storageFormat == HiveStorageFormat.AVRO) {\n-            // Avro timestamps are stored with millisecond precision\n-            return;\n-        }\n-\n-        String createTable = \"CREATE TABLE test_timestamp_precision (ts TIMESTAMP) WITH (format = '%s')\";\n-        @Language(\"SQL\") String insert = \"INSERT INTO test_timestamp_precision VALUES (TIMESTAMP '%s')\";\n-\n-        testTimestampPrecisionWrites(\n-                session,\n-                (ts, precision) -> {\n-                    assertUpdate(\"DROP TABLE IF EXISTS test_timestamp_precision\");\n-                    assertUpdate(format(createTable, storageFormat));\n-                    assertUpdate(withTimestampPrecision(session, precision), format(insert, ts), 1);\n-                });\n-    }\n-\n-    @Test\n-    public void testTimestampPrecisionCtas()\n-    {\n-        testWithAllStorageFormats(this::testTimestampPrecisionCtas);\n-    }\n-\n-    private void testTimestampPrecisionCtas(Session session, HiveStorageFormat storageFormat)\n-    {\n-        if (storageFormat == HiveStorageFormat.AVRO) {\n-            // Avro timestamps are stored with millisecond precision\n-            return;\n-        }\n-\n-        String createTableAs = \"CREATE TABLE test_timestamp_precision WITH (format = '%s') AS SELECT TIMESTAMP '%s' ts\";\n-\n-        testTimestampPrecisionWrites(\n-                session,\n-                (ts, precision) -> {\n-                    assertUpdate(\"DROP TABLE IF EXISTS test_timestamp_precision\");\n-                    assertUpdate(withTimestampPrecision(session, precision), format(createTableAs, storageFormat, ts), 1);\n-                });\n-    }\n-\n-    private void testTimestampPrecisionWrites(Session session, BiConsumer<String, HiveTimestampPrecision> populateData)\n-    {\n-        populateData.accept(\"2019-02-03 18:30:00.123\", HiveTimestampPrecision.MILLISECONDS);\n-        @Language(\"SQL\") String sql = \"SELECT ts FROM test_timestamp_precision\";\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.123')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.123')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.NANOSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.123')\");\n-\n-        populateData.accept(\"2019-02-03 18:30:00.456789\", HiveTimestampPrecision.MICROSECONDS);\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.457')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.456789')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.NANOSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.456789000')\");\n-\n-        populateData.accept(\"2019-02-03 18:30:00.456789876\", HiveTimestampPrecision.NANOSECONDS);\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.457')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.456790')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.NANOSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.456789876')\");\n-\n-        // some rounding edge cases\n-\n-        populateData.accept(\"2019-02-03 18:30:00.999999\", HiveTimestampPrecision.MICROSECONDS);\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:01.000')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.999999')\");\n-\n-        populateData.accept(\"2019-02-03 18:30:00.999999999\", HiveTimestampPrecision.NANOSECONDS);\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:01.000')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:01.000000')\");\n-        assertQuery(\n-                withTimestampPrecision(session, HiveTimestampPrecision.NANOSECONDS),\n-                sql,\n-                \"VALUES ('2019-02-03 18:30:00.999999999')\");\n-    }\n-\n     private Session getParallelWriteSession()\n     {\n         return Session.builder(getSession())\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MzA4Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553086", "bodyText": "i like the change but it belongs to the prep commit, not Variable precision timestamp support for Hive write operations", "author": "findepi", "createdAt": "2020-09-30T14:25:56Z", "path": "presto-main/src/main/java/io/prestosql/testing/MaterializedResult.java", "diffHunk": "@@ -345,13 +343,6 @@ else if (type instanceof RowType) {\n         }\n     }\n \n-    private static DecodedTimestamp toDecodedTimestamp(SqlTimestamp sqlTimestamp)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553853", "bodyText": "why did we gain toIntExact here?", "author": "findepi", "createdAt": "2020-09-30T14:26:53Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -1041,7 +1041,7 @@ private static Object preprocessWriteValueHive(Type type, Object value)\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND);\n+            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU3OTg4Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497579882", "bodyText": "I messed up during a merge while trying to move this change to its own commit (per David's suggestion).  I'll clean up.", "author": "aalbu", "createdAt": "2020-09-30T14:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-orc/src/test/java/io/prestosql/orc/OrcTester.java b/presto-orc/src/test/java/io/prestosql/orc/OrcTester.java\nindex cfe314a7b0..306299170a 100644\n--- a/presto-orc/src/test/java/io/prestosql/orc/OrcTester.java\n+++ b/presto-orc/src/test/java/io/prestosql/orc/OrcTester.java\n\n@@ -1041,7 +1040,7 @@ public class OrcTester\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));\n+            int nanosOfMilli = roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND);\n             return Timestamp.ofEpochMilli(timestamp.getEpochMillis(), nanosOfMilli);\n         }\n         if (type instanceof DecimalType) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NjI0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497556247", "bodyText": "storage_formats tests are run multiple times, on many different environments, since file format behavior may interact with things like kerberos, impersonation\nthese tests do not need to run multiple times, and i guess they take quite some time (correct?)\nwe can move them to separate group\nor, we can have them without a group (then will be run in suite-1, on multine)\n-- in any case it'd be good to document the reason for this in a code comment\nor move the tests to a spearate class", "author": "findepi", "createdAt": "2020-09-30T14:29:29Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,219 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java b/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\nindex 4c1e09e519..527ec02408 100644\n--- a/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\n+++ b/presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java\n\n@@ -332,219 +332,46 @@ public class TestHiveStorageFormats\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n+    public void testTimestamp(StorageFormat storageFormat)\n             throws Exception\n-    {\n-        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        setupTimestampData(tableName, storageFormat);\n-        // write precision is not relevant here, as Hive always uses nanos\n-        List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.123\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.123\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.1234\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.1234\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.1236\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.1236\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.123456\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.123456\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.1234564\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.1234564\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.1234567\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.1234567\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"1967-01-02 12:34:56.123456789\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.123456789\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n-\n-        // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n-        // (which only works when the value range has a min = max)\n-        for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n-        }\n-\n-        runTimestampQueries(tableName, data);\n-    }\n-\n-    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestampCreatedFromPresto(StorageFormat storageFormat)\n-            throws Exception\n-    {\n-        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        setupTimestampData(tableName, storageFormat);\n-\n-        List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(\n-                        \"MILLISECONDS\",\n-                        \"2020-01-02 12:34:56.123\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n-                new TimestampAndPrecision(\n-                        \"MILLISECONDS\",\n-                        \"2020-01-02 12:34:56.1234\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n-                new TimestampAndPrecision(\n-                        \"MILLISECONDS\",\n-                        \"2020-01-02 12:34:56.1236\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.124\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.124\")),\n-                new TimestampAndPrecision(\n-                        \"MICROSECONDS\",\n-                        \"2020-01-02 12:34:56.123456\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n-                new TimestampAndPrecision(\n-                        \"MICROSECONDS\",\n-                        \"2020-01-02 12:34:56.1234564\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n-                new TimestampAndPrecision(\n-                        \"MICROSECONDS\",\n-                        \"2020-01-02 12:34:56.1234567\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123457\")),\n-                new TimestampAndPrecision(\n-                        \"NANOSECONDS\",\n-                        \"2020-01-02 12:34:56.123456789\",\n-                        ImmutableMap.of(\n-                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n-                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n-                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n-\n-        for (TimestampAndPrecision entry : data) {\n-            // insert timestamps with different precisions\n-            setSessionProperty(onPresto().getConnection(), \"hive.timestamp_precision\", entry.getPrecision());\n-            // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n-            // (which only works when the value range has a min = max)\n-            onPresto().executeQuery(format(\"INSERT INTO %s VALUES (%s, TIMESTAMP'%s')\", tableName, entry.getId(), entry.getWriteValue()));\n-        }\n-\n-        runTimestampQueries(tableName, data);\n-    }\n-\n-    private void setupTimestampData(String tableName, StorageFormat storageFormat)\n     {\n         // only admin user is allowed to change session properties\n         Connection connection = onPresto().getConnection();\n         setAdminRole(connection);\n         setSessionProperties(connection, storageFormat);\n \n+        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n         onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n+\n         onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n-    }\n+        List<TimestampAndPrecision> data = ImmutableList.of(\n+                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n+                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n+                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n+                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n+                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n+                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n+                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+\n+        // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n+        // (which only works when the value range has a min = max)\n+        for (TimestampAndPrecision entry : data) {\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+        }\n \n-    private void runTimestampQueries(String tableName, List<TimestampAndPrecision> data)\n-            throws SQLException\n-    {\n         for (TimestampAndPrecision entry : data) {\n-            for (String precision : List.of(\"MILLISECONDS\", \"MICROSECONDS\", \"NANOSECONDS\")) {\n-                setSessionProperty(onPresto().getConnection(), \"hive.timestamp_precision\", precision);\n-                assertThat(onPresto().executeQuery(format(\"SELECT ts FROM %s WHERE id = %s\", tableName, entry.getId())))\n-                        .containsOnly(row(Timestamp.valueOf(entry.getReadValues(precision))));\n-                assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts = TIMESTAMP'%s'\", tableName, entry.getId(), entry.getReadValues(precision))))\n+            setSessionProperty(connection, \"hive.timestamp_precision\", entry.getPrecision());\n+            assertThat(onPresto().executeQuery(format(\"SELECT ts FROM %s WHERE id = %s\", tableName, entry.getId())))\n+                    .containsOnly(row(Timestamp.valueOf(entry.getRoundedValue())));\n+            assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts = TIMESTAMP'%s'\", tableName, entry.getId(), entry.getRoundedValue())))\n+                    .containsOnly(row(entry.getId()));\n+            if (entry.isRoundedUp()) {\n+                assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts > TIMESTAMP'%s'\", tableName, entry.getId(), entry.getValue())))\n+                        .containsOnly(row(entry.getId()));\n+            }\n+            if (entry.isRoundedDown()) {\n+                assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts < TIMESTAMP'%s'\", tableName, entry.getId(), entry.getValue())))\n                         .containsOnly(row(entry.getId()));\n-                if (entry.isRoundedUp(precision)) {\n-                    assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts > TIMESTAMP'%s'\", tableName, entry.getId(), entry.getWriteValue())))\n-                            .containsOnly(row(entry.getId()));\n-                }\n-                if (entry.isRoundedDown(precision)) {\n-                    assertThat(onPresto().executeQuery(format(\"SELECT id FROM %s WHERE id = %s AND ts < TIMESTAMP'%s'\", tableName, entry.getId(), entry.getWriteValue())))\n-                            .containsOnly(row(entry.getId()));\n-                }\n             }\n         }\n         onPresto().executeQuery(\"DROP TABLE \" + tableName);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NzE1OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497557158", "bodyText": "here as elswhere: confine epochMicros to each of if/else blocks and have epochSeconds and picosOfSecond as the only things common", "author": "findepi", "createdAt": "2020-09-30T14:30:38Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochMicros;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND + longTimestamp.getPicosOfMicro();\n+        }\n+        long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "chunk": "diff --git a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java b/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\ndeleted file mode 100644\nindex 1bcf9f2964..0000000000\n--- a/presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java\n+++ /dev/null\n\n@@ -1,56 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package io.prestosql.rcfile;\n-\n-import io.prestosql.spi.block.Block;\n-import io.prestosql.spi.type.LongTimestamp;\n-import io.prestosql.spi.type.TimestampType;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n-import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n-import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n-import static java.lang.Math.floorDiv;\n-import static java.lang.Math.floorMod;\n-import static java.lang.Math.toIntExact;\n-\n-public final class TimestampUtils\n-{\n-    private TimestampUtils() {}\n-\n-    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n-    {\n-        if (block.isNull(position)) {\n-            return null;\n-        }\n-        long epochMicros;\n-        long picosOfSecond;\n-        if (type.isShort()) {\n-            epochMicros = type.getLong(block, position);\n-            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n-        }\n-        else {\n-            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n-            epochMicros = longTimestamp.getEpochMicros();\n-            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND + longTimestamp.getPicosOfMicro();\n-        }\n-        long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n-        // no rounding since the the data has nanosecond precision, at most\n-        int nanosOfSecond = toIntExact(picosOfSecond / PICOSECONDS_PER_NANOSECOND);\n-\n-        return LocalDateTime.ofEpochSecond(epochSeconds, nanosOfSecond, ZoneOffset.UTC);\n-    }\n-}\n"}}, {"oid": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "url": "https://github.com/trinodb/trino/commit/58817be6cb8344ce7c1e83ca005711584e34e7a3", "message": "Add roundDiv overload in Timestamps", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "4cb7d74347385117166b0579ee36f0476ed753af", "url": "https://github.com/trinodb/trino/commit/4cb7d74347385117166b0579ee36f0476ed753af", "message": "Construct session correctly when finishing stats collection", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "url": "https://github.com/trinodb/trino/commit/8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "message": "Handle variable precision timestamps in MaterializedResult", "committedDate": "2020-11-02T23:31:24Z", "type": "commit"}, {"oid": "04b45b1c27c622b087e2040648bd074d77142055", "url": "https://github.com/trinodb/trino/commit/04b45b1c27c622b087e2040648bd074d77142055", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-11-03T03:15:14Z", "type": "commit"}, {"oid": "d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "url": "https://github.com/trinodb/trino/commit/d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "message": "Remove unused method", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "forcePushed"}]}