{"pr_number": 5402, "pr_title": "Hive ACID row-level insert and delete", "pr_createdAt": "2020-10-03T17:57:06Z", "pr_url": "https://github.com/trinodb/trino/pull/5402", "timeline": [{"oid": "f9c7e62744b77df7b7e8d1b55e8532c03f353309", "url": "https://github.com/trinodb/trino/commit/f9c7e62744b77df7b7e8d1b55e8532c03f353309", "message": "Hive ACID row-level insert and delete\n\nThis commit adds support for row-level insert and delete for Hive ACID tables,\nand product tests that verify that row-level insert (and delete where allowed)\nare working correctly for this test matrix:\n\n(partitioned | unpartitioned) X\n(bucketed | unbucketed) X\n(normal | insert-only) X\n(original files | non-original files) X\n(Presto inserts | Hive inserts) X\n(first insert | subsequent inserts) X\n(Presto deletes | Hive deletes) X\n(first delete | subsequent deletes) X\n(Hive selects to verify | Presto selects to verify)\n\nThe tests also verify that metadata delete still works correctly for non-ACID\ntables, and that row-level delete is always used for ACID tables. Hive ACID\ninsert and delete make metastore updates using the delayed commit paradigm\nprovided by SemiTransactionalHiveMetastore.\n\nACID insert and delete need four Hive metastore methods not previously\nused, and this commit adds the plumbing through the many metastore layers\nfor those methods.\n\nRecords to be deleted flow through HiveUpdatablePageSource, which feeds an OrcWriter\nthe three columns - - originalTransaction, bucketId, rowId - - that identify an\nACID row to be deleted. The writer builds the ACID delete_delta bucket, adding\nthe Orc ACID operation column specifying delete and the currentTransaction column\nto each row.\n\nA complete delete scan will in general read many Orc files from earlier transactions.\nThe delete implementation will create a HiveUpdatablePageSource for each file.\nEach will write a delete_delta file, distinguished by different statementIds.\nThese delete_delta bucket files and directories will be combined by the Hive\nACID compactor as the accumulate.\n\nACID insert is simpler than delete - - it just adds the 5 ACID columns needed\nto make insertion transactional, and creates delta directories to hold bucket files.", "committedDate": "2020-10-22T01:38:20Z", "type": "commit"}, {"oid": "f9c7e62744b77df7b7e8d1b55e8532c03f353309", "url": "https://github.com/trinodb/trino/commit/f9c7e62744b77df7b7e8d1b55e8532c03f353309", "message": "Hive ACID row-level insert and delete\n\nThis commit adds support for row-level insert and delete for Hive ACID tables,\nand product tests that verify that row-level insert (and delete where allowed)\nare working correctly for this test matrix:\n\n(partitioned | unpartitioned) X\n(bucketed | unbucketed) X\n(normal | insert-only) X\n(original files | non-original files) X\n(Presto inserts | Hive inserts) X\n(first insert | subsequent inserts) X\n(Presto deletes | Hive deletes) X\n(first delete | subsequent deletes) X\n(Hive selects to verify | Presto selects to verify)\n\nThe tests also verify that metadata delete still works correctly for non-ACID\ntables, and that row-level delete is always used for ACID tables. Hive ACID\ninsert and delete make metastore updates using the delayed commit paradigm\nprovided by SemiTransactionalHiveMetastore.\n\nACID insert and delete need four Hive metastore methods not previously\nused, and this commit adds the plumbing through the many metastore layers\nfor those methods.\n\nRecords to be deleted flow through HiveUpdatablePageSource, which feeds an OrcWriter\nthe three columns - - originalTransaction, bucketId, rowId - - that identify an\nACID row to be deleted. The writer builds the ACID delete_delta bucket, adding\nthe Orc ACID operation column specifying delete and the currentTransaction column\nto each row.\n\nA complete delete scan will in general read many Orc files from earlier transactions.\nThe delete implementation will create a HiveUpdatablePageSource for each file.\nEach will write a delete_delta file, distinguished by different statementIds.\nThese delete_delta bucket files and directories will be combined by the Hive\nACID compactor as the accumulate.\n\nACID insert is simpler than delete - - it just adds the 5 ACID columns needed\nto make insertion transactional, and creates delta directories to hold bucket files.", "committedDate": "2020-10-22T01:38:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc3NzYzMA==", "url": "https://github.com/trinodb/trino/pull/5402#discussion_r542777630", "bodyText": "Should this be moved before invoking the delegate?", "author": "findepi", "createdAt": "2020-12-14T20:58:13Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/cache/CachingHiveMetastore.java", "diffHunk": "@@ -943,6 +947,65 @@ public boolean isImpersonationEnabled()\n         return delegate.listTablePrivileges(databaseName, tableName, tableOwner, principal);\n     }\n \n+    @Override\n+    public long allocateWriteId(HiveIdentity identity, String dbName, String tableName, long transactionId)\n+    {\n+        return delegate.allocateWriteId(identity, dbName, tableName, transactionId);\n+    }\n+\n+    @Override\n+    public void acquireTableWriteLock(HiveIdentity identity, String queryId, long transactionId, String dbName, String tableName, DataOperationType operation, boolean isDynamicPartitionWrite)\n+    {\n+        delegate.acquireTableWriteLock(identity, queryId, transactionId, dbName, tableName, operation, isDynamicPartitionWrite);\n+    }\n+\n+    @Override\n+    public void updateTableWriteId(HiveIdentity identity, String dbName, String tableName, long transactionId, long writeId, OptionalLong rowCountChange)\n+    {\n+        try {\n+            delegate.updateTableWriteId(identity, dbName, tableName, transactionId, writeId, rowCountChange);\n+        }\n+        finally {\n+            invalidateTable(dbName, tableName);\n+        }\n+    }\n+\n+    @Override\n+    public void alterPartitions(HiveIdentity identity, String dbName, String tableName, List<Partition> partitions, long writeId)\n+    {\n+        identity = updateIdentity(identity);\n+        try {\n+            delegate.alterPartitions(identity, dbName, tableName, partitions, writeId);\n+        }\n+        finally {\n+            invalidatePartitionCache(dbName, tableName);\n+        }\n+    }\n+\n+    @Override\n+    public void addDynamicPartitions(HiveIdentity identity, String dbName, String tableName, List<String> partitionNames, long transactionId, long writeId, AcidOperation operation)\n+    {\n+        identity = updateIdentity(identity);\n+        try {\n+            delegate.addDynamicPartitions(identity, dbName, tableName, partitionNames, transactionId, writeId, operation);\n+        }\n+        finally {\n+            invalidatePartitionCache(dbName, tableName);\n+        }\n+    }\n+\n+    @Override\n+    public void alterTransactionalTable(HiveIdentity identity, Table table, long transactionId, long writeId, EnvironmentContext context, PrincipalPrivileges principalPrivileges)\n+    {\n+        try {\n+            delegate.alterTransactionalTable(identity, table, transactionId, writeId, context, principalPrivileges);\n+        }\n+        finally {\n+            identity = updateIdentity(identity);", "originalCommit": "f9c7e62744b77df7b7e8d1b55e8532c03f353309", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1NzQ2NzY0MQ==", "url": "https://github.com/trinodb/trino/pull/5402#discussion_r657467641", "bodyText": "What's the reason to call commit within cleanupQuery?\nwhat if\n\nquery is part of a longer transaction (we seem to commit everything too early)\nquery is cancelled/aborted/etc -- it seems we commit instead of rolling back\n\nplease help me understand\ncc @losipiuk", "author": "findepi", "createdAt": "2021-06-23T21:17:37Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/SemiTransactionalHiveMetastore.java", "diffHunk": "@@ -1068,14 +1204,15 @@ public synchronized void cleanupQuery(ConnectorSession session)\n         HiveIdentity identity = new HiveIdentity(session);\n         checkState(currentQueryId.equals(Optional.of(queryId)), \"Invalid query id %s while current query is\", queryId, currentQueryId);\n         Optional<HiveTransaction> transaction = currentHiveTransaction;\n-        currentQueryId = Optional.empty();\n-        currentHiveTransaction = Optional.empty();\n-        hiveTransactionSupplier = Optional.empty();\n \n         if (transaction.isEmpty()) {\n+            clearCurrentTransaction();\n             return;\n         }\n \n+        commit();", "originalCommit": "f9c7e62744b77df7b7e8d1b55e8532c03f353309", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}