{"pr_number": 5551, "pr_title": "Add sink.max-broadcast-buffer-size and set it to 200MB by default", "pr_createdAt": "2020-10-14T08:13:40Z", "pr_url": "https://github.com/trinodb/trino/pull/5551", "timeline": [{"oid": "670c7e4e036c61814f41e31ffc329627ee13b669", "url": "https://github.com/trinodb/trino/commit/670c7e4e036c61814f41e31ffc329627ee13b669", "message": "Add sink.max-broadcast-buffer-size and set it to 200MB by default\n\nBy default broadcast joins are chosen by CBO when build side\ndoes not exceed 100MB. It can happen that a build side is\ncollected from a single split (e.g dimension table). This means\nthat 32MB buffer can be fully filled on a single node and build side\ntasks become blocked. Scheduler will then force probe task-to-node\nassignments in order to continue with query execution. This\nprevnts scaling of probe side tasks to new nodes and also\nterminates lazy dynamic filters. Ideally, broadcast buffer\nshould never be overutilized.", "committedDate": "2020-10-14T08:16:16Z", "type": "commit"}, {"oid": "670c7e4e036c61814f41e31ffc329627ee13b669", "url": "https://github.com/trinodb/trino/commit/670c7e4e036c61814f41e31ffc329627ee13b669", "message": "Add sink.max-broadcast-buffer-size and set it to 200MB by default\n\nBy default broadcast joins are chosen by CBO when build side\ndoes not exceed 100MB. It can happen that a build side is\ncollected from a single split (e.g dimension table). This means\nthat 32MB buffer can be fully filled on a single node and build side\ntasks become blocked. Scheduler will then force probe task-to-node\nassignments in order to continue with query execution. This\nprevnts scaling of probe side tasks to new nodes and also\nterminates lazy dynamic filters. Ideally, broadcast buffer\nshould never be overutilized.", "committedDate": "2020-10-14T08:16:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwNzY3Mw==", "url": "https://github.com/trinodb/trino/pull/5551#discussion_r504507673", "bodyText": "is it better that we have it as max(sink.max-buffer-size, sink.max-broadcast-buffer-size)? and mention that in the documentation? so that if someone wants to bump the generic buffer size, the broadcast buffer also gets bumped up automatically.", "author": "rohangarg", "createdAt": "2020-10-14T08:47:02Z", "path": "presto-main/src/main/java/io/prestosql/execution/buffer/LazyOutputBuffer.java", "diffHunk": "@@ -164,7 +167,7 @@ public void setOutputBuffers(OutputBuffers newOutputBuffers)\n                         delegate = new PartitionedOutputBuffer(taskInstanceId, state, newOutputBuffers, maxBufferSize, systemMemoryContextSupplier, executor);\n                         break;\n                     case BROADCAST:\n-                        delegate = new BroadcastOutputBuffer(taskInstanceId, state, maxBufferSize, systemMemoryContextSupplier, executor, notifyStatusChanged);\n+                        delegate = new BroadcastOutputBuffer(taskInstanceId, state, maxBroadcastBufferSize, systemMemoryContextSupplier, executor, notifyStatusChanged);", "originalCommit": "670c7e4e036c61814f41e31ffc329627ee13b669", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDU2NzMzNQ==", "url": "https://github.com/trinodb/trino/pull/5551#discussion_r504567335", "bodyText": "I don't think it's needed to use max between the two. The reason is that amount of data in broadcast buffer should already be capped with CBO (e.g why to increase it above 200MB if CBO broadcast limit is still 100MB?). Additionally, using max would add some extra logic here (instead of simple toggle).\n\nmention that in the documentation?\n\ndocumentation will be in follow-up PR.", "author": "sopel39", "createdAt": "2020-10-14T10:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwNzY3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDYwMjY1Mw==", "url": "https://github.com/trinodb/trino/pull/5551#discussion_r504602653", "bodyText": "I don't think it's needed to use max between the two. The reason is that amount of data in broadcast buffer should already be capped with CBO (e.g why to increase it above 200MB if CBO broadcast limit is still 100MB?). Additionally, using max would add some extra logic here (instead of simple toggle).\n\nYes, that's right for the default case with CBO. What if someone is tuning the sink.max-buffer-size config? Ideally wouldn't we want the broadcast buffer to be atleast as much as normal buffer? (probably by just having an assertion that the max-broadcast-buffer >= max-buffer, but that could break the server start with existing configs). I am ok if you think that the documentation can cover these things.", "author": "rohangarg", "createdAt": "2020-10-14T11:29:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwNzY3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDYzMDEyNg==", "url": "https://github.com/trinodb/trino/pull/5551#discussion_r504630126", "bodyText": "Ideally wouldn't we want the broadcast buffer to be atleast as much as normal buffer?\n\nIn case of non-broadcast buffer it is important to ensure seamless flow of data without buffer trashing. Non-broadcast exchanges can transmit TBs of data.\nIn case of broadcast buffer it's more about storage of data so that build side tasks can start flushing. Broadcasted data would normally be tiny compared to hash-exchanged data.\n\nIdeally wouldn't we want the broadcast buffer to be atleast as much as normal buffer?\n\nI would consider 200MB a big buffer already. I doubt 200MB would be that beneficial for hash exchange (considering 32MB is sufficient in most of cases). IMO having 200MB buffer for hash exchange would mostly introduce additional memory overhead (in case probe side is \"slow\" to fetch data)", "author": "sopel39", "createdAt": "2020-10-14T12:19:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwNzY3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDY1NTAzOA==", "url": "https://github.com/trinodb/trino/pull/5551#discussion_r504655038", "bodyText": "Broadcasted data would normally be tiny compared to hash-exchanged data.\nI would consider 200MB a big buffer already. I doubt 200MB would be that beneficial for hash exchange (considering 32MB is sufficient in most of cases).\n\nYes, that's true.", "author": "rohangarg", "createdAt": "2020-10-14T12:58:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwNzY3Mw=="}], "type": "inlineReview", "revised_code": null}]}