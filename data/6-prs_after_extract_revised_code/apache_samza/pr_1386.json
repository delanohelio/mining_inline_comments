{"pr_number": 1386, "pr_title": "[SAMZA-2557] Adding support for nested rows access via dot path.", "pr_createdAt": "2020-06-18T21:46:02Z", "pr_url": "https://github.com/apache/samza/pull/1386", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0NjA2NA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r442546064", "bodyText": "Could we remove FILTER_ON_JOIN optimization ? It doesn't work well with remote joins. We should instead use the optimization for remote joins in the other PR that I sent.", "author": "atoomula", "createdAt": "2020-06-18T23:02:26Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java", "diffHunk": "@@ -141,20 +142,28 @@ public RelRoot plan(String query) {\n           .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n           .traitDefs(traitDefs)\n           .context(Contexts.EMPTY_CONTEXT)\n-          .costFactory(null)\n+          .programs(\n+              Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))", "originalCommit": "d41bc558c61f35e91537ff6f4787d0574b1f29f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzAyMzEwOA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r443023108", "bodyText": "@atoomula this rule is not really the main part of this work and I don't think we need to fix/choose now which rule should be used to handle filters or should or should not be pushed to table scan this is beyond the scope of this PR.\nThe main goal is to explore how we can handle the operator stack between the join and remote table scan.\nI added the rule to ensure that if a filter is there things works as expected and it seems it is working. But I would love to know what are the blind spot(s) I am missing about what work and does not work well with the remote table scan if you think this will help drive this issue. Thanks", "author": "b-slim", "createdAt": "2020-06-19T20:05:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0NjA2NA=="}], "type": "inlineReview", "revised_code": {"commit": "f08bf511ac36e5ca17eb1895edcd7da688dc95d0", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\nindex f983d1aee..17bc76369 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n\n@@ -114,56 +114,55 @@ public class QueryPlanner {\n   }\n \n   public RelRoot plan(String query) {\n-      SchemaPlus rootSchema = CalciteSchema.createRootSchema(true,false).plus();\n-      registerSourceSchemas(rootSchema);\n-\n-      List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions = udfMetadata.stream()\n-          .map(x -> new SamzaSqlScalarFunctionImpl(x))\n-          .collect(Collectors.toList());\n-\n-      final List<RelTraitDef> traitDefs = new ArrayList<>();\n-\n-      traitDefs.add(ConventionTraitDef.INSTANCE);\n-      traitDefs.add(RelCollationTraitDef.INSTANCE);\n-\n-      List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n-      sqlOperatorTables.add(new SamzaSqlOperatorTable());\n-      sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n-\n-      // Using lenient so that !=,%,- are allowed.\n-      FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n-          .parserConfig(SqlParser.configBuilder()\n-              .setLex(Lex.JAVA)\n-              .setConformance(SqlConformanceEnum.LENIENT)\n-              .setCaseSensitive(false) // Make Udfs case insensitive\n-              .build())\n-          .defaultSchema(rootSchema)\n-          .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n-          .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n-          .traitDefs(traitDefs)\n-          .context(Contexts.EMPTY_CONTEXT)\n-          .programs(\n-              Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))\n-          .build();\n-\n-      // Planner is a auto closable\n-      try (Planner planner = Frameworks.getPlanner(frameworkConfig)) {\n-        SqlNode sql = planner.parse(query);\n-        SqlNode validatedSql = planner.validate(sql);\n-        RelRoot relRoot = planner.rel(validatedSql);\n-        LOG.info(\"query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.ALL_ATTRIBUTES));\n-        RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n-        RelNode optRel = planner.transform(0, relTraitSet, relRoot.rel);\n-        if (!RelOptUtil.toString(relRoot.rel, SqlExplainLevel.NO_ATTRIBUTES)\n-            .equals(RelOptUtil.toString(optRel, SqlExplainLevel.NO_ATTRIBUTES))) {\n-          LOG.info(\"query plan Optimized:\\n\" + RelOptUtil.toString(optRel, SqlExplainLevel.ALL_ATTRIBUTES));\n-        }\n-        return relRoot.withRel(optRel);\n-      } catch (Exception e) {\n-        String errorMsg = SamzaSqlValidator.formatErrorString(query, e);\n-        LOG.error(errorMsg, e);\n-        throw new SamzaException(errorMsg, e);\n+    SchemaPlus rootSchema = CalciteSchema.createRootSchema(true, false).plus();\n+    registerSourceSchemas(rootSchema);\n+\n+    List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions =\n+        udfMetadata.stream().map(x -> new SamzaSqlScalarFunctionImpl(x)).collect(Collectors.toList());\n+\n+    final List<RelTraitDef> traitDefs = new ArrayList<>();\n+\n+    traitDefs.add(ConventionTraitDef.INSTANCE);\n+    traitDefs.add(RelCollationTraitDef.INSTANCE);\n+\n+    List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n+    sqlOperatorTables.add(new SamzaSqlOperatorTable());\n+    sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n+\n+    // Using lenient so that !=,%,- are allowed.\n+    FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n+        .parserConfig(SqlParser.configBuilder()\n+            .setLex(Lex.JAVA)\n+            .setConformance(SqlConformanceEnum.LENIENT)\n+            .setCaseSensitive(false) // Make Udfs case insensitive\n+            .build())\n+        .defaultSchema(rootSchema)\n+        .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n+        .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n+        .traitDefs(traitDefs)\n+        .context(Contexts.EMPTY_CONTEXT)\n+        .programs(\n+            Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))\n+        .build();\n+\n+    // Planner is a auto closable\n+    try (Planner planner = Frameworks.getPlanner(frameworkConfig)) {\n+      SqlNode sql = planner.parse(query);\n+      SqlNode validatedSql = planner.validate(sql);\n+      RelRoot relRoot = planner.rel(validatedSql);\n+      LOG.info(\"query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.ALL_ATTRIBUTES));\n+      RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n+      RelNode optRel = planner.transform(0, relTraitSet, relRoot.rel);\n+      if (!RelOptUtil.toString(relRoot.rel, SqlExplainLevel.NO_ATTRIBUTES)\n+          .equals(RelOptUtil.toString(optRel, SqlExplainLevel.NO_ATTRIBUTES))) {\n+        LOG.info(\"query plan Optimized:\\n\" + RelOptUtil.toString(optRel, SqlExplainLevel.ALL_ATTRIBUTES));\n       }\n+      return relRoot.withRel(optRel);\n+    } catch (Exception e) {\n+      String errorMsg = SamzaSqlValidator.formatErrorString(query, e);\n+      LOG.error(errorMsg, e);\n+      throw new SamzaException(errorMsg, e);\n+    }\n   }\n \n   public static SqlSchema getSourceSqlSchema(RelSchemaProvider relSchemaProvider) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYyMjkwMQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r443622901", "bodyText": "Looks like this is where the magic is happening, Can you add some comments describing what we are doing and why we are doing this?", "author": "srinipunuru", "createdAt": "2020-06-22T14:58:47Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/translator/JoinTranslator.java", "diffHunk": "@@ -141,8 +141,16 @@ void translate(final LogicalJoin join, final TranslatorContext translatorContext\n \n     if (tableNode.isRemoteTable()) {\n       String remoteTableName = tableNode.getSourceName();\n-      StreamTableJoinFunction joinFn = new SamzaSqlRemoteTableJoinFunction(context.getMsgConverter(remoteTableName),\n-          context.getTableKeyConverter(remoteTableName), streamNode, tableNode, join.getJoinType(), queryId);\n+      MessageStream operatorStack = context.getMessageStream(tableNode.getRelNode().getId());", "originalCommit": "6edd5247ba7a0b75dae167bcd4a8a445d2f3f2e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/translator/JoinTranslator.java b/samza-sql/src/main/java/org/apache/samza/sql/translator/JoinTranslator.java\nindex e8b9f5503..02c434d24 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/translator/JoinTranslator.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/translator/JoinTranslator.java\n\n@@ -141,16 +165,8 @@ class JoinTranslator {\n \n     if (tableNode.isRemoteTable()) {\n       String remoteTableName = tableNode.getSourceName();\n-      MessageStream operatorStack = context.getMessageStream(tableNode.getRelNode().getId());\n-      final StreamTableJoinFunction joinFn;\n-      if (operatorStack != null && operatorStack instanceof MessageStreamCollector) {\n-        joinFn = new SamzaSqlRemoteTableJoinFunction(context.getMsgConverter(remoteTableName),\n-            context.getTableKeyConverter(remoteTableName), streamNode, tableNode, join.getJoinType(), queryId,\n-            (MessageStreamCollector) operatorStack);\n-      } else {\n-        joinFn = new SamzaSqlRemoteTableJoinFunction(context.getMsgConverter(remoteTableName),\n-            context.getTableKeyConverter(remoteTableName), streamNode, tableNode, join.getJoinType(), queryId);\n-      }\n+      StreamTableJoinFunction joinFn = new SamzaSqlRemoteTableJoinFunction(context.getMsgConverter(remoteTableName),\n+          context.getTableKeyConverter(remoteTableName), streamNode, tableNode, join.getJoinType(), queryId);\n \n       return inputStream\n           .map(inputMetricsMF)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzMDEzOQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r443630139", "bodyText": "Can you add more comments on what we are doing here?", "author": "srinipunuru", "createdAt": "2020-06-22T15:08:58Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.sql.translator;\n+\n+import java.io.Closeable;\n+import java.io.Serializable;\n+import java.time.Duration;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Deque;\n+import java.util.function.Function;\n+import org.apache.samza.context.Context;\n+import org.apache.samza.operators.KV;\n+import org.apache.samza.operators.MessageStream;\n+import org.apache.samza.operators.OutputStream;\n+import org.apache.samza.operators.functions.AsyncFlatMapFunction;\n+import org.apache.samza.operators.functions.ClosableFunction;\n+import org.apache.samza.operators.functions.FilterFunction;\n+import org.apache.samza.operators.functions.FlatMapFunction;\n+import org.apache.samza.operators.functions.JoinFunction;\n+import org.apache.samza.operators.functions.MapFunction;\n+import org.apache.samza.operators.functions.SinkFunction;\n+import org.apache.samza.operators.functions.StreamTableJoinFunction;\n+import org.apache.samza.operators.windows.Window;\n+import org.apache.samza.operators.windows.WindowPane;\n+import org.apache.samza.serializers.KVSerde;\n+import org.apache.samza.serializers.Serde;\n+import org.apache.samza.sql.data.SamzaSqlRelMessage;\n+import org.apache.samza.table.Table;\n+\n+\n+/**\n+ * Collector of Map and Filter Samza Function, used to collect current call stack and trigger it when applying the join function.\n+ *\n+ * @TODO This class is a work around here to minimize the amount of code changes, but in an ideal world,\n+ * @TODO where we use Calcite planner in conventional way we can combine function when via translation of RelNodes.\n+ */\n+class MessageStreamCollector implements MessageStream<SamzaSqlRelMessage>, Serializable, Closeable {\n+\n+  private final Deque<MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>> _mapFnCallQueue =\n+      new ArrayDeque<>();\n+  private final Deque<ClosableFunction> _closingStack = new ArrayDeque<>();\n+\n+  @Override\n+  public <OM> MessageStream<OM> map(MapFunction<? super SamzaSqlRelMessage, ? extends OM> mapFn) {\n+    _mapFnCallQueue.offer((MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>) mapFn);\n+    return (MessageStream<OM>) this;\n+  }\n+\n+  @Override\n+  public MessageStream<SamzaSqlRelMessage> filter(FilterFunction<? super SamzaSqlRelMessage> filterFn) {\n+    _mapFnCallQueue.offer(new FilterMapAdapter(filterFn));\n+    return this;\n+  }\n+\n+   Function<SamzaSqlRelMessage, SamzaSqlRelMessage> getFunction(Context context) {\n+    Function<SamzaSqlRelMessage, SamzaSqlRelMessage> tailFn = null;\n+    while (!_mapFnCallQueue.isEmpty()) {", "originalCommit": "6edd5247ba7a0b75dae167bcd4a8a445d2f3f2e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU4NzU2OQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r444587569", "bodyText": "@srinipunuru added comments at the top of the class let me know if this still unclear.", "author": "b-slim", "createdAt": "2020-06-24T01:02:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzMDEzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "57954b0e1243ccc05362bb2a983274a3d76a5ad1", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java b/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\nindex 16ff4908f..1dbc689d1 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\n\n@@ -56,7 +56,8 @@ class MessageStreamCollector implements MessageStream<SamzaSqlRelMessage>, Seria\n \n   private final Deque<MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>> _mapFnCallQueue =\n       new ArrayDeque<>();\n-  private final Deque<ClosableFunction> _closingStack = new ArrayDeque<>();\n+\n+  private transient Function<Void, Void> closeFn = aVoid -> null;\n \n   @Override\n   public <OM> MessageStream<OM> map(MapFunction<? super SamzaSqlRelMessage, ? extends OM> mapFn) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzMTMxNg==", "url": "https://github.com/apache/samza/pull/1386#discussion_r443631316", "bodyText": "Can you add comments here as well on why this adapter is required and what it does?", "author": "srinipunuru", "createdAt": "2020-06-22T15:10:35Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.sql.translator;\n+\n+import java.io.Closeable;\n+import java.io.Serializable;\n+import java.time.Duration;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Deque;\n+import java.util.function.Function;\n+import org.apache.samza.context.Context;\n+import org.apache.samza.operators.KV;\n+import org.apache.samza.operators.MessageStream;\n+import org.apache.samza.operators.OutputStream;\n+import org.apache.samza.operators.functions.AsyncFlatMapFunction;\n+import org.apache.samza.operators.functions.ClosableFunction;\n+import org.apache.samza.operators.functions.FilterFunction;\n+import org.apache.samza.operators.functions.FlatMapFunction;\n+import org.apache.samza.operators.functions.JoinFunction;\n+import org.apache.samza.operators.functions.MapFunction;\n+import org.apache.samza.operators.functions.SinkFunction;\n+import org.apache.samza.operators.functions.StreamTableJoinFunction;\n+import org.apache.samza.operators.windows.Window;\n+import org.apache.samza.operators.windows.WindowPane;\n+import org.apache.samza.serializers.KVSerde;\n+import org.apache.samza.serializers.Serde;\n+import org.apache.samza.sql.data.SamzaSqlRelMessage;\n+import org.apache.samza.table.Table;\n+\n+\n+/**\n+ * Collector of Map and Filter Samza Function, used to collect current call stack and trigger it when applying the join function.\n+ *\n+ * @TODO This class is a work around here to minimize the amount of code changes, but in an ideal world,\n+ * @TODO where we use Calcite planner in conventional way we can combine function when via translation of RelNodes.\n+ */\n+class MessageStreamCollector implements MessageStream<SamzaSqlRelMessage>, Serializable, Closeable {\n+\n+  private final Deque<MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>> _mapFnCallQueue =\n+      new ArrayDeque<>();\n+  private final Deque<ClosableFunction> _closingStack = new ArrayDeque<>();\n+\n+  @Override\n+  public <OM> MessageStream<OM> map(MapFunction<? super SamzaSqlRelMessage, ? extends OM> mapFn) {\n+    _mapFnCallQueue.offer((MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>) mapFn);\n+    return (MessageStream<OM>) this;\n+  }\n+\n+  @Override\n+  public MessageStream<SamzaSqlRelMessage> filter(FilterFunction<? super SamzaSqlRelMessage> filterFn) {\n+    _mapFnCallQueue.offer(new FilterMapAdapter(filterFn));\n+    return this;\n+  }\n+\n+   Function<SamzaSqlRelMessage, SamzaSqlRelMessage> getFunction(Context context) {\n+    Function<SamzaSqlRelMessage, SamzaSqlRelMessage> tailFn = null;\n+    while (!_mapFnCallQueue.isEmpty()) {\n+      MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage> f = _mapFnCallQueue.poll();\n+      f.init(context);\n+      _closingStack.push(f);\n+      Function<SamzaSqlRelMessage, SamzaSqlRelMessage> current = x -> {\n+        if (x != null) {\n+          return f.apply(x);\n+        }\n+        return null;\n+      };\n+      if (tailFn == null) {\n+        tailFn = current;\n+      } else {\n+        tailFn = current.compose(tailFn);\n+      }\n+    }\n+    return tailFn == null ? Function.identity() : tailFn;\n+  }\n+\n+  private static class FilterMapAdapter implements MapFunction<SamzaSqlRelMessage, SamzaSqlRelMessage> {", "originalCommit": "6edd5247ba7a0b75dae167bcd4a8a445d2f3f2e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU4Nzc0NQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r444587745", "bodyText": "Added comments let me know if it is still unclear.", "author": "b-slim", "createdAt": "2020-06-24T01:03:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzYzMTMxNg=="}], "type": "inlineReview", "revised_code": {"commit": "57954b0e1243ccc05362bb2a983274a3d76a5ad1", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java b/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\nindex 16ff4908f..1dbc689d1 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\n\n@@ -56,7 +56,8 @@ class MessageStreamCollector implements MessageStream<SamzaSqlRelMessage>, Seria\n \n   private final Deque<MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>> _mapFnCallQueue =\n       new ArrayDeque<>();\n-  private final Deque<ClosableFunction> _closingStack = new ArrayDeque<>();\n+\n+  private transient Function<Void, Void> closeFn = aVoid -> null;\n \n   @Override\n   public <OM> MessageStream<OM> map(MapFunction<? super SamzaSqlRelMessage, ? extends OM> mapFn) {\n"}}, {"oid": "57954b0e1243ccc05362bb2a983274a3d76a5ad1", "url": "https://github.com/apache/samza/commit/57954b0e1243ccc05362bb2a983274a3d76a5ad1", "message": "adding more comments", "committedDate": "2020-06-24T00:04:10Z", "type": "forcePushed"}, {"oid": "957a084091d4257527d52ed1a76dc9d7d3d0fce1", "url": "https://github.com/apache/samza/commit/957a084091d4257527d52ed1a76dc9d7d3d0fce1", "message": "adding more comments", "committedDate": "2020-06-24T00:07:02Z", "type": "forcePushed"}, {"oid": "61205906f5aaef3de59d79c3fe8e9ce406d4a420", "url": "https://github.com/apache/samza/commit/61205906f5aaef3de59d79c3fe8e9ce406d4a420", "message": "adding more comments", "committedDate": "2020-06-24T00:56:54Z", "type": "forcePushed"}, {"oid": "76ad492812c00e85c13c8fe1270ff3893216f5ec", "url": "https://github.com/apache/samza/commit/76ad492812c00e85c13c8fe1270ff3893216f5ec", "message": "adding more comments", "committedDate": "2020-06-26T17:49:17Z", "type": "forcePushed"}, {"oid": "03bd7c3c512987cf3e4c856f4c687c4689c40fec", "url": "https://github.com/apache/samza/commit/03bd7c3c512987cf3e4c856f4c687c4689c40fec", "message": "refix the test", "committedDate": "2020-06-30T05:08:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4OTIzMA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r448989230", "bodyText": "I still do not get it. Why can't we use query optimization for remote tables and if we see a filter/projection between table (we can detect table vs stream in the optimizer rule) and join in the Calcite plan, push them up ?", "author": "atoomula", "createdAt": "2020-07-02T13:09:29Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.sql.translator;\n+\n+import java.io.Closeable;\n+import java.io.Serializable;\n+import java.time.Duration;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Deque;\n+import java.util.function.Function;\n+import org.apache.samza.context.Context;\n+import org.apache.samza.operators.KV;\n+import org.apache.samza.operators.MessageStream;\n+import org.apache.samza.operators.OutputStream;\n+import org.apache.samza.operators.functions.AsyncFlatMapFunction;\n+import org.apache.samza.operators.functions.FilterFunction;\n+import org.apache.samza.operators.functions.FlatMapFunction;\n+import org.apache.samza.operators.functions.JoinFunction;\n+import org.apache.samza.operators.functions.MapFunction;\n+import org.apache.samza.operators.functions.SinkFunction;\n+import org.apache.samza.operators.functions.StreamTableJoinFunction;\n+import org.apache.samza.operators.windows.Window;\n+import org.apache.samza.operators.windows.WindowPane;\n+import org.apache.samza.serializers.KVSerde;\n+import org.apache.samza.serializers.Serde;\n+import org.apache.samza.sql.data.SamzaSqlRelMessage;\n+import org.apache.samza.table.Table;\n+\n+\n+/**\n+ * Collector of Map and Filter Samza Functions to collect call stack on the top of Remote table.\n+ * This Collector will be used by Join operator and trigger it when applying the join function post lookup.\n+ *\n+ * Note that this is needed because the Remote Table can not expose a proper {@code MessageStream}.\n+ * It is a work around to minimize the amount of code changes of the current Query Translator {@link org.apache.samza.sql.translator.QueryTranslator},\n+ * But in an ideal world, we should use Calcite planner in conventional way we can combine function when via translation of RelNodes.", "originalCommit": "4ac2649e220345927a6d32c288a84ca1391dcf34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTA5NzYyMg==", "url": "https://github.com/apache/samza/pull/1386#discussion_r449097622", "bodyText": "The conventional way of using Calcite is pushing operator toward table scan as much as possible.\nThis PR does that by leveraging Calcite as is with minimal code changes or copy and past of some internal code.\nBy pushing some stuff up case remote table and some stuff down case remote table shows a clear disconnect and not clear design that a someone else beside the author of the work will be able to get it without spending hours stepping into the debugger code.\nThe other question how this will be better than current approach of composing map/filters and fuse it to join operator, don't you think it is more optimal to fuse all the lookup/project/filter within join as one operator ?\nAdding to that This way also, will enable a case where the join condition will be more than just key = c but will be able to add more conjunctions in the near future.\nIn my opinion this is the most clean way to work around the limitation of the remote table join operator with no major surgery and allowing pushing filters/projects and in the future handle richer join conditions.\nAgain the proper fix will be to adopt Calcite framework Convention pattern where an operator can be pushed inside another operator when going from logical to physical for instance in this case the Join will transformed to a new join node that knows how to translate the project and filters within it self. That is kind of what is happening now but without making this work a major surgery as someone has suggested.", "author": "b-slim", "createdAt": "2020-07-02T15:38:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4OTIzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTExNzU1MQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r455117551", "bodyText": "Ahh.. now I get it. If we have the following condition \"(p.key + 1) = pv.profileId\", we cannot really solve it with calcite rule change other than changing our translator code (one of which is what you did).", "author": "atoomula", "createdAt": "2020-07-15T14:55:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4OTIzMA=="}], "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java b/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\ndeleted file mode 100644\nindex 0ddc13699..000000000\n--- a/samza-sql/src/main/java/org/apache/samza/sql/translator/MessageStreamCollector.java\n+++ /dev/null\n\n@@ -1,214 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.samza.sql.translator;\n-\n-import java.io.Closeable;\n-import java.io.Serializable;\n-import java.time.Duration;\n-import java.util.ArrayDeque;\n-import java.util.Collection;\n-import java.util.Deque;\n-import java.util.function.Function;\n-import org.apache.samza.context.Context;\n-import org.apache.samza.operators.KV;\n-import org.apache.samza.operators.MessageStream;\n-import org.apache.samza.operators.OutputStream;\n-import org.apache.samza.operators.functions.AsyncFlatMapFunction;\n-import org.apache.samza.operators.functions.FilterFunction;\n-import org.apache.samza.operators.functions.FlatMapFunction;\n-import org.apache.samza.operators.functions.JoinFunction;\n-import org.apache.samza.operators.functions.MapFunction;\n-import org.apache.samza.operators.functions.SinkFunction;\n-import org.apache.samza.operators.functions.StreamTableJoinFunction;\n-import org.apache.samza.operators.windows.Window;\n-import org.apache.samza.operators.windows.WindowPane;\n-import org.apache.samza.serializers.KVSerde;\n-import org.apache.samza.serializers.Serde;\n-import org.apache.samza.sql.data.SamzaSqlRelMessage;\n-import org.apache.samza.table.Table;\n-\n-\n-/**\n- * Collector of Map and Filter Samza Functions to collect call stack on the top of Remote table.\n- * This Collector will be used by Join operator and trigger it when applying the join function post lookup.\n- *\n- * Note that this is needed because the Remote Table can not expose a proper {@code MessageStream}.\n- * It is a work around to minimize the amount of code changes of the current Query Translator {@link org.apache.samza.sql.translator.QueryTranslator},\n- * But in an ideal world, we should use Calcite planner in conventional way we can combine function when via translation of RelNodes.\n- */\n-class MessageStreamCollector implements MessageStream<SamzaSqlRelMessage>, Serializable, Closeable {\n-\n-  /**\n-   * Queue First in First to be Fired order of the operators on the top of Remote Table Scan.\n-   */\n-  private final Deque<MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>> mapFnCallQueue =\n-      new ArrayDeque<>();\n-\n-  /**\n-   * Function to chain the call to close from each operator.\n-   */\n-  private transient Function<Void, Void> closeFn = aVoid -> null;\n-\n-  @Override\n-  public <OM> MessageStream<OM> map(MapFunction<? super SamzaSqlRelMessage, ? extends OM> mapFn) {\n-    mapFnCallQueue.offer((MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage>) mapFn);\n-    return (MessageStream<OM>) this;\n-  }\n-\n-  @Override\n-  public MessageStream<SamzaSqlRelMessage> filter(FilterFunction<? super SamzaSqlRelMessage> filterFn) {\n-    mapFnCallQueue.offer(new FilterMapAdapter(filterFn));\n-    return this;\n-  }\n-\n-  /**\n-   * This function is called by the join operator on run time to apply filter and projects post join lookup.\n-   *\n-   * @param context Samza Execution Context\n-   * @return {code null} case filter reject the row, Samza Relational Record as it goes via Projects.\n-   */\n-  Function<SamzaSqlRelMessage, SamzaSqlRelMessage> getFunction(Context context) {\n-    Function<SamzaSqlRelMessage, SamzaSqlRelMessage> tailFn = null;\n-    Function<Void, Void> intFn = aVoid -> null; // Projects and Filters both need to be initialized.\n-    closeFn = aVoid -> null;\n-    // At this point we have a the queue of operator, where first in is the first operator on top of TableScan.\n-    while (!mapFnCallQueue.isEmpty()) {\n-      MapFunction<? super SamzaSqlRelMessage, ? extends SamzaSqlRelMessage> f = mapFnCallQueue.poll();\n-      intFn = intFn.andThen((aVoid) -> {\n-        f.init(context);\n-        return null;\n-      });\n-      closeFn.andThen((aVoid) -> {\n-        f.close();\n-        return null;\n-      });\n-\n-      Function<SamzaSqlRelMessage, SamzaSqlRelMessage> current = x -> x == null ? null : f.apply(x);\n-      if (tailFn == null) {\n-        tailFn = current;\n-      } else {\n-        tailFn = current.compose(tailFn);\n-      }\n-    }\n-    // TODO TBH not sure about this need to check if Samza Framework will be okay with late init call.\n-    intFn.apply(null); // Init call has to happen here.\n-    return tailFn == null ? Function.identity() : tailFn;\n-  }\n-\n-  /**\n-   * Filter adapter is used to compose filters with {@code MapFunction<SamzaSqlRelMessage, SamzaSqlRelMessage>}\n-   * Filter function will return {@code null} when input is {@code null} or filter condition reject current row.\n-   */\n-  private static class FilterMapAdapter implements MapFunction<SamzaSqlRelMessage, SamzaSqlRelMessage> {\n-    private final FilterFunction<? super SamzaSqlRelMessage> filterFn;\n-\n-    private FilterMapAdapter(FilterFunction<? super SamzaSqlRelMessage> filterFn) {\n-      this.filterFn = filterFn;\n-    }\n-\n-    @Override\n-    public SamzaSqlRelMessage apply(SamzaSqlRelMessage message) {\n-      if (message != null && filterFn.apply(message)) {\n-        return message;\n-      }\n-      // null on case no match\n-      return null;\n-    }\n-\n-    @Override\n-    public void close() {\n-      filterFn.close();\n-    }\n-\n-    @Override\n-    public void init(Context context) {\n-      filterFn.init(context);\n-    }\n-  }\n-\n-  @Override\n-  public void close() {\n-    if (closeFn != null) {\n-      closeFn.apply(null);\n-    }\n-  }\n-\n-  @Override\n-  public <OM> MessageStream<OM> flatMap(FlatMapFunction<? super SamzaSqlRelMessage, ? extends OM> flatMapFn) {\n-    return null;\n-  }\n-\n-  @Override\n-  public <OM> MessageStream<OM> flatMapAsync(\n-      AsyncFlatMapFunction<? super SamzaSqlRelMessage, ? extends OM> asyncFlatMapFn) {\n-    return null;\n-  }\n-\n-  @Override\n-  public void sink(SinkFunction<? super SamzaSqlRelMessage> sinkFn) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public MessageStream<SamzaSqlRelMessage> sendTo(OutputStream<SamzaSqlRelMessage> outputStream) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public <K, WV> MessageStream<WindowPane<K, WV>> window(Window<SamzaSqlRelMessage, K, WV> window, String id) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public <K, OM, JM> MessageStream<JM> join(MessageStream<OM> otherStream,\n-      JoinFunction<? extends K, ? super SamzaSqlRelMessage, ? super OM, ? extends JM> joinFn, Serde<K> keySerde,\n-      Serde<SamzaSqlRelMessage> messageSerde, Serde<OM> otherMessageSerde, Duration ttl, String id) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public <K, R extends KV, JM> MessageStream<JM> join(Table<R> table,\n-      StreamTableJoinFunction<? extends K, ? super SamzaSqlRelMessage, ? super R, ? extends JM> joinFn,\n-      Object... args) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public MessageStream<SamzaSqlRelMessage> merge(\n-      Collection<? extends MessageStream<? extends SamzaSqlRelMessage>> otherStreams) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public <K, V> MessageStream<KV<K, V>> partitionBy(MapFunction<? super SamzaSqlRelMessage, ? extends K> keyExtractor,\n-      MapFunction<? super SamzaSqlRelMessage, ? extends V> valueExtractor, KVSerde<K, V> serde, String id) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public <K, V> MessageStream<KV<K, V>> sendTo(Table<KV<K, V>> table, Object... args) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-\n-  @Override\n-  public MessageStream<SamzaSqlRelMessage> broadcast(Serde<SamzaSqlRelMessage> serde, String id) {\n-    throw new IllegalStateException(\"Not valid state\");\n-  }\n-}\n"}}, {"oid": "f08bf511ac36e5ca17eb1895edcd7da688dc95d0", "url": "https://github.com/apache/samza/commit/f08bf511ac36e5ca17eb1895edcd7da688dc95d0", "message": "fix java doc and minor change on the type cast\n\nNot sure what this test is testing for it is a regular join between Stream and local table", "committedDate": "2020-07-02T17:21:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyNzE3MQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457127171", "bodyText": "Just curious, is there any reason to set caching to false ?", "author": "atoomula", "createdAt": "2020-07-20T07:24:29Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java", "diffHunk": "@@ -110,46 +114,50 @@ private void registerSourceSchemas(SchemaPlus rootSchema) {\n   }\n \n   public RelRoot plan(String query) {\n-    try {\n-      Connection connection = DriverManager.getConnection(\"jdbc:calcite:\");\n-      CalciteConnection calciteConnection = connection.unwrap(CalciteConnection.class);\n-      SchemaPlus rootSchema = calciteConnection.getRootSchema();\n-      registerSourceSchemas(rootSchema);\n-\n-      List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions = udfMetadata.stream()\n-          .map(x -> new SamzaSqlScalarFunctionImpl(x))\n-          .collect(Collectors.toList());\n-\n-      final List<RelTraitDef> traitDefs = new ArrayList<>();\n-\n-      traitDefs.add(ConventionTraitDef.INSTANCE);\n-      traitDefs.add(RelCollationTraitDef.INSTANCE);\n-\n-      List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n-      sqlOperatorTables.add(new SamzaSqlOperatorTable());\n-      sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n-\n-      // Using lenient so that !=,%,- are allowed.\n-      FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n-          .parserConfig(SqlParser.configBuilder()\n-              .setLex(Lex.JAVA)\n-              .setConformance(SqlConformanceEnum.LENIENT)\n-              .setCaseSensitive(false) // Make Udfs case insensitive\n-              .build())\n-          .defaultSchema(rootSchema)\n-          .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n-          .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n-          .traitDefs(traitDefs)\n-          .context(Contexts.EMPTY_CONTEXT)\n-          .costFactory(null)\n-          .build();\n-      Planner planner = Frameworks.getPlanner(frameworkConfig);\n-\n+    SchemaPlus rootSchema = CalciteSchema.createRootSchema(true, false).plus();", "originalCommit": "9938a74ab4db17141dd8ed4eb3322dff5f3e6462", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwMjQ4OA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457602488", "bodyText": "We do not need caching, it is a historic optimization flag that most of cases not really needed because schema changes all the time. In fact that is the default in Calcite.", "author": "b-slim", "createdAt": "2020-07-20T18:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyNzE3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\nindex 17bc76369..767df43ec 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n\n@@ -113,51 +121,87 @@ public class QueryPlanner {\n     }\n   }\n \n+  private Planner getPlanner() {\n+    Planner planner = null;\n+    try {\n+      Connection connection = DriverManager.getConnection(\"jdbc:calcite:\");\n+      CalciteConnection calciteConnection = connection.unwrap(CalciteConnection.class);\n+      SchemaPlus rootSchema = calciteConnection.getRootSchema();\n+      registerSourceSchemas(rootSchema);\n+\n+      List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions = udfMetadata.stream()\n+          .map(SamzaSqlScalarFunctionImpl::new)\n+          .collect(Collectors.toList());\n+\n+      final List<RelTraitDef> traitDefs = new ArrayList<>();\n+\n+      traitDefs.add(ConventionTraitDef.INSTANCE);\n+      traitDefs.add(RelCollationTraitDef.INSTANCE);\n+\n+      List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n+      sqlOperatorTables.add(new SamzaSqlOperatorTable());\n+      sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n+\n+      // TODO: Introduce a pluggable rule factory.\n+      List<RelOptRule> rules = ImmutableList.of(\n+          FilterProjectTransposeRule.INSTANCE,\n+          ProjectMergeRule.INSTANCE,\n+          new SamzaSqlFilterRemoteJoinRule.SamzaSqlFilterIntoRemoteJoinRule(true, RelFactories.LOGICAL_BUILDER,\n+          systemStreamConfigBySource));\n+\n+      // Using lenient so that !=,%,- are allowed.\n+      FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n+          .parserConfig(SqlParser.configBuilder()\n+              .setLex(Lex.JAVA)\n+              .setConformance(SqlConformanceEnum.LENIENT)\n+              .setCaseSensitive(false) // Make Udfs case insensitive\n+              .build())\n+          .defaultSchema(rootSchema)\n+          .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n+          .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n+          .traitDefs(traitDefs)\n+          .programs(Programs.hep(rules, true, DefaultRelMetadataProvider.INSTANCE))\n+          .build();\n+      planner = Frameworks.getPlanner(frameworkConfig);\n+      return planner;\n+    } catch (Exception e) {\n+      String errorMsg = \"Failed to create planner.\";\n+      LOG.error(errorMsg, e);\n+      if (planner != null) {\n+        planner.close();\n+      }\n+      throw new SamzaException(errorMsg, e);\n+    }\n+  }\n+\n+  private RelRoot optimize(Planner planner, RelRoot relRoot) {\n+    RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n+    try {\n+      RelRoot optimizedRelRoot =\n+          RelRoot.of(planner.transform(0, relTraitSet, relRoot.project()), SqlKind.SELECT);\n+      LOG.info(\"query plan with optimization:\\n\"\n+          + RelOptUtil.toString(optimizedRelRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES));\n+      return optimizedRelRoot;\n+    } catch (Exception e) {\n+      String errorMsg =\n+          \"Error while optimizing query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES);\n+      LOG.error(errorMsg, e);\n+      throw new SamzaException(errorMsg, e);\n+    }\n+  }\n+\n   public RelRoot plan(String query) {\n-    SchemaPlus rootSchema = CalciteSchema.createRootSchema(true, false).plus();\n-    registerSourceSchemas(rootSchema);\n-\n-    List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions =\n-        udfMetadata.stream().map(x -> new SamzaSqlScalarFunctionImpl(x)).collect(Collectors.toList());\n-\n-    final List<RelTraitDef> traitDefs = new ArrayList<>();\n-\n-    traitDefs.add(ConventionTraitDef.INSTANCE);\n-    traitDefs.add(RelCollationTraitDef.INSTANCE);\n-\n-    List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n-    sqlOperatorTables.add(new SamzaSqlOperatorTable());\n-    sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n-\n-    // Using lenient so that !=,%,- are allowed.\n-    FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n-        .parserConfig(SqlParser.configBuilder()\n-            .setLex(Lex.JAVA)\n-            .setConformance(SqlConformanceEnum.LENIENT)\n-            .setCaseSensitive(false) // Make Udfs case insensitive\n-            .build())\n-        .defaultSchema(rootSchema)\n-        .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n-        .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n-        .traitDefs(traitDefs)\n-        .context(Contexts.EMPTY_CONTEXT)\n-        .programs(\n-            Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))\n-        .build();\n-\n-    // Planner is a auto closable\n-    try (Planner planner = Frameworks.getPlanner(frameworkConfig)) {\n+    try (Planner planner = getPlanner()) {\n       SqlNode sql = planner.parse(query);\n       SqlNode validatedSql = planner.validate(sql);\n       RelRoot relRoot = planner.rel(validatedSql);\n-      LOG.info(\"query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.ALL_ATTRIBUTES));\n-      RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n-      RelNode optRel = planner.transform(0, relTraitSet, relRoot.rel);\n-      if (!RelOptUtil.toString(relRoot.rel, SqlExplainLevel.NO_ATTRIBUTES)\n-          .equals(RelOptUtil.toString(optRel, SqlExplainLevel.NO_ATTRIBUTES))) {\n-        LOG.info(\"query plan Optimized:\\n\" + RelOptUtil.toString(optRel, SqlExplainLevel.ALL_ATTRIBUTES));\n+      LOG.info(\n+          \"query plan without optimization:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES));\n+      if (!isQueryPlanOptimizerEnabled) {\n+        LOG.info(\"Skipping query optimization as it is disabled.\");\n+        return relRoot;\n       }\n-      return relRoot.withRel(optRel);\n+      return optimize(planner, relRoot);\n     } catch (Exception e) {\n       String errorMsg = SamzaSqlValidator.formatErrorString(query, e);\n       LOG.error(errorMsg, e);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyOTAwOQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457129009", "bodyText": "Could you pull in the latest master branch code ? I have pushed Query optimization code which conflicts with your changes.", "author": "atoomula", "createdAt": "2020-07-20T07:27:14Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java", "diffHunk": "@@ -110,46 +114,50 @@ private void registerSourceSchemas(SchemaPlus rootSchema) {\n   }\n \n   public RelRoot plan(String query) {\n-    try {\n-      Connection connection = DriverManager.getConnection(\"jdbc:calcite:\");\n-      CalciteConnection calciteConnection = connection.unwrap(CalciteConnection.class);\n-      SchemaPlus rootSchema = calciteConnection.getRootSchema();\n-      registerSourceSchemas(rootSchema);\n-\n-      List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions = udfMetadata.stream()\n-          .map(x -> new SamzaSqlScalarFunctionImpl(x))\n-          .collect(Collectors.toList());\n-\n-      final List<RelTraitDef> traitDefs = new ArrayList<>();\n-\n-      traitDefs.add(ConventionTraitDef.INSTANCE);\n-      traitDefs.add(RelCollationTraitDef.INSTANCE);\n-\n-      List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n-      sqlOperatorTables.add(new SamzaSqlOperatorTable());\n-      sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n-\n-      // Using lenient so that !=,%,- are allowed.\n-      FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n-          .parserConfig(SqlParser.configBuilder()\n-              .setLex(Lex.JAVA)\n-              .setConformance(SqlConformanceEnum.LENIENT)\n-              .setCaseSensitive(false) // Make Udfs case insensitive\n-              .build())\n-          .defaultSchema(rootSchema)\n-          .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n-          .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n-          .traitDefs(traitDefs)\n-          .context(Contexts.EMPTY_CONTEXT)\n-          .costFactory(null)\n-          .build();\n-      Planner planner = Frameworks.getPlanner(frameworkConfig);\n-\n+    SchemaPlus rootSchema = CalciteSchema.createRootSchema(true, false).plus();\n+    registerSourceSchemas(rootSchema);\n+\n+    List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions =\n+        udfMetadata.stream().map(x -> new SamzaSqlScalarFunctionImpl(x)).collect(Collectors.toList());\n+\n+    final List<RelTraitDef> traitDefs = new ArrayList<>();\n+\n+    traitDefs.add(ConventionTraitDef.INSTANCE);\n+    traitDefs.add(RelCollationTraitDef.INSTANCE);\n+\n+    List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n+    sqlOperatorTables.add(new SamzaSqlOperatorTable());\n+    sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n+\n+    // Using lenient so that !=,%,- are allowed.\n+    FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n+        .parserConfig(SqlParser.configBuilder()\n+            .setLex(Lex.JAVA)\n+            .setConformance(SqlConformanceEnum.LENIENT)\n+            .setCaseSensitive(false) // Make Udfs case insensitive\n+            .build())\n+        .defaultSchema(rootSchema)\n+        .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n+        .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n+        .traitDefs(traitDefs)\n+        .context(Contexts.EMPTY_CONTEXT)\n+        .programs(\n+            Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))\n+        .build();\n+\n+    // Planner is a auto closable\n+    try (Planner planner = Frameworks.getPlanner(frameworkConfig)) {\n       SqlNode sql = planner.parse(query);\n       SqlNode validatedSql = planner.validate(sql);\n       RelRoot relRoot = planner.rel(validatedSql);\n       LOG.info(\"query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.ALL_ATTRIBUTES));\n-      return relRoot;\n+      RelTraitSet relTraitSet = RelTraitSet.createEmpty();", "originalCommit": "9938a74ab4db17141dd8ed4eb3322dff5f3e6462", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\nindex 17bc76369..767df43ec 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/planner/QueryPlanner.java\n\n@@ -113,51 +121,87 @@ public class QueryPlanner {\n     }\n   }\n \n+  private Planner getPlanner() {\n+    Planner planner = null;\n+    try {\n+      Connection connection = DriverManager.getConnection(\"jdbc:calcite:\");\n+      CalciteConnection calciteConnection = connection.unwrap(CalciteConnection.class);\n+      SchemaPlus rootSchema = calciteConnection.getRootSchema();\n+      registerSourceSchemas(rootSchema);\n+\n+      List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions = udfMetadata.stream()\n+          .map(SamzaSqlScalarFunctionImpl::new)\n+          .collect(Collectors.toList());\n+\n+      final List<RelTraitDef> traitDefs = new ArrayList<>();\n+\n+      traitDefs.add(ConventionTraitDef.INSTANCE);\n+      traitDefs.add(RelCollationTraitDef.INSTANCE);\n+\n+      List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n+      sqlOperatorTables.add(new SamzaSqlOperatorTable());\n+      sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n+\n+      // TODO: Introduce a pluggable rule factory.\n+      List<RelOptRule> rules = ImmutableList.of(\n+          FilterProjectTransposeRule.INSTANCE,\n+          ProjectMergeRule.INSTANCE,\n+          new SamzaSqlFilterRemoteJoinRule.SamzaSqlFilterIntoRemoteJoinRule(true, RelFactories.LOGICAL_BUILDER,\n+          systemStreamConfigBySource));\n+\n+      // Using lenient so that !=,%,- are allowed.\n+      FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n+          .parserConfig(SqlParser.configBuilder()\n+              .setLex(Lex.JAVA)\n+              .setConformance(SqlConformanceEnum.LENIENT)\n+              .setCaseSensitive(false) // Make Udfs case insensitive\n+              .build())\n+          .defaultSchema(rootSchema)\n+          .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n+          .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n+          .traitDefs(traitDefs)\n+          .programs(Programs.hep(rules, true, DefaultRelMetadataProvider.INSTANCE))\n+          .build();\n+      planner = Frameworks.getPlanner(frameworkConfig);\n+      return planner;\n+    } catch (Exception e) {\n+      String errorMsg = \"Failed to create planner.\";\n+      LOG.error(errorMsg, e);\n+      if (planner != null) {\n+        planner.close();\n+      }\n+      throw new SamzaException(errorMsg, e);\n+    }\n+  }\n+\n+  private RelRoot optimize(Planner planner, RelRoot relRoot) {\n+    RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n+    try {\n+      RelRoot optimizedRelRoot =\n+          RelRoot.of(planner.transform(0, relTraitSet, relRoot.project()), SqlKind.SELECT);\n+      LOG.info(\"query plan with optimization:\\n\"\n+          + RelOptUtil.toString(optimizedRelRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES));\n+      return optimizedRelRoot;\n+    } catch (Exception e) {\n+      String errorMsg =\n+          \"Error while optimizing query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES);\n+      LOG.error(errorMsg, e);\n+      throw new SamzaException(errorMsg, e);\n+    }\n+  }\n+\n   public RelRoot plan(String query) {\n-    SchemaPlus rootSchema = CalciteSchema.createRootSchema(true, false).plus();\n-    registerSourceSchemas(rootSchema);\n-\n-    List<SamzaSqlScalarFunctionImpl> samzaSqlFunctions =\n-        udfMetadata.stream().map(x -> new SamzaSqlScalarFunctionImpl(x)).collect(Collectors.toList());\n-\n-    final List<RelTraitDef> traitDefs = new ArrayList<>();\n-\n-    traitDefs.add(ConventionTraitDef.INSTANCE);\n-    traitDefs.add(RelCollationTraitDef.INSTANCE);\n-\n-    List<SqlOperatorTable> sqlOperatorTables = new ArrayList<>();\n-    sqlOperatorTables.add(new SamzaSqlOperatorTable());\n-    sqlOperatorTables.add(new SamzaSqlUdfOperatorTable(samzaSqlFunctions));\n-\n-    // Using lenient so that !=,%,- are allowed.\n-    FrameworkConfig frameworkConfig = Frameworks.newConfigBuilder()\n-        .parserConfig(SqlParser.configBuilder()\n-            .setLex(Lex.JAVA)\n-            .setConformance(SqlConformanceEnum.LENIENT)\n-            .setCaseSensitive(false) // Make Udfs case insensitive\n-            .build())\n-        .defaultSchema(rootSchema)\n-        .operatorTable(new ChainedSqlOperatorTable(sqlOperatorTables))\n-        .sqlToRelConverterConfig(SqlToRelConverter.Config.DEFAULT)\n-        .traitDefs(traitDefs)\n-        .context(Contexts.EMPTY_CONTEXT)\n-        .programs(\n-            Programs.hep(ImmutableList.of(FilterJoinRule.FILTER_ON_JOIN), true, DefaultRelMetadataProvider.INSTANCE))\n-        .build();\n-\n-    // Planner is a auto closable\n-    try (Planner planner = Frameworks.getPlanner(frameworkConfig)) {\n+    try (Planner planner = getPlanner()) {\n       SqlNode sql = planner.parse(query);\n       SqlNode validatedSql = planner.validate(sql);\n       RelRoot relRoot = planner.rel(validatedSql);\n-      LOG.info(\"query plan:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.ALL_ATTRIBUTES));\n-      RelTraitSet relTraitSet = RelTraitSet.createEmpty();\n-      RelNode optRel = planner.transform(0, relTraitSet, relRoot.rel);\n-      if (!RelOptUtil.toString(relRoot.rel, SqlExplainLevel.NO_ATTRIBUTES)\n-          .equals(RelOptUtil.toString(optRel, SqlExplainLevel.NO_ATTRIBUTES))) {\n-        LOG.info(\"query plan Optimized:\\n\" + RelOptUtil.toString(optRel, SqlExplainLevel.ALL_ATTRIBUTES));\n+      LOG.info(\n+          \"query plan without optimization:\\n\" + RelOptUtil.toString(relRoot.rel, SqlExplainLevel.EXPPLAN_ATTRIBUTES));\n+      if (!isQueryPlanOptimizerEnabled) {\n+        LOG.info(\"Skipping query optimization as it is disabled.\");\n+        return relRoot;\n       }\n-      return relRoot.withRel(optRel);\n+      return optimize(planner, relRoot);\n     } catch (Exception e) {\n       String errorMsg = SamzaSqlValidator.formatErrorString(query, e);\n       LOG.error(errorMsg, e);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQyNzQ0NA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457427444", "bodyText": "Is this truly backward compatible with with the existing GetNestedField udf ? Does this support all the types that are tested in GetSqlFieldUdf ? Esp nested map and array. https://github.com/apache/samza/blob/dcd4b558a2c702f5b5a320fdb9d0c3fcadabd09b/samza-sql/src/test/java/org/apache/samza/sql/fn/TestGetSqlFieldUdf.java", "author": "atoomula", "createdAt": "2020-07-20T14:17:32Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/udf/GetNestedField.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.sql.udf;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import java.lang.reflect.Type;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.calcite.adapter.enumerable.CallImplementor;\n+import org.apache.calcite.adapter.enumerable.EnumUtils;\n+import org.apache.calcite.adapter.enumerable.NullPolicy;\n+import org.apache.calcite.adapter.enumerable.RexImpTable;\n+import org.apache.calcite.jdbc.JavaTypeFactoryImpl;\n+import org.apache.calcite.linq4j.tree.ConstantExpression;\n+import org.apache.calcite.linq4j.tree.Expression;\n+import org.apache.calcite.linq4j.tree.ExpressionType;\n+import org.apache.calcite.linq4j.tree.Expressions;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeFactory;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.calcite.schema.Function;\n+import org.apache.calcite.schema.FunctionParameter;\n+import org.apache.calcite.schema.ImplementableFunction;\n+import org.apache.calcite.schema.ScalarFunction;\n+import org.apache.calcite.sql.SqlCallBinding;\n+import org.apache.calcite.sql.SqlFunction;\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.SqlOperandCountRange;\n+import org.apache.calcite.sql.SqlOperatorBinding;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.type.OperandTypes;\n+import org.apache.calcite.sql.type.SqlOperandCountRanges;\n+import org.apache.calcite.sql.type.SqlTypeName;\n+import org.apache.calcite.sql.validate.SqlUserDefinedFunction;\n+\n+import static org.apache.calcite.schema.impl.ReflectiveFunctionBase.builder;\n+\n+\n+/**\n+ * Operator to extract nested Rows or Fields form a struct row type using a dotted path.\n+ * The goal of this operator is two-fold.\n+ * First it is a temporary fix for https://issues.apache.org/jira/browse/CALCITE-4065 to extract a row from a row.\n+ * Second it will enable smooth backward compatible migration from existing udf that relies on legacy row format.", "originalCommit": "9938a74ab4db17141dd8ed4eb3322dff5f3e6462", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwMTc0MA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457601740", "bodyText": "It should be I run all the tests and it passed, if you have any test or use case in mind please bring it up. But this should work with all the type and will enforce type checking as oppose to the old udf that is type less in bunch corner cases. In nutshell some failure will happen if type does not match.", "author": "b-slim", "createdAt": "2020-07-20T18:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQyNzQ0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYxMjY1MQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457612651", "bodyText": "In the above test TestGetSqlFieldUdf, can you take a look to see if it handles tests starting from testMapAtLastField to testArrayAtAllIntermediateFields ? I don't think we have any tests in TestSamzaSqlEndToEnd that test such complex types at intermediate fields.", "author": "atoomula", "createdAt": "2020-07-20T18:35:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQyNzQ0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI4MDcyNA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r458280724", "bodyText": "Added more tests for this to mimic the unit tests. As you can see this will not include on how legacy handles map. Thus will need for sure to re-write such statement when going with new releases.", "author": "b-slim", "createdAt": "2020-07-21T17:49:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQyNzQ0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI4MTA4MA==", "url": "https://github.com/apache/samza/pull/1386#discussion_r458281080", "bodyText": "see 3e95902", "author": "b-slim", "createdAt": "2020-07-21T17:50:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQyNzQ0NA=="}], "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/udf/GetNestedField.java b/samza-sql/src/main/java/org/apache/samza/sql/udf/GetNestedField.java\ndeleted file mode 100644\nindex c326fefd6..000000000\n--- a/samza-sql/src/main/java/org/apache/samza/sql/udf/GetNestedField.java\n+++ /dev/null\n\n@@ -1,166 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.apache.samza.sql.udf;\n-\n-import com.google.common.base.Preconditions;\n-import com.google.common.collect.ImmutableList;\n-import java.lang.reflect.Type;\n-import java.util.Arrays;\n-import java.util.List;\n-import org.apache.calcite.adapter.enumerable.CallImplementor;\n-import org.apache.calcite.adapter.enumerable.EnumUtils;\n-import org.apache.calcite.adapter.enumerable.NullPolicy;\n-import org.apache.calcite.adapter.enumerable.RexImpTable;\n-import org.apache.calcite.jdbc.JavaTypeFactoryImpl;\n-import org.apache.calcite.linq4j.tree.ConstantExpression;\n-import org.apache.calcite.linq4j.tree.Expression;\n-import org.apache.calcite.linq4j.tree.ExpressionType;\n-import org.apache.calcite.linq4j.tree.Expressions;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rel.type.RelDataTypeFactory;\n-import org.apache.calcite.rel.type.RelDataTypeField;\n-import org.apache.calcite.schema.Function;\n-import org.apache.calcite.schema.FunctionParameter;\n-import org.apache.calcite.schema.ImplementableFunction;\n-import org.apache.calcite.schema.ScalarFunction;\n-import org.apache.calcite.sql.SqlCallBinding;\n-import org.apache.calcite.sql.SqlFunction;\n-import org.apache.calcite.sql.SqlIdentifier;\n-import org.apache.calcite.sql.SqlNode;\n-import org.apache.calcite.sql.SqlOperandCountRange;\n-import org.apache.calcite.sql.SqlOperatorBinding;\n-import org.apache.calcite.sql.parser.SqlParserPos;\n-import org.apache.calcite.sql.type.OperandTypes;\n-import org.apache.calcite.sql.type.SqlOperandCountRanges;\n-import org.apache.calcite.sql.type.SqlTypeName;\n-import org.apache.calcite.sql.validate.SqlUserDefinedFunction;\n-\n-import static org.apache.calcite.schema.impl.ReflectiveFunctionBase.builder;\n-\n-\n-/**\n- * Operator to extract nested Rows or Fields form a struct row type using a dotted path.\n- * The goal of this operator is two-fold.\n- * First it is a temporary fix for https://issues.apache.org/jira/browse/CALCITE-4065 to extract a row from a row.\n- * Second it will enable smooth backward compatible migration from existing udf that relies on legacy row format.\n- */\n-public class GetNestedField extends SqlUserDefinedFunction {\n-\n-  public static final SqlFunction INSTANCE = new GetNestedField(new ExtractFunction());\n-\n-  public GetNestedField(Function function) {\n-    super(new SqlIdentifier(\"GetNestedField\", SqlParserPos.ZERO), null, null, null, ImmutableList.of(), function);\n-  }\n-\n-  @Override\n-  public SqlOperandCountRange getOperandCountRange() {\n-    return SqlOperandCountRanges.of(2);\n-  }\n-\n-  @Override\n-  public boolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure) {\n-    final SqlNode left = callBinding.operand(0);\n-    final SqlNode right = callBinding.operand(1);\n-    final RelDataType type = callBinding.getValidator().deriveType(callBinding.getScope(), left);\n-    boolean isRow = true;\n-    if (type.getSqlTypeName() != SqlTypeName.ROW) {\n-      isRow = false;\n-    } else if (type.getSqlIdentifier().isStar()) {\n-      isRow = false;\n-    }\n-    if (!isRow && throwOnFailure) {\n-      throw callBinding.newValidationSignatureError();\n-    }\n-    return isRow && OperandTypes.STRING.checkSingleOperandType(callBinding, right, 0, throwOnFailure);\n-  }\n-\n-  @Override\n-  public RelDataType inferReturnType(SqlOperatorBinding opBinding) {\n-    final RelDataTypeFactory typeFactory = opBinding.getTypeFactory();\n-    final RelDataType recordType = opBinding.getOperandType(0);\n-    switch (recordType.getSqlTypeName()) {\n-      case ROW:\n-        final String fieldName = opBinding.getOperandLiteralValue(1, String.class);\n-        String[] fieldNameChain = fieldName.split(\"\\\\.\");\n-        RelDataType relDataType = opBinding.getOperandType(0);\n-        for (int i = 0; i < fieldNameChain.length; i++) {\n-          RelDataTypeField t = relDataType.getField(fieldNameChain[i], true, true);\n-          Preconditions.checkNotNull(t,\n-              \"Can not find \" + fieldNameChain[i] + \" within record \" + recordType.toString() + \" Original String \"\n-                  + Arrays.toString(fieldNameChain) + \" Original row \" + recordType.toString());\n-          relDataType = t.getType();\n-        }\n-        if (recordType.isNullable()) {\n-          return typeFactory.createTypeWithNullability(relDataType, true);\n-        } else {\n-          return relDataType;\n-        }\n-      default:\n-        throw new AssertionError(\"First Operand is suppose to be a Row Struct\");\n-    }\n-  }\n-\n-  private static class ExtractFunction implements ScalarFunction, ImplementableFunction {\n-    private final JavaTypeFactoryImpl javaTypeFactory = new JavaTypeFactoryImpl();\n-\n-    @Override\n-    public CallImplementor getImplementor() {\n-      return RexImpTable.createImplementor((translator, call, translatedOperands) -> {\n-        Preconditions.checkState(translatedOperands.size() == 2 && call.operands.size() == 2,\n-            \"Expected 2 operands found \" + Math.min(translatedOperands.size(), call.getOperands().size()));\n-        Expression op0 = translatedOperands.get(0);\n-        Expression op1 = translatedOperands.get(1);\n-        Preconditions.checkState(op1.getNodeType().equals(ExpressionType.Constant),\n-            \"Operand 2 has to be constant and got \" + op1.getNodeType());\n-        Preconditions.checkState(op1.type.equals(String.class), \"Operand 2 has to be String and got \" + op1.type);\n-        final String fieldName = (String) ((ConstantExpression) op1).value;\n-        String[] fieldNameChain = fieldName.split(\"\\\\.\");\n-        RelDataType relDataType = call.operands.get(0).getType();\n-        Preconditions.checkState(relDataType.getSqlTypeName().equals(SqlTypeName.ROW),\n-            \"Expected first operand to be ROW found \" + relDataType.toString());\n-        Expression currentExpression = op0;\n-        for (int i = 0; i < fieldNameChain.length; i++) {\n-          Preconditions.checkState(relDataType.getSqlTypeName() == SqlTypeName.ROW,\n-              \"Must be ROW found \" + relDataType.toString());\n-          RelDataTypeField t = relDataType.getField(fieldNameChain[i], true, true);\n-          Preconditions.checkNotNull(t,\n-              \"Notfound \" + fieldNameChain[i] + \" in the following struct \" + relDataType.toString()\n-                  + \" Original String \" + Arrays.toString(fieldNameChain) + \" Original row \" + call.operands.get(0)\n-                  .getType());\n-          currentExpression = Expressions.arrayIndex(Expressions.convert_(currentExpression, Object[].class),\n-              Expressions.constant(t.getIndex()));\n-          relDataType = t.getType();\n-        }\n-        Type fieldType = javaTypeFactory.getJavaClass(relDataType);\n-        return EnumUtils.convert(currentExpression, fieldType);\n-      }, NullPolicy.ARG0, false);\n-    }\n-\n-    @Override\n-    public RelDataType getReturnType(RelDataTypeFactory typeFactory) {\n-      throw new IllegalStateException(\"should not be called\");\n-    }\n-\n-    @Override\n-    public List<FunctionParameter> getParameters() {\n-      return builder().add(Object[].class, \"row\").add(String.class, \"path\").build();\n-    }\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ0MzI2Ng==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457443266", "bodyText": "In what scenarios do you expect the map key to be of Utf8 type ? Considering that Avro mandates the map key type to be a string, isn't it fair to expect users to convert Utf8s to string ?", "author": "atoomula", "createdAt": "2020-07-20T14:34:00Z", "path": "samza-sql/src/main/java/org/apache/samza/sql/avro/AvroRelConverter.java", "diffHunk": "@@ -194,10 +194,12 @@ public static Object convertToAvroObject(Object relObj, Schema schema) {\n             .collect(Collectors.toList());\n         return avroList;\n       case MAP:\n-        return ((Map<String, ?>) relObj).entrySet()\n-            .stream()\n-            .collect(Collectors.toMap(Map.Entry::getKey,\n-              e -> convertToAvroObject(e.getValue(), getNonNullUnionSchema(schema).getValueType())));\n+        // If you ask why not using String and that is because some strings are Wrapped into org.apache.avro.util.Utf8\n+        // TODO looking at the Utf8 code base it is not immutable, having it as a key is calling for trouble!\n+        final Map<Object, Object> outputMap = new HashMap<>();", "originalCommit": "9938a74ab4db17141dd8ed4eb3322dff5f3e6462", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5OTk4OQ==", "url": "https://github.com/apache/samza/pull/1386#discussion_r457599989", "bodyText": "@atoomula The code as of today does that, in fact the reason I run into it is because I changed to String but tested failed. To avoid making this PR a fix everything pr I added the comment and base fix for the null case needed by my work. But I agree we need to move out of Avro String especially that is is mutable.", "author": "b-slim", "createdAt": "2020-07-20T18:12:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ0MzI2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "chunk": "diff --git a/samza-sql/src/main/java/org/apache/samza/sql/avro/AvroRelConverter.java b/samza-sql/src/main/java/org/apache/samza/sql/avro/AvroRelConverter.java\nindex 25484a98f..4c221c637 100644\n--- a/samza-sql/src/main/java/org/apache/samza/sql/avro/AvroRelConverter.java\n+++ b/samza-sql/src/main/java/org/apache/samza/sql/avro/AvroRelConverter.java\n\n@@ -195,7 +202,7 @@ public class AvroRelConverter implements SamzaRelConverter {\n         return avroList;\n       case MAP:\n         // If you ask why not using String and that is because some strings are Wrapped into org.apache.avro.util.Utf8\n-        // TODO looking at the Utf8 code base it is not immutable, having it as a key is calling for trouble!\n+        // @TODO looking at the Utf8 code base it is not immutable, having it as a key is calling for trouble!\n         final Map<Object, Object> outputMap = new HashMap<>();\n         ((Map<Object, Object>) relObj).forEach((key, aValue) -> outputMap.put(key,\n             convertToAvroObject(aValue, getNonNullUnionSchema(schema).getValueType())));\n"}}, {"oid": "da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "url": "https://github.com/apache/samza/commit/da011b6d602b0ad88060550b1ff31a2e6b4c33b7", "message": "Working version still need to work on extracting nested fields udf", "committedDate": "2020-07-21T00:12:30Z", "type": "commit"}, {"oid": "19302507827c43649f7062fe13fd29fee9d5dd25", "url": "https://github.com/apache/samza/commit/19302507827c43649f7062fe13fd29fee9d5dd25", "message": "working version end to end with Filter optimization", "committedDate": "2020-07-21T00:20:30Z", "type": "commit"}, {"oid": "5c47c0feaa39b512f00e876a565192b1a49b3d9d", "url": "https://github.com/apache/samza/commit/5c47c0feaa39b512f00e876a565192b1a49b3d9d", "message": "left outer join test with filters", "committedDate": "2020-07-21T00:20:33Z", "type": "commit"}, {"oid": "5d3059bb1886a7300a8756f6b93ab41fe36c0a30", "url": "https://github.com/apache/samza/commit/5d3059bb1886a7300a8756f6b93ab41fe36c0a30", "message": "adding more comments", "committedDate": "2020-07-21T00:20:33Z", "type": "commit"}, {"oid": "87ea29e235fd076e0db03961bc810efa707f5c35", "url": "https://github.com/apache/samza/commit/87ea29e235fd076e0db03961bc810efa707f5c35", "message": "fix the type converter used by udfs", "committedDate": "2020-07-21T00:20:33Z", "type": "commit"}, {"oid": "ad1e5e8f969523afcf58b35c0927ddaa514c490f", "url": "https://github.com/apache/samza/commit/ad1e5e8f969523afcf58b35c0927ddaa514c490f", "message": "refix the test", "committedDate": "2020-07-21T00:20:33Z", "type": "commit"}, {"oid": "59c3a7398fee33002f693da49256d83a6f2e1fc9", "url": "https://github.com/apache/samza/commit/59c3a7398fee33002f693da49256d83a6f2e1fc9", "message": "Added GetNestedField built in operator to allow support backward comaptiblity", "committedDate": "2020-07-21T00:20:33Z", "type": "commit"}, {"oid": "2bc3b5d940d71fa8c0dc928e1eb919f9330f7d0a", "url": "https://github.com/apache/samza/commit/2bc3b5d940d71fa8c0dc928e1eb919f9330f7d0a", "message": "fix java doc and minor change on the type cast\n\nNot sure what this test is testing for it is a regular join between Stream and local table", "committedDate": "2020-07-21T00:21:29Z", "type": "commit"}, {"oid": "5fbeab52a88fef95174c038720aa326252067aee", "url": "https://github.com/apache/samza/commit/5fbeab52a88fef95174c038720aa326252067aee", "message": "Adding more tests and some logging to help read the compiled code", "committedDate": "2020-07-21T00:21:33Z", "type": "commit"}, {"oid": "60f9ec16a482ffaf7e0aebefbe1911181541b996", "url": "https://github.com/apache/samza/commit/60f9ec16a482ffaf7e0aebefbe1911181541b996", "message": "Adding some Type sanity to the Join functions", "committedDate": "2020-07-21T00:21:33Z", "type": "commit"}, {"oid": "958e2ea643f049274db9a35ff01855d396d7b234", "url": "https://github.com/apache/samza/commit/958e2ea643f049274db9a35ff01855d396d7b234", "message": "fix minor WAR", "committedDate": "2020-07-21T00:21:33Z", "type": "commit"}, {"oid": "50f8f8cd6a4f16ddf4e23f00cc6bad188863e37d", "url": "https://github.com/apache/samza/commit/50f8f8cd6a4f16ddf4e23f00cc6bad188863e37d", "message": "revert unwanted changes", "committedDate": "2020-07-21T01:20:52Z", "type": "commit"}, {"oid": "78e6da887d72bddf506e30fea57759ac5e1bf08a", "url": "https://github.com/apache/samza/commit/78e6da887d72bddf506e30fea57759ac5e1bf08a", "message": "fix the tests", "committedDate": "2020-07-21T01:21:17Z", "type": "forcePushed"}, {"oid": "b917b7ea98317ee1f9ad1b0528326bf92d3f9168", "url": "https://github.com/apache/samza/commit/b917b7ea98317ee1f9ad1b0528326bf92d3f9168", "message": "fix the tests", "committedDate": "2020-07-21T15:48:23Z", "type": "commit"}, {"oid": "b917b7ea98317ee1f9ad1b0528326bf92d3f9168", "url": "https://github.com/apache/samza/commit/b917b7ea98317ee1f9ad1b0528326bf92d3f9168", "message": "fix the tests", "committedDate": "2020-07-21T15:48:23Z", "type": "forcePushed"}, {"oid": "3e95902b615bd90ec686902fadbab9f98c03a75c", "url": "https://github.com/apache/samza/commit/3e95902b615bd90ec686902fadbab9f98c03a75c", "message": "Adding more tests for map type and fix the Avro conversion for type with one type only", "committedDate": "2020-07-21T17:46:02Z", "type": "commit"}, {"oid": "cd49581da4a6bcb8a5f0bc936c7adf3159b28b2b", "url": "https://github.com/apache/samza/commit/cd49581da4a6bcb8a5f0bc936c7adf3159b28b2b", "message": "fix the style checks", "committedDate": "2020-07-21T22:28:05Z", "type": "commit"}]}