{"pr_number": 668, "pr_title": "HDDS-3139. Pipeline placement should max out pipeline usage", "pr_createdAt": "2020-03-12T07:25:14Z", "pr_url": "https://github.com/apache/ozone/pull/668", "timeline": [{"oid": "0350a9a17be64b08cdf0eb438811c60d82e68eef", "url": "https://github.com/apache/ozone/commit/0350a9a17be64b08cdf0eb438811c60d82e68eef", "message": "HDDS-3139 Pipeline placement should select lowest load datanode as anchor.", "committedDate": "2020-03-12T07:27:06Z", "type": "forcePushed"}, {"oid": "29d74c3bf283e7166f37d1e0b2739742c0dc5a04", "url": "https://github.com/apache/ozone/commit/29d74c3bf283e7166f37d1e0b2739742c0dc5a04", "message": "HDDS-3139 Pipeline placement should select lowest load datanode as anchor.", "committedDate": "2020-03-12T07:29:14Z", "type": "forcePushed"}, {"oid": "e8506dc31a14b2938a5bbdb8dcabd62a1f9546e4", "url": "https://github.com/apache/ozone/commit/e8506dc31a14b2938a5bbdb8dcabd62a1f9546e4", "message": "HDDS-3139 Pipeline placement should select lowest load datanode as anchor.", "committedDate": "2020-03-12T09:54:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r395583248", "bodyText": "Could this be simplified to just nodes.get(0)? In the else branch we already know the list is not empty, so I think we can just pick the first node in the list safely.", "author": "sodonnel", "createdAt": "2020-03-20T11:42:52Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -315,6 +314,50 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n+    DatanodeDetails datanodeDetails;\n+    int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n+    int secondNodeNdx = getRand().nextInt(healthyNodes.size());\n+\n+    // There is a possibility that both numbers will be same.\n+    // if that is so, we just return the node.\n+    if (firstNodeNdx == secondNodeNdx) {\n+      datanodeDetails = healthyNodes.get(firstNodeNdx);\n+    } else {\n+      DatanodeDetails firstNodeDetails = healthyNodes.get(firstNodeNdx);\n+      DatanodeDetails secondNodeDetails = healthyNodes.get(secondNodeNdx);\n+      datanodeDetails = nodeManager.getPipelinesCount(firstNodeDetails)\n+          >= nodeManager.getPipelinesCount(secondNodeDetails)\n+          ? secondNodeDetails : firstNodeDetails;\n+    }\n+    return datanodeDetails;\n+  }\n+\n+  private List<DatanodeDetails> getLowerLoadNodes(\n+      List<DatanodeDetails> nodes, int num) {\n+    int maxPipelineUsage = nodes.size() * heavyNodeCriteria /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+    return nodes.stream()\n+        // Skip the nodes which exceeds the load limit.\n+        .filter(p -> nodeManager.getPipelinesCount(p) < num - maxPipelineUsage)\n+        .collect(Collectors.toList());\n+  }\n+\n+  private DatanodeDetails lowerLoadPick(List<DatanodeDetails> healthyNodes) {\n+    int curPipelineCounts =  stateManager\n+        .getPipelines(HddsProtos.ReplicationType.RATIS).size();\n+    DatanodeDetails datanodeDetails;\n+    List<DatanodeDetails> nodes = getLowerLoadNodes(\n+        healthyNodes, curPipelineCounts);\n+    if (nodes.isEmpty()) {\n+      // random pick node if nodes load is at same level.\n+      datanodeDetails = randomPick(healthyNodes);\n+    } else {\n+      datanodeDetails = nodes.stream().findFirst().get();", "originalCommit": "e8506dc31a14b2938a5bbdb8dcabd62a1f9546e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxMDAyNw==", "url": "https://github.com/apache/ozone/pull/668#discussion_r395610027", "bodyText": "Actually, thinking about this more - should this pick a random node from LowerLoadNodes, rather than the first node? We call getLowerLoadNodes which returns a list of nodes where the overloaded nodes are removed, but I don't think the list is sorted in anyway. The healthyNodes will will probably be naturally in the same order each time it is generated from the NodeManager. This means this lowerLoadPick method might return the same node on each call until it is overloaded. Then it would be excluded and the next node would be picked and so on. It would probably be better if we picked a random node from the less loaded nodes. Or, sort the list by load and return the first one so we are always picked the node with the least node.", "author": "sodonnel", "createdAt": "2020-03-20T12:41:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNTUxMg==", "url": "https://github.com/apache/ozone/pull/668#discussion_r395615512", "bodyText": "When i fixed the suspected bug I mentioned above, and then ran the test. The nodes do appear to fill their piplines on a node by node basis and then the test failed as each node did not have at least the average pipelines.\nMaking this change got it to pass again:\ndatanodeDetails = nodes.get(getRand().nextInt(nodes.size()) );//stream().findFirst().get();\n\nBut it might be ever better if we sorted the list by pipeline count ascending and then took the first one, but it would be more expensive.", "author": "sodonnel", "createdAt": "2020-03-20T12:52:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjIyOTk3MA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r396229970", "bodyText": "Sorting the node list would be expensive for large cluster. That's the reason why I choose to do this 'water mark' filter for selecting nodes with lower load.\nI can def do a findAny() kinda thing for random pick. @sodonnel", "author": "timmylicheng", "createdAt": "2020-03-23T06:12:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njc3NDMxNw==", "url": "https://github.com/apache/ozone/pull/668#discussion_r396774317", "bodyText": "You could probably do a \"top N\" type of sort where you only keep the lowest loaded node, but it would require a bit of a refactor of getLowerLoadNodes, probably changing it to getLowestLodeNode. That would avoid a full sort and would not be much more expensive that the current code, eg:\nDatanodeDetails lowest = null;\nint lowestPipelineCount;\nfor (DatanodeDetails dn : nodes) {\n  int nodePipelines = node.getPipelineCount();\n  if (nodePipelines > limit) {\n    continue;\n  }\n  if ((lowest == null) || lowestPipelineCount > nodePipelines {\n    lowest = node;\n    lowestPipelineCount = nodePipelines;\n  }\n}\nreturn lowest;", "author": "sodonnel", "createdAt": "2020-03-23T21:42:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg1Nzg1MQ==", "url": "https://github.com/apache/ozone/pull/668#discussion_r397857851", "bodyText": "I feel like the outcome will be similar tho. The current implementation should work just fine.", "author": "timmylicheng", "createdAt": "2020-03-25T13:36:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDE1MjY5Ng==", "url": "https://github.com/apache/ozone/pull/668#discussion_r400152696", "bodyText": "I am fine with doing a \"random pick\" from the getLowerLoadNodes list or using the idea I had above to get the node with the lowest load each time. I think there are advantages to each of them. I believe we do need to go with one of those ideas, as picking the first one will not work well.\nThe random pick is simple, but it may not spread the load evenly every time.\nPicking the lowest one each time is slightly more complicated, but it does guarantee to always use the lowest load node first and will spread the load evenly for sure. However it is less random - eg if a new node joins the cluster, then it will be used for the next N pipelines until it reaches the same load as some others.", "author": "sodonnel", "createdAt": "2020-03-30T12:30:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDcwOTIwMw==", "url": "https://github.com/apache/ozone/pull/668#discussion_r400709203", "bodyText": "@sodonnel I'm navigating thru another problem with chooseNodeFromNetworkTopology. Because topology only gives interface like networkTopology.chooseRandom(anchor.getNetworkLocation(), excluded), I have to move all higher load nodes into excluded and allow topology to pick one. So the original water mark cannot guarantee full load balance due to fall back logic I added.\nI could see your proposed sort will help picking the lowEST node. How could it help leverage to have higher load with topology? I'm still experimenting...", "author": "timmylicheng", "createdAt": "2020-03-31T07:49:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4MzI0OA=="}], "type": "inlineReview", "revised_code": {"commit": "a3171b9a7d62e9925d683eadcfc2dc3039a613ac", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex b9f5be2c78..b7a8e12849 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -314,6 +314,12 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  /**\n+   * Random pick two nodes and compare with the pipeline load.\n+   * Return the node with lower pipeline load.\n+   * @param healthyNodes healthy nodes\n+   * @return node\n+   */\n   private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n     DatanodeDetails datanodeDetails;\n     int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4NDkxNg==", "url": "https://github.com/apache/ozone/pull/668#discussion_r395584916", "bodyText": "I think a Java doc would be useful for this method to explain how it works. It seems to pick two random nodes and then return the one with the less load - is that correct?", "author": "sodonnel", "createdAt": "2020-03-20T11:47:05Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -315,6 +314,50 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {", "originalCommit": "e8506dc31a14b2938a5bbdb8dcabd62a1f9546e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjIzMDI0MA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r396230240", "bodyText": "Yea. Your understanding is correct. I will add doc as description.", "author": "timmylicheng", "createdAt": "2020-03-23T06:13:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU4NDkxNg=="}], "type": "inlineReview", "revised_code": {"commit": "a3171b9a7d62e9925d683eadcfc2dc3039a613ac", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex b9f5be2c78..b7a8e12849 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -314,6 +314,12 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  /**\n+   * Random pick two nodes and compare with the pipeline load.\n+   * Return the node with lower pipeline load.\n+   * @param healthyNodes healthy nodes\n+   * @return node\n+   */\n   private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n     DatanodeDetails datanodeDetails;\n     int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxMzUzMg==", "url": "https://github.com/apache/ozone/pull/668#discussion_r395613532", "bodyText": "I think there is a bug here. I put some debug in and ran the test you added as part of this change, and this method always returned an empty list.\nmaxPipelineUsage starts at 13, so we have:\n\"0 < 3 - 13\" -> \"0 < -10 \" -> false and all the nodes are filtered out.\n\nShould this be:\n .filter(p -> nodeManager.getPipelinesCount(p) < maxPipelineUsage - num)", "author": "sodonnel", "createdAt": "2020-03-20T12:48:55Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -315,6 +314,50 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n+    DatanodeDetails datanodeDetails;\n+    int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n+    int secondNodeNdx = getRand().nextInt(healthyNodes.size());\n+\n+    // There is a possibility that both numbers will be same.\n+    // if that is so, we just return the node.\n+    if (firstNodeNdx == secondNodeNdx) {\n+      datanodeDetails = healthyNodes.get(firstNodeNdx);\n+    } else {\n+      DatanodeDetails firstNodeDetails = healthyNodes.get(firstNodeNdx);\n+      DatanodeDetails secondNodeDetails = healthyNodes.get(secondNodeNdx);\n+      datanodeDetails = nodeManager.getPipelinesCount(firstNodeDetails)\n+          >= nodeManager.getPipelinesCount(secondNodeDetails)\n+          ? secondNodeDetails : firstNodeDetails;\n+    }\n+    return datanodeDetails;\n+  }\n+\n+  private List<DatanodeDetails> getLowerLoadNodes(\n+      List<DatanodeDetails> nodes, int num) {\n+    int maxPipelineUsage = nodes.size() * heavyNodeCriteria /\n+        HddsProtos.ReplicationFactor.THREE.getNumber();\n+    return nodes.stream()\n+        // Skip the nodes which exceeds the load limit.\n+        .filter(p -> nodeManager.getPipelinesCount(p) < num - maxPipelineUsage)", "originalCommit": "e8506dc31a14b2938a5bbdb8dcabd62a1f9546e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzg1ODEzNw==", "url": "https://github.com/apache/ozone/pull/668#discussion_r397858137", "bodyText": "Good catch. I update it. Thanks!", "author": "timmylicheng", "createdAt": "2020-03-25T13:36:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxMzUzMg=="}], "type": "inlineReview", "revised_code": {"commit": "a3171b9a7d62e9925d683eadcfc2dc3039a613ac", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex b9f5be2c78..b7a8e12849 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -314,6 +314,12 @@ DatanodeDetails fallBackPickNodes(\n     return results;\n   }\n \n+  /**\n+   * Random pick two nodes and compare with the pipeline load.\n+   * Return the node with lower pipeline load.\n+   * @param healthyNodes healthy nodes\n+   * @return node\n+   */\n   private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n     DatanodeDetails datanodeDetails;\n     int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n"}}, {"oid": "a3171b9a7d62e9925d683eadcfc2dc3039a613ac", "url": "https://github.com/apache/ozone/commit/a3171b9a7d62e9925d683eadcfc2dc3039a613ac", "message": "Add java doc.", "committedDate": "2020-03-26T06:32:26Z", "type": "forcePushed"}, {"oid": "95848da894d7be3996ba51e282c43e833c1d55a0", "url": "https://github.com/apache/ozone/commit/95848da894d7be3996ba51e282c43e833c1d55a0", "message": "Add java doc.", "committedDate": "2020-03-26T11:30:11Z", "type": "forcePushed"}, {"oid": "201869a7c92dd05f6b1d84675abc0a1ae0696819", "url": "https://github.com/apache/ozone/commit/201869a7c92dd05f6b1d84675abc0a1ae0696819", "message": "Add java doc.", "committedDate": "2020-03-27T02:39:07Z", "type": "forcePushed"}, {"oid": "d766d7fa7331dbf93595bf1083404302a76bfae4", "url": "https://github.com/apache/ozone/commit/d766d7fa7331dbf93595bf1083404302a76bfae4", "message": "Add java doc.", "committedDate": "2020-03-27T08:16:36Z", "type": "forcePushed"}, {"oid": "201869a7c92dd05f6b1d84675abc0a1ae0696819", "url": "https://github.com/apache/ozone/commit/201869a7c92dd05f6b1d84675abc0a1ae0696819", "message": "Add java doc.", "committedDate": "2020-03-27T02:39:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDE4NDYyMg==", "url": "https://github.com/apache/ozone/pull/668#discussion_r400184622", "bodyText": "I am not sure if this calculation is correct. The reason is that the healthy node list is already filtered to include only nodes with fewer than heavyNodeCritera pipelines in filterViableNodes(). Therefore the size of the list passed into this method gets smaller as the nodes are used up and eventually it stops returning any nodes, even though there are nodes valid to return. From some debug messages I added:\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:chooseDatanodes(202)) - There is no topology\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:chooseNode(391)) - In chooseNode\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:getLowerLoadNodes(351)) - Max pipeline usage is: 8\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:lowerLoadPick(368)) - getLowerLoadNodes() returned empty list\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:chooseNode(391)) - In chooseNode\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:getLowerLoadNodes(351)) - Max pipeline usage is: 6\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:lowerLoadPick(368)) - getLowerLoadNodes() returned empty list\n2020-03-30 14:18:31,682 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:chooseNode(391)) - In chooseNode\n2020-03-30 14:18:31,683 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:getLowerLoadNodes(351)) - Max pipeline usage is: 5\n2020-03-30 14:18:31,683 INFO  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:lowerLoadPick(368)) - getLowerLoadNodes() returned empty list\n2020-03-30 14:18:31,683 INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 3da2deda-7839-4e5c-88e0-a613729b99fd, Nodes: 0cbe69da-7ef6-43ff-a11a-7ba716ec7c9c{ip: 242.96.90.116, host: localhost-242.96.90.116, networkLocation: /default-rack, certSerialId: null}b4d70058-fb84-410a-8ca8-cc4e8e944fae{ip: 28.158.147.87, host: localhost-28.158.147.87, networkLocation: /default-rack, certSerialId: null}03846f48-f6e5-4dba-97b2-5ab8a7be1564{ip: 128.200.5.118, host: localhost-128.200.5.118, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-03-30T13:18:31.683Z]\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 5\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 5\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 5\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 3\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 2\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 2\n2020-03-30 14:18:31,683 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 3\n2020-03-30 14:18:31,684 INFO  pipeline.TestPipelinePlacementPolicy (TestPipelinePlacementPolicy.java:testPickLowestLoadAnchor(112)) - Pipeline count for this node is 2\n\nIf the nodes are filtered by load count in filterViableNodes, do we actually need this getLowerLoadNodes method?", "author": "sodonnel", "createdAt": "2020-03-30T13:20:22Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -316,36 +315,75 @@ DatanodeDetails fallBackPickNodes(\n   }\n \n   /**\n-   * Find a node from the healthy list and return it after removing it from the\n-   * list that we are operating on.\n-   *\n-   * @param healthyNodes - Set of healthy nodes we can choose from.\n-   * @return chosen datanodDetails\n+   * Random pick two nodes and compare with the pipeline load.\n+   * Return the node with lower pipeline load.\n+   * @param healthyNodes healthy nodes\n+   * @return node\n    */\n-  @Override\n-  public DatanodeDetails chooseNode(\n-      List<DatanodeDetails> healthyNodes) {\n-    if (healthyNodes == null || healthyNodes.isEmpty()) {\n-      return null;\n-    }\n+  private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n+    DatanodeDetails datanodeDetails;\n     int firstNodeNdx = getRand().nextInt(healthyNodes.size());\n     int secondNodeNdx = getRand().nextInt(healthyNodes.size());\n \n-    DatanodeDetails datanodeDetails;\n     // There is a possibility that both numbers will be same.\n     // if that is so, we just return the node.\n     if (firstNodeNdx == secondNodeNdx) {\n       datanodeDetails = healthyNodes.get(firstNodeNdx);\n     } else {\n       DatanodeDetails firstNodeDetails = healthyNodes.get(firstNodeNdx);\n       DatanodeDetails secondNodeDetails = healthyNodes.get(secondNodeNdx);\n-      SCMNodeMetric firstNodeMetric =\n-          nodeManager.getNodeStat(firstNodeDetails);\n-      SCMNodeMetric secondNodeMetric =\n-          nodeManager.getNodeStat(secondNodeDetails);\n-      datanodeDetails = firstNodeMetric.isGreater(secondNodeMetric.get())\n-          ? firstNodeDetails : secondNodeDetails;\n+      datanodeDetails = nodeManager.getPipelinesCount(firstNodeDetails)\n+          >= nodeManager.getPipelinesCount(secondNodeDetails)\n+          ? secondNodeDetails : firstNodeDetails;\n     }\n+    return datanodeDetails;\n+  }\n+\n+  /**\n+   * Get a list of nodes with lower load than max pipeline number.\n+   */\n+  private List<DatanodeDetails> getLowerLoadNodes(\n+      List<DatanodeDetails> nodes, int num) {\n+    int maxPipelineUsage = nodes.size() * heavyNodeCriteria /", "originalCommit": "201869a7c92dd05f6b1d84675abc0a1ae0696819", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTg1MDUwMQ==", "url": "https://github.com/apache/ozone/pull/668#discussion_r411850501", "bodyText": "Removed and updated with new method.", "author": "timmylicheng", "createdAt": "2020-04-21T03:58:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDE4NDYyMg=="}], "type": "inlineReview", "revised_code": {"commit": "b84e494d023903ae4df27a33035dbca86010fd39", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex b7a8e12849..c154d1844b 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -343,12 +348,23 @@ private DatanodeDetails randomPick(List<DatanodeDetails> healthyNodes) {\n    * Get a list of nodes with lower load than max pipeline number.\n    */\n   private List<DatanodeDetails> getLowerLoadNodes(\n-      List<DatanodeDetails> nodes, int num) {\n-    int maxPipelineUsage = nodes.size() * heavyNodeCriteria /\n-        HddsProtos.ReplicationFactor.THREE.getNumber();\n+      List<DatanodeDetails> nodes, int mark) {\n+    int limit = nodes.size() * heavyNodeCriteria\n+        / HddsProtos.ReplicationFactor.THREE.getNumber();\n     return nodes.stream()\n         // Skip the nodes which exceeds the load limit.\n-        .filter(p -> nodeManager.getPipelinesCount(p) < maxPipelineUsage - num)\n+        .filter(p -> nodeManager.getPipelinesCount(p) < limit - mark)\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * Get a list of nodes with higher load than max pipeline number.\n+   */\n+  private List<DatanodeDetails> getHigherLoadNodes(\n+      List<DatanodeDetails> nodes, int mark) {\n+    return nodes.stream()\n+        // Skip the nodes with lower load than mark.\n+        .filter(p -> nodeManager.getPipelinesCount(p) > mark)\n         .collect(Collectors.toList());\n   }\n \n"}}, {"oid": "b84e494d023903ae4df27a33035dbca86010fd39", "url": "https://github.com/apache/ozone/commit/b84e494d023903ae4df27a33035dbca86010fd39", "message": "Add higher load node range for picking node based on topology.", "committedDate": "2020-03-31T08:09:57Z", "type": "forcePushed"}, {"oid": "e476e8080630e7082d9f8dc551cab0b6e4842289", "url": "https://github.com/apache/ozone/commit/e476e8080630e7082d9f8dc551cab0b6e4842289", "message": "Add higher load node range for picking node based on topology.", "committedDate": "2020-03-31T09:00:47Z", "type": "forcePushed"}, {"oid": "7dbf0d60767aa6a59c25f67b4a4e70788868e7be", "url": "https://github.com/apache/ozone/commit/7dbf0d60767aa6a59c25f67b4a4e70788868e7be", "message": "Sort datanode with pipeline for average allocation.", "committedDate": "2020-04-13T11:42:33Z", "type": "forcePushed"}, {"oid": "1049922fc9aab42bcda48830f2f210cf92504831", "url": "https://github.com/apache/ozone/commit/1049922fc9aab42bcda48830f2f210cf92504831", "message": "Sort datanode with pipeline for average allocation.", "committedDate": "2020-04-14T03:48:34Z", "type": "forcePushed"}, {"oid": "1ebecf2505fd0588eb7054ff7f76fabf595eec09", "url": "https://github.com/apache/ozone/commit/1ebecf2505fd0588eb7054ff7f76fabf595eec09", "message": "Sort datanode with pipeline for average allocation.", "committedDate": "2020-04-14T08:11:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3Mzk1Mw==", "url": "https://github.com/apache/ozone/pull/668#discussion_r408073953", "bodyText": "Can you rename nodeOnOtherRack to nodesOnSameRack here please?", "author": "sodonnel", "createdAt": "2020-04-14T11:48:07Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -373,13 +354,31 @@ protected DatanodeDetails chooseNodeBasedOnRackAwareness(\n       return null;\n     }\n \n-    for (DatanodeDetails node : healthyNodes) {\n-      if (excludedNodes.contains(node) ||\n-          anchor.getNetworkLocation().equals(node.getNetworkLocation())) {\n-        continue;\n-      } else {\n-        return node;\n-      }\n+    List<DatanodeDetails> nodesOnOtherRack = healthyNodes.stream().filter(\n+        p -> !excludedNodes.contains(p)\n+            && !anchor.getNetworkLocation().equals(p.getNetworkLocation()))\n+        .collect(Collectors.toList());\n+    if (!nodesOnOtherRack.isEmpty()) {\n+      return nodesOnOtherRack.get(0);\n+    }\n+    return null;\n+  }\n+\n+  @VisibleForTesting\n+  protected DatanodeDetails chooseNodeBasedOnSameRack(\n+      List<DatanodeDetails> healthyNodes,  List<DatanodeDetails> excludedNodes,\n+      NetworkTopology networkTopology, DatanodeDetails anchor) {\n+    Preconditions.checkArgument(networkTopology != null);\n+    if (checkAllNodesAreEqual(networkTopology)) {\n+      return null;\n+    }\n+\n+    List<DatanodeDetails> nodesOnOtherRack = healthyNodes.stream().filter(", "originalCommit": "1ebecf2505fd0588eb7054ff7f76fabf595eec09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzM5MA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r408633390", "bodyText": "Updated", "author": "timmylicheng", "createdAt": "2020-04-15T07:24:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3Mzk1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "827a550fc4e6d05d269e8fad7c670d47cfc6f539", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex e586094eeb..91e3b7fded 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -354,31 +373,13 @@ protected DatanodeDetails chooseNodeBasedOnRackAwareness(\n       return null;\n     }\n \n-    List<DatanodeDetails> nodesOnOtherRack = healthyNodes.stream().filter(\n-        p -> !excludedNodes.contains(p)\n-            && !anchor.getNetworkLocation().equals(p.getNetworkLocation()))\n-        .collect(Collectors.toList());\n-    if (!nodesOnOtherRack.isEmpty()) {\n-      return nodesOnOtherRack.get(0);\n-    }\n-    return null;\n-  }\n-\n-  @VisibleForTesting\n-  protected DatanodeDetails chooseNodeBasedOnSameRack(\n-      List<DatanodeDetails> healthyNodes,  List<DatanodeDetails> excludedNodes,\n-      NetworkTopology networkTopology, DatanodeDetails anchor) {\n-    Preconditions.checkArgument(networkTopology != null);\n-    if (checkAllNodesAreEqual(networkTopology)) {\n-      return null;\n-    }\n-\n-    List<DatanodeDetails> nodesOnOtherRack = healthyNodes.stream().filter(\n-        p -> !excludedNodes.contains(p)\n-            && anchor.getNetworkLocation().equals(p.getNetworkLocation()))\n-        .collect(Collectors.toList());\n-    if (!nodesOnOtherRack.isEmpty()) {\n-      return nodesOnOtherRack.get(0);\n+    for (DatanodeDetails node : healthyNodes) {\n+      if (excludedNodes.contains(node) ||\n+          anchor.getNetworkLocation().equals(node.getNetworkLocation())) {\n+        continue;\n+      } else {\n+        return node;\n+      }\n     }\n     return null;\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3NDkyNA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r408074924", "bodyText": "We should add a note to this Java doc that the returned list is sorted in order of pipeline count, starting with the lowest to highest.", "author": "sodonnel", "createdAt": "2020-04-14T11:49:57Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java", "diffHunk": "@@ -110,17 +97,11 @@ boolean meetCriteria(DatanodeDetails datanodeDetails, int nodesRequired) {\n         pipelineNumDeductable++;\n       }\n     }\n-    boolean meet = (nodeManager.getPipelinesCount(datanodeDetails)\n-        - pipelineNumDeductable) < heavyNodeCriteria;\n-    if (!meet && LOG.isDebugEnabled()) {\n-      LOG.debug(\"Pipeline Placement: can't place more pipeline on heavy \" +\n-          \"datanode\uff1a \" + datanodeDetails.getUuid().toString() +\n-          \" Heaviness: \" + nodeManager.getPipelinesCount(datanodeDetails) +\n-          \" limit: \" + heavyNodeCriteria);\n-    }\n-    return meet;\n+    return pipelines.size() - pipelineNumDeductable;\n   }\n \n+\n+\n   /**\n    * Filter out viable nodes based on\n    * 1. nodes that are healthy", "originalCommit": "1ebecf2505fd0588eb7054ff7f76fabf595eec09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzQ3MA==", "url": "https://github.com/apache/ozone/pull/668#discussion_r408633470", "bodyText": "Updated.", "author": "timmylicheng", "createdAt": "2020-04-15T07:24:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODA3NDkyNA=="}], "type": "inlineReview", "revised_code": {"commit": "827a550fc4e6d05d269e8fad7c670d47cfc6f539", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\nindex e586094eeb..91e3b7fded 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelinePlacementPolicy.java\n\n@@ -97,11 +110,17 @@ int currentPipelineCount(DatanodeDetails datanodeDetails, int nodesRequired) {\n         pipelineNumDeductable++;\n       }\n     }\n-    return pipelines.size() - pipelineNumDeductable;\n+    boolean meet = (nodeManager.getPipelinesCount(datanodeDetails)\n+        - pipelineNumDeductable) < heavyNodeCriteria;\n+    if (!meet && LOG.isDebugEnabled()) {\n+      LOG.debug(\"Pipeline Placement: can't place more pipeline on heavy \" +\n+          \"datanode\uff1a \" + datanodeDetails.getUuid().toString() +\n+          \" Heaviness: \" + nodeManager.getPipelinesCount(datanodeDetails) +\n+          \" limit: \" + heavyNodeCriteria);\n+    }\n+    return meet;\n   }\n \n-\n-\n   /**\n    * Filter out viable nodes based on\n    * 1. nodes that are healthy\n"}}, {"oid": "827a550fc4e6d05d269e8fad7c670d47cfc6f539", "url": "https://github.com/apache/ozone/commit/827a550fc4e6d05d269e8fad7c670d47cfc6f539", "message": "HDDS-3179 Pipeline placement based on Topology does not have fall back protection.", "committedDate": "2020-04-21T11:39:58Z", "type": "commit"}, {"oid": "1e12cae10ebe14c6f96d3d24974bf3851e19600c", "url": "https://github.com/apache/ozone/commit/1e12cae10ebe14c6f96d3d24974bf3851e19600c", "message": "Add a test for single node rack case.", "committedDate": "2020-04-21T11:39:58Z", "type": "commit"}, {"oid": "11ac800e683920d15fbcf0407aaa7b4e729b373f", "url": "https://github.com/apache/ozone/commit/11ac800e683920d15fbcf0407aaa7b4e729b373f", "message": "HDDS-3139 Pipeline placement should select lowest load datanode as anchor.", "committedDate": "2020-04-21T11:40:58Z", "type": "commit"}, {"oid": "b38b053dc7018b55f8bc16d4ed1f3563af20a973", "url": "https://github.com/apache/ozone/commit/b38b053dc7018b55f8bc16d4ed1f3563af20a973", "message": "Add java doc.", "committedDate": "2020-04-21T11:40:58Z", "type": "commit"}, {"oid": "759c963219354ea22fc2ab0ceb1af9d4cfefe2ba", "url": "https://github.com/apache/ozone/commit/759c963219354ea22fc2ab0ceb1af9d4cfefe2ba", "message": "Add higher load node range for picking node based on topology.", "committedDate": "2020-04-21T11:40:58Z", "type": "commit"}, {"oid": "6b76a6295c52d4cb4a44e336cdee1358701afbf4", "url": "https://github.com/apache/ozone/commit/6b76a6295c52d4cb4a44e336cdee1358701afbf4", "message": "Sort datanode with pipeline for average allocation.", "committedDate": "2020-04-21T11:40:58Z", "type": "commit"}, {"oid": "2a0e319e8beed3d145143b65fb9fc2f6e4374251", "url": "https://github.com/apache/ozone/commit/2a0e319e8beed3d145143b65fb9fc2f6e4374251", "message": "Address some minor comments.", "committedDate": "2020-04-21T11:40:58Z", "type": "commit"}, {"oid": "fa11ff5f088a6ffca031165369308eacce71e074", "url": "https://github.com/apache/ozone/commit/fa11ff5f088a6ffca031165369308eacce71e074", "message": "Track potential performance issue.", "committedDate": "2020-04-21T11:53:00Z", "type": "commit"}, {"oid": "fa11ff5f088a6ffca031165369308eacce71e074", "url": "https://github.com/apache/ozone/commit/fa11ff5f088a6ffca031165369308eacce71e074", "message": "Track potential performance issue.", "committedDate": "2020-04-21T11:53:00Z", "type": "forcePushed"}]}