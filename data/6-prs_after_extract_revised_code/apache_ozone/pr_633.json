{"pr_number": 633, "pr_title": "HDDS-3123. Create REST API to serve Pipeline information and integrate with UI in Recon", "pr_createdAt": "2020-03-04T21:09:15Z", "pr_url": "https://github.com/apache/ozone/pull/633", "timeline": [{"oid": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "url": "https://github.com/apache/ozone/commit/beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "message": "Create REST API to serve Pipeline information and integrate with UI in Recon", "committedDate": "2020-03-04T21:01:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MzkyMw==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387953923", "bodyText": "Nit: Can use something like lambda forEach.", "author": "avijayanhwx", "createdAt": "2020-03-04T21:47:39Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\nindex e758aca3d..ac8c0a88c 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.ozone.recon.api;\n \n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDIyNQ==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954225", "bodyText": "Log the exception message here if not already logged further down the stack.", "author": "avijayanhwx", "createdAt": "2020-03-04T21:48:10Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\nindex e758aca3d..ac8c0a88c 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.ozone.recon.api;\n \n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NDczMg==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387954732", "bodyText": "Nit: Lambda.", "author": "avijayanhwx", "createdAt": "2020-03-04T21:49:14Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\nindex e758aca3d..ac8c0a88c 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.ozone.recon.api;\n \n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1NzQ0Nw==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387957447", "bodyText": "Seems like a lot of duplicated code between the 2 endpoint Test classes. Can we move this Test into the other class? We don't necessarily need a unit test for every endpoint class.", "author": "avijayanhwx", "createdAt": "2020-03-04T21:54:31Z", "path": "hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import com.google.inject.AbstractModule;\n+import com.google.inject.Guice;\n+import com.google.inject.Injector;\n+import com.google.inject.Singleton;\n+import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.PipelineID;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.NodeReportProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReport;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReportsProto;\n+import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.SCMHeartbeatRequestProto;\n+import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n+import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.GuiceInjectorUtilsForTestsImpl;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.persistence.AbstractSqlDatabaseTest;\n+import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n+import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n+import org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl;\n+import org.apache.hadoop.test.LambdaTestUtils;\n+import org.hadoop.ozone.recon.schema.ReconTaskSchemaDefinition;\n+import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n+import org.hadoop.ozone.recon.schema.tables.daos.ReconTaskStatusDao;\n+import org.jooq.Configuration;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import javax.ws.rs.core.Response;\n+\n+import static org.apache.hadoop.hdds.protocol.MockDatanodeDetails.randomDatanodeDetails;\n+import static org.apache.hadoop.hdds.recon.ReconConfigKeys.OZONE_RECON_DATANODE_ADDRESS_KEY;\n+import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+/**\n+ * Test for Pipeline Endpoint.\n+ */\n+public class TestPipelineEndpoint extends AbstractSqlDatabaseTest {\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\n+  private PipelineEndpoint pipelineEndpoint;\n+  private ReconStorageContainerManagerFacade reconScm;\n+  private boolean isSetupDone = false;\n+  private String pipelineId;\n+  private DatanodeDetails datanodeDetails;\n+  private GuiceInjectorUtilsForTestsImpl guiceInjectorTest =\n+      new GuiceInjectorUtilsForTestsImpl();\n+  private DatanodeDetailsProto datanodeDetailsProto;\n+  private ContainerReportsProto containerReportsProto;\n+  private long containerId = 1L;\n+  private Pipeline pipeline;\n+  private void initializeInjector() {\n+\n+    Injector injector = Guice.createInjector(new AbstractModule() {\n+      @Override\n+      protected void configure() {\n+        try {\n+          datanodeDetails = randomDatanodeDetails();\n+          pipeline = getRandomPipeline(datanodeDetails);\n+          pipelineId = pipeline.getId().getId().toString();\n+\n+          Configuration sqlConfiguration =\n+              getInjector().getInstance((Configuration.class));\n+\n+          ContainerInfo containerInfo = new ContainerInfo.Builder()\n+              .setContainerID(containerId)\n+              .setReplicationFactor(ReplicationFactor.ONE)\n+              .setState(LifeCycleState.OPEN)\n+              .setOwner(\"test\")\n+              .setPipelineID(pipeline.getId())\n+              .setReplicationType(ReplicationType.RATIS)\n+              .build();\n+          ContainerWithPipeline containerWithPipeline =\n+              new ContainerWithPipeline(containerInfo, pipeline);\n+\n+          ReconTaskSchemaDefinition taskSchemaDefinition = getInjector()\n+              .getInstance(ReconTaskSchemaDefinition.class);\n+          taskSchemaDefinition.initializeSchema();\n+\n+          ReconTaskStatusDao reconTaskStatusDao =\n+              new ReconTaskStatusDao(sqlConfiguration);\n+          MissingContainersDao missingContainersDao =\n+              new MissingContainersDao(sqlConfiguration);\n+\n+          bind(ReconTaskStatusDao.class).toInstance(reconTaskStatusDao);\n+          bind(MissingContainersDao.class).toInstance(missingContainersDao);\n+\n+          StorageContainerLocationProtocol mockScmClient = mock(\n+              StorageContainerLocationProtocol.class);\n+          StorageContainerServiceProvider mockScmServiceProvider = mock(\n+              StorageContainerServiceProviderImpl.class);\n+          when(mockScmServiceProvider.getPipeline(\n+              pipeline.getId().getProtobuf())).thenReturn(pipeline);\n+          when(mockScmServiceProvider.getContainerWithPipeline(containerId))\n+              .thenReturn(containerWithPipeline);\n+\n+          OzoneConfiguration testOzoneConfiguration =\n+              guiceInjectorTest.getTestOzoneConfiguration(temporaryFolder);\n+          testOzoneConfiguration.set(OZONE_RECON_DATANODE_ADDRESS_KEY,\n+              \"0.0.0.0:0\");\n+          bind(OzoneConfiguration.class).toInstance(testOzoneConfiguration);\n+          bind(StorageContainerLocationProtocol.class)\n+              .toInstance(mockScmClient);\n+          bind(StorageContainerServiceProvider.class)\n+              .toInstance(mockScmServiceProvider);", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java b/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java\ndeleted file mode 100644\nindex 87d8287cf..000000000\n--- a/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestPipelineEndpoint.java\n+++ /dev/null\n\n@@ -1,236 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.ozone.recon.api;\n-\n-import com.google.inject.AbstractModule;\n-import com.google.inject.Guice;\n-import com.google.inject.Injector;\n-import com.google.inject.Singleton;\n-import org.apache.hadoop.hdds.conf.OzoneConfiguration;\n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n-import org.apache.hadoop.hdds.protocol.proto.HddsProtos.DatanodeDetailsProto;\n-import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n-import org.apache.hadoop.hdds.protocol.proto.HddsProtos.PipelineID;\n-import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n-import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReplicaProto;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.ContainerReportsProto;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.NodeReportProto;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReport;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.PipelineReportsProto;\n-import org.apache.hadoop.hdds.protocol.proto.StorageContainerDatanodeProtocolProtos.SCMHeartbeatRequestProto;\n-import org.apache.hadoop.hdds.scm.container.ContainerInfo;\n-import org.apache.hadoop.hdds.scm.container.common.helpers.ContainerWithPipeline;\n-import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n-import org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol;\n-import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n-import org.apache.hadoop.ozone.recon.GuiceInjectorUtilsForTestsImpl;\n-import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n-import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n-import org.apache.hadoop.ozone.recon.persistence.AbstractSqlDatabaseTest;\n-import org.apache.hadoop.ozone.recon.scm.ReconStorageContainerManagerFacade;\n-import org.apache.hadoop.ozone.recon.spi.StorageContainerServiceProvider;\n-import org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl;\n-import org.apache.hadoop.test.LambdaTestUtils;\n-import org.hadoop.ozone.recon.schema.ReconTaskSchemaDefinition;\n-import org.hadoop.ozone.recon.schema.tables.daos.MissingContainersDao;\n-import org.hadoop.ozone.recon.schema.tables.daos.ReconTaskStatusDao;\n-import org.jooq.Configuration;\n-import org.junit.Assert;\n-import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n-\n-import javax.ws.rs.core.Response;\n-\n-import static org.apache.hadoop.hdds.protocol.MockDatanodeDetails.randomDatanodeDetails;\n-import static org.apache.hadoop.hdds.recon.ReconConfigKeys.OZONE_RECON_DATANODE_ADDRESS_KEY;\n-import static org.apache.hadoop.ozone.recon.AbstractOMMetadataManagerTest.getRandomPipeline;\n-import static org.mockito.Mockito.mock;\n-import static org.mockito.Mockito.when;\n-\n-/**\n- * Test for Pipeline Endpoint.\n- */\n-public class TestPipelineEndpoint extends AbstractSqlDatabaseTest {\n-  @Rule\n-  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n-\n-  private PipelineEndpoint pipelineEndpoint;\n-  private ReconStorageContainerManagerFacade reconScm;\n-  private boolean isSetupDone = false;\n-  private String pipelineId;\n-  private DatanodeDetails datanodeDetails;\n-  private GuiceInjectorUtilsForTestsImpl guiceInjectorTest =\n-      new GuiceInjectorUtilsForTestsImpl();\n-  private DatanodeDetailsProto datanodeDetailsProto;\n-  private ContainerReportsProto containerReportsProto;\n-  private long containerId = 1L;\n-  private Pipeline pipeline;\n-  private void initializeInjector() {\n-\n-    Injector injector = Guice.createInjector(new AbstractModule() {\n-      @Override\n-      protected void configure() {\n-        try {\n-          datanodeDetails = randomDatanodeDetails();\n-          pipeline = getRandomPipeline(datanodeDetails);\n-          pipelineId = pipeline.getId().getId().toString();\n-\n-          Configuration sqlConfiguration =\n-              getInjector().getInstance((Configuration.class));\n-\n-          ContainerInfo containerInfo = new ContainerInfo.Builder()\n-              .setContainerID(containerId)\n-              .setReplicationFactor(ReplicationFactor.ONE)\n-              .setState(LifeCycleState.OPEN)\n-              .setOwner(\"test\")\n-              .setPipelineID(pipeline.getId())\n-              .setReplicationType(ReplicationType.RATIS)\n-              .build();\n-          ContainerWithPipeline containerWithPipeline =\n-              new ContainerWithPipeline(containerInfo, pipeline);\n-\n-          ReconTaskSchemaDefinition taskSchemaDefinition = getInjector()\n-              .getInstance(ReconTaskSchemaDefinition.class);\n-          taskSchemaDefinition.initializeSchema();\n-\n-          ReconTaskStatusDao reconTaskStatusDao =\n-              new ReconTaskStatusDao(sqlConfiguration);\n-          MissingContainersDao missingContainersDao =\n-              new MissingContainersDao(sqlConfiguration);\n-\n-          bind(ReconTaskStatusDao.class).toInstance(reconTaskStatusDao);\n-          bind(MissingContainersDao.class).toInstance(missingContainersDao);\n-\n-          StorageContainerLocationProtocol mockScmClient = mock(\n-              StorageContainerLocationProtocol.class);\n-          StorageContainerServiceProvider mockScmServiceProvider = mock(\n-              StorageContainerServiceProviderImpl.class);\n-          when(mockScmServiceProvider.getPipeline(\n-              pipeline.getId().getProtobuf())).thenReturn(pipeline);\n-          when(mockScmServiceProvider.getContainerWithPipeline(containerId))\n-              .thenReturn(containerWithPipeline);\n-\n-          OzoneConfiguration testOzoneConfiguration =\n-              guiceInjectorTest.getTestOzoneConfiguration(temporaryFolder);\n-          testOzoneConfiguration.set(OZONE_RECON_DATANODE_ADDRESS_KEY,\n-              \"0.0.0.0:0\");\n-          bind(OzoneConfiguration.class).toInstance(testOzoneConfiguration);\n-          bind(StorageContainerLocationProtocol.class)\n-              .toInstance(mockScmClient);\n-          bind(StorageContainerServiceProvider.class)\n-              .toInstance(mockScmServiceProvider);\n-          bind(OzoneStorageContainerManager.class)\n-              .to(ReconStorageContainerManagerFacade.class).in(Singleton.class);\n-          bind(NodeEndpoint.class);\n-        } catch (Exception e) {\n-          Assert.fail(e.getMessage());\n-        }\n-      }\n-    });\n-\n-    pipelineEndpoint = injector.getInstance(PipelineEndpoint.class);\n-    reconScm = (ReconStorageContainerManagerFacade)\n-        injector.getInstance(OzoneStorageContainerManager.class);\n-  }\n-\n-  @Before\n-  public void setUp() {\n-    // The following setup runs only once\n-    if (!isSetupDone) {\n-      initializeInjector();\n-      isSetupDone = true;\n-    }\n-    String datanodeId = datanodeDetails.getUuid().toString();\n-    containerReportsProto = ContainerReportsProto.newBuilder()\n-        .addReports(\n-            ContainerReplicaProto.newBuilder()\n-                .setContainerID(containerId)\n-                .setState(ContainerReplicaProto.State.OPEN)\n-                .setOriginNodeId(datanodeId)\n-                .build())\n-        .build();\n-\n-    PipelineReport pipelineReport = PipelineReport.newBuilder()\n-        .setPipelineID(\n-            PipelineID.newBuilder().setId(pipelineId).build())\n-        .setIsLeader(true)\n-        .build();\n-    PipelineReportsProto pipelineReportsProto =\n-        PipelineReportsProto.newBuilder()\n-            .addPipelineReport(pipelineReport).build();\n-    datanodeDetailsProto = DatanodeDetailsProto.newBuilder()\n-        .setHostName(\"host1.datanode\")\n-        .setUuid(datanodeId)\n-        .setIpAddress(\"1.1.1.1\")\n-        .build();\n-    NodeReportProto nodeReportProto = NodeReportProto.newBuilder().build();\n-\n-    try {\n-      reconScm.getDatanodeProtocolServer()\n-          .register(datanodeDetailsProto, nodeReportProto,\n-              containerReportsProto, pipelineReportsProto);\n-      // Process all events in the event queue\n-      reconScm.getEventQueue().processAll(1000);\n-    } catch (Exception ex) {\n-      Assert.fail(ex.getMessage());\n-    }\n-  }\n-\n-  @Test\n-  public void testGetPipelines() throws Exception {\n-    Response response = pipelineEndpoint.getPipelines();\n-    PipelinesResponse pipelinesResponse =\n-        (PipelinesResponse) response.getEntity();\n-    Assert.assertEquals(1, pipelinesResponse.getTotalCount());\n-    Assert.assertEquals(1, pipelinesResponse.getPipelines().size());\n-    PipelineMetadata pipelineMetadata =\n-        pipelinesResponse.getPipelines().iterator().next();\n-    Assert.assertEquals(1, pipelineMetadata.getDatanodes().size());\n-    Assert.assertEquals(pipeline.getType().toString(),\n-        pipelineMetadata.getReplicationType());\n-    Assert.assertEquals(pipeline.getFactor().getNumber(),\n-        pipelineMetadata.getReplicationFactor());\n-    Assert.assertEquals(datanodeDetails.getHostName(),\n-        pipelineMetadata.getLeaderNode());\n-    Assert.assertEquals(pipeline.getId().getId(),\n-        pipelineMetadata.getPipelineId());\n-\n-    // if container report is processed first, and pipeline does not exist\n-    // then container is not added until the next container report is processed\n-    SCMHeartbeatRequestProto heartbeatRequestProto =\n-        SCMHeartbeatRequestProto.newBuilder()\n-            .setContainerReport(containerReportsProto)\n-            .setDatanodeDetails(datanodeDetailsProto)\n-            .build();\n-    reconScm.getDatanodeProtocolServer()\n-        .sendHeartbeat(heartbeatRequestProto);\n-\n-    LambdaTestUtils.await(30000, 5000, () -> {\n-      Response response1 = pipelineEndpoint.getPipelines();\n-      PipelinesResponse pipelinesResponse1 =\n-          (PipelinesResponse) response1.getEntity();\n-      PipelineMetadata pipelineMetadata1 =\n-          pipelinesResponse1.getPipelines().iterator().next();\n-      return (pipelineMetadata1.getContainers() == 1);\n-    });\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1OTUyMw==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387959523", "bodyText": "Shouldn't this just be IOException? From\npublic DatanodeDetails getLeaderNode() throws IOException {.\nWhy do we need to set leaderNode to \"\" on exception? It can be null, and handled in the UI maybe.", "author": "avijayanhwx", "createdAt": "2020-03-04T21:58:46Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\nindex e758aca3d..ac8c0a88c 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.ozone.recon.api;\n \n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MDI4NA==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387960284", "bodyText": "PipelineMetadata constructor looks like it is taking in a lot of parameters. A Builder may be better.", "author": "avijayanhwx", "createdAt": "2020-03-04T22:00:13Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.ozone.recon.api;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n+import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n+import org.apache.hadoop.ozone.recon.api.types.PipelinesResponse;\n+import org.apache.hadoop.ozone.recon.scm.ReconPipelineManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Endpoint to fetch details about Pipelines.\n+ */\n+@Path(\"/pipelines\")\n+@Produces(MediaType.APPLICATION_JSON)\n+public class PipelineEndpoint {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineEndpoint.class);\n+\n+  private ReconPipelineManager pipelineManager;\n+\n+  @Inject\n+  PipelineEndpoint(OzoneStorageContainerManager reconSCM) {\n+    this.pipelineManager = (ReconPipelineManager) reconSCM.getPipelineManager();\n+  }\n+\n+  /**\n+   * Return the list of pipelines with detailed information about each pipeline.\n+   * @return {@link Response}\n+   */\n+  @GET\n+  public Response getPipelines() {\n+    List<PipelineMetadata> pipelinesList = new ArrayList<>();\n+    List<Pipeline> pipelines = pipelineManager.getPipelines();\n+\n+    for (Pipeline pipeline : pipelines) {\n+      String leaderNode;\n+      UUID pipelineId = pipeline.getId().getId();\n+      List<String> datanodes = new ArrayList<>();\n+      int containers;\n+      long duration =\n+          Instant.now().toEpochMilli() -\n+              pipeline.getCreationTimestamp().toEpochMilli();\n+      try {\n+        leaderNode = pipeline.getLeaderNode().getHostName();\n+      } catch (Exception e) {\n+        leaderNode = \"\";\n+        LOG.warn(\"Cannot get leader node for pipeline {}\",\n+            pipelineId);\n+      }\n+\n+      try {\n+        containers = pipelineManager.getNumberOfContainers(pipeline.getId());\n+      } catch (Exception ex) {\n+        containers = 0;\n+        LOG.warn(\"Cannot get containers for pipeline {} \", pipelineId);\n+      }\n+      for (DatanodeDetails datanode: pipeline.getNodes()) {\n+        datanodes.add(datanode.getHostName());\n+      }\n+\n+      PipelineMetadata pipelineMetadata = new PipelineMetadata(", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\nindex e758aca3d..ac8c0a88c 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/PipelineEndpoint.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.ozone.recon.api;\n \n-import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n import org.apache.hadoop.hdds.scm.server.OzoneStorageContainerManager;\n import org.apache.hadoop.ozone.recon.api.types.PipelineMetadata;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk2MjcxOA==", "url": "https://github.com/apache/ozone/pull/633#discussion_r387962718", "bodyText": "Can we keep the type of 'pipelineID' as UUID? Since the Pipeline endpoint uses UUID.", "author": "avijayanhwx", "createdAt": "2020-03-04T22:05:13Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+/**\n+ * Metadata object that contains pipeline information of a Datanode.\n+ */\n+public class DatanodePipeline {\n+  private String pipelineID;\n+  private String replicationType;\n+  private int replicationFactor;\n+\n+  public DatanodePipeline(String pipelineID, String replicationType,", "originalCommit": "beb9f6d4a6651479e865d177a08ca49fdb58e9e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "382791a35985e75cac0d3dddd735a10f753ef215", "chunk": "diff --git a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java\nindex 58b8136c2..90b5d50a8 100644\n--- a/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java\n+++ b/hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/DatanodePipeline.java\n\n@@ -17,22 +17,24 @@\n  */\n package org.apache.hadoop.ozone.recon.api.types;\n \n+import java.util.UUID;\n+\n /**\n  * Metadata object that contains pipeline information of a Datanode.\n  */\n public class DatanodePipeline {\n-  private String pipelineID;\n+  private UUID pipelineID;\n   private String replicationType;\n   private int replicationFactor;\n \n-  public DatanodePipeline(String pipelineID, String replicationType,\n+  public DatanodePipeline(UUID pipelineID, String replicationType,\n                           int replicationFactor) {\n     this.pipelineID = pipelineID;\n     this.replicationType = replicationType;\n     this.replicationFactor = replicationFactor;\n   }\n \n-  public String getPipelineID() {\n+  public UUID getPipelineID() {\n     return pipelineID;\n   }\n \n"}}, {"oid": "382791a35985e75cac0d3dddd735a10f753ef215", "url": "https://github.com/apache/ozone/commit/382791a35985e75cac0d3dddd735a10f753ef215", "message": "Address Review comments", "committedDate": "2020-03-05T01:00:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODQ5ODM2Nw==", "url": "https://github.com/apache/ozone/pull/633#discussion_r388498367", "bodyText": "minor nit. To be consistent with terminology, we can keep it as \"state\" instead of \"status\".", "author": "avijayanhwx", "createdAt": "2020-03-05T19:02:36Z", "path": "hadoop-ozone/recon/src/main/java/org/apache/hadoop/ozone/recon/api/types/PipelineMetadata.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.recon.api.types;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline.PipelineState;\n+\n+import javax.xml.bind.annotation.XmlAccessType;\n+import javax.xml.bind.annotation.XmlAccessorType;\n+import javax.xml.bind.annotation.XmlElement;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Metadata object that represents a Pipeline.\n+ */\n+@XmlAccessorType(XmlAccessType.FIELD)\n+public class PipelineMetadata {\n+\n+  @XmlElement(name = \"pipelineId\")\n+  private UUID pipelineId;\n+\n+  @XmlElement(name = \"status\")", "originalCommit": "382791a35985e75cac0d3dddd735a10f753ef215", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}