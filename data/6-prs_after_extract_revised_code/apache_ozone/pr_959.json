{"pr_number": 959, "pr_title": "HDDS-3186. Introduce generic SCMRatisRequest and SCMRatisResponse.", "pr_createdAt": "2020-05-22T19:18:20Z", "pr_url": "https://github.com/apache/ozone/pull/959", "timeline": [{"oid": "bae48c22e88975ff07a1ab44088dc5d266a5695b", "url": "https://github.com/apache/ozone/commit/bae48c22e88975ff07a1ab44088dc5d266a5695b", "message": "HDDS-3186. Initial version.", "committedDate": "2020-05-22T19:15:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ==", "url": "https://github.com/apache/ozone/pull/959#discussion_r429809699", "bodyText": "can we put this into SCMHAUtils?", "author": "timmylicheng", "createdAt": "2020-05-25T08:41:13Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import com.google.common.base.Strings;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.server.ServerUtils;\n+import org.apache.ratis.RaftConfigKeys;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.grpc.GrpcConfigKeys;\n+import org.apache.ratis.rpc.RpcType;\n+import org.apache.ratis.server.RaftServerConfigKeys;\n+import org.apache.ratis.util.SizeInBytes;\n+import org.apache.ratis.util.TimeDuration;\n+\n+import java.io.File;\n+import java.net.InetSocketAddress;\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+\n+public class RatisUtil {", "originalCommit": "bae48c22e88975ff07a1ab44088dc5d266a5695b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTg2MjgwMQ==", "url": "https://github.com/apache/ozone/pull/959#discussion_r429862801", "bodyText": "I have moved this to ReflectionUtil class which can be used for all the utility methods related to reflection. I will update the PR soon.\nI agree that we should use the existing SCMHAUtil instead of creating new RatisUtil", "author": "nandakumar131", "createdAt": "2020-05-25T10:32:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1MDkzNA==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430250934", "bodyText": "https://issues.apache.org/jira/browse/HDDS-3660 Track it here", "author": "timmylicheng", "createdAt": "2020-05-26T08:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1OTk2Mw==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430259963", "bodyText": "I feel it's ok to have ReflectionUtil, RatisUtil, and SCMHAUtil as they serve a different purpose.", "author": "nandakumar131", "createdAt": "2020-05-26T08:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwOTY5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java\nindex dc129caa7..1bc169743 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/RatisUtil.java\n\n@@ -29,64 +29,127 @@\n import org.apache.ratis.util.TimeDuration;\n \n import java.io.File;\n-import java.net.InetSocketAddress;\n import java.util.Collections;\n import java.util.concurrent.TimeUnit;\n \n-public class RatisUtil {\n+import static org.apache.ratis.server.RaftServerConfigKeys.Log;\n+import static org.apache.ratis.server.RaftServerConfigKeys.RetryCache;\n+import static org.apache.ratis.server.RaftServerConfigKeys.Rpc;\n+import static org.apache.ratis.server.RaftServerConfigKeys.Snapshot;\n+\n+/**\n+ * Ratis Util for SCM HA.\n+ */\n+public final class RatisUtil {\n \n   private RatisUtil() {\n   }\n \n \n-  //TODO: Remove ConfigurationSource!\n-  public static RaftProperties newRaftProperties(SCMHAConfiguration haConf, ConfigurationSource conf) {\n+  /**\n+   * Constructs new Raft Properties instance using {@link SCMHAConfiguration}.\n+   * @param haConf SCMHAConfiguration\n+   * @param conf ConfigurationSource\n+   */\n+  public static RaftProperties newRaftProperties(\n+      final SCMHAConfiguration haConf, final ConfigurationSource conf) {\n+    //TODO: Remove ConfigurationSource!\n     // TODO: Check the default values.\n-    // TODO: Use configuration to read all the values.\n     final RaftProperties properties = new RaftProperties();\n-\n-    final InetSocketAddress address = haConf.getRatisBindAddress();\n-    RaftConfigKeys.Rpc.setType(properties, RpcType.valueOf(haConf.getRatisRpcType()));\n-    GrpcConfigKeys.Server.setPort(properties, address.getPort());\n-    RaftServerConfigKeys.setStorageDir(properties, Collections.singletonList(getRatisStorageDirectory(haConf, conf)));\n-    RaftServerConfigKeys.Log.setSegmentSizeMax(properties, SizeInBytes.valueOf(haConf.getRaftSegmentSize()));\n-    RaftServerConfigKeys.Log.Appender.setBufferElementLimit(properties, haConf.getLogAppenderQueueByteLimit());\n-    RaftServerConfigKeys.Log.Appender.setBufferByteLimit(properties, SizeInBytes.valueOf(haConf.getLogAppenderQueueByteLimit()));\n-    RaftServerConfigKeys.Log.setPreallocatedSize(properties, SizeInBytes.valueOf(haConf.getPreallocatedSize()));\n-    RaftServerConfigKeys.Log.Appender.setInstallSnapshotEnabled(properties, false);\n-    RaftServerConfigKeys.Log.setPurgeGap(properties, 1000000);\n-    GrpcConfigKeys.setMessageSizeMax(properties, SizeInBytes.valueOf(\"32m\"));\n-    TimeDuration serverRequestTimeout = TimeDuration.valueOf(3000, TimeUnit.MILLISECONDS);\n-    RaftServerConfigKeys.Rpc.setRequestTimeout(properties, serverRequestTimeout);\n-    TimeDuration retryCacheTimeout = TimeDuration.valueOf(600000, TimeUnit.MILLISECONDS);\n-    RaftServerConfigKeys.RetryCache.setExpiryTime(properties, retryCacheTimeout);\n-    TimeDuration serverMinTimeout = TimeDuration.valueOf(1, TimeUnit.SECONDS);\n-    long serverMaxTimeoutDuration = serverMinTimeout.toLong(TimeUnit.MILLISECONDS) + 200;\n-    final TimeDuration serverMaxTimeout = TimeDuration.valueOf(serverMaxTimeoutDuration, TimeUnit.SECONDS);\n-    RaftServerConfigKeys.Rpc.setTimeoutMin(properties, serverMinTimeout);\n-    RaftServerConfigKeys.Rpc.setTimeoutMax(properties, serverMaxTimeout);\n-    RaftServerConfigKeys.Log.setSegmentCacheNumMax(properties, 2);\n-    TimeDuration leaderElectionMinTimeout = TimeDuration.valueOf(1, TimeUnit.SECONDS);\n-    RaftServerConfigKeys.Rpc.setTimeoutMin(properties, leaderElectionMinTimeout);\n-    long leaderElectionMaxTimeout = leaderElectionMinTimeout.toLong(TimeUnit.MILLISECONDS) + 200;\n-    RaftServerConfigKeys.Rpc.setTimeoutMax(properties, TimeDuration.valueOf(leaderElectionMaxTimeout, TimeUnit.MILLISECONDS));\n-    TimeDuration nodeFailureTimeout = TimeDuration.valueOf(120, TimeUnit.SECONDS);\n-    RaftServerConfigKeys.Notification.setNoLeaderTimeout(properties, nodeFailureTimeout);\n-    RaftServerConfigKeys.Rpc.setSlownessTimeout(properties, nodeFailureTimeout);\n-    RaftServerConfigKeys.Snapshot.setAutoTriggerEnabled(properties, true);\n-    RaftServerConfigKeys.Snapshot.setAutoTriggerThreshold(properties, 400000);\n-\n+    setRaftStorageDir(properties, haConf, conf);\n+    setRaftRpcProperties(properties, haConf);\n+    setRaftLogProperties(properties, haConf);\n+    setRaftRetryCacheProperties(properties, haConf);\n+    setRaftSnapshotProperties(properties, haConf);\n     return properties;\n   }\n \n   /**\n-   * Get the local directory where ratis logs will be stored.\n+   * Set the local directory where ratis logs will be stored.\n+   *\n+   * @param properties RaftProperties instance which will be updated\n+   * @param haConf SCMHAConfiguration\n+   * @param conf ConfigurationSource\n    */\n-  public static File getRatisStorageDirectory(SCMHAConfiguration haConf, ConfigurationSource conf) {\n+  public static void setRaftStorageDir(final RaftProperties properties,\n+                                       final SCMHAConfiguration haConf,\n+                                       final ConfigurationSource conf) {\n     String storageDir = haConf.getRatisStorageDir();\n     if (Strings.isNullOrEmpty(storageDir)) {\n       storageDir = ServerUtils.getDefaultRatisDirectory(conf);\n     }\n-    return new File(storageDir);\n+    RaftServerConfigKeys.setStorageDir(properties,\n+        Collections.singletonList(new File(storageDir)));\n+  }\n+\n+  /**\n+   * Set properties related to Raft RPC.\n+   *\n+   * @param properties RaftProperties instance which will be updated\n+   * @param conf SCMHAConfiguration\n+   */\n+  private static void setRaftRpcProperties(final RaftProperties properties,\n+                                           final SCMHAConfiguration conf) {\n+    RaftConfigKeys.Rpc.setType(properties,\n+        RpcType.valueOf(conf.getRatisRpcType()));\n+    GrpcConfigKeys.Server.setPort(properties,\n+        conf.getRatisBindAddress().getPort());\n+    GrpcConfigKeys.setMessageSizeMax(properties,\n+        SizeInBytes.valueOf(\"32m\"));\n+\n+    Rpc.setRequestTimeout(properties, TimeDuration.valueOf(\n+        conf.getRatisRequestTimeout(), TimeUnit.MILLISECONDS));\n+    Rpc.setTimeoutMin(properties, TimeDuration.valueOf(\n+        conf.getRatisRequestMinTimeout(), TimeUnit.MILLISECONDS));\n+    Rpc.setTimeoutMax(properties, TimeDuration.valueOf(\n+        conf.getRatisRequestMaxTimeout(), TimeUnit.MILLISECONDS));\n+    Rpc.setSlownessTimeout(properties, TimeDuration.valueOf(\n+        conf.getRatisNodeFailureTimeout(), TimeUnit.MILLISECONDS));\n+  }\n+\n+  /**\n+   * Set properties related to Raft Log.\n+   *\n+   * @param properties RaftProperties instance which will be updated\n+   * @param conf SCMHAConfiguration\n+   */\n+  private static void setRaftLogProperties(final RaftProperties properties,\n+                                           final SCMHAConfiguration conf) {\n+    Log.setSegmentSizeMax(properties,\n+        SizeInBytes.valueOf(conf.getRaftSegmentSize()));\n+    Log.Appender.setBufferElementLimit(properties,\n+        conf.getRaftLogAppenderQueueByteLimit());\n+    Log.Appender.setBufferByteLimit(properties,\n+        SizeInBytes.valueOf(conf.getRaftLogAppenderQueueByteLimit()));\n+    Log.setPreallocatedSize(properties,\n+        SizeInBytes.valueOf(conf.getRaftSegmentPreAllocatedSize()));\n+    Log.Appender.setInstallSnapshotEnabled(properties, false);\n+    Log.setPurgeGap(properties, conf.getRaftLogPurgeGap());\n+    Log.setSegmentCacheNumMax(properties, 2);\n+  }\n+\n+  /**\n+   * Set properties related to Raft Retry Cache.\n+   *\n+   * @param properties RaftProperties instance which will be updated\n+   * @param conf SCMHAConfiguration\n+   */\n+  private static void setRaftRetryCacheProperties(\n+      final RaftProperties properties, final SCMHAConfiguration conf) {\n+    RetryCache.setExpiryTime(properties, TimeDuration.valueOf(\n+        conf.getRatisRetryCacheTimeout(), TimeUnit.MILLISECONDS));\n+  }\n+\n+  /**\n+   * Set properties related to Raft Snapshot.\n+   *\n+   * @param properties RaftProperties instance which will be updated\n+   * @param conf SCMHAConfiguration\n+   */\n+  private static void setRaftSnapshotProperties(\n+      final RaftProperties properties, final SCMHAConfiguration conf) {\n+    Snapshot.setAutoTriggerEnabled(properties, true);\n+    Snapshot.setAutoTriggerThreshold(properties, 400000);\n   }\n+\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA==", "url": "https://github.com/apache/ozone/pull/959#discussion_r429810890", "bodyText": "I've merged SCMRatisServer and SCMStateMachine into one between /ha and /ratis in timmylicheng#1. We can use /ha as your did here, but we need to combine all methods into one.", "author": "timmylicheng", "createdAt": "2020-05-25T08:43:36Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.ha;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.ratis.conf.RaftProperties;\n+import org.apache.ratis.protocol.ClientId;\n+import org.apache.ratis.protocol.RaftClientReply;\n+import org.apache.ratis.protocol.RaftClientRequest;\n+import org.apache.ratis.protocol.RaftGroup;\n+import org.apache.ratis.protocol.RaftGroupId;\n+import org.apache.ratis.protocol.RaftPeer;\n+import org.apache.ratis.protocol.RaftPeerId;\n+import org.apache.ratis.server.RaftServer;\n+\n+public class SCMRatisServer {", "originalCommit": "bae48c22e88975ff07a1ab44088dc5d266a5695b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTg2MzgxOQ==", "url": "https://github.com/apache/ozone/pull/959#discussion_r429863819", "bodyText": "I don't think we need to copy all the code/methods from OzoneManagerHA implementation. We can add things to SCMHA related classes whenever required.\nIt's better not to have code that is not used or needed.\nLet's add/update the SCMHA code when needed.", "author": "nandakumar131", "createdAt": "2020-05-25T10:34:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjgxMA==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430126810", "bodyText": "How about Snapshot in SCMStateMachine?", "author": "timmylicheng", "createdAt": "2020-05-26T02:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1MjE0NA==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430252144", "bodyText": "Track the issue in https://issues.apache.org/jira/browse/HDDS-3661.\nThis is to split the work.", "author": "timmylicheng", "createdAt": "2020-05-26T08:45:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI1ODkxOA==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430258918", "bodyText": "Let's configure/enable Ratis snapshot after we have some design plan on how to implement the snapshot.", "author": "nandakumar131", "createdAt": "2020-05-26T08:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgxMDg5MA=="}], "type": "inlineReview", "revised_code": {"commit": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java\nindex bfdac0110..209535d14 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/ha/SCMRatisServer.java\n\n@@ -27,7 +27,7 @@\n import java.util.concurrent.atomic.AtomicLong;\n \n import org.apache.hadoop.hdds.conf.ConfigurationSource;\n-import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocolProtos;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocol.RequestType;\n import org.apache.ratis.conf.RaftProperties;\n import org.apache.ratis.protocol.ClientId;\n import org.apache.ratis.protocol.RaftClientReply;\n"}}, {"oid": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "url": "https://github.com/apache/ozone/commit/ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "message": "HDDS-3186. Additional changes.", "committedDate": "2020-05-25T18:24:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjkzNw==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430126937", "bodyText": "Do we need to addContainerToDB here?", "author": "timmylicheng", "createdAt": "2020-05-26T02:31:43Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/ContainerManagerImpl.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership.  The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p/>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p/>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.container;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ContainerInfoProto;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleState;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.LifeCycleEvent;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.pipeline.Pipeline;\n+import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * TODO: Add javadoc.\n+ */\n+public class ContainerManagerImpl implements ContainerManagerV2 {\n+\n+  /**\n+   *\n+   */\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      ContainerManagerImpl.class);\n+\n+  /**\n+   *\n+   */\n+  private final ReadWriteLock lock;\n+\n+  /**\n+   *\n+   */\n+  private final PipelineManager pipelineManager;\n+\n+  /**\n+   *\n+   */\n+  private final ContainerStateManagerV2 containerStateManager;\n+\n+  /**\n+   *\n+   */\n+  public ContainerManagerImpl(\n+      // Introduce builder for this class?\n+      final Configuration conf, final PipelineManager pipelineManager,\n+      final SCMHAManager scmhaManager,\n+      final Table<ContainerID, ContainerInfo> containerStore)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineManager = pipelineManager;\n+    this.containerStateManager =  ContainerStateManagerImpl.newBuilder()\n+        .setConfiguration(conf)\n+        .setPipelineManager(pipelineManager)\n+        .setRatisServer(scmhaManager.getRatisServer())\n+        .setContainerStore(containerStore)\n+        .build();\n+  }\n+\n+  @Override\n+  public Set<ContainerID> getContainerIDs() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs();\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers() {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs().stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo getContainer(final ContainerID containerID)\n+      throws ContainerNotFoundException {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainer(containerID);\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public Set<ContainerInfo> getContainers(final LifeCycleState state) {\n+    lock.readLock().lock();\n+    try {\n+      return containerStateManager.getContainerIDs(state).stream().map(id -> {\n+        try {\n+          return containerStateManager.getContainer(id);\n+        } catch (ContainerNotFoundException e) {\n+          // How can this happen? o_O\n+          return null;\n+        }\n+      }).filter(Objects::nonNull).collect(Collectors.toSet());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public boolean exists(final ContainerID containerID) {\n+    lock.readLock().lock();\n+    try {\n+      return (containerStateManager.getContainer(containerID) != null);\n+    } catch (ContainerNotFoundException ex) {\n+      return false;\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public List<ContainerInfo> listContainers(final ContainerID startID,\n+                                            final int count) {\n+    lock.readLock().lock();\n+    try {\n+      final long startId = startID == null ? 0 : startID.getId();\n+      final List<ContainerID> containersIds =\n+          new ArrayList<>(containerStateManager.getContainerIDs());\n+      Collections.sort(containersIds);\n+      return containersIds.stream()\n+          .filter(id -> id.getId() > startId)\n+          .limit(count)\n+          .map(id -> {\n+            try {\n+              return containerStateManager.getContainer(id);\n+            } catch (ContainerNotFoundException ex) {\n+              // This can never happen, as we hold lock no one else can remove\n+              // the container after we got the container ids.\n+              LOG.warn(\"Container Missing.\", ex);\n+              return null;\n+            }\n+          }).collect(Collectors.toList());\n+    } finally {\n+      lock.readLock().unlock();\n+    }\n+  }\n+\n+  @Override\n+  public ContainerInfo allocateContainer(final ReplicationType type,\n+      final ReplicationFactor replicationFactor, final String owner)\n+      throws IOException {\n+    lock.writeLock().lock();\n+    try {\n+      final List<Pipeline> pipelines = pipelineManager\n+          .getPipelines(type, replicationFactor, Pipeline.PipelineState.OPEN);\n+\n+      if (pipelines.isEmpty()) {\n+        throw new IOException(\"Could not allocate container. Cannot get any\" +\n+            \" matching pipeline for Type:\" + type + \", Factor:\" +\n+            replicationFactor + \", State:PipelineState.OPEN\");\n+      }\n+\n+      final ContainerID containerID = containerStateManager\n+          .getNextContainerID();\n+      final Pipeline pipeline = pipelines.get(\n+          (int) containerID.getId() % pipelines.size());\n+\n+      final ContainerInfoProto containerInfo = ContainerInfoProto.newBuilder()\n+          .setState(LifeCycleState.OPEN)\n+          .setPipelineID(pipeline.getId().getProtobuf())\n+          .setUsedBytes(0)\n+          .setNumberOfKeys(0)\n+          .setStateEnterTime(Time.now())\n+          .setOwner(owner)\n+          .setContainerID(containerID.getId())\n+          .setDeleteTransactionId(0)\n+          .setReplicationFactor(pipeline.getFactor())\n+          .setReplicationType(pipeline.getType())\n+          .build();\n+      containerStateManager.addContainer(containerInfo);", "originalCommit": "ecdfa6d5a2dabe64f0d291273d8929221ff8fda3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI2MDcxNg==", "url": "https://github.com/apache/ozone/pull/959#discussion_r430260716", "bodyText": "It is handled inside ContainerStateManager.", "author": "nandakumar131", "createdAt": "2020-05-26T08:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDEyNjkzNw=="}], "type": "inlineReview", "revised_code": null}]}