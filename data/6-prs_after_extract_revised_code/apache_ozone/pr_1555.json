{"pr_number": 1555, "pr_title": "HDDS-4347.Make Ozone specific Trash remover multi threaded", "pr_createdAt": "2020-11-06T06:42:55Z", "pr_url": "https://github.com/apache/ozone/pull/1555", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNTkyOQ==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521135929", "bodyText": "Please remove the * imports", "author": "bshashikant", "createdAt": "2020-11-11T06:19:02Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;", "originalCommit": "49dec78ee794e898a0c083927238ec036131d1e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex 5d41c69cd..baf75420c 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -17,10 +17,6 @@\n  */\n package org.apache.hadoop.ozone.om;\n \n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521136226", "bodyText": "Why do we need to copy these functions? Is it doing anything special with respect to ozone\n/", "author": "bshashikant", "createdAt": "2020-11-11T06:20:01Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.*;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }\n+    }\n+\n+\n+    private long ceiling(long time, long interval) {\n+      return floor(time, interval) + interval;\n+    }\n+    private long floor(long time, long interval) {\n+      return (time / interval) * interval;\n+    }\n+\n+  }\n+\n+  private void createCheckpoint(Path trashRoot, Date date) throws IOException {", "originalCommit": "49dec78ee794e898a0c083927238ec036131d1e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE1MTMwNA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521151304", "bodyText": "Cant override these methods from TrashPolicyDefault since they have private scope in TrashPolicyDefault.so had to copy.", "author": "sadanand48", "createdAt": "2020-11-11T06:54:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE1Mzc0OA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521153748", "bodyText": "If you want to use the same functionality as already existing, there is no need to override.", "author": "bshashikant", "createdAt": "2020-11-11T06:57:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE3NzE0NQ==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r521177145", "bodyText": "Understood.", "author": "bshashikant", "createdAt": "2020-11-11T07:54:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzNjIyNg=="}], "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex 5d41c69cd..baf75420c 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -17,10 +17,6 @@\n  */\n package org.apache.hadoop.ozone.om;\n \n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0ODg4Nw==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525648887", "bodyText": "why are these tests commented out ?", "author": "prashantpogde", "createdAt": "2020-11-18T02:10:43Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,19 +210,19 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)\n   public void testFileSystem() throws Exception {\n     setupOzoneFileSystem();\n \n     testOzoneFsServiceLoader();\n     o3fs = (OzoneFileSystem) fs;\n \n-    testCreateFileShouldCheckExistenceOfDirWithSameName();\n+  /*  testCreateFileShouldCheckExistenceOfDirWithSameName();", "originalCommit": "d455115f71f3634442048527ad6fdadefbd5d5a0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\nindex 2f3ca2433..b54644268 100644\n--- a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n+++ b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n\n@@ -217,7 +217,7 @@ public void testFileSystem() throws Exception {\n     testOzoneFsServiceLoader();\n     o3fs = (OzoneFileSystem) fs;\n \n-  /*  testCreateFileShouldCheckExistenceOfDirWithSameName();\n+    testCreateFileShouldCheckExistenceOfDirWithSameName();\n     testMakeDirsWithAnExistingDirectoryPath();\n     testCreateWithInvalidPaths();\n     testListStatusWithIntermediateDir();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MjY2Nw==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r525652667", "bodyText": "this check should be inside run method in TrashPolicyOzone. I also do not see a problem if it was run on all OM nodes.", "author": "prashantpogde", "createdAt": "2020-11-18T02:16:30Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1228,17 +1238,61 @@ public void restart() throws IOException {\n       // Allow OM to start as Http Server failure is not fatal.\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n-\n     omRpcServer.start();\n+\n     isOmRpcServerRunning = true;\n \n+    if (isLeader()) {", "originalCommit": "d455115f71f3634442048527ad6fdadefbd5d5a0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\nindex 36af38858..2d2c9f468 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n\n@@ -1239,13 +1243,11 @@ public void restart() throws IOException {\n       LOG.error(\"OM HttpServer failed to start.\", ex);\n     }\n     omRpcServer.start();\n-\n     isOmRpcServerRunning = true;\n \n-    if (isLeader()) {\n-      startTrashEmptier(configuration);\n-    }\n-\n+    // TODO: Start this thread only on the leader node.\n+    //  Should be fixed after HDDS-4451.\n+    startTrashEmptier(configuration);\n     registerMXBean();\n \n     startJVMPauseMonitor();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2NTg5Ng==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526065896", "bodyText": "Can we try to catch Exception rather than IOException to avoid uncaught exception that may be swallowed here?", "author": "linyiqun", "createdAt": "2020-11-18T12:58:06Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {", "originalCommit": "d455115f71f3634442048527ad6fdadefbd5d5a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjE0NTA0NA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526145044", "bodyText": "done.", "author": "sadanand48", "createdAt": "2020-11-18T14:48:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2NTg5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex 59d5bb386..baf75420c 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -17,10 +17,6 @@\n  */\n package org.apache.hadoop.ozone.om;\n \n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA4NzY3OA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526087678", "bodyText": "Can we shutdown executor pool in the finally block?\n        try {\n             while (true) {\n                 ....\n             }\n         } finally {\n            shutdown executor pool.\n         }", "author": "linyiqun", "createdAt": "2020-11-18T13:29:38Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.ozone.om;\n+\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n+import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.text.DateFormat;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.TrashPolicyDefault;\n+import org.apache.hadoop.fs.FileAlreadyExistsException;\n+import org.apache.hadoop.fs.permission.FsAction;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** TrashPolicy for Ozone Specific Trash Operations.Through this implementation\n+ *  of TrashPolicy ozone-specific trash optimizations are/will be made such as\n+ *  having a multithreaded TrashEmptier.\n+ */\n+public class TrashPolicyOzone extends TrashPolicyDefault {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TrashPolicyOzone.class);\n+\n+  private static final Path CURRENT = new Path(\"Current\");\n+\n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n+\n+  private static final FsPermission PERMISSION =\n+      new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n+\n+  private static final DateFormat CHECKPOINT = new SimpleDateFormat(\n+      \"yyMMddHHmmss\");\n+  /** Format of checkpoint directories used prior to Hadoop 0.23. */\n+  private static final DateFormat OLD_CHECKPOINT =\n+      new SimpleDateFormat(\"yyMMddHHmm\");\n+  private static final int MSECS_PER_MINUTE = 60*1000;\n+\n+  private long emptierInterval;\n+\n+  public TrashPolicyOzone(){\n+  }\n+\n+  private TrashPolicyOzone(FileSystem fs, Configuration conf){\n+    initialize(conf, fs);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs, Path path) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+  }\n+\n+  @Override\n+  public void initialize(Configuration conf, FileSystem fs) {\n+    this.fs = fs;\n+    this.deletionInterval = (long)(conf.getFloat(\n+        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    this.emptierInterval = (long)(conf.getFloat(\n+        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)\n+        * MSECS_PER_MINUTE);\n+    if (deletionInterval < 0) {\n+      LOG.warn(\"Invalid value {} for deletion interval,\"\n+          + \" deletion interaval can not be negative.\"\n+          + \"Changing to default value 0\", deletionInterval);\n+      this.deletionInterval = 0;\n+    }\n+  }\n+\n+\n+  public Runnable getEmptier() throws IOException {\n+    return new TrashPolicyOzone.Emptier(getConf(), emptierInterval);\n+  }\n+\n+\n+  protected class Emptier implements Runnable {\n+\n+    private Configuration conf;\n+    // same as checkpoint interval\n+    private long emptierInterval;\n+\n+\n+    private ThreadPoolExecutor executor;\n+\n+    Emptier(Configuration conf, long emptierInterval) throws IOException {\n+      this.conf = conf;\n+      this.emptierInterval = emptierInterval;\n+      if (emptierInterval > deletionInterval || emptierInterval <= 0) {\n+        LOG.info(\"The configured checkpoint interval is \" +\n+            (emptierInterval / MSECS_PER_MINUTE) + \" minutes.\" +\n+            \" Using an interval of \" +\n+            (deletionInterval / MSECS_PER_MINUTE) +\n+            \" minutes that is used for deletion instead\");\n+        this.emptierInterval = deletionInterval;\n+      }\n+      LOG.info(\"Ozone Manager trash configuration: Deletion interval = \"\n+          + (deletionInterval / MSECS_PER_MINUTE)\n+          + \" minutes, Emptier interval = \"\n+          + (this.emptierInterval / MSECS_PER_MINUTE) + \" minutes.\");\n+      executor = new ThreadPoolExecutor(TRASH_EMPTIER_CORE_POOL_SIZE,\n+          TRASH_EMPTIER_CORE_POOL_SIZE, 1,\n+          TimeUnit.SECONDS, new ArrayBlockingQueue<>(1024),\n+          new ThreadPoolExecutor.CallerRunsPolicy());\n+    }\n+\n+    @Override\n+    public void run() {\n+      if (emptierInterval == 0) {\n+        return;                                   // trash disabled\n+      }\n+      long now, end;\n+      while (true) {\n+        now = Time.now();\n+        end = ceiling(now, emptierInterval);\n+        try {\n+          // sleep for interval\n+          Thread.sleep(end - now);\n+        } catch (InterruptedException e) {\n+          break;                                  // exit on interrupt\n+        }\n+\n+        try {\n+          now = Time.now();\n+          if (now >= end) {\n+            Collection<FileStatus> trashRoots;\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n+              if (!trashRoot.isDirectory()) {\n+                continue;\n+              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+                  trash.deleteCheckpoint(trashRoot.getPath(), false);\n+                  trash.createCheckpoint(trashRoot.getPath(),\n+                          new Date(Time.now()));\n+                } catch (IOException e) {\n+                  LOG.info(\"Unable to checkpoint\");\n+                }\n+              };\n+              executor.submit(task);\n+              LOG.info(\"Current threads in pool: \"\n+                  + executor.getPoolSize());\n+              LOG.info(\"Currently executing threads: \"\n+                  + executor.getActiveCount());\n+              LOG.info(\"Total number of threads(ever scheduled): \"\n+                  + executor.getTaskCount());\n+            }\n+          }\n+        } catch (Exception e) {\n+          LOG.warn(\"RuntimeException during Trash.Emptier.run(): \", e);\n+        }\n+      }\n+      try {\n+        fs.close();\n+      } catch(IOException e) {\n+        LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      }", "originalCommit": "d455115f71f3634442048527ad6fdadefbd5d5a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjE0NTEzOQ==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r526145139", "bodyText": "done.", "author": "sadanand48", "createdAt": "2020-11-18T14:48:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA4NzY3OA=="}], "type": "inlineReview", "revised_code": {"commit": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex 59d5bb386..baf75420c 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -17,10 +17,6 @@\n  */\n package org.apache.hadoop.ozone.om;\n \n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_CHECKPOINT_INTERVAL_KEY;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_DEFAULT;\n-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;\n \n import java.io.FileNotFoundException;\n import java.io.IOException;\n"}}, {"oid": "7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "url": "https://github.com/apache/ozone/commit/7447b94d902f2a4d19d2bc24dc3dfecfb5f54f71", "message": "Rebase changes", "committedDate": "2020-11-18T13:41:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzU3MDc5Ng==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527570796", "bodyText": "why do we need to increase the timeout ?", "author": "mukul1987", "createdAt": "2020-11-20T09:45:03Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -206,7 +209,7 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 300_000)\n+  @Test(timeout = 540_000)", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\nindex d7a0fd657..7771e1005 100644\n--- a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n+++ b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n\n@@ -209,7 +200,7 @@ private void checkInvalidPath(Path path) throws Exception {\n     }\n   }\n \n-  @Test(timeout = 540_000)\n+  @Test(timeout = 300_000)\n   public void testFileSystem() throws Exception {\n     setupOzoneFileSystem();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTM5MA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671390", "bodyText": "This should be outside the runnable function.", "author": "mukul1987", "createdAt": "2020-11-20T12:52:46Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n-              try {\n-                TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n-                trash.deleteCheckpoint(trashRoot.getPath(), false);\n-                trash.createCheckpoint(trashRoot.getPath(), new Date(now));\n-              } catch (IOException e) {\n-                LOG.warn(\"Trash caught: \"+e+\". Skipping \" +\n-                    trashRoot.getPath() + \".\");\n-              }\n+              Runnable task = ()->{\n+                try {\n+                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex baf75420c..ae6c45800 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -132,18 +182,18 @@ public void run() {\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n             trashRoots = fs.getTrashRoots(true); // list all trash dirs\n-            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            LOG.debug(\"Trash root Size: \" + trashRoots.size());\n             for (FileStatus trashRoot : trashRoots) {  // dump each trash\n               LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n+              TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf, om);\n               Runnable task = ()->{\n                 try {\n-                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n                   trash.deleteCheckpoint(trashRoot.getPath(), false);\n                   trash.createCheckpoint(trashRoot.getPath(),\n-                          new Date(Time.now()));\n+                      new Date(Time.now()));\n                 } catch (Exception e) {\n                   LOG.info(\"Unable to checkpoint\");\n                 }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTYxMg==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671612", "bodyText": "Same as above.", "author": "mukul1987", "createdAt": "2020-11-20T12:53:13Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex baf75420c..ae6c45800 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -132,18 +182,18 @@ public void run() {\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n             trashRoots = fs.getTrashRoots(true); // list all trash dirs\n-            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            LOG.debug(\"Trash root Size: \" + trashRoots.size());\n             for (FileStatus trashRoot : trashRoots) {  // dump each trash\n               LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n+              TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf, om);\n               Runnable task = ()->{\n                 try {\n-                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n                   trash.deleteCheckpoint(trashRoot.getPath(), false);\n                   trash.createCheckpoint(trashRoot.getPath(),\n-                          new Date(Time.now()));\n+                      new Date(Time.now()));\n                 } catch (Exception e) {\n                   LOG.info(\"Unable to checkpoint\");\n                 }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTc0NA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527671744", "bodyText": "Please change the LOG.info to LOG.debug", "author": "mukul1987", "createdAt": "2020-11-20T12:53:29Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +131,24 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs\n+            LOG.info(\"TrashrootSize: \" + trashRoots.size());", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex baf75420c..ae6c45800 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -132,18 +182,18 @@ public void run() {\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n             trashRoots = fs.getTrashRoots(true); // list all trash dirs\n-            LOG.info(\"TrashrootSize: \" + trashRoots.size());\n+            LOG.debug(\"Trash root Size: \" + trashRoots.size());\n             for (FileStatus trashRoot : trashRoots) {  // dump each trash\n               LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n+              TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf, om);\n               Runnable task = ()->{\n                 try {\n-                  TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n                   trash.deleteCheckpoint(trashRoot.getPath(), false);\n                   trash.createCheckpoint(trashRoot.getPath(),\n-                          new Date(Time.now()));\n+                      new Date(Time.now()));\n                 } catch (Exception e) {\n                   LOG.info(\"Unable to checkpoint\");\n                 }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjE5OA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672198", "bodyText": "We also need to do executor.awaitTermination as well here.", "author": "mukul1987", "createdAt": "2020-11-20T12:54:27Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -139,9 +159,12 @@ public void run() {\n         fs.close();\n       } catch(IOException e) {\n         LOG.warn(\"Trash cannot close FileSystem: \", e);\n+      } finally {\n+        executor.shutdown();", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex baf75420c..ae6c45800 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -161,10 +211,14 @@ public void run() {\n         LOG.warn(\"Trash cannot close FileSystem: \", e);\n       } finally {\n         executor.shutdown();\n+        try {\n+          executor.awaitTermination(60, TimeUnit.SECONDS);\n+        } catch (InterruptedException e) {\n+          LOG.error(\"Error attempting to shutdown\");\n+        }\n       }\n     }\n \n-\n     private long ceiling(long time, long interval) {\n       return floor(time, interval) + interval;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MjUxOA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r527672518", "bodyText": "Please change this to great from a config.", "author": "mukul1987", "createdAt": "2020-11-20T12:55:03Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -49,6 +53,8 @@\n \n   private static final Path CURRENT = new Path(\"Current\");\n \n+  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;", "originalCommit": "62383d005e00ab9b355e21bd9942c067b135606a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8aecec9de30ad4b1b01aeac1a458c87f89c92310", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex baf75420c..7006ea742 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -53,8 +59,6 @@\n \n   private static final Path CURRENT = new Path(\"Current\");\n \n-  private final static int TRASH_EMPTIER_CORE_POOL_SIZE = 5;\n-\n   private static final FsPermission PERMISSION =\n       new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODQyOA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788428", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_CHECKPOINT_INTERVAL_KEY here", "author": "mukul1987", "createdAt": "2020-11-30T17:54:10Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.checkpoint.interval\",", "originalCommit": "aa19ae01045398828a93de9388839abb127adfe7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA4MDg2Ng==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r533080866", "bodyText": "done", "author": "sadanand48", "createdAt": "2020-12-01T05:25:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODQyOA=="}], "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\nindex 28e03c879..7771e1005 100644\n--- a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n+++ b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n\n@@ -784,6 +772,7 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+\n   /**\n    * 1.Move a Key to Trash\n    * 2.Verify that the key gets deleted by the trash emptier.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODY4Mg==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532788682", "bodyText": "Lets use CommonConfigurationKeysPublic#FS_TRASH_INTERVAL_KEY here", "author": "mukul1987", "createdAt": "2020-11-30T17:54:32Z", "path": "hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java", "diffHunk": "@@ -776,4 +784,59 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+  /**\n+   * 1.Move a Key to Trash\n+   * 2.Verify that the key gets deleted by the trash emptier.\n+   * @throws Exception\n+   */\n+\n+  public void testTrash() throws Exception {\n+    String testKeyName = \"testKey2\";\n+    Path path = new Path(OZONE_URI_DELIMITER, testKeyName);\n+    ContractTestUtils.touch(fs, path);\n+    Assert.assertTrue(trash.getConf().getClass(\n+        \"fs.trash.classname\", TrashPolicy.class).\n+        isAssignableFrom(TrashPolicyOzone.class));\n+    Assert.assertEquals(trash.getConf().getInt(\"fs.trash.interval\", 0), 1);", "originalCommit": "aa19ae01045398828a93de9388839abb127adfe7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzA4MDg2MA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r533080860", "bodyText": "done", "author": "sadanand48", "createdAt": "2020-12-01T05:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4ODY4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\nindex 28e03c879..7771e1005 100644\n--- a/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n+++ b/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java\n\n@@ -784,6 +772,7 @@ public void testRenameToTrashEnabled() throws Exception {\n     // Cleanup\n     o3fs.delete(trashRoot, true);\n   }\n+\n   /**\n    * 1.Move a Key to Trash\n    * 2.Verify that the key gets deleted by the trash emptier.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r532789545", "bodyText": "I think this is intentional. @elek @bharatviswa504 can you please confirm this line ?", "author": "mukul1987", "createdAt": "2020-11-30T17:55:50Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -1275,7 +1275,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new Configuration();\n+    Configuration fsconf = new OzoneConfiguration();", "originalCommit": "aa19ae01045398828a93de9388839abb127adfe7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI1MTYyMw==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536251623", "bodyText": "From my understanding, we need to use OzoneConfiguration, as OzoneConfiguration activates ozone-default.xml\npublic static void activate() {\n// adds the default resources\nConfiguration.addDefaultResource(\"hdfs-default.xml\");\nConfiguration.addDefaultResource(\"hdfs-site.xml\");\nConfiguration.addDefaultResource(\"ozone-default.xml\");\n}\nBy using Configuration, defaults of Ozone will not be loaded. And also as we have for each config, we have defaults defined in Java code that should also be fine.\nUsing OzoneConfiguration is better IMHO.", "author": "bharatviswa504", "createdAt": "2020-12-04T17:16:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2OTI5OQ==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r537569299", "bodyText": "thx @bharatviswa504", "author": "mukul1987", "createdAt": "2020-12-07T14:54:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4OTU0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\nindex 53d93b3cc..1b4fc47dc 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n\n@@ -1275,7 +1271,7 @@ private void startTrashEmptier(Configuration conf) throws IOException {\n \n     // configuration for the FS instance that  points to a root OFS uri.\n     // This will ensure that it will cover all volumes and buckets\n-    Configuration fsconf = new OzoneConfiguration();\n+    Configuration fsconf = new Configuration();\n     String rootPath = String.format(\"%s://%s/\",\n             OzoneConsts.OZONE_OFS_URI_SCHEME, conf.get(OZONE_OM_ADDRESS_KEY));\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjU2Mjg2MA==", "url": "https://github.com/apache/ozone/pull/1555#discussion_r536562860", "bodyText": "I know it's committed in the previous commit, but can you please help me to understand why do we need FileSystem in OM side? As far as I understood the design doc has more cons against this approach.", "author": "elek", "createdAt": "2020-12-05T08:37:59Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java", "diffHunk": "@@ -115,20 +128,23 @@ public void run() {\n           now = Time.now();\n           if (now >= end) {\n             Collection<FileStatus> trashRoots;\n-            trashRoots = fs.getTrashRoots(true);      // list all trash dirs\n-\n-            for (FileStatus trashRoot : trashRoots) {   // dump each trash\n+            trashRoots = fs.getTrashRoots(true); // list all trash dirs", "originalCommit": "d28ee25d6adc25a9802badce75bca1705f41f055", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\nindex 4f9d9fd02..ae6c45800 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/TrashPolicyOzone.java\n\n@@ -131,15 +184,16 @@ public void run() {\n             trashRoots = fs.getTrashRoots(true); // list all trash dirs\n             LOG.debug(\"Trash root Size: \" + trashRoots.size());\n             for (FileStatus trashRoot : trashRoots) {  // dump each trash\n+              LOG.info(\"Trashroot:\" + trashRoot.getPath().toString());\n               if (!trashRoot.isDirectory()) {\n                 continue;\n               }\n-              TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf);\n+              TrashPolicyOzone trash = new TrashPolicyOzone(fs, conf, om);\n               Runnable task = ()->{\n                 try {\n                   trash.deleteCheckpoint(trashRoot.getPath(), false);\n                   trash.createCheckpoint(trashRoot.getPath(),\n-                          new Date(Time.now()));\n+                      new Date(Time.now()));\n                 } catch (Exception e) {\n                   LOG.info(\"Unable to checkpoint\");\n                 }\n"}}, {"oid": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "url": "https://github.com/apache/ozone/commit/87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "message": "resolve conflicts", "committedDate": "2020-12-14T16:19:52Z", "type": "commit"}, {"oid": "87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "url": "https://github.com/apache/ozone/commit/87e0376ac466e6910eb67b9fb4a7f6227f0d70aa", "message": "resolve conflicts", "committedDate": "2020-12-14T16:19:52Z", "type": "forcePushed"}, {"oid": "8aecec9de30ad4b1b01aeac1a458c87f89c92310", "url": "https://github.com/apache/ozone/commit/8aecec9de30ad4b1b01aeac1a458c87f89c92310", "message": "remove * import", "committedDate": "2020-12-14T16:33:23Z", "type": "commit"}, {"oid": "5cea401d8cb7de66cacadbd20b4fc5b54e91726d", "url": "https://github.com/apache/ozone/commit/5cea401d8cb7de66cacadbd20b4fc5b54e91726d", "message": "trigger new CI check", "committedDate": "2021-01-01T05:01:39Z", "type": "commit"}, {"oid": "723af8a4e49a0deeebed14ebe3c691ad96a330fb", "url": "https://github.com/apache/ozone/commit/723af8a4e49a0deeebed14ebe3c691ad96a330fb", "message": "trigger new CI check", "committedDate": "2021-01-01T05:02:23Z", "type": "commit"}, {"oid": "bcd1fd1d08c55394727672be000bf28bd80cf6d7", "url": "https://github.com/apache/ozone/commit/bcd1fd1d08c55394727672be000bf28bd80cf6d7", "message": "resolve test failure", "committedDate": "2021-01-02T06:19:15Z", "type": "commit"}, {"oid": "2e3c1a99240a0976fe7d39892a55b3d1d5a0d324", "url": "https://github.com/apache/ozone/commit/2e3c1a99240a0976fe7d39892a55b3d1d5a0d324", "message": "trigger new CI check", "committedDate": "2021-01-02T07:37:15Z", "type": "commit"}, {"oid": "ca071209c860ab45ef7e393d2857cce47238b99e", "url": "https://github.com/apache/ozone/commit/ca071209c860ab45ef7e393d2857cce47238b99e", "message": "trigger new CI check", "committedDate": "2021-01-04T06:55:06Z", "type": "commit"}, {"oid": "f1fc5d803f78b71a915120f8f599908538e5849a", "url": "https://github.com/apache/ozone/commit/f1fc5d803f78b71a915120f8f599908538e5849a", "message": "trigger new CI check", "committedDate": "2021-01-04T09:08:14Z", "type": "commit"}]}