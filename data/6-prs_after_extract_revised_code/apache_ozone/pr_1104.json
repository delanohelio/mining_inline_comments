{"pr_number": 1104, "pr_title": "HDDS-3612. Allow mounting bucket under other volume", "pr_createdAt": "2020-06-21T17:06:38Z", "pr_url": "https://github.com/apache/ozone/pull/1104", "timeline": [{"oid": "871028e53dc76a584f1e59d8ea24c1b0b3e67036", "url": "https://github.com/apache/ozone/commit/871028e53dc76a584f1e59d8ea24c1b0b3e67036", "message": "HDDS-3612. Allow mounting bucket under other volume", "committedDate": "2020-05-28T11:41:50Z", "type": "commit"}, {"oid": "2bfa1ed57ab321b165087264b771967dd603146a", "url": "https://github.com/apache/ozone/commit/2bfa1ed57ab321b165087264b771967dd603146a", "message": "handle links in listKeys", "committedDate": "2020-05-28T14:21:28Z", "type": "commit"}, {"oid": "d87f2daf1ef07527a397f3083b2d4deef2a3d4b7", "url": "https://github.com/apache/ozone/commit/d87f2daf1ef07527a397f3083b2d4deef2a3d4b7", "message": "one more unused constant", "committedDate": "2020-06-02T11:25:32Z", "type": "commit"}, {"oid": "472fd0d7606fa2af115117c2951ace9358edca94", "url": "https://github.com/apache/ozone/commit/472fd0d7606fa2af115117c2951ace9358edca94", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-08T08:31:15Z", "type": "commit"}, {"oid": "61dfc596eb476aabc17dccea761f76eb830b3d57", "url": "https://github.com/apache/ozone/commit/61dfc596eb476aabc17dccea761f76eb830b3d57", "message": "HDDS-3612. Require only read permission on link bucket", "committedDate": "2020-06-08T09:28:46Z", "type": "commit"}, {"oid": "9de1de563f8eb13c41ef978ca46efb77c99fedd1", "url": "https://github.com/apache/ozone/commit/9de1de563f8eb13c41ef978ca46efb77c99fedd1", "message": "HDDS-3612. Implement ozone sh bucket link", "committedDate": "2020-06-08T13:37:50Z", "type": "commit"}, {"oid": "af149fd439ba954b63c094c82e6fd7d7b59602e3", "url": "https://github.com/apache/ozone/commit/af149fd439ba954b63c094c82e6fd7d7b59602e3", "message": "HDDS-3612. More tests", "committedDate": "2020-06-08T17:58:54Z", "type": "commit"}, {"oid": "04f7968898d55da648b0a7fb8b99cdbefcced6fe", "url": "https://github.com/apache/ozone/commit/04f7968898d55da648b0a7fb8b99cdbefcced6fe", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-08T17:59:12Z", "type": "commit"}, {"oid": "fe7967712a771fad2187b76b3a51d3671e3f8def", "url": "https://github.com/apache/ozone/commit/fe7967712a771fad2187b76b3a51d3671e3f8def", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-09T08:28:53Z", "type": "commit"}, {"oid": "8163c977b5c931c86bd7b9b85003fcd746bfb788", "url": "https://github.com/apache/ozone/commit/8163c977b5c931c86bd7b9b85003fcd746bfb788", "message": "HDDS-3612. ACL tests", "committedDate": "2020-06-09T18:00:48Z", "type": "commit"}, {"oid": "c8ba71a73590c33b5f9bbf9edbd1ff4a59c59d4b", "url": "https://github.com/apache/ozone/commit/c8ba71a73590c33b5f9bbf9edbd1ff4a59c59d4b", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-09T19:32:58Z", "type": "commit"}, {"oid": "3ba27b1b20551d11f8d6af2d7dc4065c0d3020f1", "url": "https://github.com/apache/ozone/commit/3ba27b1b20551d11f8d6af2d7dc4065c0d3020f1", "message": "HDDS-3612. Fix checkstyle", "committedDate": "2020-06-10T05:37:04Z", "type": "commit"}, {"oid": "406f42aa5471152794a41b395d97faaba71a3824", "url": "https://github.com/apache/ozone/commit/406f42aa5471152794a41b395d97faaba71a3824", "message": "HDDS-3612. Fix unit tests", "committedDate": "2020-06-10T05:46:19Z", "type": "commit"}, {"oid": "d9c58020dc5ed1efa8a891901e12b3ea09ccd355", "url": "https://github.com/apache/ozone/commit/d9c58020dc5ed1efa8a891901e12b3ea09ccd355", "message": "HDDS-3612. Fix integration test", "committedDate": "2020-06-10T08:59:52Z", "type": "commit"}, {"oid": "82bf8944a0921acc84ff801554bcafab69dc1c9c", "url": "https://github.com/apache/ozone/commit/82bf8944a0921acc84ff801554bcafab69dc1c9c", "message": "HDDS-3612. Extract ResolvedBucket", "committedDate": "2020-06-10T15:49:27Z", "type": "commit"}, {"oid": "47a4d7174f4011475aa9156d456a9c057b1f6000", "url": "https://github.com/apache/ozone/commit/47a4d7174f4011475aa9156d456a9c057b1f6000", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-10T15:49:58Z", "type": "commit"}, {"oid": "0154ec655baee34e03a6fe1edf652cfcf729f0a3", "url": "https://github.com/apache/ozone/commit/0154ec655baee34e03a6fe1edf652cfcf729f0a3", "message": "HDDS-3612. Handle more types of key request", "committedDate": "2020-06-10T18:48:35Z", "type": "commit"}, {"oid": "4a4a50216666576db8882c38dad07ed9daa53507", "url": "https://github.com/apache/ozone/commit/4a4a50216666576db8882c38dad07ed9daa53507", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-10T18:48:50Z", "type": "commit"}, {"oid": "e325dcf5f294a37b1456ee4f95463f995a55c85e", "url": "https://github.com/apache/ozone/commit/e325dcf5f294a37b1456ee4f95463f995a55c85e", "message": "HDDS-3612. Fix unit tests", "committedDate": "2020-06-10T19:31:59Z", "type": "commit"}, {"oid": "bcd681c206cb8c8e99f78ab064cefecbf1a6c0ac", "url": "https://github.com/apache/ozone/commit/bcd681c206cb8c8e99f78ab064cefecbf1a6c0ac", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-15T06:38:46Z", "type": "commit"}, {"oid": "c409d18c507a15bcf2b8d31d20d56323e8bbfb0c", "url": "https://github.com/apache/ozone/commit/c409d18c507a15bcf2b8d31d20d56323e8bbfb0c", "message": "WIP - HDDS-3612. S3 acceptance tests for bucket links", "committedDate": "2020-06-15T19:19:15Z", "type": "commit"}, {"oid": "74adcc4070fc1ce539d8434632b4e9ab605d8105", "url": "https://github.com/apache/ozone/commit/74adcc4070fc1ce539d8434632b4e9ab605d8105", "message": "WIP - fix multipart upload", "committedDate": "2020-06-15T19:19:26Z", "type": "commit"}, {"oid": "7be917165c33d2db625e32b16d6ca6eb64c7bcd3", "url": "https://github.com/apache/ozone/commit/7be917165c33d2db625e32b16d6ca6eb64c7bcd3", "message": "Fix MultipartUploadComplete", "committedDate": "2020-06-16T16:07:48Z", "type": "commit"}, {"oid": "107de5b60a244bf42f76b8ae11dfc34fbb5cbde2", "url": "https://github.com/apache/ozone/commit/107de5b60a244bf42f76b8ae11dfc34fbb5cbde2", "message": "Call s3 test twice instead of templates", "committedDate": "2020-06-16T21:46:39Z", "type": "commit"}, {"oid": "e8719b7dca37f0760bdb08b9df187a0a247e8159", "url": "https://github.com/apache/ozone/commit/e8719b7dca37f0760bdb08b9df187a0a247e8159", "message": "fix checkstyle", "committedDate": "2020-06-17T06:47:45Z", "type": "commit"}, {"oid": "e70c3121528b1c5d36b0bded7a73030b499f5ed2", "url": "https://github.com/apache/ozone/commit/e70c3121528b1c5d36b0bded7a73030b499f5ed2", "message": "fix typo in acceptance test", "committedDate": "2020-06-17T06:48:02Z", "type": "commit"}, {"oid": "e29ed9eb1cbf05c739a17e901a4f7e6c8173a6c2", "url": "https://github.com/apache/ozone/commit/e29ed9eb1cbf05c739a17e901a4f7e6c8173a6c2", "message": "test s3 links in secure env", "committedDate": "2020-06-17T07:08:04Z", "type": "commit"}, {"oid": "0682736a413dbe38ca7c96cc31978e0144bbee3d", "url": "https://github.com/apache/ozone/commit/0682736a413dbe38ca7c96cc31978e0144bbee3d", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-17T08:36:26Z", "type": "commit"}, {"oid": "186d99eb27ec7aaf3f4b480183c4d75b326202cd", "url": "https://github.com/apache/ozone/commit/186d99eb27ec7aaf3f4b480183c4d75b326202cd", "message": "Audit before bucket update, fix listStatus and lookupFile", "committedDate": "2020-06-17T16:40:06Z", "type": "commit"}, {"oid": "da03cd8380cdfcad57eff8d63e63e8ddc21872dc", "url": "https://github.com/apache/ozone/commit/da03cd8380cdfcad57eff8d63e63e8ddc21872dc", "message": "HDDS-3094. Save each output of smoketest executed multiple times", "committedDate": "2020-06-18T08:47:09Z", "type": "commit"}, {"oid": "a37e661ead7e0be50c500bf0a57fd8b134697aa6", "url": "https://github.com/apache/ozone/commit/a37e661ead7e0be50c500bf0a57fd8b134697aa6", "message": "trigger new CI check", "committedDate": "2020-06-18T11:44:06Z", "type": "commit"}, {"oid": "d79cf492d8ad768517acacb325712fc85f0cc31a", "url": "https://github.com/apache/ozone/commit/d79cf492d8ad768517acacb325712fc85f0cc31a", "message": "HDDS-3826. Split Ozone FS acceptance tests", "committedDate": "2020-06-18T12:06:02Z", "type": "commit"}, {"oid": "305cbecaa12fa1deaaefc98caa304094f53ff8c5", "url": "https://github.com/apache/ozone/commit/305cbecaa12fa1deaaefc98caa304094f53ff8c5", "message": "trigger new CI check", "committedDate": "2020-06-18T15:05:29Z", "type": "commit"}, {"oid": "318e4c8888934de68abc759e018132d9865ec1d6", "url": "https://github.com/apache/ozone/commit/318e4c8888934de68abc759e018132d9865ec1d6", "message": "Merge branch 'HDDS-3826' into HDDS-3612-dev", "committedDate": "2020-06-19T08:14:16Z", "type": "commit"}, {"oid": "b9f9ce41b67b578c9bd9f3b0a8b8f9b6db88bf87", "url": "https://github.com/apache/ozone/commit/b9f9ce41b67b578c9bd9f3b0a8b8f9b6db88bf87", "message": "run ozonefs acceptance tests for links, too", "committedDate": "2020-06-19T13:58:10Z", "type": "commit"}, {"oid": "eb861501d6ff3675df25ae21cdef5fe88087b3b4", "url": "https://github.com/apache/ozone/commit/eb861501d6ff3675df25ae21cdef5fe88087b3b4", "message": "Display source bucket in info", "committedDate": "2020-06-19T20:44:00Z", "type": "commit"}, {"oid": "10ff2d6d2416f584cb637189985d826938d71311", "url": "https://github.com/apache/ozone/commit/10ff2d6d2416f584cb637189985d826938d71311", "message": "Fix typo in S3 acceptance test", "committedDate": "2020-06-21T00:40:48Z", "type": "commit"}, {"oid": "e9c468306bf05dc6f9d39a378660c223bcde8c4d", "url": "https://github.com/apache/ozone/commit/e9c468306bf05dc6f9d39a378660c223bcde8c4d", "message": "Fix setup for S3 tests with links", "committedDate": "2020-06-21T01:06:18Z", "type": "commit"}, {"oid": "b62f418465c34979365ee6ac85bfff77e34c003c", "url": "https://github.com/apache/ozone/commit/b62f418465c34979365ee6ac85bfff77e34c003c", "message": "Fix S3 acceptance setup for buckets", "committedDate": "2020-06-21T08:01:36Z", "type": "commit"}, {"oid": "382e7bd055881f89aab12da9e1c117b92aebdbef", "url": "https://github.com/apache/ozone/commit/382e7bd055881f89aab12da9e1c117b92aebdbef", "message": "trigger new CI check", "committedDate": "2020-06-21T09:59:04Z", "type": "commit"}, {"oid": "6da342c0fe7cdcc6672a9bde260d5bd3aa9a1e4c", "url": "https://github.com/apache/ozone/commit/6da342c0fe7cdcc6672a9bde260d5bd3aa9a1e4c", "message": "trigger new CI check", "committedDate": "2020-06-21T11:50:27Z", "type": "commit"}, {"oid": "5e4505a8ecf8faa979faa44b83f90e53d2be164d", "url": "https://github.com/apache/ozone/commit/5e4505a8ecf8faa979faa44b83f90e53d2be164d", "message": "trigger new CI check", "committedDate": "2020-06-21T15:29:40Z", "type": "commit"}, {"oid": "dfcdc5f9ce24b5cb040d6f78a541e44bce32f65a", "url": "https://github.com/apache/ozone/commit/dfcdc5f9ce24b5cb040d6f78a541e44bce32f65a", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-21T17:07:14Z", "type": "commit"}, {"oid": "89fc76277c12c5f1f77fd63d18ff139708f49560", "url": "https://github.com/apache/ozone/commit/89fc76277c12c5f1f77fd63d18ff139708f49560", "message": "trigger new CI check", "committedDate": "2020-06-21T18:21:20Z", "type": "commit"}, {"oid": "b51709d5dd62a50487d8f8ed6ae0d32539c65a57", "url": "https://github.com/apache/ozone/commit/b51709d5dd62a50487d8f8ed6ae0d32539c65a57", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-22T13:57:55Z", "type": "commit"}, {"oid": "3699f20d23defce4762045c318864b87f24f6124", "url": "https://github.com/apache/ozone/commit/3699f20d23defce4762045c318864b87f24f6124", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-06-27T12:42:42Z", "type": "commit"}, {"oid": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "url": "https://github.com/apache/ozone/commit/5806106e2cc8a892ba35b28ab67624c92ffa70a4", "message": "HDDS-3612. Handle links in new OMKeysDeleteRequest", "committedDate": "2020-06-28T07:18:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3OTI5OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447279299", "bodyText": "Old write code is not being used anymore.\nThis logic needs to be added to new Class OMBucketCreateRequest.java", "author": "bharatviswa504", "createdAt": "2020-06-29T22:01:51Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM4MzIzNQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447383235", "bodyText": "Thanks, I missed that.  Will update the patch.", "author": "adoroszlai", "createdAt": "2020-06-30T03:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI3OTI5OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447291849", "bodyText": "Question: No, where we checked source volume/bucket exists or not.", "author": "bharatviswa504", "createdAt": "2020-06-29T22:21:55Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java", "diffHunk": "@@ -136,54 +137,49 @@ public void createBucket(OmBucketInfo bucketInfo) throws IOException {\n         throw new OMException(\"Bucket already exist\",\n             OMException.ResultCodes.BUCKET_ALREADY_EXISTS);\n       }\n+\n       BucketEncryptionKeyInfo bek = bucketInfo.getEncryptionKeyInfo();\n-      BucketEncryptionKeyInfo.Builder bekb = null;\n-      if (bek != null) {\n-        if (kmsProvider == null) {\n-          throw new OMException(\"Invalid KMS provider, check configuration \" +\n-              CommonConfigurationKeys.HADOOP_SECURITY_KEY_PROVIDER_PATH,\n-              OMException.ResultCodes.INVALID_KMS_PROVIDER);\n-        }\n-        if (bek.getKeyName() == null) {\n-          throw new OMException(\"Bucket encryption key needed.\", OMException\n-              .ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // Talk to KMS to retrieve the bucket encryption key info.\n-        KeyProvider.Metadata metadata = getKMSProvider().getMetadata(\n-            bek.getKeyName());\n-        if (metadata == null) {\n-          throw new OMException(\"Bucket encryption key \" + bek.getKeyName()\n-              + \" doesn't exist.\",\n-              OMException.ResultCodes.BUCKET_ENCRYPTION_KEY_NOT_FOUND);\n-        }\n-        // If the provider supports pool for EDEKs, this will fill in the pool\n-        kmsProvider.warmUpEncryptedKeys(bek.getKeyName());\n-        bekb = new BucketEncryptionKeyInfo.Builder()\n-            .setKeyName(bek.getKeyName())\n-            .setVersion(CryptoProtocolVersion.ENCRYPTION_ZONES)\n-            .setSuite(CipherSuite.convert(metadata.getCipher()));\n-      }\n-      List<OzoneAcl> acls = new ArrayList<>();\n-      acls.addAll(bucketInfo.getAcls());\n-      volumeArgs.getAclMap().getDefaultAclList().forEach(\n-          a -> acls.add(OzoneAcl.fromProtobufWithAccessType(a)));\n-\n-      OmBucketInfo.Builder omBucketInfoBuilder = OmBucketInfo.newBuilder()\n-          .setVolumeName(bucketInfo.getVolumeName())\n-          .setBucketName(bucketInfo.getBucketName())\n-          .setAcls(acls)\n-          .setStorageType(bucketInfo.getStorageType())\n-          .setIsVersionEnabled(bucketInfo.getIsVersionEnabled())\n-          .setCreationTime(Time.now())\n-          .addAllMetadata(bucketInfo.getMetadata());\n+\n+      boolean hasSourceVolume = bucketInfo.getSourceVolume() != null;\n+      boolean hasSourceBucket = bucketInfo.getSourceBucket() != null;\n+\n+      if (hasSourceBucket != hasSourceVolume) {\n+        throw new OMException(\"Both source volume and source bucket are \" +\n+            \"required for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      if (bek != null && hasSourceBucket) {\n+        throw new OMException(\"Encryption cannot be set for bucket links\",\n+            OMException.ResultCodes.INVALID_REQUEST);\n+      }\n+\n+      BucketEncryptionKeyInfo.Builder bekb =\n+          createBucketEncryptionKeyInfoBuilder(bek);\n+\n+      OmBucketInfo.Builder omBucketInfoBuilder = bucketInfo.toBuilder()\n+          .setCreationTime(Time.now());\n+\n+      List<OzoneManagerProtocolProtos.OzoneAclInfo> defaultAclList =", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxODcxMg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447318712", "bodyText": "Reading more understood that if we create link for /vol1/buck1 -> /vol2/buck2 (source)\nWe create in DB /vol1/buck1 and they have sourceVolume as vol2 and sourceBucket as buck2.\nNow, when someone calls lookupKey on unresolved bucket, during actual request of lookupKey, this will result in Bucket_NOT_FOUND.  Do you think, we need to make sure that source volume/source bucket exists during link creation to avoid such scenarios?\nMy reason was this looks strange, the user thinks he created a link bucket with some source volume/source bucket that has passed without any issues, but now when creating key it is saying bucket does not exist.\nFollowing ln -s   looks confusing in our scenario.", "author": "bharatviswa504", "createdAt": "2020-06-29T23:36:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3MzQ5Mg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447373492", "bodyText": "Source bucket can be deleted any time after the link is created.  We would have to perform a reverse lookup to check if it leaves any dangling link.  Since this is not done, checking upon creation would be inconsistent.", "author": "adoroszlai", "createdAt": "2020-06-30T02:39:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ0OTgzNw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r449449837", "bodyText": "This is the same as the behavior of sym links:\nmkdir source\nln -s source dest\nrm r source\n\nNow you have a wrong pointer. You can list the content of the directory, but when you try to create a fie it will fail.", "author": "elek", "createdAt": "2020-07-03T08:26:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg3NjY2NQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r451876665", "bodyText": "Okay error seems to be confusing because the link bucket is happening through create bucket, with parameters sourcevolume/sourceBucket.\nI am not sure if someone will use our direct API's OzoneBucket/RpcClient.\nBut the explanation makes sense to me.", "author": "bharatviswa504", "createdAt": "2020-07-08T23:18:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MTg0OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI5MjIxOQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447292219", "bodyText": "Same, for all, write requests old code is not used anymore.", "author": "bharatviswa504", "createdAt": "2020-06-29T22:22:50Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2020,60 +2026,72 @@ public OmBucketInfo getBucketInfo(String volume, String bucket)\n    */\n   @Override\n   public OpenKeySession openKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);\n+\n     if (isAclEnabled) {\n       try {\n         checkAcls(ResourceType.KEY, StoreType.OZONE, ACLType.WRITE,\n-            args.getVolumeName(), args.getBucketName(), args.getKeyName());\n+            bucket.realVolume(), bucket.realBucket(), args.getKeyName());", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447301716", "bodyText": "Now for each operation if it is link bucket where if it has sourceVolume/SourceBucket we do checkAcls twice. One with READ permission on sourceBucket/SourceVolume in resoleBucketLink and one in actual request with required ACL type. It is not clear why do we need the first check acl.\nIf it requires, do you think we need to have an API where we can check all required ACLS with a single checkAcl call?", "author": "bharatviswa504", "createdAt": "2020-06-29T22:45:35Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2145,37 +2168,51 @@ public OmKeyLocationInfo allocateBlock(OmKeyArgs args, long clientID,\n    */\n   @Override\n   public OmKeyInfo lookupKey(OmKeyArgs args) throws IOException {\n+    ResolvedBucket bucket = resolveBucketLink(args);", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMTY1Nw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447311657", "bodyText": "Okay, I see is in resolveBucketLink we check Acls for read on provided bucket, and in actual request check acls on sourceBucket/sourceVolume which it is resolved to. Let me know if i am missing something here. Why do we need this?", "author": "bharatviswa504", "createdAt": "2020-06-29T23:15:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3NDk3Nw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447374977", "bodyText": "Read permission on the link is required to follow it.  Do you propose to completely skip ACL on link and allow anyone to use it?", "author": "adoroszlai", "createdAt": "2020-06-30T02:44:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYwNTk0MQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r450605941", "bodyText": "I am not sure what is the expected behavior, how is  this semantics derived?\nBecause with this approach for all mounted buckets, we do 2 checkAcls, we might put pressure on Ranger.\nCan we rely on underlying bucket acls, as anyway we verify already. Any downside/security issue?", "author": "bharatviswa504", "createdAt": "2020-07-07T04:36:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg3NzMxNg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r451877316", "bodyText": "Any info on this question?", "author": "bharatviswa504", "createdAt": "2020-07-08T23:20:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjAyMDc5Mg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r452020792", "bodyText": "I am not sure what is the expected behavior, how is this semantics derived?\nCan we rely on underlying bucket acls, as anyway we verify already. Any downside/security issue?\n\nThis matches unix symlinks permissions: if you have read access on the link, you see where it points to and can follow it.  ACL was discussed in design doc update (#1009) and the current behavior was approved.  Please check with @arp7 if we need any changes.  Also pinging @ChenSammi for input.", "author": "adoroszlai", "createdAt": "2020-07-09T07:33:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMTg4OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r452921889", "bodyText": "This matches unix symlinks permissions: if you have read access on the link, you see where it points to and can follow it.\n\n+1", "author": "arp7", "createdAt": "2020-07-10T15:40:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMTcxNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447302394", "bodyText": "The same comment for all write requests:\nCan we remove the changes from old write code path, which is not required? It is unnecessary now.", "author": "bharatviswa504", "createdAt": "2020-06-29T22:47:33Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -2197,20 +2234,25 @@ public void renameKey(OmKeyArgs args, String toKeyName) throws IOException {\n    */\n   @Override\n   public void deleteKey(OmKeyArgs args) throws IOException {\n+    Map<String, String> auditMap = args.toAuditMap();", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3NjkzOQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447376939", "bodyText": "I would have preferred removing old write code path before implementing links to avoid duplicate work.  However, now that these changes are in place, I prefer keeping them, and removing old write code path completely in a separate step.", "author": "adoroszlai", "createdAt": "2020-06-30T02:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDYwNTk5OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r450605999", "bodyText": "Makes sense to me.", "author": "bharatviswa504", "createdAt": "2020-07-07T04:36:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMwMjM5NA=="}], "type": "inlineReview", "revised_code": {"commit": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\nindex f174b90e7..e2a32d930 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n\n@@ -2260,16 +2265,13 @@ public void deleteKey(OmKeyArgs args) throws IOException {\n   /**\n    * Deletes an existing key.\n    *\n-   * @param args - List attributes of the key.\n+   * @param deleteKeys - List of keys to be deleted from volume and a bucket.\n    * @throws IOException\n    */\n   @Override\n-  public void deleteKeys(List<OmKeyArgs> args) throws IOException {\n-    if (args != null) {\n-      for (OmKeyArgs keyArgs : args) {\n-        deleteKey(keyArgs);\n-      }\n-    }\n+  public void deleteKeys(OmDeleteKeys deleteKeys) throws IOException {\n+    throw new UnsupportedOperationException(\"OzoneManager does not require \" +\n+        \"this to be implemented. As write requests use a new approach\");\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMjY0OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447312649", "bodyText": "Looks like this logic is needed for all KeyRequests. Can we move this to a common method, instead of duplicating it.", "author": "bharatviswa504", "createdAt": "2020-06-29T23:18:22Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "diffHunk": "@@ -174,6 +175,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     Result result = null;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ1Mzg4NQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447453885", "bodyText": "Thanks, extracted to a method.", "author": "adoroszlai", "createdAt": "2020-06-30T07:00:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMjY0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "277ce12196fe56a68fa22170c241af5c5c456479", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java\nindex b5c83e1f0..18061ad2c 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java\n\n@@ -175,9 +174,7 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     Result result = null;\n \n     try {\n-      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n-      keyArgs = bucket.update(keyArgs);\n-      bucket.audit(auditMap);\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n       volumeName = keyArgs.getVolumeName();\n       bucketName = keyArgs.getBucketName();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMzExMw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447313113", "bodyText": "And also do you think it would be useful to log the actual bucket/volume request which it resolved also?\nThis might help during debug purposes.", "author": "bharatviswa504", "createdAt": "2020-06-29T23:19:52Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java", "diffHunk": "@@ -149,6 +150,12 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     List<OmKeyInfo> missingParentInfos;\n \n     try {\n+      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n+      keyArgs = bucket.update(keyArgs);", "originalCommit": "5806106e2cc8a892ba35b28ab67624c92ffa70a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM3ODgzMQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r447378831", "bodyText": "Audit log includes both.", "author": "adoroszlai", "createdAt": "2020-06-30T02:59:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMxMzExMw=="}], "type": "inlineReview", "revised_code": {"commit": "277ce12196fe56a68fa22170c241af5c5c456479", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java\nindex f14a5ff16..65cc5e95b 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/file/OMDirectoryCreateRequest.java\n\n@@ -150,9 +149,7 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     List<OmKeyInfo> missingParentInfos;\n \n     try {\n-      ResolvedBucket bucket = ozoneManager.resolveBucketLink(keyArgs);\n-      keyArgs = bucket.update(keyArgs);\n-      bucket.audit(auditMap);\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n       volumeName = keyArgs.getVolumeName();\n       bucketName = keyArgs.getBucketName();\n \n"}}, {"oid": "277ce12196fe56a68fa22170c241af5c5c456479", "url": "https://github.com/apache/ozone/commit/277ce12196fe56a68fa22170c241af5c5c456479", "message": "HDDS-3612. Reduce duplication in OMKeyRequest", "committedDate": "2020-06-30T04:49:54Z", "type": "commit"}, {"oid": "30fe0427ef6dd652289365d24a58f1848a9d54e0", "url": "https://github.com/apache/ozone/commit/30fe0427ef6dd652289365d24a58f1848a9d54e0", "message": "HDDS-3612. Sanity check for link in OMBucketCreateRequest", "committedDate": "2020-06-30T04:51:41Z", "type": "commit"}, {"oid": "aff0c318e7b1b05026bab5cc15fa953530fde949", "url": "https://github.com/apache/ozone/commit/aff0c318e7b1b05026bab5cc15fa953530fde949", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-07-07T05:40:18Z", "type": "commit"}, {"oid": "0799b5e81a3f5f218e6916dbdb10f65459a898f2", "url": "https://github.com/apache/ozone/commit/0799b5e81a3f5f218e6916dbdb10f65459a898f2", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-07-14T09:02:10Z", "type": "commit"}, {"oid": "fc40b72206b47dab6da47d2b069910017a205f96", "url": "https://github.com/apache/ozone/commit/fc40b72206b47dab6da47d2b069910017a205f96", "message": "trigger new CI check", "committedDate": "2020-07-14T11:15:12Z", "type": "commit"}, {"oid": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281", "url": "https://github.com/apache/ozone/commit/fbf04a33ecad2d23e8bd57ecceca4842a9cf5281", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-07-14T17:37:54Z", "type": "commit"}, {"oid": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2", "url": "https://github.com/apache/ozone/commit/f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2", "message": "HDDS-3612. Fix checkstyle", "committedDate": "2020-07-14T17:44:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNjU3MA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454506570", "bodyText": "Can we change the error code here, the reason for this is in HA when error code is INTERNAL_ERROR we terminate OM. (This is done to avoid DB divergence)", "author": "bharatviswa504", "createdAt": "2020-07-14T17:02:35Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java", "diffHunk": "@@ -3314,4 +3396,59 @@ private void startJVMPauseMonitor() {\n     jvmPauseMonitor.init(configuration);\n     jvmPauseMonitor.start();\n   }\n+\n+  public ResolvedBucket resolveBucketLink(KeyArgs args) throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(OmKeyArgs args)\n+      throws IOException {\n+    return resolveBucketLink(\n+        Pair.of(args.getVolumeName(), args.getBucketName()));\n+  }\n+\n+  public ResolvedBucket resolveBucketLink(Pair<String, String> requested)\n+      throws IOException {\n+    Pair<String, String> resolved =\n+        resolveBucketLink(requested, new HashSet<>());\n+    return new ResolvedBucket(requested, resolved);\n+  }\n+\n+  /**\n+   * Resolves bucket symlinks. Read permission is required for following links.\n+   *\n+   * @param volumeAndBucket the bucket to be resolved (if it is a link)\n+   * @param visited collects link buckets visited during the resolution to\n+   *   avoid infinite loops\n+   * @return bucket location possibly updated with its actual volume and bucket\n+   *   after following bucket links\n+   * @throws IOException (most likely OMException) if ACL check fails, bucket is\n+   *   not found, loop is detected in the links, etc.\n+   */\n+  private Pair<String, String> resolveBucketLink(\n+      Pair<String, String> volumeAndBucket,\n+      Set<Pair<String, String>> visited) throws IOException {\n+\n+    String volumeName = volumeAndBucket.getLeft();\n+    String bucketName = volumeAndBucket.getRight();\n+    OmBucketInfo info = bucketManager.getBucketInfo(volumeName, bucketName);\n+    if (!info.isLink()) {\n+      return volumeAndBucket;\n+    }\n+\n+    if (!visited.add(volumeAndBucket)) {\n+      throw new OMException(\"Detected loop in bucket links\", INTERNAL_ERROR);", "originalCommit": "fc40b72206b47dab6da47d2b069910017a205f96", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MTUwOA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454781508", "bodyText": "Sure.", "author": "adoroszlai", "createdAt": "2020-07-15T04:20:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNjU3MA=="}], "type": "inlineReview", "revised_code": {"commit": "1dd8a0ee457307cc1a894757f4f049a64a22f671", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\nindex b5b3bfd48..0905d8188 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java\n\n@@ -3438,7 +3438,8 @@ public ResolvedBucket resolveBucketLink(Pair<String, String> requested)\n     }\n \n     if (!visited.add(volumeAndBucket)) {\n-      throw new OMException(\"Detected loop in bucket links\", INTERNAL_ERROR);\n+      throw new OMException(\"Detected loop in bucket links\",\n+          DETECTED_LOOP_IN_BUCKET_LINKS);\n     }\n \n     if (isAclEnabled) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454548791", "bodyText": "Now with this approach, we validate bucket exist twice. Once is resolvedBucketLink, and again in ValidateVolumeAndBucket. If this is link, can we skip 2nd-time check?\n(Now bucket/volume is in the full cache, but I think it will be better to avoid still)\nMight be in non-HA, this might create a problem as we release lock and then re-acquire some other thread might delete the bucket. But once HA becomes the default, we can optimize this, as in HA there is only a single thread executor. If you also think the same open the Jira for improvement", "author": "bharatviswa504", "createdAt": "2020-07-14T18:11:34Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -111,6 +110,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     Result result = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);", "originalCommit": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgxMDMwNQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454810305", "bodyText": "But once HA becomes the default, we can optimize this, as in HA there is only a single thread executor.\n\nDoes that mean we can completely get rid of the locks?", "author": "adoroszlai", "createdAt": "2020-07-15T05:59:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE0NzIwMg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455147202", "bodyText": "we cannot completely get rid of locks, as there are readers. But there will ne no parallel writers to have a situation like in non-HA, where other writer thread can acquire a lock in between", "author": "bharatviswa504", "createdAt": "2020-07-15T15:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ2MDU4NA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455460584", "bodyText": "OK, I'll check if I can update the patch to address this.", "author": "adoroszlai", "createdAt": "2020-07-16T01:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTYwODAxMg==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455608012", "bodyText": "Opened https://issues.apache.org/jira/browse/HDDS-3971 for the improvement.", "author": "adoroszlai", "createdAt": "2020-07-16T08:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU0ODc5MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454552625", "bodyText": "Minor: We can skip getting from original Args, as anyway final Volume/Bucket we get is from resolvedBucket returned keyArgs.", "author": "bharatviswa504", "createdAt": "2020-07-14T18:17:53Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java", "diffHunk": "@@ -88,21 +88,20 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       long trxnLogIndex, OzoneManagerDoubleBufferHelper omDoubleBufferHelper) {\n     DeleteKeyRequest deleteKeyRequest = getOmRequest().getDeleteKeyRequest();\n \n-    OzoneManagerProtocolProtos.KeyArgs deleteKeyArgs =\n+    OzoneManagerProtocolProtos.KeyArgs keyArgs =\n         deleteKeyRequest.getKeyArgs();\n+    Map<String, String> auditMap = buildKeyArgsAuditMap(keyArgs);\n \n-    String volumeName = deleteKeyArgs.getVolumeName();\n-    String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = deleteKeyArgs.getKeyName();\n+    String volumeName = keyArgs.getVolumeName();", "originalCommit": "fbf04a33ecad2d23e8bd57ecceca4842a9cf5281", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjkxMw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454552913", "bodyText": "The same comment applies for all requests", "author": "bharatviswa504", "createdAt": "2020-07-14T18:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MTM0OA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454781348", "bodyText": "We can skip getting from original Args, as anyway final Volume/Bucket we get is from resolvedBucket returned keyArgs.\n\nUnfortunately not, because volumeName and bucketName are used later to log result.  If resolveBucketLink throws exception (eg. due to lack of permission), then we exit from try earlier than getting resolvedBucket and we need the original values from request.\nhttps://github.com/apache/hadoop-ozone/blob/fbf04a33ecad2d23e8bd57ecceca4842a9cf5281/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyDeleteRequest.java#L173-L183", "author": "adoroszlai", "createdAt": "2020-07-15T04:19:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1MjYyNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1NTM2OA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454555368", "bodyText": "Minor: We can skip this, as anyway bucket.audit has already taken care of this.", "author": "bharatviswa504", "createdAt": "2020-07-14T18:22:34Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeysDeleteRequest.java", "diffHunk": "@@ -85,10 +87,11 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n \n     OMMetrics omMetrics = ozoneManager.getMetrics();\n     omMetrics.incNumKeyDeletes();\n-    Map<String, String> auditMap = null;\n     String volumeName = deleteKeyArgs.getVolumeName();\n     String bucketName = deleteKeyArgs.getBucketName();\n-    String keyName = \"\";\n+    Map<String, String> auditMap = new LinkedHashMap<>();\n+    auditMap.put(VOLUME, volumeName);", "originalCommit": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc4MjI5NQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454782295", "bodyText": "Similar to volumeName and bucketName variables, this is also required for the case when we encounter exception before reaching bucket.audit().", "author": "adoroszlai", "createdAt": "2020-07-15T04:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU1NTM2OA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MDYzNA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454560634", "bodyText": "Minor: Can we assign to volumeName and bucketName, similar to Key requests and use that, instead of getting multiple times.", "author": "bharatviswa504", "createdAt": "2020-07-14T18:31:34Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java", "diffHunk": "@@ -114,12 +117,15 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n         getOmRequest());\n     OMClientResponse omClientResponse = null;\n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+\n       // TODO to support S3 ACL later.\n       acquiredBucketLock =\n-          omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK, volumeName,\n-              bucketName);\n+          omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,", "originalCommit": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f5dbd53a32652b87f542d89b84064e3c11470ba4", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java\nindex 3f1c6ab9d..aa96ba995 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3InitiateMultipartUploadRequest.java\n\n@@ -118,14 +120,15 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     OMClientResponse omClientResponse = null;\n     try {\n       keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();\n \n       // TODO to support S3 ACL later.\n       acquiredBucketLock =\n           omMetadataManager.getLock().acquireWriteLock(BUCKET_LOCK,\n-              keyArgs.getVolumeName(), keyArgs.getBucketName());\n+              volumeName, bucketName);\n \n-      validateBucketAndVolume(omMetadataManager,\n-          keyArgs.getVolumeName(), keyArgs.getBucketName());\n+      validateBucketAndVolume(omMetadataManager, volumeName, bucketName);\n \n       // We are adding uploadId to key, because if multiple users try to\n       // perform multipart upload on the same key, each will try to upload, who\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MjI4OA==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454562288", "bodyText": "I see for all key requests we logged resolvedVolume/resolvedBucket. For MPU we log requested volume/bucket any reason for this?. Can we follow one approach for all requests?", "author": "bharatviswa504", "createdAt": "2020-07-14T18:34:26Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java", "diffHunk": "@@ -152,27 +158,29 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n       addResponseToDoubleBuffer(trxnLogIndex, omClientResponse,\n           omDoubleBufferHelper);\n       if (acquiredLock) {\n-        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK, volumeName,\n-            bucketName);\n+        omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK,\n+            keyArgs.getVolumeName(), keyArgs.getBucketName());\n       }\n     }\n \n     // audit log\n     auditLog(ozoneManager.getAuditLogger(), buildAuditMessage(\n-        OMAction.ABORT_MULTIPART_UPLOAD, buildKeyArgsAuditMap(keyArgs),\n+        OMAction.ABORT_MULTIPART_UPLOAD, auditMap,\n         exception, getOmRequest().getUserInfo()));\n \n     switch (result) {\n     case SUCCESS:\n       LOG.debug(\"Abort Multipart request is successfully completed for \" +\n-              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, volumeName,\n-          bucketName);\n+              \"KeyName {} in VolumeName/Bucket {}/{}\", keyName, requestedVolume,", "originalCommit": "f2a3f8f3cdbbb07a6cb72b6a30c69ec43d4551d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDgwNzE1Nw==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r454807157", "bodyText": "Updated, thanks.", "author": "adoroszlai", "createdAt": "2020-07-15T05:49:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU2MjI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "f5dbd53a32652b87f542d89b84064e3c11470ba4", "chunk": "diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java\nindex 17d9ad5a9..0726fe4a9 100644\n--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java\n+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3MultipartUploadAbortRequest.java\n\n@@ -159,7 +161,7 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n           omDoubleBufferHelper);\n       if (acquiredLock) {\n         omMetadataManager.getLock().releaseWriteLock(BUCKET_LOCK,\n-            keyArgs.getVolumeName(), keyArgs.getBucketName());\n+            volumeName, bucketName);\n       }\n     }\n \n"}}, {"oid": "234a1e051a848b441c4c5fc3f4c83f11625be698", "url": "https://github.com/apache/ozone/commit/234a1e051a848b441c4c5fc3f4c83f11625be698", "message": "Merge remote-tracking branch 'origin/master' into HDDS-3612-dev", "committedDate": "2020-07-15T04:04:18Z", "type": "commit"}, {"oid": "1dd8a0ee457307cc1a894757f4f049a64a22f671", "url": "https://github.com/apache/ozone/commit/1dd8a0ee457307cc1a894757f4f049a64a22f671", "message": "HDDS-3612. Change error code for infinite link loop", "committedDate": "2020-07-15T04:13:18Z", "type": "commit"}, {"oid": "f5dbd53a32652b87f542d89b84064e3c11470ba4", "url": "https://github.com/apache/ozone/commit/f5dbd53a32652b87f542d89b84064e3c11470ba4", "message": "HDDS-3612. S3 MPU: local var for volume/bucket; log resolved bucket, not requested one", "committedDate": "2020-07-15T04:49:09Z", "type": "commit"}, {"oid": "3241c4ff0004e4eac007c455efb931358ddcaf80", "url": "https://github.com/apache/ozone/commit/3241c4ff0004e4eac007c455efb931358ddcaf80", "message": "HDDS-3612. Delete bucket or link created in setup", "committedDate": "2020-07-15T05:33:55Z", "type": "commit"}, {"oid": "73b33562991a046aad9a69ea8de988c73ccd70f1", "url": "https://github.com/apache/ozone/commit/73b33562991a046aad9a69ea8de988c73ccd70f1", "message": "HDDS-3612. Change error code for infinite link loop - fixup", "committedDate": "2020-07-15T07:48:45Z", "type": "commit"}, {"oid": "b820d442efc9ebc590441caf2eff721201ed0353", "url": "https://github.com/apache/ozone/commit/b820d442efc9ebc590441caf2eff721201ed0353", "message": "trigger new CI check", "committedDate": "2020-07-15T10:15:39Z", "type": "commit"}, {"oid": "272a6f4865e4db97bc4d9fe37fd799fe69f59c8d", "url": "https://github.com/apache/ozone/commit/272a6f4865e4db97bc4d9fe37fd799fe69f59c8d", "message": "trigger new CI check", "committedDate": "2020-07-15T12:22:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE5OTY3OQ==", "url": "https://github.com/apache/ozone/pull/1104#discussion_r455199679", "bodyText": "openKeyName should be generated from resolveBucketLink.", "author": "bharatviswa504", "createdAt": "2020-07-15T17:04:21Z", "path": "hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMAllocateBlockRequest.java", "diffHunk": "@@ -172,6 +172,10 @@ public OMClientResponse validateAndUpdateCache(OzoneManager ozoneManager,\n     IOException exception = null;\n \n     try {\n+      keyArgs = resolveBucketLink(ozoneManager, keyArgs, auditMap);\n+      volumeName = keyArgs.getVolumeName();\n+      bucketName = keyArgs.getBucketName();", "originalCommit": "272a6f4865e4db97bc4d9fe37fd799fe69f59c8d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "717374eada44fd7116480f62d0164c89deed1794", "url": "https://github.com/apache/ozone/commit/717374eada44fd7116480f62d0164c89deed1794", "message": "HDDS-3612. openKeyName should be generated from resolved bucket", "committedDate": "2020-07-15T17:18:26Z", "type": "commit"}]}