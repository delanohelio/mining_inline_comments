{"pr_number": 980, "pr_title": "HDDS-3196 New PipelineManager interface to persist to RatisServer.", "pr_createdAt": "2020-05-28T12:21:25Z", "pr_url": "https://github.com/apache/ozone/pull/980", "timeline": [{"oid": "a81e213dddf1983e0dde796de4fb2383cec0802f", "url": "https://github.com/apache/ozone/commit/a81e213dddf1983e0dde796de4fb2383cec0802f", "message": "HDDS-3196 New PipelineManager interface to persist to RatisServer.", "committedDate": "2020-05-28T14:51:22Z", "type": "commit"}, {"oid": "a81e213dddf1983e0dde796de4fb2383cec0802f", "url": "https://github.com/apache/ozone/commit/a81e213dddf1983e0dde796de4fb2383cec0802f", "message": "HDDS-3196 New PipelineManager interface to persist to RatisServer.", "committedDate": "2020-05-28T14:51:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0Mjc5NQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432242795", "bodyText": "NIT: we can just pass RatisServer instead of SCMHAManager here.", "author": "xiaoyuyao", "createdAt": "2020-05-29T03:58:29Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -0,0 +1,637 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.scm.ScmConfigKeys;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.apache.hadoop.hdds.utils.Scheduler;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.metrics2.util.MBeans;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.management.ObjectName;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * SCM Pipeline Manager implementation.\n+ * All the write operations for pipelines must come via PipelineManager.\n+ * It synchronises all write and read operations via a ReadWriteLock.\n+ */\n+public class PipelineManagerV2Impl implements PipelineManager {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(SCMPipelineManager.class);\n+\n+  private final ReadWriteLock lock;\n+  private PipelineFactory pipelineFactory;\n+  private PipelineStateManagerV2 stateManager;\n+  private Scheduler scheduler;\n+  private BackgroundPipelineCreator backgroundPipelineCreator;\n+  private final NodeManager nodeManager;\n+  private final ConfigurationSource conf;\n+  // Pipeline Manager MXBean\n+  private ObjectName pmInfoBean;\n+  private final SCMPipelineMetrics metrics;\n+  private long pipelineWaitDefaultTimeout;\n+  private final AtomicBoolean isInSafeMode;\n+  // Used to track if the safemode pre-checks have completed. This is designed\n+  // to prevent pipelines being created until sufficient nodes have registered.\n+  private final AtomicBoolean pipelineCreationAllowed;\n+\n+  public PipelineManagerV2Impl(ConfigurationSource conf,\n+                               NodeManager nodeManager,\n+                               PipelineStateManagerV2 pipelineStateManager,\n+                               PipelineFactory pipelineFactory)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineFactory = pipelineFactory;\n+    this.stateManager = pipelineStateManager;\n+    this.nodeManager = nodeManager;\n+    this.conf = conf;\n+    this.pmInfoBean = MBeans.register(\"SCMPipelineManager\",\n+        \"SCMPipelineManagerInfo\", this);\n+    this.metrics = SCMPipelineMetrics.create();\n+    this.pipelineWaitDefaultTimeout = conf.getTimeDuration(\n+        HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL,\n+        HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL_DEFAULT,\n+        TimeUnit.MILLISECONDS);\n+    this.isInSafeMode = new AtomicBoolean(conf.getBoolean(\n+        HddsConfigKeys.HDDS_SCM_SAFEMODE_ENABLED,\n+        HddsConfigKeys.HDDS_SCM_SAFEMODE_ENABLED_DEFAULT));\n+    // Pipeline creation is only allowed after the safemode prechecks have\n+    // passed, eg sufficient nodes have registered.\n+    this.pipelineCreationAllowed = new AtomicBoolean(!this.isInSafeMode.get());\n+    initializePipelineState();\n+  }\n+\n+  public static PipelineManager newPipelineManager(\n+      ConfigurationSource conf, SCMHAManager scmhaManager,", "originalCommit": "a81e213dddf1983e0dde796de4fb2383cec0802f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1MjY0NQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432252645", "bodyText": "We may have more stuff in SCMHAManager than just SCMRatisServer for PipelineManager use cases. The idea here is to have a manager interface for SCM HA so that we won't worry about passing more things into PipelineManager like configs or other things. @xiaoyuyao", "author": "timmylicheng", "createdAt": "2020-05-29T04:44:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0Mjc5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1NzA2OQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432257069", "bodyText": "In the future, we have to do isLeader check inside PipelineManager for which we might need SCMHAManager instance.", "author": "nandakumar131", "createdAt": "2020-05-29T05:04:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0Mjc5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "a3e807c35a39300868d1ac9ce80e1125025d5a24", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\nindex 5d85838e6..058e670be 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\n\n@@ -102,7 +102,7 @@ public PipelineManagerV2Impl(ConfigurationSource conf,\n     // Pipeline creation is only allowed after the safemode prechecks have\n     // passed, eg sufficient nodes have registered.\n     this.pipelineCreationAllowed = new AtomicBoolean(!this.isInSafeMode.get());\n-    initializePipelineState();\n+    stateManager.initialize();\n   }\n \n   public static PipelineManager newPipelineManager(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0NTU2NA==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432245564", "bodyText": "NIT: can we group all the method with @replicate annotation together either at the begining or end with some java doc?", "author": "xiaoyuyao", "createdAt": "2020-05-29T04:10:55Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * <p>http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * <p>Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.metadata.Replicate;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+/**\n+ * Manages the state of pipelines in SCM.\n+ */\n+public interface PipelineStateManagerV2 {\n+\n+  @Replicate", "originalCommit": "a81e213dddf1983e0dde796de4fb2383cec0802f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI3ODI5Mg==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432278292", "bodyText": "Sure.", "author": "timmylicheng", "createdAt": "2020-05-29T06:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI0NTU2NA=="}], "type": "inlineReview", "revised_code": {"commit": "92424494cb15dcef7dd67f85dd6219e4c0316c54", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\nindex c8428b808..c6e42435e 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n\n@@ -34,9 +34,35 @@\n  */\n public interface PipelineStateManagerV2 {\n \n+  /**\n+   * Adding pipeline would be replicated to Ratis.\n+   * @param pipelineProto\n+   * @throws IOException\n+   */\n   @Replicate\n   void addPipeline(HddsProtos.Pipeline pipelineProto) throws IOException;\n \n+  /**\n+   * Removing pipeline would be replicated to Ratis.\n+   * @param pipelineIDProto\n+   * @return Pipeline removed\n+   * @throws IOException\n+   */\n+  @Replicate\n+  Pipeline removePipeline(HddsProtos.PipelineID pipelineIDProto)\n+      throws IOException;\n+\n+  /**\n+   * Updating pipeline state would be replicated to Ratis.\n+   * @param pipelineIDProto\n+   * @param newState\n+   * @throws IOException\n+   */\n+  @Replicate\n+  void updatePipelineState(HddsProtos.PipelineID pipelineIDProto,\n+                           HddsProtos.PipelineState newState)\n+      throws IOException;\n+\n   void addContainerToPipeline(PipelineID pipelineID,\n                               ContainerID containerID) throws IOException;\n \n"}}, {"oid": "92424494cb15dcef7dd67f85dd6219e4c0316c54", "url": "https://github.com/apache/ozone/commit/92424494cb15dcef7dd67f85dd6219e4c0316c54", "message": "Add javadoc for PipelineStateManagerV2.", "committedDate": "2020-05-29T04:59:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MDMwNQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432260305", "bodyText": "We should not expose TableIterator from PipelineStateManager", "author": "nandakumar131", "createdAt": "2020-05-29T05:18:32Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * <p>http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * <p>Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.metadata.Replicate;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+/**\n+ * Manages the state of pipelines in SCM.\n+ */\n+public interface PipelineStateManagerV2 {\n+\n+  @Replicate\n+  void addPipeline(HddsProtos.Pipeline pipelineProto) throws IOException;\n+\n+  void addContainerToPipeline(PipelineID pipelineID,\n+                              ContainerID containerID) throws IOException;\n+\n+  Pipeline getPipeline(PipelineID pipelineID) throws PipelineNotFoundException;\n+\n+  List<Pipeline> getPipelines();\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor,\n+                              Pipeline.PipelineState state);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor,\n+                              Pipeline.PipelineState state,\n+                              Collection<DatanodeDetails> excludeDns,\n+                              Collection<PipelineID> excludePipelines);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              Pipeline.PipelineState... states);\n+\n+  NavigableSet<ContainerID> getContainers(PipelineID pipelineID)\n+      throws IOException;\n+\n+  int getNumberOfContainers(PipelineID pipelineID) throws IOException;\n+\n+  @Replicate\n+  Pipeline removePipeline(HddsProtos.PipelineID pipelineIDProto)\n+      throws IOException;\n+\n+  void removeContainerFromPipeline(PipelineID pipelineID,\n+                                   ContainerID containerID) throws IOException;\n+\n+  @Replicate\n+  void updatePipelineState(HddsProtos.PipelineID pipelineIDProto,\n+                           HddsProtos.PipelineState newState)\n+      throws IOException;\n+\n+  boolean isPipelineStoreEmpty() throws IOException;\n+\n+  TableIterator<PipelineID, ? extends Table.KeyValue<PipelineID, Pipeline>>\n+      getPipelineStoreIterator() throws IOException;", "originalCommit": "a81e213dddf1983e0dde796de4fb2383cec0802f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjMwODg5MQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432308891", "bodyText": "Updated.", "author": "timmylicheng", "createdAt": "2020-05-29T07:39:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MDMwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "a3e807c35a39300868d1ac9ce80e1125025d5a24", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\nindex c8428b808..26ec39097 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n\n@@ -21,8 +21,6 @@\n import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n import org.apache.hadoop.hdds.scm.container.ContainerID;\n import org.apache.hadoop.hdds.scm.metadata.Replicate;\n-import org.apache.hadoop.hdds.utils.db.Table;\n-import org.apache.hadoop.hdds.utils.db.TableIterator;\n \n import java.io.IOException;\n import java.util.Collection;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MTYyNQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432261625", "bodyText": "stateManager#addPipeline is replicated via Ratis, which will make the pipeline added to in-memory and to DB on all the SCMs.\nnodeManager#addPipeline, since executed outside of PipelineStateManager will only be executed on Leader SCM. This will be a problem as the followers will not have this information.\nMove nodeManager#addPipeline call to stateManager#addPipeline.", "author": "nandakumar131", "createdAt": "2020-05-29T05:23:54Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java", "diffHunk": "@@ -0,0 +1,637 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.hdds.HddsConfigKeys;\n+import org.apache.hadoop.hdds.conf.ConfigurationSource;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationType;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos.ReplicationFactor;\n+import org.apache.hadoop.hdds.scm.ScmConfigKeys;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAManager;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.scm.safemode.SCMSafeModeManager;\n+import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.apache.hadoop.hdds.utils.Scheduler;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.apache.hadoop.metrics2.util.MBeans;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.management.ObjectName;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.ReadWriteLock;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * SCM Pipeline Manager implementation.\n+ * All the write operations for pipelines must come via PipelineManager.\n+ * It synchronises all write and read operations via a ReadWriteLock.\n+ */\n+public class PipelineManagerV2Impl implements PipelineManager {\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(SCMPipelineManager.class);\n+\n+  private final ReadWriteLock lock;\n+  private PipelineFactory pipelineFactory;\n+  private PipelineStateManagerV2 stateManager;\n+  private Scheduler scheduler;\n+  private BackgroundPipelineCreator backgroundPipelineCreator;\n+  private final NodeManager nodeManager;\n+  private final ConfigurationSource conf;\n+  // Pipeline Manager MXBean\n+  private ObjectName pmInfoBean;\n+  private final SCMPipelineMetrics metrics;\n+  private long pipelineWaitDefaultTimeout;\n+  private final AtomicBoolean isInSafeMode;\n+  // Used to track if the safemode pre-checks have completed. This is designed\n+  // to prevent pipelines being created until sufficient nodes have registered.\n+  private final AtomicBoolean pipelineCreationAllowed;\n+\n+  public PipelineManagerV2Impl(ConfigurationSource conf,\n+                               NodeManager nodeManager,\n+                               PipelineStateManagerV2 pipelineStateManager,\n+                               PipelineFactory pipelineFactory)\n+      throws IOException {\n+    this.lock = new ReentrantReadWriteLock();\n+    this.pipelineFactory = pipelineFactory;\n+    this.stateManager = pipelineStateManager;\n+    this.nodeManager = nodeManager;\n+    this.conf = conf;\n+    this.pmInfoBean = MBeans.register(\"SCMPipelineManager\",\n+        \"SCMPipelineManagerInfo\", this);\n+    this.metrics = SCMPipelineMetrics.create();\n+    this.pipelineWaitDefaultTimeout = conf.getTimeDuration(\n+        HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL,\n+        HddsConfigKeys.HDDS_PIPELINE_REPORT_INTERVAL_DEFAULT,\n+        TimeUnit.MILLISECONDS);\n+    this.isInSafeMode = new AtomicBoolean(conf.getBoolean(\n+        HddsConfigKeys.HDDS_SCM_SAFEMODE_ENABLED,\n+        HddsConfigKeys.HDDS_SCM_SAFEMODE_ENABLED_DEFAULT));\n+    // Pipeline creation is only allowed after the safemode prechecks have\n+    // passed, eg sufficient nodes have registered.\n+    this.pipelineCreationAllowed = new AtomicBoolean(!this.isInSafeMode.get());\n+    initializePipelineState();\n+  }\n+\n+  public static PipelineManager newPipelineManager(\n+      ConfigurationSource conf, SCMHAManager scmhaManager,\n+      NodeManager nodeManager, Table<PipelineID, Pipeline> pipelineStore,\n+      PipelineFactory pipelineFactory) throws IOException {\n+    // Create PipelineStateManager\n+    PipelineStateManagerV2 stateManager = PipelineStateManagerV2Impl\n+        .newBuilder().setPipelineStore(pipelineStore)\n+        .setRatisServer(scmhaManager.getRatisServer()).build();\n+\n+    // Create PipelineManager\n+    PipelineManagerV2Impl pipelineManager = new PipelineManagerV2Impl(conf,\n+        nodeManager, stateManager, pipelineFactory);\n+\n+    // Create background thread.\n+    Scheduler scheduler = new Scheduler(\n+        \"RatisPipelineUtilsThread\", false, 1);\n+    BackgroundPipelineCreator backgroundPipelineCreator =\n+        new BackgroundPipelineCreator(pipelineManager, scheduler, conf);\n+    pipelineManager.setBackgroundPipelineCreator(backgroundPipelineCreator);\n+    pipelineManager.setScheduler(scheduler);\n+\n+    return pipelineManager;\n+  }\n+\n+  protected void initializePipelineState() throws IOException {\n+    if (stateManager.isPipelineStoreEmpty()) {\n+      LOG.info(\"No pipeline exists in current db\");\n+      return;\n+    }\n+    TableIterator<PipelineID, ? extends Table.KeyValue<PipelineID, Pipeline>>\n+        iterator = stateManager.getPipelineStoreIterator();\n+    while (iterator.hasNext()) {\n+      Pipeline pipeline = iterator.next().getValue();\n+      stateManager.addPipeline(pipeline.getProtobufMessage());\n+      nodeManager.addPipeline(pipeline);\n+    }\n+  }\n+\n+  @Override\n+  public Pipeline createPipeline(ReplicationType type,\n+                                 ReplicationFactor factor) throws IOException {\n+    if (!isPipelineCreationAllowed() && factor != ReplicationFactor.ONE) {\n+      LOG.debug(\"Pipeline creation is not allowed until safe mode prechecks \" +\n+          \"complete\");\n+      throw new IOException(\"Pipeline creation is not allowed as safe mode \" +\n+          \"prechecks have not yet passed\");\n+    }\n+    lock.writeLock().lock();\n+    try {\n+      Pipeline pipeline = pipelineFactory.create(type, factor);\n+      stateManager.addPipeline(pipeline.getProtobufMessage());\n+      nodeManager.addPipeline(pipeline);", "originalCommit": "a81e213dddf1983e0dde796de4fb2383cec0802f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI5MDQzNg==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432290436", "bodyText": "OK Will do", "author": "timmylicheng", "createdAt": "2020-05-29T06:57:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MTYyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "a3e807c35a39300868d1ac9ce80e1125025d5a24", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\nindex 5d85838e6..058e670be 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineManagerV2Impl.java\n\n@@ -102,7 +102,7 @@ public PipelineManagerV2Impl(ConfigurationSource conf,\n     // Pipeline creation is only allowed after the safemode prechecks have\n     // passed, eg sufficient nodes have registered.\n     this.pipelineCreationAllowed = new AtomicBoolean(!this.isInSafeMode.get());\n-    initializePipelineState();\n+    stateManager.initialize();\n   }\n \n   public static PipelineManager newPipelineManager(\n"}}, {"oid": "a3e807c35a39300868d1ac9ce80e1125025d5a24", "url": "https://github.com/apache/ozone/commit/a3e807c35a39300868d1ac9ce80e1125025d5a24", "message": "Refactor intialize in PipelineManager.", "committedDate": "2020-05-29T07:43:34Z", "type": "forcePushed"}, {"oid": "aac141d704996265a8523231e3f2af2b1f5e20a9", "url": "https://github.com/apache/ozone/commit/aac141d704996265a8523231e3f2af2b1f5e20a9", "message": "Refactor intialize in PipelineManager.", "committedDate": "2020-05-29T08:00:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg0NDA0OQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432844049", "bodyText": "We don't need a initialize method exposed, this can. be done called inside PipelineStateManagerImpl constructor.", "author": "nandakumar131", "createdAt": "2020-05-30T14:04:16Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * <p>http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * <p>Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.metadata.Replicate;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+/**\n+ * Manages the state of pipelines in SCM.\n+ */\n+public interface PipelineStateManagerV2 {\n+\n+  /**\n+   * Adding pipeline would be replicated to Ratis.\n+   * @param pipelineProto\n+   * @throws IOException\n+   */\n+  @Replicate\n+  void addPipeline(HddsProtos.Pipeline pipelineProto) throws IOException;\n+\n+  /**\n+   * Removing pipeline would be replicated to Ratis.\n+   * @param pipelineIDProto\n+   * @return Pipeline removed\n+   * @throws IOException\n+   */\n+  @Replicate\n+  void removePipeline(HddsProtos.PipelineID pipelineIDProto)\n+      throws IOException;\n+\n+  /**\n+   * Updating pipeline state would be replicated to Ratis.\n+   * @param pipelineIDProto\n+   * @param newState\n+   * @throws IOException\n+   */\n+  @Replicate\n+  void updatePipelineState(HddsProtos.PipelineID pipelineIDProto,\n+                           HddsProtos.PipelineState newState)\n+      throws IOException;\n+\n+  void addContainerToPipeline(PipelineID pipelineID,\n+                              ContainerID containerID) throws IOException;\n+\n+  Pipeline getPipeline(PipelineID pipelineID) throws PipelineNotFoundException;\n+\n+  List<Pipeline> getPipelines();\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor,\n+                              Pipeline.PipelineState state);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              HddsProtos.ReplicationFactor factor,\n+                              Pipeline.PipelineState state,\n+                              Collection<DatanodeDetails> excludeDns,\n+                              Collection<PipelineID> excludePipelines);\n+\n+  List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                              Pipeline.PipelineState... states);\n+\n+  NavigableSet<ContainerID> getContainers(PipelineID pipelineID)\n+      throws IOException;\n+\n+  int getNumberOfContainers(PipelineID pipelineID) throws IOException;\n+\n+\n+  void removeContainerFromPipeline(PipelineID pipelineID,\n+                                   ContainerID containerID) throws IOException;\n+\n+  void initialize() throws IOException;", "originalCommit": "aac141d704996265a8523231e3f2af2b1f5e20a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzAyNjI5OA==", "url": "https://github.com/apache/ozone/pull/980#discussion_r433026298", "bodyText": "Updated.", "author": "timmylicheng", "createdAt": "2020-06-01T03:22:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg0NDA0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "609403252528ac8c13187592fea7db1f2ffb268f", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\nindex d1a845be9..402157566 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2.java\n\n@@ -95,7 +95,5 @@ void addContainerToPipeline(PipelineID pipelineID,\n   void removeContainerFromPipeline(PipelineID pipelineID,\n                                    ContainerID containerID) throws IOException;\n \n-  void initialize() throws IOException;\n-\n   void close() throws Exception;\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg0NDE5OA==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432844198", "bodyText": "We should not do null check here. If pipelineStore and nodeManager are null there is a problem/bug.", "author": "nandakumar131", "createdAt": "2020-05-30T14:06:10Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * <p>http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * <p>Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocol;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler;\n+import org.apache.hadoop.hdds.scm.ha.SCMRatisServer;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Proxy;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+/**\n+ * Implementation of pipeline state manager.\n+ * PipelineStateMap class holds the data structures related to pipeline and its\n+ * state. All the read and write operations in PipelineStateMap are protected\n+ * by a read write lock.\n+ */\n+public class PipelineStateManagerV2Impl implements PipelineStateManagerV2 {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineStateManager.class);\n+\n+  private final PipelineStateMap pipelineStateMap;\n+  private final NodeManager nodeManager;\n+  private Table<PipelineID, Pipeline> pipelineStore;\n+\n+  public PipelineStateManagerV2Impl(Table<PipelineID, Pipeline> pipelineStore,\n+                                    NodeManager nodeManager) {\n+    this.pipelineStateMap = new PipelineStateMap();\n+    this.nodeManager = nodeManager;\n+    this.pipelineStore = pipelineStore;\n+  }\n+\n+  @Override\n+  public void initialize() throws IOException {\n+    if (pipelineStore == null || nodeManager == null) {\n+      throw new IOException(\"PipelineStore cannot be null\");\n+    }\n+    if (pipelineStore.isEmpty()) {\n+      LOG.info(\"No pipeline exists in current db\");\n+      return;\n+    }\n+    TableIterator<PipelineID, ? extends Table.KeyValue<PipelineID, Pipeline>>\n+        iterator = pipelineStore.iterator();\n+    while (iterator.hasNext()) {\n+      Pipeline pipeline = iterator.next().getValue();\n+      addPipeline(pipeline.getProtobufMessage());\n+    }\n+  }\n+\n+  @Override\n+  public void addPipeline(HddsProtos.Pipeline pipelineProto)\n+      throws IOException {\n+    Pipeline pipeline = Pipeline.getFromProtobuf(pipelineProto);\n+    if (pipelineStore != null) {\n+      pipelineStore.put(pipeline.getId(), pipeline);\n+    }\n+    pipelineStateMap.addPipeline(pipeline);\n+    if (nodeManager != null) {\n+      nodeManager.addPipeline(pipeline);\n+    }", "originalCommit": "aac141d704996265a8523231e3f2af2b1f5e20a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzAyNjMzMA==", "url": "https://github.com/apache/ozone/pull/980#discussion_r433026330", "bodyText": "Update.", "author": "timmylicheng", "createdAt": "2020-06-01T03:22:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg0NDE5OA=="}], "type": "inlineReview", "revised_code": {"commit": "609403252528ac8c13187592fea7db1f2ffb268f", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\nindex 1f147c3fb..c74dc8678 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\n\n@@ -51,15 +51,16 @@\n   private final NodeManager nodeManager;\n   private Table<PipelineID, Pipeline> pipelineStore;\n \n-  public PipelineStateManagerV2Impl(Table<PipelineID, Pipeline> pipelineStore,\n-                                    NodeManager nodeManager) {\n+  public PipelineStateManagerV2Impl(\n+      Table<PipelineID, Pipeline> pipelineStore, NodeManager nodeManager)\n+      throws IOException {\n     this.pipelineStateMap = new PipelineStateMap();\n     this.nodeManager = nodeManager;\n     this.pipelineStore = pipelineStore;\n+    initialize();\n   }\n \n-  @Override\n-  public void initialize() throws IOException {\n+  private void initialize() throws IOException {\n     if (pipelineStore == null || nodeManager == null) {\n       throw new IOException(\"PipelineStore cannot be null\");\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg0NDIxMQ==", "url": "https://github.com/apache/ozone/pull/980#discussion_r432844211", "bodyText": "We should not do null check here. If pipelineStore and nodeManager are null there is a problem/bug.", "author": "nandakumar131", "createdAt": "2020-05-30T14:06:22Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * <p>\n+ * <p>http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * <p>Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.hadoop.hdds.scm.pipeline;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.protocol.proto.SCMRatisProtocol;\n+import org.apache.hadoop.hdds.scm.container.ContainerID;\n+import org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler;\n+import org.apache.hadoop.hdds.scm.ha.SCMRatisServer;\n+import org.apache.hadoop.hdds.scm.node.NodeManager;\n+import org.apache.hadoop.hdds.utils.db.Table;\n+import org.apache.hadoop.hdds.utils.db.TableIterator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Proxy;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.NavigableSet;\n+\n+/**\n+ * Implementation of pipeline state manager.\n+ * PipelineStateMap class holds the data structures related to pipeline and its\n+ * state. All the read and write operations in PipelineStateMap are protected\n+ * by a read write lock.\n+ */\n+public class PipelineStateManagerV2Impl implements PipelineStateManagerV2 {\n+\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(PipelineStateManager.class);\n+\n+  private final PipelineStateMap pipelineStateMap;\n+  private final NodeManager nodeManager;\n+  private Table<PipelineID, Pipeline> pipelineStore;\n+\n+  public PipelineStateManagerV2Impl(Table<PipelineID, Pipeline> pipelineStore,\n+                                    NodeManager nodeManager) {\n+    this.pipelineStateMap = new PipelineStateMap();\n+    this.nodeManager = nodeManager;\n+    this.pipelineStore = pipelineStore;\n+  }\n+\n+  @Override\n+  public void initialize() throws IOException {\n+    if (pipelineStore == null || nodeManager == null) {\n+      throw new IOException(\"PipelineStore cannot be null\");\n+    }\n+    if (pipelineStore.isEmpty()) {\n+      LOG.info(\"No pipeline exists in current db\");\n+      return;\n+    }\n+    TableIterator<PipelineID, ? extends Table.KeyValue<PipelineID, Pipeline>>\n+        iterator = pipelineStore.iterator();\n+    while (iterator.hasNext()) {\n+      Pipeline pipeline = iterator.next().getValue();\n+      addPipeline(pipeline.getProtobufMessage());\n+    }\n+  }\n+\n+  @Override\n+  public void addPipeline(HddsProtos.Pipeline pipelineProto)\n+      throws IOException {\n+    Pipeline pipeline = Pipeline.getFromProtobuf(pipelineProto);\n+    if (pipelineStore != null) {\n+      pipelineStore.put(pipeline.getId(), pipeline);\n+    }\n+    pipelineStateMap.addPipeline(pipeline);\n+    if (nodeManager != null) {\n+      nodeManager.addPipeline(pipeline);\n+    }\n+    LOG.info(\"Created pipeline {}.\", pipeline);\n+  }\n+\n+  @Override\n+  public void addContainerToPipeline(\n+      PipelineID pipelineId, ContainerID containerID)\n+      throws IOException {\n+    pipelineStateMap.addContainerToPipeline(pipelineId, containerID);\n+  }\n+\n+  @Override\n+  public Pipeline getPipeline(PipelineID pipelineID)\n+      throws PipelineNotFoundException {\n+    return pipelineStateMap.getPipeline(pipelineID);\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines() {\n+    return pipelineStateMap.getPipelines();\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines(HddsProtos.ReplicationType type) {\n+    return pipelineStateMap.getPipelines(type);\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines(\n+      HddsProtos.ReplicationType type, HddsProtos.ReplicationFactor factor) {\n+    return pipelineStateMap.getPipelines(type, factor);\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines(\n+      HddsProtos.ReplicationType type, HddsProtos.ReplicationFactor factor,\n+                              Pipeline.PipelineState state) {\n+    return pipelineStateMap.getPipelines(type, factor, state);\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines(\n+      HddsProtos.ReplicationType type, HddsProtos.ReplicationFactor factor,\n+      Pipeline.PipelineState state, Collection<DatanodeDetails> excludeDns,\n+      Collection<PipelineID> excludePipelines) {\n+    return pipelineStateMap\n+        .getPipelines(type, factor, state, excludeDns, excludePipelines);\n+  }\n+\n+  @Override\n+  public List<Pipeline> getPipelines(HddsProtos.ReplicationType type,\n+                                     Pipeline.PipelineState... states) {\n+    return pipelineStateMap.getPipelines(type, states);\n+  }\n+\n+  @Override\n+  public NavigableSet<ContainerID> getContainers(PipelineID pipelineID)\n+      throws IOException {\n+    return pipelineStateMap.getContainers(pipelineID);\n+  }\n+\n+  @Override\n+  public int getNumberOfContainers(PipelineID pipelineID) throws IOException {\n+    return pipelineStateMap.getNumberOfContainers(pipelineID);\n+  }\n+\n+  @Override\n+  public void removePipeline(HddsProtos.PipelineID pipelineIDProto)\n+      throws IOException {\n+    PipelineID pipelineID = PipelineID.getFromProtobuf(pipelineIDProto);\n+    if (pipelineStore != null) {\n+      pipelineStore.delete(pipelineID);\n+    }\n+    Pipeline pipeline = pipelineStateMap.removePipeline(pipelineID);\n+    if (nodeManager != null) {\n+      nodeManager.removePipeline(pipeline);\n+    }", "originalCommit": "aac141d704996265a8523231e3f2af2b1f5e20a9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "609403252528ac8c13187592fea7db1f2ffb268f", "chunk": "diff --git a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\nindex 1f147c3fb..c74dc8678 100644\n--- a/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\n+++ b/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java\n\n@@ -51,15 +51,16 @@\n   private final NodeManager nodeManager;\n   private Table<PipelineID, Pipeline> pipelineStore;\n \n-  public PipelineStateManagerV2Impl(Table<PipelineID, Pipeline> pipelineStore,\n-                                    NodeManager nodeManager) {\n+  public PipelineStateManagerV2Impl(\n+      Table<PipelineID, Pipeline> pipelineStore, NodeManager nodeManager)\n+      throws IOException {\n     this.pipelineStateMap = new PipelineStateMap();\n     this.nodeManager = nodeManager;\n     this.pipelineStore = pipelineStore;\n+    initialize();\n   }\n \n-  @Override\n-  public void initialize() throws IOException {\n+  private void initialize() throws IOException {\n     if (pipelineStore == null || nodeManager == null) {\n       throw new IOException(\"PipelineStore cannot be null\");\n     }\n"}}, {"oid": "609403252528ac8c13187592fea7db1f2ffb268f", "url": "https://github.com/apache/ozone/commit/609403252528ac8c13187592fea7db1f2ffb268f", "message": "Refactor intialize in PipelineManager.", "committedDate": "2020-06-01T03:16:00Z", "type": "commit"}, {"oid": "609403252528ac8c13187592fea7db1f2ffb268f", "url": "https://github.com/apache/ozone/commit/609403252528ac8c13187592fea7db1f2ffb268f", "message": "Refactor intialize in PipelineManager.", "committedDate": "2020-06-01T03:16:00Z", "type": "forcePushed"}]}