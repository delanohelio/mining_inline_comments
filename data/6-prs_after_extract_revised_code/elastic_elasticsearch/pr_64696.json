{"pr_number": 64696, "pr_title": "Allow searchable snapshot cache service to periodically fsync cache files", "pr_createdAt": "2020-11-06T12:38:02Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/64696", "timeline": [{"oid": "012eee2aa6ed7221ca25ff91c637dbc381b508e3", "url": "https://github.com/elastic/elasticsearch/commit/012eee2aa6ed7221ca25ff91c637dbc381b508e3", "message": "Periodically fsync searchable snapshots cache files", "committedDate": "2020-11-06T12:11:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcyNTYxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r518725614", "bodyText": "\ud83e\udd26", "author": "tlrx", "createdAt": "2020-11-06T12:39:30Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java", "diffHunk": "@@ -335,7 +335,7 @@ public void onEviction(CacheFile evictedCacheFile) {\n     public static void assertNumberOfFSyncs(final Path path, final Matcher<Long> matcher) {\n         final FSyncTrackingFileSystemProvider provider = (FSyncTrackingFileSystemProvider) path.getFileSystem().provider();\n         final AtomicLong fsyncCounter = provider.files.get(path);\n-        assertThat(\"File [\" + path + \"] was never fsynced\", notNullValue());\n+        assertThat(\"File [\" + path + \"] was never fsynced\", fsyncCounter, notNullValue());", "originalCommit": "012eee2aa6ed7221ca25ff91c637dbc381b508e3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\nindex 359fbabc276..9bf16b3220a 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\n\n@@ -332,11 +368,11 @@ public class CacheFileTests extends ESTestCase {\n         return mergeContiguousRanges(ranges);\n     }\n \n-    public static void assertNumberOfFSyncs(final Path path, final Matcher<Long> matcher) {\n+    public static void assertNumberOfFSyncs(final Path path, final Matcher<Integer> matcher) {\n         final FSyncTrackingFileSystemProvider provider = (FSyncTrackingFileSystemProvider) path.getFileSystem().provider();\n-        final AtomicLong fsyncCounter = provider.files.get(path);\n-        assertThat(\"File [\" + path + \"] was never fsynced\", fsyncCounter, notNullValue());\n-        assertThat(\"Mismatching number of fsync for [\" + path + \"]\", fsyncCounter.get(), matcher);\n+        final Integer fsyncCount = provider.getNumberOfFSyncs(path);\n+        assertThat(\"File [\" + path + \"] was never fsynced\", fsyncCount, notNullValue());\n+        assertThat(\"Mismatching number of fsync for [\" + path + \"]\", fsyncCount, matcher);\n     }\n \n     private static FSyncTrackingFileSystemProvider setupFSyncCountingFileSystem() {\n"}}, {"oid": "499f12bf15c81235ac24f7b6915cc0264258b680", "url": "https://github.com/elastic/elasticsearch/commit/499f12bf15c81235ac24f7b6915cc0264258b680", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-09T16:58:57Z", "type": "commit"}, {"oid": "31299c1a14f827892eb97b38228f68f77baea1ce", "url": "https://github.com/elastic/elasticsearch/commit/31299c1a14f827892eb97b38228f68f77baea1ce", "message": "Fix spotless", "committedDate": "2020-11-09T17:02:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMxNjY2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520316665", "bodyText": "I wonder if it was better to not instantiate the CacheService at all on non-data nodes? Having it support non-data nodes without the cacheSyncTask seems counter intuitive (unless there is a good reason).\nThat would allow removing the asserts/ifs on cacheSyncTask != null.", "author": "henningandersen", "createdAt": "2020-11-10T06:20:43Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,31 +82,63 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Logger logger = LogManager.getLogger(CacheService.class);\n+\n+    private final ClusterService clusterService;\n+    private final NodeEnvironment nodeEnvironment;\n+    private final ThreadPool threadPool;\n+    private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n     private final Runnable cacheCleaner;\n     private final ByteSizeValue rangeSize;\n \n-    public CacheService(final Runnable cacheCleaner, final Settings settings) {\n-        this(cacheCleaner, SNAPSHOT_CACHE_SIZE_SETTING.get(settings), SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings));\n-    }\n-\n-    // exposed for tests\n-    public CacheService(final Runnable cacheCleaner, final ByteSizeValue cacheSize, final ByteSizeValue rangeSize) {\n-        this.cacheSize = Objects.requireNonNull(cacheSize);\n+    public CacheService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final ThreadPool threadPool,\n+        final NodeEnvironment nodeEnvironment,\n+        final Runnable cacheCleaner\n+    ) {\n+        this.clusterService = Objects.requireNonNull(clusterService);\n+        this.nodeEnvironment = Objects.requireNonNull(nodeEnvironment);\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.cacheSize = SNAPSHOT_CACHE_SIZE_SETTING.get(settings);\n         this.cacheCleaner = Objects.requireNonNull(cacheCleaner);\n-        this.rangeSize = Objects.requireNonNull(rangeSize);\n+        this.rangeSize = SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings);\n         this.cache = CacheBuilder.<CacheKey, CacheFile>builder()\n             .setMaximumWeight(cacheSize.getBytes())\n             .weigher((key, entry) -> entry.getLength())\n             // NORELEASE This does not immediately free space on disk, as cache file are only deleted when all index inputs\n             // are done with reading/writing the cache file\n             .removalListener(notification -> IOUtils.closeWhileHandlingException(() -> notification.getValue().startEviction()))\n             .build();\n+\n+        if (DiscoveryNode.isDataNode(settings)) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQzOTkxNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520439917", "bodyText": "++ I think not instantiating it would be nice.\nMild worry on this :) <- it might be a little cumbersome to get it right due to transport actions? (haven't checked this here in detail but I remember trying to do a similar thing elsewhere and it turned out to be tricky)", "author": "original-brownbear", "createdAt": "2020-11-10T10:07:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMxNjY2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -91,11 +78,11 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         Setting.Property.Dynamic\n     );\n \n+    private static final Supplier<Set<CacheFile>> SUPPLIER_OF_CACHE_FILES_TO_SYNC = ConcurrentCollections::newConcurrentSet;\n     private static final Logger logger = LogManager.getLogger(CacheService.class);\n \n-    private final ClusterService clusterService;\n-    private final NodeEnvironment nodeEnvironment;\n     private final ThreadPool threadPool;\n+    private final AtomicReference<Set<CacheFile>> cacheFilesToSyncRef;\n     private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMTM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520331340", "bodyText": "I think the reason we need this is because cacheSyncTask.cancel does not promise to not reschedule until rescheduleIfNecessary is called again?\nI wonder if that is a bug we should fix in AbstractAsyncTask? Can certainly be done in a follow-up (or separate PR).", "author": "henningandersen", "createdAt": "2020-11-10T06:55:48Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -207,160 +184,107 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         cache.refresh();\n     }\n \n-    // used in tests\n-    CacheSynchronizationTask getCacheSyncTask() {\n-        return cacheSyncTask;\n-    }\n-\n     void setCacheSyncInterval(TimeValue interval) {\n         assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n     /**\n-     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n      */\n-    @Override\n-    public void clusterChanged(ClusterChangedEvent event) {\n-        assert cacheSyncTask != null;\n-\n-        if (event.routingTableChanged()) {\n-            final ClusterState clusterState = event.state();\n-            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n-            assert localNode.isDataNode();\n-\n-            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n-            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);\n+        assert added : \"cache file already marked as updated \" + cacheFile;\n+    }\n \n-            if (shouldSynchronize == false) {\n-                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.cancel();\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * set of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.get();\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n \n-            } else if (cacheSyncTask.isScheduled() == false) {\n-                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.rescheduleIfNecessary();\n-            }\n-        }\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSyncRef.get().contains(cacheFile);\n     }\n \n     /**\n-     * Synchronize the cache files and dirs.\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current set of cache files to synchronize referenced by {@link #cacheFilesToSyncRef}. When\n+     * this method is invoked it atomically retrieves the current set of cache files to synchronize and replaces it with a new empty one.\n+     * The previous set of cache files will be used to synchronize the files while the new set will be used to add the cache files to\n+     * synchronize the next time this method runs.\n      *\n-     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n-     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n-     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n-     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n+    protected void synchronizeCache() {\n         if (lifecycleState() != Lifecycle.State.STARTED) {\n+            logger.debug(\"skipping cache synchronization (cache service is closing)\");\n             return;\n         }\n-        final ClusterState clusterState = clusterService.state();\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n-        assert routingNode != null;\n \n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        for (ShardRouting shardRouting : routingNode) {\n-            if (shardRouting.active()) {\n-                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                final Settings indexSettings = indexMetadata.getSettings();\n-                if (isSearchableSnapshotStore(indexSettings)) {\n-                    final ShardId shardId = shardRouting.shardId();\n-                    final SnapshotId snapshotId = new SnapshotId(\n-                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n-                    );\n-                    final IndexId indexId = new IndexId(\n-                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n-                    );\n-\n-                    boolean syncDirectory = false;\n-                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n-                        final CacheKey cacheKey = entry.v1();\n-                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n-                            final CacheFile cacheFile = entry.v2();\n-                            try {\n-                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                                if (ranges.isEmpty() == false) {\n-                                    logger.trace(\n-                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName(),\n-                                        ranges.size()\n-                                    );\n-                                    syncDirectory = true;\n-                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                                }\n-                            } catch (Exception e) {\n-                                logger.warn(\n-                                    () -> new ParameterizedMessage(\n-                                        \"{} failed to fsync cache file [{}]\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName()\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-                        }\n-                    }\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.getAndSet(SUPPLIER_OF_CACHE_FILES_TO_SYNC.get());\n+        if (cacheFilesToSync.isEmpty()) {\n+            logger.debug(\"skipping cache synchronization (no cache files to fsync)\");\n+            return;\n+        }\n \n-                    if (syncDirectory) {\n-                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n-                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n-                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n-                            if (Files.exists(snapshotCacheDir)) {\n-                                try {\n-                                    IOUtils.fsync(snapshotCacheDir, true, false);\n-                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n-                                } catch (Exception e) {\n-                                    logger.warn(\n-                                        () -> new ParameterizedMessage(\n-                                            \"{} failed to synchronize cache directory [{}]\",\n-                                            shardId,\n-                                            snapshotCacheDir\n-                                        ),\n-                                        e\n-                                    );\n-                                }\n-                            }\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (CacheFile cacheFile : cacheFilesToSync) {\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n                         }\n                     }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n                 }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n         }\n+\n         if (logger.isDebugEnabled()) {\n             final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n             logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n         }\n     }\n \n-    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n-        if (routingNode != null) {\n-            for (ShardRouting shardRouting : routingNode) {\n-                if (shardRouting.active()) {\n-                    final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                    if (isSearchableSnapshotStore(indexMetadata.getSettings())) {\n-                        return true;\n-                    }\n-                }\n-            }\n-        }\n-        return false;\n-    }\n-\n     class CacheSynchronizationTask extends AbstractAsyncTask {\n \n-        private final AtomicBoolean allowReschedule = new AtomicBoolean(false);\n-\n         CacheSynchronizationTask(ThreadPool threadPool, TimeValue interval) {\n             super(logger, Objects.requireNonNull(threadPool), Objects.requireNonNull(interval), true);\n         }\n \n         @Override\n         protected boolean mustReschedule() {\n-            return allowReschedule.get();\n+            return true;\n         }\n \n         @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjE0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520332146", "bodyText": "I think this could mean that we will not start fsync'ing during initialization/recovery of the first shard(s) on a starting node?", "author": "henningandersen", "createdAt": "2020-11-10T06:58:06Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {\n+                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n+                final Settings indexSettings = indexMetadata.getSettings();\n+                if (isSearchableSnapshotStore(indexSettings)) {\n+                    final ShardId shardId = shardRouting.shardId();\n+                    final SnapshotId snapshotId = new SnapshotId(\n+                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n+                    );\n+                    final IndexId indexId = new IndexId(\n+                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n+                    );\n+\n+                    boolean syncDirectory = false;\n+                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n+                        final CacheKey cacheKey = entry.v1();\n+                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n+                            final CacheFile cacheFile = entry.v2();\n+                            try {\n+                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                                if (ranges.isEmpty() == false) {\n+                                    logger.trace(\n+                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n+                                        shardId,\n+                                        cacheFile.getFile().getFileName(),\n+                                        ranges.size()\n+                                    );\n+                                    syncDirectory = true;\n+                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                                }\n+                            } catch (Exception e) {\n+                                logger.warn(\n+                                    () -> new ParameterizedMessage(\n+                                        \"{} failed to fsync cache file [{}]\",\n+                                        shardId,\n+                                        cacheFile.getFile().getFileName()\n+                                    ),\n+                                    e\n+                                );\n+                            }\n+                        }\n+                    }\n+\n+                    if (syncDirectory) {\n+                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n+                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n+                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n+                            if (Files.exists(snapshotCacheDir)) {\n+                                try {\n+                                    IOUtils.fsync(snapshotCacheDir, true, false);\n+                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n+                                } catch (Exception e) {\n+                                    logger.warn(\n+                                        () -> new ParameterizedMessage(\n+                                            \"{} failed to synchronize cache directory [{}]\",\n+                                            shardId,\n+                                            snapshotCacheDir\n+                                        ),\n+                                        e\n+                                    );\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        if (logger.isDebugEnabled()) {\n+            final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n+            logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n+        }\n+    }\n+\n+    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n+        if (routingNode != null) {\n+            for (ShardRouting shardRouting : routingNode) {\n+                if (shardRouting.active()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -207,160 +184,107 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         cache.refresh();\n     }\n \n-    // used in tests\n-    CacheSynchronizationTask getCacheSyncTask() {\n-        return cacheSyncTask;\n-    }\n-\n     void setCacheSyncInterval(TimeValue interval) {\n         assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n     /**\n-     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n      */\n-    @Override\n-    public void clusterChanged(ClusterChangedEvent event) {\n-        assert cacheSyncTask != null;\n-\n-        if (event.routingTableChanged()) {\n-            final ClusterState clusterState = event.state();\n-            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n-            assert localNode.isDataNode();\n-\n-            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n-            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);\n+        assert added : \"cache file already marked as updated \" + cacheFile;\n+    }\n \n-            if (shouldSynchronize == false) {\n-                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.cancel();\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * set of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.get();\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n \n-            } else if (cacheSyncTask.isScheduled() == false) {\n-                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.rescheduleIfNecessary();\n-            }\n-        }\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSyncRef.get().contains(cacheFile);\n     }\n \n     /**\n-     * Synchronize the cache files and dirs.\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current set of cache files to synchronize referenced by {@link #cacheFilesToSyncRef}. When\n+     * this method is invoked it atomically retrieves the current set of cache files to synchronize and replaces it with a new empty one.\n+     * The previous set of cache files will be used to synchronize the files while the new set will be used to add the cache files to\n+     * synchronize the next time this method runs.\n      *\n-     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n-     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n-     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n-     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n+    protected void synchronizeCache() {\n         if (lifecycleState() != Lifecycle.State.STARTED) {\n+            logger.debug(\"skipping cache synchronization (cache service is closing)\");\n             return;\n         }\n-        final ClusterState clusterState = clusterService.state();\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n-        assert routingNode != null;\n \n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        for (ShardRouting shardRouting : routingNode) {\n-            if (shardRouting.active()) {\n-                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                final Settings indexSettings = indexMetadata.getSettings();\n-                if (isSearchableSnapshotStore(indexSettings)) {\n-                    final ShardId shardId = shardRouting.shardId();\n-                    final SnapshotId snapshotId = new SnapshotId(\n-                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n-                    );\n-                    final IndexId indexId = new IndexId(\n-                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n-                    );\n-\n-                    boolean syncDirectory = false;\n-                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n-                        final CacheKey cacheKey = entry.v1();\n-                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n-                            final CacheFile cacheFile = entry.v2();\n-                            try {\n-                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                                if (ranges.isEmpty() == false) {\n-                                    logger.trace(\n-                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName(),\n-                                        ranges.size()\n-                                    );\n-                                    syncDirectory = true;\n-                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                                }\n-                            } catch (Exception e) {\n-                                logger.warn(\n-                                    () -> new ParameterizedMessage(\n-                                        \"{} failed to fsync cache file [{}]\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName()\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-                        }\n-                    }\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.getAndSet(SUPPLIER_OF_CACHE_FILES_TO_SYNC.get());\n+        if (cacheFilesToSync.isEmpty()) {\n+            logger.debug(\"skipping cache synchronization (no cache files to fsync)\");\n+            return;\n+        }\n \n-                    if (syncDirectory) {\n-                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n-                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n-                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n-                            if (Files.exists(snapshotCacheDir)) {\n-                                try {\n-                                    IOUtils.fsync(snapshotCacheDir, true, false);\n-                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n-                                } catch (Exception e) {\n-                                    logger.warn(\n-                                        () -> new ParameterizedMessage(\n-                                            \"{} failed to synchronize cache directory [{}]\",\n-                                            shardId,\n-                                            snapshotCacheDir\n-                                        ),\n-                                        e\n-                                    );\n-                                }\n-                            }\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (CacheFile cacheFile : cacheFilesToSync) {\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n                         }\n                     }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n                 }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n         }\n+\n         if (logger.isDebugEnabled()) {\n             final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n             logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n         }\n     }\n \n-    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n-        if (routingNode != null) {\n-            for (ShardRouting shardRouting : routingNode) {\n-                if (shardRouting.active()) {\n-                    final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                    if (isSearchableSnapshotStore(indexMetadata.getSettings())) {\n-                        return true;\n-                    }\n-                }\n-            }\n-        }\n-        return false;\n-    }\n-\n     class CacheSynchronizationTask extends AbstractAsyncTask {\n \n-        private final AtomicBoolean allowReschedule = new AtomicBoolean(false);\n-\n         CacheSynchronizationTask(ThreadPool threadPool, TimeValue interval) {\n             super(logger, Objects.requireNonNull(threadPool), Objects.requireNonNull(interval), true);\n         }\n \n         @Override\n         protected boolean mustReschedule() {\n-            return allowReschedule.get();\n+            return true;\n         }\n \n         @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjY1MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520332650", "bodyText": "I think we also want to fsync initializing shards?", "author": "henningandersen", "createdAt": "2020-11-10T06:59:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -207,160 +184,107 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         cache.refresh();\n     }\n \n-    // used in tests\n-    CacheSynchronizationTask getCacheSyncTask() {\n-        return cacheSyncTask;\n-    }\n-\n     void setCacheSyncInterval(TimeValue interval) {\n         assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n     /**\n-     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n      */\n-    @Override\n-    public void clusterChanged(ClusterChangedEvent event) {\n-        assert cacheSyncTask != null;\n-\n-        if (event.routingTableChanged()) {\n-            final ClusterState clusterState = event.state();\n-            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n-            assert localNode.isDataNode();\n-\n-            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n-            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);\n+        assert added : \"cache file already marked as updated \" + cacheFile;\n+    }\n \n-            if (shouldSynchronize == false) {\n-                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.cancel();\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * set of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.get();\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n \n-            } else if (cacheSyncTask.isScheduled() == false) {\n-                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.rescheduleIfNecessary();\n-            }\n-        }\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSyncRef.get().contains(cacheFile);\n     }\n \n     /**\n-     * Synchronize the cache files and dirs.\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current set of cache files to synchronize referenced by {@link #cacheFilesToSyncRef}. When\n+     * this method is invoked it atomically retrieves the current set of cache files to synchronize and replaces it with a new empty one.\n+     * The previous set of cache files will be used to synchronize the files while the new set will be used to add the cache files to\n+     * synchronize the next time this method runs.\n      *\n-     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n-     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n-     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n-     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n+    protected void synchronizeCache() {\n         if (lifecycleState() != Lifecycle.State.STARTED) {\n+            logger.debug(\"skipping cache synchronization (cache service is closing)\");\n             return;\n         }\n-        final ClusterState clusterState = clusterService.state();\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n-        assert routingNode != null;\n \n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        for (ShardRouting shardRouting : routingNode) {\n-            if (shardRouting.active()) {\n-                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                final Settings indexSettings = indexMetadata.getSettings();\n-                if (isSearchableSnapshotStore(indexSettings)) {\n-                    final ShardId shardId = shardRouting.shardId();\n-                    final SnapshotId snapshotId = new SnapshotId(\n-                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n-                    );\n-                    final IndexId indexId = new IndexId(\n-                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n-                    );\n-\n-                    boolean syncDirectory = false;\n-                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n-                        final CacheKey cacheKey = entry.v1();\n-                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n-                            final CacheFile cacheFile = entry.v2();\n-                            try {\n-                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                                if (ranges.isEmpty() == false) {\n-                                    logger.trace(\n-                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName(),\n-                                        ranges.size()\n-                                    );\n-                                    syncDirectory = true;\n-                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                                }\n-                            } catch (Exception e) {\n-                                logger.warn(\n-                                    () -> new ParameterizedMessage(\n-                                        \"{} failed to fsync cache file [{}]\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName()\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-                        }\n-                    }\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.getAndSet(SUPPLIER_OF_CACHE_FILES_TO_SYNC.get());\n+        if (cacheFilesToSync.isEmpty()) {\n+            logger.debug(\"skipping cache synchronization (no cache files to fsync)\");\n+            return;\n+        }\n \n-                    if (syncDirectory) {\n-                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n-                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n-                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n-                            if (Files.exists(snapshotCacheDir)) {\n-                                try {\n-                                    IOUtils.fsync(snapshotCacheDir, true, false);\n-                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n-                                } catch (Exception e) {\n-                                    logger.warn(\n-                                        () -> new ParameterizedMessage(\n-                                            \"{} failed to synchronize cache directory [{}]\",\n-                                            shardId,\n-                                            snapshotCacheDir\n-                                        ),\n-                                        e\n-                                    );\n-                                }\n-                            }\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (CacheFile cacheFile : cacheFilesToSync) {\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n                         }\n                     }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n                 }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n         }\n+\n         if (logger.isDebugEnabled()) {\n             final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n             logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n         }\n     }\n \n-    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n-        if (routingNode != null) {\n-            for (ShardRouting shardRouting : routingNode) {\n-                if (shardRouting.active()) {\n-                    final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                    if (isSearchableSnapshotStore(indexMetadata.getSettings())) {\n-                        return true;\n-                    }\n-                }\n-            }\n-        }\n-        return false;\n-    }\n-\n     class CacheSynchronizationTask extends AbstractAsyncTask {\n \n-        private final AtomicBoolean allowReschedule = new AtomicBoolean(false);\n-\n         CacheSynchronizationTask(ThreadPool threadPool, TimeValue interval) {\n             super(logger, Objects.requireNonNull(threadPool), Objects.requireNonNull(interval), true);\n         }\n \n         @Override\n         protected boolean mustReschedule() {\n-            return allowReschedule.get();\n+            return true;\n         }\n \n         @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzNTQ5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520335497", "bodyText": "This seems like an n^2 algorithm. Since we iterate the cache entries, could we not just fsync the cache files individually as long as they are in the cache?", "author": "henningandersen", "createdAt": "2020-11-10T07:07:12Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {\n+                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n+                final Settings indexSettings = indexMetadata.getSettings();\n+                if (isSearchableSnapshotStore(indexSettings)) {\n+                    final ShardId shardId = shardRouting.shardId();\n+                    final SnapshotId snapshotId = new SnapshotId(\n+                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n+                    );\n+                    final IndexId indexId = new IndexId(\n+                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n+                    );\n+\n+                    boolean syncDirectory = false;\n+                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ3MjgzMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520472830", "bodyText": "++, I would also think there's no need to be tricky here. We already have all the tricky logic for handling a cache file's life-cycle in CacheFile => I think I like the idea of just iterating over all CacheFile here combined with Henning's other point of having the CacheFile register itself for fsync in some form. That seems like it wouldn't add new complexities around synchronization and life-cycle beyond what we already have in CacheFile?", "author": "original-brownbear", "createdAt": "2020-11-10T10:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzNTQ5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -207,160 +184,107 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         cache.refresh();\n     }\n \n-    // used in tests\n-    CacheSynchronizationTask getCacheSyncTask() {\n-        return cacheSyncTask;\n-    }\n-\n     void setCacheSyncInterval(TimeValue interval) {\n         assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n     /**\n-     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n      */\n-    @Override\n-    public void clusterChanged(ClusterChangedEvent event) {\n-        assert cacheSyncTask != null;\n-\n-        if (event.routingTableChanged()) {\n-            final ClusterState clusterState = event.state();\n-            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n-            assert localNode.isDataNode();\n-\n-            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n-            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);\n+        assert added : \"cache file already marked as updated \" + cacheFile;\n+    }\n \n-            if (shouldSynchronize == false) {\n-                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.cancel();\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * set of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.get();\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n \n-            } else if (cacheSyncTask.isScheduled() == false) {\n-                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.rescheduleIfNecessary();\n-            }\n-        }\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSyncRef.get().contains(cacheFile);\n     }\n \n     /**\n-     * Synchronize the cache files and dirs.\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current set of cache files to synchronize referenced by {@link #cacheFilesToSyncRef}. When\n+     * this method is invoked it atomically retrieves the current set of cache files to synchronize and replaces it with a new empty one.\n+     * The previous set of cache files will be used to synchronize the files while the new set will be used to add the cache files to\n+     * synchronize the next time this method runs.\n      *\n-     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n-     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n-     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n-     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n+    protected void synchronizeCache() {\n         if (lifecycleState() != Lifecycle.State.STARTED) {\n+            logger.debug(\"skipping cache synchronization (cache service is closing)\");\n             return;\n         }\n-        final ClusterState clusterState = clusterService.state();\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n-        assert routingNode != null;\n \n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        for (ShardRouting shardRouting : routingNode) {\n-            if (shardRouting.active()) {\n-                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                final Settings indexSettings = indexMetadata.getSettings();\n-                if (isSearchableSnapshotStore(indexSettings)) {\n-                    final ShardId shardId = shardRouting.shardId();\n-                    final SnapshotId snapshotId = new SnapshotId(\n-                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n-                    );\n-                    final IndexId indexId = new IndexId(\n-                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n-                    );\n-\n-                    boolean syncDirectory = false;\n-                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n-                        final CacheKey cacheKey = entry.v1();\n-                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n-                            final CacheFile cacheFile = entry.v2();\n-                            try {\n-                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                                if (ranges.isEmpty() == false) {\n-                                    logger.trace(\n-                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName(),\n-                                        ranges.size()\n-                                    );\n-                                    syncDirectory = true;\n-                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                                }\n-                            } catch (Exception e) {\n-                                logger.warn(\n-                                    () -> new ParameterizedMessage(\n-                                        \"{} failed to fsync cache file [{}]\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName()\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-                        }\n-                    }\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.getAndSet(SUPPLIER_OF_CACHE_FILES_TO_SYNC.get());\n+        if (cacheFilesToSync.isEmpty()) {\n+            logger.debug(\"skipping cache synchronization (no cache files to fsync)\");\n+            return;\n+        }\n \n-                    if (syncDirectory) {\n-                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n-                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n-                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n-                            if (Files.exists(snapshotCacheDir)) {\n-                                try {\n-                                    IOUtils.fsync(snapshotCacheDir, true, false);\n-                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n-                                } catch (Exception e) {\n-                                    logger.warn(\n-                                        () -> new ParameterizedMessage(\n-                                            \"{} failed to synchronize cache directory [{}]\",\n-                                            shardId,\n-                                            snapshotCacheDir\n-                                        ),\n-                                        e\n-                                    );\n-                                }\n-                            }\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (CacheFile cacheFile : cacheFilesToSync) {\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n                         }\n                     }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n                 }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n         }\n+\n         if (logger.isDebugEnabled()) {\n             final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n             logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n         }\n     }\n \n-    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n-        if (routingNode != null) {\n-            for (ShardRouting shardRouting : routingNode) {\n-                if (shardRouting.active()) {\n-                    final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                    if (isSearchableSnapshotStore(indexMetadata.getSettings())) {\n-                        return true;\n-                    }\n-                }\n-            }\n-        }\n-        return false;\n-    }\n-\n     class CacheSynchronizationTask extends AbstractAsyncTask {\n \n-        private final AtomicBoolean allowReschedule = new AtomicBoolean(false);\n-\n         CacheSynchronizationTask(ThreadPool threadPool, TimeValue interval) {\n             super(logger, Objects.requireNonNull(threadPool), Objects.requireNonNull(interval), true);\n         }\n \n         @Override\n         protected boolean mustReschedule() {\n-            return allowReschedule.get();\n+            return true;\n         }\n \n         @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0ODIyNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520348224", "bodyText": "I think this is true. In fact, it looks like the lru-chain would be unsafely published with no happens-before to the reader.\nI think the iteration of the entries done in this PR is thus unsafe, at least it might skip some entries.\nI think the same applies to iterating over keys(), which we do a few places.\nTogether with other comments in this PR, this makes me think that perhaps it was easier to let CacheFile's that need fsync register with the CacheService (or a registry in between)?", "author": "henningandersen", "createdAt": "2020-11-10T07:38:30Z", "path": "server/src/main/java/org/elasticsearch/common/cache/Cache.java", "diffHunk": "@@ -650,6 +650,36 @@ public void remove() {\n         };\n     }\n \n+    /**\n+     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n+     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n+     * undefined.", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6b238d6e76b0ad8445feae40ef7076611d88a5c8", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/common/cache/Cache.java b/server/src/main/java/org/elasticsearch/common/cache/Cache.java\nindex 586c093a9cf..0384e778766 100644\n--- a/server/src/main/java/org/elasticsearch/common/cache/Cache.java\n+++ b/server/src/main/java/org/elasticsearch/common/cache/Cache.java\n\n@@ -650,36 +650,6 @@ public class Cache<K, V> {\n         };\n     }\n \n-    /**\n-     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n-     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n-     * undefined.\n-     *\n-     * @return an LRU-ordered {@link Iterable} over the entries in the cache\n-     */\n-    public Iterable<Tuple<K,V>> entries() {\n-        return () -> new Iterator<>() {\n-\n-            private final CacheIterator iterator = new CacheIterator(head);\n-\n-            @Override\n-            public boolean hasNext() {\n-                return iterator.hasNext();\n-            }\n-\n-            @Override\n-            public Tuple<K,V> next() {\n-                final Cache.Entry<K, V> next = iterator.next();\n-                return Tuple.tuple(next.key, next.value);\n-            }\n-\n-            @Override\n-            public void remove() {\n-                iterator.remove();\n-            }\n-        };\n-    }\n-\n     private class CacheIterator implements Iterator<Entry<K, V>> {\n         private Entry<K, V> current;\n         private Entry<K, V> next;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0OTI2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520349262", "bodyText": "I wonder if we need to couple this to cluster state updates? Instead we could either trigger on the presence of any cache files or as proposed in another comment an explicit fsync-needed registration?", "author": "henningandersen", "createdAt": "2020-11-10T07:40:34Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 055fe5d81ac..ea32145dbbf 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -207,160 +184,107 @@ public class CacheService extends AbstractLifecycleComponent implements ClusterS\n         cache.refresh();\n     }\n \n-    // used in tests\n-    CacheSynchronizationTask getCacheSyncTask() {\n-        return cacheSyncTask;\n-    }\n-\n     void setCacheSyncInterval(TimeValue interval) {\n         assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n     /**\n-     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n      */\n-    @Override\n-    public void clusterChanged(ClusterChangedEvent event) {\n-        assert cacheSyncTask != null;\n-\n-        if (event.routingTableChanged()) {\n-            final ClusterState clusterState = event.state();\n-            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n-            assert localNode.isDataNode();\n-\n-            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n-            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);\n+        assert added : \"cache file already marked as updated \" + cacheFile;\n+    }\n \n-            if (shouldSynchronize == false) {\n-                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.cancel();\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * set of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.get();\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n \n-            } else if (cacheSyncTask.isScheduled() == false) {\n-                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n-                cacheSyncTask.rescheduleIfNecessary();\n-            }\n-        }\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSyncRef.get().contains(cacheFile);\n     }\n \n     /**\n-     * Synchronize the cache files and dirs.\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current set of cache files to synchronize referenced by {@link #cacheFilesToSyncRef}. When\n+     * this method is invoked it atomically retrieves the current set of cache files to synchronize and replaces it with a new empty one.\n+     * The previous set of cache files will be used to synchronize the files while the new set will be used to add the cache files to\n+     * synchronize the next time this method runs.\n      *\n-     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n-     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n-     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n-     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n+    protected void synchronizeCache() {\n         if (lifecycleState() != Lifecycle.State.STARTED) {\n+            logger.debug(\"skipping cache synchronization (cache service is closing)\");\n             return;\n         }\n-        final ClusterState clusterState = clusterService.state();\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n-        assert routingNode != null;\n \n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        for (ShardRouting shardRouting : routingNode) {\n-            if (shardRouting.active()) {\n-                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                final Settings indexSettings = indexMetadata.getSettings();\n-                if (isSearchableSnapshotStore(indexSettings)) {\n-                    final ShardId shardId = shardRouting.shardId();\n-                    final SnapshotId snapshotId = new SnapshotId(\n-                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n-                    );\n-                    final IndexId indexId = new IndexId(\n-                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n-                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n-                    );\n-\n-                    boolean syncDirectory = false;\n-                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n-                        final CacheKey cacheKey = entry.v1();\n-                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n-                            final CacheFile cacheFile = entry.v2();\n-                            try {\n-                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                                if (ranges.isEmpty() == false) {\n-                                    logger.trace(\n-                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName(),\n-                                        ranges.size()\n-                                    );\n-                                    syncDirectory = true;\n-                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                                }\n-                            } catch (Exception e) {\n-                                logger.warn(\n-                                    () -> new ParameterizedMessage(\n-                                        \"{} failed to fsync cache file [{}]\",\n-                                        shardId,\n-                                        cacheFile.getFile().getFileName()\n-                                    ),\n-                                    e\n-                                );\n-                            }\n-                        }\n-                    }\n+        final Set<CacheFile> cacheFilesToSync = cacheFilesToSyncRef.getAndSet(SUPPLIER_OF_CACHE_FILES_TO_SYNC.get());\n+        if (cacheFilesToSync.isEmpty()) {\n+            logger.debug(\"skipping cache synchronization (no cache files to fsync)\");\n+            return;\n+        }\n \n-                    if (syncDirectory) {\n-                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n-                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n-                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n-                            if (Files.exists(snapshotCacheDir)) {\n-                                try {\n-                                    IOUtils.fsync(snapshotCacheDir, true, false);\n-                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n-                                } catch (Exception e) {\n-                                    logger.warn(\n-                                        () -> new ParameterizedMessage(\n-                                            \"{} failed to synchronize cache directory [{}]\",\n-                                            shardId,\n-                                            snapshotCacheDir\n-                                        ),\n-                                        e\n-                                    );\n-                                }\n-                            }\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (CacheFile cacheFile : cacheFilesToSync) {\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n                         }\n                     }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n                 }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n         }\n+\n         if (logger.isDebugEnabled()) {\n             final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n             logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n         }\n     }\n \n-    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n-        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n-        if (routingNode != null) {\n-            for (ShardRouting shardRouting : routingNode) {\n-                if (shardRouting.active()) {\n-                    final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n-                    if (isSearchableSnapshotStore(indexMetadata.getSettings())) {\n-                        return true;\n-                    }\n-                }\n-            }\n-        }\n-        return false;\n-    }\n-\n     class CacheSynchronizationTask extends AbstractAsyncTask {\n \n-        private final AtomicBoolean allowReschedule = new AtomicBoolean(false);\n-\n         CacheSynchronizationTask(ThreadPool threadPool, TimeValue interval) {\n             super(logger, Objects.requireNonNull(threadPool), Objects.requireNonNull(interval), true);\n         }\n \n         @Override\n         protected boolean mustReschedule() {\n-            return allowReschedule.get();\n+            return true;\n         }\n \n         @Override\n"}}, {"oid": "bf0e6600fc90cf1c0fbdde3e591ce53e7dcdaaa4", "url": "https://github.com/elastic/elasticsearch/commit/bf0e6600fc90cf1c0fbdde3e591ce53e7dcdaaa4", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-12T11:39:31Z", "type": "commit"}, {"oid": "9085f81a55fcb04b673705afad62a70bf54225d3", "url": "https://github.com/elastic/elasticsearch/commit/9085f81a55fcb04b673705afad62a70bf54225d3", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-13T09:20:39Z", "type": "commit"}, {"oid": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "url": "https://github.com/elastic/elasticsearch/commit/fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "message": "use registering mechanism to sync cache files", "committedDate": "2020-11-16T11:46:45Z", "type": "commit"}, {"oid": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "url": "https://github.com/elastic/elasticsearch/commit/f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-16T11:47:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524247069", "bodyText": "This looks unused now?", "author": "henningandersen", "createdAt": "2020-11-16T12:55:09Z", "path": "server/src/main/java/org/elasticsearch/common/cache/Cache.java", "diffHunk": "@@ -650,6 +650,36 @@ public void remove() {\n         };\n     }\n \n+    /**\n+     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n+     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n+     * undefined.\n+     *\n+     * @return an LRU-ordered {@link Iterable} over the entries in the cache\n+     */\n+    public Iterable<Tuple<K,V>> entries() {", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM5NTQyNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524395426", "bodyText": "Just a drive by comment @tlrx this is still unused and can probably go away, just in case you missed it :)\nI'll take a proper look at this PR in general now", "author": "original-brownbear", "createdAt": "2020-11-16T16:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkzODAxNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524938016", "bodyText": "Just a drive by comment @tlrx this is still unused and can probably go away, just in case you missed it :)\n\nThanks! I'll remove it.\n\nI'll take a proper look at this PR in general now\n\nI was about to ping you once Henning approved the direction :)", "author": "tlrx", "createdAt": "2020-11-17T07:39:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjA1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962059", "bodyText": "I removed the unused entries() method in 6b238d6", "author": "tlrx", "createdAt": "2020-11-17T08:19:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "6b238d6e76b0ad8445feae40ef7076611d88a5c8", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/common/cache/Cache.java b/server/src/main/java/org/elasticsearch/common/cache/Cache.java\nindex 586c093a9cf..0384e778766 100644\n--- a/server/src/main/java/org/elasticsearch/common/cache/Cache.java\n+++ b/server/src/main/java/org/elasticsearch/common/cache/Cache.java\n\n@@ -650,36 +650,6 @@ public class Cache<K, V> {\n         };\n     }\n \n-    /**\n-     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n-     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n-     * undefined.\n-     *\n-     * @return an LRU-ordered {@link Iterable} over the entries in the cache\n-     */\n-    public Iterable<Tuple<K,V>> entries() {\n-        return () -> new Iterator<>() {\n-\n-            private final CacheIterator iterator = new CacheIterator(head);\n-\n-            @Override\n-            public boolean hasNext() {\n-                return iterator.hasNext();\n-            }\n-\n-            @Override\n-            public Tuple<K,V> next() {\n-                final Cache.Entry<K, V> next = iterator.next();\n-                return Tuple.tuple(next.key, next.value);\n-            }\n-\n-            @Override\n-            public void remove() {\n-                iterator.remove();\n-            }\n-        };\n-    }\n-\n     private class CacheIterator implements Iterator<Entry<K, V>> {\n         private Entry<K, V> current;\n         private Entry<K, V> next;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MjI4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524252282", "bodyText": "Looks like this might as well be a method (or inlined)?", "author": "henningandersen", "createdAt": "2020-11-16T13:04:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +69,65 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Supplier<Set<CacheFile>> SUPPLIER_OF_CACHE_FILES_TO_SYNC = ConcurrentCollections::newConcurrentSet;", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MjA4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524342085", "bodyText": "I removed this when moving to a Queue implementation.", "author": "tlrx", "createdAt": "2020-11-16T15:14:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MjI4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "684e01ec740fa9c69b20c19d902305df8231e480", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex ea32145dbbf..1a95983b20c 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -78,17 +77,27 @@ public class CacheService extends AbstractLifecycleComponent {\n         Setting.Property.Dynamic\n     );\n \n-    private static final Supplier<Set<CacheFile>> SUPPLIER_OF_CACHE_FILES_TO_SYNC = ConcurrentCollections::newConcurrentSet;\n+    public static final Setting<Integer> SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING = Setting.intSetting(\n+        SETTINGS_PREFIX + \"max_files_to_sync\",\n+        10_000,                                                 // default\n+        0,                                                      // min\n+        Integer.MAX_VALUE,                                      // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n     private static final Logger logger = LogManager.getLogger(CacheService.class);\n \n     private final ThreadPool threadPool;\n-    private final AtomicReference<Set<CacheFile>> cacheFilesToSyncRef;\n+    private final ConcurrentLinkedQueue<CacheFile> cacheFilesToSync;\n     private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n     private final Runnable cacheCleaner;\n     private final ByteSizeValue rangeSize;\n \n+    private volatile int maxCacheFilesToSyncAtOnce;\n+\n     public CacheService(\n         final Settings settings,\n         final ClusterService clusterService,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MzcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524253711", "bodyText": "I think this is a leftover from last iteration? Since it is a final field initialized in constructor, I would prefer not to have this assert.", "author": "henningandersen", "createdAt": "2020-11-16T13:06:47Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +183,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MTg4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524341887", "bodyText": "Right, I removed it", "author": "tlrx", "createdAt": "2020-11-16T15:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MzcxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "684e01ec740fa9c69b20c19d902305df8231e480", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex ea32145dbbf..1a95983b20c 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -185,10 +197,13 @@ public class CacheService extends AbstractLifecycleComponent {\n     }\n \n     void setCacheSyncInterval(TimeValue interval) {\n-        assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n     /**\n      * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n      * <p>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MDM4OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524260388", "bodyText": "There is a race condition here, since we first get the set and then add to it. But the synchronizeCache method might read the set and check that it is empty before the add is done here, risking that we miss an fsync. Same is true for the non-empty case, in that it could start iterating over the set before the add is executed.\nMaybe we can use a queue instead? Since CacheFile ensures it is only registered once, we might not need the set semantics except when removing a cache file (where we could just iterate the queue, seems ok, could even just leave it in the queue).", "author": "henningandersen", "createdAt": "2020-11-16T13:18:09Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +183,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MzkwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524343901", "bodyText": "You're perfectly right, I'm sorry I did not catch it by myself as it is obvious. I pushed 684e01e to use a ConcurrentLinkedQueue which should give us the right semantic.", "author": "tlrx", "createdAt": "2020-11-16T15:17:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MDM4OA=="}], "type": "inlineReview", "revised_code": {"commit": "684e01ec740fa9c69b20c19d902305df8231e480", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex ea32145dbbf..1a95983b20c 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -185,10 +197,13 @@ public class CacheService extends AbstractLifecycleComponent {\n     }\n \n     void setCacheSyncInterval(TimeValue interval) {\n-        assert cacheSyncTask != null;\n         cacheSyncTask.setInterval(interval);\n     }\n \n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n     /**\n      * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n      * <p>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524266404", "bodyText": "If the compareAndSet above does not succeed, should we then perhaps fail when running tests (using an assert)?", "author": "henningandersen", "createdAt": "2020-11-16T13:28:03Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -444,12 +461,12 @@ boolean needsFsync() {\n                         assert completedRanges != null;\n                         assert completedRanges.isEmpty() == false;\n \n-                        IOUtils.fsync(file, false, false); // TODO don't forget to fsync parent directory\n+                        IOUtils.fsync(file, false, false);\n                         success = true;\n                         return completedRanges;\n                     } finally {\n                         if (success == false) {\n-                            needsFsync.set(true);\n+                            markAsNeedsFSync();\n                         }\n                     }\n                 }", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0NDYwNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524344607", "bodyText": "I think we can but the existing tests assume that fsync can be executed at any time even when fsync is not needed. Those tests should be adapted as well, maybe in a follow up?", "author": "tlrx", "createdAt": "2020-11-16T15:18:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwODI2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525008269", "bodyText": "\ud83d\udc4d", "author": "henningandersen", "createdAt": "2020-11-17T09:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "684e01ec740fa9c69b20c19d902305df8231e480", "url": "https://github.com/elastic/elasticsearch/commit/684e01ec740fa9c69b20c19d902305df8231e480", "message": "Use a queue", "committedDate": "2020-11-16T15:14:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjkxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524426914", "bodyText": "Looks like we're only ever passing null here in tests, maybe cleaner to just pass the noop consumer in tests than having this conditional?", "author": "original-brownbear", "createdAt": "2020-11-16T17:04:41Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -117,10 +124,11 @@ protected void closeInternal() {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file) {\n+    public CacheFile(String description, long length, Path file, @Nullable Consumer<CacheFile> fsyncListener) {\n         this.tracker = new SparseFileTracker(file.toString(), length);\n         this.description = Objects.requireNonNull(description);\n         this.file = Objects.requireNonNull(file);\n+        this.needsFsyncListener = fsyncListener != null ? fsyncListener : cacheFile -> {};", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjI0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962246", "bodyText": "Done in af47aaa", "author": "tlrx", "createdAt": "2020-11-17T08:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjkxNA=="}], "type": "inlineReview", "revised_code": {"commit": "af47aaa052d82b6033de699956a575ffd780ab73", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex 2246a69ca00..1951d55e8ce 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -124,11 +124,11 @@ public class CacheFile {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file, @Nullable Consumer<CacheFile> fsyncListener) {\n+    public CacheFile(String description, long length, Path file, Consumer<CacheFile> fsyncListener) {\n         this.tracker = new SparseFileTracker(file.toString(), length);\n         this.description = Objects.requireNonNull(description);\n         this.file = Objects.requireNonNull(file);\n-        this.needsFsyncListener = fsyncListener != null ? fsyncListener : cacheFile -> {};\n+        this.needsFsyncListener = Objects.requireNonNull(fsyncListener);\n         assert invariant();\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMjM0OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524532348", "bodyText": "I wonder if we should be this heroic? I guess I could see us running into an IOException here when exceeding the FD limit, but beyond that it seems there's very little valid reasons to keep going with a cache file after we fail to fsync it?\nShould we have a notion of forcefully dropping such a file from the cache since we can't trust it any longer?", "author": "original-brownbear", "createdAt": "2020-11-16T19:52:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTI4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941285", "bodyText": "I agree, my attention was to not add the cache file to the Lucene index if the fsync failed.\n\nShould we have a notion of forcefully dropping such a file from the cache since we can't trust it any longer?\n\nI think we need such a mechanism because we should also discard a cache file in case we fail to write a range in it. I think I can try to tackle this in a follow up but I expect tests to be quite complex.", "author": "tlrx", "createdAt": "2020-11-17T07:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMjM0OA=="}], "type": "inlineReview", "revised_code": {"commit": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1a95983b20c..274bcc43413 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,14 +218,12 @@ public class CacheService extends AbstractLifecycleComponent {\n     /**\n      * This method is invoked after a {@link CacheFile} is evicted from the cache.\n      * <p>\n-     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n-     * queue of cache files to synchronize if the instance is referenced there.\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n      *\n      * @param cacheFile the evicted instance\n      */\n     void onCacheFileRemoval(CacheFile cacheFile) {\n         IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n-        cacheFilesToSync.remove(cacheFile);\n     }\n \n     // used in tests\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMzU1OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524533558", "bodyText": "Same as the other comment, maybe even more pronounced here: what does it mean if we fail to fsync the directory? Doesn't it at least mean that we failed to fsync the file as well? (it's certainly not guaranteed to be safely persisted if it was just created on many Linux FS)", "author": "original-brownbear", "createdAt": "2020-11-16T19:54:18Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTYyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941625", "bodyText": "Doesn't it at least mean that we failed to fsync the file as well? (it's certainly not guaranteed to be safely persisted if it was just created on many Linux FS)\n\nThat's my understanding as well, meaning that the cache file should not be added to the Lucene index.", "author": "tlrx", "createdAt": "2020-11-17T07:47:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMzU1OA=="}], "type": "inlineReview", "revised_code": {"commit": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1a95983b20c..274bcc43413 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,14 +218,12 @@ public class CacheService extends AbstractLifecycleComponent {\n     /**\n      * This method is invoked after a {@link CacheFile} is evicted from the cache.\n      * <p>\n-     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n-     * queue of cache files to synchronize if the instance is referenced there.\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n      *\n      * @param cacheFile the evicted instance\n      */\n     void onCacheFileRemoval(CacheFile cacheFile) {\n         IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n-        cacheFilesToSync.remove(cacheFile);\n     }\n \n     // used in tests\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524535233", "bodyText": "Should we first remove the file from the queue and then evict to have less of a race here with concurrent fsync runs?", "author": "original-brownbear", "createdAt": "2020-11-16T19:57:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTk2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941965", "bodyText": "I saw it the other way, as startEviction() should prevent more ranges to be written and then the cache file to register itself back into the queue.", "author": "tlrx", "createdAt": "2020-11-17T07:47:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjYyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962621", "bodyText": "I removed the remove() call in eabe562", "author": "tlrx", "createdAt": "2020-11-17T08:20:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw=="}], "type": "inlineReview", "revised_code": {"commit": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1a95983b20c..274bcc43413 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,14 +218,12 @@ public class CacheService extends AbstractLifecycleComponent {\n     /**\n      * This method is invoked after a {@link CacheFile} is evicted from the cache.\n      * <p>\n-     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n-     * queue of cache files to synchronize if the instance is referenced there.\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n      *\n      * @param cacheFile the evicted instance\n      */\n     void onCacheFileRemoval(CacheFile cacheFile) {\n         IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n-        cacheFilesToSync.remove(cacheFile);\n     }\n \n     // used in tests\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524540649", "bodyText": "Also, calling remove (O(n)) on a ConcurrentLinkedQueue feels like it may bring trouble if we're dealing with a large number of files queued up? Do we even need to do this when we could simply skip evicted files when polling the fsync queue?", "author": "original-brownbear", "createdAt": "2020-11-16T20:07:11Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDAxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524944011", "bodyText": "Agree - Henning also raised this point. The CacheFile#fsync() method should return an empty set of ranges if the cache file is evicted and deleted from disk, we can rely on this to skip removed files.", "author": "tlrx", "createdAt": "2020-11-17T07:52:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962550", "bodyText": "I removed the remove() call in eabe562", "author": "tlrx", "createdAt": "2020-11-17T08:19:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1a95983b20c..274bcc43413 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,14 +218,12 @@ public class CacheService extends AbstractLifecycleComponent {\n     /**\n      * This method is invoked after a {@link CacheFile} is evicted from the cache.\n      * <p>\n-     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n-     * queue of cache files to synchronize if the instance is referenced there.\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n      *\n      * @param cacheFile the evicted instance\n      */\n     void onCacheFileRemoval(CacheFile cacheFile) {\n         IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n-        cacheFilesToSync.remove(cacheFile);\n     }\n \n     // used in tests\n"}}, {"oid": "6b238d6e76b0ad8445feae40ef7076611d88a5c8", "url": "https://github.com/elastic/elasticsearch/commit/6b238d6e76b0ad8445feae40ef7076611d88a5c8", "message": "revert changes in Cache", "committedDate": "2020-11-17T08:13:11Z", "type": "commit"}, {"oid": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "url": "https://github.com/elastic/elasticsearch/commit/eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "message": "do not remove from queue on eviction", "committedDate": "2020-11-17T08:14:06Z", "type": "commit"}, {"oid": "af47aaa052d82b6033de699956a575ffd780ab73", "url": "https://github.com/elastic/elasticsearch/commit/af47aaa052d82b6033de699956a575ffd780ab73", "message": "noop fsyncListener", "committedDate": "2020-11-17T08:17:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525005337", "bodyText": "It would be nice to ensure we never loop further than the set of cache files already in the queue at the beginning of this method. Can we cap the number of iterations by the size of the queue before we start any fsync'ing? It is O(n) on the linked-queue implementation, but I think that is fine.\nIf we just continue looping, we risk an oscillating effect of writing another block of data and then fsync'ing it multiple times, resulting in much more fsync'ing than desired.", "author": "henningandersen", "createdAt": "2020-11-17T09:27:33Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE5OTk1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525199959", "bodyText": "This is a good suggestion, I pushed 437c8ea.", "author": "tlrx", "createdAt": "2020-11-17T14:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwNjI1OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525206258", "bodyText": "Are you sure this is ok? The size() call isn't just O(n) it also has no accuracy guarantees. Should we maybe use org.elasticsearch.common.util.concurrent.SizeBlockingQueue here to make this a little safer?", "author": "original-brownbear", "createdAt": "2020-11-17T14:41:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIxMzcwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525213701", "bodyText": "I'd prefer not using a BlockingQueue at all. An alternative could be to maintain a cacheFilesToSync atomic counter that is incremented when the cache file register itself for fsync (in onCacheFileUpdate) and decremented everytime a fsync is executed. The current size would be captured before we start any fsync'ing.", "author": "tlrx", "createdAt": "2020-11-17T14:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIxODQ4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525218482", "bodyText": "Ah right, this queue isn't blocking :) -> counter sounds good to me", "author": "original-brownbear", "createdAt": "2020-11-17T14:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIyNTUzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525225539", "bodyText": "I pushed 395845d", "author": "tlrx", "createdAt": "2020-11-17T15:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}], "type": "inlineReview", "revised_code": {"commit": "437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 274bcc43413..a687c5f0f8b 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -246,7 +246,7 @@ public class CacheService extends AbstractLifecycleComponent {\n         long count = 0L;\n         final Set<Path> cacheDirs = new HashSet<>();\n         final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        final int maxCacheFilesToSync = Math.min(cacheFilesToSync.size(), this.maxCacheFilesToSyncAtOnce);\n         for (long i = 0L; i < maxCacheFilesToSync; i++) {\n             if (lifecycleState() != Lifecycle.State.STARTED) {\n                 logger.debug(\"stopping cache synchronization (cache service is closing)\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAzOTAzOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525039038", "bodyText": "I think we only expect IOException here. Perhaps we can assert that to ensure tests will fail?\nSimilar assert a few lines up.", "author": "henningandersen", "createdAt": "2020-11-17T10:17:32Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDAzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200031", "bodyText": "Makes sense, I added c20bf75", "author": "tlrx", "createdAt": "2020-11-17T14:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAzOTAzOA=="}], "type": "inlineReview", "revised_code": {"commit": "437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 274bcc43413..a687c5f0f8b 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -246,7 +246,7 @@ public class CacheService extends AbstractLifecycleComponent {\n         long count = 0L;\n         final Set<Path> cacheDirs = new HashSet<>();\n         final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        final int maxCacheFilesToSync = Math.min(cacheFilesToSync.size(), this.maxCacheFilesToSyncAtOnce);\n         for (long i = 0L; i < maxCacheFilesToSync; i++) {\n             if (lifecycleState() != Lifecycle.State.STARTED) {\n                 logger.debug(\"stopping cache synchronization (cache service is closing)\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MTg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525051853", "bodyText": "nit: I find it nicer to just pass in a Runnable here, to make it clear that a CacheFile can only request an fsync of itself.", "author": "henningandersen", "createdAt": "2020-11-17T10:37:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -117,10 +124,11 @@ protected void closeInternal() {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file) {\n+    public CacheFile(String description, long length, Path file, Consumer<CacheFile> fsyncListener) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDA2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200069", "bodyText": "I pushed 74f728f to use a Runnable", "author": "tlrx", "createdAt": "2020-11-17T14:33:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MTg1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "74f728f51f097f2129314ffdcc64bdc9eeebc554", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex 1951d55e8ce..d8ebd1a9ecb 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -124,11 +123,11 @@ public class CacheFile {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file, Consumer<CacheFile> fsyncListener) {\n+    public CacheFile(String description, long length, Path file, Runnable onNeedFSync) {\n         this.tracker = new SparseFileTracker(file.toString(), length);\n         this.description = Objects.requireNonNull(description);\n         this.file = Objects.requireNonNull(file);\n-        this.needsFsyncListener = Objects.requireNonNull(fsyncListener);\n+        this.needsFsyncRunnable = Objects.requireNonNull(onNeedFSync);\n         assert invariant();\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MzcxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525053714", "bodyText": "This will add it back on the queue, so we continually try to fsync a bad file. I saw the comments Armin made in other places about this, we can tackle this in the same follow-up.", "author": "henningandersen", "createdAt": "2020-11-17T10:40:09Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -444,12 +461,12 @@ boolean needsFsync() {\n                         assert completedRanges != null;\n                         assert completedRanges.isEmpty() == false;\n \n-                        IOUtils.fsync(file, false, false); // TODO don't forget to fsync parent directory\n+                        IOUtils.fsync(file, false, false);\n                         success = true;\n                         return completedRanges;\n                     } finally {\n                         if (success == false) {\n-                            needsFsync.set(true);\n+                            markAsNeedsFSync();", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDEwMw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200103", "bodyText": "Let's do that \ud83d\udc4d", "author": "tlrx", "createdAt": "2020-11-17T14:33:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MzcxNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1NTE0NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525055144", "bodyText": "I wonder if we should lower this to 1 second.\nI can imagine us using this for a poor-mans rate limiter - set the interval to 1 second and number of files to sync to 10 on a spinning disk setup in case fsync'ing causes issues.", "author": "henningandersen", "createdAt": "2020-11-17T10:42:16Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +68,78 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDE1NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200154", "bodyText": "Makes sense, I pushed 365812d", "author": "tlrx", "createdAt": "2020-11-17T14:33:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1NTE0NA=="}], "type": "inlineReview", "revised_code": {"commit": "365812d53aebf7023cdd8010f430274de0930247", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 274bcc43413..92713674ecd 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -68,7 +69,7 @@ public class CacheService extends AbstractLifecycleComponent {\n         Setting.Property.NodeScope\n     );\n \n-    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);\n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n     public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n         SETTINGS_PREFIX + \"sync_interval\",\n         TimeValue.timeValueSeconds(60L),                        // default\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA2MDU4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525060587", "bodyText": "These fields are unused. Seems like you intended the rootDir to have significance?", "author": "henningandersen", "createdAt": "2020-11-17T10:50:53Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -245,4 +291,46 @@ public void putAsync(\n             listener.onResponse(null);\n         }\n     }\n+\n+    /**\n+     * A {@link FileSystemProvider} that counts the number of times the method {@link FileChannel#force(boolean)} is executed on every\n+     * files.\n+     */\n+    public static class FSyncTrackingFileSystemProvider extends FilterFileSystemProvider {\n+\n+        private final Map<Path, AtomicInteger> files = new ConcurrentHashMap<>();\n+        private final FileSystem delegateInstance;\n+        private final Path rootDir;", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDE5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200191", "bodyText": "This should have been mutualized with some other tests, it is now in 5091a5d. Thanks for spotting this.", "author": "tlrx", "createdAt": "2020-11-17T14:33:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA2MDU4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\nindex f528db5215f..ec4614fc96d 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n\n@@ -299,6 +300,7 @@ public final class TestUtils {\n     public static class FSyncTrackingFileSystemProvider extends FilterFileSystemProvider {\n \n         private final Map<Path, AtomicInteger> files = new ConcurrentHashMap<>();\n+        private final AtomicBoolean failFSyncs = new AtomicBoolean();\n         private final FileSystem delegateInstance;\n         private final Path rootDir;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3MTE0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525071146", "bodyText": "Would be good to verify that once we evicted, we do not fsync these CacheFiles anymore.", "author": "henningandersen", "createdAt": "2020-11-17T11:08:14Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.store.cache.CacheFile;\n+import org.elasticsearch.index.store.cache.CacheKey;\n+import org.elasticsearch.index.store.cache.TestUtils.FSyncTrackingFileSystemProvider;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.xpack.searchablesnapshots.AbstractSearchableSnapshotsTestCase;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.SortedSet;\n+\n+import static org.elasticsearch.index.store.cache.TestUtils.randomPopulateAndReads;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n+\n+    private static FSyncTrackingFileSystemProvider fileSystemProvider;\n+\n+    @BeforeClass\n+    public static void installFileSystem() {\n+        fileSystemProvider = new FSyncTrackingFileSystemProvider(PathUtils.getDefaultFileSystem(), createTempDir());\n+        PathUtilsForTesting.installMock(fileSystemProvider.getFileSystem(null));\n+    }\n+\n+    @AfterClass\n+    public static void removeFileSystem() {\n+        PathUtilsForTesting.teardown();\n+    }\n+\n+    public void testCacheSynchronization() throws Exception {\n+        final int numShards = randomIntBetween(1, 3);\n+        final Index index = new Index(randomAlphaOfLength(5).toLowerCase(Locale.ROOT), UUIDs.randomBase64UUID(random()));\n+        final SnapshotId snapshotId = new SnapshotId(\"_snapshot_name\", UUIDs.randomBase64UUID(random()));\n+        final IndexId indexId = new IndexId(\"_index_name\", UUIDs.randomBase64UUID(random()));\n+\n+        logger.debug(\"--> creating shard cache directories on disk\");\n+        final Path[] shardsCacheDirs = new Path[numShards];\n+        for (int i = 0; i < numShards; i++) {\n+            final Path shardDataPath = randomFrom(nodeEnvironment.availableShardPaths(new ShardId(index, i)));\n+            assertFalse(Files.exists(shardDataPath));\n+\n+            logger.debug(\"--> creating directories [{}] for shard [{}]\", shardDataPath.toAbsolutePath(), i);\n+            shardsCacheDirs[i] = Files.createDirectories(CacheService.resolveSnapshotCache(shardDataPath).resolve(snapshotId.getUUID()));\n+        }\n+\n+        try (CacheService cacheService = defaultCacheService()) {\n+            cacheService.start();\n+\n+            logger.debug(\"--> setting large cache sync interval (explicit cache synchronization calls in test)\");\n+            cacheService.setCacheSyncInterval(TimeValue.timeValueMillis(Long.MAX_VALUE));\n+\n+            // Keep a count of the number of writes for every cache file existing in the cache\n+            final Map<CacheKey, Tuple<CacheFile, Integer>> previous = new HashMap<>();\n+\n+            for (int iteration = 0; iteration < between(1, 10); iteration++) {\n+\n+                final Map<CacheKey, Tuple<CacheFile, Integer>> updates = new HashMap<>();\n+\n+                logger.trace(\"--> more random reads/writes from existing cache files\");\n+                for (Map.Entry<CacheKey, Tuple<CacheFile, Integer>> cacheEntry : randomSubsetOf(previous.entrySet())) {\n+                    final CacheKey cacheKey = cacheEntry.getKey();\n+                    final CacheFile cacheFile = cacheEntry.getValue().v1();\n+\n+                    final CacheFile.EvictionListener listener = evictedCacheFile -> {};\n+                    cacheFile.acquire(listener);\n+\n+                    final SortedSet<Tuple<Long, Long>> newCacheRanges = randomPopulateAndReads(cacheFile);\n+                    assertThat(cacheService.isCacheFileToSync(cacheFile), is(newCacheRanges.isEmpty() == false));\n+                    if (newCacheRanges.isEmpty() == false) {\n+                        final int numberOfWrites = cacheEntry.getValue().v2() + 1;\n+                        updates.put(cacheKey, Tuple.tuple(cacheFile, numberOfWrites));\n+                    }\n+                    cacheFile.release(listener);\n+                }\n+\n+                logger.trace(\"--> creating new cache files and randomly read/write them\");\n+                for (int i = 0; i < between(1, 25); i++) {\n+                    final ShardId shardId = new ShardId(index, randomIntBetween(0, numShards - 1));\n+                    final String fileName = String.format(Locale.ROOT, \"file_%d_%d\", iteration, i);\n+                    final CacheKey cacheKey = new CacheKey(snapshotId, indexId, shardId, fileName);\n+                    final CacheFile cacheFile = cacheService.get(cacheKey, randomIntBetween(1, 10_000), shardsCacheDirs[shardId.id()]);\n+\n+                    final CacheFile.EvictionListener listener = evictedCacheFile -> {};\n+                    cacheFile.acquire(listener);\n+\n+                    final SortedSet<Tuple<Long, Long>> newRanges = randomPopulateAndReads(cacheFile);\n+                    assertThat(cacheService.isCacheFileToSync(cacheFile), is(newRanges.isEmpty() == false));\n+                    updates.put(cacheKey, Tuple.tuple(cacheFile, newRanges.isEmpty() ? 0 : 1));\n+                    cacheFile.release(listener);\n+                }\n+\n+                logger.trace(\"--> evicting random cache files\");\n+                for (CacheKey evictedCacheKey : randomSubsetOf(Sets.union(previous.keySet(), updates.keySet()))) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDI1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200257", "bodyText": "Right - I added f69dde9", "author": "tlrx", "createdAt": "2020-11-17T14:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3MTE0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f69dde9e9e911a02fbf728a378e65da8b56cba7b", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\nindex 8bec280eb28..c1df46a88b0 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\n\n@@ -112,10 +112,17 @@ public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n                 }\n \n                 logger.trace(\"--> evicting random cache files\");\n+                final Map<CacheFile, Integer> evictions = new HashMap<>();\n                 for (CacheKey evictedCacheKey : randomSubsetOf(Sets.union(previous.keySet(), updates.keySet()))) {\n                     cacheService.removeFromCache(evictedCacheKey::equals);\n-                    previous.remove(evictedCacheKey);\n-                    updates.remove(evictedCacheKey);\n+                    Tuple<CacheFile, Integer> evicted = previous.remove(evictedCacheKey);\n+                    if (evicted != null) {\n+                        evictions.put(evicted.v1(), evicted.v2());\n+                        updates.remove(evictedCacheKey);\n+                    } else {\n+                        evicted = updates.remove(evictedCacheKey);\n+                        evictions.put(evicted.v1(), 0);\n+                    }\n                 }\n \n                 logger.trace(\"--> capturing expected number of fsyncs per cache directory before synchronization\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3NDk4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525074989", "bodyText": "I think we should bias towards smaller values, perhaps using scaledRandomInt?", "author": "henningandersen", "createdAt": "2020-11-17T11:14:38Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java", "diffHunk": "@@ -63,19 +101,27 @@ protected CacheService randomCacheService() {\n         if (randomBoolean()) {\n             cacheSettings.put(CacheService.SNAPSHOT_CACHE_RANGE_SIZE_SETTING.getKey(), randomCacheRangeSize());\n         }\n-        return new CacheService(AbstractSearchableSnapshotsTestCase::noOpCacheCleaner, cacheSettings.build());\n+        if (randomBoolean()) {\n+            cacheSettings.put(\n+                CacheService.SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING.getKey(),\n+                TimeValue.timeValueSeconds(randomLongBetween(MIN_SNAPSHOT_CACHE_SYNC_INTERVAL.getSeconds(), Long.MAX_VALUE))", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDI5MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200290", "bodyText": "I pushed 8fe920b to randomize between 1 and 120 seconds.", "author": "tlrx", "createdAt": "2020-11-17T14:33:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3NDk4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "8fe920be20ba2478f45e2940c688b9ab6ded559f", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java\nindex 7ee27c0cf7f..47a2be35bf4 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java\n\n@@ -104,7 +104,7 @@ public abstract class AbstractSearchableSnapshotsTestCase extends ESIndexInputTe\n         if (randomBoolean()) {\n             cacheSettings.put(\n                 CacheService.SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING.getKey(),\n-                TimeValue.timeValueSeconds(randomLongBetween(MIN_SNAPSHOT_CACHE_SYNC_INTERVAL.getSeconds(), Long.MAX_VALUE))\n+                TimeValue.timeValueSeconds(scaledRandomIntBetween(1, 120))\n             );\n         }\n         return new CacheService(cacheSettings.build(), clusterService, threadPool, AbstractSearchableSnapshotsTestCase::noOpCacheCleaner);\n"}}, {"oid": "437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "url": "https://github.com/elastic/elasticsearch/commit/437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "message": "limit iterations", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "c20bf75e9f58a71cfcc624b2cb230f3167c0c6b7", "url": "https://github.com/elastic/elasticsearch/commit/c20bf75e9f58a71cfcc624b2cb230f3167c0c6b7", "message": "assert IOE", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "365812d53aebf7023cdd8010f430274de0930247", "url": "https://github.com/elastic/elasticsearch/commit/365812d53aebf7023cdd8010f430274de0930247", "message": "min 1s", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "8fe920be20ba2478f45e2940c688b9ab6ded559f", "url": "https://github.com/elastic/elasticsearch/commit/8fe920be20ba2478f45e2940c688b9ab6ded559f", "message": "scaledRandomIntBetween(1, 120)", "committedDate": "2020-11-17T12:23:44Z", "type": "commit"}, {"oid": "74f728f51f097f2129314ffdcc64bdc9eeebc554", "url": "https://github.com/elastic/elasticsearch/commit/74f728f51f097f2129314ffdcc64bdc9eeebc554", "message": "Use runnable", "committedDate": "2020-11-17T13:30:22Z", "type": "commit"}, {"oid": "5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "url": "https://github.com/elastic/elasticsearch/commit/5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "message": "mutualize FSyncTrackingFileSystemProvider", "committedDate": "2020-11-17T13:48:20Z", "type": "commit"}, {"oid": "f69dde9e9e911a02fbf728a378e65da8b56cba7b", "url": "https://github.com/elastic/elasticsearch/commit/f69dde9e9e911a02fbf728a378e65da8b56cba7b", "message": "check evictions", "committedDate": "2020-11-17T14:32:35Z", "type": "commit"}, {"oid": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "url": "https://github.com/elastic/elasticsearch/commit/395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "message": "use atomic long to count cache files", "committedDate": "2020-11-17T15:03:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MDA0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525260049", "bodyText": "NIT: we seem to generally wrap parameters in [{}] when logging?", "author": "original-brownbear", "createdAt": "2020-11-17T15:38:16Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,129 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final long value = numberOfCacheFilesToSync.decrementAndGet();\n+            assert value >= 0 : value;\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            assert e instanceof IOException : e;\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                assert e instanceof IOException : e;\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n+            }\n+        }\n+        if (logger.isDebugEnabled()) {\n+            final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n+            logger.debug(\n+                \"cache files synchronization is done ({} cache files synchronized in {})\",", "originalCommit": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "082b76db40bd1076b57905433caff29247dc4859", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1c5a6506ac5..cbd1b077378 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -251,7 +251,7 @@ public class CacheService extends AbstractLifecycleComponent {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected void synchronizeCache() {\n+    protected synchronized void synchronizeCache() {\n         long count = 0L;\n         final Set<Path> cacheDirs = new HashSet<>();\n         final long startTimeNanos = threadPool.relativeTimeInNanos();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MTk4NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525261984", "bodyText": "Could we theoretically assert that the service has been stopped here? (it seems the only way for the queue to be reduced is for this method to run and it should only ever run once at any point in time)", "author": "original-brownbear", "createdAt": "2020-11-17T15:40:39Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,129 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");", "originalCommit": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTkwOTE5OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525909198", "bodyText": "Since this method is the only place where cache files are removed from the queue I think it makes more sense to synchronized the synchronizeCache() method and asserts here that we never poll a null cacheFile", "author": "tlrx", "createdAt": "2020-11-18T08:48:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MTk4NA=="}], "type": "inlineReview", "revised_code": {"commit": "082b76db40bd1076b57905433caff29247dc4859", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 1c5a6506ac5..cbd1b077378 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -251,7 +251,7 @@ public class CacheService extends AbstractLifecycleComponent {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected void synchronizeCache() {\n+    protected synchronized void synchronizeCache() {\n         long count = 0L;\n         final Set<Path> cacheDirs = new HashSet<>();\n         final long startTimeNanos = threadPool.relativeTimeInNanos();\n"}}, {"oid": "082b76db40bd1076b57905433caff29247dc4859", "url": "https://github.com/elastic/elasticsearch/commit/082b76db40bd1076b57905433caff29247dc4859", "message": "[] + synchronized assert", "committedDate": "2020-11-18T09:09:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk3NDU1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525974553", "bodyText": "nit: I would find it more readable with an explicit lock object. It also reduces the risk of/if someone synchronizing another method in this class", "author": "henningandersen", "createdAt": "2020-11-18T10:25:29Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -251,7 +251,7 @@ boolean isCacheFileToSync(CacheFile cacheFile) {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected void synchronizeCache() {\n+    protected synchronized void synchronizeCache() {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4ODAxOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527688018", "bodyText": "I agree, an explicit lock object would help. It also helps if we want to wait a bit for the cache sync task to terminate before shutdown, so I added such a lock.", "author": "tlrx", "createdAt": "2020-11-20T13:25:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk3NDU1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex cbd1b077378..d4c5625fec2 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -251,51 +276,62 @@ public class CacheService extends AbstractLifecycleComponent {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n-        long count = 0L;\n-        final Set<Path> cacheDirs = new HashSet<>();\n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n-        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+    protected void synchronizeCache() {\n+        cacheSyncLock.lock();\n+        try {\n             if (lifecycleState() != Lifecycle.State.STARTED) {\n                 logger.debug(\"stopping cache synchronization (cache service is closing)\");\n-                break;\n+                return;\n             }\n-            final CacheFile cacheFile = cacheFilesToSync.poll();\n-            assert cacheFile != null;\n-\n-            final long value = numberOfCacheFilesToSync.decrementAndGet();\n-            assert value >= 0 : value;\n-            final Path cacheFilePath = cacheFile.getFile();\n-            try {\n-                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n-                if (ranges.isEmpty() == false) {\n-                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n-                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n-                    if (cacheDirs.add(cacheDir)) {\n-                        try {\n-                            IOUtils.fsync(cacheDir, true, false);\n-                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n-                        } catch (Exception e) {\n-                            assert e instanceof IOException : e;\n-                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+\n+            long count = 0L;\n+            final Set<Path> cacheDirs = new HashSet<>();\n+            final long startTimeNanos = threadPool.relativeTimeInNanos();\n+            final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+\n+            for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+                final CacheFile cacheFile = cacheFilesToSync.poll();\n+                assert cacheFile != null;\n+\n+                final long value = numberOfCacheFilesToSync.decrementAndGet();\n+                assert value >= 0 : value;\n+                final Path cacheFilePath = cacheFile.getFile();\n+                try {\n+                    final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                    if (ranges.isEmpty() == false) {\n+                        logger.trace(\n+                            \"cache file [{}] synchronized with [{}] completed range(s)\",\n+                            cacheFilePath.getFileName(),\n+                            ranges.size()\n+                        );\n+                        final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                        if (cacheDirs.add(cacheDir)) {\n+                            try {\n+                                IOUtils.fsync(cacheDir, true, false);\n+                                logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                            } catch (Exception e) {\n+                                assert e instanceof IOException : e;\n+                                logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                            }\n                         }\n+                        // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                        count += 1L;\n                     }\n-                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n-                    count += 1L;\n+                } catch (Exception e) {\n+                    assert e instanceof IOException : e;\n+                    logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n                 }\n-            } catch (Exception e) {\n-                assert e instanceof IOException : e;\n-                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n             }\n-        }\n-        if (logger.isDebugEnabled()) {\n-            final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n-            logger.debug(\n-                \"cache files synchronization is done ([{}] cache files synchronized in [{}])\",\n-                count,\n-                TimeValue.timeValueNanos(elapsedNanos)\n-            );\n+            if (logger.isDebugEnabled()) {\n+                final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n+                logger.debug(\n+                    \"cache files synchronization is done ([{}] cache files synchronized in [{}])\",\n+                    count,\n+                    TimeValue.timeValueNanos(elapsedNanos)\n+                );\n+            }\n+        } finally {\n+            cacheSyncLock.unlock();\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4NzIyMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525987220", "bodyText": "Should we also wait (with timeout) for any ongoing cache sync task to complete?", "author": "henningandersen", "createdAt": "2020-11-18T10:44:59Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +71,80 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    public static final Setting<Integer> SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING = Setting.intSetting(\n+        SETTINGS_PREFIX + \"max_files_to_sync\",\n+        10_000,                                                 // default\n+        0,                                                      // min\n+        Integer.MAX_VALUE,                                      // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Logger logger = LogManager.getLogger(CacheService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final ConcurrentLinkedQueue<CacheFile> cacheFilesToSync;\n+    private final AtomicLong numberOfCacheFilesToSync;\n+    private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n     private final Runnable cacheCleaner;\n     private final ByteSizeValue rangeSize;\n \n-    public CacheService(final Runnable cacheCleaner, final Settings settings) {\n-        this(cacheCleaner, SNAPSHOT_CACHE_SIZE_SETTING.get(settings), SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings));\n-    }\n+    private volatile int maxCacheFilesToSyncAtOnce;\n \n-    // exposed for tests\n-    public CacheService(final Runnable cacheCleaner, final ByteSizeValue cacheSize, final ByteSizeValue rangeSize) {\n-        this.cacheSize = Objects.requireNonNull(cacheSize);\n+    public CacheService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final ThreadPool threadPool,\n+        final Runnable cacheCleaner\n+    ) {\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.cacheSize = SNAPSHOT_CACHE_SIZE_SETTING.get(settings);\n         this.cacheCleaner = Objects.requireNonNull(cacheCleaner);\n-        this.rangeSize = Objects.requireNonNull(rangeSize);\n+        this.rangeSize = SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings);\n         this.cache = CacheBuilder.<CacheKey, CacheFile>builder()\n             .setMaximumWeight(cacheSize.getBytes())\n             .weigher((key, entry) -> entry.getLength())\n             // NORELEASE This does not immediately free space on disk, as cache file are only deleted when all index inputs\n             // are done with reading/writing the cache file\n-            .removalListener(notification -> IOUtils.closeWhileHandlingException(() -> notification.getValue().startEviction()))\n+            .removalListener(notification -> onCacheFileRemoval(notification.getValue()))\n             .build();\n+        this.numberOfCacheFilesToSync = new AtomicLong();\n+        this.cacheFilesToSync = new ConcurrentLinkedQueue<>();\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        this.maxCacheFilesToSyncAtOnce = SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING.get(settings);\n+        clusterSettings.addSettingsUpdateConsumer(SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING, this::setMaxCacheFilesToSyncAtOnce);\n+        this.cacheSyncTask = new CacheSynchronizationTask(threadPool, SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING.get(settings));\n+        clusterSettings.addSettingsUpdateConsumer(SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING, this::setCacheSyncInterval);\n     }\n \n     public static Path getShardCachePath(ShardPath shardPath) {\n-        return shardPath.getDataPath().resolve(\"snapshot_cache\");\n+        return resolveSnapshotCache(shardPath.getDataPath());\n+    }\n+\n+    static Path resolveSnapshotCache(Path path) {\n+        return path.resolve(\"snapshot_cache\");\n     }\n \n     @Override\n     protected void doStart() {\n+        cacheSyncTask.rescheduleIfNecessary();\n         cacheCleaner.run();\n     }\n \n     @Override\n     protected void doStop() {\n+        cacheSyncTask.close();", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4ODEyOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527688128", "bodyText": "\ud83d\udc4d", "author": "tlrx", "createdAt": "2020-11-20T13:25:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4NzIyMA=="}], "type": "inlineReview", "revised_code": {"commit": "bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex cbd1b077378..d4c5625fec2 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -73,7 +74,7 @@ public class CacheService extends AbstractLifecycleComponent {\n \n     public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n     public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n-        SETTINGS_PREFIX + \"sync_interval\",\n+        SETTINGS_PREFIX + \"sync.interval\",\n         TimeValue.timeValueSeconds(60L),                        // default\n         MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n         Setting.Property.NodeScope,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODM3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525988375", "bodyText": "I think this can be private?", "author": "henningandersen", "createdAt": "2020-11-18T10:46:46Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDgzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684839", "bodyText": "I pushed ea34570", "author": "tlrx", "createdAt": "2020-11-20T13:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODM3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "ea34570bfaf68a928b29187c32fa1f3686b85fd9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex cbd1b077378..a0e232cee6a 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,7 +218,7 @@ public class CacheService extends AbstractLifecycleComponent {\n      *\n      * @param cacheFile the instance that needs to be fsync\n      */\n-    void onCacheFileUpdate(CacheFile cacheFile) {\n+    private void onCacheFileUpdate(CacheFile cacheFile) {\n         assert cacheFile != null;\n         cacheFilesToSync.offer(cacheFile);\n         numberOfCacheFilesToSync.incrementAndGet();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODQyNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525988426", "bodyText": "I think this can be private?", "author": "henningandersen", "createdAt": "2020-11-18T10:46:50Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDg3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684877", "bodyText": "I pushed ea34570", "author": "tlrx", "createdAt": "2020-11-20T13:19:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODQyNg=="}], "type": "inlineReview", "revised_code": {"commit": "ea34570bfaf68a928b29187c32fa1f3686b85fd9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex cbd1b077378..a0e232cee6a 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,7 +218,7 @@ public class CacheService extends AbstractLifecycleComponent {\n      *\n      * @param cacheFile the instance that needs to be fsync\n      */\n-    void onCacheFileUpdate(CacheFile cacheFile) {\n+    private void onCacheFileUpdate(CacheFile cacheFile) {\n         assert cacheFile != null;\n         cacheFilesToSync.offer(cacheFile);\n         numberOfCacheFilesToSync.incrementAndGet();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5MDk5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525990995", "bodyText": "Do we need to fsync the directory except for the first time we fsync a file created in the directory? Perhaps we should do that when creating the file instead?\nThis can be handled in a follow-up if you prefer (and agree).", "author": "henningandersen", "createdAt": "2020-11-18T10:50:53Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            assert cacheFile != null;\n+\n+            final long value = numberOfCacheFilesToSync.decrementAndGet();\n+            assert value >= 0 : value;\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY5MzE3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527693179", "bodyText": "I found it simpler to do it here and concentrate the fsync logic at one place, but I agree it means an extra fsync per cache directory every 60s.\n\nPerhaps we should do that when creating the file instead?\n\nThat would mean to fsync the cache dir the first time a cache file is opened and have a mechanism to keep the knowledge of which cache dir was already fsync or not, since the cache file can be evicted before the cache sync task is executed. That sounds a bit more complex for a little gain to me.", "author": "tlrx", "createdAt": "2020-11-20T13:34:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5MDk5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "ea34570bfaf68a928b29187c32fa1f3686b85fd9", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex cbd1b077378..a0e232cee6a 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -218,7 +218,7 @@ public class CacheService extends AbstractLifecycleComponent {\n      *\n      * @param cacheFile the instance that needs to be fsync\n      */\n-    void onCacheFileUpdate(CacheFile cacheFile) {\n+    private void onCacheFileUpdate(CacheFile cacheFile) {\n         assert cacheFile != null;\n         cacheFilesToSync.offer(cacheFile);\n         numberOfCacheFilesToSync.incrementAndGet();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5NTI5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525995299", "bodyText": "Can we move this into a method on the file system provider so that it just reads:\nprovider.tearDown();\n\nhere?", "author": "henningandersen", "createdAt": "2020-11-18T10:57:31Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java", "diffHunk": "@@ -271,23 +300,30 @@ public void testFSyncFailure() throws Exception {\n                 final SortedSet<Tuple<Long, Long>> expectedCompletedRanges = randomPopulateAndReads(cacheFile);\n                 if (expectedCompletedRanges.isEmpty() == false) {\n                     assertTrue(cacheFile.needsFsync());\n-                    expectThrows(IOException.class, cacheFile::fsync);\n+                    assertTrue(needsFSyncCalled.getAndSet(false));\n+                    IOException exception = expectThrows(IOException.class, cacheFile::fsync);\n+                    assertThat(exception.getMessage(), containsString(\"simulated\"));\n+                    assertTrue(cacheFile.needsFsync());\n+                    assertTrue(needsFSyncCalled.getAndSet(false));\n                 } else {\n                     assertFalse(cacheFile.needsFsync());\n                     final SortedSet<Tuple<Long, Long>> completedRanges = cacheFile.fsync();\n                     assertTrue(completedRanges.isEmpty());\n                 }\n-                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(0L));\n+                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(0));\n \n-                fileSystem.failFSyncs.set(false);\n+                fileSystem.failFSyncs(false);\n \n                 final SortedSet<Tuple<Long, Long>> completedRanges = cacheFile.fsync();\n                 assertArrayEquals(completedRanges.toArray(Tuple[]::new), expectedCompletedRanges.toArray(Tuple[]::new));\n-                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(expectedCompletedRanges.isEmpty() ? 0L : 1L));\n+                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(expectedCompletedRanges.isEmpty() ? 0 : 1));\n                 assertFalse(cacheFile.needsFsync());\n+                assertFalse(needsFSyncCalled.get());\n             } finally {\n                 cacheFile.release(listener);\n             }\n+        } finally {\n+            PathUtilsForTesting.installMock(fileSystem.getDelegateInstance());", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDk4MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684980", "bodyText": "+1 I pushed 54d051d", "author": "tlrx", "createdAt": "2020-11-20T13:19:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5NTI5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "54d051d8829b323fe7748daee37ac5ff5aefd170", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\nindex 9bf16b3220a..0c5d6b18d22 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java\n\n@@ -323,7 +323,7 @@ public class CacheFileTests extends ESTestCase {\n                 cacheFile.release(listener);\n             }\n         } finally {\n-            PathUtilsForTesting.installMock(fileSystem.getDelegateInstance());\n+            fileSystem.tearDown();\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwMDg5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526000893", "bodyText": "I think we should do this before cacheService.start() to avoid a race condition of the schedule task \"just started to run\" before we change this, which could interfere with the testing below.", "author": "henningandersen", "createdAt": "2020-11-18T11:06:23Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.store.cache.CacheFile;\n+import org.elasticsearch.index.store.cache.CacheKey;\n+import org.elasticsearch.index.store.cache.TestUtils.FSyncTrackingFileSystemProvider;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.xpack.searchablesnapshots.AbstractSearchableSnapshotsTestCase;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.SortedSet;\n+\n+import static org.elasticsearch.index.store.cache.TestUtils.randomPopulateAndReads;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n+\n+    private static FSyncTrackingFileSystemProvider fileSystemProvider;\n+\n+    @BeforeClass\n+    public static void installFileSystem() {\n+        fileSystemProvider = new FSyncTrackingFileSystemProvider(PathUtils.getDefaultFileSystem(), createTempDir());\n+        PathUtilsForTesting.installMock(fileSystemProvider.getFileSystem(null));\n+    }\n+\n+    @AfterClass\n+    public static void removeFileSystem() {\n+        PathUtilsForTesting.teardown();\n+    }\n+\n+    public void testCacheSynchronization() throws Exception {\n+        final int numShards = randomIntBetween(1, 3);\n+        final Index index = new Index(randomAlphaOfLength(5).toLowerCase(Locale.ROOT), UUIDs.randomBase64UUID(random()));\n+        final SnapshotId snapshotId = new SnapshotId(\"_snapshot_name\", UUIDs.randomBase64UUID(random()));\n+        final IndexId indexId = new IndexId(\"_index_name\", UUIDs.randomBase64UUID(random()));\n+\n+        logger.debug(\"--> creating shard cache directories on disk\");\n+        final Path[] shardsCacheDirs = new Path[numShards];\n+        for (int i = 0; i < numShards; i++) {\n+            final Path shardDataPath = randomFrom(nodeEnvironment.availableShardPaths(new ShardId(index, i)));\n+            assertFalse(Files.exists(shardDataPath));\n+\n+            logger.debug(\"--> creating directories [{}] for shard [{}]\", shardDataPath.toAbsolutePath(), i);\n+            shardsCacheDirs[i] = Files.createDirectories(CacheService.resolveSnapshotCache(shardDataPath).resolve(snapshotId.getUUID()));\n+        }\n+\n+        try (CacheService cacheService = defaultCacheService()) {\n+            cacheService.start();\n+\n+            logger.debug(\"--> setting large cache sync interval (explicit cache synchronization calls in test)\");\n+            cacheService.setCacheSyncInterval(TimeValue.timeValueMillis(Long.MAX_VALUE));", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NTgwMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527685800", "bodyText": "Right - I pushed 6066924", "author": "tlrx", "createdAt": "2020-11-20T13:21:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwMDg5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "54d051d8829b323fe7748daee37ac5ff5aefd170", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\nindex c1df46a88b0..33821a26344 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java\n\n@@ -46,7 +46,7 @@ public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n \n     @AfterClass\n     public static void removeFileSystem() {\n-        PathUtilsForTesting.teardown();\n+        fileSystemProvider.tearDown();\n     }\n \n     public void testCacheSynchronization() throws Exception {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwNDE4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526004187", "bodyText": "This looks like it is a near identical copy from CacheFileTests, but the original method has not been removed, I think it should?", "author": "henningandersen", "createdAt": "2020-11-18T11:11:49Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -22,20 +27,62 @@\n import java.io.FileNotFoundException;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.FileSystem;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.ArrayList;\n import java.util.Comparator;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n import java.util.SortedSet;\n import java.util.TreeSet;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n+import static java.util.Collections.synchronizedNavigableSet;\n+import static org.apache.lucene.util.LuceneTestCase.random;\n+import static org.elasticsearch.common.settings.Settings.builder;\n+import static org.elasticsearch.node.Node.NODE_NAME_SETTING;\n+import static org.elasticsearch.test.ESTestCase.between;\n+import static org.elasticsearch.test.ESTestCase.randomLongBetween;\n import static org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsConstants.toIntBytes;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.equalTo;\n+import static org.junit.Assert.assertTrue;\n import static org.mockito.Mockito.mock;\n \n public final class TestUtils {\n     private TestUtils() {}\n \n+    public static SortedSet<Tuple<Long, Long>> randomPopulateAndReads(final CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NTQ4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527685481", "bodyText": "Apparently I started to mutualize utility methods but did not gone through... I pushed e8ad9be", "author": "tlrx", "createdAt": "2020-11-20T13:20:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwNDE4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "54d051d8829b323fe7748daee37ac5ff5aefd170", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\nindex ec4614fc96d..9a69ae0b964 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n\n@@ -20,6 +20,7 @@ import org.elasticsearch.common.blobstore.BlobPath;\n import org.elasticsearch.common.blobstore.DeleteResult;\n import org.elasticsearch.common.bytes.BytesReference;\n import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n import org.elasticsearch.common.io.Streams;\n import org.elasticsearch.index.store.IndexInputStats;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAxMDIwMg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526010202", "bodyText": "That the tests work with this confused me for a while - but CacheFile uses deleteIfExists, which delegates to the original file system rather than going here. We need to keep the fsync counters for the check that we no longer fsync after evict to work.\nI wonder if this override of delete is at all necessary?", "author": "henningandersen", "createdAt": "2020-11-18T11:21:42Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -245,4 +292,62 @@ public void putAsync(\n             listener.onResponse(null);\n         }\n     }\n+\n+    /**\n+     * A {@link FileSystemProvider} that counts the number of times the method {@link FileChannel#force(boolean)} is executed on every\n+     * files.\n+     */\n+    public static class FSyncTrackingFileSystemProvider extends FilterFileSystemProvider {\n+\n+        private final Map<Path, AtomicInteger> files = new ConcurrentHashMap<>();\n+        private final AtomicBoolean failFSyncs = new AtomicBoolean();\n+        private final FileSystem delegateInstance;\n+        private final Path rootDir;\n+\n+        public FSyncTrackingFileSystemProvider(FileSystem delegate, Path rootDir) {\n+            super(\"fsynccounting://\", delegate);\n+            this.rootDir = new FilterPath(rootDir, this.fileSystem);\n+            this.delegateInstance = delegate;\n+        }\n+\n+        public FileSystem getDelegateInstance() {\n+            return delegateInstance;\n+        }\n+\n+        public void failFSyncs(boolean shouldFail) {\n+            failFSyncs.set(shouldFail);\n+        }\n+\n+        public Path resolve(String other) {\n+            return rootDir.resolve(other);\n+        }\n+\n+        @Nullable\n+        public Integer getNumberOfFSyncs(Path path) {\n+            final AtomicInteger counter = files.get(path);\n+            return counter != null ? counter.get() : null;\n+        }\n+\n+        @Override\n+        public FileChannel newFileChannel(Path path, Set<? extends OpenOption> options, FileAttribute<?>... attrs) throws IOException {\n+            final AtomicInteger counter = files.computeIfAbsent(path, p -> new AtomicInteger(0));\n+            return new FilterFileChannel(delegate.newFileChannel(toDelegate(path), options, attrs)) {\n+\n+                @Override\n+                public void force(boolean metaData) throws IOException {\n+                    if (failFSyncs.get()) {\n+                        throw new IOException(\"simulated\");\n+                    }\n+                    super.force(metaData);\n+                    counter.incrementAndGet();\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public void delete(Path path) throws IOException {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4Njg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527686853", "bodyText": "That the tests work with this confused me for a while - but CacheFile uses deleteIfExists, which delegates to the original file system rather than going here.\n\nI agree this is confusing. This delete method is a left over from a previous version of a test that worked differently. I removed the method in e9721c4. I also noticed a subtility in the testFSyncOnEvictedFile() test where the file is not released until the test ends, preventing the file to be deleted from disk. I added some randomization there.", "author": "tlrx", "createdAt": "2020-11-20T13:23:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAxMDIwMg=="}], "type": "inlineReview", "revised_code": {"commit": "54d051d8829b323fe7748daee37ac5ff5aefd170", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\nindex ec4614fc96d..9a69ae0b964 100644\n--- a/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n+++ b/x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java\n\n@@ -310,10 +311,6 @@ public final class TestUtils {\n             this.delegateInstance = delegate;\n         }\n \n-        public FileSystem getDelegateInstance() {\n-            return delegateInstance;\n-        }\n-\n         public void failFSyncs(boolean shouldFail) {\n             failFSyncs.set(shouldFail);\n         }\n"}}, {"oid": "ea34570bfaf68a928b29187c32fa1f3686b85fd9", "url": "https://github.com/elastic/elasticsearch/commit/ea34570bfaf68a928b29187c32fa1f3686b85fd9", "message": "private", "committedDate": "2020-11-20T09:44:30Z", "type": "commit"}, {"oid": "54d051d8829b323fe7748daee37ac5ff5aefd170", "url": "https://github.com/elastic/elasticsearch/commit/54d051d8829b323fe7748daee37ac5ff5aefd170", "message": "provider.tearDown()", "committedDate": "2020-11-20T10:02:03Z", "type": "commit"}, {"oid": "e8ad9be817caba9d9f7ff4ea33d60ee56cfbae53", "url": "https://github.com/elastic/elasticsearch/commit/e8ad9be817caba9d9f7ff4ea33d60ee56cfbae53", "message": "randomPopulateAndReads", "committedDate": "2020-11-20T10:07:05Z", "type": "commit"}, {"oid": "6066924795a61fb689cf0b2740e17074019b5eeb", "url": "https://github.com/elastic/elasticsearch/commit/6066924795a61fb689cf0b2740e17074019b5eeb", "message": "set interval before start", "committedDate": "2020-11-20T10:08:50Z", "type": "commit"}, {"oid": "e9721c43b8c24cb74475e7ecbd1fb2e4f5feda38", "url": "https://github.com/elastic/elasticsearch/commit/e9721c43b8c24cb74475e7ecbd1fb2e4f5feda38", "message": "deleteIfExists", "committedDate": "2020-11-20T10:52:19Z", "type": "commit"}, {"oid": "bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "url": "https://github.com/elastic/elasticsearch/commit/bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "message": "lock & waitfor termination", "committedDate": "2020-11-20T13:16:31Z", "type": "commit"}, {"oid": "46adb3c4344e330a099a1642da31b25a668a5a34", "url": "https://github.com/elastic/elasticsearch/commit/46adb3c4344e330a099a1642da31b25a668a5a34", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-20T13:17:53Z", "type": "commit"}, {"oid": "04a4d77ed3762dd581bd8b6d57eaef88ef322af3", "url": "https://github.com/elastic/elasticsearch/commit/04a4d77ed3762dd581bd8b6d57eaef88ef322af3", "message": "missing close", "committedDate": "2020-11-20T13:24:36Z", "type": "commit"}, {"oid": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "url": "https://github.com/elastic/elasticsearch/commit/db24043323d0cd4ac10470d839ace3ea4293a7a5", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-23T08:22:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3MjQzMg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528572432", "bodyText": "Perhaps just 10 seconds default, since we only need to wait for one fsync and if it takes more than 10s to do one, we really want to continue shutting down the node anyway? The other doStop timeouts that I found (did not search thoroughly though) are in the 10-30s range.", "author": "henningandersen", "createdAt": "2020-11-23T09:39:26Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -73,28 +74,37 @@\n \n     public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n     public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n-        SETTINGS_PREFIX + \"sync_interval\",\n+        SETTINGS_PREFIX + \"sync.interval\",\n         TimeValue.timeValueSeconds(60L),                        // default\n         MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n         Setting.Property.NodeScope,\n         Setting.Property.Dynamic\n     );\n \n     public static final Setting<Integer> SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING = Setting.intSetting(\n-        SETTINGS_PREFIX + \"max_files_to_sync\",\n+        SETTINGS_PREFIX + \"sync.max_files\",\n         10_000,                                                 // default\n         0,                                                      // min\n-        Integer.MAX_VALUE,                                      // min\n+        Integer.MAX_VALUE,                                      // max\n         Setting.Property.NodeScope,\n         Setting.Property.Dynamic\n     );\n \n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_SHUTDOWN_TIMEOUT = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync.shutdown_timeout\",\n+        TimeValue.timeValueSeconds(60L),                        // default", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTcwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591709", "bodyText": "Agreed.", "author": "tlrx", "createdAt": "2020-11-23T10:10:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3MjQzMg=="}], "type": "inlineReview", "revised_code": {"commit": "10216ea40af97363b47646ffe3bcadb384f0fbde", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 0905bd35403..6afe9c3b9f2 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -92,7 +92,7 @@ public class CacheService extends AbstractLifecycleComponent {\n \n     public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_SHUTDOWN_TIMEOUT = Setting.timeSetting(\n         SETTINGS_PREFIX + \"sync.shutdown_timeout\",\n-        TimeValue.timeValueSeconds(60L),                        // default\n+        TimeValue.timeValueSeconds(10L),                        // default\n         TimeValue.ZERO,                                         // min\n         Setting.Property.NodeScope\n     );\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NTg0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528575847", "bodyText": "I think we need to also do cacheSyncTask.close() and cache.invalidateAll() in this case? Possibly better to surround the tryLock with a separate try catch for InterruptedException.", "author": "henningandersen", "createdAt": "2020-11-23T09:44:51Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -144,8 +156,22 @@ protected void doStart() {\n \n     @Override\n     protected void doStop() {\n-        cacheSyncTask.close();\n-        cache.invalidateAll();\n+        boolean acquired = false;\n+        try {\n+            acquired = cacheSyncLock.tryLock(cacheSyncStopTimeout.duration(), cacheSyncStopTimeout.timeUnit());\n+            if (acquired == false) {\n+                logger.warn(\"failed to acquire cache sync lock in [{}], cache might be partially persisted\", cacheSyncStopTimeout);\n+            }\n+            cacheSyncTask.close();\n+            cache.invalidateAll();\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            logger.warn(\"interrupted while waiting for cache sync lock\", e);", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTU5MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591590", "bodyText": "Oh right, I'll surround the tryLock", "author": "tlrx", "createdAt": "2020-11-23T10:10:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NTg0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "10216ea40af97363b47646ffe3bcadb384f0fbde", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 0905bd35403..6afe9c3b9f2 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -158,15 +158,17 @@ public class CacheService extends AbstractLifecycleComponent {\n     protected void doStop() {\n         boolean acquired = false;\n         try {\n-            acquired = cacheSyncLock.tryLock(cacheSyncStopTimeout.duration(), cacheSyncStopTimeout.timeUnit());\n-            if (acquired == false) {\n-                logger.warn(\"failed to acquire cache sync lock in [{}], cache might be partially persisted\", cacheSyncStopTimeout);\n+            try {\n+                acquired = cacheSyncLock.tryLock(cacheSyncStopTimeout.duration(), cacheSyncStopTimeout.timeUnit());\n+                if (acquired == false) {\n+                    logger.warn(\"failed to acquire cache sync lock in [{}], cache might be partially persisted\", cacheSyncStopTimeout);\n+                }\n+            } catch (InterruptedException e) {\n+                Thread.currentThread().interrupt();\n+                logger.warn(\"interrupted while waiting for cache sync lock\", e);\n             }\n             cacheSyncTask.close();\n             cache.invalidateAll();\n-        } catch (InterruptedException e) {\n-            Thread.currentThread().interrupt();\n-            logger.warn(\"interrupted while waiting for cache sync lock\", e);\n         } finally {\n             if (acquired) {\n                 cacheSyncLock.unlock();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NjgwNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528576804", "bodyText": "I would prefer to keep this inside the loop to ensure we break out as soon as possible when shutting down.", "author": "henningandersen", "createdAt": "2020-11-23T09:46:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -251,51 +277,62 @@ boolean isCacheFileToSync(CacheFile cacheFile) {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n-        long count = 0L;\n-        final Set<Path> cacheDirs = new HashSet<>();\n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n-        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+    protected void synchronizeCache() {\n+        cacheSyncLock.lock();\n+        try {\n             if (lifecycleState() != Lifecycle.State.STARTED) {", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTM3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591371", "bodyText": "Ok", "author": "tlrx", "createdAt": "2020-11-23T10:09:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NjgwNA=="}], "type": "inlineReview", "revised_code": {"commit": "10216ea40af97363b47646ffe3bcadb384f0fbde", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\nindex 0905bd35403..6afe9c3b9f2 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java\n\n@@ -280,17 +282,17 @@ public class CacheService extends AbstractLifecycleComponent {\n     protected void synchronizeCache() {\n         cacheSyncLock.lock();\n         try {\n-            if (lifecycleState() != Lifecycle.State.STARTED) {\n-                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n-                return;\n-            }\n-\n             long count = 0L;\n             final Set<Path> cacheDirs = new HashSet<>();\n             final long startTimeNanos = threadPool.relativeTimeInNanos();\n             final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n \n             for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+                if (lifecycleState() != Lifecycle.State.STARTED) {\n+                    logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                    return;\n+                }\n+\n                 final CacheFile cacheFile = cacheFilesToSync.poll();\n                 assert cacheFile != null;\n \n"}}, {"oid": "10216ea40af97363b47646ffe3bcadb384f0fbde", "url": "https://github.com/elastic/elasticsearch/commit/10216ea40af97363b47646ffe3bcadb384f0fbde", "message": "nits", "committedDate": "2020-11-23T10:16:10Z", "type": "commit"}]}