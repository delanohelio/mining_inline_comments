{"pr_number": 51327, "pr_title": "Upgrade to lucene-8.5.0-snapshot-3333ce7da6d", "pr_createdAt": "2020-01-22T17:40:36Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51327", "timeline": [{"oid": "2ae12136fea1f4b5a131ba062d58081b4fe2bc63", "url": "https://github.com/elastic/elasticsearch/commit/2ae12136fea1f4b5a131ba062d58081b4fe2bc63", "message": "Upgrade to lucene-8.5.0-snapshot-3333ce7da6d", "committedDate": "2020-01-22T17:28:03Z", "type": "commit"}, {"oid": "a9f0c999292e7e05429907ca30d415ad9e3a870b", "url": "https://github.com/elastic/elasticsearch/commit/a9f0c999292e7e05429907ca30d415ad9e3a870b", "message": "Keep previous behaviour of FieldHighlighter::highlightOffsetsEnums\n\nLUCENE-9093 modified how FieldHighlighter breaks texts into passages,\nwhich doesn't work well with elasticsearch custome BoundedBreakIteratorScanner.\nThis commit for now keeps previous behaviour of FieldHighlighter.", "committedDate": "2020-01-23T14:31:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMDk1MA==", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370530950", "bodyText": "I think we can remove XIntervals now that LUCENE-9050 is released - just use plain Intervals instead.", "author": "romseygeek", "createdAt": "2020-01-24T09:07:13Z", "path": "server/src/main/java/org/elasticsearch/index/query/IntervalsSourceProvider.java", "diffHunk": "@@ -797,8 +797,8 @@ public IntervalsSource getSource(QueryShardContext context, MappedFieldType fiel\n             BytesRef normalizedTerm = analyzer.normalize(fieldType.name(), term);\n             FuzzyQuery fq = new FuzzyQuery(new Term(fieldType.name(), normalizedTerm),\n                 fuzziness.asDistance(term), prefixLength, 128, transpositions);\n-            CompiledAutomaton ca = new CompiledAutomaton(fq.toAutomaton());\n-            source = XIntervals.multiterm(ca, term);\n+            CompiledAutomaton[] automata = fq.getAutomata();\n+            source = XIntervals.multiterm(automata[automata.length - 1], term);\n             if (useField != null) {", "originalCommit": "a9f0c999292e7e05429907ca30d415ad9e3a870b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDY2OTcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370669711", "bodyText": "@romseygeek Thanks for the comment. Looks like Intervals.multiterm expects Automaton, while a FuzzyQuery can only produce CompiledAutomaton.  Or is there any other way to use Intervals.multiterm?", "author": "mayya-sharipova", "createdAt": "2020-01-24T14:45:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMDk1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDY3MTczNw==", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370671737", "bodyText": "Hm, maybe we need to put a fuzzy method directly on Intervals then.  Let's leave XIntervals in there for the moment, I'll open a lucene ticket to clean this up.", "author": "romseygeek", "createdAt": "2020-01-24T14:49:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMDk1MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMTk3OA==", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370531978", "bodyText": "This just overrides LUCENE-9093 and preserves the previous behaviour, correct? +1 if so", "author": "romseygeek", "createdAt": "2020-01-24T09:10:11Z", "path": "server/src/main/java/org/apache/lucene/search/uhighlight/CustomFieldHighlighter.java", "diffHunk": "@@ -76,4 +82,84 @@\n         }\n         return EMPTY_PASSAGE;\n     }\n+\n+    // TODO: use FieldHighlighter::highlightOffsetsEnums and modify BoundedBreakIteratorScanner to work with it\n+    // LUCENE-9093 modified how FieldHighlighter breaks texts into passages,\n+    // which doesn't work well with BoundedBreakIteratorScanner\n+    // This is the copy of highlightOffsetsEnums before LUCENE-9093.\n+    @Override\n+    protected Passage[] highlightOffsetsEnums(OffsetsEnum off)\n+        throws IOException {\n+\n+        final int contentLength = this.breakIterator.getText().getEndIndex();\n+\n+        if (off.nextPosition() == false) {\n+            return new Passage[0];\n+        }\n+\n+        PriorityQueue<Passage> passageQueue = new PriorityQueue<>(Math.min(64, maxPassages + 1), (left, right) -> {\n+            if (left.getScore() < right.getScore()) {\n+                return -1;\n+            } else if (left.getScore() > right.getScore()) {\n+                return 1;\n+            } else {\n+                return left.getStartOffset() - right.getStartOffset();\n+            }\n+        });\n+        Passage passage = new Passage(); // the current passage in-progress.  Will either get reset or added to queue.\n+\n+        do {\n+            int start = off.startOffset();\n+            if (start == -1) {\n+                throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n+            }\n+            int end = off.endOffset();\n+            if (start < contentLength && end > contentLength) {\n+                continue;\n+            }\n+            // See if this term should be part of a new passage.\n+            if (start >= passage.getEndOffset()) {\n+                passage = maybeAddPassage(passageQueue, passageScorer, passage, contentLength);\n+                // if we exceed limit, we are done\n+                if (start >= contentLength) {\n+                    break;\n+                }\n+                passage.setStartOffset(Math.max(this.breakIterator.preceding(start + 1), 0));\n+                passage.setEndOffset(Math.min(this.breakIterator.following(start), contentLength));\n+            }\n+            // Add this term to the passage.\n+            BytesRef term = off.getTerm();// a reference; safe to refer to\n+            assert term != null;\n+            passage.addMatch(start, end, term, off.freq());\n+        } while (off.nextPosition());\n+        maybeAddPassage(passageQueue, passageScorer, passage, contentLength);\n+\n+        Passage[] passages = passageQueue.toArray(new Passage[passageQueue.size()]);\n+        // sort in ascending order\n+        Arrays.sort(passages, Comparator.comparingInt(Passage::getStartOffset));\n+        return passages;\n+    }\n+\n+    // TODO: use FieldHighlighter::maybeAddPassage\n+    // After removing CustomFieldHighlighter::highlightOffsetsEnums, remove this method as well.\n+    private Passage maybeAddPassage(PriorityQueue<Passage> passageQueue, PassageScorer scorer, Passage passage, int contentLength) {\n+        if (passage.getStartOffset() == -1) {\n+            // empty passage, we can ignore it\n+            return passage;\n+        }\n+        passage.setScore(scorer.score(passage, contentLength));\n+        // new sentence: first add 'passage' to queue\n+        if (passageQueue.size() == maxPassages && passage.getScore() < passageQueue.peek().getScore()) {\n+            passage.reset(); // can't compete, just reset it\n+        } else {\n+            passageQueue.offer(passage);\n+            if (passageQueue.size() > maxPassages) {\n+                passage = passageQueue.poll();\n+                passage.reset();\n+            } else {\n+                passage = new Passage();\n+            }\n+        }\n+        return passage;\n+    }", "originalCommit": "a9f0c999292e7e05429907ca30d415ad9e3a870b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDY2MTIxNA==", "url": "https://github.com/elastic/elasticsearch/pull/51327#discussion_r370661214", "bodyText": "exactly, it just preserves the previous behaviour.", "author": "mayya-sharipova", "createdAt": "2020-01-24T14:28:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMTk3OA=="}], "type": "inlineReview", "revised_code": null}]}