{"pr_number": 50769, "pr_title": "Do not force refresh when write indexing buffer", "pr_createdAt": "2020-01-08T22:59:50Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/50769", "timeline": [{"oid": "2f1f61e596513cba72e904a267e3c1b3f166c561", "url": "https://github.com/elastic/elasticsearch/commit/2f1f61e596513cba72e904a267e3c1b3f166c561", "message": "Do not force refresh when write indexing buffer", "committedDate": "2020-01-08T22:20:37Z", "type": "commit"}, {"oid": "2261b3f32e9165209ffd711bde3a8815d735de1d", "url": "https://github.com/elastic/elasticsearch/commit/2261b3f32e9165209ffd711bde3a8815d735de1d", "message": "Merge branch 'master' into indexing-memory", "committedDate": "2020-01-08T23:03:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDQ4NzQyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364487421", "bodyText": "I only added this new test. Other tests are unchanged.", "author": "dnhatn", "createdAt": "2020-01-08T23:04:01Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,83 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {", "originalCommit": "2261b3f32e9165209ffd711bde3a8815d735de1d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e6839093339bc1b9ca15b174adec03486d3c1ac2", "chunk": "diff --git a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\nindex 9a5777d9088..052f1453e03 100644\n--- a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n+++ b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n\n@@ -364,6 +364,7 @@ public class IndexingMemoryControllerTests extends IndexShardTestCase {\n         };\n         IndexShard shard = newStartedShard(randomBoolean(), Settings.EMPTY,\n             config -> new InternalEngine(configWithRefreshListener(config, refreshListener)));\n+        refreshLatch.set(new CountDownLatch(1)); // block refresh\n         final RefreshStats refreshStats = shard.refreshStats();\n         final IndexingMemoryController controller = new IndexingMemoryController(\n             Settings.builder().put(\"indices.memory.interval\", \"200h\") // disable it\n"}}, {"oid": "e6839093339bc1b9ca15b174adec03486d3c1ac2", "url": "https://github.com/elastic/elasticsearch/commit/e6839093339bc1b9ca15b174adec03486d3c1ac2", "message": "do not check for rejected", "committedDate": "2020-01-09T02:51:38Z", "type": "commit"}, {"oid": "f0a05f98d63cac908023df9c91955a84a55e39f1", "url": "https://github.com/elastic/elasticsearch/commit/f0a05f98d63cac908023df9c91955a84a55e39f1", "message": "Merge branch 'master' into indexing-memory", "committedDate": "2020-01-09T02:52:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyMTQ1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364621459", "bodyText": "nit: I prefer to find the stats object to assert on first and then assert to ensure we get a NPE if stats for some reason do not contain \"refresh\" rather than pass the test.", "author": "henningandersen", "createdAt": "2020-01-09T08:58:57Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java", "diffHunk": "@@ -346,117 +328,81 @@ public void testThrottling() throws Exception {\n         controller.forceCheck();\n         controller.assertNotThrottled(shard0);\n         controller.assertNotThrottled(shard1);\n+        closeShards(shard0, shard1);\n     }\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n-\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n-        }\n-\n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    EngineConfig configWithRefreshListener(EngineConfig config, ReferenceManager.RefreshListener listener) {\n+        final List<ReferenceManager.RefreshListener> internalRefreshListener = new ArrayList<>(config.getInternalRefreshListener());;\n+        internalRefreshListener.add(listener);\n+        return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+            config.getIndexSettings(), config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+            config.getSimilarity(), new CodecService(null, logger), config.getEventListener(), config.getQueryCache(),\n+            config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+            config.getExternalRefreshListener(), internalRefreshListener, config.getIndexSort(),\n+            config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+            config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n+    }\n \n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+    public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {\n+        SetOnce<CountDownLatch> refreshLatch = new SetOnce<>();\n+        ReferenceManager.RefreshListener refreshListener = new ReferenceManager.RefreshListener() {\n             @Override\n-            protected List<IndexShard> availableShards() {\n-                return Collections.singletonList(shard);\n+            public void beforeRefresh() {\n+                if (refreshLatch.get() != null) {\n+                    try {\n+                        refreshLatch.get().await();\n+                    } catch (InterruptedException e) {\n+                        throw new AssertionError(e);\n+                    }\n+                }\n             }\n \n             @Override\n-            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n-                return shard.getIndexBufferRAMBytesUsed();\n-            }\n+            public void afterRefresh(boolean didRefresh) {\n \n+            }\n+        };\n+        IndexShard shard = newStartedShard(randomBoolean(), Settings.EMPTY,\n+            config -> new InternalEngine(configWithRefreshListener(config, refreshListener)));\n+        refreshLatch.set(new CountDownLatch(1)); // block refresh\n+        final RefreshStats refreshStats = shard.refreshStats();\n+        final IndexingMemoryController controller = new IndexingMemoryController(\n+            Settings.builder().put(\"indices.memory.interval\", \"200h\") // disable it\n+                .put(\"indices.memory.index_buffer_size\", \"1024b\").build(),\n+            threadPool,\n+            Collections.singleton(shard)) {\n             @Override\n-            protected void writeIndexingBufferAsync(IndexShard shard) {\n-                // just do it sync'd for this test\n-                shard.writeIndexingBuffer();\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return randomLongBetween(1025, 10 * 1024 * 1024);\n             }\n \n             @Override\n-            protected Cancellable scheduleTask(ThreadPool threadPool) {\n-                return null;\n+            protected long getShardWritingBytes(IndexShard shard) {\n+                return 0L;\n             }\n         };\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareDelete(\"index\", id).get();\n+        int iterations = randomIntBetween(10, 100);\n+        for (int i = 0; i < iterations; i++) {\n+            controller.forceCheck();\n         }\n-\n-        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n-\n-        imc.forceCheck();\n-\n-        // We must assertBusy because the writeIndexingBufferAsync is done in background (REFRESH) thread pool:\n         assertBusy(() -> {\n-            try (Engine.Searcher s2 = shard.acquireSearcher(\"index\")) {\n-                // 100 buffered deletes will easily exceed our 1 KB indexing buffer so it should trigger a write:\n-                final long indexingBufferBytes2 = shard.getIndexBufferRAMBytesUsed();\n-                assertTrue(indexingBufferBytes2 < indexingBufferBytes1);\n+            for (ThreadPoolStats.Stats stats : threadPool.stats()) {", "originalCommit": "f0a05f98d63cac908023df9c91955a84a55e39f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDg4MzUxMw==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364883513", "bodyText": "++. Adjusted in 7475515.", "author": "dnhatn", "createdAt": "2020-01-09T18:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyMTQ1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "747551513e5712883168a48d4916d2ec6e4202e7", "chunk": "diff --git a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\nindex 052f1453e03..78ae5118435 100644\n--- a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n+++ b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerTests.java\n\n@@ -343,6 +343,16 @@ public class IndexingMemoryControllerTests extends IndexShardTestCase {\n             config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n     }\n \n+    ThreadPoolStats.Stats getRefreshThreadPoolStats() {\n+        final ThreadPoolStats stats = threadPool.stats();\n+        for (ThreadPoolStats.Stats s : stats) {\n+            if (s.getName().equals(ThreadPool.Names.REFRESH)) {\n+                return s;\n+            }\n+        }\n+        throw new AssertionError(\"refresh thread pool stats not found [\" + stats + \"]\");\n+    }\n+\n     public void testSkipRefreshIfShardIsRefreshingAlready() throws Exception {\n         SetOnce<CountDownLatch> refreshLatch = new SetOnce<>();\n         ReferenceManager.RefreshListener refreshListener = new ReferenceManager.RefreshListener() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyOTA5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364629095", "bodyText": "I think there is a (very small) risk that the IndexingMemoryController created by the node was triggered on one  of the deletes and that this causes the writeIndexingBuffer/refresh call triggered here to return immediately. It does take a lot of bad circumstances though (of which the heap size alone will likely prevent this), but I still think we should address it. Maybe the TODO above is doable if this test is moved to its own class? Or we could simply add a node-setting that essentially disables it by setting the limit very high?", "author": "henningandersen", "createdAt": "2020-01-09T09:17:04Z", "path": "server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.indices;\n+\n+import org.apache.lucene.index.DirectoryReader;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeResponse;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.common.CheckedFunction;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.IndexShardIT;\n+import org.elasticsearch.index.shard.IndexShardTestCase;\n+import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.test.ESSingleNodeTestCase;\n+import org.elasticsearch.threadpool.Scheduler.Cancellable;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.util.Collections.emptyMap;\n+import static java.util.Collections.emptySet;\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n+\n+public class IndexingMemoryControllerIT extends ESSingleNodeTestCase {\n+\n+    // #10312\n+    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n+        createIndex(\"index\",\n+                    Settings.builder().put(\"index.number_of_shards\", 1)\n+                                      .put(\"index.number_of_replicas\", 0)\n+                                      .put(\"index.refresh_interval\", -1)\n+                                      .build());\n+        ensureGreen();\n+\n+        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n+        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n+        IndexShard shard = indexService.getShardOrNull(0);\n+        assertNotNull(shard);\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n+        }\n+\n+        // Force merge so we know all merges are done before we start deleting:\n+        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n+        assertNoFailures(r);\n+\n+        // Make a shell of an IMC to check up on indexing buffer usage:\n+        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+\n+        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n+        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n+            @Override\n+            protected List<IndexShard> availableShards() {\n+                return Collections.singletonList(shard);\n+            }\n+\n+            @Override\n+            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n+                return shard.getIndexBufferRAMBytesUsed();\n+            }\n+\n+            @Override\n+            protected void writeIndexingBufferAsync(IndexShard shard) {\n+                // just do it sync'd for this test\n+                shard.writeIndexingBuffer();\n+            }\n+\n+            @Override\n+            protected Cancellable scheduleTask(ThreadPool threadPool) {\n+                return null;\n+            }\n+        };\n+\n+        for (int i = 0; i < 100; i++) {\n+            String id = Integer.toString(i);\n+            client().prepareDelete(\"index\", id).get();\n+        }\n+\n+        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n+\n+        imc.forceCheck();", "originalCommit": "f0a05f98d63cac908023df9c91955a84a55e39f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDg4MzkwMA==", "url": "https://github.com/elastic/elasticsearch/pull/50769#discussion_r364883900", "bodyText": "Good point. I pushed 4d04e97.", "author": "dnhatn", "createdAt": "2020-01-09T18:05:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDYyOTA5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4d04e97c214626fd184de151d6fe36949e0267cb", "chunk": "diff --git a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java\nindex e56876d2ffc..5d5786e992d 100644\n--- a/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java\n+++ b/server/src/test/java/org/elasticsearch/indices/IndexingMemoryControllerIT.java\n\n@@ -18,146 +18,84 @@\n  */\n package org.elasticsearch.indices;\n \n-import org.apache.lucene.index.DirectoryReader;\n-import org.elasticsearch.Version;\n+import org.apache.logging.log4j.LogManager;\n import org.elasticsearch.action.admin.indices.forcemerge.ForceMergeResponse;\n-import org.elasticsearch.cluster.node.DiscoveryNode;\n-import org.elasticsearch.cluster.routing.ShardRouting;\n-import org.elasticsearch.common.CheckedFunction;\n import org.elasticsearch.common.settings.Settings;\n-import org.elasticsearch.common.xcontent.XContentType;\n import org.elasticsearch.index.IndexService;\n-import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.IndexSettings;\n+import org.elasticsearch.index.codec.CodecService;\n+import org.elasticsearch.index.engine.EngineConfig;\n+import org.elasticsearch.index.engine.EngineFactory;\n+import org.elasticsearch.index.engine.InternalEngine;\n+import org.elasticsearch.index.refresh.RefreshStats;\n import org.elasticsearch.index.shard.IndexShard;\n-import org.elasticsearch.index.shard.IndexShardIT;\n-import org.elasticsearch.index.shard.IndexShardTestCase;\n-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;\n-import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.EnginePlugin;\n+import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.test.ESSingleNodeTestCase;\n-import org.elasticsearch.threadpool.Scheduler.Cancellable;\n-import org.elasticsearch.threadpool.ThreadPool;\n \n-import java.io.IOException;\n-import java.util.Collections;\n+import java.util.ArrayList;\n+import java.util.Collection;\n import java.util.List;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicReference;\n+import java.util.Optional;\n \n-import static java.util.Collections.emptyMap;\n-import static java.util.Collections.emptySet;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;\n+import static org.hamcrest.Matchers.greaterThan;\n \n public class IndexingMemoryControllerIT extends ESSingleNodeTestCase {\n \n-    // #10312\n-    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n-        createIndex(\"index\",\n-                    Settings.builder().put(\"index.number_of_shards\", 1)\n-                                      .put(\"index.number_of_replicas\", 0)\n-                                      .put(\"index.refresh_interval\", -1)\n-                                      .build());\n-        ensureGreen();\n+    @Override\n+    protected Settings nodeSettings() {\n+        return Settings.builder().put(super.nodeSettings())\n+            // small indexing buffer so that we can trigger refresh after buffering 100 deletes\n+            .put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n+    }\n \n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"index\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n-        assertNotNull(shard);\n+    @Override\n+    protected Collection<Class<? extends Plugin>> getPlugins() {\n+        final List<Class<? extends Plugin>> plugins = new ArrayList<>(super.getPlugins());\n+        plugins.add(TestEnginePlugin.class);\n+        return plugins;\n+    }\n \n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareIndex(\"index\").setId(id).setSource(\"field\", \"value\").get();\n+    public static class TestEnginePlugin extends Plugin implements EnginePlugin {\n+\n+        EngineConfig engineConfigWithLargerIndexingMemory(EngineConfig config) {\n+            // We need to set a larger buffer for the IndexWriter; otherwise, it will flush before the IndexingMemoryController.\n+            Settings settings = Settings.builder().put(config.getIndexSettings().getSettings())\n+                .put(\"indices.memory.index_buffer_size\", \"10mb\").build();\n+            IndexSettings indexSettings = new IndexSettings(config.getIndexSettings().getIndexMetaData(), settings);\n+            return new EngineConfig(config.getShardId(), config.getAllocationId(), config.getThreadPool(),\n+                indexSettings, config.getWarmer(), config.getStore(), config.getMergePolicy(), config.getAnalyzer(),\n+                config.getSimilarity(), new CodecService(null, LogManager.getLogger(IndexingMemoryControllerIT.class)),\n+                config.getEventListener(), config.getQueryCache(),\n+                config.getQueryCachingPolicy(), config.getTranslogConfig(), config.getFlushMergesAfter(),\n+                config.getExternalRefreshListener(), config.getInternalRefreshListener(), config.getIndexSort(),\n+                config.getCircuitBreakerService(), config.getGlobalCheckpointSupplier(), config.retentionLeasesSupplier(),\n+                config.getPrimaryTermSupplier(), config.getTombstoneDocSupplier());\n         }\n \n-        // Force merge so we know all merges are done before we start deleting:\n-        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n-        assertNoFailures(r);\n-\n-        // Make a shell of an IMC to check up on indexing buffer usage:\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"1kb\").build();\n-\n-        // TODO: would be cleaner if I could pass this 1kb setting to the single node this test created....\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, null, null) {\n-            @Override\n-            protected List<IndexShard> availableShards() {\n-                return Collections.singletonList(shard);\n-            }\n-\n-            @Override\n-            protected long getIndexBufferRAMBytesUsed(IndexShard shard) {\n-                return shard.getIndexBufferRAMBytesUsed();\n-            }\n-\n-            @Override\n-            protected void writeIndexingBufferAsync(IndexShard shard) {\n-                // just do it sync'd for this test\n-                shard.writeIndexingBuffer();\n-            }\n-\n-            @Override\n-            protected Cancellable scheduleTask(ThreadPool threadPool) {\n-                return null;\n-            }\n-        };\n-\n-        for (int i = 0; i < 100; i++) {\n-            String id = Integer.toString(i);\n-            client().prepareDelete(\"index\", id).get();\n+        @Override\n+        public Optional<EngineFactory> getEngineFactory(IndexSettings indexSettings) {\n+            return Optional.of(config -> new InternalEngine(engineConfigWithLargerIndexingMemory(config)));\n         }\n-\n-        final long indexingBufferBytes1 = shard.getIndexBufferRAMBytesUsed();\n-\n-        imc.forceCheck();\n-\n-        // We must assertBusy because the writeIndexingBufferAsync is done in background (REFRESH) thread pool:\n-        assertBusy(() -> {\n-            try (Engine.Searcher s2 = shard.acquireSearcher(\"index\")) {\n-                // 100 buffered deletes will easily exceed our 1 KB indexing buffer so it should trigger a write:\n-                final long indexingBufferBytes2 = shard.getIndexBufferRAMBytesUsed();\n-                assertTrue(indexingBufferBytes2 < indexingBufferBytes1);\n-            }\n-        });\n     }\n \n-    public void testTranslogRecoveryWorksWithIMC() throws IOException {\n-        createIndex(\"test\");\n-        ensureGreen();\n-        IndicesService indicesService = getInstanceFromNode(IndicesService.class);\n-        IndexService indexService = indicesService.indexService(resolveIndex(\"test\"));\n-        IndexShard shard = indexService.getShardOrNull(0);\n+    // #10312\n+    public void testDeletesAloneCanTriggerRefresh() throws Exception {\n+        IndexService indexService = createIndex(\"index\", Settings.builder().put(\"index.number_of_shards\", 1)\n+            .put(\"index.number_of_replicas\", 0).put(\"index.refresh_interval\", -1).build());\n+        IndexShard shard = indexService.getShard(0);\n         for (int i = 0; i < 100; i++) {\n-            client().prepareIndex(\"test\").setId(Integer.toString(i)).setSource(\"{\\\"foo\\\" : \\\"bar\\\"}\", XContentType.JSON).get();\n+            client().prepareIndex(\"index\").setId(Integer.toString(i)).setSource(\"field\", \"value\").get();\n         }\n-\n-        CheckedFunction<DirectoryReader, DirectoryReader, IOException> wrapper = directoryReader -> directoryReader;\n-        shard.close(\"simon says\", false);\n-        AtomicReference<IndexShard> shardRef = new AtomicReference<>();\n-        Settings settings = Settings.builder().put(\"indices.memory.index_buffer_size\", \"50kb\").build();\n-        Iterable<IndexShard> iterable = () -> (shardRef.get() == null) ? Collections.<IndexShard>emptyList().iterator()\n-            : Collections.singleton(shardRef.get()).iterator();\n-        AtomicInteger flushes = new AtomicInteger();\n-        IndexingMemoryController imc = new IndexingMemoryController(settings, client().threadPool(), iterable) {\n-            @Override\n-            protected void writeIndexingBufferAsync(IndexShard shard) {\n-                assertEquals(shard, shardRef.get());\n-                flushes.incrementAndGet();\n-                shard.writeIndexingBuffer();\n-            }\n-        };\n-        final IndexShard newShard = IndexShardIT.newIndexShard(indexService, shard, wrapper, new NoneCircuitBreakerService(), imc);\n-        shardRef.set(newShard);\n-        try {\n-            assertEquals(0, imc.availableShards().size());\n-            ShardRouting routing = newShard.routingEntry();\n-            DiscoveryNode localNode = new DiscoveryNode(\"foo\", buildNewFakeTransportAddress(), emptyMap(), emptySet(), Version.CURRENT);\n-            newShard.markAsRecovering(\"store\", new RecoveryState(routing, localNode, null));\n-\n-            assertEquals(1, imc.availableShards().size());\n-            assertTrue(IndexShardTestCase.recoverFromStore(newShard));\n-            assertTrue(\"we should have flushed in IMC at least once but did: \" + flushes.get(), flushes.get() >= 1);\n-            IndexShardTestCase.updateRoutingEntry(newShard, routing.moveToStarted());\n-        } finally {\n-            newShard.close(\"simon says\", false);\n+        // Force merge so we know all merges are done before we start deleting:\n+        ForceMergeResponse r = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet();\n+        assertNoFailures(r);\n+        final RefreshStats refreshStats = shard.refreshStats();\n+        for (int i = 0; i < 100; i++) {\n+            client().prepareDelete(\"index\", Integer.toString(i)).get();\n         }\n+        // need to assert busily as IndexingMemoryController refreshes in background\n+        assertBusy(() -> assertThat(shard.refreshStats().getTotal(), greaterThan(refreshStats.getTotal() + 1)));\n     }\n-\n }\n"}}, {"oid": "747551513e5712883168a48d4916d2ec6e4202e7", "url": "https://github.com/elastic/elasticsearch/commit/747551513e5712883168a48d4916d2ec6e4202e7", "message": "ensure refresh threadpool stats exist", "committedDate": "2020-01-09T13:52:11Z", "type": "commit"}, {"oid": "4d04e97c214626fd184de151d6fe36949e0267cb", "url": "https://github.com/elastic/elasticsearch/commit/4d04e97c214626fd184de151d6fe36949e0267cb", "message": "arrange tests", "committedDate": "2020-01-09T17:58:04Z", "type": "commit"}]}