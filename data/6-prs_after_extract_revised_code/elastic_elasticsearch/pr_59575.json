{"pr_number": 59575, "pr_title": "Remove unneeded rest params from Data Stream Stats", "pr_createdAt": "2020-07-14T21:56:57Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/59575", "timeline": [{"oid": "975c8da5b4d14374a9f8e4be26305abb70759684", "url": "https://github.com/elastic/elasticsearch/commit/975c8da5b4d14374a9f8e4be26305abb70759684", "message": "Remove unused indices options from data streams stats rest request", "committedDate": "2020-07-14T20:59:48Z", "type": "commit"}, {"oid": "f6b489cc170e3302937fd0d4a7e6a58b19a72e0c", "url": "https://github.com/elastic/elasticsearch/commit/f6b489cc170e3302937fd0d4a7e6a58b19a72e0c", "message": "Add a quick test to ensure closed indices do not impact stats", "committedDate": "2020-07-14T21:53:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MTYyNw==", "url": "https://github.com/elastic/elasticsearch/pull/59575#discussion_r454671627", "bodyText": "Out of curiosity, since we're trying to get stats from closed indices, should we have a disclaimer that the stats (like max timestamp for instance) could be wrong if indices are closed?", "author": "dakrone", "createdAt": "2020-07-14T22:02:21Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java", "diffHunk": "@@ -76,7 +77,9 @@ public DataStreamsStatsAction() {\n \n     public static class Request extends BroadcastRequest<Request> {\n         public Request() {\n-            super((String[]) null);\n+            // this doesn't really matter since data stream name resolution isn't affected by IndicesOptions and\n+            // a data stream's backing indices are retrieved from its metadata\n+            super(null, IndicesOptions.fromOptions(false, true, true, true, false, false, true, false));", "originalCommit": "f6b489cc170e3302937fd0d4a7e6a58b19a72e0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MjU4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/59575#discussion_r454672583", "bodyText": "Probably. Not sure where best to capture that disclaimer. The docs? We'll probably want to state that anyway, since in the future we will probably only pull timestamp data from the latest index (maybe latest two indices) which could also technically lead to inaccurate timestamps.", "author": "jbaiera", "createdAt": "2020-07-14T22:04:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MTYyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3OTExMA==", "url": "https://github.com/elastic/elasticsearch/pull/59575#discussion_r454679110", "bodyText": "I think the docs is the best place for it", "author": "dakrone", "createdAt": "2020-07-14T22:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MTYyNw=="}], "type": "inlineReview", "revised_code": {"commit": "6bb5fe1e9baa0ce990f5d1d47dac286ec2afadd7", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\ndeleted file mode 100644\nindex 59e9db93251..00000000000\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n+++ /dev/null\n\n@@ -1,444 +0,0 @@\n-/*\n- * Licensed to Elasticsearch under one or more contributor\n- * license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright\n- * ownership. Elasticsearch licenses this file to you under\n- * the Apache License, Version 2.0 (the \"License\"); you may\n- * not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-package org.elasticsearch.action.admin.indices.datastream;\n-\n-import org.apache.lucene.document.LongPoint;\n-import org.apache.lucene.index.IndexReader;\n-import org.apache.lucene.index.PointValues;\n-import org.elasticsearch.action.ActionType;\n-import org.elasticsearch.action.support.ActionFilters;\n-import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n-import org.elasticsearch.action.support.IndicesOptions;\n-import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n-import org.elasticsearch.action.support.broadcast.BroadcastResponse;\n-import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n-import org.elasticsearch.cluster.ClusterState;\n-import org.elasticsearch.cluster.block.ClusterBlockException;\n-import org.elasticsearch.cluster.block.ClusterBlockLevel;\n-import org.elasticsearch.cluster.metadata.IndexAbstraction;\n-import org.elasticsearch.cluster.metadata.IndexAbstractionResolver;\n-import org.elasticsearch.cluster.metadata.IndexMetadata;\n-import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n-import org.elasticsearch.cluster.routing.ShardRouting;\n-import org.elasticsearch.cluster.routing.ShardsIterator;\n-import org.elasticsearch.cluster.service.ClusterService;\n-import org.elasticsearch.common.inject.Inject;\n-import org.elasticsearch.common.io.stream.StreamInput;\n-import org.elasticsearch.common.io.stream.StreamOutput;\n-import org.elasticsearch.common.io.stream.Writeable;\n-import org.elasticsearch.common.unit.ByteSizeValue;\n-import org.elasticsearch.common.xcontent.ToXContentObject;\n-import org.elasticsearch.common.xcontent.XContentBuilder;\n-import org.elasticsearch.index.IndexService;\n-import org.elasticsearch.index.engine.Engine;\n-import org.elasticsearch.index.shard.IndexShard;\n-import org.elasticsearch.index.shard.ShardNotFoundException;\n-import org.elasticsearch.index.store.StoreStats;\n-import org.elasticsearch.indices.IndicesService;\n-import org.elasticsearch.threadpool.ThreadPool;\n-import org.elasticsearch.transport.TransportService;\n-\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Objects;\n-import java.util.Set;\n-import java.util.SortedMap;\n-import java.util.stream.Stream;\n-\n-public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Response> {\n-\n-    public static final DataStreamsStatsAction INSTANCE = new DataStreamsStatsAction();\n-    public static final String NAME = \"indices:monitor/data_stream/stats\";\n-\n-    public DataStreamsStatsAction() {\n-        super(NAME, DataStreamsStatsAction.Response::new);\n-    }\n-\n-    public static class Request extends BroadcastRequest<Request> {\n-        public Request() {\n-            // this doesn't really matter since data stream name resolution isn't affected by IndicesOptions and\n-            // a data stream's backing indices are retrieved from its metadata\n-            super(null, IndicesOptions.fromOptions(false, true, true, true, false, false, true, false));\n-        }\n-\n-        public Request(StreamInput in) throws IOException {\n-            super(in);\n-        }\n-    }\n-\n-    public static class Response extends BroadcastResponse {\n-        private final int dataStreamCount;\n-        private final int backingIndices;\n-        private final ByteSizeValue totalStoreSize;\n-        private final DataStreamStats[] dataStreams;\n-\n-        public Response(int totalShards, int successfulShards, int failedShards, List<DefaultShardOperationFailedException> shardFailures,\n-                        int dataStreamCount, int backingIndices, ByteSizeValue totalStoreSize, DataStreamStats[] dataStreams) {\n-            super(totalShards, successfulShards, failedShards, shardFailures);\n-            this.dataStreamCount = dataStreamCount;\n-            this.backingIndices = backingIndices;\n-            this.totalStoreSize = totalStoreSize;\n-            this.dataStreams = dataStreams;\n-        }\n-\n-        public Response(StreamInput in) throws IOException {\n-            super(in);\n-            this.dataStreamCount = in.readVInt();\n-            this.backingIndices = in.readVInt();\n-            this.totalStoreSize = new ByteSizeValue(in);\n-            this.dataStreams = in.readArray(DataStreamStats::new, DataStreamStats[]::new);\n-        }\n-\n-        @Override\n-        public void writeTo(StreamOutput out) throws IOException {\n-            super.writeTo(out);\n-            out.writeVInt(dataStreamCount);\n-            out.writeVInt(backingIndices);\n-            totalStoreSize.writeTo(out);\n-            out.writeArray(dataStreams);\n-        }\n-\n-        @Override\n-        protected void addCustomXContentFields(XContentBuilder builder, Params params) throws IOException {\n-            builder.field(\"data_stream_count\", dataStreamCount);\n-            builder.field(\"backing_indices\", backingIndices);\n-            builder.humanReadableField(\"total_store_size_bytes\", \"total_store_size\", totalStoreSize);\n-            builder.array(\"data_streams\", (Object[]) dataStreams);\n-        }\n-\n-        public int getDataStreamCount() {\n-            return dataStreamCount;\n-        }\n-\n-        public int getBackingIndices() {\n-            return backingIndices;\n-        }\n-\n-        public ByteSizeValue getTotalStoreSize() {\n-            return totalStoreSize;\n-        }\n-\n-        public DataStreamStats[] getDataStreams() {\n-            return dataStreams;\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (this == obj) {\n-                return true;\n-            }\n-            if (obj == null || getClass() != obj.getClass()) {\n-                return false;\n-            }\n-            Response response = (Response) obj;\n-            return dataStreamCount == response.dataStreamCount &&\n-                backingIndices == response.backingIndices &&\n-                Objects.equals(totalStoreSize, response.totalStoreSize) &&\n-                Arrays.equals(dataStreams, response.dataStreams);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            int result = Objects.hash(dataStreamCount, backingIndices, totalStoreSize);\n-            result = 31 * result + Arrays.hashCode(dataStreams);\n-            return result;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"Response{\" +\n-                \"dataStreamCount=\" + dataStreamCount +\n-                \", backingIndices=\" + backingIndices +\n-                \", totalStoreSize=\" + totalStoreSize +\n-                \", dataStreams=\" + Arrays.toString(dataStreams) +\n-                '}';\n-        }\n-    }\n-\n-    public static class DataStreamStats implements ToXContentObject, Writeable {\n-        private final String dataStream;\n-        private final int backingIndices;\n-        private final ByteSizeValue storeSize;\n-        private final long maximumTimestamp;\n-\n-        public DataStreamStats(String dataStream, int backingIndices, ByteSizeValue storeSize, long maximumTimestamp) {\n-            this.dataStream = dataStream;\n-            this.backingIndices = backingIndices;\n-            this.storeSize = storeSize;\n-            this.maximumTimestamp = maximumTimestamp;\n-        }\n-\n-        public DataStreamStats(StreamInput in) throws IOException {\n-            this.dataStream = in.readString();\n-            this.backingIndices = in.readVInt();\n-            this.storeSize = new ByteSizeValue(in);\n-            this.maximumTimestamp = in.readVLong();\n-        }\n-\n-        @Override\n-        public void writeTo(StreamOutput out) throws IOException {\n-            out.writeString(dataStream);\n-            out.writeVInt(backingIndices);\n-            storeSize.writeTo(out);\n-            out.writeVLong(maximumTimestamp);\n-        }\n-\n-        @Override\n-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n-            builder.startObject();\n-            builder.field(\"data_stream\", dataStream);\n-            builder.field(\"backing_indices\", backingIndices);\n-            builder.humanReadableField(\"store_size_bytes\", \"store_size\", storeSize);\n-            builder.field(\"maximum_timestamp\", maximumTimestamp);\n-            builder.endObject();\n-            return builder;\n-        }\n-\n-        public String getDataStream() {\n-            return dataStream;\n-        }\n-\n-        public int getBackingIndices() {\n-            return backingIndices;\n-        }\n-\n-        public ByteSizeValue getStoreSize() {\n-            return storeSize;\n-        }\n-\n-        public long getMaximumTimestamp() {\n-            return maximumTimestamp;\n-        }\n-\n-        @Override\n-        public boolean equals(Object obj) {\n-            if (this == obj) {\n-                return true;\n-            }\n-            if (obj == null || getClass() != obj.getClass()) {\n-                return false;\n-            }\n-            DataStreamStats that = (DataStreamStats) obj;\n-            return backingIndices == that.backingIndices &&\n-                maximumTimestamp == that.maximumTimestamp &&\n-                Objects.equals(dataStream, that.dataStream) &&\n-                Objects.equals(storeSize, that.storeSize);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return Objects.hash(dataStream, backingIndices, storeSize, maximumTimestamp);\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"DataStreamStats{\" +\n-                \"dataStream='\" + dataStream + '\\'' +\n-                \", backingIndices=\" + backingIndices +\n-                \", storeSize=\" + storeSize +\n-                \", maximumTimestamp=\" + maximumTimestamp +\n-                '}';\n-        }\n-    }\n-\n-    public static class DataStreamShardStats implements Writeable {\n-        private final ShardRouting shardRouting;\n-        private final StoreStats storeStats;\n-        private final long maxTimestamp;\n-\n-        public DataStreamShardStats(ShardRouting shardRouting, StoreStats storeStats, long maxTimestamp) {\n-            this.shardRouting = shardRouting;\n-            this.storeStats = storeStats;\n-            this.maxTimestamp = maxTimestamp;\n-        }\n-\n-        public DataStreamShardStats(StreamInput in) throws IOException {\n-            this.shardRouting = new ShardRouting(in);\n-            this.storeStats = new StoreStats(in);\n-            this.maxTimestamp = in.readVLong();\n-        }\n-\n-        @Override\n-        public void writeTo(StreamOutput out) throws IOException {\n-            shardRouting.writeTo(out);\n-            storeStats.writeTo(out);\n-            out.writeVLong(maxTimestamp);\n-        }\n-\n-        public ShardRouting getShardRouting() {\n-            return shardRouting;\n-        }\n-\n-        public StoreStats getStoreStats() {\n-            return storeStats;\n-        }\n-\n-        public long getMaxTimestamp() {\n-            return maxTimestamp;\n-        }\n-    }\n-\n-    private static class AggregatedStats {\n-        Set<String> backingIndices = new HashSet<>();\n-        long storageBytes = 0L;\n-        long maxTimestamp = 0L;\n-    }\n-\n-    public static class TransportAction extends TransportBroadcastByNodeAction<Request, Response, DataStreamShardStats> {\n-\n-        private final ClusterService clusterService;\n-        private final IndicesService indicesService;\n-        private final IndexAbstractionResolver indexAbstractionResolver;\n-\n-        @Inject\n-        public TransportAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n-                                               ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n-            super(DataStreamsStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n-                Request::new, ThreadPool.Names.MANAGEMENT);\n-            this.clusterService = clusterService;\n-            this.indicesService = indicesService;\n-            this.indexAbstractionResolver = new IndexAbstractionResolver(indexNameExpressionResolver);\n-        }\n-\n-        @Override\n-        protected Request readRequestFrom(StreamInput in) throws IOException {\n-            return new Request(in);\n-        }\n-\n-        @Override\n-        protected ClusterBlockException checkGlobalBlock(ClusterState state, Request request) {\n-            return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n-        }\n-\n-        @Override\n-        protected ClusterBlockException checkRequestBlock(ClusterState state, Request request, String[] concreteIndices) {\n-            return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n-        }\n-\n-        @Override\n-        protected ShardsIterator shards(ClusterState clusterState, Request request, String[] concreteIndices) {\n-            String[] requestIndices = request.indices();\n-            if (requestIndices == null || requestIndices.length == 0) {\n-                requestIndices = new String[]{\"*\"};\n-            }\n-            List<String> abstractionNames = indexAbstractionResolver.resolveIndexAbstractions(requestIndices, request.indicesOptions(),\n-                clusterState.getMetadata(), true); // Always include data streams for data streams stats api\n-            SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n-\n-            String[] concreteDatastreamIndices = abstractionNames.stream().flatMap(abstractionName -> {\n-                IndexAbstraction indexAbstraction = indicesLookup.get(abstractionName);\n-                assert indexAbstraction != null;\n-                if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {\n-                    IndexAbstraction.DataStream dataStream = (IndexAbstraction.DataStream) indexAbstraction;\n-                    List<IndexMetadata> indices = dataStream.getIndices();\n-                    return indices.stream().map(idx -> idx.getIndex().getName());\n-                } else {\n-                    return Stream.empty();\n-                }\n-            }).toArray(String[]::new);\n-            return clusterState.getRoutingTable().allShards(concreteDatastreamIndices);\n-        }\n-\n-        @Override\n-        protected DataStreamShardStats shardOperation(Request request, ShardRouting shardRouting) throws IOException {\n-            IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());\n-            IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());\n-            // if we don't have the routing entry yet, we need it stats wise, we treat it as if the shard is not ready yet\n-            if (indexShard.routingEntry() == null) {\n-                throw new ShardNotFoundException(indexShard.shardId());\n-            }\n-            StoreStats storeStats = indexShard.storeStats();\n-            IndexAbstraction indexAbstraction = clusterService.state().getMetadata().getIndicesLookup().get(shardRouting.getIndexName());\n-            assert indexAbstraction != null;\n-            IndexAbstraction.DataStream dataStream = indexAbstraction.getParentDataStream();\n-            assert dataStream != null;\n-            long maxTimestamp = 0L;\n-            try (Engine.Searcher searcher = indexShard.acquireSearcher(\"data_stream_stats\")) {\n-                IndexReader indexReader = searcher.getIndexReader();\n-                String fieldName = dataStream.getDataStream().getTimeStampField().getName();\n-                byte[] maxPackedValue = PointValues.getMaxPackedValue(indexReader, fieldName);\n-                if (maxPackedValue != null) {\n-                    maxTimestamp = LongPoint.decodeDimension(maxPackedValue, 0);\n-                }\n-            }\n-            return new DataStreamShardStats(\n-                indexShard.routingEntry(),\n-                storeStats,\n-                maxTimestamp\n-            );\n-        }\n-\n-        @Override\n-        protected DataStreamShardStats readShardResult(StreamInput in) throws IOException {\n-            return new DataStreamShardStats(in);\n-        }\n-\n-        @Override\n-        protected Response newResponse(Request request, int totalShards, int successfulShards,\n-                                                       int failedShards, List<DataStreamShardStats> dataStreamShardStats,\n-                                                       List<DefaultShardOperationFailedException> shardFailures,\n-                                                       ClusterState clusterState) {\n-            Map<String, AggregatedStats> aggregatedDataStreamsStats = new HashMap<>();\n-            Set<String> allBackingIndices = new HashSet<>();\n-            long totalStoreSizeBytes = 0L;\n-\n-            SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n-            for (DataStreamShardStats shardStat : dataStreamShardStats) {\n-                String indexName = shardStat.getShardRouting().getIndexName();\n-                IndexAbstraction indexAbstraction = indicesLookup.get(indexName);\n-                IndexAbstraction.DataStream dataStream = indexAbstraction.getParentDataStream();\n-                assert dataStream != null;\n-\n-                // Aggregate global stats\n-                totalStoreSizeBytes += shardStat.getStoreStats().sizeInBytes();\n-                allBackingIndices.add(indexName);\n-\n-                // Aggregate data stream stats\n-                AggregatedStats stats = aggregatedDataStreamsStats.computeIfAbsent(dataStream.getName(), s -> new AggregatedStats());\n-                stats.storageBytes += shardStat.getStoreStats().sizeInBytes();\n-                stats.maxTimestamp = Math.max(stats.maxTimestamp, shardStat.getMaxTimestamp());\n-                stats.backingIndices.add(indexName);\n-            }\n-\n-            DataStreamStats[] dataStreamStats = aggregatedDataStreamsStats.entrySet().stream()\n-                .map(entry -> new DataStreamStats(\n-                    entry.getKey(),\n-                    entry.getValue().backingIndices.size(),\n-                    new ByteSizeValue(entry.getValue().storageBytes),\n-                    entry.getValue().maxTimestamp))\n-                .toArray(DataStreamStats[]::new);\n-\n-            return new Response(\n-                totalShards,\n-                successfulShards,\n-                failedShards,\n-                shardFailures,\n-                aggregatedDataStreamsStats.size(),\n-                allBackingIndices.size(),\n-                new ByteSizeValue(totalStoreSizeBytes),\n-                dataStreamStats\n-            );\n-        }\n-    }\n-}\n"}}, {"oid": "928cc4b34903c1986c9f4cafd447a2b098a662fa", "url": "https://github.com/elastic/elasticsearch/commit/928cc4b34903c1986c9f4cafd447a2b098a662fa", "message": "precommit", "committedDate": "2020-07-14T22:28:19Z", "type": "commit"}, {"oid": "6bb5fe1e9baa0ce990f5d1d47dac286ec2afadd7", "url": "https://github.com/elastic/elasticsearch/commit/6bb5fe1e9baa0ce990f5d1d47dac286ec2afadd7", "message": "Merge branch 'master' into data-streams-stats-options", "committedDate": "2020-07-15T15:34:19Z", "type": "commit"}]}