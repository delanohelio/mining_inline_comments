{"pr_number": 62564, "pr_title": "[ML] Handle data frame analytics state spreading over multiple docs", "pr_createdAt": "2020-09-17T16:15:07Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/62564", "timeline": [{"oid": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "url": "https://github.com/elastic/elasticsearch/commit/bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "message": "[ML] Handle data frame analytics state spreading over multiple docs\n\nWhen state persistence was first implemented for data frame analytics\nwe had the assumption that state would always fit in a single document.\nHowever this is not the case any more.\n\nThis commit adds handling of state that spreads over multiple documents.", "committedDate": "2020-09-17T16:04:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQxMzY2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490413665", "bodyText": "nit...as this is technically not a suffix any longer :D\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final String STATE_DOC_ID_SUFFIX = \"_classification_state#\";\n          \n          \n            \n                private static final String STATE_DOC_ID_INFIX = \"_classification_state#\";", "author": "benwtrent", "createdAt": "2020-09-17T16:53:00Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java", "diffHunk": "@@ -55,7 +55,7 @@\n     public static final ParseField RANDOMIZE_SEED = new ParseField(\"randomize_seed\");\n     public static final ParseField FEATURE_PROCESSORS = new ParseField(\"feature_processors\");\n \n-    private static final String STATE_DOC_ID_SUFFIX = \"_classification_state#1\";\n+    private static final String STATE_DOC_ID_SUFFIX = \"_classification_state#\";", "originalCommit": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "11150afea4c91b32647eeac127c85ff864da623d", "chunk": "diff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java\nindex 55f0605bbb6..758a9cc7ead 100644\n--- a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java\n+++ b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java\n\n@@ -55,7 +55,7 @@ public class Classification implements DataFrameAnalysis {\n     public static final ParseField RANDOMIZE_SEED = new ParseField(\"randomize_seed\");\n     public static final ParseField FEATURE_PROCESSORS = new ParseField(\"feature_processors\");\n \n-    private static final String STATE_DOC_ID_SUFFIX = \"_classification_state#\";\n+    private static final String STATE_DOC_ID_INFIX = \"_classification_state#\";\n \n     private static final String NUM_CLASSES = \"num_classes\";\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQxMzg3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490413879", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final String STATE_DOC_ID_SUFFIX = \"_regression_state#\";\n          \n          \n            \n                private static final String STATE_DOC_ID_INFIX = \"_regression_state#\";", "author": "benwtrent", "createdAt": "2020-09-17T16:53:21Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java", "diffHunk": "@@ -51,7 +51,7 @@\n     public static final ParseField LOSS_FUNCTION_PARAMETER = new ParseField(\"loss_function_parameter\");\n     public static final ParseField FEATURE_PROCESSORS = new ParseField(\"feature_processors\");\n \n-    private static final String STATE_DOC_ID_SUFFIX = \"_regression_state#1\";\n+    private static final String STATE_DOC_ID_SUFFIX = \"_regression_state#\";", "originalCommit": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ea697fb8713f44de7e70be40aa0f0e6960f0b851", "chunk": "diff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java\nindex c29ef23a3f9..b6d0d6df115 100644\n--- a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java\n+++ b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java\n\n@@ -51,7 +51,7 @@ public class Regression implements DataFrameAnalysis {\n     public static final ParseField LOSS_FUNCTION_PARAMETER = new ParseField(\"loss_function_parameter\");\n     public static final ParseField FEATURE_PROCESSORS = new ParseField(\"feature_processors\");\n \n-    private static final String STATE_DOC_ID_SUFFIX = \"_regression_state#\";\n+    private static final String STATE_DOC_ID_INFIX = \"_regression_state#\";\n \n     private static final ConstructingObjectParser<Regression, Void> LENIENT_PARSER = createParser(true);\n     private static final ConstructingObjectParser<Regression, Void> STRICT_PARSER = createParser(false);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcyOTMzMA==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490729330", "bodyText": "Is this recursion needed? Would it be possible to delete all the #1, #2, etc. in one deleteByQuery request?\nI know we don't know the number of state docs in advance, but maybe we could apply some id pattern?", "author": "przemekwitek", "createdAt": "2020-09-18T06:29:08Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteDataFrameAnalyticsAction.java", "diffHunk": "@@ -242,17 +241,46 @@ private void deleteState(ParentTaskAssigningClient parentTaskClient,\n                              DataFrameAnalyticsConfig config,\n                              TimeValue timeout,\n                              ActionListener<BulkByScrollResponse> listener) {\n-        List<String> ids = new ArrayList<>();\n-        ids.add(StoredProgress.documentId(config.getId()));\n-        if (config.getAnalysis().persistsState()) {\n-            ids.add(config.getAnalysis().getStateDocId(config.getId()));\n+        ActionListener<Boolean> deleteModelStateListener = ActionListener.wrap(\n+            r -> executeDeleteByQuery(\n+                    parentTaskClient,\n+                    AnomalyDetectorsIndex.jobStateIndexPattern(),\n+                    QueryBuilders.idsQuery().addIds(StoredProgress.documentId(config.getId())),\n+                    timeout,\n+                    listener\n+                )\n+            , listener::onFailure\n+        );\n+\n+        deleteModelState(parentTaskClient, config, timeout, 1, deleteModelStateListener);\n+    }\n+\n+    private void deleteModelState(ParentTaskAssigningClient parentTaskClient,\n+                                  DataFrameAnalyticsConfig config,\n+                                  TimeValue timeout,\n+                                  int docNum,\n+                                  ActionListener<Boolean> listener) {\n+        if (config.getAnalysis().persistsState() == false) {\n+            listener.onResponse(true);\n+            return;\n         }\n+\n+        IdsQueryBuilder query = QueryBuilders.idsQuery().addIds(config.getAnalysis().getStateDocIdPrefix(config.getId()) + docNum);\n         executeDeleteByQuery(\n             parentTaskClient,\n             AnomalyDetectorsIndex.jobStateIndexPattern(),\n-            QueryBuilders.idsQuery().addIds(ids.toArray(String[]::new)),\n+            query,\n             timeout,\n-            listener\n+            ActionListener.wrap(\n+                response -> {\n+                    if (response.getDeleted() > 0) {\n+                        deleteModelState(parentTaskClient, config, timeout, docNum + 1, listener);", "originalCommit": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgyMzM4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490823386", "bodyText": "Unfortunately can't have a pattern query for ids.\nNote, however, this is not a real recursion. As the client call is async, each deleteModelState call completes immediately. We then make the new call when we get a response from the client.", "author": "dimitris-athanasiou", "createdAt": "2020-09-18T09:33:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcyOTMzMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcyOTgyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490729825", "bodyText": "Does UnusedStateRemover class need to be changed too?", "author": "przemekwitek", "createdAt": "2020-09-18T06:30:21Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportDeleteDataFrameAnalyticsAction.java", "diffHunk": "@@ -242,17 +241,46 @@ private void deleteState(ParentTaskAssigningClient parentTaskClient,\n                              DataFrameAnalyticsConfig config,\n                              TimeValue timeout,\n                              ActionListener<BulkByScrollResponse> listener) {\n-        List<String> ids = new ArrayList<>();\n-        ids.add(StoredProgress.documentId(config.getId()));\n-        if (config.getAnalysis().persistsState()) {\n-            ids.add(config.getAnalysis().getStateDocId(config.getId()));\n+        ActionListener<Boolean> deleteModelStateListener = ActionListener.wrap(", "originalCommit": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjcxNDY4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r492714687", "bodyText": "No because the corresponding job id extractors (see Classification.extractJobIdFromStateDoc and Regression.extractJobIdFromStateDoc) successfully extract the job id regardless of the document number that follows the infix.", "author": "dimitris-athanasiou", "createdAt": "2020-09-22T13:02:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcyOTgyNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDczMTYxMw==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490731613", "bodyText": "This comment is somewhat related to the one about using recursion. Could we fetch all the state docs at once using some pattern-matched query?\nIf not, and if\nwe expect  many state docs to exist, we could try to fetch them in batches (by adding ids #1, #2, ..., #10 to one ids query) to reduce the number of queries.\nPlease disregard the above if we expect the number of docs to be small so there is no need for premature optimization.", "author": "przemekwitek", "createdAt": "2020-09-18T06:35:02Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/NativeAnalyticsProcess.java", "diffHunk": "@@ -56,10 +59,23 @@ public AnalyticsProcessConfig getConfig() {\n     }\n \n     @Override\n-    public void restoreState(BytesReference state) throws IOException {\n-        Objects.requireNonNull(state);\n+    public void restoreState(Client client, String stateDocIdPrefix) throws IOException {\n+        Objects.requireNonNull(stateDocIdPrefix);\n         try (OutputStream restoreStream = processRestoreStream()) {\n-            StateToProcessWriterHelper.writeStateToStream(state, restoreStream);\n+            int docNum = 0;\n+            while (true) {\n+                if (isProcessKilled()) {\n+                    return;\n+                }\n+\n+                SearchResponse stateResponse = client.prepareSearch(AnomalyDetectorsIndex.jobStateIndexPattern())\n+                    .setSize(1)\n+                    .setQuery(QueryBuilders.idsQuery().addIds(stateDocIdPrefix + ++docNum)).get();", "originalCommit": "bcdb6b5d76a0e7918997bfa5e6afac9f96071e86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgxNDQ3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490814472", "bodyText": "Could we fetch all the state docs at once using some pattern-matched query?\n\nWe deliberately fetch one at a time because if there is more than one then all but the last will be quite big (~16MB in size).  The reason why we split the state over multiple documents is to avoid using all the JVM heap with a massive model state that we have to hold in memory in its entirety.\nThere should probably be a comment to say we are deliberately only bringing one document into memory at a time because they are big.", "author": "droberts195", "createdAt": "2020-09-18T09:16:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDczMTYxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgzMDU3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/62564#discussion_r490830577", "bodyText": "The reason why we split the state over multiple documents is to avoid using all the JVM heap with a massive model state that we have to hold in memory in its entirety.\n\nGreat, thanks for explaining that!", "author": "przemekwitek", "createdAt": "2020-09-18T09:43:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDczMTYxMw=="}], "type": "inlineReview", "revised_code": {"commit": "888a6e7468dfe48f4006ffefb5fa96d197e5852f", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/NativeAnalyticsProcess.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/NativeAnalyticsProcess.java\nindex 7e361c614dd..8f35dfaf3e4 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/NativeAnalyticsProcess.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/NativeAnalyticsProcess.java\n\n@@ -68,13 +74,16 @@ public class NativeAnalyticsProcess extends AbstractNativeAnalyticsProcess<Analy\n                     return;\n                 }\n \n+                // We fetch the documents one at a time because all together they can amount to too much memory\n                 SearchResponse stateResponse = client.prepareSearch(AnomalyDetectorsIndex.jobStateIndexPattern())\n                     .setSize(1)\n                     .setQuery(QueryBuilders.idsQuery().addIds(stateDocIdPrefix + ++docNum)).get();\n                 if (stateResponse.getHits().getHits().length == 0) {\n                     break;\n                 }\n-                StateToProcessWriterHelper.writeStateToStream(stateResponse.getHits().getAt(0).getSourceRef(), restoreStream);\n+                SearchHit stateDoc = stateResponse.getHits().getAt(0);\n+                logger.debug(() -> new ParameterizedMessage(\"[{}] Restoring state document [{}]\", config.jobId(), stateDoc.getId()));\n+                StateToProcessWriterHelper.writeStateToStream(stateDoc.getSourceRef(), restoreStream);\n             }\n         }\n     }\n"}}, {"oid": "11150afea4c91b32647eeac127c85ff864da623d", "url": "https://github.com/elastic/elasticsearch/commit/11150afea4c91b32647eeac127c85ff864da623d", "message": "Update x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Classification.java\n\nCo-authored-by: Benjamin Trent <ben.w.trent@gmail.com>", "committedDate": "2020-09-22T13:00:46Z", "type": "commit"}, {"oid": "ea697fb8713f44de7e70be40aa0f0e6960f0b851", "url": "https://github.com/elastic/elasticsearch/commit/ea697fb8713f44de7e70be40aa0f0e6960f0b851", "message": "Update x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java\n\nCo-authored-by: Benjamin Trent <ben.w.trent@gmail.com>", "committedDate": "2020-09-22T13:00:54Z", "type": "commit"}, {"oid": "888a6e7468dfe48f4006ffefb5fa96d197e5852f", "url": "https://github.com/elastic/elasticsearch/commit/888a6e7468dfe48f4006ffefb5fa96d197e5852f", "message": "Add comment and useful debug statement", "committedDate": "2020-09-22T13:34:38Z", "type": "commit"}, {"oid": "97ac021262151d54d886ead3a4df718eaad99ac3", "url": "https://github.com/elastic/elasticsearch/commit/97ac021262151d54d886ead3a4df718eaad99ac3", "message": "Merge branch 'master' into handle-dfa-state-spreading-multiple-docs", "committedDate": "2020-09-22T13:35:01Z", "type": "commit"}, {"oid": "cb4af575b36c28d5ff30be6803bb1ab8acdc3205", "url": "https://github.com/elastic/elasticsearch/commit/cb4af575b36c28d5ff30be6803bb1ab8acdc3205", "message": "Fix compile errors", "committedDate": "2020-09-22T13:52:57Z", "type": "commit"}, {"oid": "a7b8a0f67223f4e98f92d27165b881090f44a4a5", "url": "https://github.com/elastic/elasticsearch/commit/a7b8a0f67223f4e98f92d27165b881090f44a4a5", "message": "Merge branch 'master' into handle-dfa-state-spreading-multiple-docs", "committedDate": "2020-09-23T06:58:30Z", "type": "commit"}]}