{"pr_number": 55274, "pr_title": "Reestablish peer recovery after network errors", "pr_createdAt": "2020-04-16T00:06:06Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55274", "timeline": [{"oid": "53cbbdc8ba0c6627261d3f3acabf34b1230adc28", "url": "https://github.com/elastic/elasticsearch/commit/53cbbdc8ba0c6627261d3f3acabf34b1230adc28", "message": "WIP", "committedDate": "2020-04-03T23:13:51Z", "type": "commit"}, {"oid": "395b1cfb299cdeebdfedbd2271bfd999cdd8d55f", "url": "https://github.com/elastic/elasticsearch/commit/395b1cfb299cdeebdfedbd2271bfd999cdd8d55f", "message": "Changes", "committedDate": "2020-04-04T00:19:09Z", "type": "commit"}, {"oid": "1c4b04f0368823e7c6fe699bd875ac93dbb4fe22", "url": "https://github.com/elastic/elasticsearch/commit/1c4b04f0368823e7c6fe699bd875ac93dbb4fe22", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-06T16:05:58Z", "type": "commit"}, {"oid": "2891cde4c70445d795a7e59ce3dedcea8fb3e2d1", "url": "https://github.com/elastic/elasticsearch/commit/2891cde4c70445d795a7e59ce3dedcea8fb3e2d1", "message": "Catch exceptions", "committedDate": "2020-04-06T16:59:56Z", "type": "commit"}, {"oid": "7d24bc32ad783a7bd605ed5e4d2b716ea4d89809", "url": "https://github.com/elastic/elasticsearch/commit/7d24bc32ad783a7bd605ed5e4d2b716ea4d89809", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-06T23:24:45Z", "type": "commit"}, {"oid": "62910c7820bca21589ba14bac35880eeaaeb31d9", "url": "https://github.com/elastic/elasticsearch/commit/62910c7820bca21589ba14bac35880eeaaeb31d9", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-09T20:09:45Z", "type": "commit"}, {"oid": "249c2106eaffad450a80880aff82c499f478437d", "url": "https://github.com/elastic/elasticsearch/commit/249c2106eaffad450a80880aff82c499f478437d", "message": "Changes", "committedDate": "2020-04-09T21:04:32Z", "type": "commit"}, {"oid": "8e429af0c5f525e1b0d116b40529ced1a0bfb86c", "url": "https://github.com/elastic/elasticsearch/commit/8e429af0c5f525e1b0d116b40529ced1a0bfb86c", "message": "Work on test", "committedDate": "2020-04-10T00:08:56Z", "type": "commit"}, {"oid": "4d67ad64d91273800bc2f933df3cd8d191bf6df0", "url": "https://github.com/elastic/elasticsearch/commit/4d67ad64d91273800bc2f933df3cd8d191bf6df0", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-10T00:42:01Z", "type": "commit"}, {"oid": "f36b94dd42e88bb353d8e5eb1125267830a9865c", "url": "https://github.com/elastic/elasticsearch/commit/f36b94dd42e88bb353d8e5eb1125267830a9865c", "message": "Changes", "committedDate": "2020-04-10T15:59:59Z", "type": "commit"}, {"oid": "5b6d2c597828b81e7448d5c239d09500ca445288", "url": "https://github.com/elastic/elasticsearch/commit/5b6d2c597828b81e7448d5c239d09500ca445288", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-14T17:54:53Z", "type": "commit"}, {"oid": "aa04ad03ead314d738e99d87834b6bb02f62cb6e", "url": "https://github.com/elastic/elasticsearch/commit/aa04ad03ead314d738e99d87834b6bb02f62cb6e", "message": "Changes", "committedDate": "2020-04-14T22:49:52Z", "type": "commit"}, {"oid": "3e494c249819e15767fd355fbc64cd61382d04ae", "url": "https://github.com/elastic/elasticsearch/commit/3e494c249819e15767fd355fbc64cd61382d04ae", "message": "Fix", "committedDate": "2020-04-14T23:12:01Z", "type": "commit"}, {"oid": "e21f650dc6d7048d7d639fa4dc268c179f143d76", "url": "https://github.com/elastic/elasticsearch/commit/e21f650dc6d7048d7d639fa4dc268c179f143d76", "message": "Idempotency", "committedDate": "2020-04-15T21:06:46Z", "type": "commit"}, {"oid": "65af4bcaf57e769d8821d53f233778c24174c69a", "url": "https://github.com/elastic/elasticsearch/commit/65af4bcaf57e769d8821d53f233778c24174c69a", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures", "committedDate": "2020-04-15T21:17:16Z", "type": "commit"}, {"oid": "1697e99a83cf20374443f16882125fcb46fccd74", "url": "https://github.com/elastic/elasticsearch/commit/1697e99a83cf20374443f16882125fcb46fccd74", "message": "Reestablish", "committedDate": "2020-04-16T00:02:23Z", "type": "commit"}, {"oid": "a2c568f8d7ef531a651877809608c9ae686964ef", "url": "https://github.com/elastic/elasticsearch/commit/a2c568f8d7ef531a651877809608c9ae686964ef", "message": "Version check", "committedDate": "2020-04-16T00:07:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ3OTI0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r409479247", "bodyText": "Should we guard against empty onGoingRetryableActions here before forking off?", "author": "original-brownbear", "createdAt": "2020-04-16T11:20:51Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java", "diffHunk": "@@ -174,15 +217,67 @@ public void writeFileChunk(StoreFileMetadata fileMetadata, long position, BytesR\n             throttleTimeInNanos = 0;\n         }\n \n-        transportService.sendRequest(targetNode, PeerRecoveryTargetService.Actions.FILE_CHUNK,\n-            new RecoveryFileChunkRequest(recoveryId, shardId, fileMetadata, position, content, lastChunk,\n-                totalTranslogOps,\n+        final long requestSeqNo = requestSeqNoGenerator.getAndIncrement();\n+        final TimeValue initialDelay = TimeValue.timeValueMillis(50);\n+        final TimeValue timeout = fileChunkRequestOptions.timeout();\n+        final Object key = new Object();\n+        final ActionListener<Void> removeListener = ActionListener.runBefore(listener, () -> onGoingRetryableActions.remove(key));\n+        final RetryableAction<Void> fileChunkAction = new RetryableAction<>(logger, threadPool, initialDelay, timeout, removeListener) {\n+\n+            @Override\n+            public void tryAction(ActionListener<Void> listener) {\n                 /* we send estimateTotalOperations with every request since we collect stats on the target and that way we can\n                  * see how many translog ops we accumulate while copying files across the network. A future optimization\n                  * would be in to restart file copy again (new deltas) if we have too many translog ops are piling up.\n                  */\n-                throttleTimeInNanos), fileChunkRequestOptions, new ActionListenerResponseHandler<>(\n-                    ActionListener.map(listener, r -> null), in -> TransportResponse.Empty.INSTANCE, ThreadPool.Names.GENERIC));\n+                final RecoveryFileChunkRequest request = new RecoveryFileChunkRequest(recoveryId, requestSeqNo, shardId, fileMetadata,\n+                    position, content, lastChunk, totalTranslogOps, throttleTimeInNanos);\n+                transportService.sendRequest(targetNode, PeerRecoveryTargetService.Actions.FILE_CHUNK,\n+                    request, fileChunkRequestOptions, new ActionListenerResponseHandler<>(\n+                        ActionListener.map(listener, r -> null), in -> TransportResponse.Empty.INSTANCE, ThreadPool.Names.GENERIC));\n+            }\n+\n+            @Override\n+            public boolean shouldRetry(Exception e) {\n+                return retriesSupported && retryableException(e);\n+            }\n+        };\n+\n+        startRetryableAction(key, fileChunkAction);\n+    }\n+\n+    @Override\n+    public void cancel() {\n+        isCancelled = true;\n+        final RuntimeException exception = new CancellableThreads.ExecutionCancelledException(\"recovery was cancelled\");\n+        // Dispatch to generic as cancellation calls can come on the cluster state applier thread\n+        threadPool.generic().execute(() -> {", "originalCommit": "a2c568f8d7ef531a651877809608c9ae686964ef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "269739d1a5240f2ae3478c7ce946f574f507fdb2", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java b/server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java\nindex 39b67217b45..293c8abd0ea 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RemoteRecoveryTargetHandler.java\n\n@@ -217,53 +212,57 @@ public class RemoteRecoveryTargetHandler implements RecoveryTargetHandler {\n             throttleTimeInNanos = 0;\n         }\n \n-        final long requestSeqNo = requestSeqNoGenerator.getAndIncrement();\n-        final TimeValue initialDelay = TimeValue.timeValueMillis(50);\n-        final TimeValue timeout = fileChunkRequestOptions.timeout();\n-        final Object key = new Object();\n-        final ActionListener<Void> removeListener = ActionListener.runBefore(listener, () -> onGoingRetryableActions.remove(key));\n-        final RetryableAction<Void> fileChunkAction = new RetryableAction<>(logger, threadPool, initialDelay, timeout, removeListener) {\n-\n-            @Override\n-            public void tryAction(ActionListener<Void> listener) {\n-                /* we send estimateTotalOperations with every request since we collect stats on the target and that way we can\n-                 * see how many translog ops we accumulate while copying files across the network. A future optimization\n-                 * would be in to restart file copy again (new deltas) if we have too many translog ops are piling up.\n-                 */\n-                final RecoveryFileChunkRequest request = new RecoveryFileChunkRequest(recoveryId, requestSeqNo, shardId, fileMetadata,\n-                    position, content, lastChunk, totalTranslogOps, throttleTimeInNanos);\n-                transportService.sendRequest(targetNode, PeerRecoveryTargetService.Actions.FILE_CHUNK,\n-                    request, fileChunkRequestOptions, new ActionListenerResponseHandler<>(\n-                        ActionListener.map(listener, r -> null), in -> TransportResponse.Empty.INSTANCE, ThreadPool.Names.GENERIC));\n-            }\n-\n-            @Override\n-            public boolean shouldRetry(Exception e) {\n-                return retriesSupported && retryableException(e);\n-            }\n-        };\n-\n-        startRetryableAction(key, fileChunkAction);\n+        final String action = PeerRecoveryTargetService.Actions.FILE_CHUNK;\n+        /* we send estimateTotalOperations with every request since we collect stats on the target and that way we can\n+         * see how many translog ops we accumulate while copying files across the network. A future optimization\n+         * would be in to restart file copy again (new deltas) if we have too many translog ops are piling up.\n+         */\n+        final RecoveryFileChunkRequest request = new RecoveryFileChunkRequest(\n+            recoveryId, -1, shardId, fileMetadata, position, content, lastChunk, totalTranslogOps, throttleTimeInNanos);\n+        final Writeable.Reader<TransportResponse.Empty> reader = in -> TransportResponse.Empty.INSTANCE;\n+        executeRetryableAction(action, request, fileChunkRequestOptions, ActionListener.map(listener, r -> null), reader);\n     }\n \n     @Override\n     public void cancel() {\n         isCancelled = true;\n+        if (onGoingRetryableActions.isEmpty()) {\n+            return;\n+        }\n         final RuntimeException exception = new CancellableThreads.ExecutionCancelledException(\"recovery was cancelled\");\n         // Dispatch to generic as cancellation calls can come on the cluster state applier thread\n         threadPool.generic().execute(() -> {\n-            for (Map.Entry<Object, RetryableAction<?>> action : onGoingRetryableActions.entrySet()) {\n-                action.getValue().cancel(exception);\n+            for (RetryableAction<?> action : onGoingRetryableActions.values()) {\n+                action.cancel(exception);\n             }\n             onGoingRetryableActions.clear();\n         });\n     }\n \n-    private <T> void startRetryableAction(Object key, RetryableAction<T> action) {\n-        onGoingRetryableActions.put(key, action);\n-        action.run();\n+    private <T extends TransportResponse> void executeRetryableAction(String action, TransportRequest request,\n+                                                                      TransportRequestOptions options, ActionListener<T> actionListener,\n+                                                                      Writeable.Reader<T> reader) {\n+        final Object key = new Object();\n+        final ActionListener<T> removeListener = ActionListener.runBefore(actionListener, () -> onGoingRetryableActions.remove(key));\n+        final TimeValue initialDelay = TimeValue.timeValueMillis(200);\n+        final TimeValue timeout = recoverySettings.internalActionRetryTimeout();\n+        final RetryableAction<T> retryableAction = new RetryableAction<>(logger, threadPool, initialDelay, timeout, removeListener) {\n+\n+            @Override\n+            public void tryAction(ActionListener<T> listener) {\n+                transportService.sendRequest(targetNode, action, request, options,\n+                    new ActionListenerResponseHandler<>(listener, reader, ThreadPool.Names.GENERIC));\n+            }\n+\n+            @Override\n+            public boolean shouldRetry(Exception e) {\n+                return retriesSupported && retryableException(e);\n+            }\n+        };\n+        onGoingRetryableActions.put(key, retryableAction);\n+        retryableAction.run();\n         if (isCancelled) {\n-            action.cancel(new CancellableThreads.ExecutionCancelledException(\"recovery was cancelled\"));\n+            retryableAction.cancel(new CancellableThreads.ExecutionCancelledException(\"recovery was cancelled\"));\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ4MTEwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r409481104", "bodyText": "remote -> remove", "author": "original-brownbear", "createdAt": "2020-04-16T11:24:19Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.util.concurrent.EsExecutors;\n+import org.elasticsearch.common.util.concurrent.ListenableFuture;\n+import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;\n+\n+public class RequestTracker {\n+\n+    private final Map<Long, ListenableFuture<Void>> ongoingRequests = new HashMap<>();\n+    private final LocalCheckpointTracker checkpointTracker = new LocalCheckpointTracker(NO_OPS_PERFORMED, NO_OPS_PERFORMED);\n+\n+    public synchronized ActionListener<Void> markReceivedAndCreateListener(long requestSeqNo, ActionListener<Void> listener) {\n+        if (checkpointTracker.hasProcessed(requestSeqNo)) {\n+            final ListenableFuture<Void> existingFuture = ongoingRequests.get(requestSeqNo);\n+            if (existingFuture != null) {\n+                existingFuture.addListener(listener, EsExecutors.newDirectExecutorService());\n+            } else {\n+                listener.onResponse(null);\n+            }\n+            return null;\n+        } else {\n+            checkpointTracker.markSeqNoAsProcessed(requestSeqNo);\n+            final ListenableFuture<Void> future = new ListenableFuture<>();\n+            ongoingRequests.put(requestSeqNo, future);\n+            future.addListener(new ActionListener<>() {\n+                @Override\n+                public void onResponse(Void v) {\n+                    synchronized (RequestTracker.this) {\n+                        ongoingRequests.remove(requestSeqNo);\n+                    }\n+                    listener.onResponse(v);\n+                }\n+\n+                @Override\n+                public void onFailure(Exception e) {\n+                    // We do not remote the future to cache the error for retried requests", "originalCommit": "a2c568f8d7ef531a651877809608c9ae686964ef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0c66d760e76dd10de4bab229d153ae1c0699c7b8", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java b/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java\nindex 37e065bd84c..46c8240f003 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java\n\n@@ -58,7 +58,7 @@ public class RequestTracker {\n \n                 @Override\n                 public void onFailure(Exception e) {\n-                    // We do not remote the future to cache the error for retried requests\n+                    // We do not remove the future to cache the error for retried requests\n                     listener.onFailure(e);\n                 }\n             }, EsExecutors.newDirectExecutorService());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTExNzcwOA==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r411117708", "bodyText": "I think we really need some JavaDoc that explains the exact mechanics of this transport action.", "author": "original-brownbear", "createdAt": "2020-04-20T06:12:30Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java", "diffHunk": "@@ -75,6 +77,8 @@ public PeerRecoverySourceService(TransportService transportService, IndicesServi\n         this.recoverySettings = recoverySettings;\n         transportService.registerRequestHandler(Actions.START_RECOVERY, ThreadPool.Names.GENERIC, StartRecoveryRequest::new,\n             new StartRecoveryTransportRequestHandler());\n+        transportService.registerRequestHandler(Actions.REESTABLISH_RECOVERY, ThreadPool.Names.GENERIC, ReestablishRecoveryRequest::new,", "originalCommit": "a2c568f8d7ef531a651877809608c9ae686964ef", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "269739d1a5240f2ae3478c7ce946f574f507fdb2", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\nindex 01f742a06ee..7de0e1cb029 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\n\n@@ -70,8 +70,7 @@ public class PeerRecoverySourceService extends AbstractLifecycleComponent implem\n     final OngoingRecoveries ongoingRecoveries = new OngoingRecoveries();\n \n     @Inject\n-    public PeerRecoverySourceService(TransportService transportService, IndicesService indicesService,\n-                                     RecoverySettings recoverySettings) {\n+    public PeerRecoverySourceService(TransportService transportService, IndicesService indicesService, RecoverySettings recoverySettings) {\n         this.transportService = transportService;\n         this.indicesService = indicesService;\n         this.recoverySettings = recoverySettings;\n"}}, {"oid": "269739d1a5240f2ae3478c7ce946f574f507fdb2", "url": "https://github.com/elastic/elasticsearch/commit/269739d1a5240f2ae3478c7ce946f574f507fdb2", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures_v2", "committedDate": "2020-05-08T16:16:24Z", "type": "commit"}, {"oid": "262aba93616975ef6b71194a8339ce9e6c8e5997", "url": "https://github.com/elastic/elasticsearch/commit/262aba93616975ef6b71194a8339ce9e6c8e5997", "message": "Changes", "committedDate": "2020-05-08T16:20:52Z", "type": "commit"}, {"oid": "9f7b60fa5241e095585c73e4be37ea2023ebb47f", "url": "https://github.com/elastic/elasticsearch/commit/9f7b60fa5241e095585c73e4be37ea2023ebb47f", "message": "Chnages", "committedDate": "2020-05-08T17:43:00Z", "type": "commit"}, {"oid": "0c66d760e76dd10de4bab229d153ae1c0699c7b8", "url": "https://github.com/elastic/elasticsearch/commit/0c66d760e76dd10de4bab229d153ae1c0699c7b8", "message": "Changes", "committedDate": "2020-05-08T19:36:42Z", "type": "commit"}, {"oid": "f0aee01d629b7bfa6607dc53e850463dd4cc0887", "url": "https://github.com/elastic/elasticsearch/commit/f0aee01d629b7bfa6607dc53e850463dd4cc0887", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures_v2", "committedDate": "2020-05-11T18:47:15Z", "type": "commit"}, {"oid": "8ff3b28a72518c4e47b60bd16d55bafa3c5a51ea", "url": "https://github.com/elastic/elasticsearch/commit/8ff3b28a72518c4e47b60bd16d55bafa3c5a51ea", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures_v2", "committedDate": "2020-05-11T23:13:28Z", "type": "commit"}, {"oid": "2bebd52869a64c61e6e6f172c58fa65912369fd6", "url": "https://github.com/elastic/elasticsearch/commit/2bebd52869a64c61e6e6f172c58fa65912369fd6", "message": "Changes", "committedDate": "2020-05-11T23:50:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY3MjcwNg==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r424672706", "bodyText": "We also need to compare targetAllocationId as we can have two ongoing recoveries for the same shard with the same recoveryId from different targets.", "author": "dnhatn", "createdAt": "2020-05-13T19:15:35Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java", "diffHunk": "@@ -218,6 +255,24 @@ synchronized RecoverySourceHandler addNewRecovery(StartRecoveryRequest request,\n                 return handler;\n             }\n \n+            /**\n+             * Adds recovery source handler.\n+             */\n+            synchronized void reestablishRecovery(ReestablishRecoveryRequest request, ActionListener<RecoveryResponse> listener) {\n+                RecoverySourceHandler handler = null;\n+                for (RecoverySourceHandler existingHandler : recoveryHandlers) {\n+                    if (existingHandler.getRequest().recoveryId() == request.recoveryId()) {", "originalCommit": "2bebd52869a64c61e6e6f172c58fa65912369fd6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16e003cd256d52012b8211bd8e0f576546a85ada", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\nindex 96fd491ee74..c42e47cfcd1 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java\n\n@@ -261,7 +261,8 @@ public class PeerRecoverySourceService extends AbstractLifecycleComponent implem\n             synchronized void reestablishRecovery(ReestablishRecoveryRequest request, ActionListener<RecoveryResponse> listener) {\n                 RecoverySourceHandler handler = null;\n                 for (RecoverySourceHandler existingHandler : recoveryHandlers) {\n-                    if (existingHandler.getRequest().recoveryId() == request.recoveryId()) {\n+                    if (existingHandler.getRequest().recoveryId() == request.recoveryId() &&\n+                        existingHandler.getRequest().targetAllocationId().equals(request.targetAllocationId())) {\n                         handler = existingHandler;\n                         break;\n                     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY4NjM0OA==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r424686348", "bodyText": "Can we have a test verifying this? Maybe a concurrent test?", "author": "dnhatn", "createdAt": "2020-05-13T19:40:49Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.util.concurrent.EsExecutors;\n+import org.elasticsearch.common.util.concurrent.ListenableFuture;\n+import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;\n+\n+public class RequestTracker {\n+\n+    private final Map<Long, ListenableFuture<Void>> ongoingRequests = new HashMap<>();\n+    private final LocalCheckpointTracker checkpointTracker = new LocalCheckpointTracker(NO_OPS_PERFORMED, NO_OPS_PERFORMED);\n+\n+    public synchronized ActionListener<Void> markReceivedAndCreateListener(long requestSeqNo, ActionListener<Void> listener) {", "originalCommit": "2bebd52869a64c61e6e6f172c58fa65912369fd6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16e003cd256d52012b8211bd8e0f576546a85ada", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\nsimilarity index 96%\nrename from server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java\nrename to server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\nindex 46c8240f003..0245aadb01d 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/RequestTracker.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\n\n@@ -29,7 +29,7 @@ import java.util.Map;\n \n import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;\n \n-public class RequestTracker {\n+public class RecoveryRequestTracker {\n \n     private final Map<Long, ListenableFuture<Void>> ongoingRequests = new HashMap<>();\n     private final LocalCheckpointTracker checkpointTracker = new LocalCheckpointTracker(NO_OPS_PERFORMED, NO_OPS_PERFORMED);\n"}}, {"oid": "16e003cd256d52012b8211bd8e0f576546a85ada", "url": "https://github.com/elastic/elasticsearch/commit/16e003cd256d52012b8211bd8e0f576546a85ada", "message": "Changes", "committedDate": "2020-05-13T22:19:09Z", "type": "commit"}, {"oid": "937c4d4f0bc971eba3485c2a35b8599922a936ba", "url": "https://github.com/elastic/elasticsearch/commit/937c4d4f0bc971eba3485c2a35b8599922a936ba", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures_v2", "committedDate": "2020-05-14T15:50:59Z", "type": "commit"}, {"oid": "36b41bc6ff3d4219255b013549837e7c0661104d", "url": "https://github.com/elastic/elasticsearch/commit/36b41bc6ff3d4219255b013549837e7c0661104d", "message": "Change", "committedDate": "2020-05-14T21:10:33Z", "type": "commit"}, {"oid": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "url": "https://github.com/elastic/elasticsearch/commit/1a39e4ac1c6dc581402ad87697d484766e4cd94b", "message": "Synchronized map", "committedDate": "2020-05-14T21:21:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE1MzA1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r427153059", "bodyText": "I wonder what will happen if the original recovery request has run to completion before reestablishRecovery has been called. At that point, the RecoverySourceHandler  has been  removed and we'll get a ResourceNotFoundException, even though the recovery completed. The target shard will then completely reset and restart the recovery. Not a biggie (given that the retry should be fast, as it has a retention lease and will do an ops-based recovery), just interesting case to consider.", "author": "ywelsch", "createdAt": "2020-05-19T09:15:26Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoverySourceService.java", "diffHunk": "@@ -218,6 +255,25 @@ synchronized RecoverySourceHandler addNewRecovery(StartRecoveryRequest request,\n                 return handler;\n             }\n \n+            /**\n+             * Adds recovery source handler.\n+             */\n+            synchronized void reestablishRecovery(ReestablishRecoveryRequest request, ActionListener<RecoveryResponse> listener) {", "originalCommit": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIzODc5NA==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r428238794", "bodyText": "I will consider this scenario in a potential follow-up cleanups. This PR is already pretty big, so I want to hold off right now.", "author": "tbrooks8", "createdAt": "2020-05-20T18:55:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE1MzA1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgwMTM1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r429801355", "bodyText": "As I said, I'm fine keeping the behavior as is (as it should incrementally restart due to ops-based recovery), just interesting to reason through the behavior.", "author": "ywelsch", "createdAt": "2020-05-25T08:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE1MzA1OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE1ODcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r427158711", "bodyText": "when is the listener null?", "author": "ywelsch", "createdAt": "2020-05-19T09:24:33Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java", "diffHunk": "@@ -513,6 +448,11 @@ public void messageReceived(RecoveryCleanFilesRequest request, TransportChannel\n         public void messageReceived(final RecoveryFileChunkRequest request, TransportChannel channel, Task task) throws Exception {\n             try (RecoveryRef recoveryRef = onGoingRecoveries.getRecoverySafe(request.recoveryId(), request.shardId())) {\n                 final RecoveryTarget recoveryTarget = recoveryRef.target();\n+                final ActionListener<Void> listener = createOrFinishListener(recoveryRef, channel, Actions.FILE_CHUNK, request);\n+                if (listener == null) {", "originalCommit": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI3MjU3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r428272579", "bodyText": "I added the java doc which explains it.", "author": "tbrooks8", "createdAt": "2020-05-20T19:57:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE1ODcxMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE2MDk5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r427160996", "bodyText": "Can you add a comment here saying that the ResourceNotFoundException covers a failed reestablishRecovery? Given that ResourceNotFoundException is a super class for some exceptions (notably some that we handle earlier here), for example RetentionLeaseNotFoundException, that there's a risk that we might end up indefinitely retrying in case something's wrong with the recovery. I think I would prefer a more specialized exception or targeted approach here.", "author": "ywelsch", "createdAt": "2020-05-19T09:28:10Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java", "diffHunk": "@@ -562,7 +530,131 @@ public void onFailure(Exception e) {\n \n         @Override\n         public void doRun() {\n-            doRecovery(recoveryId);\n+            doRecovery(recoveryId, startRecoveryRequest);\n+        }\n+    }\n+\n+    private class RecoveryResponseHandler implements TransportResponseHandler<RecoveryResponse> {\n+\n+        private final long recoveryId;\n+        private final StartRecoveryRequest request;\n+        private final RecoveryState.Timer timer;\n+\n+        private RecoveryResponseHandler(final StartRecoveryRequest request, final RecoveryState.Timer timer) {\n+            this.recoveryId = request.recoveryId();\n+            this.request = request;\n+            this.timer = timer;\n+        }\n+\n+        @Override\n+        public void handleResponse(RecoveryResponse recoveryResponse) {\n+            final TimeValue recoveryTime = new TimeValue(timer.time());\n+            // do this through ongoing recoveries to remove it from the collection\n+            onGoingRecoveries.markRecoveryAsDone(recoveryId);\n+            if (logger.isTraceEnabled()) {\n+                StringBuilder sb = new StringBuilder();\n+                sb.append('[').append(request.shardId().getIndex().getName()).append(']')\n+                    .append('[').append(request.shardId().id()).append(\"] \");\n+                sb.append(\"recovery completed from \").append(request.sourceNode()).append(\", took[\").append(recoveryTime)\n+                    .append(\"]\\n\");\n+                sb.append(\"   phase1: recovered_files [\").append(recoveryResponse.phase1FileNames.size()).append(\"]\")\n+                    .append(\" with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1TotalSize)).append(\"]\")\n+                    .append(\", took [\").append(timeValueMillis(recoveryResponse.phase1Time)).append(\"], throttling_wait [\")\n+                    .append(timeValueMillis(recoveryResponse.phase1ThrottlingWaitTime)).append(']').append(\"\\n\");\n+                sb.append(\"         : reusing_files   [\").append(recoveryResponse.phase1ExistingFileNames.size())\n+                    .append(\"] with total_size of [\").append(new ByteSizeValue(recoveryResponse.phase1ExistingTotalSize))\n+                    .append(\"]\\n\");\n+                sb.append(\"   phase2: start took [\").append(timeValueMillis(recoveryResponse.startTime)).append(\"]\\n\");\n+                sb.append(\"         : recovered [\").append(recoveryResponse.phase2Operations).append(\"]\")\n+                    .append(\" transaction log operations\")\n+                    .append(\", took [\").append(timeValueMillis(recoveryResponse.phase2Time)).append(\"]\")\n+                    .append(\"\\n\");\n+                logger.trace(\"{}\", sb);\n+            } else {\n+                logger.debug(\"{} recovery done from [{}], took [{}]\", request.shardId(), request.sourceNode(),\n+                    recoveryTime);\n+            }\n+        }\n+\n+        @Override\n+        public void handleException(TransportException e) {\n+            onException(e);\n+        }\n+\n+        private void onException(Exception e) {\n+            if (logger.isTraceEnabled()) {\n+                logger.trace(() -> new ParameterizedMessage(\n+                    \"[{}][{}] Got exception on recovery\", request.shardId().getIndex().getName(),\n+                    request.shardId().id()), e);\n+            }\n+            Throwable cause = ExceptionsHelper.unwrapCause(e);\n+            if (cause instanceof CancellableThreads.ExecutionCancelledException) {\n+                // this can also come from the source wrapped in a RemoteTransportException\n+                onGoingRecoveries.failRecovery(recoveryId, new RecoveryFailedException(request,\n+                    \"source has canceled the recovery\", cause), false);\n+                return;\n+            }\n+            if (cause instanceof RecoveryEngineException) {\n+                // unwrap an exception that was thrown as part of the recovery\n+                cause = cause.getCause();\n+            }\n+            // do it twice, in case we have double transport exception\n+            cause = ExceptionsHelper.unwrapCause(cause);\n+            if (cause instanceof RecoveryEngineException) {\n+                // unwrap an exception that was thrown as part of the recovery\n+                cause = cause.getCause();\n+            }\n+\n+            // here, we would add checks against exception that need to be retried (and not removeAndClean in this case)\n+\n+            if (cause instanceof IllegalIndexShardStateException || cause instanceof IndexNotFoundException ||\n+                cause instanceof ShardNotFoundException) {\n+                // if the target is not ready yet, retry\n+                retryRecovery(\n+                    recoveryId,\n+                    \"remote shard not ready\",\n+                    recoverySettings.retryDelayStateSync(),\n+                    recoverySettings.activityTimeout());\n+                return;\n+            }\n+\n+            if (cause instanceof DelayRecoveryException || cause instanceof ResourceNotFoundException) {", "originalCommit": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7342511534c4d1b52305f4ec8d95c9cbc5bc6145", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java\nindex 6c9a74f3597..5b16d70b49a 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java\n\n@@ -618,7 +617,9 @@ public class PeerRecoveryTargetService implements IndexEventListener {\n                 return;\n             }\n \n-            if (cause instanceof DelayRecoveryException || cause instanceof ResourceNotFoundException) {\n+            // PeerRecoveryNotFound is returned when the source node cannot find the recovery requested by\n+            // the REESTABLISH_RECOVERY request. In this case, we delay and then attempt to restart.\n+            if (cause instanceof DelayRecoveryException || cause instanceof PeerRecoveryNotFound) {\n                 retryRecovery(recoveryId, cause, recoverySettings.retryDelayStateSync(),\n                     recoverySettings.activityTimeout());\n                 return;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE2NjI1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r427166257", "bodyText": "Can you add @nullable annotation and add some docs for this method?", "author": "ywelsch", "createdAt": "2020-05-19T09:36:34Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.util.concurrent.EsExecutors;\n+import org.elasticsearch.common.util.concurrent.ListenableFuture;\n+import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;\n+\n+public class RecoveryRequestTracker {\n+\n+    private final Map<Long, ListenableFuture<Void>> ongoingRequests = Collections.synchronizedMap(new HashMap<>());\n+    private final LocalCheckpointTracker checkpointTracker = new LocalCheckpointTracker(NO_OPS_PERFORMED, NO_OPS_PERFORMED);\n+\n+    public synchronized ActionListener<Void> markReceivedAndCreateListener(long requestSeqNo, ActionListener<Void> listener) {", "originalCommit": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7342511534c4d1b52305f4ec8d95c9cbc5bc6145", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\nindex d7e72e0a5a2..24081ac92e2 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\n\n@@ -20,6 +20,7 @@\n package org.elasticsearch.indices.recovery;\n \n import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.util.concurrent.EsExecutors;\n import org.elasticsearch.common.util.concurrent.ListenableFuture;\n import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzE2NjcxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55274#discussion_r427166715", "bodyText": "combine this with the previous line", "author": "ywelsch", "createdAt": "2020-05-19T09:37:19Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.indices.recovery;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.util.concurrent.EsExecutors;\n+import org.elasticsearch.common.util.concurrent.ListenableFuture;\n+import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.elasticsearch.index.seqno.SequenceNumbers.NO_OPS_PERFORMED;\n+\n+public class RecoveryRequestTracker {\n+\n+    private final Map<Long, ListenableFuture<Void>> ongoingRequests = Collections.synchronizedMap(new HashMap<>());\n+    private final LocalCheckpointTracker checkpointTracker = new LocalCheckpointTracker(NO_OPS_PERFORMED, NO_OPS_PERFORMED);\n+\n+    public synchronized ActionListener<Void> markReceivedAndCreateListener(long requestSeqNo, ActionListener<Void> listener) {\n+        if (checkpointTracker.hasProcessed(requestSeqNo)) {\n+            final ListenableFuture<Void> existingFuture;\n+            existingFuture = ongoingRequests.get(requestSeqNo);", "originalCommit": "1a39e4ac1c6dc581402ad87697d484766e4cd94b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7342511534c4d1b52305f4ec8d95c9cbc5bc6145", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\nindex d7e72e0a5a2..24081ac92e2 100644\n--- a/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\n+++ b/server/src/main/java/org/elasticsearch/indices/recovery/RecoveryRequestTracker.java\n\n@@ -20,6 +20,7 @@\n package org.elasticsearch.indices.recovery;\n \n import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.Nullable;\n import org.elasticsearch.common.util.concurrent.EsExecutors;\n import org.elasticsearch.common.util.concurrent.ListenableFuture;\n import org.elasticsearch.index.seqno.LocalCheckpointTracker;\n"}}, {"oid": "6d6d78a037a22b0d4dfe37180208a46a9b56df8f", "url": "https://github.com/elastic/elasticsearch/commit/6d6d78a037a22b0d4dfe37180208a46a9b56df8f", "message": "Merge remote-tracking branch 'upstream/master' into retry_peer_recovery_failures_v2", "committedDate": "2020-05-20T18:18:50Z", "type": "commit"}, {"oid": "7342511534c4d1b52305f4ec8d95c9cbc5bc6145", "url": "https://github.com/elastic/elasticsearch/commit/7342511534c4d1b52305f4ec8d95c9cbc5bc6145", "message": "Changes", "committedDate": "2020-05-20T18:55:09Z", "type": "commit"}]}