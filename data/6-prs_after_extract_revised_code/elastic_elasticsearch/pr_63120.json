{"pr_number": 63120, "pr_title": "Wildcard field - add normalisation of ngram tokens to reduce disk space.", "pr_createdAt": "2020-10-01T11:26:57Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63120", "timeline": [{"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28", "url": "https://github.com/elastic/elasticsearch/commit/ceb82a10c64b94414dee8fa8a196886f61796a28", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817", "committedDate": "2020-10-01T11:55:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxMjI3MA==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498212270", "bodyText": "Can we generalize the block checks above with Character.isLetterOrDigit() == false ?", "author": "jimczi", "createdAt": "2020-10-01T12:40:39Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            TokenStream tok = new NormaliseThinningFilter(tokenizer);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+                return new TokenStreamComponents(tokenizer);\n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {\n+        private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+        \n+        /**\n+         * Create a new NormaliseThinningFilter, that normalizes token text such that even-numbered ascii values\n+         * are made odd and punctuation is replaced with /\n+         * \n+         * @param in TokenStream to filter\n+         */\n+        public NormaliseThinningFilter(TokenStream in) {\n+          super(in);\n+        }\n+        \n+        @Override\n+        public final boolean incrementToken() throws IOException {\n+          if (input.incrementToken()) {\n+              normalize(termAtt.buffer(), 0, termAtt.length());\n+            return true;\n+          } else\n+            return false;\n+        }\n+        \n+        public static String normalize(String s) {\n+            char[] chars = s.toCharArray();\n+            normalize(chars, 0, chars.length);\n+            return new String(chars);            \n+        }\n+        \n+        /**\n+         * Normalizes a token\n+         */\n+        public static void normalize(final char[] buffer, final int offset, final int limit) {\n+          assert buffer.length >= limit;\n+          assert 0 <= offset && offset <= buffer.length;\n+          for (int i = offset; i < limit;) {\n+            int codepoint = Character.codePointAt(buffer, i, limit);\n+            i += Character.toChars(\n+                    normalize(codepoint), buffer, i);\n+           }\n+        }\n+\n+        private static int normalize(int codepoint) {\n+            // Normalize  space ! \" # $ % &  ' ( } * + , - . chars to / \n+            if (codepoint >=32 && codepoint <= 47) {\n+                return 47; \n+            }\n+            // Normalize : ; < = > ? @ chars to / \n+            if (codepoint >=58 && codepoint <= 64) {\n+                return 47; \n+            }\n+            // Normalize  [ \\ ] ^ _ ` chars to / \n+            if (codepoint >=91 && codepoint <= 96) {\n+                return 47; \n+            }\n+            // Normalize  { | } ~ chars to / \n+            if (codepoint >=123 && codepoint <= 126) {\n+                return 47; \n+            }", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -97,7 +98,9 @@ public class WildcardFieldMapper extends FieldMapper {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            TokenStream tok = new NormaliseThinningFilter(tokenizer);\n+            \n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+            tok = new PunctuationFoldingFilter(tok);\n             \n             return new TokenStreamComponents(r -> {\n                 tokenizer.setReader(r);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNDY1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498214653", "bodyText": "We could add the lowercase filter here instead of lowercasing outside of the analyzer ? I also wonder if putting a ASCIIFoldingFilter makes sense but that's maybe a different scope.", "author": "jimczi", "createdAt": "2020-10-01T12:44:34Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -97,7 +98,9 @@ public class WildcardFieldMapper extends FieldMapper {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            TokenStream tok = new NormaliseThinningFilter(tokenizer);\n+            \n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+            tok = new PunctuationFoldingFilter(tok);\n             \n             return new TokenStreamComponents(r -> {\n                 tokenizer.setReader(r);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNjk2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498216961", "bodyText": "This should depend on the index created version ?", "author": "jimczi", "createdAt": "2020-10-01T12:48:10Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -299,19 +303,21 @@ public class WildcardFieldMapper extends FieldMapper {\n \n         static Analyzer lowercaseNormalizer = new LowercaseNormalizer();\n \n-        private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+        private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta, Version version) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n+            \n+            if (version.onOrAfter(Version.V_7_10_0)) {\n+                setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n+            } else {\n+                setIndexAnalyzer(WILDCARD_ANALYZER_7_9);\n+            }\n         }\n \n         @Override\n         public Query wildcardQuery(String wildcardPattern, RewriteMethod method, boolean caseInsensitive, QueryShardContext context) {\n \n-            String ngramIndexPattern = addLineEndChars(toLowerCase(wildcardPattern));\n-            \n-            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);\n-\n+            String ngramIndexPattern = addLineEndChars(wildcardPattern);\n             // Break search term into tokens\n             Set<String> tokens = new LinkedHashSet<>();\n             StringBuilder sequence = new StringBuilder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217711", "bodyText": "You don't need to resolve this at query-time. The correct analyzer can be picked once from the index created version when the field type is created.", "author": "jimczi", "createdAt": "2020-10-01T12:49:26Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n         }\n \n         @Override\n         public Query wildcardQuery(String wildcardPattern, RewriteMethod method, boolean caseInsensitive, QueryShardContext context) {\n \n             String ngramIndexPattern = addLineEndChars(toLowerCase(wildcardPattern));\n+            \n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -299,19 +303,21 @@ public class WildcardFieldMapper extends FieldMapper {\n \n         static Analyzer lowercaseNormalizer = new LowercaseNormalizer();\n \n-        private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n+        private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta, Version version) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n+            \n+            if (version.onOrAfter(Version.V_7_10_0)) {\n+                setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n+            } else {\n+                setIndexAnalyzer(WILDCARD_ANALYZER_7_9);\n+            }\n         }\n \n         @Override\n         public Query wildcardQuery(String wildcardPattern, RewriteMethod method, boolean caseInsensitive, QueryShardContext context) {\n \n-            String ngramIndexPattern = addLineEndChars(toLowerCase(wildcardPattern));\n-            \n-            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);\n-\n+            String ngramIndexPattern = addLineEndChars(wildcardPattern);\n             // Break search term into tokens\n             Set<String> tokens = new LinkedHashSet<>();\n             StringBuilder sequence = new StringBuilder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzg4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217883", "bodyText": "same here", "author": "jimczi", "createdAt": "2020-10-01T12:49:41Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -673,6 +765,7 @@ public Query rangeQuery(\n         ) {\n             BytesRef lower = lowerTerm == null ? null : BytesRefs.toBytesRef(lowerTerm);\n             BytesRef upper = upperTerm == null ? null : BytesRefs.toBytesRef(upperTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -765,14 +757,13 @@ public class WildcardFieldMapper extends FieldMapper {\n         ) {\n             BytesRef lower = lowerTerm == null ? null : BytesRefs.toBytesRef(lowerTerm);\n             BytesRef upper = upperTerm == null ? null : BytesRefs.toBytesRef(upperTerm);\n-            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);\n             Query accelerationQuery = null;\n             if (lowerTerm != null && upperTerm != null) {\n                 // Long common prefixes e.g. \"C:/Program Files/a,txt\" to \"C:/Program Files/z,txt\"\n                 // can be accelerated by searching for all the common leading ngrams e.g. c:/, /pr, rog, gra etc\n                 StringBuilder commonPrefix = new StringBuilder();\n-                String lowerS = addLineEndChars(toLowerCase(lower.utf8ToString()));\n-                String upperS = addLineEndChars(toLowerCase(upper.utf8ToString()));\n+                String lowerS = addLineEndChars(lower.utf8ToString());\n+                String upperS = addLineEndChars(upper.utf8ToString());\n                 for (int i = 0; i < Math.min(lowerS.length(), upperS.length());) {\n                     final int cL = lowerS.codePointAt(i);\n                     final int cU = upperS.codePointAt(i);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzk2MA==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217960", "bodyText": "and here", "author": "jimczi", "createdAt": "2020-10-01T12:49:47Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -751,6 +836,8 @@ public Query fuzzyQuery(\n         ) {\n             String searchTerm = BytesRefs.toString(value);\n             String lowerSearchTerm = toLowerCase(searchTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 2985e286c89..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -835,28 +826,25 @@ public class WildcardFieldMapper extends FieldMapper {\n             QueryShardContext context\n         ) {\n             String searchTerm = BytesRefs.toString(value);\n-            String lowerSearchTerm = toLowerCase(searchTerm);\n-            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);\n-            \n             try {\n                 BooleanQuery.Builder bqBuilder = new BooleanQuery.Builder();\n                 //The approximation query can have a prefix and any number of ngrams.\n                 BooleanQuery.Builder approxBuilder = new BooleanQuery.Builder();\n \n-                String postPrefixString = lowerSearchTerm;\n+                String postPrefixString = searchTerm;\n \n                 // Add all content prior to prefixLength as a MUST clause to the ngram index query\n                 if (prefixLength > 0) {\n                     Set<String> prefixTokens = new LinkedHashSet<>();\n-                    postPrefixString = lowerSearchTerm.substring(prefixLength);\n-                    String prefixCandidate = TOKEN_START_OR_END_CHAR + lowerSearchTerm.substring(0,  prefixLength);\n-                    getNgramTokens(prefixTokens, prefixCandidate, analyzer);\n+                    postPrefixString = searchTerm.substring(prefixLength);\n+                    String prefixCandidate = TOKEN_START_OR_END_CHAR + searchTerm.substring(0,  prefixLength);\n+                    getNgramTokens(prefixTokens, prefixCandidate);\n                     for (String prefixToken : prefixTokens) {\n                         addClause(prefixToken, approxBuilder, Occur.MUST);\n                     }\n                 }\n                 // Tokenize all content after the prefix\n-                TokenStream tokenizer = analyzer.tokenStream(name(), postPrefixString);\n+                TokenStream tokenizer = indexAnalyzer().tokenStream(name(), postPrefixString);\n                 CharTermAttribute termAtt = tokenizer.addAttribute(CharTermAttribute.class);\n                 ArrayList<String> postPrefixTokens = new ArrayList<>();\n                 String firstToken = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0OTg3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498749877", "bodyText": "nit: can we rename into PunctuationFoldingFilter or something similar ?", "author": "jimczi", "createdAt": "2020-10-02T10:48:05Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +94,95 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            \n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+            tok = new NormaliseThinningFilter(tok);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+//                return new TokenStreamComponents(tokenizer);\n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {", "originalCommit": "c2e4e84800ac207379be6e1254a95e4c03833b17", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "chunk": "diff --git a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\nindex 3e82eaf7c67..7cd023eec2b 100644\n--- a/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n+++ b/x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java\n\n@@ -100,7 +100,7 @@ public class WildcardFieldMapper extends FieldMapper {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n             \n             TokenStream tok = new LowerCaseFilter(tokenizer);\n-            tok = new NormaliseThinningFilter(tok);\n+            tok = new PunctuationFoldingFilter(tok);\n             \n             return new TokenStreamComponents(r -> {\n                 tokenizer.setReader(r);\n"}}, {"oid": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "url": "https://github.com/elastic/elasticsearch/commit/2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "message": "Class rename", "committedDate": "2020-10-02T11:04:35Z", "type": "forcePushed"}, {"oid": "bb905c67fa41ba6718d9c593848c166762b8cb6a", "url": "https://github.com/elastic/elasticsearch/commit/bb905c67fa41ba6718d9c593848c166762b8cb6a", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "de6c3f6613df9806aaa7d2598bb439b27d138853", "url": "https://github.com/elastic/elasticsearch/commit/de6c3f6613df9806aaa7d2598bb439b27d138853", "message": "Addressing review comments. Made lowercaseFilter part of Analyzer and set IndexAnalyzer appropriately on FieldType construction", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "4261a2aad4baffc8907bf78fc499d515233927a1", "url": "https://github.com/elastic/elasticsearch/commit/4261a2aad4baffc8907bf78fc499d515233927a1", "message": "Line length", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "url": "https://github.com/elastic/elasticsearch/commit/d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "message": "Remove debug", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "dcbe91ffd5917d12e87216d57f9008ff60536d0d", "url": "https://github.com/elastic/elasticsearch/commit/dcbe91ffd5917d12e87216d57f9008ff60536d0d", "message": "Class rename", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "message": "Removed commented out code", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "message": "Removed commented out code", "committedDate": "2020-10-02T13:46:53Z", "type": "forcePushed"}]}