{"pr_number": 60528, "pr_title": "[ML] adds new feature_processors field for data frame analytics", "pr_createdAt": "2020-07-31T15:52:55Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/60528", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzM2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r463693367", "bodyText": "@dimitris-athanasiou I am torn with what to do here.", "author": "benwtrent", "createdAt": "2020-07-31T15:55:29Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java", "diffHunk": "@@ -304,22 +368,42 @@ private ExtractedFields detectExtractedFields(Set<String> fields, Set<FieldSelec\n         return extractedFields;\n     }\n \n-    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields, boolean preferSource,\n+    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields,\n+                                                   boolean preferSource,\n                                                    Set<FieldSelection> fieldSelection) {\n-        Set<String> requiredFields = config.getAnalysis().getRequiredFields().stream().map(RequiredField::getName)\n+        Set<String> requiredFields = config.getAnalysis()\n+            .getRequiredFields()\n+            .stream()\n+            .map(RequiredField::getName)\n             .collect(Collectors.toSet());\n         Map<String, ExtractedField> nameOrParentToField = new LinkedHashMap<>();\n         for (ExtractedField currentField : extractedFields.getAllFields()) {\n+            // If this field or its parent is processed ONLY, then its fine. We don't need to deduplicate it as it won't be sent\n+            // directly to the native process\n+            if (extractedFields.getProcessedOnlyFields().contains(currentField.getName())) {\n+                nameOrParentToField.put(currentField.getName(), currentField);\n+                continue;\n+            }\n+            if (currentField.isMultiField() && extractedFields.getProcessedOnlyFields().contains(currentField.getParentField())) {\n+                nameOrParentToField.put(currentField.getParentField(), currentField);\n+                continue;\n+            }\n             String nameOrParent = currentField.isMultiField() ? currentField.getParentField() : currentField.getName();\n             ExtractedField existingField = nameOrParentToField.putIfAbsent(nameOrParent, currentField);\n+            // TODO, there is an issue where the processed field references the field `foo.keyword` but an included field references `foo`\n+            // The included field might only be `foo`. How should we adjust the `foo.keyword` inclusion?\n+            // It seems to me that we should disallow users from asking for a `foo.keyword` field in the processors.", "originalCommit": "5530aa4cd2648789d12c341101d05fff8b186aa3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2Mjc0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r464362742", "bodyText": "Well, if we prevent folks from including a \"organically\" AND via a feature_processor, we could skirt this issue.", "author": "benwtrent", "createdAt": "2020-08-03T11:47:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzM2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM5NDEzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r464394131", "bodyText": "I am going to implement the following restriction:\n\nIf the field is referenced in a feature_processor it cannot be included directly in analytics.\nWe will provide an identity processor so that folks can do this themselves in the future if necessary.", "author": "benwtrent", "createdAt": "2020-08-03T12:54:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzY5MzM2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "bb3d5279474158fa9fff795683eb640b74664040", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\nindex 327f3731350..b13b2ba4bf5 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n\n@@ -376,23 +392,22 @@ public class ExtractedFieldsDetector {\n             .stream()\n             .map(RequiredField::getName)\n             .collect(Collectors.toSet());\n+        Set<String> processorInputFields = extractedFields.getProcessedFieldInputs();\n         Map<String, ExtractedField> nameOrParentToField = new LinkedHashMap<>();\n         for (ExtractedField currentField : extractedFields.getAllFields()) {\n-            // If this field or its parent is processed ONLY, then its fine. We don't need to deduplicate it as it won't be sent\n-            // directly to the native process\n-            if (extractedFields.getProcessedOnlyFields().contains(currentField.getName())) {\n+            // Different processors could have different fields `foo` vs `foo.keyword`\n+            // We don't want to accidentally remove an extractor that a processor depends on.\n+            if (processorInputFields.contains(currentField.getName())) {\n                 nameOrParentToField.put(currentField.getName(), currentField);\n                 continue;\n             }\n-            if (currentField.isMultiField() && extractedFields.getProcessedOnlyFields().contains(currentField.getParentField())) {\n+            if (currentField.isMultiField() && processorInputFields.contains(currentField.getParentField())) {\n                 nameOrParentToField.put(currentField.getParentField(), currentField);\n                 continue;\n             }\n+            // If a processor does not reference the field or the parent field, we can select as desired\n             String nameOrParent = currentField.isMultiField() ? currentField.getParentField() : currentField.getName();\n             ExtractedField existingField = nameOrParentToField.putIfAbsent(nameOrParent, currentField);\n-            // TODO, there is an issue where the processed field references the field `foo.keyword` but an included field references `foo`\n-            // The included field might only be `foo`. How should we adjust the `foo.keyword` inclusion?\n-            // It seems to me that we should disallow users from asking for a `foo.keyword` field in the processors.\n             if (existingField != null) {\n                 ExtractedField parent = currentField.isMultiField() ? existingField : currentField;\n                 ExtractedField multiField = currentField.isMultiField() ? currentField : existingField;\n"}}, {"oid": "036c5243f83447d20c4f3bd867ffd60ae20236d2", "url": "https://github.com/elastic/elasticsearch/commit/036c5243f83447d20c4f3bd867ffd60ae20236d2", "message": "[ML] adds new feature_processors field for data frame analytics\n\nfeature_processors allow users to create custom features from\nindividual document fields.", "committedDate": "2020-07-31T18:39:06Z", "type": "forcePushed"}, {"oid": "bb3d5279474158fa9fff795683eb640b74664040", "url": "https://github.com/elastic/elasticsearch/commit/bb3d5279474158fa9fff795683eb640b74664040", "message": "[ML] adds new feature_processors field for data frame analytics\n\nfeature_processors allow users to create custom features from\nindividual document fields.", "committedDate": "2020-08-03T21:08:47Z", "type": "forcePushed"}, {"oid": "53730cd3641f46c038ffd5263634397efaad8514", "url": "https://github.com/elastic/elasticsearch/commit/53730cd3641f46c038ffd5263634397efaad8514", "message": "[ML] adds new feature_processors field for data frame analytics\n\nfeature_processors allow users to create custom features from\nindividual document fields.", "committedDate": "2020-08-04T13:46:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTA2NzA1NA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r465067054", "bodyText": "if we want to address this TODO, it will require transform this into a Builder format of parsing.\nSince that would be a ton more churn for this PR, I suggest doing that at a later time", "author": "benwtrent", "createdAt": "2020-08-04T13:54:21Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/analyses/Regression.java", "diffHunk": "@@ -59,14 +66,21 @@\n                 (Double) a[8],\n                 (Long) a[9],\n                 (LossFunction) a[10],\n-                (Double) a[11]));\n+                (Double) a[11],\n+                (List<PreProcessor>) a[12]));\n         parser.declareString(constructorArg(), DEPENDENT_VARIABLE);\n         BoostedTreeParams.declareFields(parser);\n         parser.declareString(optionalConstructorArg(), PREDICTION_FIELD_NAME);\n         parser.declareDouble(optionalConstructorArg(), TRAINING_PERCENT);\n         parser.declareLong(optionalConstructorArg(), RANDOMIZE_SEED);\n         parser.declareString(optionalConstructorArg(), LossFunction::fromString, LOSS_FUNCTION);\n         parser.declareDouble(optionalConstructorArg(), LOSS_FUNCTION_PARAMETER);\n+        parser.declareNamedObjects(optionalConstructorArg(),\n+            (p, c, n) -> lenient ?\n+                p.namedObject(LenientlyParsedPreProcessor.class, n, new PreProcessor.PreProcessorParseContext(true)) :\n+                p.namedObject(StrictlyParsedPreProcessor.class, n, new PreProcessor.PreProcessorParseContext(true)),\n+            (regression) -> {/*TODO should we throw if this is not set?*/},", "originalCommit": "53730cd3641f46c038ffd5263634397efaad8514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ1NjE4NA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468456184", "bodyText": "There is another version of declareNamedObjects that doesn't need the Consumer<Value> argument. Could we not just use that instead?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T09:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTA2NzA1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUwNTUzNw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468505537", "bodyText": "No. That method assumes a JSON object of JSON objects. Which is not what we want. Order is important for these, at least we do want the order to be deterministic.", "author": "benwtrent", "createdAt": "2020-08-11T11:18:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTA2NzA1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTA3ODY4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r465078689", "bodyText": "I think this would be helpful to keep for future debugging purposes.", "author": "benwtrent", "createdAt": "2020-08-04T14:10:05Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/AnalyticsProcessManager.java", "diffHunk": "@@ -268,8 +268,11 @@ private void writeDataRows(DataFrameDataExtractor dataExtractor, AnalyticsProces\n         }\n     }\n \n-    private void writeHeaderRecord(DataFrameDataExtractor dataExtractor, AnalyticsProcess<AnalyticsResult> process) throws IOException {\n+    private void writeHeaderRecord(DataFrameDataExtractor dataExtractor,\n+                                   AnalyticsProcess<AnalyticsResult> process,\n+                                   DataFrameAnalyticsTask task) throws IOException {\n         List<String> fieldNames = dataExtractor.getFieldNames();\n+        LOGGER.debug(() -> new ParameterizedMessage(\"[{}] header row fields {}\", task.getParams().getId(), fieldNames));", "originalCommit": "53730cd3641f46c038ffd5263634397efaad8514", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "497c7a8928f87d1d812425bacb899182e67bf34e", "url": "https://github.com/elastic/elasticsearch/commit/497c7a8928f87d1d812425bacb899182e67bf34e", "message": "[ML] adds new feature_processors field for data frame analytics\n\nfeature_processors allow users to create custom features from\nindividual document fields.", "committedDate": "2020-08-04T14:10:57Z", "type": "commit"}, {"oid": "497c7a8928f87d1d812425bacb899182e67bf34e", "url": "https://github.com/elastic/elasticsearch/commit/497c7a8928f87d1d812425bacb899182e67bf34e", "message": "[ML] adds new feature_processors field for data frame analytics\n\nfeature_processors allow users to create custom features from\nindividual document fields.", "committedDate": "2020-08-04T14:10:57Z", "type": "forcePushed"}, {"oid": "517cd851a23b416483de6a45c811c42d413ff6f2", "url": "https://github.com/elastic/elasticsearch/commit/517cd851a23b416483de6a45c811c42d413ff6f2", "message": "muting bwc test", "committedDate": "2020-08-04T14:43:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ1ODQwNA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468458404", "bodyText": "May I suggest we rename this to isCustomByDefault? I think it'd make reading it easier.", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T09:45:53Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/PreProcessor.java", "diffHunk": "@@ -18,6 +18,18 @@\n  */\n public interface PreProcessor extends NamedXContentObject, NamedWriteable, Accountable {\n \n+    class PreProcessorParseContext {\n+        public static final PreProcessorParseContext DEFAULT = new PreProcessorParseContext(false);\n+        final boolean defaultIsCustomValue;\n+        public PreProcessorParseContext(boolean defaultIsCustomValue) {\n+            this.defaultIsCustomValue = defaultIsCustomValue;\n+        }\n+\n+        public boolean isDefaultIsCustomValue() {", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/PreProcessor.java b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/PreProcessor.java\nindex 4258408707f..59666477370 100644\n--- a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/PreProcessor.java\n+++ b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/inference/preprocessing/PreProcessor.java\n\n@@ -25,7 +25,7 @@ public interface PreProcessor extends NamedXContentObject, NamedWriteable, Accou\n             this.defaultIsCustomValue = defaultIsCustomValue;\n         }\n \n-        public boolean isDefaultIsCustomValue() {\n+        public boolean isCustomByDefault() {\n             return defaultIsCustomValue;\n         }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2MTA1OA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468461058", "bodyText": "Should we handle null here by setting it to an empty list?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T09:50:30Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ExtractedFields.java", "diffHunk": "@@ -21,27 +21,39 @@\n import java.util.stream.Collectors;\n \n /**\n- * The fields the datafeed has to extract\n+ * The fields the data[feed|frame] has to extract\n  */\n public class ExtractedFields {\n \n     private final List<ExtractedField> allFields;\n     private final List<ExtractedField> docValueFields;\n+    private final List<ProcessedField> processedFields;\n     private final String[] sourceFields;\n     private final Map<String, Long> cardinalitiesForFieldsWithConstraints;\n \n-    public ExtractedFields(List<ExtractedField> allFields, Map<String, Long> cardinalitiesForFieldsWithConstraints) {\n-        this.allFields = Collections.unmodifiableList(allFields);\n+    public ExtractedFields(List<ExtractedField> allFields,\n+                           List<ProcessedField> processedFields,\n+                           Map<String, Long> cardinalitiesForFieldsWithConstraints) {\n+        this.allFields = new ArrayList<>(allFields);\n         this.docValueFields = filterFields(ExtractedField.Method.DOC_VALUE, allFields);\n         this.sourceFields = filterFields(ExtractedField.Method.SOURCE, allFields).stream().map(ExtractedField::getSearchField)\n             .toArray(String[]::new);\n         this.cardinalitiesForFieldsWithConstraints = Collections.unmodifiableMap(cardinalitiesForFieldsWithConstraints);\n+        this.processedFields = processedFields;", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ExtractedFields.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ExtractedFields.java\nindex 4f3ad5bb322..3853ea2629a 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ExtractedFields.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ExtractedFields.java\n\n@@ -39,7 +39,7 @@ public class ExtractedFields {\n         this.sourceFields = filterFields(ExtractedField.Method.SOURCE, allFields).stream().map(ExtractedField::getSearchField)\n             .toArray(String[]::new);\n         this.cardinalitiesForFieldsWithConstraints = Collections.unmodifiableMap(cardinalitiesForFieldsWithConstraints);\n-        this.processedFields = processedFields;\n+        this.processedFields = processedFields == null ? Collections.emptyList() : processedFields;\n     }\n \n     public List<ProcessedField> getProcessedFields() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2MjQxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468462419", "bodyText": "nit: make inputs type just Map<String, Object>", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T09:52:52Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.extractor;\n+\n+import org.elasticsearch.search.SearchHit;\n+import org.elasticsearch.xpack.core.ml.inference.preprocessing.PreProcessor;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+public class ProcessedField {\n+    private final PreProcessor preProcessor;\n+\n+    public ProcessedField(PreProcessor processor) {\n+        this.preProcessor = Objects.requireNonNull(processor);\n+    }\n+\n+    public List<String> getInputFieldNames() {\n+        return preProcessor.inputFields();\n+    }\n+\n+    public List<String> getOutputFieldNames() {\n+        return preProcessor.outputFields();\n+    }\n+\n+    public Set<String> getOutputFieldType(String outputField) {\n+        return Collections.singleton(preProcessor.getOutputFieldType(outputField));\n+    }\n+\n+    public Object[] value(SearchHit hit, Function<String, ExtractedField> fieldExtractor) {\n+        HashMap<String, Object> inputs = new HashMap<>(preProcessor.inputFields().size(), 1.0f);", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\nindex 704bce5d01d..50f13f94086 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\n\n@@ -11,6 +11,7 @@ import org.elasticsearch.xpack.core.ml.inference.preprocessing.PreProcessor;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n import java.util.Objects;\n import java.util.Set;\n import java.util.function.Function;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2NzM2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468467363", "bodyText": "Should we simplify by calling these 2 variables organicFeatures, processedFeatures?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T10:01:51Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java", "diffHunk": "@@ -67,10 +72,29 @@\n     private boolean hasNext;\n     private boolean searchHasShardFailure;\n     private final CachedSupplier<TrainTestSplitter> trainTestSplitter;\n+    // These are fields that are sent directly to the analytics process\n+    // They are not passed through a feature_processor\n+    private final List<String> organicExtractedFeatures;", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\nindex ac74d26bf38..d2b03e0eda8 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n\n@@ -74,27 +73,27 @@ public class DataFrameDataExtractor {\n     private final CachedSupplier<TrainTestSplitter> trainTestSplitter;\n     // These are fields that are sent directly to the analytics process\n     // They are not passed through a feature_processor\n-    private final List<String> organicExtractedFeatures;\n+    private final String[] organicFeatures;\n     // These are the output field names for the feature_processors\n-    private final List<String> processedOutputFields;\n-    private final HashMap<String, ExtractedField> extractedFieldHashMap;\n+    private final String[] processedFeatures;\n+    private final Map<String, ExtractedField> extractedFieldsByName;\n \n     DataFrameDataExtractor(Client client, DataFrameDataExtractorContext context) {\n         this.client = Objects.requireNonNull(client);\n         this.context = Objects.requireNonNull(context);\n         Set<String> processedFieldInputs = context.extractedFields.getProcessedFieldInputs();\n-        this.organicExtractedFeatures = context.extractedFields.getAllFields()\n+        this.organicFeatures = context.extractedFields.getAllFields()\n             .stream()\n             .map(ExtractedField::getName)\n             .filter(f -> processedFieldInputs.contains(f) == false)\n-            .collect(Collectors.toList());\n-        this.processedOutputFields = context.extractedFields.getProcessedFields()\n+            .toArray(String[]::new);\n+        this.processedFeatures = context.extractedFields.getProcessedFields()\n             .stream()\n             .map(ProcessedField::getOutputFieldNames)\n             .flatMap(List::stream)\n-            .collect(Collectors.toList());\n-        this.extractedFieldHashMap = new LinkedHashMap<>();\n-        context.extractedFields.getAllFields().forEach(f -> this.extractedFieldHashMap.put(f.getName(), f));\n+            .toArray(String[]::new);\n+        this.extractedFieldsByName = new LinkedHashMap<>();\n+        context.extractedFields.getAllFields().forEach(f -> this.extractedFieldsByName.put(f.getName(), f));\n         hasNext = true;\n         searchHasShardFailure = false;\n         this.trainTestSplitter = new CachedSupplier<>(context.trainTestSplitterFactory::create);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2NzU5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468467591", "bodyText": "nit: use Map<String, ExtractedField>", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T10:02:19Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java", "diffHunk": "@@ -67,10 +72,29 @@\n     private boolean hasNext;\n     private boolean searchHasShardFailure;\n     private final CachedSupplier<TrainTestSplitter> trainTestSplitter;\n+    // These are fields that are sent directly to the analytics process\n+    // They are not passed through a feature_processor\n+    private final List<String> organicExtractedFeatures;\n+    // These are the output field names for the feature_processors\n+    private final List<String> processedOutputFields;\n+    private final HashMap<String, ExtractedField> extractedFieldHashMap;", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2OTY5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468469696", "bodyText": "May I suggest renaming variable to extractedFieldsByName?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T10:06:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2NzU5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\nindex ac74d26bf38..d2b03e0eda8 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n\n@@ -74,27 +73,27 @@ public class DataFrameDataExtractor {\n     private final CachedSupplier<TrainTestSplitter> trainTestSplitter;\n     // These are fields that are sent directly to the analytics process\n     // They are not passed through a feature_processor\n-    private final List<String> organicExtractedFeatures;\n+    private final String[] organicFeatures;\n     // These are the output field names for the feature_processors\n-    private final List<String> processedOutputFields;\n-    private final HashMap<String, ExtractedField> extractedFieldHashMap;\n+    private final String[] processedFeatures;\n+    private final Map<String, ExtractedField> extractedFieldsByName;\n \n     DataFrameDataExtractor(Client client, DataFrameDataExtractorContext context) {\n         this.client = Objects.requireNonNull(client);\n         this.context = Objects.requireNonNull(context);\n         Set<String> processedFieldInputs = context.extractedFields.getProcessedFieldInputs();\n-        this.organicExtractedFeatures = context.extractedFields.getAllFields()\n+        this.organicFeatures = context.extractedFields.getAllFields()\n             .stream()\n             .map(ExtractedField::getName)\n             .filter(f -> processedFieldInputs.contains(f) == false)\n-            .collect(Collectors.toList());\n-        this.processedOutputFields = context.extractedFields.getProcessedFields()\n+            .toArray(String[]::new);\n+        this.processedFeatures = context.extractedFields.getProcessedFields()\n             .stream()\n             .map(ProcessedField::getOutputFieldNames)\n             .flatMap(List::stream)\n-            .collect(Collectors.toList());\n-        this.extractedFieldHashMap = new LinkedHashMap<>();\n-        context.extractedFields.getAllFields().forEach(f -> this.extractedFieldHashMap.put(f.getName(), f));\n+            .toArray(String[]::new);\n+        this.extractedFieldsByName = new LinkedHashMap<>();\n+        context.extractedFields.getAllFields().forEach(f -> this.extractedFieldsByName.put(f.getName(), f));\n         hasNext = true;\n         searchHasShardFailure = false;\n         this.trainTestSplitter = new CachedSupplier<>(context.trainTestSplitterFactory::create);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ3ODEwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468478105", "bodyText": "I wonder if we could simplify this and avoid the need for lastIndex. The way I have understood we write the organic features first. Could we have here something along the following lines:\nfor i in [0, extractedValues.length)\n    if i < len(organic_features)\n      add organic value in position i\n    else\n      get processed values\n      copy them into position i + processed_values_length", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T10:23:02Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java", "diffHunk": "@@ -188,26 +212,78 @@ private void setFetchSource(SearchRequestBuilder searchRequestBuilder) {\n         return rows;\n     }\n \n-    private Row createRow(SearchHit hit) {\n-        String[] extractedValues = new String[context.extractedFields.getAllFields().size()];\n-        for (int i = 0; i < extractedValues.length; ++i) {\n-            ExtractedField field = context.extractedFields.getAllFields().get(i);\n+    private int extractNonProcessedValues(SearchHit hit, String[] extractedValues) {\n+        int lastIndex = 0;\n+        for (String organicFeature : organicExtractedFeatures) {\n+            ExtractedField field = extractedFieldHashMap.get(organicFeature);\n             Object[] values = field.value(hit);\n             if (values.length == 1 && (values[0] instanceof Number || values[0] instanceof String)) {\n-                extractedValues[i] = Objects.toString(values[0]);\n+                extractedValues[lastIndex++] = Objects.toString(values[0]);\n             } else {\n                 if (values.length == 0 && context.supportsRowsWithMissingValues) {\n                     // if values is empty then it means it's a missing value\n-                    extractedValues[i] = NULL_VALUE;\n+                    extractedValues[lastIndex++] = NULL_VALUE;\n+                } else {\n+                    // we are here if we have a missing value but the analysis does not support those\n+                    // or the value type is not supported (e.g. arrays, etc.)\n+                    return -1;\n+                }\n+            }\n+        }\n+        return lastIndex;\n+    }\n+\n+    private int extractProcessedValue(ProcessedField processedField, SearchHit hit, String[] extractedValues, int start) {\n+        int lastIndex = start;\n+        Object[] values = processedField.value(hit, extractedFieldHashMap::get);\n+        if (values.length == 0) {\n+            if (context.supportsRowsWithMissingValues == false) {\n+                return -1;\n+            }\n+            for (String ignored : processedField.getOutputFieldNames()) {\n+                // if values is empty then it means it's a missing value\n+                extractedValues[lastIndex++] = NULL_VALUE;\n+            }\n+            return lastIndex;\n+        }\n+        if (values.length != processedField.getOutputFieldNames().size()) {\n+            throw ExceptionsHelper.badRequestException(\n+                \"field_processor [{}] output size expected to be [{}], instead it was [{}]\",\n+                processedField.getProcessorName(),\n+                processedField.getOutputFieldNames().size(),\n+                values.length);\n+        }\n+        for (int k = 0; k < processedField.getOutputFieldNames().size(); ++k) {\n+            Object value = values[k];\n+            if (value instanceof Number || value instanceof String) {\n+                extractedValues[lastIndex++] = Objects.toString(value);\n+            } else {\n+                if (value == null && context.supportsRowsWithMissingValues) {\n+                    // if values is null then it means it's a missing value\n+                    extractedValues[lastIndex++] = NULL_VALUE;\n                 } else {\n                     // we are here if we have a missing value but the analysis does not support those\n                     // or the value type is not supported (e.g. arrays, etc.)\n-                    extractedValues = null;\n-                    break;\n+                    return -1;\n                 }\n             }\n         }\n-        boolean isTraining = extractedValues == null ? false : trainTestSplitter.get().isTraining(extractedValues);\n+        return lastIndex;\n+    }\n+\n+    private Row createRow(SearchHit hit) {\n+        String[] extractedValues = new String[organicExtractedFeatures.size() + processedOutputFields.size()];\n+        int lastIndex = extractNonProcessedValues(hit, extractedValues);", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUyMzAwMw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468523003", "bodyText": "@dimitris-athanasiou this does not end up making it any simpler. I will see what I can do.", "author": "benwtrent", "createdAt": "2020-08-11T11:53:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ3ODEwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\nindex ac74d26bf38..d2b03e0eda8 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractor.java\n\n@@ -212,40 +211,35 @@ public class DataFrameDataExtractor {\n         return rows;\n     }\n \n-    private int extractNonProcessedValues(SearchHit hit, String[] extractedValues) {\n-        int lastIndex = 0;\n-        for (String organicFeature : organicExtractedFeatures) {\n-            ExtractedField field = extractedFieldHashMap.get(organicFeature);\n-            Object[] values = field.value(hit);\n-            if (values.length == 1 && (values[0] instanceof Number || values[0] instanceof String)) {\n-                extractedValues[lastIndex++] = Objects.toString(values[0]);\n-            } else {\n-                if (values.length == 0 && context.supportsRowsWithMissingValues) {\n-                    // if values is empty then it means it's a missing value\n-                    extractedValues[lastIndex++] = NULL_VALUE;\n-                } else {\n-                    // we are here if we have a missing value but the analysis does not support those\n-                    // or the value type is not supported (e.g. arrays, etc.)\n-                    return -1;\n-                }\n-            }\n+    private String extractNonProcessedValues(SearchHit hit, String organicFeature) {\n+        ExtractedField field = extractedFieldsByName.get(organicFeature);\n+        Object[] values = field.value(hit);\n+        if (values.length == 1 && isValidValue(values[0])) {\n+            return Objects.toString(values[0]);\n+        }\n+        if (values.length == 0 && context.supportsRowsWithMissingValues) {\n+            // if values is empty then it means it's a missing value\n+            return NULL_VALUE;\n         }\n-        return lastIndex;\n+        // we are here if we have a missing value but the analysis does not support those\n+        // or the value type is not supported (e.g. arrays, etc.)\n+        return null;\n     }\n \n-    private int extractProcessedValue(ProcessedField processedField, SearchHit hit, String[] extractedValues, int start) {\n-        int lastIndex = start;\n-        Object[] values = processedField.value(hit, extractedFieldHashMap::get);\n+    private String[] extractProcessedValue(ProcessedField processedField, SearchHit hit) {\n+        Object[] values = processedField.value(hit, extractedFieldsByName::get);\n+        if (values.length == 0 && context.supportsRowsWithMissingValues == false) {\n+            return null;\n+        }\n+        final String[] extractedValue = new String[processedField.getOutputFieldNames().size()];\n+        for (int i = 0; i < processedField.getOutputFieldNames().size(); i++) {\n+            extractedValue[i] = NULL_VALUE;\n+        }\n+        // if values is empty then it means it's a missing value\n         if (values.length == 0) {\n-            if (context.supportsRowsWithMissingValues == false) {\n-                return -1;\n-            }\n-            for (String ignored : processedField.getOutputFieldNames()) {\n-                // if values is empty then it means it's a missing value\n-                extractedValues[lastIndex++] = NULL_VALUE;\n-            }\n-            return lastIndex;\n+            return extractedValue;\n         }\n+\n         if (values.length != processedField.getOutputFieldNames().size()) {\n             throw ExceptionsHelper.badRequestException(\n                 \"field_processor [{}] output size expected to be [{}], instead it was [{}]\",\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUwMDU2NA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468500564", "bodyText": "wrap {} in square brackets", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T11:07:51Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java", "diffHunk": "@@ -69,44 +77,101 @@\n     }\n \n     public Tuple<ExtractedFields, List<FieldSelection>> detect() {\n+        List<ProcessedField> processedFields = extractFeatureProcessors()\n+            .stream()\n+            .map(ProcessedField::new)\n+            .collect(Collectors.toList());\n         TreeSet<FieldSelection> fieldSelection = new TreeSet<>(Comparator.comparing(FieldSelection::getName));\n-        Set<String> fields = getIncludedFields(fieldSelection);\n+        Set<String> fields = getIncludedFields(fieldSelection,\n+            processedFields.stream()\n+                .map(ProcessedField::getInputFieldNames)\n+                .flatMap(List::stream)\n+                .collect(Collectors.toSet()));\n         checkFieldsHaveCompatibleTypes(fields);\n         checkRequiredFields(fields);\n         checkFieldsWithCardinalityLimit();\n-        ExtractedFields extractedFields = detectExtractedFields(fields, fieldSelection);\n+        ExtractedFields extractedFields = detectExtractedFields(fields, fieldSelection, processedFields);\n         addIncludedFields(extractedFields, fieldSelection);\n \n         return Tuple.tuple(extractedFields, Collections.unmodifiableList(new ArrayList<>(fieldSelection)));\n     }\n \n-    private Set<String> getIncludedFields(Set<FieldSelection> fieldSelection) {\n+    private Set<String> getIncludedFields(Set<FieldSelection> fieldSelection, Set<String> requiredFieldsForProcessors) {\n         Set<String> fields = new TreeSet<>(fieldCapabilitiesResponse.get().keySet());\n+        validateFieldsRequireForProcessors(requiredFieldsForProcessors);\n         fields.removeAll(IGNORE_FIELDS);\n         removeFieldsUnderResultsField(fields);\n         removeObjects(fields);\n         applySourceFiltering(fields);\n+        if (fields.containsAll(requiredFieldsForProcessors) == false) {\n+            throw ExceptionsHelper.badRequestException(\n+                \"fields {} required by field_processors are not included in source filtering.\",\n+                Sets.difference(requiredFieldsForProcessors, fields));\n+        }\n         FetchSourceContext analyzedFields = config.getAnalyzedFields();\n \n         // If the user has not explicitly included fields we'll include all compatible fields\n         if (analyzedFields == null || analyzedFields.includes().length == 0) {\n             removeFieldsWithIncompatibleTypes(fields, fieldSelection);\n         }\n         includeAndExcludeFields(fields, fieldSelection);\n+        if (fields.containsAll(requiredFieldsForProcessors) == false) {\n+            throw ExceptionsHelper.badRequestException(\n+                \"fields {} required by field_processors are not included in the analyzed_fields.\",\n+                Sets.difference(requiredFieldsForProcessors, fields));\n+        }\n \n         return fields;\n     }\n \n+    private void validateFieldsRequireForProcessors(Set<String> processorFields) {\n+        Set<String> fieldsForProcessor = new HashSet<>(processorFields);\n+        removeFieldsUnderResultsField(fieldsForProcessor);\n+        if (fieldsForProcessor.size() < processorFields.size()) {\n+            throw ExceptionsHelper.badRequestException(\"fields contained in results field {} cannot be used in a feature_processor\",", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\nindex 52a0a6ed39a..fce7a3f3d30 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n\n@@ -128,7 +128,7 @@ public class ExtractedFieldsDetector {\n         Set<String> fieldsForProcessor = new HashSet<>(processorFields);\n         removeFieldsUnderResultsField(fieldsForProcessor);\n         if (fieldsForProcessor.size() < processorFields.size()) {\n-            throw ExceptionsHelper.badRequestException(\"fields contained in results field {} cannot be used in a feature_processor\",\n+            throw ExceptionsHelper.badRequestException(\"fields contained in results field [{}] cannot be used in a feature_processor\",\n                 config.getDest().getResultsField());\n         }\n         removeObjects(fieldsForProcessor);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUwMjY0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468502643", "bodyText": "add a ; after \"analysis\"?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T11:12:26Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java", "diffHunk": "@@ -304,26 +383,52 @@ private ExtractedFields detectExtractedFields(Set<String> fields, Set<FieldSelec\n         return extractedFields;\n     }\n \n-    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields, boolean preferSource,\n+    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields,\n+                                                   boolean preferSource,\n                                                    Set<FieldSelection> fieldSelection) {\n-        Set<String> requiredFields = config.getAnalysis().getRequiredFields().stream().map(RequiredField::getName)\n+        Set<String> requiredFields = config.getAnalysis()\n+            .getRequiredFields()\n+            .stream()\n+            .map(RequiredField::getName)\n             .collect(Collectors.toSet());\n+        Set<String> processorInputFields = extractedFields.getProcessedFieldInputs();\n         Map<String, ExtractedField> nameOrParentToField = new LinkedHashMap<>();\n         for (ExtractedField currentField : extractedFields.getAllFields()) {\n             String nameOrParent = currentField.isMultiField() ? currentField.getParentField() : currentField.getName();\n             ExtractedField existingField = nameOrParentToField.putIfAbsent(nameOrParent, currentField);\n             if (existingField != null) {\n                 ExtractedField parent = currentField.isMultiField() ? existingField : currentField;\n                 ExtractedField multiField = currentField.isMultiField() ? currentField : existingField;\n+                // If required fields contains parent or multifield and the processor input fields reference the other, that is an error\n+                // we should not allow processing of data that is required.\n+                if ((requiredFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName()))\n+                    || (requiredFields.contains(multiField.getName()) && processorInputFields.contains(parent.getName()))) {\n+                    throw ExceptionsHelper.badRequestException(\n+                        \"feature_processors cannot be applied to required fields for analysis multi-field [{}] parent [{}]\",", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\nindex 52a0a6ed39a..fce7a3f3d30 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n\n@@ -404,15 +404,16 @@ public class ExtractedFieldsDetector {\n                 if ((requiredFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName()))\n                     || (requiredFields.contains(multiField.getName()) && processorInputFields.contains(parent.getName()))) {\n                     throw ExceptionsHelper.badRequestException(\n-                        \"feature_processors cannot be applied to required fields for analysis multi-field [{}] parent [{}]\",\n+                        \"feature_processors cannot be applied to required fields for analysis; multi-field [{}] parent [{}]\",\n                         multiField.getName(),\n                         parent.getName());\n                 }\n                 // If processor input fields have BOTH, we need to keep both.\n                 if (processorInputFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName())) {\n-                    nameOrParentToField.put(parent.getName(), parent);\n-                    nameOrParentToField.put(multiField.getName(), multiField);\n-                    continue;\n+                    throw ExceptionsHelper.badRequestException(\n+                        \"feature_processors refer to both multi-field [{}] and parent [{}]. Please only refer to one or the other\",\n+                        multiField.getName(),\n+                        parent.getName());\n                 }\n                 nameOrParentToField.put(nameOrParent,\n                     chooseMultiFieldOrParent(preferSource, requiredFields, processorInputFields, parent, multiField, fieldSelection));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUwMzI2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468503263", "bodyText": "Doesn't that lead to complexity? Could we error here and request that a field is always referred to in the same way?", "author": "dimitris-athanasiou", "createdAt": "2020-08-11T11:13:52Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java", "diffHunk": "@@ -304,26 +383,52 @@ private ExtractedFields detectExtractedFields(Set<String> fields, Set<FieldSelec\n         return extractedFields;\n     }\n \n-    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields, boolean preferSource,\n+    private ExtractedFields deduplicateMultiFields(ExtractedFields extractedFields,\n+                                                   boolean preferSource,\n                                                    Set<FieldSelection> fieldSelection) {\n-        Set<String> requiredFields = config.getAnalysis().getRequiredFields().stream().map(RequiredField::getName)\n+        Set<String> requiredFields = config.getAnalysis()\n+            .getRequiredFields()\n+            .stream()\n+            .map(RequiredField::getName)\n             .collect(Collectors.toSet());\n+        Set<String> processorInputFields = extractedFields.getProcessedFieldInputs();\n         Map<String, ExtractedField> nameOrParentToField = new LinkedHashMap<>();\n         for (ExtractedField currentField : extractedFields.getAllFields()) {\n             String nameOrParent = currentField.isMultiField() ? currentField.getParentField() : currentField.getName();\n             ExtractedField existingField = nameOrParentToField.putIfAbsent(nameOrParent, currentField);\n             if (existingField != null) {\n                 ExtractedField parent = currentField.isMultiField() ? existingField : currentField;\n                 ExtractedField multiField = currentField.isMultiField() ? currentField : existingField;\n+                // If required fields contains parent or multifield and the processor input fields reference the other, that is an error\n+                // we should not allow processing of data that is required.\n+                if ((requiredFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName()))\n+                    || (requiredFields.contains(multiField.getName()) && processorInputFields.contains(parent.getName()))) {\n+                    throw ExceptionsHelper.badRequestException(\n+                        \"feature_processors cannot be applied to required fields for analysis multi-field [{}] parent [{}]\",\n+                        multiField.getName(),\n+                        parent.getName());\n+                }\n+                // If processor input fields have BOTH, we need to keep both.", "originalCommit": "517cd851a23b416483de6a45c811c42d413ff6f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUzNzk5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468537992", "bodyText": "For sure, we can error here. It would be weird that the same user chooses separate multi-fields for different processed fields.", "author": "benwtrent", "createdAt": "2020-08-11T12:21:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODUwMzI2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "52405e72a3ed609d89dbb0753240861b9bcb5139", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\nindex 52a0a6ed39a..fce7a3f3d30 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n\n@@ -404,15 +404,16 @@ public class ExtractedFieldsDetector {\n                 if ((requiredFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName()))\n                     || (requiredFields.contains(multiField.getName()) && processorInputFields.contains(parent.getName()))) {\n                     throw ExceptionsHelper.badRequestException(\n-                        \"feature_processors cannot be applied to required fields for analysis multi-field [{}] parent [{}]\",\n+                        \"feature_processors cannot be applied to required fields for analysis; multi-field [{}] parent [{}]\",\n                         multiField.getName(),\n                         parent.getName());\n                 }\n                 // If processor input fields have BOTH, we need to keep both.\n                 if (processorInputFields.contains(parent.getName()) && processorInputFields.contains(multiField.getName())) {\n-                    nameOrParentToField.put(parent.getName(), parent);\n-                    nameOrParentToField.put(multiField.getName(), multiField);\n-                    continue;\n+                    throw ExceptionsHelper.badRequestException(\n+                        \"feature_processors refer to both multi-field [{}] and parent [{}]. Please only refer to one or the other\",\n+                        multiField.getName(),\n+                        parent.getName());\n                 }\n                 nameOrParentToField.put(nameOrParent,\n                     chooseMultiFieldOrParent(preferSource, requiredFields, processorInputFields, parent, multiField, fieldSelection));\n"}}, {"oid": "1e2ef32bcbca8f056789df82646ef644620568fe", "url": "https://github.com/elastic/elasticsearch/commit/1e2ef32bcbca8f056789df82646ef644620568fe", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-dfa-add-processors", "committedDate": "2020-08-11T11:34:03Z", "type": "commit"}, {"oid": "52405e72a3ed609d89dbb0753240861b9bcb5139", "url": "https://github.com/elastic/elasticsearch/commit/52405e72a3ed609d89dbb0753240861b9bcb5139", "message": "addressing PR comments", "committedDate": "2020-08-11T12:28:29Z", "type": "commit"}, {"oid": "4cae33aadba07803ea56eb15ddb7b3cb4bf68a07", "url": "https://github.com/elastic/elasticsearch/commit/4cae33aadba07803ea56eb15ddb7b3cb4bf68a07", "message": "fixing test", "committedDate": "2020-08-11T14:36:10Z", "type": "commit"}, {"oid": "b8a6df9b565373824d31d190958d78d8e19c20af", "url": "https://github.com/elastic/elasticsearch/commit/b8a6df9b565373824d31d190958d78d8e19c20af", "message": "adding field processor test", "committedDate": "2020-08-11T15:03:54Z", "type": "commit"}, {"oid": "be5c29013d81bae1db23f7c8c509f6dfa57dc2fd", "url": "https://github.com/elastic/elasticsearch/commit/be5c29013d81bae1db23f7c8c509f6dfa57dc2fd", "message": "fixing test", "committedDate": "2020-08-11T15:05:53Z", "type": "commit"}, {"oid": "d419dfc817beff45cfd1a819aaa92294f366b97e", "url": "https://github.com/elastic/elasticsearch/commit/d419dfc817beff45cfd1a819aaa92294f366b97e", "message": "ensuring output feature uniqueness", "committedDate": "2020-08-11T16:03:27Z", "type": "commit"}, {"oid": "21c6999837269394643d13bdd683c4772de1ee75", "url": "https://github.com/elastic/elasticsearch/commit/21c6999837269394643d13bdd683c4772de1ee75", "message": "adding more tests", "committedDate": "2020-08-12T14:42:57Z", "type": "commit"}, {"oid": "553d221b39113ea107961a1a39560c50d36b343f", "url": "https://github.com/elastic/elasticsearch/commit/553d221b39113ea107961a1a39560c50d36b343f", "message": "Merge branch 'master' into feature/ml-dfa-add-processors", "committedDate": "2020-08-12T14:52:30Z", "type": "commit"}, {"oid": "a8d130f465ca737ba6bb018adae5c5da98b5fa35", "url": "https://github.com/elastic/elasticsearch/commit/a8d130f465ca737ba6bb018adae5c5da98b5fa35", "message": "fixing precommit", "committedDate": "2020-08-12T15:12:38Z", "type": "commit"}, {"oid": "eac75c1457d5cce4a18b9e6753634e6dbb5e473e", "url": "https://github.com/elastic/elasticsearch/commit/eac75c1457d5cce4a18b9e6753634e6dbb5e473e", "message": "Merge branch 'feature/ml-dfa-add-processors' of github.com:benwtrent/elasticsearch into feature/ml-dfa-add-processors", "committedDate": "2020-08-12T15:13:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk5MTU3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r468991577", "bodyText": "nit: space after if", "author": "dimitris-athanasiou", "createdAt": "2020-08-12T04:01:05Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java", "diffHunk": "@@ -525,6 +527,37 @@ private void addIncludedFields(ExtractedFields extractedFields, Set<FieldSelecti\n         }\n     }\n \n+    static void checkOutputFeatureUniqueness(List<ProcessedField> processedFields, Set<String> selectedFields) {\n+        Set<String> processInputs = processedFields.stream()\n+            .map(ProcessedField::getInputFieldNames)\n+            .flatMap(List::stream)\n+            .collect(Collectors.toSet());\n+        // All analysis fields that we include that are NOT processed\n+        // This indicates that they are sent as is\n+        Set<String> organicFields = Sets.difference(selectedFields, processInputs);\n+\n+        Set<String> processedFeatures = new HashSet<>();\n+        Set<String> duplicatedFields = new HashSet<>();\n+        for (ProcessedField processedField : processedFields) {\n+            for (String output : processedField.getOutputFieldNames()) {\n+                if(processedFeatures.add(output) == false) {", "originalCommit": "d419dfc817beff45cfd1a819aaa92294f366b97e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ad152088ab7cb87977d19dc6881bead402927b6", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\nindex 695a02facd0..1b03544d015 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetector.java\n\n@@ -540,7 +540,7 @@ public class ExtractedFieldsDetector {\n         Set<String> duplicatedFields = new HashSet<>();\n         for (ProcessedField processedField : processedFields) {\n             for (String output : processedField.getOutputFieldNames()) {\n-                if(processedFeatures.add(output) == false) {\n+                if (processedFeatures.add(output) == false) {\n                     duplicatedFields.add(output);\n                 }\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg3NzIzNw==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r469877237", "bodyText": "Does this work correctly? If we filter out null objects, won't we mess the correspondence of the values to the output fields?", "author": "dimitris-athanasiou", "createdAt": "2020-08-13T11:15:23Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java", "diffHunk": "@@ -52,7 +52,7 @@ public ProcessedField(PreProcessor processor) {\n             }\n         }\n         preProcessor.process(inputs);\n-        return preProcessor.outputFields().stream().map(inputs::get).toArray();\n+        return preProcessor.outputFields().stream().map(inputs::get).filter(Objects::nonNull).toArray();", "originalCommit": "21c6999837269394643d13bdd683c4772de1ee75", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDEzNjA2MA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r470136060", "bodyText": "Let me think on this more.\nWe don't want to return partial lists, for sure. But we also don't want to put empty/missing unless the caller supports missing values...", "author": "benwtrent", "createdAt": "2020-08-13T17:46:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg3NzIzNw=="}], "type": "inlineReview", "revised_code": {"commit": "7ad152088ab7cb87977d19dc6881bead402927b6", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\nindex 9c4140d4386..50f13f94086 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/extractor/ProcessedField.java\n\n@@ -52,7 +52,7 @@ public class ProcessedField {\n             }\n         }\n         preProcessor.process(inputs);\n-        return preProcessor.outputFields().stream().map(inputs::get).filter(Objects::nonNull).toArray();\n+        return preProcessor.outputFields().stream().map(inputs::get).toArray();\n     }\n \n     public String getProcessorName() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg3ODQ2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r469878462", "bodyText": "rename to testGetFieldNames_GivenProcessesFeatures ?", "author": "dimitris-athanasiou", "createdAt": "2020-08-13T11:18:07Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java", "diffHunk": "@@ -472,12 +479,100 @@ public void testGetCategoricalFields() {\n             containsInAnyOrder(\"field_keyword\", \"field_text\", \"field_boolean\"));\n     }\n \n+    public void testWithProcessedFeatures_FieldInfo() {", "originalCommit": "21c6999837269394643d13bdd683c4772de1ee75", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ad152088ab7cb87977d19dc6881bead402927b6", "chunk": "diff --git a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\nindex fc2fbd7149b..5d910c5fca7 100644\n--- a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\n+++ b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\n\n@@ -479,7 +479,7 @@ public class DataFrameDataExtractorTests extends ESTestCase {\n             containsInAnyOrder(\"field_keyword\", \"field_text\", \"field_boolean\"));\n     }\n \n-    public void testWithProcessedFeatures_FieldInfo() {\n+    public void testGetFieldNames_GivenProcessesFeatures() {\n         // Explicit cast of ExtractedField args necessary for Eclipse due to https://bugs.eclipse.org/bugs/show_bug.cgi?id=530915\n         extractedFields = new ExtractedFields(Arrays.asList(\n             (ExtractedField) new DocValueField(\"field_boolean\", Collections.singleton(\"boolean\")),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg3ODgxNA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r469878814", "bodyText": "shall we make this private?", "author": "dimitris-athanasiou", "createdAt": "2020-08-13T11:18:51Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java", "diffHunk": "@@ -551,4 +646,70 @@ protected SearchResponse executeSearchScrollRequest(String scrollId) {\n             return searchResponse;\n         }\n     }\n+\n+    static class CategoricalPreProcessor implements PreProcessor {", "originalCommit": "21c6999837269394643d13bdd683c4772de1ee75", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ad152088ab7cb87977d19dc6881bead402927b6", "chunk": "diff --git a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\nindex fc2fbd7149b..5d910c5fca7 100644\n--- a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\n+++ b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/DataFrameDataExtractorTests.java\n\n@@ -647,7 +647,7 @@ public class DataFrameDataExtractorTests extends ESTestCase {\n         }\n     }\n \n-    static class CategoricalPreProcessor implements PreProcessor {\n+    private static class CategoricalPreProcessor implements PreProcessor {\n \n         private final List<String> inputFields;\n         private final List<String> outputFields;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg4MDE0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r469880141", "bodyText": "I think there is a lot of value on keeping the unit tests targeting a very specific piece of functionality when possible. The reason for that is that when a test fails, it is really helpful it if makes it clear what the problem was. I would suggest splitting this test into individual tests with names that indicate the validation that is tested. It also makes the tests serve as live documentation.\nI realise this is a subjective preference. If you are not convinced by the argument, you can of course leave it as is :-)", "author": "dimitris-athanasiou", "createdAt": "2020-08-13T11:21:42Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetectorTests.java", "diffHunk": "@@ -943,6 +949,196 @@ public void testDetect_GivenAnalyzedFieldExcludesObjectField() {\n         assertThat(e.getMessage(), equalTo(\"analyzed_fields must not include or exclude object fields: [object_field]\"));\n     }\n \n+    public void testDetect_givenFeatureProcessorsFailures() {", "originalCommit": "21c6999837269394643d13bdd683c4772de1ee75", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDEzNzM2OA==", "url": "https://github.com/elastic/elasticsearch/pull/60528#discussion_r470137368", "bodyText": "\ud83d\ude2d\nThis PR is going to end up being near 2k lines.", "author": "benwtrent", "createdAt": "2020-08-13T17:48:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg4MDE0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ad152088ab7cb87977d19dc6881bead402927b6", "chunk": "diff --git a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetectorTests.java b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetectorTests.java\nindex a1a716c6b39..9e06cda25c6 100644\n--- a/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetectorTests.java\n+++ b/x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/extractor/ExtractedFieldsDetectorTests.java\n\n@@ -949,168 +960,149 @@ public class ExtractedFieldsDetectorTests extends ESTestCase {\n         assertThat(e.getMessage(), equalTo(\"analyzed_fields must not include or exclude object fields: [object_field]\"));\n     }\n \n-    public void testDetect_givenFeatureProcessorsFailures() {\n-        FieldCapabilitiesResponse fieldCapabilities = new MockFieldCapsResponseBuilder()\n-            .addAggregatableField(\"field_11\", \"float\")\n-            .addNonAggregatableField(\"field_21\", \"float\")\n-            .addAggregatableField(\"field_21.child\", \"float\")\n-            .addNonAggregatableField(\"field_31\", \"float\")\n-            .addAggregatableField(\"field_31.child\", \"float\")\n-            .addNonAggregatableField(\"object_field\", \"object\")\n-            .build();\n+    public void testDetect_givenFeatureProcessorsFailures_ResultsField() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"ml.result\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"fields contained in results field [ml] cannot be used in a feature_processor\"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"ml.result\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"fields contained in results field [ml] cannot be used in a feature_processor\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_Objects() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"object_field\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"fields for feature_processors must not be objects\"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"object_field\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"fields for feature_processors must not be objects\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_ReservedFields() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"_id\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"the following fields cannot be used in feature_processors\"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"_id\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"the following fields cannot be used in feature_processors\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_MissingFieldFromIndex() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"bar\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"the fields [bar] were not found in the field capabilities of the source indices\"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"bar\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"the fields [bar] were not found in the field capabilities of the source indices\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_UsingRequiredField() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_31\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"required analysis fields [field_31] cannot be used in a feature_processor\"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_31\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"required analysis fields [field_31] cannot be used in a feature_processor\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_BadSourceFiltering() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        sourceFiltering = new FetchSourceContext(true, null, new String[]{\"field_1*\"});\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_11\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-        {\n-            sourceFiltering = new FetchSourceContext(true, null, new String[]{\"field_1*\"});\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_11\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"fields [field_11] required by field_processors are not included in source filtering.\"));\n+    }\n \n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"fields [field_11] required by field_processors are not included in source filtering.\"));\n-            sourceFiltering = null;\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_MissingAnalyzedField() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        analyzedFields = new FetchSourceContext(true, null, new String[]{\"field_1*\"});\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_11\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-        {\n-            analyzedFields = new FetchSourceContext(true, null, new String[]{\"field_1*\"});\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_11\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"fields [field_11] required by field_processors are not included in the analyzed_fields\"));\n+    }\n \n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"fields [field_11] required by field_processors are not included in the analyzed_fields\"));\n-            analyzedFields = null;\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_RequiredMultiFields() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_31.child\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\", Arrays.asList(buildPreProcessor(\"field_31.child\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"feature_processors cannot be applied to required fields for analysis; \"));\n \n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"feature_processors cannot be applied to required fields for analysis; \"));\n+        extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31.child\", Arrays.asList(buildPreProcessor(\"field_31\", \"foo\"))),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-            extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31.child\", Arrays.asList(buildPreProcessor(\"field_31\", \"foo\"))),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n+        ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"feature_processors cannot be applied to required fields for analysis; \"));\n+    }\n \n-            ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"feature_processors cannot be applied to required fields for analysis; \"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_BothMultiFields() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\",\n+                Arrays.asList(\n+                    buildPreProcessor(\"field_21\", \"foo\"),\n+                    buildPreProcessor(\"field_21.child\", \"bar\")\n+                )),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\",\n-                    Arrays.asList(\n-                        buildPreProcessor(\"field_21\", \"foo\"),\n-                        buildPreProcessor(\"field_21.child\", \"bar\")\n-                        )),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"feature_processors refer to both multi-field \"));\n-        }\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"feature_processors refer to both multi-field \"));\n+    }\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\",\n-                    Arrays.asList(\n-                        buildPreProcessor(\"field_11\", \"foo\"),\n-                        buildPreProcessor(\"field_21\", \"foo\")\n-                    )),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\"feature_processors must define unique output field names; duplicate fields [foo]\"));\n-        }\n+    public void testDetect_givenFeatureProcessorsFailures_DuplicateOutputFields() {\n+        FieldCapabilitiesResponse fieldCapabilities = simpleFieldResponse();\n+        ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n+            buildRegressionConfig(\"field_31\",\n+                Arrays.asList(\n+                    buildPreProcessor(\"field_11\", \"foo\"),\n+                    buildPreProcessor(\"field_21\", \"foo\")\n+                )),\n+            100,\n+            fieldCapabilities,\n+            Collections.emptyMap());\n \n-        {\n-            ExtractedFieldsDetector extractedFieldsDetector = new ExtractedFieldsDetector(\n-                buildRegressionConfig(\"field_31\",\n-                    Arrays.asList(\n-                        buildPreProcessor(\"field_11\", \"field_21\")\n-                    )),\n-                100,\n-                fieldCapabilities,\n-                Collections.emptyMap());\n-\n-            ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n-            assertThat(ex.getMessage(),\n-                containsString(\n-                    \"feature_processors output fields must not include non-processed analysis fields; duplicate fields [field_21]\"));\n-        }\n+        ElasticsearchStatusException ex = expectThrows(ElasticsearchStatusException.class, extractedFieldsDetector::detect);\n+        assertThat(ex.getMessage(),\n+            containsString(\"feature_processors must define unique output field names; duplicate fields [foo]\"));\n     }\n \n     public void testDetect_withFeatureProcessors() {\n"}}, {"oid": "b923b15f64db3a929952daa79bb5e4b5b4657c03", "url": "https://github.com/elastic/elasticsearch/commit/b923b15f64db3a929952daa79bb5e4b5b4657c03", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-dfa-add-processors", "committedDate": "2020-08-13T17:56:33Z", "type": "commit"}, {"oid": "7ad152088ab7cb87977d19dc6881bead402927b6", "url": "https://github.com/elastic/elasticsearch/commit/7ad152088ab7cb87977d19dc6881bead402927b6", "message": "adjusting output, addressing pr comments", "committedDate": "2020-08-13T19:02:40Z", "type": "commit"}, {"oid": "f8951d09f16c56361abc1d8ed8d36e54b7ae521d", "url": "https://github.com/elastic/elasticsearch/commit/f8951d09f16c56361abc1d8ed8d36e54b7ae521d", "message": "fixing formatting", "committedDate": "2020-08-13T19:04:20Z", "type": "commit"}]}