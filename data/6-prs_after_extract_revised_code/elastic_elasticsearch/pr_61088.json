{"pr_number": 61088, "pr_title": "Stabilize testSnapshotDeleteRelocatingPrimaryIndex", "pr_createdAt": "2020-08-13T11:26:11Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/61088", "timeline": [{"oid": "7a88f7c288902c1641d24ae98f4e630547e91b18", "url": "https://github.com/elastic/elasticsearch/commit/7a88f7c288902c1641d24ae98f4e630547e91b18", "message": "Stabilize testSnapshotDeleteRelocatingPrimaryIndex\n\nWith `100` documents the relocation might finish before the snapshot starts\ncausing no shards to fail snapshotting as expected.\n\nCloses #61069", "committedDate": "2020-08-13T11:17:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5MzQ0OA==", "url": "https://github.com/elastic/elasticsearch/pull/61088#discussion_r469893448", "bodyText": "Can we instead block relocation from completing? Otherwise there's still theoretically a race (albeit less likely)", "author": "ywelsch", "createdAt": "2020-08-13T11:49:46Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java", "diffHunk": "@@ -2044,7 +2044,8 @@ public void testSnapshotDeleteRelocatingPrimaryIndex() throws Exception {\n         final String indexName = \"test-idx\";\n         assertAcked(prepareCreate(indexName, 2, indexSettingsNoReplicas(between(2, 10))));\n         ensureGreen(indexName);\n-        indexRandomDocs(indexName, 100);\n+        // Use a large number of documents so the relocation below takes long enough for the snapshot to run concurrently\n+        indexRandomDocs(indexName, 25000);", "originalCommit": "7a88f7c288902c1641d24ae98f4e630547e91b18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5NDk5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/61088#discussion_r469894999", "bodyText": "Do we have a pre-packaged way of doing that in tests? (I couldn't find one, hence this fix) I could try to come up with one if we don't but it looks like that would take a bit of work.", "author": "original-brownbear", "createdAt": "2020-08-13T11:53:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5MzQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5Njc2NA==", "url": "https://github.com/elastic/elasticsearch/pull/61088#discussion_r469896764", "bodyText": "Something along the lines of IndexRecoveryIT.RecoveryActionBlocker", "author": "ywelsch", "createdAt": "2020-08-13T11:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5MzQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTkzODE1OA==", "url": "https://github.com/elastic/elasticsearch/pull/61088#discussion_r469938158", "bodyText": "Thanks! Could've though of that myself \ud83e\udd26 -> moved the test to the dedicated cluster tests now for this so I can just black-hole the file chunk requests but don't have to bother with cleaning up the cluster networking after the test.", "author": "original-brownbear", "createdAt": "2020-08-13T13:09:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg5MzQ0OA=="}], "type": "inlineReview", "revised_code": {"commit": "168c4105835a789a2bcfb0c269fa19f3e03e5df6", "chunk": "diff --git a/server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java b/server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\nindex 6030d787ae5..b017ee1a671 100644\n--- a/server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\n+++ b/server/src/internalClusterTest/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java\n\n@@ -2036,39 +2036,6 @@ public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCas\n         logger.info(\"--> done\");\n     }\n \n-    public void testSnapshotDeleteRelocatingPrimaryIndex() throws Exception {\n-        final String repoName = \"test-repo\";\n-        createRepository(repoName, \"fs\");\n-\n-        // Create index on two nodes and make sure each node has a primary by setting no replicas\n-        final String indexName = \"test-idx\";\n-        assertAcked(prepareCreate(indexName, 2, indexSettingsNoReplicas(between(2, 10))));\n-        ensureGreen(indexName);\n-        // Use a large number of documents so the relocation below takes long enough for the snapshot to run concurrently\n-        indexRandomDocs(indexName, 25000);\n-\n-        logger.info(\"--> start relocations\");\n-        allowNodes(indexName, 1);\n-\n-        logger.info(\"--> wait for relocations to start\");\n-\n-        assertBusy(() -> assertThat(\n-                client().admin().cluster().prepareHealth(indexName).execute().actionGet().getRelocatingShards(), greaterThan(0)),\n-                1L, TimeUnit.MINUTES);\n-\n-        logger.info(\"--> snapshot\");\n-        client().admin().cluster().prepareCreateSnapshot(repoName, \"test-snap\")\n-                .setWaitForCompletion(false).setPartial(true).setIndices(indexName).get();\n-\n-        assertAcked(client().admin().indices().prepareDelete(indexName));\n-\n-        logger.info(\"--> wait for snapshot to complete\");\n-        SnapshotInfo snapshotInfo = waitForCompletion(repoName, \"test-snap\", TimeValue.timeValueSeconds(600));\n-        assertThat(snapshotInfo.state(), equalTo(SnapshotState.PARTIAL));\n-        assertThat(snapshotInfo.shardFailures().size(), greaterThan(0));\n-        logger.info(\"--> done\");\n-    }\n-\n     public void testSnapshotMoreThanOnce() throws InterruptedException {\n         Client client = client();\n \n"}}, {"oid": "168c4105835a789a2bcfb0c269fa19f3e03e5df6", "url": "https://github.com/elastic/elasticsearch/commit/168c4105835a789a2bcfb0c269fa19f3e03e5df6", "message": "CR: block relocation by black-holing file chunks", "committedDate": "2020-08-13T13:06:45Z", "type": "commit"}]}