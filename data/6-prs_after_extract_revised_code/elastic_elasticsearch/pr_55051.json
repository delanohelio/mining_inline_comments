{"pr_number": 55051, "pr_title": "Provide repository-level stats for searchable snapshots", "pr_createdAt": "2020-04-10T12:10:01Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55051", "timeline": [{"oid": "444955d21014f0a8f6992b11f35d67535f4e1444", "url": "https://github.com/elastic/elasticsearch/commit/444955d21014f0a8f6992b11f35d67535f4e1444", "message": "Provide repository-level stats for searchable snapshots", "committedDate": "2020-04-10T12:04:13Z", "type": "commit"}, {"oid": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "url": "https://github.com/elastic/elasticsearch/commit/d060429f92dc2938e0c800f8bfd6bd497579c1d6", "message": "Merge remote-tracking branch 'elastic/master' into record-list-get-calls", "committedDate": "2020-04-10T12:04:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc0OTEwMw==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406749103", "bodyText": "Just a general question (will try to review properly shortly):  Should this maybe live in x-pack core since this isn't just a searchable snapshots related piece of functionality and we have plans to use it elsewhere also?", "author": "original-brownbear", "createdAt": "2020-04-10T13:07:01Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/rest/RestRepositoryStatsAction.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.rest;\n+\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.rest.BaseRestHandler;\n+import org.elasticsearch.rest.RestHandler;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.action.RestToXContentListener;\n+import org.elasticsearch.xpack.searchablesnapshots.action.RepositoryStatsAction;\n+import org.elasticsearch.xpack.searchablesnapshots.action.RepositoryStatsRequest;\n+\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.GET;\n+\n+public class RestRepositoryStatsAction extends BaseRestHandler {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MjA2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406752061", "bodyText": "I wanted to keep the scope small here so that we can iterate more quickly on this API. For now, the scope of this is only targeting searchable snapshot investigations. We can at a later stage discuss whether this change is more broadly usable. The main issue with the stats reported here are that they're reset as soon as a repository is updated or a node is restarted, which might make this a confusing API. The core functionality for tracing, that might be useful in the context of Cloud, is in the respective blobstore implementation, and might be exposed differently (e.g. periodic logging)", "author": "ywelsch", "createdAt": "2020-04-10T13:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc0OTEwMw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NzI3NA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406757274", "bodyText": "This fails reproducibly for me with  -Dtests.seed=73DAD8B23C19870D", "author": "original-brownbear", "createdAt": "2020-04-10T13:28:46Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "chunk": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\nindex 880c2cb506b..247e1ddd466 100644\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n\n@@ -235,23 +235,35 @@ public class S3BlobStoreRepositoryTests extends ESMockAPIBasedRepositoryIntegTes\n \n         final long getCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).getCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    return count + ((S3HttpHandler) h).getCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n-        final long listCalls = handlers.values().stream().filter(h -> h instanceof S3HttpHandler)\n+        final long listCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).listCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    return count + ((S3HttpHandler) h).listCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MTk4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406761989", "bodyText": "You probably don't want this filter because it prevents you from seeing the erroneous handlers below in the mapping.", "author": "original-brownbear", "createdAt": "2020-04-10T13:40:37Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                if (h instanceof S3HttpHandler) {\n+                    return ((S3HttpHandler) h).getCalls.get();\n+                } else if (h instanceof S3ErroneousHttpHandler) {\n+                    return ((S3ErroneousHttpHandler) h).getCalls.get();\n+                } else {\n+                    return 0L;\n+                }\n+            })\n+            .sum();\n+        final long listCalls = handlers.values().stream().filter(h -> h instanceof S3HttpHandler)", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "chunk": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\nindex 880c2cb506b..247e1ddd466 100644\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n\n@@ -235,23 +235,35 @@ public class S3BlobStoreRepositoryTests extends ESMockAPIBasedRepositoryIntegTes\n \n         final long getCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).getCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    return count + ((S3HttpHandler) h).getCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n-        final long listCalls = handlers.values().stream().filter(h -> h instanceof S3HttpHandler)\n+        final long listCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).listCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    return count + ((S3HttpHandler) h).listCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MzQ5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406763497", "bodyText": "This won't work (I think that's the reason for the test failure I mentioned). The handlers field does not contain the erroneous handler wrappers.See org.elasticsearch.repositories.blobstore.ESMockAPIBasedRepositoryIntegTestCase#setUpHttpServer:\n    @Before\n    public void setUpHttpServer() {\n        handlers = createHttpHandlers();\n        handlers.forEach((c, h) -> httpServer.createContext(c, wrap(randomBoolean() ? createErroneousHttpHandler(h) : h, logger)));\n    }\n\nyou'll have to put the erroneous handlers into another map (so you get the counts from both the normal and the erroneous wrappers by going over both maps) or similar.", "author": "original-brownbear", "createdAt": "2020-04-10T13:44:24Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2NzI2MA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407967260", "bodyText": "I think we could add a counting http handler that would wrap the handlers (similarly to what ExceptionCatchingHttpHandler does) and that would update counters when receiving an HttpExchange.\nI think we're interesting in couting all GETs including the retries?", "author": "tlrx", "createdAt": "2020-04-14T08:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MzQ5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "chunk": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\nindex 880c2cb506b..247e1ddd466 100644\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n\n@@ -235,23 +235,35 @@ public class S3BlobStoreRepositoryTests extends ESMockAPIBasedRepositoryIntegTes\n \n         final long getCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).getCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    return count + ((S3HttpHandler) h).getCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n-        final long listCalls = handlers.values().stream().filter(h -> h instanceof S3HttpHandler)\n+        final long listCalls = handlers.values().stream()\n             .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n                 if (h instanceof S3HttpHandler) {\n-                    return ((S3HttpHandler) h).listCalls.get();\n-                } else if (h instanceof S3ErroneousHttpHandler) {\n-                    return ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    return count + ((S3HttpHandler) h).listCalls.get();\n                 } else {\n-                    return 0L;\n+                    assert false;\n+                    return count;\n                 }\n             })\n             .sum();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2NDUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406764504", "bodyText": "NIT: Revert", "author": "original-brownbear", "createdAt": "2020-04-10T13:47:01Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java", "diffHunk": "@@ -135,4 +151,5 @@ public static CannedAccessControlList initCannedACL(String cannedACL) {\n \n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n+", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "chunk": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\nindex b9ac1af1ef3..d635b2869e7 100644\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\n\n@@ -152,4 +174,17 @@ class S3BlobStore implements BlobStore {\n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n \n+    static class S3Stats {\n+\n+        final AtomicLong listCount = new AtomicLong();\n+\n+        final AtomicLong getCount = new AtomicLong();\n+\n+        Map<String, Long> toMap() {\n+            final Map<String, Long> results = new HashMap<>();\n+            results.put(\"GET\", getCount.get());\n+            results.put(\"LIST\", listCount.get());\n+            return results;\n+        }\n+    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2NjAwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406766004", "bodyText": "You could just keep these collectors as fields on S3BlobStore and have getters for them on it?\nThen you save adding new fields to the retrying input stream and containers and don't have to create a new instance for every container + get request.", "author": "original-brownbear", "createdAt": "2020-04-10T13:50:24Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java", "diffHunk": "@@ -78,10 +82,22 @@\n     private final S3BlobStore blobStore;\n     private final String keyPath;\n \n+    private final RequestMetricCollector listMetricCollector;\n+\n     S3BlobContainer(BlobPath path, S3BlobStore blobStore) {\n         super(path);\n         this.blobStore = blobStore;\n         this.keyPath = path.buildAsString();\n+        this.listMetricCollector = new RequestMetricCollector() {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "chunk": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java\nindex 91facc654ae..177512784b3 100644\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java\n\n@@ -82,22 +78,10 @@ class S3BlobContainer extends AbstractBlobContainer {\n     private final S3BlobStore blobStore;\n     private final String keyPath;\n \n-    private final RequestMetricCollector listMetricCollector;\n-\n     S3BlobContainer(BlobPath path, S3BlobStore blobStore) {\n         super(path);\n         this.blobStore = blobStore;\n         this.keyPath = path.buildAsString();\n-        this.listMetricCollector = new RequestMetricCollector() {\n-            @Override\n-            public void collectMetrics(Request<?> request, Response<?> response) {\n-                assert request.getHttpMethod().name().equals(\"GET\");\n-                final Number requestCount = request.getAWSRequestMetrics().getTimingInfo()\n-                    .getCounter(AWSRequestMetrics.Field.RequestCount.name());\n-                assert requestCount != null;\n-                blobStore.modifiableStats().listCount.addAndGet(requestCount.longValue());\n-            }\n-        };\n     }\n \n     @Override\n"}}, {"oid": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "url": "https://github.com/elastic/elasticsearch/commit/6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "message": "Armin's feedback", "committedDate": "2020-04-14T07:01:31Z", "type": "commit"}, {"oid": "af17d17ea8cab8976be6c4e695775a7c9006e10e", "url": "https://github.com/elastic/elasticsearch/commit/af17d17ea8cab8976be6c4e695775a7c9006e10e", "message": "Merge remote-tracking branch 'elastic/master' into record-list-get-calls", "committedDate": "2020-04-14T07:02:04Z", "type": "commit"}, {"oid": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "url": "https://github.com/elastic/elasticsearch/commit/fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "message": "forbiddenAPIs", "committedDate": "2020-04-14T07:48:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk1OTAzMA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407959030", "bodyText": "Since it's an inner class, maybe just call it Stats", "author": "tlrx", "createdAt": "2020-04-14T08:31:16Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java", "diffHunk": "@@ -135,4 +173,18 @@ public static CannedAccessControlList initCannedACL(String cannedACL) {\n \n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n+\n+    static class S3Stats {", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "chunk": "diff --git a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\nindex d635b2869e7..cec264efe8e 100644\n--- a/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\n+++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java\n\n@@ -174,7 +174,7 @@ class S3BlobStore implements BlobStore {\n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n \n-    static class S3Stats {\n+    static class Stats {\n \n         final AtomicLong listCount = new AtomicLong();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MzU2OA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407963568", "bodyText": "Can you remove the log message and add them to the assertEquals() methods instead?", "author": "tlrx", "createdAt": "2020-04-14T08:38:48Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,94 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n+                if (h instanceof S3HttpHandler) {\n+                    return count + ((S3HttpHandler) h).getCalls.get();\n+                } else {\n+                    assert false;\n+                    return count;\n+                }\n+            })\n+            .sum();\n+        final long listCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n+                if (h instanceof S3HttpHandler) {\n+                    return count + ((S3HttpHandler) h).listCalls.get();\n+                } else {\n+                    assert false;\n+                    return count;\n+                }\n+            })\n+            .sum();\n+\n+        logger.info(\"SDK sent {} GET calls and handler measured {} GET calls\", sdkGetCalls, getCalls);", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "chunk": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\nindex 247e1ddd466..e3fab59e7d4 100644\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n\n@@ -228,51 +228,38 @@ public class S3BlobStoreRepositoryTests extends ESMockAPIBasedRepositoryIntegTes\n             })\n             .filter(r -> r != null)\n             .map(r -> r.stats())\n-            .reduce((s1, s2) -> s1.combine(s2))\n+            .reduce((s1, s2) -> s1.merge(s2))\n             .get();\n         final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n         final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n \n         final long getCalls = handlers.values().stream()\n             .mapToLong(h -> {\n-                long count = 0;\n                 while (h instanceof DelegatingHttpHandler) {\n-                    if (h instanceof S3ErroneousHttpHandler) {\n-                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    if (h instanceof S3StatsHttpHandler) {\n+                        return ((S3StatsHttpHandler) h).getCalls.get();\n                     }\n                     h = ((DelegatingHttpHandler) h).getDelegate();\n                 }\n-                if (h instanceof S3HttpHandler) {\n-                    return count + ((S3HttpHandler) h).getCalls.get();\n-                } else {\n-                    assert false;\n-                    return count;\n-                }\n+                assert false;\n+                return 0L;\n             })\n             .sum();\n         final long listCalls = handlers.values().stream()\n             .mapToLong(h -> {\n-                long count = 0;\n                 while (h instanceof DelegatingHttpHandler) {\n-                    if (h instanceof S3ErroneousHttpHandler) {\n-                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    if (h instanceof S3StatsHttpHandler) {\n+                        return ((S3StatsHttpHandler) h).listCalls.get();\n                     }\n                     h = ((DelegatingHttpHandler) h).getDelegate();\n                 }\n-                if (h instanceof S3HttpHandler) {\n-                    return count + ((S3HttpHandler) h).listCalls.get();\n-                } else {\n-                    assert false;\n-                    return count;\n-                }\n+                assert false;\n+                return 0L;\n             })\n             .sum();\n \n-        logger.info(\"SDK sent {} GET calls and handler measured {} GET calls\", sdkGetCalls, getCalls);\n-        logger.info(\"SDK sent {} LIST calls and handler measured {} LIST calls\", sdkListCalls, listCalls);\n-\n-        assertEquals(getCalls, sdkGetCalls);\n-        assertEquals(listCalls, sdkListCalls);\n+        assertEquals(\"SDK sent \" + sdkGetCalls + \" GET calls and handler measured \" + getCalls + \" GET calls\", getCalls, sdkGetCalls);\n+        assertEquals(\"SDK sent \" + sdkListCalls + \" LIST calls and handler measured \" + listCalls + \" LIST calls\", listCalls, sdkListCalls);\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2NzU2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407967566", "bodyText": "I'd move this in a dedicated HttpHandler that would wrap other handlers", "author": "tlrx", "createdAt": "2020-04-14T08:45:06Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -256,10 +355,24 @@ private void validateAuthHeader(HttpExchange exchange) {\n     @SuppressForbidden(reason = \"this test uses a HttpServer to emulate an S3 endpoint\")\n     private static class S3ErroneousHttpHandler extends ErroneousHttpHandler {\n \n+        public final AtomicLong getCalls = new AtomicLong();", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "chunk": "diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\nindex 247e1ddd466..e3fab59e7d4 100644\n--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java\n\n@@ -355,28 +342,43 @@ public class S3BlobStoreRepositoryTests extends ESMockAPIBasedRepositoryIntegTes\n     @SuppressForbidden(reason = \"this test uses a HttpServer to emulate an S3 endpoint\")\n     private static class S3ErroneousHttpHandler extends ErroneousHttpHandler {\n \n+        S3ErroneousHttpHandler(final HttpHandler delegate, final int maxErrorsPerRequest) {\n+            super(delegate, maxErrorsPerRequest);\n+        }\n+\n+        @Override\n+        protected String requestUniqueId(final HttpExchange exchange) {\n+            // Amazon SDK client provides a unique ID per request\n+            return exchange.getRequestHeaders().getFirst(AmazonHttpClient.HEADER_SDK_TRANSACTION_ID);\n+        }\n+    }\n+\n+    @SuppressForbidden(reason = \"this test uses a HttpServer to emulate an S3 endpoint\")\n+    private static class S3StatsHttpHandler implements DelegatingHttpHandler {\n+\n+        private final HttpHandler delegate;\n+\n         public final AtomicLong getCalls = new AtomicLong();\n         public final AtomicLong listCalls = new AtomicLong();\n \n-        S3ErroneousHttpHandler(final HttpHandler delegate, final int maxErrorsPerRequest) {\n-            super(delegate, maxErrorsPerRequest);\n+        S3StatsHttpHandler(final HttpHandler delegate) {\n+            this.delegate = delegate;\n+        }\n+\n+        @Override\n+        public HttpHandler getDelegate() {\n+            return delegate;\n         }\n \n         @Override\n-        protected void handleAsError(final HttpExchange exchange) throws IOException {\n+        public void handle(HttpExchange exchange) throws IOException {\n             final String request = exchange.getRequestMethod() + \" \" + exchange.getRequestURI().toString();\n             if (Regex.simpleMatch(\"GET /*/?prefix=*\", request)) {\n                 listCalls.incrementAndGet();\n             } else if (Regex.simpleMatch(\"GET /*/*\", request)) {\n                 getCalls.incrementAndGet();\n             }\n-            super.handleAsError(exchange);\n-        }\n-\n-        @Override\n-        protected String requestUniqueId(final HttpExchange exchange) {\n-            // Amazon SDK client provides a unique ID per request\n-            return exchange.getRequestHeaders().getFirst(AmazonHttpClient.HEADER_SDK_TRANSACTION_ID);\n+            delegate.handle(exchange);\n         }\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2OTI1NA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407969254", "bodyText": "Maybe rename this method to merge? (to be consistent with other Stats classes that have similar methods like ForecastStats, SnapshotPolicyStats etc)", "author": "tlrx", "createdAt": "2020-04-14T08:47:54Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.repositories;\n+\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class RepositoryStats implements Writeable {\n+\n+    public static final RepositoryStats EMPTY_STATS = new RepositoryStats(Collections.emptyMap());\n+\n+    public final Map<String, Long> requestCounts;\n+\n+    public RepositoryStats(Map<String, Long> requestCounts) {\n+        this.requestCounts = Collections.unmodifiableMap(requestCounts);\n+    }\n+\n+    public RepositoryStats(StreamInput in) throws IOException {\n+        this.requestCounts = in.readMap(StreamInput::readString, StreamInput::readLong);\n+    }\n+\n+    public RepositoryStats combine(RepositoryStats otherStats) {", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java\nindex e236b46dfe7..50a8b466301 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java\n\n@@ -42,7 +42,7 @@ public class RepositoryStats implements Writeable {\n         this.requestCounts = in.readMap(StreamInput::readString, StreamInput::readLong);\n     }\n \n-    public RepositoryStats combine(RepositoryStats otherStats) {\n+    public RepositoryStats merge(RepositoryStats otherStats) {\n         final Map<String, Long> result = new HashMap<>();\n         result.putAll(requestCounts);\n         for (Map.Entry<String, Long> entry : otherStats.requestCounts.entrySet()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3NDg0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407974841", "bodyText": "Should we catch the repository missing exception here - in case the repository is not yet known by this node - and return empty stats too?", "author": "tlrx", "createdAt": "2020-04-14T08:56:30Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/action/TransportRepositoryStatsAction.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.action;\n+\n+import org.elasticsearch.action.FailedNodeException;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.nodes.TransportNodesAction;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class TransportRepositoryStatsAction extends TransportNodesAction<\n+    RepositoryStatsRequest,\n+    RepositoryStatsResponse,\n+    RepositoryStatsNodeRequest,\n+    RepositoryStatsNodeResponse> {\n+\n+    private final RepositoriesService repositoriesService;\n+    private final XPackLicenseState licenseState;\n+\n+    @Inject\n+    public TransportRepositoryStatsAction(\n+        ThreadPool threadPool,\n+        ClusterService clusterService,\n+        TransportService transportService,\n+        ActionFilters actionFilters,\n+        RepositoriesService repositoriesService,\n+        XPackLicenseState licenseState\n+    ) {\n+        super(\n+            RepositoryStatsAction.NAME,\n+            threadPool,\n+            clusterService,\n+            transportService,\n+            actionFilters,\n+            RepositoryStatsRequest::new,\n+            RepositoryStatsNodeRequest::new,\n+            ThreadPool.Names.SAME,\n+            RepositoryStatsNodeResponse.class\n+        );\n+        this.repositoriesService = repositoriesService;\n+        this.licenseState = Objects.requireNonNull(licenseState);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsResponse newResponse(\n+        RepositoryStatsRequest request,\n+        List<RepositoryStatsNodeResponse> nodes,\n+        List<FailedNodeException> failures\n+    ) {\n+        return new RepositoryStatsResponse(clusterService.getClusterName(), nodes, failures);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeRequest newNodeRequest(RepositoryStatsRequest request) {\n+        return new RepositoryStatsNodeRequest(request.getRepository());\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeResponse newNodeResponse(StreamInput in) throws IOException {\n+        return new RepositoryStatsNodeResponse(in);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeResponse nodeOperation(RepositoryStatsNodeRequest request, Task task) {\n+        SearchableSnapshots.ensureValidLicense(licenseState);\n+        if (clusterService.localNode().isMasterNode() == false && clusterService.localNode().isDataNode() == false) {\n+            return new RepositoryStatsNodeResponse(clusterService.localNode(), RepositoryStats.EMPTY_STATS);\n+        }\n+        final Repository repository = repositoriesService.repository(request.getRepository());", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAxMDExNg==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r408010116", "bodyText": "I would like to avoid that as it would then silently provide partial stats", "author": "ywelsch", "createdAt": "2020-04-14T09:51:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3NDg0MQ=="}], "type": "inlineReview", "revised_code": null}, {"oid": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "url": "https://github.com/elastic/elasticsearch/commit/08ce54c2a45499436defb023b1f3d68a6ed075a2", "message": "Tanguy feedback", "committedDate": "2020-04-14T10:03:38Z", "type": "commit"}]}