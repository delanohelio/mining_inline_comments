{"pr_number": 55293, "pr_title": "Make RepositoryData Less Memory Heavy", "pr_createdAt": "2020-04-16T09:35:50Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55293", "timeline": [{"oid": "13cb49a81148ca6d9c73c5fcecb592253ce8d5c6", "url": "https://github.com/elastic/elasticsearch/commit/13cb49a81148ca6d9c73c5fcecb592253ce8d5c6", "message": "Make RepositoryData Less Memory Heavy\n\nWe don't really need `LinkedHashSet` here. We can assume that all the\nentries are unique and just use a list and use the list utilities to\ncreate the cheapest possible version of the list.\nAlso, this fixes a bug in `addSnapshot` which would mutate the existing\nlinked hash set on the current instance (fortunately this never caused a real world bug)\nand brings the collection in line with the java docs on its getter that claim immutability.", "committedDate": "2020-04-16T09:27:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQyNTQ4MA==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r409425480", "bodyText": "This was broken, we were mutating the existing LinkedHashSet", "author": "original-brownbear", "createdAt": "2020-04-16T09:46:29Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);", "originalCommit": "13cb49a81148ca6d9c73c5fcecb592253ce8d5c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8319e2116d138668e38c3a72b709a8889868088a", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\nindex 5f14411c134..d0ba06ff674 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n\n@@ -220,9 +220,10 @@ public final class RepositoryData {\n             if (snapshotIds == null) {\n                 allIndexSnapshots.put(indexId, List.of(snapshotId));\n             } else {\n-                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds.size() + 1);\n+                copy.addAll(snapshotIds);\n                 copy.add(snapshotId);\n-                allIndexSnapshots.put(indexId, List.copyOf(copy));\n+                allIndexSnapshots.put(indexId, Collections.unmodifiableList(copy));\n             }\n         }\n         return new RepositoryData(genId, snapshots, newSnapshotStates, newSnapshotVersions, allIndexSnapshots,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQyODMwNw==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r409428307", "bodyText": "Not great that we're quadratic here now (for the nested loop), but I don't think it really matters much relative to the significant space+GC savings.", "author": "original-brownbear", "createdAt": "2020-04-16T09:51:09Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -253,23 +261,24 @@ public RepositoryData removeSnapshot(final SnapshotId snapshotId, final ShardGen\n         newSnapshotStates.remove(snapshotId.getUUID());\n         final Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.remove(snapshotId.getUUID());\n-        Map<IndexId, Set<SnapshotId>> indexSnapshots = new HashMap<>();\n+        Map<IndexId, List<SnapshotId>> indexSnapshots = new HashMap<>();\n         for (final IndexId indexId : indices.values()) {\n-            Set<SnapshotId> set;\n-            Set<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n+            List<SnapshotId> remaining;\n+            List<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n             assert snapshotIds != null;\n             if (snapshotIds.contains(snapshotId)) {", "originalCommit": "13cb49a81148ca6d9c73c5fcecb592253ce8d5c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b267d9c4ad95e220544c773d01750e886283d471", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\nindex 5f14411c134..da2ffc26ac2 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n\n@@ -266,14 +266,15 @@ public final class RepositoryData {\n             List<SnapshotId> remaining;\n             List<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n             assert snapshotIds != null;\n-            if (snapshotIds.contains(snapshotId)) {\n+            final int listIndex = snapshotIds.indexOf(snapshotId);\n+            if (listIndex > -1) {\n                 if (snapshotIds.size() == 1) {\n                     // removing the snapshot will mean no more snapshots\n                     // have this index, so just skip over it\n                     continue;\n                 }\n                 remaining = new ArrayList<>(snapshotIds);\n-                remaining.remove(snapshotId);\n+                remaining.remove(listIndex);\n                 remaining = List.copyOf(remaining);\n             } else {\n                 remaining = snapshotIds;\n"}}, {"oid": "b267d9c4ad95e220544c773d01750e886283d471", "url": "https://github.com/elastic/elasticsearch/commit/b267d9c4ad95e220544c773d01750e886283d471", "message": "at least be a little efficient", "committedDate": "2020-04-16T10:12:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411158448", "bodyText": "why create a copy of the copy?", "author": "ywelsch", "createdAt": "2020-04-20T07:35:33Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -213,9 +214,16 @@ public RepositoryData addSnapshot(final SnapshotId snapshotId,\n         newSnapshotStates.put(snapshotId.getUUID(), snapshotState);\n         Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.put(snapshotId.getUUID(), version);\n-        Map<IndexId, Set<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n+        Map<IndexId, List<SnapshotId>> allIndexSnapshots = new HashMap<>(indexSnapshots);\n         for (final IndexId indexId : shardGenerations.indices()) {\n-            allIndexSnapshots.computeIfAbsent(indexId, k -> new LinkedHashSet<>()).add(snapshotId);\n+            final List<SnapshotId> snapshotIds = allIndexSnapshots.get(indexId);\n+            if (snapshotIds == null) {\n+                allIndexSnapshots.put(indexId, List.of(snapshotId));\n+            } else {\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                copy.add(snapshotId);\n+                allIndexSnapshots.put(indexId, List.copyOf(copy));", "originalCommit": "b267d9c4ad95e220544c773d01750e886283d471", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTIwODIyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411208229", "bodyText": "These RepositoryData instances live for quite a while, so I figured the cost of doing another copy is worth the lower storage overhead + shorter path to the GC root compared to wrapping with Collections.unmodifiableList? I could technically make this more efficient by copying to a SnapshotId[] and then just wrapping that array but I figured this wasn't that much slower and nicer to read.", "author": "original-brownbear", "createdAt": "2020-04-20T08:55:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM4NzE3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411387173", "bodyText": "I looked into how List.copyOf is implemented, and lo and behold, it copies the elements twice (first calls Collection.toArray(), and then creates another copy of that temporary array in List.of (using manual for loop, FFS).\nThis means that the list is copied three times here, plus the resize of the ArrayList when calling copy.add(snapshotId);, leading to another full copy ....\nHigh-level languages ftw.", "author": "ywelsch", "createdAt": "2020-04-20T13:42:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQxMDQzMg==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411410432", "bodyText": ":) you win => I pushed 8319e21 , probably not worth the hassle to go further than this then.", "author": "original-brownbear", "createdAt": "2020-04-20T14:11:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODQ0OA=="}], "type": "inlineReview", "revised_code": {"commit": "8319e2116d138668e38c3a72b709a8889868088a", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\nindex da2ffc26ac2..d0ba06ff674 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n\n@@ -220,9 +220,10 @@ public final class RepositoryData {\n             if (snapshotIds == null) {\n                 allIndexSnapshots.put(indexId, List.of(snapshotId));\n             } else {\n-                final List<SnapshotId> copy = new ArrayList<>(snapshotIds);\n+                final List<SnapshotId> copy = new ArrayList<>(snapshotIds.size() + 1);\n+                copy.addAll(snapshotIds);\n                 copy.add(snapshotId);\n-                allIndexSnapshots.put(indexId, List.copyOf(copy));\n+                allIndexSnapshots.put(indexId, Collections.unmodifiableList(copy));\n             }\n         }\n         return new RepositoryData(genId, snapshots, newSnapshotStates, newSnapshotVersions, allIndexSnapshots,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTQ1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411159451", "bodyText": "same thing here, copy of copy", "author": "ywelsch", "createdAt": "2020-04-20T07:37:23Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -253,23 +261,25 @@ public RepositoryData removeSnapshot(final SnapshotId snapshotId, final ShardGen\n         newSnapshotStates.remove(snapshotId.getUUID());\n         final Map<String, Version> newSnapshotVersions = new HashMap<>(snapshotVersions);\n         newSnapshotVersions.remove(snapshotId.getUUID());\n-        Map<IndexId, Set<SnapshotId>> indexSnapshots = new HashMap<>();\n+        Map<IndexId, List<SnapshotId>> indexSnapshots = new HashMap<>();\n         for (final IndexId indexId : indices.values()) {\n-            Set<SnapshotId> set;\n-            Set<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n+            List<SnapshotId> remaining;\n+            List<SnapshotId> snapshotIds = this.indexSnapshots.get(indexId);\n             assert snapshotIds != null;\n-            if (snapshotIds.contains(snapshotId)) {\n+            final int listIndex = snapshotIds.indexOf(snapshotId);\n+            if (listIndex > -1) {\n                 if (snapshotIds.size() == 1) {\n                     // removing the snapshot will mean no more snapshots\n                     // have this index, so just skip over it\n                     continue;\n                 }\n-                set = new LinkedHashSet<>(snapshotIds);\n-                set.remove(snapshotId);\n+                remaining = new ArrayList<>(snapshotIds);\n+                remaining.remove(listIndex);\n+                remaining = List.copyOf(remaining);", "originalCommit": "b267d9c4ad95e220544c773d01750e886283d471", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8319e2116d138668e38c3a72b709a8889868088a", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\nindex da2ffc26ac2..d0ba06ff674 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n\n@@ -275,7 +276,7 @@ public final class RepositoryData {\n                 }\n                 remaining = new ArrayList<>(snapshotIds);\n                 remaining.remove(listIndex);\n-                remaining = List.copyOf(remaining);\n+                remaining = Collections.unmodifiableList(remaining);\n             } else {\n                 remaining = snapshotIds;\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTg4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55293#discussion_r411159883", "bodyText": "copy of copy", "author": "ywelsch", "createdAt": "2020-04-20T07:38:06Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryData.java", "diffHunk": "@@ -513,7 +523,7 @@ public static RepositoryData snapshotsFromXContent(final XContentParser parser,\n                             }\n                         }\n                         assert indexId != null;\n-                        indexSnapshots.put(indexId, snapshotIds);\n+                        indexSnapshots.put(indexId, List.copyOf(snapshotIds));", "originalCommit": "b267d9c4ad95e220544c773d01750e886283d471", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8319e2116d138668e38c3a72b709a8889868088a", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\nindex da2ffc26ac2..d0ba06ff674 100644\n--- a/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n+++ b/server/src/main/java/org/elasticsearch/repositories/RepositoryData.java\n\n@@ -523,7 +524,7 @@ public final class RepositoryData {\n                             }\n                         }\n                         assert indexId != null;\n-                        indexSnapshots.put(indexId, List.copyOf(snapshotIds));\n+                        indexSnapshots.put(indexId, Collections.unmodifiableList(snapshotIds));\n                         for (int i = 0; i < gens.size(); i++) {\n                             shardGenerations.put(indexId, i, gens.get(i));\n                         }\n"}}, {"oid": "d99b2850790e86de5477bfcd1b50f0c7774e4300", "url": "https://github.com/elastic/elasticsearch/commit/d99b2850790e86de5477bfcd1b50f0c7774e4300", "message": "Merge remote-tracking branch 'elastic/master' into smaller-repository-data", "committedDate": "2020-04-20T13:44:55Z", "type": "commit"}, {"oid": "8319e2116d138668e38c3a72b709a8889868088a", "url": "https://github.com/elastic/elasticsearch/commit/8319e2116d138668e38c3a72b709a8889868088a", "message": "unmodifiable list it is :)", "committedDate": "2020-04-20T14:09:21Z", "type": "commit"}]}