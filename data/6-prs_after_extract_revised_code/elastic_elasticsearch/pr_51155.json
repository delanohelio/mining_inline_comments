{"pr_number": 51155, "pr_title": "Implement top_metrics agg", "pr_createdAt": "2020-01-17T13:33:41Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51155", "timeline": [{"oid": "0fb37b53efa864d65054bedcd6f5debd38470865", "url": "https://github.com/elastic/elasticsearch/commit/0fb37b53efa864d65054bedcd6f5debd38470865", "message": "Implement top_metrics agg\n\nThe `top_metrics` agg is kind of like `top_hits` but it only works on\ndoc values so it *should* be faster.\n\nAt this point it is fairly limited in that it only supports a single,\nnumeric sort and a single, numeric metric. And it only fetches the \"very\ntopest\" document worth of metric. We plan to support returning a\nconfigurable number of top metrics, requesting more than one metric and\nmore than one sort. And, eventually, non-numeric sorts and metrics. The\ntrick is doing those things fairly efficiently.\n\nCo-Authored by: Zachary Tong <zach@elastic.co>", "committedDate": "2020-01-17T13:33:03Z", "type": "commit"}, {"oid": "a105a6351ea8f0f23817ac6e9ae77785a4cf2858", "url": "https://github.com/elastic/elasticsearch/commit/a105a6351ea8f0f23817ac6e9ae77785a4cf2858", "message": "Moar tests", "committedDate": "2020-01-17T14:10:17Z", "type": "commit"}, {"oid": "4d2557d4c89fbfd6aa211780e2ea4f85cf5f0f0b", "url": "https://github.com/elastic/elasticsearch/commit/4d2557d4c89fbfd6aa211780e2ea4f85cf5f0f0b", "message": "Better", "committedDate": "2020-01-17T14:19:23Z", "type": "commit"}, {"oid": "5146563423e13c3199b335b274d528de0c2fba4a", "url": "https://github.com/elastic/elasticsearch/commit/5146563423e13c3199b335b274d528de0c2fba4a", "message": "Checkstyle", "committedDate": "2020-01-17T14:24:26Z", "type": "commit"}, {"oid": "12abffde5614ccd005252ebd7e33b942e084d662", "url": "https://github.com/elastic/elasticsearch/commit/12abffde5614ccd005252ebd7e33b942e084d662", "message": "Fixup docs compile", "committedDate": "2020-01-17T14:28:02Z", "type": "commit"}, {"oid": "a685e2936b9328c1b21c4d606f5aacc640dcffcd", "url": "https://github.com/elastic/elasticsearch/commit/a685e2936b9328c1b21c4d606f5aacc640dcffcd", "message": "Explain", "committedDate": "2020-01-17T14:41:12Z", "type": "commit"}, {"oid": "0f130d4ac9909f5a201cc6455cce643382260371", "url": "https://github.com/elastic/elasticsearch/commit/0f130d4ac9909f5a201cc6455cce643382260371", "message": "Sneaky sneaky", "committedDate": "2020-01-17T15:40:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAzNzAxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r368037019", "bodyText": "Note to self: this should blow up on the default case.", "author": "nik9000", "createdAt": "2020-01-17T16:55:03Z", "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.Writeable.Reader;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.AbstractWireSerializingTestCase;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.Collections.unmodifiableList;\n+import static java.util.stream.Collectors.toList;\n+\n+public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase<InternalTopMetrics> {\n+    private static final List<DocValueFormat> RANDOM_FORMATS = unmodifiableList(Arrays.asList(\n+            DocValueFormat.RAW, DocValueFormat.BINARY, DocValueFormat.BOOLEAN\n+    ));\n+\n+    @Override\n+    protected NamedWriteableRegistry getNamedWriteableRegistry() {\n+        return new NamedWriteableRegistry(RANDOM_FORMATS.stream()\n+                .map(f -> new NamedWriteableRegistry.Entry(DocValueFormat.class, f.getWriteableName(), in -> f))\n+                .collect(toList())); \n+    }\n+\n+    @Override\n+    protected InternalTopMetrics createTestInstance() {\n+        String name = randomAlphaOfLength(5);\n+        DocValueFormat sortFormat = randomFrom(RANDOM_FORMATS);\n+        SortOrder sortOrder = randomFrom(SortOrder.values());\n+        double sortValue = randomDouble();\n+        String metricName = randomAlphaOfLength(5);\n+        double metricValue = randomDouble();\n+        return new InternalTopMetrics(name, sortFormat, sortOrder, sortValue, metricName, metricValue, emptyList(), null);\n+    }\n+    \n+    @Override\n+    protected InternalTopMetrics mutateInstance(InternalTopMetrics instance) throws IOException {\n+        String name = instance.getName();\n+        DocValueFormat sortFormat = instance.getSortFormat();\n+        SortOrder sortOrder = instance.getSortOrder();\n+        double sortValue = instance.getSortValue();\n+        String metricName = instance.getMetricName();\n+        double metricValue = instance.getMetricValue();\n+        switch (randomInt(5)) {", "originalCommit": "0fb37b53efa864d65054bedcd6f5debd38470865", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "chunk": "diff --git a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\nindex 10d390fb2b2..f4bd040cd32 100644\n--- a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\n+++ b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\n\n@@ -70,6 +70,8 @@ public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase\n         case 5:\n             metricValue = randomValueOtherThan(metricValue, () -> randomDouble());\n             break;\n+        default:\n+            throw new IllegalArgumentException(\"bad mutation\");\n         }\n         return new InternalTopMetrics(name, sortFormat, sortOrder, sortValue, metricName, metricValue, emptyList(), null);\n     }\n"}}, {"oid": "eacddb520c738500def6dbcdbe9c19cf0f2a2057", "url": "https://github.com/elastic/elasticsearch/commit/eacddb520c738500def6dbcdbe9c19cf0f2a2057", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-17T17:16:35Z", "type": "commit"}, {"oid": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "url": "https://github.com/elastic/elasticsearch/commit/2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "message": "Throw", "committedDate": "2020-01-17T17:17:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NTA5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369155091", "bodyText": "Hmm, should we be extending MultiValuesSourceAggregationBuilder instead?  I worry about aggs that implement AbstractAggBuilder directly.  They'll probably be harder to convert to the new VS framework, and tend to get ignored during refactoring/wide changes because they don't extend the main VS classes.", "author": "polyfractal", "createdAt": "2020-01-21T17:59:59Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMDU2MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369220560", "bodyText": "MultiValuesSourceAggregationBuilder dictates a bunch of stuff about the xcontent layout that don't make sense for this agg. To be honest I'm a little suspect of anything that does inherit from it.", "author": "nik9000", "createdAt": "2020-01-21T20:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NTA5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3MjcyNw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369172727", "bodyText": "Maybe we can just resolve the sort field via the usual mechanism and check the ValuesSource to make sure it's what we want?  That would be more inline with how the VS refactor will do things too.", "author": "polyfractal", "createdAt": "2020-01-21T18:36:14Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NDk5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369174997", "bodyText": "Let's create a new AggFactory class rather than anonymous, to stay consistent with other aggs (and to make debugging easier).", "author": "polyfractal", "createdAt": "2020-01-21T18:40:44Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMDk2NA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369220964", "bodyText": "I can certainly do that. I kind of figured we wanted fewer of these classes and this one seemed like a simple enough place to save. I'm happy to switch back.", "author": "nik9000", "createdAt": "2020-01-21T20:16:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NDk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyOTU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369229550", "bodyText": "Generally ++ to less boilerplate, but in this case the Factory plays a prominent role in the new VS stuff so we'd be adding it back anyway.  Main reason I suggested we add it here :)", "author": "polyfractal", "createdAt": "2020-01-21T20:36:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NDk5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTQ0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369175445", "bodyText": "Let's move this to the top of the AggBuilder for consistency w/ other aggs.", "author": "polyfractal", "createdAt": "2020-01-21T18:41:36Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {\n+            @Override\n+            protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+                    List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+                return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, sortComparator,\n+                        sortBuilders.get(0).order(), sort.formats[0], sortField.needsScores(), metricField.getFieldName(),\n+                        metricValueSource);\n+            }\n+        };\n+    }\n+\n+    public static final ConstructingObjectParser<TopMetricsAggregationBuilder, String> PARSER = new ConstructingObjectParser<>(NAME,", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTU4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369175587", "bodyText": "Is it possible to constrain the sort parser to just object arrays?  Switching the JSON type (objects or strings) makes life hard for clients, albeit less on the request side than the response.  Still would be nice if it were consistent.", "author": "polyfractal", "createdAt": "2020-01-21T18:41:55Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);\n+        SortAndFormats sort = SortBuilder.buildSort(sortBuilders, queryShardContext).orElseGet(() ->\n+                // Empty in this case means that the we attempted to sort on score descending\n+                new SortAndFormats(new Sort(SortField.FIELD_SCORE), new DocValueFormat[] {DocValueFormat.RAW}));\n+        if (sort.sort.getSort().length != 1) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        }\n+        SortField sortField = sort.sort.getSort()[0];\n+        FieldComparator<?> untypedCmp = sortField.getComparator(1, 0);\n+        /* This check is kind of nasty, but it is the only way we have of making sure we're getting numerics.\n+         * We would like to drop that requirement but we'll likely do that by getting *more* information\n+         * about the type, not less. */\n+        if (false == untypedCmp instanceof FieldComparator.NumericComparator &&\n+                false == untypedCmp instanceof FieldComparator.RelevanceComparator) {\n+            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on numeric values\");\n+        }\n+        @SuppressWarnings(\"unchecked\") // We checked this with instanceof above\n+        FieldComparator<? extends Number> sortComparator = (FieldComparator<? extends Number>) untypedCmp;\n+        return new AggregatorFactory(name, queryShardContext, parent, subFactoriesBuilder, metaData) {\n+            @Override\n+            protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+                    List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+                return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, sortComparator,\n+                        sortBuilders.get(0).order(), sort.formats[0], sortField.needsScores(), metricField.getFieldName(),\n+                        metricValueSource);\n+            }\n+        };\n+    }\n+\n+    public static final ConstructingObjectParser<TopMetricsAggregationBuilder, String> PARSER = new ConstructingObjectParser<>(NAME,\n+            false, (args, name) -> {\n+                @SuppressWarnings(\"unchecked\")\n+                List<SortBuilder<?>> sorts = (List<SortBuilder<?>>) args[0];\n+                MultiValuesSourceFieldConfig metricField = (MultiValuesSourceFieldConfig) args[1];\n+                return new TopMetricsAggregationBuilder(name, sorts, metricField);\n+            });\n+    static {\n+        PARSER.declareField(constructorArg(), (p, n) -> SortBuilder.fromXContent(p), SORT_FIELD, \n+                ObjectParser.ValueType.OBJECT_ARRAY_OR_STRING);", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMTI5OA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369221298", "bodyText": "Our traditional sort takes all of these so I declared it this way to be consistent with everything else. I can keep it just object array.", "author": "nik9000", "createdAt": "2020-01-21T20:17:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTU4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyOTY4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369229689", "bodyText": "Ah I see.  Hmm, breaking consistency with existing sort might be more confusing in that case.  I'm fine with leaving as-is considering. \ud83d\udc4d", "author": "polyfractal", "createdAt": "2020-01-21T20:36:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3NTU4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4Mjc2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369182766", "bodyText": "So there's an agg-specific form of AbstractWireSerializingTestCase called InternalAggregationTestCase which you'll probably want to use instead.  It includes some agg-specific tests, generates random instances and mutates them, checks reductions, parsing, etc.\nI think you can probably use that in place of InternalTopMetricsWireTests and InternalTopMetricsXContentTests.  Could probably roll the reduction logic from InternalTopMetricsReduceTests into it as well if you wanted.", "author": "polyfractal", "createdAt": "2020-01-21T18:56:13Z", "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.Writeable.Reader;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.sort.SortOrder;\n+import org.elasticsearch.test.AbstractWireSerializingTestCase;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.Collections.unmodifiableList;\n+import static java.util.stream.Collectors.toList;\n+\n+public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase<InternalTopMetrics> {", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "21a2387a2ab23de462bf40b10bed7ebf540388ea", "chunk": "diff --git a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\nindex f4bd040cd32..15f2d5d2d09 100644\n--- a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\n+++ b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetricsWireTests.java\n\n@@ -13,12 +13,12 @@ import org.elasticsearch.search.sort.SortOrder;\n import org.elasticsearch.test.AbstractWireSerializingTestCase;\n \n import java.io.IOException;\n+import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.List;\n \n import static java.util.Collections.emptyList;\n import static java.util.Collections.unmodifiableList;\n-import static java.util.stream.Collectors.toList;\n \n public class InternalTopMetricsWireTests extends AbstractWireSerializingTestCase<InternalTopMetrics> {\n     private static final List<DocValueFormat> RANDOM_FORMATS = unmodifiableList(Arrays.asList(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MzkwMg==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369183902", "bodyText": "AggregatorTestCase has helper methods called search() and searchAndReduce() which are preferred over calling search on the indexSearcher directly.  The helper methods on the test class do things like incremental reductions, scripting, pipeline aggs etc which are missed if you execute the search directly.\nIt's unfortunately a bit variable over the test codebase, so depending where you look there are a few different styles.  But using one of the forms of searchAndReduce() in particular is preferred.", "author": "polyfractal", "createdAt": "2020-01-21T18:58:33Z", "path": "x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.IndexableField;\n+import org.apache.lucene.index.RandomIndexWriter;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.NumericUtils;\n+import org.elasticsearch.common.CheckedConsumer;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.index.mapper.NumberFieldMapper.NumberType;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.sort.FieldSortBuilder;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+import static java.util.Collections.singletonList;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.notANumber;\n+\n+public class TopMetricsAggregatorTests extends AggregatorTestCase {\n+    public void testNoDocs() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {},\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortFormat(), equalTo(DocValueFormat.RAW));\n+        assertThat(result.getSortOrder(), equalTo(SortOrder.ASC));\n+        assertThat(result.getSortValue(), notANumber());\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testUnmappedMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(singletonList(doubleField(\"s\", 1.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"));\n+        assertThat(result.getSortValue(), notANumber());\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testMissingValueForMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(singletonList(doubleField(\"s\", 1.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortValue(), equalTo(1.0d));\n+        assertThat(result.getMetricValue(), notANumber());\n+    }\n+\n+    public void testActualValueForMetric() throws IOException {\n+        InternalTopMetrics result = collect(simpleBuilder(), new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(result.getSortValue(), equalTo(1.0d));\n+        assertThat(result.getMetricValue(), equalTo(2.0d));\n+    }\n+\n+    public void testAscending() throws IOException {\n+        TopMetricsAggregationBuilder builder = simpleBuilder();\n+        builder.getSortBuilders().get(0).order(SortOrder.ASC);\n+        InternalTopMetrics empty = collect(builder, new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 2.0), doubleField(\"m\", 3.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(empty.getSortValue(), equalTo(1.0d));\n+        assertThat(empty.getMetricValue(), equalTo(2.0d));\n+    }\n+\n+    public void testDescending() throws IOException {\n+        TopMetricsAggregationBuilder builder = simpleBuilder();\n+        builder.getSortBuilders().get(0).order(SortOrder.DESC);\n+        InternalTopMetrics empty = collect(builder, new MatchAllDocsQuery(), writer -> {\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 1.0), doubleField(\"m\", 2.0)));\n+                    writer.addDocument(Arrays.asList(doubleField(\"s\", 2.0), doubleField(\"m\", 3.0)));\n+                },\n+                numberField(NumberType.DOUBLE, \"s\"), numberField(NumberType.DOUBLE, \"m\"));\n+        assertThat(empty.getSortValue(), equalTo(2.0d));\n+        assertThat(empty.getMetricValue(), equalTo(3.0d));\n+    }\n+\n+    private TopMetricsAggregationBuilder simpleBuilder() {\n+        return new TopMetricsAggregationBuilder(\"test\", singletonList(new FieldSortBuilder(\"s\")),\n+                new MultiValuesSourceFieldConfig.Builder().setFieldName(\"m\").build());\n+    }\n+\n+    private MappedFieldType numberField(NumberType numberType, String name) {\n+        NumberFieldMapper.NumberFieldType type = new NumberFieldMapper.NumberFieldType(numberType);\n+        type.setName(name);\n+        return type;\n+    }\n+\n+    private IndexableField doubleField(String name, double value) {\n+        return new SortedNumericDocValuesField(name, NumericUtils.doubleToSortableLong(value));\n+    }\n+\n+    private InternalTopMetrics collect(TopMetricsAggregationBuilder builder, Query query,\n+            CheckedConsumer<RandomIndexWriter, IOException> buildIndex, MappedFieldType... fields) throws IOException {\n+        try (Directory directory = newDirectory()) {\n+            try (RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory)) {\n+                buildIndex.accept(indexWriter);\n+            }\n+\n+            try (IndexReader indexReader = DirectoryReader.open(directory)) {\n+                IndexSearcher indexSearcher = newSearcher(indexReader, true, true);\n+                TopMetricsAggregator aggregator = createAggregator(builder, indexSearcher, fields);\n+                aggregator.preCollection();\n+                indexSearcher.search(query, aggregator);", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "390c4c5dd0c7fe12d18270c7756eb5c9ab2f6bab", "chunk": "diff --git a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java\nindex 7cf706851b2..ee77a119164 100644\n--- a/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java\n+++ b/x-pack/plugin/analytics/src/test/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorTests.java\n\n@@ -118,11 +118,7 @@ public class TopMetricsAggregatorTests extends AggregatorTestCase {\n \n             try (IndexReader indexReader = DirectoryReader.open(directory)) {\n                 IndexSearcher indexSearcher = newSearcher(indexReader, true, true);\n-                TopMetricsAggregator aggregator = createAggregator(builder, indexSearcher, fields);\n-                aggregator.preCollection();\n-                indexSearcher.search(query, aggregator);\n-                aggregator.postCollection();\n-                InternalTopMetrics result = (InternalTopMetrics) aggregator.buildAggregation(0L);\n+                InternalTopMetrics result = (InternalTopMetrics) search(indexSearcher, query, builder, fields);\n                 assertThat(result.getSortFormat(), equalTo(DocValueFormat.RAW));\n                 assertThat(result.getSortOrder(), equalTo(builder.getSortBuilders().get(0).order()));\n                 assertThat(result.getMetricName(), equalTo(builder.getMetricField().getFieldName()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NTQ4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369195487", "bodyText": "So toValuesSource() typically happens in the factory (as well as field type checking/validation).  I think there are some technical reasons for the arrangement, but another reason is so that the factory can return mapped vs unmapped aggregator results.\nE.g. if either metricValueSource or sort are unmapped fields we'll need to handle that somehow, which is typically done with a createUnmapped() method on the factory to generate an unmapped, placeholder agg.\nSee ValuesSourceAggregatorFactory#createInternal() as an example of how the regular VS aggs do this.  VSAggFactory calls createUnmapped on the agg sub-class which then knows how to generate an \"empty\" unmapped aggregator.  This varies a little depending on the agg, some handle it internal to the agg while others have a dedicated unmapped aggregator.", "author": "polyfractal", "createdAt": "2020-01-21T19:22:43Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.Sort;\n+import org.apache.lucene.search.SortField;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ContextParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortAndFormats;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.search.builder.SearchSourceBuilder.SORT_FIELD;\n+\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {\n+    public static final String NAME = \"top_metrics\";\n+    public static final ParseField METRIC_FIELD = new ParseField(\"metric\");\n+\n+    private final List<SortBuilder<?>> sortBuilders;\n+    // TODO MultiValuesSourceFieldConfig has more things than we support and less things than we want to support\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    /**\n+     * Ctor for parsing.\n+     */\n+    public TopMetricsAggregationBuilder(String name, List<SortBuilder<?>> sortBuilders, MultiValuesSourceFieldConfig metricField) {\n+        super(name);\n+        if (sortBuilders.size() != 1) {\n+            throw new IllegalArgumentException(\"[sort] must contain exactly one sort\");\n+        }\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    /**\n+     * Cloning ctor for reducing.\n+     */\n+    public TopMetricsAggregationBuilder(TopMetricsAggregationBuilder clone, AggregatorFactories.Builder factoriesBuilder,\n+            Map<String, Object> metaData) {\n+        super(clone, factoriesBuilder, metaData);\n+        this.sortBuilders = clone.sortBuilders;\n+        this.metricField = clone.metricField;\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public TopMetricsAggregationBuilder(StreamInput in) throws IOException {\n+        super(in);\n+        @SuppressWarnings(\"unchecked\")\n+        List<SortBuilder<?>> sortBuilders = (List<SortBuilder<?>>) (List<?>) in.readNamedWriteableList(SortBuilder.class); \n+        this.sortBuilders = sortBuilders;\n+        this.metricField = new MultiValuesSourceFieldConfig(in);\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteableList(sortBuilders);\n+        metricField.writeTo(out);\n+    }\n+\n+    @Override\n+    protected AggregationBuilder shallowCopy(AggregatorFactories.Builder factoriesBuilder, Map<String, Object> metaData) {\n+        return new TopMetricsAggregationBuilder(this, factoriesBuilder, metaData);\n+    }\n+\n+    @Override\n+    protected AggregatorFactory doBuild(QueryShardContext queryShardContext, AggregatorFactory parent, Builder subFactoriesBuilder)\n+            throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\nindex 3396640acd9..a0384f3ecfc 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregationBuilder.java\n\n@@ -5,9 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.Sort;\n-import org.apache.lucene.search.SortField;\n import org.elasticsearch.common.ParseField;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjMzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369206335", "bodyText": "I think this might be a bit of a dealbreaker unfortunately?  E.g. the predominant use-case for this agg is fetching the most recent value as defined by a timestamp, so date formatting is relatively important.", "author": "polyfractal", "createdAt": "2020-01-21T19:45:36Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.SearchSortValues;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final double sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, double sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    static InternalTopMetrics buildEmptyAggregation(String name, DocValueFormat sortFormat, SortOrder sortOrder, String metricField,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        return new InternalTopMetrics(name, sortFormat, sortOrder, Double.NaN, metricField, Double.NaN, pipelineAggregators, metaData);\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public InternalTopMetrics(StreamInput in) throws IOException {\n+        super(in);\n+        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n+        sortOrder = SortOrder.readFromStream(in);\n+        sortValue = in.readDouble();\n+        metricName = in.readString();\n+        metricValue = in.readDouble();\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteable(sortFormat);\n+        sortOrder.writeTo(out);\n+        out.writeDouble(sortValue);\n+        out.writeString(metricName);\n+        out.writeDouble(metricValue);\n+    }\n+\n+    @Override\n+    public String getWriteableName() {\n+        return TopMetricsAggregationBuilder.NAME;\n+    }\n+\n+    @Override\n+    public Object getProperty(List<String> path) {\n+        if (path.isEmpty()) {\n+            return this;\n+        }\n+        if (path.size() == 1 && metricName.contentEquals(path.get(1))) {\n+            return metricValue;\n+        }\n+        throw new IllegalArgumentException(\"path not supported for [\" + getName() + \"]: \" + path);\n+    }\n+\n+    @Override\n+    public InternalTopMetrics reduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {\n+        Iterator<InternalAggregation> itr = aggregations.iterator();\n+        InternalTopMetrics first;\n+        while (true) {\n+            if (false == itr.hasNext()) {\n+                // Reducing a bunch of empty aggregations\n+                return buildReduced(DocValueFormat.RAW, Double.NaN, Double.NaN);\n+            }\n+            first = (InternalTopMetrics) itr.next();\n+            // Results with NaN sorts are empty\n+            if (false == Double.isNaN(first.sortValue)) {\n+                break;\n+            }\n+        }\n+        DocValueFormat bestSortFormat = first.sortFormat;\n+        double bestSortValue = first.sortValue;\n+        double bestMetricValue = first.metricValue;\n+        int reverseMul = sortOrder == SortOrder.DESC ? -1 : 1;\n+        while (itr.hasNext()) {\n+            InternalTopMetrics result = (InternalTopMetrics) itr.next();\n+            // Results with NaN sorts are empty\n+            if (Double.isNaN(result.sortValue)) {\n+                continue;\n+            }\n+            if (reverseMul * Double.compare(bestSortValue, result.sortValue) > 0) {\n+                bestSortFormat = result.sortFormat;\n+                bestSortValue = result.sortValue;\n+                bestMetricValue = result.metricValue;\n+            }\n+        }\n+        return buildReduced(bestSortFormat, bestSortValue, bestMetricValue);\n+    }\n+\n+    private InternalTopMetrics buildReduced(DocValueFormat bestSortFormat, double bestSortValue, double bestMetricValue) {\n+        return new InternalTopMetrics(getName(), bestSortFormat, sortOrder, bestSortValue, metricName, bestMetricValue,\n+                pipelineAggregators(), getMetaData());\n+    }\n+\n+    @Override\n+    public XContentBuilder doXContentBody(XContentBuilder builder, Params params) throws IOException {\n+        builder.startArray(\"top\");\n+        builder.startObject();\n+        {\n+            // Sadly, this won't output dates correctly because they always come back as doubles. We \n+            SearchSortValues sortValues = new SearchSortValues(new Object[] {sortValue}, new DocValueFormat[] {sortFormat});", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxOTk5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369219992", "bodyText": "I'm sure we can get the formatting right eventually. I'd sort of taken your initial prototype with doubles and ran with it.", "author": "nik9000", "createdAt": "2020-01-21T20:14:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjMzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "21a2387a2ab23de462bf40b10bed7ebf540388ea", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\nindex 2d70194a1a4..0a69880402d 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n\n@@ -5,29 +5,37 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n import org.elasticsearch.search.DocValueFormat;\n-import org.elasticsearch.search.SearchSortValues;\n import org.elasticsearch.search.aggregations.InternalAggregation;\n import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n import org.elasticsearch.search.sort.SortOrder;\n \n import java.io.IOException;\n+import java.util.Arrays;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n \n public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n     private final DocValueFormat sortFormat;\n     private final SortOrder sortOrder;\n-    private final double sortValue;\n+    private final SortValue sortValue;\n     private final String metricName;\n     private final double metricValue;\n \n-    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, double sortValue, String metricName,\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n             double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n         super(name, pipelineAggregators, metaData);\n         this.sortFormat = sortFormat;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjQ4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369206481", "bodyText": "Hmm, I'm not sure about this.  I know why it was done this way (so sort and value can go in one array), but since the predominant use-case is dates, floating point error/rounding is not ideal.  Would be very confusing for customers to see a returned date that doesn't match the date in their document, or potentially mismatch with a date_histo bucket that it resides in.", "author": "polyfractal", "createdAt": "2020-01-21T19:45:52Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.LeafFieldComparator;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.LeafBucketCollectorBase;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+class TopMetricsAggregator extends MetricsAggregator {\n+    /**\n+     * Field comparator for doing the sort. This comes from Lucene and it isn't quite what we need\n+     * but it is pretty close. We'll likely revisit this but for now it is very good at letting us\n+     * use the normal sorting infrastructure.\n+     */\n+    private final FieldComparator<? extends Number> sortComparator;\n+    private final SortOrder sortOrder;\n+    private final DocValueFormat sortFormat;\n+    private final boolean sortNeedsScores;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData,\n+            FieldComparator<? extends Number> sortComparator, SortOrder sortOrder, DocValueFormat sortFormat, boolean sortNeedsScores,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sortComparator = sortComparator;\n+        this.sortOrder = sortOrder;\n+        this.sortFormat = sortFormat;\n+        this.sortNeedsScores = sortNeedsScores;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = sortNeedsScores || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        LeafFieldComparator leafCmp = sortComparator.getLeafComparator(ctx);\n+        int reverseMul = sortOrder == SortOrder.DESC ? -1 : 1;\n+        return new LeafBucketCollectorBase(sub, metricValues) {\n+            @Override\n+            public void collect(int doc, long bucket) throws IOException {\n+                long offset = bucket * 2;\n+                if (offset + 2 > values.size()) {\n+                    long oldSize = values.size();\n+                    values = context.bigArrays().grow(values, offset + 2);\n+                    values.fill(oldSize, values.size(), Double.NaN);\n+                }\n+\n+                double bestSort = values.get(offset);\n+                // This generates a Double instance and throws it away. Sad, but it is the price we pay for using Lucene APIs.\n+                leafCmp.copy(0, doc);\n+                double sort = sortComparator.value(0).doubleValue();", "originalCommit": "2b7a62e3ca1bf2c297d1375d1c27b5526feaf64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxOTM4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r369219389", "bodyText": "This being a double is something I inherited from your first implementation so I did the whole array merging thing. I fairly sure that we won't stick with this implementation once we want to support multiple hits but it felt ok \"for now\".", "author": "nik9000", "createdAt": "2020-01-21T20:12:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjQ4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "21a2387a2ab23de462bf40b10bed7ebf540388ea", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\nindex 7478929d706..592b4a16413 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n\n@@ -7,14 +7,11 @@\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n import org.apache.lucene.index.LeafReaderContext;\n-import org.apache.lucene.search.FieldComparator;\n-import org.apache.lucene.search.LeafFieldComparator;\n import org.apache.lucene.search.Scorable;\n import org.apache.lucene.search.ScoreMode;\n import org.elasticsearch.common.lease.Releasables;\n import org.elasticsearch.common.util.DoubleArray;\n import org.elasticsearch.index.fielddata.NumericDoubleValues;\n-import org.elasticsearch.search.DocValueFormat;\n import org.elasticsearch.search.MultiValueMode;\n import org.elasticsearch.search.aggregations.Aggregator;\n import org.elasticsearch.search.aggregations.InternalAggregation;\n"}}, {"oid": "caf10048bf13f3b8f2fa205ee9a63bafbf217800", "url": "https://github.com/elastic/elasticsearch/commit/caf10048bf13f3b8f2fa205ee9a63bafbf217800", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-21T20:22:44Z", "type": "commit"}, {"oid": "9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "url": "https://github.com/elastic/elasticsearch/commit/9f12a5e1354823ccc2a9bc365d871cbb1f65bb78", "message": "Factory time", "committedDate": "2020-01-21T20:33:20Z", "type": "commit"}, {"oid": "845a8e79a9e29cc76ab5e6599a6375a2e8a13bd4", "url": "https://github.com/elastic/elasticsearch/commit/845a8e79a9e29cc76ab5e6599a6375a2e8a13bd4", "message": "Move", "committedDate": "2020-01-21T20:38:35Z", "type": "commit"}, {"oid": "390c4c5dd0c7fe12d18270c7756eb5c9ab2f6bab", "url": "https://github.com/elastic/elasticsearch/commit/390c4c5dd0c7fe12d18270c7756eb5c9ab2f6bab", "message": "Use fancy test methods", "committedDate": "2020-01-21T20:46:49Z", "type": "commit"}, {"oid": "21a2387a2ab23de462bf40b10bed7ebf540388ea", "url": "https://github.com/elastic/elasticsearch/commit/21a2387a2ab23de462bf40b10bed7ebf540388ea", "message": "Bucketed sort", "committedDate": "2020-01-23T15:26:39Z", "type": "commit"}, {"oid": "feeca63c29f704fd30e00a52a5ddabc85ca62a75", "url": "https://github.com/elastic/elasticsearch/commit/feeca63c29f704fd30e00a52a5ddabc85ca62a75", "message": "Squish nocommits", "committedDate": "2020-01-23T15:35:11Z", "type": "commit"}, {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "url": "https://github.com/elastic/elasticsearch/commit/228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-23T16:05:45Z", "type": "commit"}, {"oid": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "url": "https://github.com/elastic/elasticsearch/commit/228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-23T16:05:45Z", "type": "forcePushed"}, {"oid": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "url": "https://github.com/elastic/elasticsearch/commit/5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-27T15:19:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI4NjQxMA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371286410", "bodyText": "I believe bigArrays.grow() does this size check so we could skip here.", "author": "polyfractal", "createdAt": "2020-01-27T14:55:21Z", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket > maxBucket) {\n+                assert maxBucket + 1 == bucket :\"expected bucket to be [\" + (maxBucket + 1) + \"] but was [\" + bucket + \"]\";\n+                maxBucket = bucket;\n+                if (bucket >= buckets().size()) {", "originalCommit": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a2569ded9edd24b8275701f11d00862fd85214e6", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\nindex 8e6e3ae4fb5..34559a5fb97 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n\n@@ -42,7 +42,7 @@ public abstract class BucketedSort implements Releasable {\n     private final DocValueFormat format;\n     private long maxBucket = -1;\n \n-    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+    private BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n         this.bigArrays = bigArrays;\n         this.order = order;\n         this.format = format;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI5MDUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371290504", "bodyText": "I don't believe this assertion holds true in all scenarios, e.g. it's not required that buckets are incremented in a dense fashion.  For example an auto-date-histo can merge buckets together during collection, which will introduce gaps in the ordinals that sub-aggs see.", "author": "polyfractal", "createdAt": "2020-01-27T15:01:57Z", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket > maxBucket) {\n+                assert maxBucket + 1 == bucket :\"expected bucket to be [\" + (maxBucket + 1) + \"] but was [\" + bucket + \"]\";", "originalCommit": "228ccc9e7fa9cf2f6929bb61beca552e7ca79f7c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM2MzM3MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371363370", "bodyText": "OK - then I think I'll have to fill in the gaps with NaN or something we never select so we know when the value is empty.", "author": "nik9000", "createdAt": "2020-01-27T17:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTI5MDUwNA=="}], "type": "inlineReview", "revised_code": {"commit": "a2569ded9edd24b8275701f11d00862fd85214e6", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\nindex 8e6e3ae4fb5..34559a5fb97 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n\n@@ -42,7 +42,7 @@ public abstract class BucketedSort implements Releasable {\n     private final DocValueFormat format;\n     private long maxBucket = -1;\n \n-    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+    private BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n         this.bigArrays = bigArrays;\n         this.order = order;\n         this.format = format;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371308358", "bodyText": "Out of curiosity, why do we need a ctor that accepts Object sortValue?  E.g. we'll always know it's at least a SortValue object right?", "author": "polyfractal", "createdAt": "2020-01-27T15:30:51Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final SortValue sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, Object sortValue, String metricName,", "originalCommit": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzOTI3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371339279", "bodyText": "Oh I see, we don't actually know the SortValue.  BucketedSort only gives us back an object, because we don't know which \"ForFoo\" was used for the sort value (ForLong, etc).\nHmm.  I wonder if we should do this conversion on the other end?  Something like toSortValue() on BucketedSort, which each implementation knows how to turn into an implementation of SortValue and then serialize that?\nIt feels a little cleaner since we don't need instance-of checks to resolve the SortValue, and would protect against situations where two types serialize the same data type  but should be interpreted as something different on the receiving end.  I think the various Bytes implementations might run into this (string bytes != range bytes for example).  Dunno if we'll ever implement situations where we'd run into it though.\nOTOH, it adds extra serialization code to all the SortValues.", "author": "polyfractal", "createdAt": "2020-01-27T16:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM1NzA3OA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371357078", "bodyText": "I think we could do the conversion on the other end if we want SortValue to become a \"core\" thing. I think it'd be cleaner, even. Do you think I should move SortValue over?", "author": "nik9000", "createdAt": "2020-01-27T16:49:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM3MjE0MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371372140", "bodyText": "Ahhh right, forgot about the split here. Hmm. I'm leaning towards \"yes\", feels generally like a \"core\" thing.  WDYT?", "author": "polyfractal", "createdAt": "2020-01-27T17:17:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NDcxNA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371384714", "bodyText": "Sure! I'll move it over.", "author": "nik9000", "createdAt": "2020-01-27T17:41:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMwODM1OA=="}], "type": "inlineReview", "revised_code": {"commit": "a2569ded9edd24b8275701f11d00862fd85214e6", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\nindex 0a69880402d..1cafe89cb1b 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n\n@@ -5,8 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.elasticsearch.common.io.stream.NamedWriteable;\n-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371327450", "bodyText": "Is the \"hit\" naming following a search/lucene convention?  If not, I wonder if we should call it collect() to mirror the agg conventions?  It's obviously not quite the same since it returns a bool, but it does \"collect\" at the same time too.  Dunno, no strong opinion.", "author": "polyfractal", "createdAt": "2020-01-27T16:00:59Z", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support mulitiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+    private long maxBucket = -1;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the results.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket.\n+     */\n+    public final Object getValue(long bucket) {\n+        if (bucket > maxBucket) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was hit.\n+     */\n+    protected abstract Object getValueForBucket(long bucket);\n+\n+    @Override\n+    public void close() {\n+        buckets().close();\n+    }\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean hit(int doc, long bucket) throws IOException {", "originalCommit": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM2MDEzMA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371360130", "bodyText": "It only collects if the hit is competitive so I didn't like collect. I'll think on the name!", "author": "nik9000", "createdAt": "2020-01-27T16:54:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM3MzgyNw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371373827", "bodyText": "aha right, makes sense.  collectIfCompetitive()?  fwiw, other aggs discard docs in collect() if they aren't \"competitive\" so not too unusual, e.g. min/max obviously only keep min or max, bucketing aggs can discard docs if they don't match include/exclude, etc etc.\nBut they also don't have a return value, so it is probably good to call this something different just so it's clear they aren't exactly the same\nI dunno, no strong feelings here :)", "author": "polyfractal", "createdAt": "2020-01-27T17:20:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyMjE2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371822161", "bodyText": "I'm going to just go with collectIfCompetitive for now. I'll have to add priority queue stuff in a follow up and then the method's name may scream at me to change. But for now collect seems fine.", "author": "nik9000", "createdAt": "2020-01-28T14:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkxNTc0MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371915740", "bodyText": "Works for me!", "author": "polyfractal", "createdAt": "2020-01-28T16:33:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMyNzQ1MA=="}], "type": "inlineReview", "revised_code": {"commit": "a2569ded9edd24b8275701f11d00862fd85214e6", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\nindex 8e6e3ae4fb5..34559a5fb97 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n\n@@ -42,7 +42,7 @@ public abstract class BucketedSort implements Releasable {\n     private final DocValueFormat format;\n     private long maxBucket = -1;\n \n-    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+    private BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n         this.bigArrays = bigArrays;\n         this.order = order;\n         this.format = format;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzMDMyOA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371330328", "bodyText": "Just for my understanding/clarification, the way the SortValues are setup is basically:\n\nIf the types differ (Long compared to Double, it does a comparison on the class name and uses that for ordering)\nOtherwise, if the types are the same it does the type-specific comparison\n\nThat correct?", "author": "polyfractal", "createdAt": "2020-01-27T16:05:38Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.common.io.stream.NamedWriteable;\n+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.search.DocValueFormat;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.sort.SortOrder;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class InternalTopMetrics extends InternalAggregation {\n+    public static List<NamedWriteableRegistry.Entry> writeables() {\n+        return Arrays.asList(\n+                new NamedWriteableRegistry.Entry(SortValue.class, DoubleSortValue.NAME, DoubleSortValue::new),\n+                new NamedWriteableRegistry.Entry(SortValue.class, LongSortValue.NAME, LongSortValue::new));\n+    }\n+\n+    private final DocValueFormat sortFormat;\n+    private final SortOrder sortOrder;\n+    private final SortValue sortValue;\n+    private final String metricName;\n+    private final double metricValue;\n+\n+    private InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, SortValue sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        super(name, pipelineAggregators, metaData);\n+        this.sortFormat = sortFormat;\n+        this.sortOrder = sortOrder;\n+        this.sortValue = sortValue;\n+        this.metricName = metricName;\n+        this.metricValue = metricValue;\n+    }\n+\n+    InternalTopMetrics(String name, DocValueFormat sortFormat, SortOrder sortOrder, Object sortValue, String metricName,\n+            double metricValue, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        this(name, sortFormat, sortOrder, sortValueFor(sortValue), metricName, metricValue, pipelineAggregators, metaData);\n+    }\n+\n+    static InternalTopMetrics buildEmptyAggregation(String name, String metricField,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {\n+        return new InternalTopMetrics(name, DocValueFormat.RAW, SortOrder.ASC, null, metricField, Double.NaN, pipelineAggregators,\n+                metaData);\n+    }\n+\n+    /**\n+     * Read from a stream.\n+     */\n+    public InternalTopMetrics(StreamInput in) throws IOException {\n+        super(in);\n+        sortFormat = in.readNamedWriteable(DocValueFormat.class);\n+        sortOrder = SortOrder.readFromStream(in);\n+        sortValue = in.readOptionalNamedWriteable(SortValue.class);\n+        metricName = in.readString();\n+        metricValue = in.readDouble();\n+    }\n+\n+    @Override\n+    protected void doWriteTo(StreamOutput out) throws IOException {\n+        out.writeNamedWriteable(sortFormat);\n+        sortOrder.writeTo(out);\n+        out.writeOptionalNamedWriteable(sortValue);\n+        out.writeString(metricName);\n+        out.writeDouble(metricValue);\n+    }\n+\n+    @Override\n+    public String getWriteableName() {\n+        return TopMetricsAggregationBuilder.NAME;\n+    }\n+\n+    @Override\n+    public Object getProperty(List<String> path) {\n+        if (path.isEmpty()) {\n+            return this;\n+        }\n+        if (path.size() == 1 && metricName.contentEquals(path.get(1))) {\n+            return metricValue;\n+        }\n+        throw new IllegalArgumentException(\"path not supported for [\" + getName() + \"]: \" + path);\n+    }\n+\n+    @Override\n+    public InternalTopMetrics reduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {\n+        Iterator<InternalAggregation> itr = aggregations.iterator();\n+        InternalTopMetrics first;\n+        do {\n+            if (false == itr.hasNext()) {\n+                // All of the aggregations are empty.\n+                return buildEmptyAggregation(name, metricName, pipelineAggregators(), getMetaData());\n+            }\n+            first = (InternalTopMetrics) itr.next();\n+        } while (first.sortValue == null);\n+        DocValueFormat bestSortFormat = first.sortFormat;\n+        SortValue bestSortValue = first.sortValue;\n+        double bestMetricValue = first.metricValue;\n+        int reverseMul = first.sortOrder.reverseMul();\n+        while (itr.hasNext()) {\n+            InternalTopMetrics result = (InternalTopMetrics) itr.next();\n+            if (result.sortValue == null) {\n+                // Don't bother checking empty results.\n+                continue;\n+            }\n+            if (reverseMul * bestSortValue.compareTo(result.sortValue) > 0) {", "originalCommit": "5f71b84c6d3ddcd87ea1b8f4cf64140788b2c19b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM2MTgzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371361839", "bodyText": "It compares the writeable name for the sorting, not the class name. But you had it pretty much. This sort of comparison will only be done on the reducing node so I don't think it is super important what key it uses, just that it uses something. And the writeable name is right there.\nThough maybe it does matter if we reduce in multiple phases on multiple nodes. Is that a thing that cross cluster search does? If so I should probably be a little more explicit here.", "author": "nik9000", "createdAt": "2020-01-27T16:57:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzMDMyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM3NTQ5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371375499", "bodyText": "\ud83d\udc4d\nI believe CCS can potentially execute like that.  One mode streams all shard results (from all nodes/clusters) to the coordinator and reduces.  But a different mode does an incremental reduce in a per-cluster coordinator and streams those \"intermediate\" shard results to the original coordinator for a final reduce.  I forget the name of that mode but it's basically designed for higher-latency CCS where you don't want to ship all the shard results across the world.\nBut I think writeable name should be fine even in that case, right?  It just needs to be consistent?", "author": "polyfractal", "createdAt": "2020-01-27T17:23:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzMDMyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NDIzOA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r371384238", "bodyText": "It does need to be consistent. But I think it is important to add tests and comments explaining why it needs to be consistent. I guess writeable name has to be consistent for the wire protocol to work at all.", "author": "nik9000", "createdAt": "2020-01-27T17:40:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTMzMDMyOA=="}], "type": "inlineReview", "revised_code": {"commit": "a2569ded9edd24b8275701f11d00862fd85214e6", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\nindex 0a69880402d..1cafe89cb1b 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/InternalTopMetrics.java\n\n@@ -5,8 +5,6 @@\n  */\n package org.elasticsearch.xpack.analytics.topmetrics;\n \n-import org.elasticsearch.common.io.stream.NamedWriteable;\n-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;\n import org.elasticsearch.common.io.stream.StreamInput;\n import org.elasticsearch.common.io.stream.StreamOutput;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n"}}, {"oid": "aa33abba8faf536d89a3c16742100e3dc4cabd03", "url": "https://github.com/elastic/elasticsearch/commit/aa33abba8faf536d89a3c16742100e3dc4cabd03", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-27T17:44:57Z", "type": "commit"}, {"oid": "a2569ded9edd24b8275701f11d00862fd85214e6", "url": "https://github.com/elastic/elasticsearch/commit/a2569ded9edd24b8275701f11d00862fd85214e6", "message": "Move SortValue to core", "committedDate": "2020-01-27T20:27:43Z", "type": "commit"}, {"oid": "e2925e3ec4d3348ba45945c9f85707eae0e2638f", "url": "https://github.com/elastic/elasticsearch/commit/e2925e3ec4d3348ba45945c9f85707eae0e2638f", "message": "moar sort", "committedDate": "2020-01-28T14:04:08Z", "type": "commit"}, {"oid": "98091fa562c99f58d65f8d1d2c4e144b3d8c0d4c", "url": "https://github.com/elastic/elasticsearch/commit/98091fa562c99f58d65f8d1d2c4e144b3d8c0d4c", "message": "Rename", "committedDate": "2020-01-28T14:08:25Z", "type": "commit"}, {"oid": "b9d80852727474a8b303eb38412aef2a9ee3bc38", "url": "https://github.com/elastic/elasticsearch/commit/b9d80852727474a8b303eb38412aef2a9ee3bc38", "message": "Cleanup", "committedDate": "2020-01-28T14:16:58Z", "type": "commit"}, {"oid": "935c755c13a7676b7dc31f8594d1ad146d2ffe52", "url": "https://github.com/elastic/elasticsearch/commit/935c755c13a7676b7dc31f8594d1ad146d2ffe52", "message": "Drop method from SortValue", "committedDate": "2020-01-28T15:21:52Z", "type": "commit"}, {"oid": "fb7f1226912956f90a0f88a990fcb2ba1b2b08d0", "url": "https://github.com/elastic/elasticsearch/commit/fb7f1226912956f90a0f88a990fcb2ba1b2b08d0", "message": "last test", "committedDate": "2020-01-28T15:27:22Z", "type": "commit"}, {"oid": "a6c69d85663208d02b34a5f96532ed89d47e2e08", "url": "https://github.com/elastic/elasticsearch/commit/a6c69d85663208d02b34a5f96532ed89d47e2e08", "message": "Smaller collector?", "committedDate": "2020-01-28T15:39:01Z", "type": "commit"}, {"oid": "9544c15e3a8aec6b075b11ed80f55cb65974f31a", "url": "https://github.com/elastic/elasticsearch/commit/9544c15e3a8aec6b075b11ed80f55cb65974f31a", "message": "Move to InternalAggregationTestCase", "committedDate": "2020-01-28T20:37:46Z", "type": "commit"}, {"oid": "6efdd1423c3bb4da77a38a28762a8db497814260", "url": "https://github.com/elastic/elasticsearch/commit/6efdd1423c3bb4da77a38a28762a8db497814260", "message": "high level client support", "committedDate": "2020-01-29T15:26:58Z", "type": "commit"}, {"oid": "0a44b09a47cd72600430cfd319eed5d76a290241", "url": "https://github.com/elastic/elasticsearch/commit/0a44b09a47cd72600430cfd319eed5d76a290241", "message": "A little better docs", "committedDate": "2020-01-29T15:52:40Z", "type": "commit"}, {"oid": "ef8afc3773530ee4e7c866075b26275e07c77413", "url": "https://github.com/elastic/elasticsearch/commit/ef8afc3773530ee4e7c866075b26275e07c77413", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-29T16:50:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0OTkxNg==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r372549916", "bodyText": "Could we have a default implementation based on the sortField implementation? My understanding is that SortField provides anything we need, BucketedSort is just nice because it has the concept of buckets that SortField doesn't have?", "author": "jpountz", "createdAt": "2020-01-29T18:18:51Z", "path": "server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java", "diffHunk": "@@ -72,6 +76,12 @@\n      */\n     SortField sortField(@Nullable Object missingValue, MultiValueMode sortMode, Nested nested, boolean reverse);\n \n+    default BucketedSort newBucketedSort(BigArrays bigArrays, @Nullable Object missingValue, MultiValueMode sortMode, Nested nested,\n+            SortOrder sortOrder, DocValueFormat format) {\n+        // TODO implement all the fields.\n+        throw new IllegalArgumentException(\"Unsupported field type\");", "originalCommit": "8304db1e98b374385468d1319a47b2bd0b3a01a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MzIxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r372573219", "bodyText": "Are you thinking of an implementation that uses an array of SortFields?", "author": "nik9000", "createdAt": "2020-01-29T19:04:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0OTkxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3ODM2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r372578369", "bodyText": "yes", "author": "jpountz", "createdAt": "2020-01-29T19:14:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0OTkxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4NjA2MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373586060", "bodyText": "I looked at this and it turned out to be kind of fiddly to get right. Given that we only want to support numeric sorts on his agg anyway it was easier to just remove this TODO and either implement the sort of throw an exception saying that it doesn't work on this field type.", "author": "nik9000", "createdAt": "2020-01-31T17:06:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU0OTkxNg=="}], "type": "inlineReview", "revised_code": {"commit": "80bf931e07eca3c6b1b75648ffcb373086499dd7", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java b/server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java\nindex 798dfff69ae..4047cec659c 100644\n--- a/server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java\n+++ b/server/src/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java\n\n@@ -76,11 +76,8 @@ public interface IndexFieldData<FD extends AtomicFieldData> extends IndexCompone\n      */\n     SortField sortField(@Nullable Object missingValue, MultiValueMode sortMode, Nested nested, boolean reverse);\n \n-    default BucketedSort newBucketedSort(BigArrays bigArrays, @Nullable Object missingValue, MultiValueMode sortMode, Nested nested,\n-            SortOrder sortOrder, DocValueFormat format) {\n-        // TODO implement all the fields.\n-        throw new IllegalArgumentException(\"Unsupported field type\");\n-    }\n+    BucketedSort newBucketedSort(BigArrays bigArrays, @Nullable Object missingValue, MultiValueMode sortMode, Nested nested,\n+            SortOrder sortOrder, DocValueFormat format);\n \n     /**\n      * Clears any resources associated with this field data.\n"}}, {"oid": "0b191f8db23808a570f3116477c7baeec3a97fc9", "url": "https://github.com/elastic/elasticsearch/commit/0b191f8db23808a570f3116477c7baeec3a97fc9", "message": "Test", "committedDate": "2020-01-30T16:19:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAyNzczNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373027735", "bodyText": "I was confused by this, since usually things that descend from AbstractAggregationBuilder are the entry points for that aggregation.  In this case, it looks like we're just using the XContentBuilder aspect of this, presumably for the HLRC to build out requests?  If that's the case, I think it would help to make clear in the javadoc that this is not the main builder for this aggregation, and be explicit about its intended use.\nI don't think I'm alone in thinking our aggregation builders do too much, and this seems symptomatic of that.   Maybe at some point, we can talk about breaking up those roles.", "author": "not-napoleon", "createdAt": "2020-01-30T15:45:07Z", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.analytics;\n+\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+/**\n+ * Builds the Top Metrics aggregation request.\n+ */\n+public class TopMetricsAggregationBuilder extends AbstractAggregationBuilder<TopMetricsAggregationBuilder> {", "originalCommit": "8304db1e98b374385468d1319a47b2bd0b3a01a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5MDY1MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373090650", "bodyText": "I think I have to descend from AbstractAggregationBuilder to make the client happy. I can check.", "author": "nik9000", "createdAt": "2020-01-30T17:32:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAyNzczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA5NDE3MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373094170", "bodyText": "I'm also pretty sure you have to.   All I'm suggesting is adding a note to the javadoc that explains what an aggregation builder is doing here, and that it's not the \"main\" builder for Top Metrics.   It makes sense in context of this PR, but I am imagining a future where someone is looking at all classes that implement AbstractAggregationBuilder and scratching their head.", "author": "not-napoleon", "createdAt": "2020-01-30T17:40:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAyNzczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4Njg0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373586843", "bodyText": "I've added javadoc explaining this.", "author": "nik9000", "createdAt": "2020-01-31T17:07:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAyNzczNQ=="}], "type": "inlineReview", "revised_code": {"commit": "49ee3c7ec6a2fba8bd4b78a4a3264aa88124d9ee", "chunk": "diff --git a/client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java b/client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java\nindex 8de647f917c..97c4e625a56 100644\n--- a/client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java\n+++ b/client/rest-high-level/src/main/java/org/elasticsearch/client/analytics/TopMetricsAggregationBuilder.java\n\n@@ -20,12 +20,15 @@\n package org.elasticsearch.client.analytics;\n \n import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.query.QueryRewriteContext;\n import org.elasticsearch.index.query.QueryShardContext;\n import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;\n import org.elasticsearch.search.aggregations.AggregationBuilder;\n import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n import org.elasticsearch.search.sort.SortBuilder;\n \n import java.io.IOException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1MzQyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373053429", "bodyText": "I understand why we're not using MultiValuesSourceAggregationBuilder, but I don't understand why we aren't using ValuesSourceAggregationBuilder (and ValuesSourceAggregatorFactory).  We have one field that we want to get a ValuesSource for, which is what ValuesSourceAggregationBuilder does.  Maybe there's some reason I'm missing here?  Using VSAB will also make my life easier when it comes time to wire this up to the registry ;)", "author": "not-napoleon", "createdAt": "2020-01-30T16:26:30Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.elasticsearch.index.query.QueryShardContext;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.AggregatorFactories.Builder;\n+import org.elasticsearch.search.aggregations.AggregatorFactory;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.MultiValuesSourceFieldConfig;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortBuilder;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class TopMetricsAggregatorFactory extends AggregatorFactory {\n+    private final List<SortBuilder<?>> sortBuilders;\n+    private final MultiValuesSourceFieldConfig metricField;\n+\n+    public TopMetricsAggregatorFactory(String name, QueryShardContext queryShardContext, AggregatorFactory parent,\n+            Builder subFactoriesBuilder, Map<String, Object> metaData, List<SortBuilder<?>> sortBuilders,\n+            MultiValuesSourceFieldConfig metricField) throws IOException {\n+        super(name, queryShardContext, parent, subFactoriesBuilder, metaData);\n+        this.sortBuilders = sortBuilders;\n+        this.metricField = metricField;\n+    }\n+\n+    @Override\n+    protected TopMetricsAggregator createInternal(SearchContext searchContext, Aggregator parent, boolean collectsFromSingleBucket,\n+            List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {\n+        ValuesSourceConfig<ValuesSource.Numeric> metricFieldSource = ValuesSourceConfig.resolve(queryShardContext, ValueType.NUMERIC,\n+                metricField.getFieldName(), metricField.getScript(), metricField.getMissing(), metricField.getTimeZone(), null);\n+        ValuesSource.Numeric metricValueSource = metricFieldSource.toValuesSource(queryShardContext);", "originalCommit": "8304db1e98b374385468d1319a47b2bd0b3a01a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA3MzIyMA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373073220", "bodyText": "We have one field that we want to get a ValuesSource for, which is what ValuesSourceAggregationBuilder does. Maybe there's some reason I'm missing here? Using VSAB will also make my life easier when it comes time to wire this up to the registry ;)\n\nI'll look at it and let you know. I started with the multi-value source config thing but it had issues with the request format. Right now we have a single value here but I believe we'll end up with more in the future.", "author": "nik9000", "createdAt": "2020-01-30T17:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1MzQyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzEwMzgxNw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373103817", "bodyText": "I just checked - ValuesSourceAggregationBuilder ties me to a single value source but I expect to support multiple values.", "author": "nik9000", "createdAt": "2020-01-30T17:59:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA1MzQyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "80bf931e07eca3c6b1b75648ffcb373086499dd7", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java\nindex 28988b5f9d1..c5060f948d1 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregatorFactory.java\n\n@@ -44,10 +44,12 @@ public class TopMetricsAggregatorFactory extends AggregatorFactory {\n         if (metricValueSource == null) {\n             return createUnmapped(searchContext, parent, pipelineAggregators, metaData);\n         }\n-        if (sortBuilders.size()!= 1) {\n-            throw new IllegalArgumentException(\"[top_metrics] only supports sorting on a single field\");\n+        BucketedSort bucketedSort;\n+        try {\n+            bucketedSort = sortBuilders.get(0).buildBucketedSort(searchContext.getQueryShardContext());\n+        } catch (IllegalArgumentException e) {\n+            throw new IllegalArgumentException(\"unsupported sort: \" + e.getMessage(), e);\n         }\n-        BucketedSort bucketedSort = sortBuilders.get(0).buildBucketedSort(searchContext.getQueryShardContext());\n \n         return new TopMetricsAggregator(name, searchContext, parent, pipelineAggregators, metaData, bucketedSort,\n                 metricField.getFieldName(), metricValueSource);\n"}}, {"oid": "49ee3c7ec6a2fba8bd4b78a4a3264aa88124d9ee", "url": "https://github.com/elastic/elasticsearch/commit/49ee3c7ec6a2fba8bd4b78a4a3264aa88124d9ee", "message": "Javadoc", "committedDate": "2020-01-30T17:39:38Z", "type": "commit"}, {"oid": "6d83a2ac1dc67c305d048d8a743f121d8a15b647", "url": "https://github.com/elastic/elasticsearch/commit/6d83a2ac1dc67c305d048d8a743f121d8a15b647", "message": "yaml", "committedDate": "2020-01-30T19:31:12Z", "type": "commit"}, {"oid": "80bf931e07eca3c6b1b75648ffcb373086499dd7", "url": "https://github.com/elastic/elasticsearch/commit/80bf931e07eca3c6b1b75648ffcb373086499dd7", "message": "Force define", "committedDate": "2020-01-30T22:33:14Z", "type": "commit"}, {"oid": "7f46898f458c6c4161e847d23438bd5f9dc13619", "url": "https://github.com/elastic/elasticsearch/commit/7f46898f458c6c4161e847d23438bd5f9dc13619", "message": "Script", "committedDate": "2020-01-31T13:41:29Z", "type": "commit"}, {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "url": "https://github.com/elastic/elasticsearch/commit/c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "message": "geo_distance", "committedDate": "2020-01-31T17:07:56Z", "type": "commit"}, {"oid": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "url": "https://github.com/elastic/elasticsearch/commit/c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "message": "geo_distance", "committedDate": "2020-01-31T17:07:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4OTU5MA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373589590", "bodyText": "I haven't written tests for plugging in these abstractions other than the tests for top_metrics itself. I'd love some advice on what is worth it. This one probably isn't, but DoubleValuesComparatorSource probably is. Same for the sort implementations, I guess. Thoughts?", "author": "nik9000", "createdAt": "2020-01-31T17:14:33Z", "path": "modules/mapper-extras/src/main/java/org/elasticsearch/index/mapper/ScaledFloatFieldMapper.java", "diffHunk": "@@ -522,6 +525,12 @@ public SortField sortField(@Nullable Object missingValue, MultiValueMode sortMod\n             return new SortField(getFieldName(), source, reverse);\n         }\n \n+        @Override\n+        public BucketedSort newBucketedSort(BigArrays bigArrays, Object missingValue, MultiValueMode sortMode, Nested nested,", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMjUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373612504", "bodyText": "I'm not sure tbh.  I'm inclined to say that since top_metrics is the only consumer at the moment, the current testing is sufficient.", "author": "polyfractal", "createdAt": "2020-01-31T18:09:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU4OTU5MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MDA3OA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373590078", "bodyText": "I'm using a ConstructingObjectParser to build ParsedTopHits, thus the change here.", "author": "nik9000", "createdAt": "2020-01-31T17:15:39Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/ParsedAggregation.java", "diffHunk": "@@ -36,7 +36,7 @@\n  */\n public abstract class ParsedAggregation implements Aggregation, ToXContentFragment {\n \n-    protected static void declareAggregationFields(ObjectParser<? extends ParsedAggregation, Void> objectParser) {\n+    protected static void declareAggregationFields(AbstractObjectParser<? extends ParsedAggregation, ?> objectParser) {", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTA1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373591056", "bodyText": "Hmmm - this looks like it should have been a nocommit for me. I don't believe you can get here now but I need to double check on it.", "author": "nik9000", "createdAt": "2020-01-31T17:17:53Z", "path": "server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java", "diffHunk": "@@ -368,13 +348,57 @@ public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n             }\n             SortedNumericDVIndexFieldData numericFieldData = (SortedNumericDVIndexFieldData) fieldData;\n             NumericType resolvedType = resolveNumericType(numericType);\n-            field = numericFieldData.sortField(resolvedType, missing, localSortMode, nested, reverse);\n+            field = numericFieldData.sortField(resolvedType, missing, localSortMode(), nested, reverse);\n         } else {\n-            field = fieldData.sortField(missing, localSortMode, nested, reverse);\n+            field = fieldData.sortField(missing, localSortMode(), nested, reverse);\n         }\n         return new SortFieldAndFormat(field, fieldType.docValueFormat(null, null));\n     }\n \n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        MappedFieldType fieldType = context.fieldMapper(fieldName);\n+        Nested nested = nested(context, fieldType);\n+        if (fieldType == null) {\n+            if (unmappedType != null) {\n+                fieldType = context.getMapperService().unmappedFieldType(unmappedType);\n+            } else {\n+                throw new QueryShardException(context, \"No mapping found for [\" + fieldName + \"] in order to sort on\");\n+            }\n+        }\n+\n+        IndexFieldData<?> fieldData = context.getForField(fieldType);\n+        if (fieldData instanceof IndexNumericFieldData == false\n+                && (sortMode == SortMode.SUM || sortMode == SortMode.AVG || sortMode == SortMode.MEDIAN)) {\n+            throw new QueryShardException(context, \"we only support AVG, MEDIAN and SUM on number based fields\");\n+        }\n+        if (numericType != null) {\n+            throw new IllegalArgumentException(\"not yet supported\");", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNzkxNw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373607917", "bodyText": "Couldn't this be set if the user supplies a numeric_type type hint on the sort object?", "author": "polyfractal", "createdAt": "2020-01-31T17:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTA1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxNjY2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373616661", "bodyText": "GRRR! I had it confused. Yeah. I'll take a look.", "author": "nik9000", "createdAt": "2020-01-31T18:19:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTA1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "05c64643c578120ec405e68101a0b3cd2ef3c0fd", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java b/server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\nindex aa0f4f81100..f6086975039 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/FieldSortBuilder.java\n\n@@ -357,14 +353,14 @@ public class FieldSortBuilder extends SortBuilder<FieldSortBuilder> {\n \n     @Override\n     public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        if (DOC_FIELD_NAME.equals(fieldName)) {\n+            throw new IllegalArgumentException(\"sorting by _doc is not supported\");\n+        }\n+\n         MappedFieldType fieldType = context.fieldMapper(fieldName);\n         Nested nested = nested(context, fieldType);\n         if (fieldType == null) {\n-            if (unmappedType != null) {\n-                fieldType = context.getMapperService().unmappedFieldType(unmappedType);\n-            } else {\n-                throw new QueryShardException(context, \"No mapping found for [\" + fieldName + \"] in order to sort on\");\n-            }\n+            fieldType = resolveUnmappedType(context);\n         }\n \n         IndexFieldData<?> fieldData = context.getForField(fieldType);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MTU4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373591585", "bodyText": "These are all extracted into private methods to make building the BucketedSort simpler.", "author": "nik9000", "createdAt": "2020-01-31T17:19:06Z", "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -489,8 +490,43 @@ public static GeoDistanceSortBuilder fromXContent(XContentParser parser, String\n \n     @Override\n     public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java b/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\nindex bb1b9e6cb1a..ae031fbac8c 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n\n@@ -526,7 +526,7 @@ public class GeoDistanceSortBuilder extends SortBuilder<GeoDistanceSortBuilder>\n     }\n \n     private GeoPoint[] localPoints() {\n-     // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n+        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n         // on 2.x created indexes\n         GeoPoint[] localPoints =  points.toArray(new GeoPoint[points.size()]);\n         if (GeoValidationMethod.isIgnoreMalformed(validation) == false) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjUwOA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373592508", "bodyText": "It looks like we actually have three ways to do geo distance - the optimization above and a single point to single point optimization inside GeoUtils.distanceValues. It isn't clear to me that it is worth doing a bunch of work to mimic the optimization above without benchmarks. Which I will write eventually.", "author": "nik9000", "createdAt": "2020-01-31T17:21:16Z", "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -489,8 +490,43 @@ public static GeoDistanceSortBuilder fromXContent(XContentParser parser, String\n \n     @Override\n     public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        boolean reverse = order == SortOrder.DESC;\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n \n-        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n+        if (geoIndexFieldData.getClass() == LatLonPointDVIndexFieldData.class // only works with 5.x geo_point\n+                && nested == null\n+                && localSortMode == MultiValueMode.MIN // LatLonDocValuesField internally picks the closest point\n+                && unit == DistanceUnit.METERS\n+                && reverse == false\n+                && localPoints.length == 1) {\n+            return new SortFieldAndFormat(\n+                    LatLonDocValuesField.newDistanceSort(fieldName, localPoints[0].lat(), localPoints[0].lon()),\n+                    DocValueFormat.RAW);\n+        }\n+\n+        return new SortFieldAndFormat(\n+                new SortField(fieldName, comparatorSource(localPoints, localSortMode, geoIndexFieldData, nested), reverse),\n+                DocValueFormat.RAW);\n+    }\n+\n+    @Override\n+    public BucketedSort buildBucketedSort(QueryShardContext context) throws IOException {\n+        GeoPoint[] localPoints = localPoints();\n+        MultiValueMode localSortMode = localSortMode();\n+        IndexGeoPointFieldData geoIndexFieldData = fieldData(context);\n+        Nested nested = nested(context);\n+\n+        // TODO implement the single point optimization above ", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwODYyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373608621", "bodyText": "++ I think this is fine to start", "author": "polyfractal", "createdAt": "2020-01-31T17:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java b/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\nindex bb1b9e6cb1a..ae031fbac8c 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java\n\n@@ -526,7 +526,7 @@ public class GeoDistanceSortBuilder extends SortBuilder<GeoDistanceSortBuilder>\n     }\n \n     private GeoPoint[] localPoints() {\n-     // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n+        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed\n         // on 2.x created indexes\n         GeoPoint[] localPoints =  points.toArray(new GeoPoint[points.size()]);\n         if (GeoValidationMethod.isIgnoreMalformed(validation) == false) {\n"}}, {"oid": "e846862865a20ecb3594508cdcab7acbdcc4be37", "url": "https://github.com/elastic/elasticsearch/commit/e846862865a20ecb3594508cdcab7acbdcc4be37", "message": "Fix indentation", "committedDate": "2020-01-31T17:21:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzU5MjkzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373592935", "bodyText": "These seem like candidates for a follow up.", "author": "nik9000", "createdAt": "2020-01-31T17:22:18Z", "path": "server/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortBuilder.java", "diffHunk": "@@ -515,15 +551,19 @@ public SortFieldAndFormat build(QueryShardContext context) throws IOException {\n                 GeoUtils.normalizePoint(point, true, true);\n             }\n         }\n+        return localPoints;\n+    }\n \n-        boolean reverse = (order == SortOrder.DESC);\n-        final MultiValueMode finalSortMode;\n-        if (sortMode == null) {\n-            finalSortMode = reverse ? MultiValueMode.MAX : MultiValueMode.MIN;\n-        } else {\n-            finalSortMode = MultiValueMode.fromString(sortMode.toString());\n+    private MultiValueMode localSortMode() {\n+        // TODO this lines up with FieldSortBuilder. Share?", "originalCommit": "c36f28ee4737d1cc048b30e3ca5e0ce11d95b43c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNTMwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373605301", "bodyText": "Curiosity question: the other exceptions just say \"can only sort on numerics\", but this one is formatted a bit different, is there a reason the CONTENT_TYPE is helpful here but not elsewhere?", "author": "polyfractal", "createdAt": "2020-01-31T17:51:50Z", "path": "server/src/main/java/org/elasticsearch/index/mapper/IdFieldMapper.java", "diffHunk": "@@ -203,6 +207,12 @@ public SortField sortField(Object missingValue, MultiValueMode sortMode, Nested\n                             return new SortField(getFieldName(), source, reverse);\n                         }\n \n+                        @Override\n+                        public BucketedSort newBucketedSort(BigArrays bigArrays, Object missingValue, MultiValueMode sortMode,\n+                                Nested nested, SortOrder sortOrder, DocValueFormat format) {\n+                            throw new UnsupportedOperationException(\"can't sort on the [\" + CONTENT_TYPE + \"] field\");", "originalCommit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxNTgwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373615805", "bodyText": "I copied it from above. I imagine it would be helpful everywhere. Let me see what I can do!", "author": "nik9000", "createdAt": "2020-01-31T18:17:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNTMwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzcwNTEzOA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373705138", "bodyText": "So that data isn't typically available where I throw the exception. If we want it badly enough we can have it, but I think we need to want it.", "author": "nik9000", "createdAt": "2020-01-31T22:01:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNTMwMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYwNjYyMg==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373606622", "bodyText": "\ud83d\udc4d", "author": "polyfractal", "createdAt": "2020-01-31T17:55:03Z", "path": "server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.sort;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.elasticsearch.common.lease.Releasable;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.lucene.ScorerAware;\n+import org.elasticsearch.common.util.BigArray;\n+import org.elasticsearch.common.util.BigArrays;\n+import org.elasticsearch.common.util.BitArray;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.common.util.FloatArray;\n+import org.elasticsearch.common.util.LongArray;\n+import org.elasticsearch.search.DocValueFormat;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Type specialized sort implementations designed for use in aggregations.\n+ */\n+public abstract class BucketedSort implements Releasable {\n+    // TODO priority queue semantics to support multiple hits in the buckets\n+    protected final BigArrays bigArrays;\n+    private final SortOrder order;\n+    private final DocValueFormat format;\n+\n+    public BucketedSort(BigArrays bigArrays, SortOrder order, DocValueFormat format) {\n+        this.bigArrays = bigArrays;\n+        this.order = order;\n+        this.format = format;\n+    }\n+\n+    /**\n+     * The order of the sort.\n+     */\n+    public final SortOrder getOrder() {\n+        return order;\n+    }\n+\n+    /**\n+     * The format to use when presenting the values.\n+     */\n+    public final DocValueFormat getFormat() {\n+        return format;\n+    }\n+\n+    /**\n+     * Get the value for a bucket if it has been collected, null otherwise.\n+     */\n+    public final SortValue getValue(long bucket) {\n+        if (bucket >= buckets().size()) {\n+            return null;\n+        }\n+        return getValueForBucket(bucket);\n+    }\n+\n+    /**\n+     * Get the {@linkplain Leaf} implementation that'll do that actual collecting.\n+     */\n+    public abstract Leaf forLeaf(LeafReaderContext ctx) throws IOException;\n+\n+    /**\n+     * Does this sort need scores? Most don't, but sorting on {@code _score} does.\n+     */\n+    public abstract boolean needsScores();\n+\n+    /**\n+     * The {@linkplain BigArray} backing this sort.\n+     */\n+    protected abstract BigArray buckets();\n+\n+    /**\n+     * Grow the {@linkplain BigArray} backing this sort to account for new buckets.\n+     * This will only be called if the array is too small.\n+     */\n+    protected abstract void grow(long minSize);\n+\n+    /**\n+     * Get the value for a bucket. This will only be called if the bucket was collected.\n+     */\n+    protected abstract SortValue getValueForBucket(long bucket);\n+\n+    /**\n+     * Performs the actual collection against a {@linkplain LeafReaderContext}.\n+     */\n+    public abstract class Leaf implements ScorerAware {\n+        /**\n+         * Collect this doc, returning {@code true} if it is competitive.\n+         */\n+        public final boolean collectIfCompetitive(int doc, long bucket) throws IOException {\n+            if (false == advanceExact(doc)) {\n+                return false;\n+            }\n+            if (bucket >= buckets().size()) {\n+                grow(bucket + 1);\n+                setValue(bucket);\n+                return true;\n+            }\n+            return setIfCompetitive(bucket);\n+        }\n+\n+        /**\n+         * Move the underlying data source reader to the doc and return\n+         * {@code true} if there is data for the sort value.\n+         */\n+        protected abstract boolean advanceExact(int doc) throws IOException;\n+\n+        /**\n+         * Set the value for a particular bucket to the value that doc has for the sort.\n+         * This is called when we're *sure* we haven't yet seen the bucket.\n+         */\n+        protected abstract void setValue(long bucket) throws IOException;\n+\n+        /**\n+         * If the value that doc has for the sort is competitive with the other values\n+         * then set it. This is called for buckets we *might* have already seen. So\n+         * implementers will have to check for \"empty\" buckets in their own way. The\n+         * vaguery here is for two reasons:\n+         * <ul>\n+         * <li>When we see a bucket that won't fit in our arrays we oversize them so\n+         *     we don't have to grow them by 1 every time.</li>\n+         * <li>Buckets don't always arrive in order and our storage is \"dense\" on the\n+         *     bucket ordinal. For example, we might get bucket number 4 grow the array\n+         *     to fit it, and *then* get bucket number 3.</li>\n+         * </ul>\n+         */\n+        protected abstract boolean setIfCompetitive(long bucket) throws IOException;\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code double} keys.\n+     */\n+    public abstract static class ForDoubles extends BucketedSort {\n+        private DoubleArray buckets = bigArrays.newDoubleArray(1);\n+\n+        public ForDoubles(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+            // NaN is a sentinel value for \"unused\"\n+            buckets.set(0, Double.NaN);\n+        }\n+\n+        @Override\n+        public boolean needsScores() { return false; }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            long oldSize = buckets.size();\n+            buckets = bigArrays.grow(buckets, minSize);\n+            buckets.fill(oldSize, buckets.size(), Double.NaN);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            double val = buckets.get(bucket);\n+            if (Double.isNaN(val)) {\n+                return null;\n+            }\n+            return SortValue.from(val);\n+        }\n+\n+        @Override\n+        public final void close() {\n+            buckets.close();\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract double docValue() throws IOException;\n+\n+            @Override\n+            public final void setScorer(Scorable scorer) {}\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                double docSort = docValue();\n+                double bestSort = buckets.get(bucket);\n+                // The NaN check is important here because it needs to always lose.\n+                if (false == Double.isNaN(bestSort) && getOrder().reverseMul() * Double.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code float} keys.\n+     */\n+    public abstract static class ForFloats extends BucketedSort {\n+        private FloatArray buckets = bigArrays.newFloatArray(1);\n+\n+        public ForFloats(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+            // NaN is a sentinel value for \"unused\"\n+            buckets.set(0, Float.NaN);\n+        }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            long oldSize = buckets.size();\n+            buckets = bigArrays.grow(buckets, minSize);\n+            buckets.fill(oldSize, buckets.size(), Float.NaN);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            float val = buckets.get(bucket);\n+            if (Float.isNaN(val)) {\n+                return null;\n+            }\n+            return SortValue.from(val);\n+        }\n+\n+        @Override\n+        public final void close() {\n+            buckets.close();\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract float docValue() throws IOException;\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                float docSort = docValue();\n+                float bestSort = buckets.get(bucket);\n+                // The NaN check is important here because it needs to always lose.\n+                if (false == Float.isNaN(bestSort) && getOrder().reverseMul() * Float.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+\n+        }\n+    }\n+\n+    /**\n+     * Superclass for implementations of {@linkplain BucketedSort} for {@code long} keys.\n+     */\n+    public abstract static class ForLongs extends BucketedSort {\n+        /**\n+         * Tracks which buckets have been seen before so we can *always*\n+         * set the value in that case. We need this because there isn't a\n+         * sentinel value in the {@code long} type that we can use for this\n+         * like NaN in {@code double} or {@code float}.\n+         */\n+        private BitArray seen = new BitArray(1, bigArrays);\n+        /**\n+         * The actual values.\n+         */\n+        private LongArray buckets = bigArrays.newLongArray(1);\n+\n+        public ForLongs(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+            super(bigArrays, sortOrder, format);\n+        }\n+\n+        @Override\n+        public boolean needsScores() { return false; }\n+\n+        @Override\n+        protected final BigArray buckets() { return buckets; }\n+\n+        @Override\n+        protected final void grow(long minSize) {\n+            buckets = bigArrays.grow(buckets, minSize);\n+        }\n+\n+        @Override\n+        public final SortValue getValueForBucket(long bucket) {\n+            if (bucket > Integer.MAX_VALUE) {\n+                /* We throw exceptions if we try to collect buckets bigger\n+                 * than an int so we *can't* have seen any of these. */\n+                return null;\n+            }\n+            if (false == seen.get((int) bucket)) {\n+                /* Buckets we haven't seen must be null here so we can\n+                 * skip \"gaps\" in seen buckets. */\n+                return null;\n+            }\n+            return SortValue.from(buckets.get(bucket));\n+        }\n+\n+        @Override\n+        public final void close() {\n+            Releasables.close(seen, buckets);\n+        }\n+\n+        protected abstract class Leaf extends BucketedSort.Leaf {\n+            protected abstract long docValue() throws IOException;\n+\n+            @Override\n+            public final void setScorer(Scorable scorer) {}\n+\n+            @Override\n+            protected final void setValue(long bucket) throws IOException {\n+                seen.set(bucketIsInt(bucket));\n+                buckets.set(bucket, docValue());\n+            }\n+\n+            @Override\n+            protected final boolean setIfCompetitive(long bucket) throws IOException {\n+                long docSort = docValue();\n+                int intBucket = bucketIsInt(bucket);\n+                if (false == seen.get(intBucket)) {\n+                    seen.set(intBucket);\n+                    buckets.set(bucket, docSort);\n+                    return true;\n+                }\n+                long bestSort = buckets.get(bucket); \n+                if (getOrder().reverseMul() * Double.compare(bestSort, docSort) <= 0) {\n+                    return false;\n+                }\n+                buckets.set(bucket, docSort);\n+                return true;\n+            }\n+\n+            private int bucketIsInt(long bucket) {\n+                if (bucket > Integer.MAX_VALUE) {\n+                    throw new UnsupportedOperationException(\"Long sort keys don't support more than [\" + Integer.MAX_VALUE + \"] buckets\");\n+                    // I don't feel too bad about that because it'd take about 16 GB of memory....", "originalCommit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7762c4fce9fa8cba24500614a9e2878053c51944", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\nindex 48a89a4134c..9070f0003da 100644\n--- a/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n+++ b/server/src/main/java/org/elasticsearch/search/sort/BucketedSort.java\n\n@@ -284,6 +284,7 @@ public abstract class BucketedSort implements Releasable {\n          * The actual values.\n          */\n         private LongArray buckets = bigArrays.newLongArray(1);\n+        private long maxBucket = -1;\n \n         public ForLongs(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n             super(bigArrays, sortOrder, format);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMDU3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373610577", "bodyText": "Not sure I understand the comment.  Extend \"Base\"?", "author": "polyfractal", "createdAt": "2020-01-31T18:04:33Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortValue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Collects the {@code top_metrics} aggregation.\n+ *\n+ * This extends {@linkplain NumericMetricsAggregator.MultiValue} as a compromise\n+ * to allow sorting on the metric. Right now it only collects a single metric\n+ * but we expect it to collect a list of them in the future. Also in the future\n+ * we expect it to allow collecting non-string metrics which'll change how we\n+ * do the inheritance. Finally, we also expect it to allow collecting more than\n+ * one document worth of metrics. Once that happens we'll need to come up with\n+ * some way to pick which document's metrics to use for the sort.\n+ */\n+class TopMetricsAggregator extends MetricsAggregator {\n+    private final BucketedSort sort;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData, BucketedSort sort,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sort = sort;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = (sort != null && sort.needsScores()) || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        assert sub == LeafBucketCollector.NO_OP_COLLECTOR : \"Expected noop but was \" + sub.toString();\n+\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        BucketedSort.Leaf leafSort = sort.forLeaf(ctx);\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.", "originalCommit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxNjI3OA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373616278", "bodyText": "I believe this is a leftover. I'll remove.", "author": "nik9000", "createdAt": "2020-01-31T18:18:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMDU3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "6dbc02b7398d28d19504de7ce5138753ee000fe6", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\nindex d1ea8c4c1a7..40e041204fd 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n\n@@ -75,7 +75,7 @@ class TopMetricsAggregator extends MetricsAggregator {\n         // TODO allow configuration of value mode\n         NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n \n-        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.\n+        return new LeafBucketCollector() {\n             @Override\n             public void collect(int doc, long bucket) throws IOException {\n                 if (leafSort.collectIfCompetitive(doc, bucket)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzYxMTA4NA==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r373611084", "bodyText": "This is much cleaner, thanks for rewiring it to send the SortValue (despite making that class comparatively a lot larger b/c of all the serialization)", "author": "polyfractal", "createdAt": "2020-01-31T18:05:53Z", "path": "x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.analytics.topmetrics;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.Scorable;\n+import org.apache.lucene.search.ScoreMode;\n+import org.elasticsearch.common.lease.Releasables;\n+import org.elasticsearch.common.util.DoubleArray;\n+import org.elasticsearch.index.fielddata.NumericDoubleValues;\n+import org.elasticsearch.search.MultiValueMode;\n+import org.elasticsearch.search.aggregations.Aggregator;\n+import org.elasticsearch.search.aggregations.InternalAggregation;\n+import org.elasticsearch.search.aggregations.LeafBucketCollector;\n+import org.elasticsearch.search.aggregations.metrics.MetricsAggregator;\n+import org.elasticsearch.search.aggregations.metrics.NumericMetricsAggregator;\n+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;\n+import org.elasticsearch.search.aggregations.support.ValuesSource;\n+import org.elasticsearch.search.internal.SearchContext;\n+import org.elasticsearch.search.sort.BucketedSort;\n+import org.elasticsearch.search.sort.SortValue;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Collects the {@code top_metrics} aggregation.\n+ *\n+ * This extends {@linkplain NumericMetricsAggregator.MultiValue} as a compromise\n+ * to allow sorting on the metric. Right now it only collects a single metric\n+ * but we expect it to collect a list of them in the future. Also in the future\n+ * we expect it to allow collecting non-string metrics which'll change how we\n+ * do the inheritance. Finally, we also expect it to allow collecting more than\n+ * one document worth of metrics. Once that happens we'll need to come up with\n+ * some way to pick which document's metrics to use for the sort.\n+ */\n+class TopMetricsAggregator extends MetricsAggregator {\n+    private final BucketedSort sort;\n+    private final String metricName;\n+    private final ValuesSource.Numeric metricValueSource;\n+    private DoubleArray values;\n+\n+    TopMetricsAggregator(String name, SearchContext context, Aggregator parent, List<PipelineAggregator> pipelineAggregators,\n+            Map<String, Object> metaData, BucketedSort sort,\n+            String metricName, ValuesSource.Numeric metricValueSource) throws IOException {\n+        super(name, context, parent, pipelineAggregators, metaData);\n+        this.sort = sort;\n+        this.metricName = metricName;\n+        this.metricValueSource = metricValueSource;\n+        if (metricValueSource != null) {\n+            values = context.bigArrays().newDoubleArray(2, false);\n+            values.fill(0, values.size(), Double.NaN);\n+        }\n+    }\n+\n+    @Override\n+    public ScoreMode scoreMode() {\n+        boolean needs = (sort != null && sort.needsScores()) || (metricValueSource != null && metricValueSource.needsScores());\n+        return needs ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES;\n+    }\n+\n+    @Override\n+    public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {\n+        assert sub == LeafBucketCollector.NO_OP_COLLECTOR : \"Expected noop but was \" + sub.toString();\n+\n+        if (metricValueSource == null) {\n+            return LeafBucketCollector.NO_OP_COLLECTOR;\n+        }\n+        BucketedSort.Leaf leafSort = sort.forLeaf(ctx);\n+        // TODO allow configuration of value mode\n+        NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n+\n+        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.\n+            @Override\n+            public void collect(int doc, long bucket) throws IOException {\n+                if (leafSort.collectIfCompetitive(doc, bucket)) {\n+                    if (bucket >= values.size()) {\n+                        long oldSize = values.size();\n+                        values = context.bigArrays().grow(values, bucket + 1);\n+                        values.fill(oldSize, values.size(), Double.NaN);\n+                    }\n+                    double metricValue = metricValues.advanceExact(doc) ? metricValues.doubleValue() : Double.NaN; \n+                    values.set(bucket, metricValue);\n+                }\n+            }\n+\n+            @Override\n+            public void setScorer(Scorable s) throws IOException {\n+                leafSort.setScorer(s);\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public InternalAggregation buildAggregation(long bucket) throws IOException {\n+        if (metricValueSource == null) {\n+            return buildEmptyAggregation();\n+        }\n+        double metricValue = values.get(bucket);\n+        SortValue sortValue = sort.getValue(bucket);", "originalCommit": "e846862865a20ecb3594508cdcab7acbdcc4be37", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6dbc02b7398d28d19504de7ce5138753ee000fe6", "chunk": "diff --git a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\nindex d1ea8c4c1a7..40e041204fd 100644\n--- a/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n+++ b/x-pack/plugin/analytics/src/main/java/org/elasticsearch/xpack/analytics/topmetrics/TopMetricsAggregator.java\n\n@@ -75,7 +75,7 @@ class TopMetricsAggregator extends MetricsAggregator {\n         // TODO allow configuration of value mode\n         NumericDoubleValues metricValues = MultiValueMode.AVG.select(metricValueSource.doubleValues(ctx));\n \n-        return new LeafBucketCollector() { // TODO do we need to extend *Base*? It doesn't look like we use it.\n+        return new LeafBucketCollector() {\n             @Override\n             public void collect(int doc, long bucket) throws IOException {\n                 if (leafSort.collectIfCompetitive(doc, bucket)) {\n"}}, {"oid": "af3fe9d7ee440a28adbb550ba18b5ad82641522e", "url": "https://github.com/elastic/elasticsearch/commit/af3fe9d7ee440a28adbb550ba18b5ad82641522e", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-31T18:39:02Z", "type": "commit"}, {"oid": "05c64643c578120ec405e68101a0b3cd2ef3c0fd", "url": "https://github.com/elastic/elasticsearch/commit/05c64643c578120ec405e68101a0b3cd2ef3c0fd", "message": "WIP", "committedDate": "2020-01-31T21:36:52Z", "type": "commit"}, {"oid": "0a9e3cce0dec822789217873325367fd2ec18683", "url": "https://github.com/elastic/elasticsearch/commit/0a9e3cce0dec822789217873325367fd2ec18683", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-01-31T21:37:08Z", "type": "commit"}, {"oid": "36eb495a894077c852bb35ce9c65e68d3687ead8", "url": "https://github.com/elastic/elasticsearch/commit/36eb495a894077c852bb35ce9c65e68d3687ead8", "message": "Fixup casting", "committedDate": "2020-01-31T21:43:41Z", "type": "commit"}, {"oid": "290cc279154b5850946cb7c6089b574400b78855", "url": "https://github.com/elastic/elasticsearch/commit/290cc279154b5850946cb7c6089b574400b78855", "message": "Cleanup", "committedDate": "2020-01-31T21:59:58Z", "type": "commit"}, {"oid": "6dbc02b7398d28d19504de7ce5138753ee000fe6", "url": "https://github.com/elastic/elasticsearch/commit/6dbc02b7398d28d19504de7ce5138753ee000fe6", "message": "Drop out of date comment", "committedDate": "2020-02-03T12:55:07Z", "type": "commit"}, {"oid": "5902e6c3871073de21fe04e16422b465a3335d87", "url": "https://github.com/elastic/elasticsearch/commit/5902e6c3871073de21fe04e16422b465a3335d87", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-03T13:04:38Z", "type": "commit"}, {"oid": "ca3acf20d65175d5706f1bfbd9e1f545bb9213a6", "url": "https://github.com/elastic/elasticsearch/commit/ca3acf20d65175d5706f1bfbd9e1f545bb9213a6", "message": "Update docs", "committedDate": "2020-02-03T14:24:29Z", "type": "commit"}, {"oid": "1fc6a2a86b38aac74ac1e853db18fcaf2bf1efec", "url": "https://github.com/elastic/elasticsearch/commit/1fc6a2a86b38aac74ac1e853db18fcaf2bf1efec", "message": "numeric_type examples", "committedDate": "2020-02-03T15:24:08Z", "type": "commit"}, {"oid": "a06ca3c2c05afed4e6db1fffe9b192646dca544f", "url": "https://github.com/elastic/elasticsearch/commit/a06ca3c2c05afed4e6db1fffe9b192646dca544f", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-04T15:02:06Z", "type": "commit"}, {"oid": "7762c4fce9fa8cba24500614a9e2878053c51944", "url": "https://github.com/elastic/elasticsearch/commit/7762c4fce9fa8cba24500614a9e2878053c51944", "message": "Ooops", "committedDate": "2020-02-04T20:44:02Z", "type": "commit"}, {"oid": "0b7871595b15779b36d0e154f7b9f32205a25d2a", "url": "https://github.com/elastic/elasticsearch/commit/0b7871595b15779b36d0e154f7b9f32205a25d2a", "message": "Implement sorting by top_metrics", "committedDate": "2020-02-04T21:49:30Z", "type": "commit"}, {"oid": "ea2e9974cef8da15804382d1f84764094aa50c48", "url": "https://github.com/elastic/elasticsearch/commit/ea2e9974cef8da15804382d1f84764094aa50c48", "message": "Better shuffle", "committedDate": "2020-02-05T13:19:22Z", "type": "commit"}, {"oid": "bdd067631a18f196185d709392ebd205082ffd84", "url": "https://github.com/elastic/elasticsearch/commit/bdd067631a18f196185d709392ebd205082ffd84", "message": "Checkstyle", "committedDate": "2020-02-05T14:51:46Z", "type": "commit"}, {"oid": "09d969b297eb94a58a6eaeae26a48566edb4e32a", "url": "https://github.com/elastic/elasticsearch/commit/09d969b297eb94a58a6eaeae26a48566edb4e32a", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-05T14:54:25Z", "type": "commit"}, {"oid": "d7429b6c556550600b4d5df79b38154b8d5720af", "url": "https://github.com/elastic/elasticsearch/commit/d7429b6c556550600b4d5df79b38154b8d5720af", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-05T17:21:02Z", "type": "commit"}, {"oid": "d1b90e2bc0a4d875bd9220879d3003f2a005ac3d", "url": "https://github.com/elastic/elasticsearch/commit/d1b90e2bc0a4d875bd9220879d3003f2a005ac3d", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-05T19:25:45Z", "type": "commit"}, {"oid": "c7b63177a8fc891b98d287360997652031e9e96a", "url": "https://github.com/elastic/elasticsearch/commit/c7b63177a8fc891b98d287360997652031e9e96a", "message": "Docs and test", "committedDate": "2020-02-05T21:36:37Z", "type": "commit"}, {"oid": "ba6e21f7f50bab21d13eb382f7438c0fd0173602", "url": "https://github.com/elastic/elasticsearch/commit/ba6e21f7f50bab21d13eb382f7438c0fd0173602", "message": "Tests", "committedDate": "2020-02-05T21:47:29Z", "type": "commit"}, {"oid": "fdada3cf70cadb43e1155ec11acd6d24e05c649f", "url": "https://github.com/elastic/elasticsearch/commit/fdada3cf70cadb43e1155ec11acd6d24e05c649f", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-05T23:43:33Z", "type": "commit"}, {"oid": "e47d6c64dc775912f8bce25d91ea0770df4171aa", "url": "https://github.com/elastic/elasticsearch/commit/e47d6c64dc775912f8bce25d91ea0770df4171aa", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-10T18:54:43Z", "type": "commit"}, {"oid": "abfc012a779540d95290f32fd1b05a97a6efd6a1", "url": "https://github.com/elastic/elasticsearch/commit/abfc012a779540d95290f32fd1b05a97a6efd6a1", "message": "Fix javadoc", "committedDate": "2020-02-10T18:55:57Z", "type": "commit"}, {"oid": "03ff2b5cec336200738e37823829587cf93be0e3", "url": "https://github.com/elastic/elasticsearch/commit/03ff2b5cec336200738e37823829587cf93be0e3", "message": "Javadoc", "committedDate": "2020-02-10T19:02:01Z", "type": "commit"}, {"oid": "04c2fcd4fd6fe888e906e2db54f4b44151a32f00", "url": "https://github.com/elastic/elasticsearch/commit/04c2fcd4fd6fe888e906e2db54f4b44151a32f00", "message": "Merge!", "committedDate": "2020-02-11T18:02:04Z", "type": "commit"}, {"oid": "9752139c9eb0ae4ddb6da39037e2233617159c82", "url": "https://github.com/elastic/elasticsearch/commit/9752139c9eb0ae4ddb6da39037e2233617159c82", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-11T18:20:40Z", "type": "commit"}, {"oid": "4240a53a62f9ad891982aa6791b07b889c26836f", "url": "https://github.com/elastic/elasticsearch/commit/4240a53a62f9ad891982aa6791b07b889c26836f", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-11T20:53:39Z", "type": "commit"}, {"oid": "ca6e52d6fc9ed17e0176546ed9d84edf7cd5c149", "url": "https://github.com/elastic/elasticsearch/commit/ca6e52d6fc9ed17e0176546ed9d84edf7cd5c149", "message": "Test", "committedDate": "2020-02-11T20:59:34Z", "type": "commit"}, {"oid": "792da85be72714f486271336b49948e797c6d850", "url": "https://github.com/elastic/elasticsearch/commit/792da85be72714f486271336b49948e797c6d850", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-13T13:04:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NzA0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379047042", "bodyText": "Can we add more information to this error message, e.g. index name, field name, field type?", "author": "jpountz", "createdAt": "2020-02-13T18:40:59Z", "path": "server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java", "diffHunk": "@@ -135,6 +139,11 @@ public void setScorer(Scorable scorer) {\n         };\n     }\n \n+    @Override\n+    public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n+        throw new IllegalArgumentException(\"only supported on numeric values\");", "originalCommit": "792da85be72714f486271336b49948e797c6d850", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA1MzE0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51155#discussion_r379053141", "bodyText": "Please ignore if this would make the API horrible due to the need to propagate the required information.", "author": "jpountz", "createdAt": "2020-02-13T18:52:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NzA0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java b/server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java\nindex de6a51507ba..b170c1aeae4 100644\n--- a/server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java\n+++ b/server/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefFieldComparatorSource.java\n\n@@ -141,7 +141,7 @@ public class BytesRefFieldComparatorSource extends IndexFieldData.XFieldComparat\n \n     @Override\n     public BucketedSort newBucketedSort(BigArrays bigArrays, SortOrder sortOrder, DocValueFormat format) {\n-        throw new IllegalArgumentException(\"only supported on numeric values\");\n+        throw new IllegalArgumentException(\"only supported on numeric fields\");\n     }\n \n     /**\n"}}, {"oid": "6577077ed0a5fb4303f467426f753f51e21b57c0", "url": "https://github.com/elastic/elasticsearch/commit/6577077ed0a5fb4303f467426f753f51e21b57c0", "message": "Merge branch 'master' into top_metrics", "committedDate": "2020-02-13T20:56:32Z", "type": "commit"}, {"oid": "43c705b9342132869124105139049cc276e8048d", "url": "https://github.com/elastic/elasticsearch/commit/43c705b9342132869124105139049cc276e8048d", "message": "Merge tests", "committedDate": "2020-02-13T20:58:39Z", "type": "commit"}, {"oid": "5f46829bfcbd6267bd312cc177e8679aac4786e0", "url": "https://github.com/elastic/elasticsearch/commit/5f46829bfcbd6267bd312cc177e8679aac4786e0", "message": "Flip example", "committedDate": "2020-02-13T21:03:52Z", "type": "commit"}, {"oid": "2b5dca14bd82fe36972005c0b4c5fc28c20d276d", "url": "https://github.com/elastic/elasticsearch/commit/2b5dca14bd82fe36972005c0b4c5fc28c20d276d", "message": "No tie breaking", "committedDate": "2020-02-13T21:20:01Z", "type": "commit"}, {"oid": "e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "url": "https://github.com/elastic/elasticsearch/commit/e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "message": "Error message", "committedDate": "2020-02-13T22:35:49Z", "type": "commit"}, {"oid": "e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "url": "https://github.com/elastic/elasticsearch/commit/e6fd60142e2c5aa9b89614a84543990f3a53ad6f", "message": "Error message", "committedDate": "2020-02-13T22:35:49Z", "type": "forcePushed"}, {"oid": "134d99b842afab240c4e230f4ebc5aca7b3d9cfb", "url": "https://github.com/elastic/elasticsearch/commit/134d99b842afab240c4e230f4ebc5aca7b3d9cfb", "message": "Word", "committedDate": "2020-02-13T23:37:07Z", "type": "commit"}, {"oid": "896e08aa33b2b1f70a8f706e4461798f7bc0b282", "url": "https://github.com/elastic/elasticsearch/commit/896e08aa33b2b1f70a8f706e4461798f7bc0b282", "message": "Another word", "committedDate": "2020-02-14T11:00:55Z", "type": "commit"}]}