{"pr_number": 51593, "pr_title": "Optimize GCS Mock", "pr_createdAt": "2020-01-29T07:45:31Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51593", "timeline": [{"oid": "a586dfdf53f37c7a7c330f6caaa1f2a493643be4", "url": "https://github.com/elastic/elasticsearch/commit/a586dfdf53f37c7a7c330f6caaa1f2a493643be4", "message": "Optimize GCS Mock\n\nThis test was still very GC heavy in Java 8 runs in particular\nwhich seems to slow down request processing to the point of timeouts\nin some runs.\nThis PR completely removes the large number of O(MB) `byte[]` allocations\nthat were happening in the mock http handler which cuts the allocation rate\nby about a factor of 5 in my local testing for the GC heavy `testSnapshotWithLargeSegmentFiles`\nrun.\n\nCloses #51446", "committedDate": "2020-01-29T07:29:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjIzMjQyMw==", "url": "https://github.com/elastic/elasticsearch/pull/51593#discussion_r372232423", "bodyText": "Using the BAOS here was pretty brutal for multi MB requests :) Much nicer now with the 16kb chunks Streams.readFully(wrappedRequest) produces", "author": "original-brownbear", "createdAt": "2020-01-29T07:53:25Z", "path": "test/fixtures/gcs-fixture/src/main/java/fixture/gcs/GoogleCloudStorageHttpHandler.java", "diffHunk": "@@ -212,35 +213,21 @@ public void handle(final HttpExchange exchange) throws IOException {\n                     exchange.sendResponseHeaders(RestStatus.NOT_FOUND.getStatus(), -1);\n                     return;\n                 }\n-                byte[] blob = BytesReference.toBytes(blobs.get(blobName));\n+                BytesReference blob = blobs.get(blobName);\n                 final String range = exchange.getRequestHeaders().getFirst(\"Content-Range\");\n                 final Integer limit = getContentRangeLimit(range);\n                 final int start = getContentRangeStart(range);\n                 final int end = getContentRangeEnd(range);\n \n-                final ByteArrayOutputStream out = new ByteArrayOutputStream() {", "originalCommit": "a586dfdf53f37c7a7c330f6caaa1f2a493643be4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjIzMjk2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51593#discussion_r372232967", "bodyText": "Even though slice wastes some memory here for the wrapping around the actual blob content for smaller blobs, it's a huge efficiency gain to stick with 16kb chunks from the BytesReference compared to allocating a potentially MB sized array.", "author": "original-brownbear", "createdAt": "2020-01-29T07:54:57Z", "path": "test/fixtures/gcs-fixture/src/main/java/fixture/gcs/GoogleCloudStorageHttpHandler.java", "diffHunk": "@@ -308,10 +295,7 @@ private String httpServerUrl(final HttpExchange exchange) {\n             } else {\n                 // removes the trailing end \"\\r\\n--__END_OF_PART__--\\r\\n\" which is 23 bytes long\n                 int len = fullRequestBody.length() - startPos - 23;\n-                final InputStream stream = fullRequestBody.slice(startPos, len).streamInput();\n-                final byte[] buffer = new byte[len];\n-                Streams.readFully(stream, buffer);\n-                content = Tuple.tuple(name, new BytesArray(buffer));\n+                content = Tuple.tuple(name, fullRequestBody.slice(startPos, len));", "originalCommit": "a586dfdf53f37c7a7c330f6caaa1f2a493643be4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjIzODg1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51593#discussion_r372238856", "bodyText": "I didn't know about this one \ud83d\udc4d", "author": "tlrx", "createdAt": "2020-01-29T08:12:30Z", "path": "test/fixtures/gcs-fixture/src/main/java/fixture/gcs/GoogleCloudStorageHttpHandler.java", "diffHunk": "@@ -212,35 +213,21 @@ public void handle(final HttpExchange exchange) throws IOException {\n                     exchange.sendResponseHeaders(RestStatus.NOT_FOUND.getStatus(), -1);\n                     return;\n                 }\n-                byte[] blob = BytesReference.toBytes(blobs.get(blobName));\n+                BytesReference blob = blobs.get(blobName);\n                 final String range = exchange.getRequestHeaders().getFirst(\"Content-Range\");\n                 final Integer limit = getContentRangeLimit(range);\n                 final int start = getContentRangeStart(range);\n                 final int end = getContentRangeEnd(range);\n \n-                final ByteArrayOutputStream out = new ByteArrayOutputStream() {\n-                    @Override\n-                    public byte[] toByteArray() {\n-                        return buf;\n-                    }\n-                };\n-                long bytesRead = Streams.copy(wrappedRequest, out, new byte[128]);\n-                int length = Math.max(end + 1, limit != null ? limit : 0);\n-                if ((int) bytesRead > length) {\n-                    throw new AssertionError(\"Requesting more bytes than available for blob\");\n-                }\n-                if (length > blob.length) {\n-                    blob = ArrayUtil.growExact(blob, length);\n-                }\n-                System.arraycopy(out.toByteArray(), 0, blob, start, Math.toIntExact(bytesRead));\n-                blobs.put(blobName, new BytesArray(blob));\n+                blob = new CompositeBytesReference(blob, Streams.readFully(wrappedRequest));", "originalCommit": "a586dfdf53f37c7a7c330f6caaa1f2a493643be4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}