{"pr_number": 58707, "pr_title": "Data Stream Stats API", "pr_createdAt": "2020-06-29T22:15:30Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58707", "timeline": [{"oid": "3c2d4dee1191316f343c700937143326372361b6", "url": "https://github.com/elastic/elasticsearch/commit/3c2d4dee1191316f343c700937143326372361b6", "message": "WIP", "committedDate": "2020-06-29T19:11:16Z", "type": "commit"}, {"oid": "9505e33bde84ce157eea132296e3aa5765db0d4f", "url": "https://github.com/elastic/elasticsearch/commit/9505e33bde84ce157eea132296e3aa5765db0d4f", "message": "Some clean up", "committedDate": "2020-06-29T22:07:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4NzQ2MA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r447287460", "bodyText": "This is on the short list to move to a utility where the logic can be shared between the places it is used.", "author": "jbaiera", "createdAt": "2020-06-29T22:16:21Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.stats;\n+\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.regex.Regex;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.index.IndexNotFoundException;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class TransportDataStreamsStatsAction extends TransportBroadcastByNodeAction<DataStreamsStatsRequest, DataStreamsStatsResponse,\n+    DataStreamShardStats> {\n+\n+    private final IndicesService indicesService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+\n+    @Inject\n+    public TransportDataStreamsStatsAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n+                                       ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n+        super(DataStreamStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n+            DataStreamsStatsRequest::new, ThreadPool.Names.MANAGEMENT);\n+        this.indicesService = indicesService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+    }\n+\n+    @Override\n+    protected DataStreamsStatsRequest readRequestFrom(StreamInput in) throws IOException {\n+        return new DataStreamsStatsRequest(in);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkGlobalBlock(ClusterState state, DataStreamsStatsRequest request) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkRequestBlock(ClusterState state, DataStreamsStatsRequest request, String[] concreteIndices) {\n+        return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n+    }\n+\n+    private static List<String> resolveIndexAbstractions(String[] indices, IndicesOptions indicesOptions, Metadata metadata,", "originalCommit": "9505e33bde84ce157eea132296e3aa5765db0d4f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b3a903a30ba1158cbbfe33ff27c84055ce50f426", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\nindex 65f560b50c9..223aa8949fa 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\n\n@@ -19,6 +19,9 @@\n \n package org.elasticsearch.action.admin.indices.stats;\n \n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n import org.elasticsearch.action.support.ActionFilters;\n import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n import org.elasticsearch.action.support.IndicesOptions;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4ODI4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r447288283", "bodyText": "Working on doing the lucene searching at the shard level to obtain this. Could use some guidance here.", "author": "jbaiera", "createdAt": "2020-06-29T22:17:18Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.stats;\n+\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.regex.Regex;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.index.IndexNotFoundException;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class TransportDataStreamsStatsAction extends TransportBroadcastByNodeAction<DataStreamsStatsRequest, DataStreamsStatsResponse,\n+    DataStreamShardStats> {\n+\n+    private final IndicesService indicesService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+\n+    @Inject\n+    public TransportDataStreamsStatsAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n+                                       ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n+        super(DataStreamStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n+            DataStreamsStatsRequest::new, ThreadPool.Names.MANAGEMENT);\n+        this.indicesService = indicesService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+    }\n+\n+    @Override\n+    protected DataStreamsStatsRequest readRequestFrom(StreamInput in) throws IOException {\n+        return new DataStreamsStatsRequest(in);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkGlobalBlock(ClusterState state, DataStreamsStatsRequest request) {\n+        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n+    }\n+\n+    @Override\n+    protected ClusterBlockException checkRequestBlock(ClusterState state, DataStreamsStatsRequest request, String[] concreteIndices) {\n+        return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n+    }\n+\n+    private static List<String> resolveIndexAbstractions(String[] indices, IndicesOptions indicesOptions, Metadata metadata,\n+                                                         IndexNameExpressionResolver indexNameExpressionResolver) {\n+        final boolean replaceWildcards = indicesOptions.expandWildcardsOpen() || indicesOptions.expandWildcardsClosed();\n+        Set<String> availableIndexAbstractions = metadata.getIndicesLookup().keySet();\n+        List<String> finalIndices = new ArrayList<>();\n+        boolean wildcardSeen = false;\n+        for (String index : indices) {\n+            String indexAbstraction;\n+            boolean minus = false;\n+            if (index.charAt(0) == '-' && wildcardSeen) {\n+                indexAbstraction = index.substring(1);\n+                minus = true;\n+            } else {\n+                indexAbstraction = index;\n+            }\n+\n+            // we always need to check for date math expressions\n+            final String dateMathName = indexNameExpressionResolver.resolveDateMathExpression(indexAbstraction);\n+            if (dateMathName != indexAbstraction) {\n+                assert dateMathName.equals(indexAbstraction) == false;\n+                if (replaceWildcards && Regex.isSimpleMatchPattern(dateMathName)) {\n+                    // continue\n+                    indexAbstraction = dateMathName;\n+                } else if (availableIndexAbstractions.contains(dateMathName) &&\n+                    isIndexVisible(indexAbstraction, dateMathName, indicesOptions, metadata, true)) {\n+                    if (minus) {\n+                        finalIndices.remove(dateMathName);\n+                    } else {\n+                        finalIndices.add(dateMathName);\n+                    }\n+                } else {\n+                    if (indicesOptions.ignoreUnavailable() == false) {\n+                        throw new IndexNotFoundException(dateMathName);\n+                    }\n+                }\n+            }\n+\n+            if (replaceWildcards && Regex.isSimpleMatchPattern(indexAbstraction)) {\n+                wildcardSeen = true;\n+                Set<String> resolvedIndices = new HashSet<>();\n+                for (String authorizedIndex : availableIndexAbstractions) {\n+                    if (Regex.simpleMatch(indexAbstraction, authorizedIndex) &&\n+                        isIndexVisible(indexAbstraction, authorizedIndex, indicesOptions, metadata)) {\n+                        resolvedIndices.add(authorizedIndex);\n+                    }\n+                }\n+                if (resolvedIndices.isEmpty()) {\n+                    //es core honours allow_no_indices for each wildcard expression, we do the same here by throwing index not found.\n+                    if (indicesOptions.allowNoIndices() == false) {\n+                        throw new IndexNotFoundException(indexAbstraction);\n+                    }\n+                } else {\n+                    if (minus) {\n+                        finalIndices.removeAll(resolvedIndices);\n+                    } else {\n+                        finalIndices.addAll(resolvedIndices);\n+                    }\n+                }\n+            } else if (dateMathName.equals(indexAbstraction)) {\n+                if (minus) {\n+                    finalIndices.remove(indexAbstraction);\n+                } else {\n+                    finalIndices.add(indexAbstraction);\n+                }\n+            }\n+        }\n+        return finalIndices;\n+    }\n+\n+    private static boolean isIndexVisible(String expression, String index, IndicesOptions indicesOptions, Metadata metadata) {\n+        return isIndexVisible(expression, index, indicesOptions, metadata, false);\n+    }\n+\n+    private static boolean isIndexVisible(String expression, String index, IndicesOptions indicesOptions, Metadata metadata,\n+                                          boolean dateMathExpression) {\n+        IndexAbstraction indexAbstraction = metadata.getIndicesLookup().get(index);\n+        final boolean isHidden = indexAbstraction.isHidden();\n+        if (indexAbstraction.getType() == IndexAbstraction.Type.ALIAS) {\n+            //it's an alias, ignore expandWildcardsOpen and expandWildcardsClosed.\n+            //complicated to support those options with aliases pointing to multiple indices...\n+            if (indicesOptions.ignoreAliases()) {\n+                return false;\n+            } else if (isHidden == false || indicesOptions.expandWildcardsHidden() || isVisibleDueToImplicitHidden(expression, index)) {\n+                return true;\n+            } else {\n+                return false;\n+            }\n+        }\n+        if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {\n+            // If indicesOptions.includeDataStreams() returns false then we fail later in IndexNameExpressionResolver.\n+            if (isHidden == false || indicesOptions.expandWildcardsHidden()) {\n+                return true;\n+            } else {\n+                return false;\n+            }\n+        }\n+        assert indexAbstraction.getIndices().size() == 1 : \"concrete index must point to a single index\";\n+        IndexMetadata indexMetadata = indexAbstraction.getIndices().get(0);\n+        if (isHidden && indicesOptions.expandWildcardsHidden() == false && isVisibleDueToImplicitHidden(expression, index) == false) {\n+            return false;\n+        }\n+\n+        // the index is not hidden and since it is a date math expression, we consider it visible regardless of open/closed\n+        if (dateMathExpression) {\n+            assert IndexMetadata.State.values().length == 2 : \"a new IndexMetadata.State value may need to be handled!\";\n+            return true;\n+        }\n+        if (indexMetadata.getState() == IndexMetadata.State.CLOSE && indicesOptions.expandWildcardsClosed()) {\n+            return true;\n+        }\n+        if (indexMetadata.getState() == IndexMetadata.State.OPEN && indicesOptions.expandWildcardsOpen()) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    private static boolean isVisibleDueToImplicitHidden(String expression, String index) {\n+        return index.startsWith(\".\") && expression.startsWith(\".\") && Regex.isSimpleMatchPattern(expression);\n+    }\n+\n+    @Override\n+    protected ShardsIterator shards(ClusterState clusterState, DataStreamsStatsRequest request, String[] concreteIndices) {\n+        String[] requestIndices = request.indices();\n+        if (requestIndices == null || requestIndices.length == 0) {\n+            requestIndices = new String[]{\"*\"};\n+        }\n+        List<String> abstractionNames = resolveIndexAbstractions(requestIndices, request.indicesOptions(), clusterState.getMetadata(), indexNameExpressionResolver);\n+        SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n+\n+        String[] concreteDatastreamIndices = abstractionNames.stream().flatMap(abstractionName -> {\n+            IndexAbstraction indexAbstraction = indicesLookup.get(abstractionName);\n+            assert indexAbstraction != null;\n+            if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {\n+                IndexAbstraction.DataStream dataStream = (IndexAbstraction.DataStream) indexAbstraction;\n+                List<IndexMetadata> indices = dataStream.getIndices();\n+                return indices.stream().map(idx -> idx.getIndex().getName());\n+            } else {\n+                return Stream.empty();\n+            }\n+        }).toArray(String[]::new);\n+        return clusterState.getRoutingTable().allShards(concreteDatastreamIndices);\n+    }\n+\n+    @Override\n+    protected DataStreamShardStats shardOperation(DataStreamsStatsRequest request, ShardRouting shardRouting) throws IOException {\n+        IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());\n+        IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());\n+        // if we don't have the routing entry yet, we need it stats wise, we treat it as if the shard is not ready yet\n+        if (indexShard.routingEntry() == null) {\n+            throw new ShardNotFoundException(indexShard.shardId());\n+        }\n+        StoreStats storeStats = indexShard.storeStats();\n+        return new DataStreamShardStats(\n+            indexShard.routingEntry(),\n+            storeStats,\n+            0L //TODO", "originalCommit": "9505e33bde84ce157eea132296e3aa5765db0d4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ0ODYwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r447448609", "bodyText": "I think something like this would work here:\nIndexAbstraction indexAbstraction = \n   clusterService.state().metadata().getIndicesLookup().get(shardRouting.getIndexName());\nDataStream dataStream = indexAbstraction.getParentDataStream().getDataStream();\ntry (Engine.Searcher engineSearcher = indexShard.acquireSearcher(\"data_stream_stats\")) {\n  IndexReader indexReader = engineSearcher.getIndexReader();\n  String fieldName = dataStream.getTimeStampField().getName(); // Should be the fieldname in the Lucene index\n  long maxValue = LongPoint.decodeDimension(PointValues.getMaxPackedValue(indexReader, fieldName), 0); // dates (and numbers) are stored as point fields (backed by a bkd tree) and we can efficiently get the max value per segment and this method gets the max for all segments per Lucene index \n  // indexShard.mapperService().fieldType(fieldName).valueForDisplay(); perhaps format to a printable name instead of seconds since epoch? \n return new DataStreamShardStats(\n    indexShard.routingEntry(),\n    storeStats,\n    maxValue\n  );\n}", "author": "martijnvg", "createdAt": "2020-06-30T06:49:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzI4ODI4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b3a903a30ba1158cbbfe33ff27c84055ce50f426", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\nindex 65f560b50c9..223aa8949fa 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportDataStreamsStatsAction.java\n\n@@ -19,6 +19,9 @@\n \n package org.elasticsearch.action.admin.indices.stats;\n \n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n import org.elasticsearch.action.support.ActionFilters;\n import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n import org.elasticsearch.action.support.IndicesOptions;\n"}}, {"oid": "9c0271d9b953442a2d0308b587ca3bc9fd8f3c4a", "url": "https://github.com/elastic/elasticsearch/commit/9c0271d9b953442a2d0308b587ca3bc9fd8f3c4a", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-06-30T19:24:20Z", "type": "commit"}, {"oid": "b3a903a30ba1158cbbfe33ff27c84055ce50f426", "url": "https://github.com/elastic/elasticsearch/commit/b3a903a30ba1158cbbfe33ff27c84055ce50f426", "message": "Add collection of max timestamp.\n\nClean up precommit errors.\nAdd some more testing.", "committedDate": "2020-06-30T23:05:23Z", "type": "commit"}, {"oid": "3ad81e6acdb7cc05818a39a10b0d935080f8ad1a", "url": "https://github.com/elastic/elasticsearch/commit/3ad81e6acdb7cc05818a39a10b0d935080f8ad1a", "message": "De-duplicate index abstraction resolution code", "committedDate": "2020-07-01T17:43:20Z", "type": "commit"}, {"oid": "0f3f6ef839a87e8f98813dcbed1b9dba30648868", "url": "https://github.com/elastic/elasticsearch/commit/0f3f6ef839a87e8f98813dcbed1b9dba30648868", "message": "Collapse stats classes into one file.\n\nFix some compilation errors.", "committedDate": "2020-07-01T18:56:26Z", "type": "commit"}, {"oid": "c1dbc97a71833f56f042aec6b07b34b9e7342668", "url": "https://github.com/elastic/elasticsearch/commit/c1dbc97a71833f56f042aec6b07b34b9e7342668", "message": "Rest API, spec, and tests.\n\nStandardize action name (\"streams\" plural)", "committedDate": "2020-07-02T05:44:57Z", "type": "commit"}, {"oid": "a6e43946398966adc91e5f512342d05455afa50a", "url": "https://github.com/elastic/elasticsearch/commit/a6e43946398966adc91e5f512342d05455afa50a", "message": "Move the new code to the data stream package", "committedDate": "2020-07-02T05:58:16Z", "type": "commit"}, {"oid": "b8bf667ee91eaed952cc3b35d308bc1b0b4c6184", "url": "https://github.com/elastic/elasticsearch/commit/b8bf667ee91eaed952cc3b35d308bc1b0b4c6184", "message": "Fix some errors", "committedDate": "2020-07-02T16:39:09Z", "type": "commit"}, {"oid": "9e83e67b16e93e13d749b5bc0b5be65e9f9f6596", "url": "https://github.com/elastic/elasticsearch/commit/9e83e67b16e93e13d749b5bc0b5be65e9f9f6596", "message": "Cleanup", "committedDate": "2020-07-02T16:40:02Z", "type": "commit"}, {"oid": "74cef55e49c4cbbe0da787fae04d2e34b4cf2733", "url": "https://github.com/elastic/elasticsearch/commit/74cef55e49c4cbbe0da787fae04d2e34b4cf2733", "message": "Added HLRC methods. Standardized method/field names.", "committedDate": "2020-07-02T20:49:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NzA1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450087051", "bodyText": "Maybe we should fail the request if anything other than a data stream is specified?", "author": "martijnvg", "createdAt": "2020-07-06T09:08:45Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,377 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.datastream;\n+\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n+import org.elasticsearch.action.support.broadcast.BroadcastResponse;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexAbstractionResolver;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Response> {\n+\n+    public static final DataStreamsStatsAction INSTANCE = new DataStreamsStatsAction();\n+    public static final String NAME = \"indices:monitor/data_stream/stats\";\n+\n+    public DataStreamsStatsAction() {\n+        super(NAME, DataStreamsStatsAction.Response::new);\n+    }\n+\n+    public static class Request extends BroadcastRequest<Request> {\n+        public Request() {\n+            super((String[]) null);\n+        }\n+\n+        public Request(StreamInput in) throws IOException {\n+            super(in);\n+        }\n+    }\n+\n+    public static class Response extends BroadcastResponse {\n+        private final int dataStreamCount;\n+        private final int backingIndices;\n+        private final ByteSizeValue totalStoreSize;\n+        private final DataStreamStats[] dataStreams;\n+\n+        public Response(int totalShards, int successfulShards, int failedShards, List<DefaultShardOperationFailedException> shardFailures,\n+                        int dataStreamCount, int backingIndices, ByteSizeValue totalStoreSize, DataStreamStats[] dataStreams) {\n+            super(totalShards, successfulShards, failedShards, shardFailures);\n+            this.dataStreamCount = dataStreamCount;\n+            this.backingIndices = backingIndices;\n+            this.totalStoreSize = totalStoreSize;\n+            this.dataStreams = dataStreams;\n+        }\n+\n+        public Response(StreamInput in) throws IOException {\n+            super(in);\n+            this.dataStreamCount = in.readVInt();\n+            this.backingIndices = in.readVInt();\n+            this.totalStoreSize = new ByteSizeValue(in);\n+            this.dataStreams = in.readArray(DataStreamStats::new, DataStreamStats[]::new);\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            super.writeTo(out);\n+            out.writeVInt(dataStreamCount);\n+            out.writeVInt(backingIndices);\n+            totalStoreSize.writeTo(out);\n+            out.writeArray(dataStreams);\n+        }\n+\n+        @Override\n+        protected void addCustomXContentFields(XContentBuilder builder, Params params) throws IOException {\n+            builder.field(\"data_stream_count\", dataStreamCount);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"total_store_size_bytes\", \"total_store_size\", totalStoreSize);\n+            builder.array(\"data_streams\", (Object[]) dataStreams);\n+        }\n+\n+        public int getDataStreamCount() {\n+            return dataStreamCount;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getTotalStoreSize() {\n+            return totalStoreSize;\n+        }\n+\n+        public DataStreamStats[] getDataStreams() {\n+            return dataStreams;\n+        }\n+    }\n+\n+    public static class DataStreamStats implements ToXContentObject, Writeable {\n+        private final String dataStream;\n+        private final int backingIndices;\n+        private final ByteSizeValue storeSize;\n+        private final long maximumTimestamp;\n+\n+        public DataStreamStats(String dataStream, int backingIndices, ByteSizeValue storeSize, long maximumTimestamp) {\n+            this.dataStream = dataStream;\n+            this.backingIndices = backingIndices;\n+            this.storeSize = storeSize;\n+            this.maximumTimestamp = maximumTimestamp;\n+        }\n+\n+        public DataStreamStats(StreamInput in) throws IOException {\n+            this.dataStream = in.readString();\n+            this.backingIndices = in.readVInt();\n+            this.storeSize = new ByteSizeValue(in);\n+            this.maximumTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeString(dataStream);\n+            out.writeVInt(backingIndices);\n+            storeSize.writeTo(out);\n+            out.writeVLong(maximumTimestamp);\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            builder.startObject();\n+            builder.field(\"data_stream\", dataStream);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"store_size_bytes\", \"store_size\", storeSize);\n+            builder.field(\"maximum_timestamp\", maximumTimestamp);\n+            builder.endObject();\n+            return builder;\n+        }\n+\n+        public String getDataStream() {\n+            return dataStream;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getStoreSize() {\n+            return storeSize;\n+        }\n+\n+        public long getMaximumTimestamp() {\n+            return maximumTimestamp;\n+        }\n+    }\n+\n+    public static class DataStreamShardStats implements Writeable {\n+        private final ShardRouting shardRouting;\n+        private final StoreStats storeStats;\n+        private final long maxTimestamp;\n+\n+        public DataStreamShardStats(ShardRouting shardRouting, StoreStats storeStats, long maxTimestamp) {\n+            this.shardRouting = shardRouting;\n+            this.storeStats = storeStats;\n+            this.maxTimestamp = maxTimestamp;\n+        }\n+\n+        public DataStreamShardStats(StreamInput in) throws IOException {\n+            this.shardRouting = new ShardRouting(in);\n+            this.storeStats = new StoreStats(in);\n+            this.maxTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            shardRouting.writeTo(out);\n+            storeStats.writeTo(out);\n+            out.writeVLong(maxTimestamp);\n+        }\n+\n+        public ShardRouting getShardRouting() {\n+            return shardRouting;\n+        }\n+\n+        public StoreStats getStoreStats() {\n+            return storeStats;\n+        }\n+\n+        public long getMaxTimestamp() {\n+            return maxTimestamp;\n+        }\n+    }\n+\n+    private static class AggregatedStats {\n+        Set<String> backingIndices = new HashSet<>();\n+        long storageBytes = 0L;\n+        long maxTimestamp = 0L;\n+    }\n+\n+    public static class TransportAction extends TransportBroadcastByNodeAction<Request, Response, DataStreamShardStats> {\n+\n+        private final ClusterService clusterService;\n+        private final IndicesService indicesService;\n+        private final IndexAbstractionResolver indexAbstractionResolver;\n+\n+        @Inject\n+        public TransportAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n+                                               ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n+            super(DataStreamsStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n+                Request::new, ThreadPool.Names.MANAGEMENT);\n+            this.clusterService = clusterService;\n+            this.indicesService = indicesService;\n+            this.indexAbstractionResolver = new IndexAbstractionResolver(indexNameExpressionResolver);\n+        }\n+\n+        @Override\n+        protected Request readRequestFrom(StreamInput in) throws IOException {\n+            return new Request(in);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkGlobalBlock(ClusterState state, Request request) {\n+            return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkRequestBlock(ClusterState state, Request request, String[] concreteIndices) {\n+            return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n+        }\n+\n+        @Override\n+        protected ShardsIterator shards(ClusterState clusterState, Request request, String[] concreteIndices) {\n+            String[] requestIndices = request.indices();\n+            if (requestIndices == null || requestIndices.length == 0) {\n+                requestIndices = new String[]{\"*\"};\n+            }\n+            List<String> abstractionNames = indexAbstractionResolver.resolveIndexAbstractions(requestIndices, request.indicesOptions(),\n+                clusterState.getMetadata());\n+            SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n+\n+            String[] concreteDatastreamIndices = abstractionNames.stream().flatMap(abstractionName -> {\n+                IndexAbstraction indexAbstraction = indicesLookup.get(abstractionName);\n+                assert indexAbstraction != null;\n+                if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {", "originalCommit": "74cef55e49c4cbbe0da787fae04d2e34b4cf2733", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ1NzIzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450457239", "bodyText": "Perhaps this makes sense if we receive a concrete expression that is a non-wildcard input, but * is a valid input here which would technically match indices.", "author": "jbaiera", "createdAt": "2020-07-06T20:17:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NzA1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ2Mzc2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450463765", "bodyText": "Perhaps this makes sense if we receive a concrete expression that is a non-wildcard input, but * is a valid input here which would technically match indices.\n\nI have a similar issue on a PR that I have open for converting data stream admin actions from cluster-level actions to index-level actions (#59095). Those actions should not be applied to anything other than data streams but with security enabled, wildcards are expanded to indices, aliases and data streams. We solved the reverse problem (don't expand wildcards for index actions that cannot operate on data streams to include data streams) but it seems like in a few cases, we need the opposite -- don't expand wildcards on actions that support only data streams to include indices and aliases.", "author": "danhermann", "createdAt": "2020-07-06T20:31:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NzA1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ2NTU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450465550", "bodyText": "if we receive a concrete expression that is a non-wildcard input, but * is a valid input here which would technically match indices.\n\nI see, I forgot about that. In that case it makes sense to not fail and just filter out the IndexAbstractions that are not data streams.", "author": "martijnvg", "createdAt": "2020-07-06T20:35:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4NzA1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\nindex dfe9b802db0..035c73d2248 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n\n@@ -332,7 +332,7 @@ public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Re\n                                                        int failedShards, List<DataStreamShardStats> dataStreamShardStats,\n                                                        List<DefaultShardOperationFailedException> shardFailures,\n                                                        ClusterState clusterState) {\n-            Map<String, AggregatedStats> dataStreamsStats = new HashMap<>();\n+            Map<String, AggregatedStats> aggregatedDataStreamsStats = new HashMap<>();\n             Set<String> allBackingIndices = new HashSet<>();\n             long totalStoreSizeBytes = 0L;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4OTg5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450089895", "bodyText": "I think we only need to capture this information from the latest backing index?\nAll other backing indices should have max timestamp that is lower than\nthe timestamp in the latest index.\nMaybe we need to collect the max timestamp from the two latest backing indices,\nin the case the write index just rolled over.", "author": "martijnvg", "createdAt": "2020-07-06T09:13:53Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,377 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.datastream;\n+\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n+import org.elasticsearch.action.support.broadcast.BroadcastResponse;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexAbstractionResolver;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Response> {\n+\n+    public static final DataStreamsStatsAction INSTANCE = new DataStreamsStatsAction();\n+    public static final String NAME = \"indices:monitor/data_stream/stats\";\n+\n+    public DataStreamsStatsAction() {\n+        super(NAME, DataStreamsStatsAction.Response::new);\n+    }\n+\n+    public static class Request extends BroadcastRequest<Request> {\n+        public Request() {\n+            super((String[]) null);\n+        }\n+\n+        public Request(StreamInput in) throws IOException {\n+            super(in);\n+        }\n+    }\n+\n+    public static class Response extends BroadcastResponse {\n+        private final int dataStreamCount;\n+        private final int backingIndices;\n+        private final ByteSizeValue totalStoreSize;\n+        private final DataStreamStats[] dataStreams;\n+\n+        public Response(int totalShards, int successfulShards, int failedShards, List<DefaultShardOperationFailedException> shardFailures,\n+                        int dataStreamCount, int backingIndices, ByteSizeValue totalStoreSize, DataStreamStats[] dataStreams) {\n+            super(totalShards, successfulShards, failedShards, shardFailures);\n+            this.dataStreamCount = dataStreamCount;\n+            this.backingIndices = backingIndices;\n+            this.totalStoreSize = totalStoreSize;\n+            this.dataStreams = dataStreams;\n+        }\n+\n+        public Response(StreamInput in) throws IOException {\n+            super(in);\n+            this.dataStreamCount = in.readVInt();\n+            this.backingIndices = in.readVInt();\n+            this.totalStoreSize = new ByteSizeValue(in);\n+            this.dataStreams = in.readArray(DataStreamStats::new, DataStreamStats[]::new);\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            super.writeTo(out);\n+            out.writeVInt(dataStreamCount);\n+            out.writeVInt(backingIndices);\n+            totalStoreSize.writeTo(out);\n+            out.writeArray(dataStreams);\n+        }\n+\n+        @Override\n+        protected void addCustomXContentFields(XContentBuilder builder, Params params) throws IOException {\n+            builder.field(\"data_stream_count\", dataStreamCount);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"total_store_size_bytes\", \"total_store_size\", totalStoreSize);\n+            builder.array(\"data_streams\", (Object[]) dataStreams);\n+        }\n+\n+        public int getDataStreamCount() {\n+            return dataStreamCount;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getTotalStoreSize() {\n+            return totalStoreSize;\n+        }\n+\n+        public DataStreamStats[] getDataStreams() {\n+            return dataStreams;\n+        }\n+    }\n+\n+    public static class DataStreamStats implements ToXContentObject, Writeable {\n+        private final String dataStream;\n+        private final int backingIndices;\n+        private final ByteSizeValue storeSize;\n+        private final long maximumTimestamp;\n+\n+        public DataStreamStats(String dataStream, int backingIndices, ByteSizeValue storeSize, long maximumTimestamp) {\n+            this.dataStream = dataStream;\n+            this.backingIndices = backingIndices;\n+            this.storeSize = storeSize;\n+            this.maximumTimestamp = maximumTimestamp;\n+        }\n+\n+        public DataStreamStats(StreamInput in) throws IOException {\n+            this.dataStream = in.readString();\n+            this.backingIndices = in.readVInt();\n+            this.storeSize = new ByteSizeValue(in);\n+            this.maximumTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeString(dataStream);\n+            out.writeVInt(backingIndices);\n+            storeSize.writeTo(out);\n+            out.writeVLong(maximumTimestamp);\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            builder.startObject();\n+            builder.field(\"data_stream\", dataStream);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"store_size_bytes\", \"store_size\", storeSize);\n+            builder.field(\"maximum_timestamp\", maximumTimestamp);\n+            builder.endObject();\n+            return builder;\n+        }\n+\n+        public String getDataStream() {\n+            return dataStream;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getStoreSize() {\n+            return storeSize;\n+        }\n+\n+        public long getMaximumTimestamp() {\n+            return maximumTimestamp;\n+        }\n+    }\n+\n+    public static class DataStreamShardStats implements Writeable {\n+        private final ShardRouting shardRouting;\n+        private final StoreStats storeStats;\n+        private final long maxTimestamp;\n+\n+        public DataStreamShardStats(ShardRouting shardRouting, StoreStats storeStats, long maxTimestamp) {\n+            this.shardRouting = shardRouting;\n+            this.storeStats = storeStats;\n+            this.maxTimestamp = maxTimestamp;\n+        }\n+\n+        public DataStreamShardStats(StreamInput in) throws IOException {\n+            this.shardRouting = new ShardRouting(in);\n+            this.storeStats = new StoreStats(in);\n+            this.maxTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            shardRouting.writeTo(out);\n+            storeStats.writeTo(out);\n+            out.writeVLong(maxTimestamp);\n+        }\n+\n+        public ShardRouting getShardRouting() {\n+            return shardRouting;\n+        }\n+\n+        public StoreStats getStoreStats() {\n+            return storeStats;\n+        }\n+\n+        public long getMaxTimestamp() {\n+            return maxTimestamp;\n+        }\n+    }\n+\n+    private static class AggregatedStats {\n+        Set<String> backingIndices = new HashSet<>();\n+        long storageBytes = 0L;\n+        long maxTimestamp = 0L;\n+    }\n+\n+    public static class TransportAction extends TransportBroadcastByNodeAction<Request, Response, DataStreamShardStats> {\n+\n+        private final ClusterService clusterService;\n+        private final IndicesService indicesService;\n+        private final IndexAbstractionResolver indexAbstractionResolver;\n+\n+        @Inject\n+        public TransportAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n+                                               ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n+            super(DataStreamsStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n+                Request::new, ThreadPool.Names.MANAGEMENT);\n+            this.clusterService = clusterService;\n+            this.indicesService = indicesService;\n+            this.indexAbstractionResolver = new IndexAbstractionResolver(indexNameExpressionResolver);\n+        }\n+\n+        @Override\n+        protected Request readRequestFrom(StreamInput in) throws IOException {\n+            return new Request(in);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkGlobalBlock(ClusterState state, Request request) {\n+            return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkRequestBlock(ClusterState state, Request request, String[] concreteIndices) {\n+            return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n+        }\n+\n+        @Override\n+        protected ShardsIterator shards(ClusterState clusterState, Request request, String[] concreteIndices) {\n+            String[] requestIndices = request.indices();\n+            if (requestIndices == null || requestIndices.length == 0) {\n+                requestIndices = new String[]{\"*\"};\n+            }\n+            List<String> abstractionNames = indexAbstractionResolver.resolveIndexAbstractions(requestIndices, request.indicesOptions(),\n+                clusterState.getMetadata());\n+            SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n+\n+            String[] concreteDatastreamIndices = abstractionNames.stream().flatMap(abstractionName -> {\n+                IndexAbstraction indexAbstraction = indicesLookup.get(abstractionName);\n+                assert indexAbstraction != null;\n+                if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {\n+                    IndexAbstraction.DataStream dataStream = (IndexAbstraction.DataStream) indexAbstraction;\n+                    List<IndexMetadata> indices = dataStream.getIndices();\n+                    return indices.stream().map(idx -> idx.getIndex().getName());\n+                } else {\n+                    return Stream.empty();\n+                }\n+            }).toArray(String[]::new);\n+            return clusterState.getRoutingTable().allShards(concreteDatastreamIndices);\n+        }\n+\n+        @Override\n+        protected DataStreamShardStats shardOperation(Request request, ShardRouting shardRouting) throws IOException {\n+            IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());\n+            IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());\n+            // if we don't have the routing entry yet, we need it stats wise, we treat it as if the shard is not ready yet\n+            if (indexShard.routingEntry() == null) {\n+                throw new ShardNotFoundException(indexShard.shardId());\n+            }\n+            StoreStats storeStats = indexShard.storeStats();\n+            IndexAbstraction indexAbstraction = clusterService.state().getMetadata().getIndicesLookup().get(shardRouting.getIndexName());\n+            assert indexAbstraction != null;\n+            IndexAbstraction.DataStream dataStream = indexAbstraction.getParentDataStream();\n+            assert dataStream != null;\n+            long maxTimestamp = 0L;\n+            try (Engine.Searcher searcher = indexShard.acquireSearcher(\"data_stream_stats\")) {", "originalCommit": "74cef55e49c4cbbe0da787fae04d2e34b4cf2733", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ1NjE0OA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450456148", "bodyText": "I'm not well versed in the costs for different Lucene operations. Is this operation heavy enough that we would see a benefit from only targeting the latest indices? If so, the most recent index is easy enough to discern because it's configured in the data stream to accept writes. Are the backing indices to be considered always going to be the same naming format (using numbers?), and do we think that's a stable enough practice to base stat collection logic on?", "author": "jbaiera", "createdAt": "2020-07-06T20:15:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4OTg5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ2NzE2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450467161", "bodyText": "This isn't a very expensive operations compared to other Lucene operations. However I think that for cold indices, not heaving to do this operation on most shards is a win.\n\nAre the backing indices to be considered always going to be the same naming format (using numbers?), and do we think that's a stable enough practice to base stat collection logic on?\n\nFor now it is stable, but when existing indices can be imported into a data stream not. Perhaps this should be based on the ordering of the indices in the data stream? The last index should always be the write index.", "author": "martijnvg", "createdAt": "2020-07-06T20:39:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4OTg5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTEyNjEwMA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451126100", "bodyText": "I think for now it is ok to go to all shards and retrieve the max timestamp. This is an optimization that can be done later.", "author": "martijnvg", "createdAt": "2020-07-07T20:32:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA4OTg5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\nindex dfe9b802db0..035c73d2248 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n\n@@ -332,7 +332,7 @@ public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Re\n                                                        int failedShards, List<DataStreamShardStats> dataStreamShardStats,\n                                                        List<DefaultShardOperationFailedException> shardFailures,\n                                                        ClusterState clusterState) {\n-            Map<String, AggregatedStats> dataStreamsStats = new HashMap<>();\n+            Map<String, AggregatedStats> aggregatedDataStreamsStats = new HashMap<>();\n             Set<String> allBackingIndices = new HashSet<>();\n             long totalStoreSizeBytes = 0L;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA5MTA4OA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r450091088", "bodyText": "maybe rename dataStreamsStats variable to aggregatedDataStreamsStats?", "author": "martijnvg", "createdAt": "2020-07-06T09:15:47Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,377 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.datastream;\n+\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n+import org.elasticsearch.action.support.broadcast.BroadcastResponse;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexAbstractionResolver;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Response> {\n+\n+    public static final DataStreamsStatsAction INSTANCE = new DataStreamsStatsAction();\n+    public static final String NAME = \"indices:monitor/data_stream/stats\";\n+\n+    public DataStreamsStatsAction() {\n+        super(NAME, DataStreamsStatsAction.Response::new);\n+    }\n+\n+    public static class Request extends BroadcastRequest<Request> {\n+        public Request() {\n+            super((String[]) null);\n+        }\n+\n+        public Request(StreamInput in) throws IOException {\n+            super(in);\n+        }\n+    }\n+\n+    public static class Response extends BroadcastResponse {\n+        private final int dataStreamCount;\n+        private final int backingIndices;\n+        private final ByteSizeValue totalStoreSize;\n+        private final DataStreamStats[] dataStreams;\n+\n+        public Response(int totalShards, int successfulShards, int failedShards, List<DefaultShardOperationFailedException> shardFailures,\n+                        int dataStreamCount, int backingIndices, ByteSizeValue totalStoreSize, DataStreamStats[] dataStreams) {\n+            super(totalShards, successfulShards, failedShards, shardFailures);\n+            this.dataStreamCount = dataStreamCount;\n+            this.backingIndices = backingIndices;\n+            this.totalStoreSize = totalStoreSize;\n+            this.dataStreams = dataStreams;\n+        }\n+\n+        public Response(StreamInput in) throws IOException {\n+            super(in);\n+            this.dataStreamCount = in.readVInt();\n+            this.backingIndices = in.readVInt();\n+            this.totalStoreSize = new ByteSizeValue(in);\n+            this.dataStreams = in.readArray(DataStreamStats::new, DataStreamStats[]::new);\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            super.writeTo(out);\n+            out.writeVInt(dataStreamCount);\n+            out.writeVInt(backingIndices);\n+            totalStoreSize.writeTo(out);\n+            out.writeArray(dataStreams);\n+        }\n+\n+        @Override\n+        protected void addCustomXContentFields(XContentBuilder builder, Params params) throws IOException {\n+            builder.field(\"data_stream_count\", dataStreamCount);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"total_store_size_bytes\", \"total_store_size\", totalStoreSize);\n+            builder.array(\"data_streams\", (Object[]) dataStreams);\n+        }\n+\n+        public int getDataStreamCount() {\n+            return dataStreamCount;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getTotalStoreSize() {\n+            return totalStoreSize;\n+        }\n+\n+        public DataStreamStats[] getDataStreams() {\n+            return dataStreams;\n+        }\n+    }\n+\n+    public static class DataStreamStats implements ToXContentObject, Writeable {\n+        private final String dataStream;\n+        private final int backingIndices;\n+        private final ByteSizeValue storeSize;\n+        private final long maximumTimestamp;\n+\n+        public DataStreamStats(String dataStream, int backingIndices, ByteSizeValue storeSize, long maximumTimestamp) {\n+            this.dataStream = dataStream;\n+            this.backingIndices = backingIndices;\n+            this.storeSize = storeSize;\n+            this.maximumTimestamp = maximumTimestamp;\n+        }\n+\n+        public DataStreamStats(StreamInput in) throws IOException {\n+            this.dataStream = in.readString();\n+            this.backingIndices = in.readVInt();\n+            this.storeSize = new ByteSizeValue(in);\n+            this.maximumTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeString(dataStream);\n+            out.writeVInt(backingIndices);\n+            storeSize.writeTo(out);\n+            out.writeVLong(maximumTimestamp);\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            builder.startObject();\n+            builder.field(\"data_stream\", dataStream);\n+            builder.field(\"backing_indices\", backingIndices);\n+            builder.humanReadableField(\"store_size_bytes\", \"store_size\", storeSize);\n+            builder.field(\"maximum_timestamp\", maximumTimestamp);\n+            builder.endObject();\n+            return builder;\n+        }\n+\n+        public String getDataStream() {\n+            return dataStream;\n+        }\n+\n+        public int getBackingIndices() {\n+            return backingIndices;\n+        }\n+\n+        public ByteSizeValue getStoreSize() {\n+            return storeSize;\n+        }\n+\n+        public long getMaximumTimestamp() {\n+            return maximumTimestamp;\n+        }\n+    }\n+\n+    public static class DataStreamShardStats implements Writeable {\n+        private final ShardRouting shardRouting;\n+        private final StoreStats storeStats;\n+        private final long maxTimestamp;\n+\n+        public DataStreamShardStats(ShardRouting shardRouting, StoreStats storeStats, long maxTimestamp) {\n+            this.shardRouting = shardRouting;\n+            this.storeStats = storeStats;\n+            this.maxTimestamp = maxTimestamp;\n+        }\n+\n+        public DataStreamShardStats(StreamInput in) throws IOException {\n+            this.shardRouting = new ShardRouting(in);\n+            this.storeStats = new StoreStats(in);\n+            this.maxTimestamp = in.readVLong();\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            shardRouting.writeTo(out);\n+            storeStats.writeTo(out);\n+            out.writeVLong(maxTimestamp);\n+        }\n+\n+        public ShardRouting getShardRouting() {\n+            return shardRouting;\n+        }\n+\n+        public StoreStats getStoreStats() {\n+            return storeStats;\n+        }\n+\n+        public long getMaxTimestamp() {\n+            return maxTimestamp;\n+        }\n+    }\n+\n+    private static class AggregatedStats {\n+        Set<String> backingIndices = new HashSet<>();\n+        long storageBytes = 0L;\n+        long maxTimestamp = 0L;\n+    }\n+\n+    public static class TransportAction extends TransportBroadcastByNodeAction<Request, Response, DataStreamShardStats> {\n+\n+        private final ClusterService clusterService;\n+        private final IndicesService indicesService;\n+        private final IndexAbstractionResolver indexAbstractionResolver;\n+\n+        @Inject\n+        public TransportAction(ClusterService clusterService, TransportService transportService, IndicesService indicesService,\n+                                               ActionFilters actionFilters, IndexNameExpressionResolver indexNameExpressionResolver) {\n+            super(DataStreamsStatsAction.NAME, clusterService, transportService, actionFilters, indexNameExpressionResolver,\n+                Request::new, ThreadPool.Names.MANAGEMENT);\n+            this.clusterService = clusterService;\n+            this.indicesService = indicesService;\n+            this.indexAbstractionResolver = new IndexAbstractionResolver(indexNameExpressionResolver);\n+        }\n+\n+        @Override\n+        protected Request readRequestFrom(StreamInput in) throws IOException {\n+            return new Request(in);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkGlobalBlock(ClusterState state, Request request) {\n+            return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n+        }\n+\n+        @Override\n+        protected ClusterBlockException checkRequestBlock(ClusterState state, Request request, String[] concreteIndices) {\n+            return state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA_READ, concreteIndices);\n+        }\n+\n+        @Override\n+        protected ShardsIterator shards(ClusterState clusterState, Request request, String[] concreteIndices) {\n+            String[] requestIndices = request.indices();\n+            if (requestIndices == null || requestIndices.length == 0) {\n+                requestIndices = new String[]{\"*\"};\n+            }\n+            List<String> abstractionNames = indexAbstractionResolver.resolveIndexAbstractions(requestIndices, request.indicesOptions(),\n+                clusterState.getMetadata());\n+            SortedMap<String, IndexAbstraction> indicesLookup = clusterState.getMetadata().getIndicesLookup();\n+\n+            String[] concreteDatastreamIndices = abstractionNames.stream().flatMap(abstractionName -> {\n+                IndexAbstraction indexAbstraction = indicesLookup.get(abstractionName);\n+                assert indexAbstraction != null;\n+                if (indexAbstraction.getType() == IndexAbstraction.Type.DATA_STREAM) {\n+                    IndexAbstraction.DataStream dataStream = (IndexAbstraction.DataStream) indexAbstraction;\n+                    List<IndexMetadata> indices = dataStream.getIndices();\n+                    return indices.stream().map(idx -> idx.getIndex().getName());\n+                } else {\n+                    return Stream.empty();\n+                }\n+            }).toArray(String[]::new);\n+            return clusterState.getRoutingTable().allShards(concreteDatastreamIndices);\n+        }\n+\n+        @Override\n+        protected DataStreamShardStats shardOperation(Request request, ShardRouting shardRouting) throws IOException {\n+            IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());\n+            IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());\n+            // if we don't have the routing entry yet, we need it stats wise, we treat it as if the shard is not ready yet\n+            if (indexShard.routingEntry() == null) {\n+                throw new ShardNotFoundException(indexShard.shardId());\n+            }\n+            StoreStats storeStats = indexShard.storeStats();\n+            IndexAbstraction indexAbstraction = clusterService.state().getMetadata().getIndicesLookup().get(shardRouting.getIndexName());\n+            assert indexAbstraction != null;\n+            IndexAbstraction.DataStream dataStream = indexAbstraction.getParentDataStream();\n+            assert dataStream != null;\n+            long maxTimestamp = 0L;\n+            try (Engine.Searcher searcher = indexShard.acquireSearcher(\"data_stream_stats\")) {\n+                IndexReader indexReader = searcher.getIndexReader();\n+                String fieldName = dataStream.getDataStream().getTimeStampField().getName();\n+                byte[] maxPackedValue = PointValues.getMaxPackedValue(indexReader, fieldName);\n+                if (maxPackedValue != null) {\n+                    maxTimestamp = LongPoint.decodeDimension(maxPackedValue, 0);\n+                }\n+            }\n+            return new DataStreamShardStats(\n+                indexShard.routingEntry(),\n+                storeStats,\n+                maxTimestamp\n+            );\n+        }\n+\n+        @Override\n+        protected DataStreamShardStats readShardResult(StreamInput in) throws IOException {\n+            return new DataStreamShardStats(in);\n+        }\n+\n+        @Override\n+        protected Response newResponse(Request request, int totalShards, int successfulShards,\n+                                                       int failedShards, List<DataStreamShardStats> dataStreamShardStats,\n+                                                       List<DefaultShardOperationFailedException> shardFailures,\n+                                                       ClusterState clusterState) {\n+            Map<String, AggregatedStats> dataStreamsStats = new HashMap<>();", "originalCommit": "74cef55e49c4cbbe0da787fae04d2e34b4cf2733", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\nindex dfe9b802db0..035c73d2248 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n\n@@ -332,7 +332,7 @@ public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Re\n                                                        int failedShards, List<DataStreamShardStats> dataStreamShardStats,\n                                                        List<DefaultShardOperationFailedException> shardFailures,\n                                                        ClusterState clusterState) {\n-            Map<String, AggregatedStats> dataStreamsStats = new HashMap<>();\n+            Map<String, AggregatedStats> aggregatedDataStreamsStats = new HashMap<>();\n             Set<String> allBackingIndices = new HashSet<>();\n             long totalStoreSizeBytes = 0L;\n \n"}}, {"oid": "f3e8eef1300c9ca8dedc0d2eae5aaf596d385e3c", "url": "https://github.com/elastic/elasticsearch/commit/f3e8eef1300c9ca8dedc0d2eae5aaf596d385e3c", "message": "Rest client method and api spec name agreement", "committedDate": "2020-07-06T15:42:28Z", "type": "commit"}, {"oid": "b264441a1bd1936c7e737b97254604cc8ddde0ac", "url": "https://github.com/elastic/elasticsearch/commit/b264441a1bd1936c7e737b97254604cc8ddde0ac", "message": "Fixing XContent tests and logic", "committedDate": "2020-07-06T19:11:18Z", "type": "commit"}, {"oid": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "url": "https://github.com/elastic/elasticsearch/commit/a72e35ba8029f11384fe732a3cf12c09dcaa4267", "message": "Cleanup", "committedDate": "2020-07-06T20:49:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNDk5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451504995", "bodyText": "maybe add a serialization unit test for this response class that extends from AbstractWireSerializingTestCase?", "author": "martijnvg", "createdAt": "2020-07-08T12:26:31Z", "path": "server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java", "diffHunk": "@@ -0,0 +1,377 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.action.admin.indices.datastream;\n+\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.PointValues;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.DefaultShardOperationFailedException;\n+import org.elasticsearch.action.support.broadcast.BroadcastRequest;\n+import org.elasticsearch.action.support.broadcast.BroadcastResponse;\n+import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexAbstraction;\n+import org.elasticsearch.cluster.metadata.IndexAbstractionResolver;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardsIterator;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.index.IndexService;\n+import org.elasticsearch.index.engine.Engine;\n+import org.elasticsearch.index.shard.IndexShard;\n+import org.elasticsearch.index.shard.ShardNotFoundException;\n+import org.elasticsearch.index.store.StoreStats;\n+import org.elasticsearch.indices.IndicesService;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.SortedMap;\n+import java.util.stream.Stream;\n+\n+public class DataStreamsStatsAction extends ActionType<DataStreamsStatsAction.Response> {\n+\n+    public static final DataStreamsStatsAction INSTANCE = new DataStreamsStatsAction();\n+    public static final String NAME = \"indices:monitor/data_stream/stats\";\n+\n+    public DataStreamsStatsAction() {\n+        super(NAME, DataStreamsStatsAction.Response::new);\n+    }\n+\n+    public static class Request extends BroadcastRequest<Request> {\n+        public Request() {\n+            super((String[]) null);\n+        }\n+\n+        public Request(StreamInput in) throws IOException {\n+            super(in);\n+        }\n+    }\n+\n+    public static class Response extends BroadcastResponse {\n+        private final int dataStreamCount;\n+        private final int backingIndices;\n+        private final ByteSizeValue totalStoreSize;\n+        private final DataStreamStats[] dataStreams;\n+\n+        public Response(int totalShards, int successfulShards, int failedShards, List<DefaultShardOperationFailedException> shardFailures,", "originalCommit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2c0a5b47b7de2b2b8580caf7e37e244d78affd8d", "chunk": "diff --git a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\nindex 035c73d2248..7ce66566da0 100644\n--- a/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n+++ b/server/src/main/java/org/elasticsearch/action/admin/indices/datastream/DataStreamsStatsAction.java\n\n@@ -55,10 +55,12 @@ import org.elasticsearch.threadpool.ThreadPool;\n import org.elasticsearch.transport.TransportService;\n \n import java.io.IOException;\n+import java.util.Arrays;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n import java.util.SortedMap;\n import java.util.stream.Stream;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUwNjg4NA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451506884", "bodyText": "equalTo(0) should be equalTo(0L), a test failed because of this.", "author": "martijnvg", "createdAt": "2020-07-08T12:29:55Z", "path": "client/rest-high-level/src/test/java/org/elasticsearch/client/IndicesClientIT.java", "diffHunk": "@@ -1608,6 +1611,26 @@ public void testDataStreams() throws Exception {\n         assertThat(dataStream.getTimeStampField(), equalTo(\"@timestamp\"));\n         assertThat(dataStream.getIndices(), hasSize(1));\n \n+        DataStreamsStatsRequest dataStreamsStatsRequest = new DataStreamsStatsRequest();\n+        DataStreamsStatsResponse dataStreamsStatsResponse = execute(dataStreamsStatsRequest, indices::dataStreamsStats,\n+            indices::dataStreamsStatsAsync);\n+        int dataStreamsCount = dataStreamsStatsResponse.getDataStreamCount();\n+        assertThat(dataStreamsCount, equalTo(1));\n+        int backingIndices = dataStreamsStatsResponse.getBackingIndices();\n+        assertThat(backingIndices, equalTo(1));\n+        ByteSizeValue byteSizeValue = dataStreamsStatsResponse.getTotalStoreSize();\n+        assertThat(byteSizeValue, notNullValue());\n+        assertThat(byteSizeValue.getBytes(), not(equalTo(0L)));\n+        Map<String, DataStreamStats> dataStreamsStats = dataStreamsStatsResponse.getDataStreams();\n+        assertThat(dataStreamsStats, notNullValue());\n+        assertThat(dataStreamsStats.size(), equalTo(1));\n+        DataStreamStats dataStreamStat = dataStreamsStats.get(dataStreamName);\n+        assertThat(dataStreamStat, notNullValue());\n+        assertThat(dataStreamStat.getDataStream(), equalTo(dataStreamName));\n+        assertThat(dataStreamStat.getBackingIndices(), equalTo(1));\n+        assertThat(dataStreamStat.getMaximumTimestamp(), equalTo(0)); // No data in here", "originalCommit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2c0a5b47b7de2b2b8580caf7e37e244d78affd8d", "chunk": "diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/IndicesClientIT.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/IndicesClientIT.java\nindex dbfec50c4cf..ebc5fec7440 100644\n--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/IndicesClientIT.java\n+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/IndicesClientIT.java\n\n@@ -1628,7 +1628,7 @@ public class IndicesClientIT extends ESRestHighLevelClientTestCase {\n         assertThat(dataStreamStat, notNullValue());\n         assertThat(dataStreamStat.getDataStream(), equalTo(dataStreamName));\n         assertThat(dataStreamStat.getBackingIndices(), equalTo(1));\n-        assertThat(dataStreamStat.getMaximumTimestamp(), equalTo(0)); // No data in here\n+        assertThat(dataStreamStat.getMaximumTimestamp(), equalTo(0L)); // No data in here\n         assertThat(dataStreamStat.getStoreSize().getBytes(), not(equalTo(0L))); // but still takes up some space on disk\n \n         DeleteDataStreamRequest deleteDataStreamRequest = new DeleteDataStreamRequest(dataStreamName);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNTQxMg==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451515412", "bodyText": "I think this request should implement IndicesRequest.Replaceable so that it works as an index-level action with security. You'll probably want to add a corresponding test to https://github.com/elastic/elasticsearch/blob/master/x-pack/plugin/src/test/resources/rest-api-spec/test/security/authz/50_data_streams.yml to validate that stats are retrieved only for the data streams that are authorized for the user.", "author": "danhermann", "createdAt": "2020-07-08T12:44:25Z", "path": "client/rest-high-level/src/main/java/org/elasticsearch/client/indices/DataStreamsStatsRequest.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.client.indices;\n+\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Validatable;\n+\n+public class DataStreamsStatsRequest implements Validatable {", "originalCommit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyMDU4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451620586", "bodyText": "Should this be on the HLRC request class or the transport request? I'm assuming transport, but wanted to double check.", "author": "jbaiera", "createdAt": "2020-07-08T15:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNTQxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyMjM1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451622353", "bodyText": "Actually, it looks like this interface is extended already on BroadcastRequest which is the super class on the transport request. Is this something that still needs to be done on the client side?", "author": "jbaiera", "createdAt": "2020-07-08T15:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNTQxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY1MTQ3OA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451651478", "bodyText": "Actually, it looks like this interface is extended already on BroadcastRequest which is the super class on the transport request. Is this something that still needs to be done on the client side?\n\nAh, you're right. I missed that. Because the action name begins with indices:monitor, it should automatically be picked up by the monitor and manage index privileges which I think is appropriate. Maybe just a REST test to verify that, then.", "author": "danhermann", "createdAt": "2020-07-08T15:55:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUxNTQxMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUzODA0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451538049", "bodyText": "Note that this clause was not included in the code for the resolve index action because it would never apply to data streams. If you want to consolidate all that code (which would be great!), you'll need to incorporate that clause back into the common implementation.", "author": "danhermann", "createdAt": "2020-07-08T13:20:06Z", "path": "x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/authz/IndicesAndAliasesResolver.java", "diffHunk": "@@ -335,135 +337,6 @@ private boolean containsWildcards(IndicesRequest indicesRequest) {\n         return false;\n     }\n \n-    //TODO Investigate reusing code from vanilla es to resolve index names and wildcards\n-    private List<String> replaceWildcardsWithAuthorizedIndices(Iterable<String> indices, IndicesOptions indicesOptions, Metadata metadata,\n-                                                               List<String> authorizedIndices, boolean replaceWildcards) {\n-        //the order matters when it comes to exclusions\n-        List<String> finalIndices = new ArrayList<>();\n-        boolean wildcardSeen = false;\n-        for (String index : indices) {\n-            String aliasOrIndex;\n-            boolean minus = false;\n-            if (index.charAt(0) == '-' && wildcardSeen) {\n-                aliasOrIndex = index.substring(1);\n-                minus = true;\n-            } else {\n-                aliasOrIndex = index;\n-            }\n-\n-            // we always need to check for date math expressions\n-            final String dateMathName = nameExpressionResolver.resolveDateMathExpression(aliasOrIndex);\n-            if (dateMathName != aliasOrIndex) {\n-                assert dateMathName.equals(aliasOrIndex) == false;\n-                if (replaceWildcards && Regex.isSimpleMatchPattern(dateMathName)) {\n-                    // continue\n-                    aliasOrIndex = dateMathName;\n-                } else if (authorizedIndices.contains(dateMathName) &&\n-                    isIndexVisible(aliasOrIndex, dateMathName, indicesOptions, metadata, true)) {\n-                    if (minus) {\n-                        finalIndices.remove(dateMathName);\n-                    } else {\n-                        finalIndices.add(dateMathName);\n-                    }\n-                } else {\n-                    if (indicesOptions.ignoreUnavailable() == false) {\n-                        throw new IndexNotFoundException(dateMathName);\n-                    }\n-                }\n-            }\n-\n-            if (replaceWildcards && Regex.isSimpleMatchPattern(aliasOrIndex)) {\n-                wildcardSeen = true;\n-                Set<String> resolvedIndices = new HashSet<>();\n-                for (String authorizedIndex : authorizedIndices) {\n-                    if (Regex.simpleMatch(aliasOrIndex, authorizedIndex) &&\n-                        isIndexVisible(aliasOrIndex, authorizedIndex, indicesOptions, metadata)) {\n-                        resolvedIndices.add(authorizedIndex);\n-                    }\n-                }\n-                if (resolvedIndices.isEmpty()) {\n-                    //es core honours allow_no_indices for each wildcard expression, we do the same here by throwing index not found.\n-                    if (indicesOptions.allowNoIndices() == false) {\n-                        throw new IndexNotFoundException(aliasOrIndex);\n-                    }\n-                } else {\n-                    if (minus) {\n-                        finalIndices.removeAll(resolvedIndices);\n-                    } else {\n-                        finalIndices.addAll(resolvedIndices);\n-                    }\n-                }\n-            } else if (dateMathName == aliasOrIndex) {\n-                // we can use == here to compare strings since the name expression resolver returns the same instance, but add an assert\n-                // to ensure we catch this if it changes\n-\n-                assert dateMathName.equals(aliasOrIndex);\n-                //Metadata#convertFromWildcards checks if the index exists here and throws IndexNotFoundException if not (based on\n-                // ignore_unavailable). We only add/remove the index: if the index is missing or the current user is not authorized\n-                // to access it either an AuthorizationException will be thrown later in AuthorizationService, or the index will be\n-                // removed from the list, based on the ignore_unavailable option.\n-                if (minus) {\n-                    finalIndices.remove(aliasOrIndex);\n-                } else {\n-                    finalIndices.add(aliasOrIndex);\n-                }\n-            }", "originalCommit": "a72e35ba8029f11384fe732a3cf12c09dcaa4267", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYxNDMxNA==", "url": "https://github.com/elastic/elasticsearch/pull/58707#discussion_r451614314", "bodyText": "This should be covered already on lines 107-113 on the common implementation, though it looks a little different because the comments have been removed and the equals logic is a bit more straightforward.", "author": "jbaiera", "createdAt": "2020-07-08T15:02:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTUzODA0OQ=="}], "type": "inlineReview", "revised_code": null}, {"oid": "2c0a5b47b7de2b2b8580caf7e37e244d78affd8d", "url": "https://github.com/elastic/elasticsearch/commit/2c0a5b47b7de2b2b8580caf7e37e244d78affd8d", "message": "PR Feedback", "committedDate": "2020-07-08T15:45:37Z", "type": "commit"}, {"oid": "a4ca1689887db6829feec388e03f3e0b117c8b32", "url": "https://github.com/elastic/elasticsearch/commit/a4ca1689887db6829feec388e03f3e0b117c8b32", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-08T20:17:14Z", "type": "commit"}, {"oid": "ad6a18877d9edf12291549b5eb1f49cd690b257f", "url": "https://github.com/elastic/elasticsearch/commit/ad6a18877d9edf12291549b5eb1f49cd690b257f", "message": "Add rest test for data streams stats on security", "committedDate": "2020-07-09T13:58:59Z", "type": "commit"}, {"oid": "80244460b32287c2e2a34f18a02411f8a6c879c5", "url": "https://github.com/elastic/elasticsearch/commit/80244460b32287c2e2a34f18a02411f8a6c879c5", "message": "Fixing tests", "committedDate": "2020-07-09T16:43:39Z", "type": "commit"}, {"oid": "0c7b7bc83bb87f12c7a818cd27a3bd25dc26ceb4", "url": "https://github.com/elastic/elasticsearch/commit/0c7b7bc83bb87f12c7a818cd27a3bd25dc26ceb4", "message": "Fix more tests", "committedDate": "2020-07-09T17:41:39Z", "type": "commit"}, {"oid": "a16e029724c8850280564a2db8acfd1554347765", "url": "https://github.com/elastic/elasticsearch/commit/a16e029724c8850280564a2db8acfd1554347765", "message": "Fixing security test", "committedDate": "2020-07-09T18:23:05Z", "type": "commit"}, {"oid": "9756c81db0b48679fbbce08adb8120f33732de03", "url": "https://github.com/elastic/elasticsearch/commit/9756c81db0b48679fbbce08adb8120f33732de03", "message": "Precommit", "committedDate": "2020-07-09T19:11:21Z", "type": "commit"}, {"oid": "3f032132455952a76802c5177567f9ddc92b50b2", "url": "https://github.com/elastic/elasticsearch/commit/3f032132455952a76802c5177567f9ddc92b50b2", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-09T20:47:28Z", "type": "commit"}, {"oid": "28de11c9d2472484833bfd190e609569e3a9ffeb", "url": "https://github.com/elastic/elasticsearch/commit/28de11c9d2472484833bfd190e609569e3a9ffeb", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-13T19:27:25Z", "type": "commit"}, {"oid": "724e8b22bc083f3a70d28b057afe45a19eef62b4", "url": "https://github.com/elastic/elasticsearch/commit/724e8b22bc083f3a70d28b057afe45a19eef62b4", "message": "Update security tests after merge", "committedDate": "2020-07-13T19:28:37Z", "type": "commit"}, {"oid": "6e8a38a45ebb399d570b42b2f6cc6cad891b8d28", "url": "https://github.com/elastic/elasticsearch/commit/6e8a38a45ebb399d570b42b2f6cc6cad891b8d28", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-13T19:58:34Z", "type": "commit"}, {"oid": "56ebf9b99b509ce8ab456ea82ced928e4b323178", "url": "https://github.com/elastic/elasticsearch/commit/56ebf9b99b509ce8ab456ea82ced928e4b323178", "message": "Move test to xpack plugin so that it runs correctly", "committedDate": "2020-07-13T21:27:11Z", "type": "commit"}, {"oid": "f42f789c21195ed02a3e96b00277df0b55b39359", "url": "https://github.com/elastic/elasticsearch/commit/f42f789c21195ed02a3e96b00277df0b55b39359", "message": "clean up correct data stream in tests", "committedDate": "2020-07-14T01:25:40Z", "type": "commit"}, {"oid": "5bad0ce9803b63971c8b67b8fb7655732447bbe4", "url": "https://github.com/elastic/elasticsearch/commit/5bad0ce9803b63971c8b67b8fb7655732447bbe4", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-14T05:46:13Z", "type": "commit"}, {"oid": "39d02b403813ee6352c86013684bd7417a2b550b", "url": "https://github.com/elastic/elasticsearch/commit/39d02b403813ee6352c86013684bd7417a2b550b", "message": "Method contract changed and one of the call sites became erroneous", "committedDate": "2020-07-14T14:42:30Z", "type": "commit"}, {"oid": "7e505fa7ebc123fc1e78cfc6aade62994f74793c", "url": "https://github.com/elastic/elasticsearch/commit/7e505fa7ebc123fc1e78cfc6aade62994f74793c", "message": "Merge branch 'master' into data-stream-stats", "committedDate": "2020-07-14T15:25:58Z", "type": "commit"}, {"oid": "dcbf5ec0f919c7beb8125e1b288e2433c769a702", "url": "https://github.com/elastic/elasticsearch/commit/dcbf5ec0f919c7beb8125e1b288e2433c769a702", "message": "Fix test compilation", "committedDate": "2020-07-14T16:43:28Z", "type": "commit"}, {"oid": "d3b8be398e0c4bef80a61d1c7f634a38b9b8f5de", "url": "https://github.com/elastic/elasticsearch/commit/d3b8be398e0c4bef80a61d1c7f634a38b9b8f5de", "message": "Fix rest tests again", "committedDate": "2020-07-14T17:50:29Z", "type": "commit"}]}