{"pr_number": 55529, "pr_title": "[ML] Add effective max model memory limit to ML info", "pr_createdAt": "2020-04-21T13:40:22Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55529", "timeline": [{"oid": "1d4db68f89d63b7164e4f4eca845fe1de88f2274", "url": "https://github.com/elastic/elasticsearch/commit/1d4db68f89d63b7164e4f4eca845fe1de88f2274", "message": "[ML] Add effective current max model memory limit to ML info\n\nThe ML info endpoint returns the max_model_memory_limit setting\nif one is configured.  However, it is still possible to create\na job that cannot run anywhere in the current cluster because\nno node in the cluster has enough memory to accommodate it.\n\nThis change adds an extra piece of information,\nlimits.current_effective_max_model_memory_limit, to the ML info\nresponse that returns the biggest model memory limit that could\nbe run in the current cluster assuming no other jobs were\nrunning.\n\nThe idea is that the ML UI will be able to warn users who try to\ncreate jobs with higher model memory limits that their jobs will\nnot be able to start unless they add a bigger ML node to their\ncluster.\n\nRelates elastic/kibana#63942", "committedDate": "2020-04-21T13:37:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0MjA5NA==", "url": "https://github.com/elastic/elasticsearch/pull/55529#discussion_r412242094", "bodyText": "It might be nice to indicate that there is room available for larger jobs if they increased their MAX_MODEL_MEMORY_LIMIT setting.\nBut, in the scenarios where the user could take action, it seems to me that they SHOULD already know the native memory available.", "author": "benwtrent", "createdAt": "2020-04-21T14:36:57Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportMlInfoAction.java", "diffHunk": "@@ -106,11 +111,50 @@ private ByteSizeValue defaultModelMemoryLimit() {\n         return anomalyDetectorsDefaults;\n     }\n \n+    static ByteSizeValue calculateCurrentEffectiveMaxModelMemoryLimit(int maxMachineMemoryPercent, DiscoveryNodes nodes) {\n+\n+        long maxMlMemory = -1;\n+\n+        for (DiscoveryNode node : nodes) {\n+\n+            Map<String, String> nodeAttributes = node.getAttributes();\n+            String machineMemoryStr = nodeAttributes.get(MachineLearning.MACHINE_MEMORY_NODE_ATTR);\n+            if (machineMemoryStr == null) {\n+                continue;\n+            }\n+            long machineMemory;\n+            try {\n+                machineMemory = Long.parseLong(machineMemoryStr);\n+            } catch (NumberFormatException e) {\n+                continue;\n+            }\n+            maxMlMemory = Math.max(maxMlMemory, machineMemory * maxMachineMemoryPercent / 100);\n+        }\n+\n+        if (maxMlMemory <= 0) {\n+            // This implies there are currently no ML nodes in the cluster, so we\n+            // have no idea what the effective limit would be if one were added\n+            return null;\n+        }\n+\n+        maxMlMemory -= Math.max(Job.PROCESS_MEMORY_OVERHEAD.getBytes(), DataFrameAnalyticsConfig.PROCESS_MEMORY_OVERHEAD.getBytes());\n+        maxMlMemory -= MachineLearning.NATIVE_EXECUTABLE_CODE_OVERHEAD.getBytes();\n+        return new ByteSizeValue(Math.max(0L, maxMlMemory) / 1024 / 1024, ByteSizeUnit.MB);\n+    }\n+\n     private Map<String, Object> limits() {\n         Map<String, Object> limits = new HashMap<>();\n+        ByteSizeValue currentEffectiveMaxModelMemoryLimit = calculateCurrentEffectiveMaxModelMemoryLimit(\n+            clusterService.getClusterSettings().get(MachineLearning.MAX_MACHINE_MEMORY_PERCENT), clusterService.state().getNodes());\n         ByteSizeValue maxModelMemoryLimit = clusterService.getClusterSettings().get(MachineLearningField.MAX_MODEL_MEMORY_LIMIT);\n         if (maxModelMemoryLimit != null && maxModelMemoryLimit.getBytes() > 0) {\n-            limits.put(\"max_model_memory_limit\", maxModelMemoryLimit);\n+            limits.put(\"max_model_memory_limit\", maxModelMemoryLimit.getStringRep());\n+            if (currentEffectiveMaxModelMemoryLimit == null || currentEffectiveMaxModelMemoryLimit.compareTo(maxModelMemoryLimit) > 0) {", "originalCommit": "1d4db68f89d63b7164e4f4eca845fe1de88f2274", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI5MDA2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55529#discussion_r412290067", "bodyText": "The main scenario where MAX_MODEL_MEMORY_LIMIT is in Cloud, where it's controlled by the Cloud environment.\nThe other scenario where we envisage it being used is when an administrator wants to lower powered users from using all the resources with a single job.\nIn both cases, the user seeing the effect of the restriction wouldn't have the power to increase the limit.  It's extremely unlikely there would be a scenario where the user being affected by the limit had the power to change it.  Superusers who are using ML and have complete control of their hardware probably don't have the setting set at all.\nIn the event that both the hard maximum and effective maximum constrain the size of a job the UI should report the hard maximum.\nFor Elastic Cloud there is the desire for the UI to suggest upgrading to more powerful nodes if limits are hit, as that's just a case of a few clicks in the Cloud console (and paying more).  But I think this endpoint still provides enough information to facilitate that because within the Cloud environment we're already setting a hard maximum limit.", "author": "droberts195", "createdAt": "2020-04-21T15:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0MjA5NA=="}], "type": "inlineReview", "revised_code": {"commit": "9b183f43f501a4480800a4fd44fb70af54846e1e", "chunk": "diff --git a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportMlInfoAction.java b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportMlInfoAction.java\nindex dd578d92b57..dd55a07ebdc 100644\n--- a/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportMlInfoAction.java\n+++ b/x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportMlInfoAction.java\n\n@@ -111,7 +110,7 @@ public class TransportMlInfoAction extends HandledTransportAction<MlInfoAction.R\n         return anomalyDetectorsDefaults;\n     }\n \n-    static ByteSizeValue calculateCurrentEffectiveMaxModelMemoryLimit(int maxMachineMemoryPercent, DiscoveryNodes nodes) {\n+    static ByteSizeValue calculateEffectiveMaxModelMemoryLimit(int maxMachineMemoryPercent, DiscoveryNodes nodes) {\n \n         long maxMlMemory = -1;\n \n"}}, {"oid": "5bfc7d41e8620077c4f12d6f82729cde0265d189", "url": "https://github.com/elastic/elasticsearch/commit/5bfc7d41e8620077c4f12d6f82729cde0265d189", "message": "Fix docs test", "committedDate": "2020-04-21T15:56:28Z", "type": "commit"}, {"oid": "3c08ac562d6ac45447126534562c1351ca066279", "url": "https://github.com/elastic/elasticsearch/commit/3c08ac562d6ac45447126534562c1351ca066279", "message": "Fix checkstyle", "committedDate": "2020-04-21T16:33:29Z", "type": "commit"}, {"oid": "9b183f43f501a4480800a4fd44fb70af54846e1e", "url": "https://github.com/elastic/elasticsearch/commit/9b183f43f501a4480800a4fd44fb70af54846e1e", "message": "current_effective -> effective\n\nWe decided that using two words was overly verbose", "committedDate": "2020-04-22T09:46:26Z", "type": "commit"}]}