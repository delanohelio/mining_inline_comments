{"pr_number": 58728, "pr_title": "Allow read operations to be executed without waiting for full range to be written in cache", "pr_createdAt": "2020-06-30T10:39:54Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58728", "timeline": [{"oid": "35985e1a77383fc9b730b5a1a459200ac64b2fcb", "url": "https://github.com/elastic/elasticsearch/commit/35985e1a77383fc9b730b5a1a459200ac64b2fcb", "message": "Use progress listener in CacheFile", "committedDate": "2020-06-30T10:38:34Z", "type": "commit"}, {"oid": "28091b888998d690d9cf926aa0e80362f75cb590", "url": "https://github.com/elastic/elasticsearch/commit/28091b888998d690d9cf926aa0e80362f75cb590", "message": "Merge branch 'master' into use-progressable-listener-in-cache-file", "committedDate": "2020-06-30T12:03:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDUwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r447674501", "bodyText": "Could also be named prewarmExecutor()", "author": "tlrx", "createdAt": "2020-06-30T13:18:42Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java", "diffHunk": "@@ -317,6 +318,14 @@ public CacheFile getCacheFile(CacheKey cacheKey, long fileLength) throws Excepti\n         return cacheService.get(cacheKey, fileLength, cacheDir);\n     }\n \n+    public Executor executor() {\n+        return threadPool.executor(SearchableSnapshotsConstants.SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n+    }\n+\n+    public Executor directExecutor() {", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMTY1OA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r447721658", "bodyText": "++ I'd prefer that, lest we use this executor for something else in the future and then decide to change it. Can we name the other executor() method something more specific too?", "author": "DaveCTurner", "createdAt": "2020-06-30T14:21:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIyMDIwNA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448220204", "bodyText": "Can we name the other executor() method something more specific too?\n\nI'm terrible at naming things (sorry, kids)... what do you think of  searchExecutor() ? cacheWritingExecutor() ?", "author": "tlrx", "createdAt": "2020-07-01T08:58:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIyNzYxNA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448227614", "bodyText": "Tricky one TBH. How about cacheFetchAsyncExecutor()?", "author": "DaveCTurner", "createdAt": "2020-07-01T09:11:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIzMDAwMw==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448230003", "bodyText": "+1", "author": "tlrx", "createdAt": "2020-07-01T09:15:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDUwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java\nindex 23bb9135d27..111f9b4ccfb 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/SearchableSnapshotDirectory.java\n\n@@ -318,11 +318,11 @@ public class SearchableSnapshotDirectory extends BaseDirectory {\n         return cacheService.get(cacheKey, fileLength, cacheDir);\n     }\n \n-    public Executor executor() {\n+    public Executor cacheFetchAsyncExecutor() {\n         return threadPool.executor(SearchableSnapshotsConstants.SEARCHABLE_SNAPSHOTS_THREAD_POOL_NAME);\n     }\n \n-    public Executor directExecutor() {\n+    public Executor prewarmExecutor() {\n         return threadPool.executor(ThreadPool.Names.SAME);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NDc4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r447674789", "bodyText": "This is already verified by the SparseFileTracker itself", "author": "tlrx", "createdAt": "2020-06-30T13:19:07Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -259,38 +262,68 @@ private void ensureOpen() {\n         }\n     }\n \n-    CompletableFuture<Integer> fetchRange(\n-        long start,\n-        long end,\n-        CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n-        CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n+    @FunctionalInterface\n+    interface CacheReader {\n+        int read(FileChannel channel) throws IOException;\n+    }\n+\n+    @FunctionalInterface\n+    interface CacheWriter {\n+        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    }\n+\n+    CompletableFuture<Integer> fetchAsync(\n+        final Tuple<Long, Long> rangeToWrite,\n+        final Tuple<Long, Long> rangeToRead,\n+        final CacheReader reader,\n+        final CacheWriter writer,\n+        final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n-            if (start < 0 || start > tracker.getLength() || start > end || end > tracker.getLength()) {", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex e92024244e9..c6e0557bb48 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -263,39 +261,43 @@ public class CacheFile {\n     }\n \n     @FunctionalInterface\n-    interface CacheReader {\n-        int read(FileChannel channel) throws IOException;\n+    interface RangeAvailableHandler {\n+        int onRangeAvailable(FileChannel channel) throws IOException;\n     }\n \n     @FunctionalInterface\n-    interface CacheWriter {\n-        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    interface RangeMissingHandler {\n+        void fillCacheRange(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n     }\n \n     CompletableFuture<Integer> fetchAsync(\n         final Tuple<Long, Long> rangeToWrite,\n         final Tuple<Long, Long> rangeToRead,\n-        final CacheReader reader,\n-        final CacheWriter writer,\n+        final RangeAvailableHandler reader,\n+        final RangeMissingHandler writer,\n         final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n             ensureOpen();\n-            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                rangeToWrite,\n-                rangeToRead,\n-                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)\n-            );\n+            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, ActionListener.wrap(success -> {\n+                final int read = reader.onRangeAvailable(channel);\n+                assert read == rangeToRead.v2() - rangeToRead.v1() : \"partial read [\"\n+                    + read\n+                    + \"] does not match the range to read [\"\n+                    + rangeToRead.v2()\n+                    + '-'\n+                    + rangeToRead.v1()\n+                    + ']';\n+                future.complete(read);\n+            }, future::completeExceptionally));\n \n             if (gaps.isEmpty() == false) {\n-                final Iterator<SparseFileTracker.Gap> iterator = new ArrayList<>(gaps).iterator();\n                 executor.execute(new AbstractRunnable() {\n \n                     @Override\n                     protected void doRun() {\n-                        while (iterator.hasNext()) {\n-                            final SparseFileTracker.Gap gap = iterator.next();\n+                        for (SparseFileTracker.Gap gap : gaps) {\n                             try {\n                                 ensureOpen();\n                                 if (readLock.tryLock() == false) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NTY2MA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r447675660", "bodyText": "This was previously embedded in the readCacheFile() method but feels wrong to me; the readCacheFile() should expect a ByteBuffer with an appropriate limit.", "author": "tlrx", "createdAt": "2020-06-30T13:20:17Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -141,13 +143,22 @@ protected void readInternal(ByteBuffer b) throws IOException {\n             try {\n                 final CacheFile cacheFile = getCacheFileSafe();\n                 try (Releasable ignored = cacheFile.fileLock()) {\n-                    final Tuple<Long, Long> range = computeRange(pos);\n-                    bytesRead = cacheFile.fetchRange(\n-                        range.v1(),\n-                        range.v2(),\n-                        (start, end) -> readCacheFile(cacheFile.getChannel(), end, pos, b, len),\n-                        (start, end) -> writeCacheFile(cacheFile.getChannel(), start, end)\n-                    ).get();\n+                    final Tuple<Long, Long> rangeToWrite = computeRange(pos);\n+                    final Tuple<Long, Long> rangeToRead = Tuple.tuple(pos, Math.min(pos + len, rangeToWrite.v2()));\n+\n+                    bytesRead = cacheFile.fetchAsync(rangeToWrite, rangeToRead, (channel) -> {\n+                        final int read;\n+                        if ((rangeToRead.v2() - rangeToRead.v1()) < b.remaining()) {", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODE5NDAzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448194031", "bodyText": "++ there was a recent change to the Lucene APIs replacing byte[], int, int with ByteBuffer but this was not pushed all the way through this code.", "author": "DaveCTurner", "createdAt": "2020-07-01T08:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NTY2MA=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\nindex 7dd63c161f8..b7bdd8bb8ca 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\n\n@@ -158,7 +158,7 @@ public class CachedBlobContainerIndexInput extends BaseSearchableSnapshotIndexIn\n                             read = readCacheFile(channel, pos, b);\n                         }\n                         return read;\n-                    }, this::writeCacheFile, directory.executor()).get();\n+                    }, this::writeCacheFile, directory.cacheFetchAsyncExecutor()).get();\n                 }\n             } catch (final Exception e) {\n                 if (e instanceof AlreadyClosedException || (e.getCause() != null && e.getCause() instanceof AlreadyClosedException)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NzYzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r447677639", "bodyText": "Maybe it deserves some comment: we don't care about reading the cached data for prewarming, it just need to cache the range. This is why it got passed an empty range to read. This way if the range is already (or about to be) written by a concurrent search it returns immediately and process the next small range. If the range is not available then the cache data will be written by this prewarming task.", "author": "tlrx", "createdAt": "2020-06-30T13:22:57Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java", "diffHunk": "@@ -224,31 +235,33 @@ public void prefetchPart(final int part) throws IOException {\n                     while (remainingBytes > 0L) {\n                         assert totalBytesRead + remainingBytes == rangeLength;\n                         final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remainingBytes, cacheFileReference);\n+\n                         final long readStart = rangeStart + totalBytesRead;\n-                        cacheFile.fetchRange(readStart, readStart + bytesRead, (start, end) -> {\n-                            logger.trace(\n-                                \"prefetchPart: range [{}-{}] of file [{}] is available in cache\",\n-                                start,\n-                                end,\n-                                fileInfo.physicalName()\n-                            );\n-                            return Math.toIntExact(end - start);\n-                        }, (start, end) -> {\n-                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n-                                copyBuffer,\n-                                Math.toIntExact(start - readStart),\n-                                Math.toIntExact(end - start)\n-                            );\n-                            final int writtenBytes = positionalWrite(fc, start, byteBuffer);\n-                            logger.trace(\n-                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n-                                start,\n-                                end,\n-                                fileInfo.physicalName(),\n-                                writtenBytes\n-                            );\n-                            totalBytesWritten.addAndGet(writtenBytes);\n-                        });\n+                        final long readEnd = readStart + bytesRead;\n+\n+                        cacheFile.fetchAsync(\n+                            Tuple.tuple(readStart, readEnd),\n+                            Tuple.tuple(readStart, readStart),", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODE3NTI3MA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448175270", "bodyText": "++ let's add a comment saying that in the code too.", "author": "DaveCTurner", "createdAt": "2020-07-01T07:39:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3NzYzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\nindex 7dd63c161f8..b7bdd8bb8ca 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInput.java\n\n@@ -236,32 +236,33 @@ public class CachedBlobContainerIndexInput extends BaseSearchableSnapshotIndexIn\n                         assert totalBytesRead + remainingBytes == rangeLength;\n                         final int bytesRead = readSafe(input, copyBuffer, rangeStart, rangeEnd, remainingBytes, cacheFileReference);\n \n+                        // The range to prewarm in cache\n                         final long readStart = rangeStart + totalBytesRead;\n-                        final long readEnd = readStart + bytesRead;\n-\n-                        cacheFile.fetchAsync(\n-                            Tuple.tuple(readStart, readEnd),\n-                            Tuple.tuple(readStart, readStart),\n-                            (channel) -> 0,\n-                            (channel, start, end, progressUpdater) -> {\n-                                final ByteBuffer byteBuffer = ByteBuffer.wrap(\n-                                    copyBuffer,\n-                                    Math.toIntExact(start - readStart),\n-                                    Math.toIntExact(end - start)\n-                                );\n-                                final int writtenBytes = positionalWrite(channel, start, byteBuffer);\n-                                logger.trace(\n-                                    \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n-                                    start,\n-                                    end,\n-                                    fileInfo.physicalName(),\n-                                    writtenBytes\n-                                );\n-                                totalBytesWritten.addAndGet(writtenBytes);\n-                                progressUpdater.accept(start + writtenBytes);\n-                            },\n-                            directory.directExecutor()\n-                        );\n+                        final Tuple<Long, Long> rangeToWrite = Tuple.tuple(readStart, readStart + bytesRead);\n+\n+                        // Prewarming don't need to read the cached data after it been written in cache; so the range to read is empty. In\n+                        // case where the range is actively being (or about to be) written in cache by a concurrent search the sync fetching\n+                        // returns immediately and the next range can be prewarmed. If the range is not available in cache then the range\n+                        // will be written by this prewarming task and blocks until fully written to disk.\n+                        final Tuple<Long, Long> rangeToRead = Tuple.tuple(readStart, readStart);\n+\n+                        cacheFile.fetchAsync(rangeToWrite, rangeToRead, (channel) -> 0, (channel, start, end, progressUpdater) -> {\n+                            final ByteBuffer byteBuffer = ByteBuffer.wrap(\n+                                copyBuffer,\n+                                Math.toIntExact(start - readStart),\n+                                Math.toIntExact(end - start)\n+                            );\n+                            final int writtenBytes = positionalWrite(channel, start, byteBuffer);\n+                            logger.trace(\n+                                \"prefetchPart: writing range [{}-{}] of file [{}], [{}] bytes written\",\n+                                start,\n+                                end,\n+                                fileInfo.physicalName(),\n+                                writtenBytes\n+                            );\n+                            totalBytesWritten.addAndGet(writtenBytes);\n+                            progressUpdater.accept(start + writtenBytes);\n+                        }, directory.prewarmExecutor());\n                         totalBytesRead += bytesRead;\n                         remainingBytes -= bytesRead;\n                     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODE3MzQyNA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448173424", "bodyText": "Why do we remove the gap from the list here?", "author": "DaveCTurner", "createdAt": "2020-07-01T07:35:46Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -259,38 +262,68 @@ private void ensureOpen() {\n         }\n     }\n \n-    CompletableFuture<Integer> fetchRange(\n-        long start,\n-        long end,\n-        CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n-        CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n+    @FunctionalInterface\n+    interface CacheReader {\n+        int read(FileChannel channel) throws IOException;\n+    }\n+\n+    @FunctionalInterface\n+    interface CacheWriter {\n+        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    }\n+\n+    CompletableFuture<Integer> fetchAsync(\n+        final Tuple<Long, Long> rangeToWrite,\n+        final Tuple<Long, Long> rangeToRead,\n+        final CacheReader reader,\n+        final CacheWriter writer,\n+        final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n-            if (start < 0 || start > tracker.getLength() || start > end || end > tracker.getLength()) {\n-                throw new IllegalArgumentException(\n-                    \"Invalid range [start=\" + start + \", end=\" + end + \"] for length [\" + tracker.getLength() + ']'\n-                );\n-            }\n             ensureOpen();\n             final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                Tuple.tuple(start, end),\n-                Tuple.tuple(start, end), // TODO use progressive sub range to trigger read operations sooner\n-                ActionListener.wrap(\n-                    rangeReady -> future.complete(onRangeAvailable.apply(start, end)),\n-                    rangeFailure -> future.completeExceptionally(rangeFailure)\n-                )\n+                rangeToWrite,\n+                rangeToRead,\n+                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)\n             );\n \n-            for (SparseFileTracker.Gap gap : gaps) {\n-                try {\n-                    ensureOpen();\n-                    onRangeMissing.accept(gap.start(), gap.end());\n-                    gap.onProgress(gap.end()); // TODO update progress in onRangeMissing\n-                    gap.onCompletion();\n-                } catch (Exception e) {\n-                    gap.onFailure(e);\n-                }\n+            if (gaps.isEmpty() == false) {\n+                final Iterator<SparseFileTracker.Gap> iterator = new ArrayList<>(gaps).iterator();\n+                executor.execute(new AbstractRunnable() {\n+\n+                    @Override\n+                    protected void doRun() {\n+                        while (iterator.hasNext()) {\n+                            final SparseFileTracker.Gap gap = iterator.next();\n+                            try {\n+                                ensureOpen();\n+                                if (readLock.tryLock() == false) {\n+                                    throw new AlreadyClosedException(\"Cache file channel is being evicted, writing attempt cancelled\");\n+                                }\n+                                try {\n+                                    ensureOpen();\n+                                    if (channel == null) {\n+                                        throw new AlreadyClosedException(\"Cache file channel has been released and closed\");\n+                                    }\n+                                    writer.write(channel, gap.start(), gap.end(), gap::onProgress);\n+                                    gap.onCompletion();\n+                                } finally {\n+                                    readLock.unlock();\n+                                }\n+                            } catch (Exception e) {\n+                                gap.onFailure(e);\n+                            } finally {\n+                                iterator.remove();", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIzNzkxOA==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448237918", "bodyText": "This is a left over - I think we can just iterate over the list of gaps.", "author": "tlrx", "createdAt": "2020-07-01T09:29:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODE3MzQyNA=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex e92024244e9..c6e0557bb48 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -263,39 +261,43 @@ public class CacheFile {\n     }\n \n     @FunctionalInterface\n-    interface CacheReader {\n-        int read(FileChannel channel) throws IOException;\n+    interface RangeAvailableHandler {\n+        int onRangeAvailable(FileChannel channel) throws IOException;\n     }\n \n     @FunctionalInterface\n-    interface CacheWriter {\n-        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    interface RangeMissingHandler {\n+        void fillCacheRange(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n     }\n \n     CompletableFuture<Integer> fetchAsync(\n         final Tuple<Long, Long> rangeToWrite,\n         final Tuple<Long, Long> rangeToRead,\n-        final CacheReader reader,\n-        final CacheWriter writer,\n+        final RangeAvailableHandler reader,\n+        final RangeMissingHandler writer,\n         final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n             ensureOpen();\n-            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                rangeToWrite,\n-                rangeToRead,\n-                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)\n-            );\n+            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, ActionListener.wrap(success -> {\n+                final int read = reader.onRangeAvailable(channel);\n+                assert read == rangeToRead.v2() - rangeToRead.v1() : \"partial read [\"\n+                    + read\n+                    + \"] does not match the range to read [\"\n+                    + rangeToRead.v2()\n+                    + '-'\n+                    + rangeToRead.v1()\n+                    + ']';\n+                future.complete(read);\n+            }, future::completeExceptionally));\n \n             if (gaps.isEmpty() == false) {\n-                final Iterator<SparseFileTracker.Gap> iterator = new ArrayList<>(gaps).iterator();\n                 executor.execute(new AbstractRunnable() {\n \n                     @Override\n                     protected void doRun() {\n-                        while (iterator.hasNext()) {\n-                            final SparseFileTracker.Gap gap = iterator.next();\n+                        for (SparseFileTracker.Gap gap : gaps) {\n                             try {\n                                 ensureOpen();\n                                 if (readLock.tryLock() == false) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwMTYxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448201615", "bodyText": "Can we assert that reader.read(channel) returns rangeToRead.end() - rangeToRead.start() here?", "author": "DaveCTurner", "createdAt": "2020-07-01T08:26:35Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -259,38 +262,68 @@ private void ensureOpen() {\n         }\n     }\n \n-    CompletableFuture<Integer> fetchRange(\n-        long start,\n-        long end,\n-        CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n-        CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n+    @FunctionalInterface\n+    interface CacheReader {\n+        int read(FileChannel channel) throws IOException;\n+    }\n+\n+    @FunctionalInterface\n+    interface CacheWriter {\n+        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    }\n+\n+    CompletableFuture<Integer> fetchAsync(\n+        final Tuple<Long, Long> rangeToWrite,\n+        final Tuple<Long, Long> rangeToRead,\n+        final CacheReader reader,\n+        final CacheWriter writer,\n+        final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n-            if (start < 0 || start > tracker.getLength() || start > end || end > tracker.getLength()) {\n-                throw new IllegalArgumentException(\n-                    \"Invalid range [start=\" + start + \", end=\" + end + \"] for length [\" + tracker.getLength() + ']'\n-                );\n-            }\n             ensureOpen();\n             final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                Tuple.tuple(start, end),\n-                Tuple.tuple(start, end), // TODO use progressive sub range to trigger read operations sooner\n-                ActionListener.wrap(\n-                    rangeReady -> future.complete(onRangeAvailable.apply(start, end)),\n-                    rangeFailure -> future.completeExceptionally(rangeFailure)\n-                )\n+                rangeToWrite,\n+                rangeToRead,\n+                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIzODExOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448238119", "bodyText": "Good suggestion, thanks", "author": "tlrx", "createdAt": "2020-07-01T09:30:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwMTYxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex e92024244e9..c6e0557bb48 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -263,39 +261,43 @@ public class CacheFile {\n     }\n \n     @FunctionalInterface\n-    interface CacheReader {\n-        int read(FileChannel channel) throws IOException;\n+    interface RangeAvailableHandler {\n+        int onRangeAvailable(FileChannel channel) throws IOException;\n     }\n \n     @FunctionalInterface\n-    interface CacheWriter {\n-        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    interface RangeMissingHandler {\n+        void fillCacheRange(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n     }\n \n     CompletableFuture<Integer> fetchAsync(\n         final Tuple<Long, Long> rangeToWrite,\n         final Tuple<Long, Long> rangeToRead,\n-        final CacheReader reader,\n-        final CacheWriter writer,\n+        final RangeAvailableHandler reader,\n+        final RangeMissingHandler writer,\n         final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n             ensureOpen();\n-            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                rangeToWrite,\n-                rangeToRead,\n-                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)\n-            );\n+            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, ActionListener.wrap(success -> {\n+                final int read = reader.onRangeAvailable(channel);\n+                assert read == rangeToRead.v2() - rangeToRead.v1() : \"partial read [\"\n+                    + read\n+                    + \"] does not match the range to read [\"\n+                    + rangeToRead.v2()\n+                    + '-'\n+                    + rangeToRead.v1()\n+                    + ']';\n+                future.complete(read);\n+            }, future::completeExceptionally));\n \n             if (gaps.isEmpty() == false) {\n-                final Iterator<SparseFileTracker.Gap> iterator = new ArrayList<>(gaps).iterator();\n                 executor.execute(new AbstractRunnable() {\n \n                     @Override\n                     protected void doRun() {\n-                        while (iterator.hasNext()) {\n-                            final SparseFileTracker.Gap gap = iterator.next();\n+                        for (SparseFileTracker.Gap gap : gaps) {\n                             try {\n                                 ensureOpen();\n                                 if (readLock.tryLock() == false) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwODQyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448208425", "bodyText": "What, no CheckedQuadConsumer<...>? \ud83d\ude01\nI'm torn about having these be separate interfaces vs combining them together perhaps along with some other arguments to fetchAsync too. I'm finding it especially strange that CacheReader#read only takes a FileChannel; this indicates that rangeToRead is now available, but that's very implicit now.\nMaybe different names would help. How about something like RangeMissingHandler#fillCacheRange and RangeAvailableHandler#onRangeAvailable?", "author": "DaveCTurner", "createdAt": "2020-07-01T08:38:04Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -259,38 +262,68 @@ private void ensureOpen() {\n         }\n     }\n \n-    CompletableFuture<Integer> fetchRange(\n-        long start,\n-        long end,\n-        CheckedBiFunction<Long, Long, Integer, IOException> onRangeAvailable,\n-        CheckedBiConsumer<Long, Long, IOException> onRangeMissing\n+    @FunctionalInterface\n+    interface CacheReader {\n+        int read(FileChannel channel) throws IOException;\n+    }\n+\n+    @FunctionalInterface\n+    interface CacheWriter {\n+        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;", "originalCommit": "28091b888998d690d9cf926aa0e80362f75cb590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI0NTQzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/58728#discussion_r448245431", "bodyText": "What, no CheckedQuadConsumer<...>? grin\n\nDon't tempt me :)\n\nMaybe different names would help. How about something like RangeMissingHandler#fillCacheRange and RangeAvailableHandler#onRangeAvailable?\n\nI went this route and renamed to RangeMissingHandler/RangeAvailableHandler", "author": "tlrx", "createdAt": "2020-07-01T09:43:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwODQyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "chunk": "diff --git a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\nindex e92024244e9..c6e0557bb48 100644\n--- a/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n+++ b/x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java\n\n@@ -263,39 +261,43 @@ public class CacheFile {\n     }\n \n     @FunctionalInterface\n-    interface CacheReader {\n-        int read(FileChannel channel) throws IOException;\n+    interface RangeAvailableHandler {\n+        int onRangeAvailable(FileChannel channel) throws IOException;\n     }\n \n     @FunctionalInterface\n-    interface CacheWriter {\n-        void write(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n+    interface RangeMissingHandler {\n+        void fillCacheRange(FileChannel channel, long from, long to, Consumer<Long> progressUpdater) throws IOException;\n     }\n \n     CompletableFuture<Integer> fetchAsync(\n         final Tuple<Long, Long> rangeToWrite,\n         final Tuple<Long, Long> rangeToRead,\n-        final CacheReader reader,\n-        final CacheWriter writer,\n+        final RangeAvailableHandler reader,\n+        final RangeMissingHandler writer,\n         final Executor executor\n     ) {\n         final CompletableFuture<Integer> future = new CompletableFuture<>();\n         try {\n             ensureOpen();\n-            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(\n-                rangeToWrite,\n-                rangeToRead,\n-                ActionListener.wrap(success -> future.complete(reader.read(channel)), future::completeExceptionally)\n-            );\n+            final List<SparseFileTracker.Gap> gaps = tracker.waitForRange(rangeToWrite, rangeToRead, ActionListener.wrap(success -> {\n+                final int read = reader.onRangeAvailable(channel);\n+                assert read == rangeToRead.v2() - rangeToRead.v1() : \"partial read [\"\n+                    + read\n+                    + \"] does not match the range to read [\"\n+                    + rangeToRead.v2()\n+                    + '-'\n+                    + rangeToRead.v1()\n+                    + ']';\n+                future.complete(read);\n+            }, future::completeExceptionally));\n \n             if (gaps.isEmpty() == false) {\n-                final Iterator<SparseFileTracker.Gap> iterator = new ArrayList<>(gaps).iterator();\n                 executor.execute(new AbstractRunnable() {\n \n                     @Override\n                     protected void doRun() {\n-                        while (iterator.hasNext()) {\n-                            final SparseFileTracker.Gap gap = iterator.next();\n+                        for (SparseFileTracker.Gap gap : gaps) {\n                             try {\n                                 ensureOpen();\n                                 if (readLock.tryLock() == false) {\n"}}, {"oid": "afe11a0151726d4c66b856c410ddeba69e1be6f4", "url": "https://github.com/elastic/elasticsearch/commit/afe11a0151726d4c66b856c410ddeba69e1be6f4", "message": "apply feedback", "committedDate": "2020-07-01T09:46:19Z", "type": "commit"}, {"oid": "36f84b7f3d3ecc003ccfc4449c665060b49b8798", "url": "https://github.com/elastic/elasticsearch/commit/36f84b7f3d3ecc003ccfc4449c665060b49b8798", "message": "Merge branch 'master' into use-progressable-listener-in-cache-file", "committedDate": "2020-07-01T09:46:39Z", "type": "commit"}, {"oid": "b0e5d1d24f0a8a0480ab85df2c3d0bcdf7287615", "url": "https://github.com/elastic/elasticsearch/commit/b0e5d1d24f0a8a0480ab85df2c3d0bcdf7287615", "message": "Revert InternalTestCluster", "committedDate": "2020-07-01T10:09:46Z", "type": "commit"}, {"oid": "53232bd7ee3c7058ce3109edfd649cc2b25b4cec", "url": "https://github.com/elastic/elasticsearch/commit/53232bd7ee3c7058ce3109edfd649cc2b25b4cec", "message": "assert thread pool in positionalWrite", "committedDate": "2020-07-01T10:16:08Z", "type": "commit"}]}