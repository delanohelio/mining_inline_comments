{"pr_number": 13907, "pr_title": "[FLINK-19942][Connectors / JDBC]Support sink parallelism configuration to JDBC connector", "pr_createdAt": "2020-11-03T12:37:07Z", "pr_url": "https://github.com/apache/flink/pull/13907", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg2OTQ3MQ==", "url": "https://github.com/apache/flink/pull/13907#discussion_r535869471", "bodyText": "does the equals and hash function need to be modify? @zhuxiaoshang", "author": "zhisheng17", "createdAt": "2020-12-04T06:37:10Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java", "diffHunk": "@@ -55,6 +61,10 @@ public int getMaxRetries() {\n \t\treturn maxRetries;\n \t}\n \n+\tpublic Integer getParallelism() {\n+\t\treturn parallelism;\n+\t}\n+\n \t@Override\n \tpublic boolean equals(Object o) {\n \t\tif (this == o) {", "originalCommit": "49181d26aa6a07bc289544ad0d55929fd2c89377", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMzM5Nw==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539033397", "bodyText": "Yes you are right @zhisheng17 ,I ignored.", "author": "zhuxiaoshang", "createdAt": "2020-12-09T06:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg2OTQ3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "chunk": "diff --git a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\nindex c6a40bfc2f..4871eaa8e0 100644\n--- a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n+++ b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n\n@@ -61,10 +55,6 @@ public class JdbcExecutionOptions implements Serializable {\n \t\treturn maxRetries;\n \t}\n \n-\tpublic Integer getParallelism() {\n-\t\treturn parallelism;\n-\t}\n-\n \t@Override\n \tpublic boolean equals(Object o) {\n \t\tif (this == o) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzNzAxMw==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539037013", "bodyText": "Will return false when parallelism > 128?", "author": "V1ncentzzZ", "createdAt": "2020-12-09T06:13:37Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java", "diffHunk": "@@ -66,12 +76,13 @@ public boolean equals(Object o) {\n \t\tJdbcExecutionOptions that = (JdbcExecutionOptions) o;\n \t\treturn batchIntervalMs == that.batchIntervalMs &&\n \t\t\tbatchSize == that.batchSize &&\n-\t\t\tmaxRetries == that.maxRetries;\n+\t\t\tmaxRetries == that.maxRetries &&\n+\t\t\tparallelism == that.parallelism;", "originalCommit": "f4f1cf14d4d413c4c87881516215c7ffffd5be64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzOTkzNg==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539039936", "bodyText": "Maybe the framework will check whether the parallelism > max parallelism limit.\nMoreover where do you get the 128?IIRC,128 is the limit of max keyGroup.", "author": "zhuxiaoshang", "createdAt": "2020-12-09T06:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzNzAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA0MjY5OA==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539042698", "bodyText": "My suggestion is that use equals() instead of == beacause of the == will return false when parallelism's value more than 128.", "author": "V1ncentzzZ", "createdAt": "2020-12-09T06:28:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzNzAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA0MzM0MQ==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539043341", "bodyText": "ok,I have changed it.", "author": "zhuxiaoshang", "createdAt": "2020-12-09T06:29:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzNzAxMw=="}], "type": "inlineReview", "revised_code": {"commit": "5ba8c4410ef2616561f46462d1000056949e8c6b", "chunk": "diff --git a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\nindex c66b0ddb2c..0aa85a0eae 100644\n--- a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n+++ b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n\n@@ -77,7 +77,7 @@ public class JdbcExecutionOptions implements Serializable {\n \t\treturn batchIntervalMs == that.batchIntervalMs &&\n \t\t\tbatchSize == that.batchSize &&\n \t\t\tmaxRetries == that.maxRetries &&\n-\t\t\tparallelism == that.parallelism;\n+\t\t\tObjects.equals(parallelism, that.parallelism);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzODc4Ng==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539038786", "bodyText": "@zhuxiaoshang maybe, idea will recommend to use equals() instead of ==", "author": "zhisheng17", "createdAt": "2020-12-09T06:18:25Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java", "diffHunk": "@@ -66,12 +76,13 @@ public boolean equals(Object o) {\n \t\tJdbcExecutionOptions that = (JdbcExecutionOptions) o;\n \t\treturn batchIntervalMs == that.batchIntervalMs &&\n \t\t\tbatchSize == that.batchSize &&\n-\t\t\tmaxRetries == that.maxRetries;\n+\t\t\tmaxRetries == that.maxRetries &&\n+\t\t\tparallelism == that.parallelism;", "originalCommit": "f4f1cf14d4d413c4c87881516215c7ffffd5be64", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5ba8c4410ef2616561f46462d1000056949e8c6b", "chunk": "diff --git a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\nindex c66b0ddb2c..0aa85a0eae 100644\n--- a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n+++ b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n\n@@ -77,7 +77,7 @@ public class JdbcExecutionOptions implements Serializable {\n \t\treturn batchIntervalMs == that.batchIntervalMs &&\n \t\t\tbatchSize == that.batchSize &&\n \t\t\tmaxRetries == that.maxRetries &&\n-\t\t\tparallelism == that.parallelism;\n+\t\t\tObjects.equals(parallelism, that.parallelism);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA4ODQ2Mg==", "url": "https://github.com/apache/flink/pull/13907#discussion_r539088462", "bodyText": "It's seem this method is useless now? If no one uses it, please delete it. Otherwise, we can just treat this method as\nof(outputFormat, null)", "author": "fsk119", "createdAt": "2020-12-09T08:06:09Z", "path": "flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java", "diffHunk": "@@ -36,6 +38,23 @@ static OutputFormatProvider of(OutputFormat<RowData> outputFormat) {\n \t\treturn () -> outputFormat;", "originalCommit": "a20a54634b452b7a9fbc28e3a292196376602b3f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5ba8c4410ef2616561f46462d1000056949e8c6b", "chunk": "diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\nindex f63f9828fd..47cf69bcd9 100644\n--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\n+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\n\n@@ -31,13 +31,6 @@ import java.util.Optional;\n @PublicEvolving\n public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider, ParallelismProvider {\n \n-\t/**\n-\t * Helper method for creating a static provider.\n-\t */\n-\tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat) {\n-\t\treturn () -> outputFormat;\n-\t}\n-\n \t/**\n \t * Helper method for creating a static provider with a provided sink parallelism.\n \t */\n"}}, {"oid": "5ba8c4410ef2616561f46462d1000056949e8c6b", "url": "https://github.com/apache/flink/commit/5ba8c4410ef2616561f46462d1000056949e8c6b", "message": "[FLINK-19942][Connectors / JDBC]Support sink parallelism configuration to JDBC connector", "committedDate": "2020-12-09T09:19:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1NDEzNg==", "url": "https://github.com/apache/flink/pull/13907#discussion_r540754136", "bodyText": "This is a public API. Please add a new method instead of changing the existing one, otherwise, it's not API compatible.", "author": "wuchong", "createdAt": "2020-12-11T07:53:48Z", "path": "flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java", "diffHunk": "@@ -23,17 +23,29 @@\n import org.apache.flink.table.connector.ParallelismProvider;\n import org.apache.flink.table.data.RowData;\n \n+import java.util.Optional;\n+\n /**\n  * Provider of an {@link OutputFormat} instance as a runtime implementation for {@link DynamicTableSink}.\n  */\n @PublicEvolving\n public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider, ParallelismProvider {\n \n \t/**\n-\t * Helper method for creating a static provider.\n+\t * Helper method for creating a static provider with a provided sink parallelism.\n \t */\n-\tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat) {\n-\t\treturn () -> outputFormat;\n+\tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat, Integer sinkParallelism) {", "originalCommit": "5ba8c4410ef2616561f46462d1000056949e8c6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc4ODg1Nw==", "url": "https://github.com/apache/flink/pull/13907#discussion_r540788857", "bodyText": "According to  @fsk119 's suggestion,I removed the old method because it is never used.\nIf not i can get it back.", "author": "zhuxiaoshang", "createdAt": "2020-12-11T08:57:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1NDEzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgwNDMyNA==", "url": "https://github.com/apache/flink/pull/13907#discussion_r540804324", "bodyText": "This is a public API. We don't know whether it is used by external projects.", "author": "wuchong", "createdAt": "2020-12-11T09:22:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1NDEzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgxMTQ0OA==", "url": "https://github.com/apache/flink/pull/13907#discussion_r540811448", "bodyText": "ok\uff0cgot it", "author": "zhuxiaoshang", "createdAt": "2020-12-11T09:33:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1NDEzNg=="}], "type": "inlineReview", "revised_code": {"commit": "9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "chunk": "diff --git a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\nindex 47cf69bcd9..f63f9828fd 100644\n--- a/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\n+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java\n\n@@ -31,6 +31,13 @@ import java.util.Optional;\n @PublicEvolving\n public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider, ParallelismProvider {\n \n+\t/**\n+\t * Helper method for creating a static provider.\n+\t */\n+\tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat) {\n+\t\treturn () -> outputFormat;\n+\t}\n+\n \t/**\n \t * Helper method for creating a static provider with a provided sink parallelism.\n \t */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1OTE0Nw==", "url": "https://github.com/apache/flink/pull/13907#discussion_r540759147", "bodyText": "I'm not sure about adding this to JdbcExecutionOptions, because JdbcExecutionOptions is an public API for JdbcSink. For JdbcSink#sink, this may looks weird because the configured parallelism doesn't work as the returned object is SinkFunction.\nAnother option is adding the parallelism to JdbcDmlOption or JdbcOption, they are both internal class.", "author": "wuchong", "createdAt": "2020-12-11T08:04:16Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java", "diffHunk": "@@ -35,12 +35,18 @@\n \tprivate final long batchIntervalMs;\n \tprivate final int batchSize;\n \tprivate final int maxRetries;\n+\tprivate final Integer parallelism;\n \n-\tprivate JdbcExecutionOptions(long batchIntervalMs, int batchSize, int maxRetries) {\n+\tprivate JdbcExecutionOptions(\n+\t\t\tlong batchIntervalMs,\n+\t\t\tint batchSize,\n+\t\t\tint maxRetries,\n+\t\t\tInteger parallelism) {", "originalCommit": "5ba8c4410ef2616561f46462d1000056949e8c6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "chunk": "diff --git a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\nindex 0aa85a0eae..4871eaa8e0 100644\n--- a/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n+++ b/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExecutionOptions.java\n\n@@ -35,18 +35,12 @@ public class JdbcExecutionOptions implements Serializable {\n \tprivate final long batchIntervalMs;\n \tprivate final int batchSize;\n \tprivate final int maxRetries;\n-\tprivate final Integer parallelism;\n \n-\tprivate JdbcExecutionOptions(\n-\t\t\tlong batchIntervalMs,\n-\t\t\tint batchSize,\n-\t\t\tint maxRetries,\n-\t\t\tInteger parallelism) {\n+\tprivate JdbcExecutionOptions(long batchIntervalMs, int batchSize, int maxRetries) {\n \t\tPreconditions.checkArgument(maxRetries >= 0);\n \t\tthis.batchIntervalMs = batchIntervalMs;\n \t\tthis.batchSize = batchSize;\n \t\tthis.maxRetries = maxRetries;\n-\t\tthis.parallelism = parallelism;\n \t}\n \n \tpublic long getBatchIntervalMs() {\n"}}, {"oid": "9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "url": "https://github.com/apache/flink/commit/9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "message": "[FLINK-19942][jdbc] Support sink parallelism configuration for JDBC connector\n\nThis closes #13907", "committedDate": "2020-12-21T03:06:24Z", "type": "commit"}, {"oid": "9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "url": "https://github.com/apache/flink/commit/9341091a00aaf73556b7e6c5f9bc319a9512dd5a", "message": "[FLINK-19942][jdbc] Support sink parallelism configuration for JDBC connector\n\nThis closes #13907", "committedDate": "2020-12-21T03:06:24Z", "type": "forcePushed"}]}