{"pr_number": 12594, "pr_title": "[FLINK-18072][hbase] HBaseLookupFunction can not work with new internal data structure RowData", "pr_createdAt": "2020-06-11T07:32:41Z", "pr_url": "https://github.com/apache/flink/pull/12594", "timeline": [{"oid": "5be824fed4684ac3078b929bb7e5eecb7c976ce6", "url": "https://github.com/apache/flink/commit/5be824fed4684ac3078b929bb7e5eecb7c976ce6", "message": "[FLINK-18072][hbase] HBaseLookupFunction can not work with new internal data structure RowData", "committedDate": "2020-06-11T07:22:13Z", "type": "commit"}, {"oid": "0341f1b2975e50cae4afc99173f0a1b7a27ed870", "url": "https://github.com/apache/flink/commit/0341f1b2975e50cae4afc99173f0a1b7a27ed870", "message": "minor", "committedDate": "2020-06-11T13:09:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI2MzU2Mg==", "url": "https://github.com/apache/flink/pull/12594#discussion_r439263562", "bodyText": "Do not use HBaseReadWriteHelper. It uses legacy type. You can add a new method createGet in HbaseSerDe.", "author": "wuchong", "createdAt": "2020-06-12T07:50:46Z", "path": "flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.hbase.source;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.connector.hbase.util.HBaseConfigurationUtil;\n+import org.apache.flink.connector.hbase.util.HBaseReadWriteHelper;\n+import org.apache.flink.connector.hbase.util.HBaseSerde;\n+import org.apache.flink.connector.hbase.util.HBaseTableSchema;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.functions.FunctionContext;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.util.StringUtils;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.TableNotFoundException;\n+import org.apache.hadoop.hbase.client.Connection;\n+import org.apache.hadoop.hbase.client.ConnectionFactory;\n+import org.apache.hadoop.hbase.client.HTable;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+\n+/**\n+ * The HBaseRowDataLookupFunction is a standard user-defined table function, it can be used in tableAPI\n+ * and also useful for temporal table join plan in SQL. It looks up the result as {@link RowData}.\n+ */\n+@Internal\n+public class HBaseRowDataLookupFunction extends TableFunction<RowData> {\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(HBaseRowDataLookupFunction.class);\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final String hTableName;\n+\tprivate final byte[] serializedConfig;\n+\tprivate final HBaseTableSchema hbaseTableSchema;\n+\tprivate final String nullStringLiteral;\n+\n+\tprivate transient HBaseReadWriteHelper readHelper;\n+\tprivate transient Connection hConnection;\n+\tprivate transient HTable table;\n+\tprivate transient HBaseSerde serde;\n+\n+\tpublic HBaseRowDataLookupFunction(\n+\t\t\tConfiguration configuration,\n+\t\t\tString hTableName,\n+\t\t\tHBaseTableSchema hbaseTableSchema,\n+\t\t\tString nullStringLiteral) {\n+\t\tthis.serializedConfig = HBaseConfigurationUtil.serializeConfiguration(configuration);\n+\t\tthis.hTableName = hTableName;\n+\t\tthis.hbaseTableSchema = hbaseTableSchema;\n+\t\tthis.nullStringLiteral = nullStringLiteral;\n+\t}\n+\n+\t/**\n+\t * The invoke entry point of lookup function.\n+\t * @param rowKey the lookup key. Currently only support single rowkey.\n+\t */\n+\tpublic void eval(Object rowKey) throws IOException {\n+\t\t// fetch result\n+\t\tResult result = table.get(readHelper.createGet(rowKey));", "originalCommit": "0341f1b2975e50cae4afc99173f0a1b7a27ed870", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "34bcc247a9818e01531c1a118104ac935ae5ae02", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\nindex 486a9cc89b3..ba3977cd7c6 100644\n--- a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\n+++ b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\n\n@@ -21,7 +21,6 @@ package org.apache.flink.connector.hbase.source;\n import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.connector.hbase.util.HBaseConfigurationUtil;\n-import org.apache.flink.connector.hbase.util.HBaseReadWriteHelper;\n import org.apache.flink.connector.hbase.util.HBaseSerde;\n import org.apache.flink.connector.hbase.util.HBaseTableSchema;\n import org.apache.flink.table.data.RowData;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI2OTM3OQ==", "url": "https://github.com/apache/flink/pull/12594#discussion_r439269379", "bodyText": "Could you add a DECIMAL to the lookup table? It is the other error-prone type.", "author": "wuchong", "createdAt": "2020-06-12T08:02:59Z", "path": "flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java", "diffHunk": "@@ -558,71 +539,71 @@ public void testHBaseLookupTableSource() throws Exception {\n \t\t}\n \t\tStreamExecutionEnvironment streamEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tStreamTableEnvironment streamTableEnv = StreamTableEnvironment.create(streamEnv, streamSettings);\n+\n+\t\t// prepare dimension table data.\n+\t\tDataStream<Row> ds = streamEnv.fromCollection(testData1).returns(testTypeInfo1);\n+\t\tstreamTableEnv.createTemporaryView(\"testData\", ds);\n+\t\tString ddl = getDDLForTestTable3();\n+\t\tstreamTableEnv.executeSql(ddl);\n+\n+\t\tString query = \"INSERT INTO hbase \" +\n+\t\t\t\"SELECT rowkey, ROW(f1c1), ROW(f2c1, f2c2), ROW(f3c1, f3c2, f3c3), ROW(f4c1, f4c2, f4c3) \" +\n+\t\t\t\"FROM testData\";\n+\t\tTableEnvUtil.execInsertSqlAndWaitResult(streamTableEnv, query);\n \t\tStreamITCase.clear();\n \n \t\t// prepare a source table\n \t\tString srcTableName = \"src\";\n-\t\tDataStream<Row> ds = streamEnv.fromCollection(testData2).returns(testTypeInfo2);\n-\t\tTable in = streamTableEnv.fromDataStream(ds, $(\"a\"), $(\"b\"), $(\"c\"), $(\"proc\").proctime());\n+\t\tDataStream<Row> srcDs = streamEnv.fromCollection(testData2).returns(testTypeInfo2);\n+\t\tTable in = streamTableEnv.fromDataStream(srcDs, $(\"a\"), $(\"b\"), $(\"c\"), $(\"proc\").proctime());\n \t\tstreamTableEnv.registerTable(srcTableName, in);\n \n-\t\tif (isLegacyConnector) {\n-\t\t\tMap<String, String> tableProperties = hbaseTableProperties();\n-\t\t\tTableSource<?> source = TableFactoryService\n-\t\t\t\t.find(HBaseTableFactory.class, tableProperties)\n-\t\t\t\t.createTableSource(tableProperties);\n-\t\t\t((TableEnvironmentInternal) streamTableEnv).registerTableSourceInternal(\"hbaseLookup\", source);\n-\t\t} else {\n-\t\t\tstreamTableEnv.executeSql(\n-\t\t\t\t\t\"CREATE TABLE hbaseLookup (\" +\n-\t\t\t\t\t\" family1 ROW<col1 INT>,\" +\n-\t\t\t\t\t\" rk INT,\" +\n-\t\t\t\t\t\" family2 ROW<col1 STRING, col2 BIGINT>,\" +\n-\t\t\t\t\t\" family3 ROW<col1 DOUBLE, col2 BOOLEAN, col3 STRING>\" +\n-\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\" 'connector' = 'hbase-1.4',\" +\n-\t\t\t\t\t\" 'table-name' = '\" + TEST_TABLE_1 + \"',\" +\n-\t\t\t\t\t\" 'zookeeper.quorum' = '\" + getZookeeperQuorum() + \"'\" +\n-\t\t\t\t\t\")\");\n-\t\t}\n \t\t// perform a temporal table join query\n-\t\tString query = \"SELECT a,family1.col1, family3.col3 FROM src \" +\n-\t\t\t\"JOIN hbaseLookup FOR SYSTEM_TIME AS OF src.proc as h ON src.a = h.rk\";\n-\t\tTable result = streamTableEnv.sqlQuery(query);\n+\t\tString dimJoinQuery = \"SELECT\" +\n+\t\t\t\" a,\" +\n+\t\t\t\" b,\" +\n+\t\t\t\" family1.col1,\" +\n+\t\t\t\" family2.col1,\" +\n+\t\t\t\" family2.col2,\" +\n+\t\t\t\" family3.col1,\" +\n+\t\t\t\" family3.col2,\" +\n+\t\t\t\" family3.col3,\" +\n+\t\t\t\" family4.col1,\" +\n+\t\t\t\" family4.col2,\" +\n+\t\t\t\" family4.col3\" +\n+\t\t\t\" FROM src JOIN hbase FOR SYSTEM_TIME AS OF src.proc as h ON src.a = h.rowkey\";\n+\t\tIterator<Row> collected = streamTableEnv.executeSql(dimJoinQuery).collect();\n+\t\tList<String> result = Lists.newArrayList(collected).stream()\n+\t\t\t.map(Row::toString)\n+\t\t\t.sorted()\n+\t\t\t.collect(Collectors.toList());\n+\n+\t\t// check result, the time type in collected result is LOCAL_DATE_TIME, LOCAL_DATE, LOCAL_TIME\n+\t\tList<String> expected = new ArrayList<>();\n+\t\texpected.add(\"1,1,10,Hello-1,100,1.01,false,Welt-1,2019-08-18T19:00,2019-08-18,19:00\");\n+\t\texpected.add(\"2,2,20,Hello-2,200,2.02,true,Welt-2,2019-08-18T19:01,2019-08-18,19:01\");\n+\t\texpected.add(\"3,2,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,19:02\");\n+\t\texpected.add(\"3,3,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,19:02\");", "originalCommit": "0341f1b2975e50cae4afc99173f0a1b7a27ed870", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "34bcc247a9818e01531c1a118104ac935ae5ae02", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\nindex 561d46ce62d..bdea88ee402 100644\n--- a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n+++ b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n\n@@ -537,58 +474,90 @@ public class HBaseConnectorITCase extends HBaseTestBase {\n \t\t\t// lookup table source is only supported in blink planner, skip for old planner\n \t\t\treturn;\n \t\t}\n-\t\tStreamExecutionEnvironment streamEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n-\t\tStreamTableEnvironment streamTableEnv = StreamTableEnvironment.create(streamEnv, streamSettings);\n+\t\t// only test TIMESTAMP/DATE/TIME/DECIMAL for new connector(using blink-planner), because new connector encodes\n+\t\t// DATE/TIME to int, the old one encodes to long, and DECIMAL with precision works well in new connector.\n+\t\tfinal boolean testTimeAndDecimalTypes = !isLegacyConnector;\n+\t\tString timeAndDecimalFields = testTimeAndDecimalTypes ?\n+\t\t\t\", h.family4.col1, h.family4.col2, h.family4.col3, h.family4.col4 \" : \"\";\n \n-\t\t// prepare dimension table data.\n-\t\tDataStream<Row> ds = streamEnv.fromCollection(testData1).returns(testTypeInfo1);\n-\t\tstreamTableEnv.createTemporaryView(\"testData\", ds);\n-\t\tString ddl = getDDLForTestTable3();\n-\t\tstreamTableEnv.executeSql(ddl);\n+\t\tStreamExecutionEnvironment execEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(execEnv, streamSettings);\n \n-\t\tString query = \"INSERT INTO hbase \" +\n-\t\t\t\"SELECT rowkey, ROW(f1c1), ROW(f2c1, f2c2), ROW(f3c1, f3c2, f3c3), ROW(f4c1, f4c2, f4c3) \" +\n-\t\t\t\"FROM testData\";\n-\t\tTableEnvUtil.execInsertSqlAndWaitResult(streamTableEnv, query);\n-\t\tStreamITCase.clear();\n+\t\tif (isLegacyConnector) {\n+\t\t\tHBaseTableSource hbaseTable = new HBaseTableSource(getConf(), TEST_TABLE_1);\n+\t\t\thbaseTable.addColumn(FAMILY1, F1COL1, Integer.class);\n+\t\t\thbaseTable.addColumn(FAMILY2, F2COL1, String.class);\n+\t\t\thbaseTable.addColumn(FAMILY2, F2COL2, Long.class);\n+\t\t\thbaseTable.addColumn(FAMILY3, F3COL1, Double.class);\n+\t\t\thbaseTable.addColumn(FAMILY3, F3COL2, Boolean.class);\n+\t\t\thbaseTable.addColumn(FAMILY3, F3COL3, String.class);\n+\t\t\thbaseTable.setRowKey(ROW_KEY, Integer.class);\n+\t\t\t((TableEnvironmentInternal) tEnv).registerTableSourceInternal(TEST_TABLE_1, hbaseTable);\n+\t\t} else {\n+\t\t\ttEnv.executeSql(\n+\t\t\t\t\"CREATE TABLE \" + TEST_TABLE_1 + \" (\" +\n+\t\t\t\t\t\" family1 ROW<col1 INT>,\" +\n+\t\t\t\t\t\" family2 ROW<col1 STRING, col2 BIGINT>,\" +\n+\t\t\t\t\t\" family3 ROW<col1 DOUBLE, col2 BOOLEAN, col3 STRING>,\" +\n+\t\t\t\t\t\" rowkey INT,\" +\n+\t\t\t\t\t\" family4 ROW<col1 TIMESTAMP(3), col2 DATE, col3 TIME(3), col4 DECIMAL(12, 4)>,\" +\n+\t\t\t\t\t\" PRIMARY KEY (rowkey) NOT ENFORCED\" +\n+\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\" 'connector' = 'hbase-1.4',\" +\n+\t\t\t\t\t\" 'table-name' = '\" + TEST_TABLE_1 + \"',\" +\n+\t\t\t\t\t\" 'zookeeper.quorum' = '\" + getZookeeperQuorum() + \"'\" +\n+\t\t\t\t\t\")\");\n+\t\t}\n \n \t\t// prepare a source table\n \t\tString srcTableName = \"src\";\n-\t\tDataStream<Row> srcDs = streamEnv.fromCollection(testData2).returns(testTypeInfo2);\n-\t\tTable in = streamTableEnv.fromDataStream(srcDs, $(\"a\"), $(\"b\"), $(\"c\"), $(\"proc\").proctime());\n-\t\tstreamTableEnv.registerTable(srcTableName, in);\n+\t\tDataStream<Row> srcDs = execEnv.fromCollection(testData2).returns(testTypeInfo2);\n+\t\tTable in = tEnv.fromDataStream(srcDs, $(\"a\"), $(\"b\"), $(\"c\"), $(\"proc\").proctime());\n+\t\ttEnv.registerTable(srcTableName, in);\n \n \t\t// perform a temporal table join query\n \t\tString dimJoinQuery = \"SELECT\" +\n \t\t\t\" a,\" +\n \t\t\t\" b,\" +\n-\t\t\t\" family1.col1,\" +\n-\t\t\t\" family2.col1,\" +\n-\t\t\t\" family2.col2,\" +\n-\t\t\t\" family3.col1,\" +\n-\t\t\t\" family3.col2,\" +\n-\t\t\t\" family3.col3,\" +\n-\t\t\t\" family4.col1,\" +\n-\t\t\t\" family4.col2,\" +\n-\t\t\t\" family4.col3\" +\n-\t\t\t\" FROM src JOIN hbase FOR SYSTEM_TIME AS OF src.proc as h ON src.a = h.rowkey\";\n-\t\tIterator<Row> collected = streamTableEnv.executeSql(dimJoinQuery).collect();\n+\t\t\t\" h.family1.col1,\" +\n+\t\t\t\" h.family2.col1,\" +\n+\t\t\t\" h.family2.col2,\" +\n+\t\t\t\" h.family3.col1,\" +\n+\t\t\t\" h.family3.col2,\" +\n+\t\t\t\" h.family3.col3\" +\n+\t\t\ttimeAndDecimalFields +\n+\t\t\t\" FROM src JOIN \" + TEST_TABLE_1 + \" FOR SYSTEM_TIME AS OF src.proc as h ON src.a = h.rowkey\";\n+\t\tIterator<Row> collected = tEnv.executeSql(dimJoinQuery).collect();\n \t\tList<String> result = Lists.newArrayList(collected).stream()\n \t\t\t.map(Row::toString)\n \t\t\t.sorted()\n \t\t\t.collect(Collectors.toList());\n \n-\t\t// check result, the time type in collected result is LOCAL_DATE_TIME, LOCAL_DATE, LOCAL_TIME\n \t\tList<String> expected = new ArrayList<>();\n-\t\texpected.add(\"1,1,10,Hello-1,100,1.01,false,Welt-1,2019-08-18T19:00,2019-08-18,19:00\");\n-\t\texpected.add(\"2,2,20,Hello-2,200,2.02,true,Welt-2,2019-08-18T19:01,2019-08-18,19:01\");\n-\t\texpected.add(\"3,2,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,19:02\");\n-\t\texpected.add(\"3,3,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,19:02\");\n+\t\tRecordExtractor extractor = record -> {\n+\t\t\tString[] elements = record.split(\",\");\n+\t\t\tList<String> res = new ArrayList<>();\n+\t\t\tfor (int i = 0; i < elements.length; i++) {\n+\t\t\t\t// skip TIMESTAMP/DATE/TIME/DECIMAL fields\n+\t\t\t\tif (!testTimeAndDecimalTypes && i >= 8 && i <= 11) {\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tres.add(elements[i]);\n+\t\t\t}\n+\t\t\treturn res.stream().collect(Collectors.joining(\",\"));\n+\t\t};\n+\t\texpected.add(extractor.extract(\"1,1,10,Hello-1,100,1.01,false,Welt-1,2019-08-18T19:00,2019-08-18,\" +\n+\t\t\t\"19:00,12345678.0001\"));\n+\t\texpected.add(extractor.extract(\"2,2,20,Hello-2,200,2.02,true,Welt-2,2019-08-18T19:01,2019-08-18,\" +\n+\t\t\t\"19:01,12345678.0002\"));\n+\t\texpected.add(extractor.extract(\"3,2,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,\" +\n+\t\t\t\"19:02,12345678.0003\"));\n+\t\texpected.add(extractor.extract(\"3,3,30,Hello-3,300,3.03,false,Welt-3,2019-08-18T19:02,2019-08-18,\" +\n+\t\t\t\"19:02,12345678.0003\"));\n \n \t\tassertEquals(expected, result);\n \t}\n \n-\n \t// -------------------------------------------------------------------------------------\n \t// HBase lookup source tests\n \t// -------------------------------------------------------------------------------------\n"}}, {"oid": "34bcc247a9818e01531c1a118104ac935ae5ae02", "url": "https://github.com/apache/flink/commit/34bcc247a9818e01531c1a118104ac935ae5ae02", "message": "address comments and timestamp/time/date/decimal test in ITCase", "committedDate": "2020-06-15T12:52:44Z", "type": "commit"}, {"oid": "b6e4be8ec670abd7490d4077b162451cbff47902", "url": "https://github.com/apache/flink/commit/b6e4be8ec670abd7490d4077b162451cbff47902", "message": "format", "committedDate": "2020-06-15T14:27:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI2Mjg2NA==", "url": "https://github.com/apache/flink/pull/12594#discussion_r440262864", "bodyText": "The returned Get may be null.", "author": "wuchong", "createdAt": "2020-06-15T15:32:30Z", "path": "flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java", "diffHunk": "@@ -79,7 +77,7 @@ public HBaseRowDataLookupFunction(\n \t */\n \tpublic void eval(Object rowKey) throws IOException {\n \t\t// fetch result\n-\t\tResult result = table.get(readHelper.createGet(rowKey));\n+\t\tResult result = table.get(serde.createGet(rowKey));", "originalCommit": "34bcc247a9818e01531c1a118104ac935ae5ae02", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a6358e3178bb96500b37a7f0e209845cd4822622", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\nindex ba3977cd7c6..6a36fa3c3bd 100644\n--- a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\n+++ b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/source/HBaseRowDataLookupFunction.java\n\n@@ -77,10 +78,13 @@ public class HBaseRowDataLookupFunction extends TableFunction<RowData> {\n \t */\n \tpublic void eval(Object rowKey) throws IOException {\n \t\t// fetch result\n-\t\tResult result = table.get(serde.createGet(rowKey));\n-\t\tif (!result.isEmpty()) {\n-\t\t\t// parse and collect\n-\t\t\tcollect(serde.convertToRow(result));\n+\t\tGet get = serde.createGet(rowKey);\n+\t\tif (get != null) {\n+\t\t\tResult result = table.get(get);\n+\t\t\tif (!result.isEmpty()) {\n+\t\t\t\t// parse and collect\n+\t\t\t\tcollect(serde.convertToRow(result));\n+\t\t\t}\n \t\t}\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY4NDM3NQ==", "url": "https://github.com/apache/flink/pull/12594#discussion_r440684375", "bodyText": "We can reuse the GenericRowData.", "author": "wuchong", "createdAt": "2020-06-16T08:40:32Z", "path": "flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/util/HBaseSerde.java", "diffHunk": "@@ -190,6 +191,30 @@ public Scan createScan() {\n \t\treturn scan;\n \t}\n \n+\t/**\n+\t * Returns an instance of Get that retrieves the matches records from the HBase table.\n+\t *\n+\t * @return The appropriate instance of Get for this use case.\n+\t */\n+\tpublic Get createGet(Object rowKey) {\n+\t\tcheckArgument(keyEncoder != null, \"row key is not set.\");\n+\t\tGenericRowData rowData = new GenericRowData(1);", "originalCommit": "b6e4be8ec670abd7490d4077b162451cbff47902", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a6358e3178bb96500b37a7f0e209845cd4822622", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/util/HBaseSerde.java b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/util/HBaseSerde.java\nindex 9ffb806eda5..b848f508b63 100644\n--- a/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/util/HBaseSerde.java\n+++ b/flink-connectors/flink-connector-hbase/src/main/java/org/apache/flink/connector/hbase/util/HBaseSerde.java\n\n@@ -198,9 +200,8 @@ public class HBaseSerde {\n \t */\n \tpublic Get createGet(Object rowKey) {\n \t\tcheckArgument(keyEncoder != null, \"row key is not set.\");\n-\t\tGenericRowData rowData = new GenericRowData(1);\n-\t\trowData.setField(0, rowKey);\n-\t\tbyte[] rowkey = keyEncoder.encode(rowData, 0);\n+\t\trowWithRowKey.setField(0, rowKey);\n+\t\tbyte[] rowkey = keyEncoder.encode(rowWithRowKey, 0);\n \t\tif (rowkey.length == 0) {\n \t\t\t// drop dirty records, rowkey shouldn't be zero length\n \t\t\treturn null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY5ODY4OQ==", "url": "https://github.com/apache/flink/pull/12594#discussion_r440698689", "bodyText": "Can we also migrate this to use DDL?", "author": "wuchong", "createdAt": "2020-06-16T09:02:40Z", "path": "flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java", "diffHunk": "@@ -377,57 +344,28 @@ public void testTableSink() throws Exception {\n \t\t\tTableSink tableSink = TableFactoryService\n \t\t\t\t.find(HBaseTableFactory.class, descriptorProperties.asMap())\n \t\t\t\t.createTableSink(descriptorProperties.asMap());\n-\t\t\t((TableEnvironmentInternal) tEnv).registerTableSinkInternal(\"hbase\", tableSink);\n+\t\t\t((TableEnvironmentInternal) tEnv).registerTableSinkInternal(TEST_TABLE_2, tableSink);", "originalCommit": "b6e4be8ec670abd7490d4077b162451cbff47902", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a6358e3178bb96500b37a7f0e209845cd4822622", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\nindex 2941db5ed99..278f851ec94 100644\n--- a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n+++ b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n\n@@ -321,34 +313,8 @@ public class HBaseConnectorITCase extends HBaseTestBase {\n \t\tString table1DDL = createHBaseTableDDL(TEST_TABLE_1, false);\n \t\ttEnv.executeSql(table1DDL);\n \n-\t\tif (isLegacyConnector) {\n-\t\t\tHBaseTableSchema schema = new HBaseTableSchema();\n-\t\t\tschema.setRowKey(ROW_KEY, Integer.class);\n-\t\t\tschema.addColumn(FAMILY1, F1COL1, Integer.class);\n-\t\t\tschema.addColumn(FAMILY2, F2COL1, String.class);\n-\t\t\tschema.addColumn(FAMILY2, F2COL2, Long.class);\n-\t\t\tschema.addColumn(FAMILY3, F3COL1, Double.class);\n-\t\t\tschema.addColumn(FAMILY3, F3COL2, Boolean.class);\n-\t\t\tschema.addColumn(FAMILY3, F3COL3, String.class);\n-\n-\t\t\tMap<String, String> tableProperties = new HashMap<>();\n-\t\t\ttableProperties.put(\"connector.type\", \"hbase\");\n-\t\t\ttableProperties.put(\"connector.version\", \"1.4.3\");\n-\t\t\ttableProperties.put(\"connector.property-version\", \"1\");\n-\t\t\ttableProperties.put(\"connector.table-name\", TEST_TABLE_2);\n-\t\t\ttableProperties.put(\"connector.zookeeper.quorum\", getZookeeperQuorum());\n-\t\t\ttableProperties.put(\"connector.zookeeper.znode.parent\", \"/hbase\");\n-\t\t\tDescriptorProperties descriptorProperties = new DescriptorProperties(true);\n-\t\t\tdescriptorProperties.putTableSchema(SCHEMA, schema.convertsToTableSchema());\n-\t\t\tdescriptorProperties.putProperties(tableProperties);\n-\t\t\tTableSink tableSink = TableFactoryService\n-\t\t\t\t.find(HBaseTableFactory.class, descriptorProperties.asMap())\n-\t\t\t\t.createTableSink(descriptorProperties.asMap());\n-\t\t\t((TableEnvironmentInternal) tEnv).registerTableSinkInternal(TEST_TABLE_2, tableSink);\n-\t\t} else {\n-\t\t\tString table2DDL = createHBaseTableDDL(TEST_TABLE_2, false);\n-\t\t\ttEnv.executeSql(table2DDL);\n-\t\t}\n+\t\tString table2DDL = createHBaseTableDDL(TEST_TABLE_2, false);\n+\t\ttEnv.executeSql(table2DDL);\n \n \t\tString query = \"INSERT INTO \" + TEST_TABLE_2 + \" SELECT\" +\n \t\t\t\" rowkey,\" +\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDcwNDA5OA==", "url": "https://github.com/apache/flink/pull/12594#discussion_r440704098", "bodyText": "This test code is really hard to maintain and read. I would suggest only test for blink planner and new connector for simplification.", "author": "wuchong", "createdAt": "2020-06-16T09:11:34Z", "path": "flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java", "diffHunk": "@@ -455,99 +392,82 @@ public void testTableSink() throws Exception {\n \n \t@Test\n \tpublic void testTableSourceSinkWithDDL() throws Exception {\n+\t\t// only test TIMESTAMP/DATE/TIME/DECIMAL for new connector(using blink-planner), because new connector encodes\n+\t\t// DATE/TIME to int, the old one encodes to long, and DECIMAL with precision works well in new connector.\n+\t\tfinal boolean testTimeAndDecimalTypes = BLINK_PLANNER.equals(planner) && !isLegacyConnector;", "originalCommit": "b6e4be8ec670abd7490d4077b162451cbff47902", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a6358e3178bb96500b37a7f0e209845cd4822622", "chunk": "diff --git a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\nindex 2941db5ed99..278f851ec94 100644\n--- a/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n+++ b/flink-connectors/flink-connector-hbase/src/test/java/org/apache/flink/connector/hbase/HBaseConnectorITCase.java\n\n@@ -392,30 +357,29 @@ public class HBaseConnectorITCase extends HBaseTestBase {\n \n \t@Test\n \tpublic void testTableSourceSinkWithDDL() throws Exception {\n-\t\t// only test TIMESTAMP/DATE/TIME/DECIMAL for new connector(using blink-planner), because new connector encodes\n-\t\t// DATE/TIME to int, the old one encodes to long, and DECIMAL with precision works well in new connector.\n-\t\tfinal boolean testTimeAndDecimalTypes = BLINK_PLANNER.equals(planner) && !isLegacyConnector;\n-\t\tString timeAndDecimalFields = testTimeAndDecimalTypes ?\n-\t\t\t\", h.family4.col1, h.family4.col2, h.family4.col3, h.family4.col4 \" : \"\";\n+\t\tif (OLD_PLANNER.equals(planner) || isLegacyConnector) {\n+\t\t\t// only test for blink planner and new connector, because types TIMESTAMP/DATE/TIME/DECIMAL works well in new\n+\t\t\t// connector(using blink-planner), but has some precision problem in old planner or legacy connector.\n+\t\t\treturn;\n+\t\t}\n \n \t\tStreamExecutionEnvironment execEnv = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(execEnv, streamSettings);\n \n \t\t// regiter HBase table testTable1 which contains test data\n-\t\tString table1DDL = createHBaseTableDDL(TEST_TABLE_1, testTimeAndDecimalTypes);\n+\t\tString table1DDL = createHBaseTableDDL(TEST_TABLE_1, true);\n \t\ttEnv.executeSql(table1DDL);\n \n \t\t// register HBase table which is empty\n-\t\tString table3DDL = createHBaseTableDDL(TEST_TABLE_3, testTimeAndDecimalTypes);\n+\t\tString table3DDL = createHBaseTableDDL(TEST_TABLE_3, true);\n \t\ttEnv.executeSql(table3DDL);\n \n-\t\tString family4 = testTimeAndDecimalTypes ? \", family4 \" : \"\";\n \t\tString insertStatement = \"INSERT INTO \" + TEST_TABLE_3 +\n \t\t\t\" SELECT rowkey,\" +\n \t\t\t\" family1,\" +\n \t\t\t\" family2,\" +\n-\t\t\t\" family3\" +\n-\t\t\tfamily4 +\n+\t\t\t\" family3,\" +\n+\t\t\t\" family4\" +\n \t\t\t\" from \" + TEST_TABLE_1;\n \t\t// wait to finish\n \t\tTableEnvUtil.execInsertSqlAndWaitResult(tEnv, insertStatement);\n"}}, {"oid": "a6358e3178bb96500b37a7f0e209845cd4822622", "url": "https://github.com/apache/flink/commit/a6358e3178bb96500b37a7f0e209845cd4822622", "message": "address comments", "committedDate": "2020-06-16T17:07:30Z", "type": "commit"}, {"oid": "79249151cc48e2711a224e5ca943c41ae434ce19", "url": "https://github.com/apache/flink/commit/79249151cc48e2711a224e5ca943c41ae434ce19", "message": "minor", "committedDate": "2020-06-17T02:37:44Z", "type": "commit"}]}