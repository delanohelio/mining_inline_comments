{"pr_number": 13834, "pr_title": "[FLINK-19872][csv] Fix CSV format is unable to parse millisecond for TIME type", "pr_createdAt": "2020-10-29T06:42:52Z", "pr_url": "https://github.com/apache/flink/pull/13834", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0Mjk4MQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514842981", "bodyText": "final int precision = timeType.getPrecision();\n\t\tif (precision > 3) {\n\t\t\tthrow new IllegalArgumentException(\"CSV format does not support TIME type \" +\n\t\t\t\t\"with precision: \" + precision + \", it only supports precision 0 ~ 3.\");\n\t\t}\n\t\t// get number of milliseconds of the day\n\t\treturn jsonNode -> {\n\t\t\tLocalTime localTime = LocalTime.parse(jsonNode.asText());\n\t\t\tif (precision == 0) {\n\t\t\t\treturn localTime.toSecondOfDay() * 1000L;\n\t\t\t} else {\n\t\t\t\treturn (int) (localTime.toNanoOfDay() / 1000_000L);\n\t\t\t}\n\t\t};\nThrows exception in compile phase instead during runtime.\nBesides, we can also support precision 0~3.", "author": "wuchong", "createdAt": "2020-10-30T04:36:58Z", "path": "flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java", "diffHunk": "@@ -221,12 +221,22 @@ private int convertToDate(JsonNode jsonNode) {\n \t\treturn (int) Date.valueOf(jsonNode.asText()).toLocalDate().toEpochDay();\n \t}\n \n-\tprivate int convertToTime(JsonNode jsonNode) {\n+\tprivate CsvToRowDataConverter convertToTime(TimeType timeType) {\n+\t\tfinal int precision = timeType.getPrecision();\n \t\t// csv currently is using Time.valueOf() to parse time string\n-\t\tLocalTime localTime = Time.valueOf(jsonNode.asText()).toLocalTime();\n \t\t// TODO: FLINK-17525 support millisecond and nanosecond\n \t\t// get number of milliseconds of the day\n-\t\treturn localTime.toSecondOfDay() * 1000;\n+\t\treturn jsonNode -> {\n+\t\t\tLocalTime localTime = LocalTime.parse(jsonNode.asText());\n+\t\t\tif (precision == 3) {\n+\t\t\t\treturn localTime.toNanoOfDay() / 1000_000L;\n+\t\t\t} else if (precision == 0) {\n+\t\t\t\treturn localTime.toSecondOfDay() * 1000L;\n+\t\t\t} else {\n+\t\t\t\tthrow new IllegalArgumentException(\"Csv does not support TIME type \" +\n+\t\t\t\t\t\"with precision: \" + precision + \", it only supports precision 0 or 3.\");\n+\t\t\t}\n+\t\t};", "originalCommit": "3792d96b470ee584cd60265925bf578d65fffa64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg4NTIyNw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514885227", "bodyText": "I will optimize.", "author": "pyscala", "createdAt": "2020-10-30T05:52:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0Mjk4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\nindex c7921892199..8ff2936c6c6 100644\n--- a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\n+++ b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\n\n@@ -226,16 +226,22 @@ public class CsvToRowDataConverters implements Serializable {\n \t\t// csv currently is using Time.valueOf() to parse time string\n \t\t// TODO: FLINK-17525 support millisecond and nanosecond\n \t\t// get number of milliseconds of the day\n+\t\tif (precision > 3) {\n+\t\t\tthrow new IllegalArgumentException(\"Csv does not support TIME type \" +\n+\t\t\t\t\"with precision: \" + precision + \", it only supports precision 0 ~ 3.\");\n+\t\t}\n \t\treturn jsonNode -> {\n \t\t\tLocalTime localTime = LocalTime.parse(jsonNode.asText());\n-\t\t\tif (precision == 3) {\n-\t\t\t\treturn localTime.toNanoOfDay() / 1000_000L;\n+\t\t\tint mills = (int) (localTime.toNanoOfDay() / 1000_000L);\n+\t\t\t// this is for rounding off values out of precision\n+\t\t\tif (precision == 2) {\n+\t\t\t\tmills = mills / 10 * 10;\n+\t\t\t} else if (precision == 1) {\n+\t\t\t\tmills = mills / 100 * 100;\n \t\t\t} else if (precision == 0) {\n-\t\t\t\treturn localTime.toSecondOfDay() * 1000L;\n-\t\t\t} else {\n-\t\t\t\tthrow new IllegalArgumentException(\"Csv does not support TIME type \" +\n-\t\t\t\t\t\"with precision: \" + precision + \", it only supports precision 0 or 3.\");\n+\t\t\t\tmills = mills / 1000 * 1000;\n \t\t\t}\n+\t\t\treturn mills;\n \t\t};\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0NDAyNw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514844027", "bodyText": "We should still use getInt, because we always use int to represent number of milliseconds of the day in Flink SQL internally. See Javadoc of RowData.", "author": "wuchong", "createdAt": "2020-10-30T04:38:14Z", "path": "flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java", "diffHunk": "@@ -128,7 +128,7 @@ private static RowFieldConverter createRowFieldConverter(LogicalType fieldType)\n \t\t\tcase DATE:\n \t\t\t\treturn (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n \t\t\tcase TIME_WITHOUT_TIME_ZONE:\n-\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n+\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getLong(pos), container);", "originalCommit": "3792d96b470ee584cd60265925bf578d65fffa64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg5MTIzMA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514891230", "bodyText": "Will overflow when supporting nanosecond precision in the future", "author": "pyscala", "createdAt": "2020-10-30T06:15:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0NDAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkwMTIxNA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514901214", "bodyText": "That's why we don't support precision > 3 for now.\nWhen the planner supports precision > 3 in the future, we can update csv format to use the higer precision data structure (maybe long or otheres).", "author": "wuchong", "createdAt": "2020-10-30T06:51:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0NDAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkxMDI4OA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514910288", "bodyText": "get it", "author": "pyscala", "createdAt": "2020-10-30T07:20:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0NDAyNw=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java\nindex 3994962bab6..dfcf3780fc7 100644\n--- a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java\n+++ b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java\n\n@@ -128,7 +128,7 @@ public class RowDataToCsvConverters implements Serializable {\n \t\t\tcase DATE:\n \t\t\t\treturn (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n \t\t\tcase TIME_WITHOUT_TIME_ZONE:\n-\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getLong(pos), container);\n+\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n \t\t\tcase TIMESTAMP_WITH_TIME_ZONE:\n \t\t\t\tfinal int zonedTimestampPrecision = ((LocalZonedTimestampType) fieldType).getPrecision();\n \t\t\t\treturn (csvMapper, container, row, pos) ->\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514849074", "bodyText": "Why not reuse the testNullableField method?", "author": "wuchong", "createdAt": "2020-10-30T04:44:06Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -109,6 +109,54 @@ public void testSerializeDeserialize() throws Exception {\n \t\t\tnew byte[] {107, 3, 11});\n \t}\n \n+\t@Test\n+\tpublic void testSerializeDeserializeForTime() throws Exception {\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.232\",\n+\t\t\t\"12:12:12.232\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),", "originalCommit": "3792d96b470ee584cd60265925bf578d65fffa64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg4NjcwNw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514886707", "bodyText": "For example, the input is \"12:12:12.232\", but the precision is 2, then the result should be \"12:12:12.23\". The existing test named testNullableField  must be modified to meet the needs of this test. But the change affects other test cases. So i add a new test methed named testFieldForTime.", "author": "pyscala", "createdAt": "2020-10-30T05:58:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkwMDQ2Ng==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514900466", "bodyText": "For such case, I think you can use the test method only validate the deserialization.\ntestField(\n\t\t\tDataType fieldType,\n\t\t\tString csvValue,\n\t\t\tObject value,\n\t\t\tConsumer<CsvRowDataDeserializationSchema.Builder> deserializationConfig,\n\t\t\tString fieldDelimiter)", "author": "wuchong", "createdAt": "2020-10-30T06:48:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk0MTY2Ng==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514941666", "bodyText": "Sorry for my carelessness, I will optimize it.", "author": "pyscala", "createdAt": "2020-10-30T08:36:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk4MzgxMA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514983810", "bodyText": "@wuchong\nthe following code\nRow actualRow = (Row) DataFormatConverters.getConverterForDataType(dataType).toExternal(deserializedRow); \nin methed\ntestField( DataType fieldType, String csvValue, Object value, Consumer<CsvRowDataDeserializationSchema.Builder> deserializationConfig, String fieldDelimiter)\nwill change TIME(n) (0<=n<=3) to  TIME(0) .Then the test will fail.\nI still use testFieldForTime().", "author": "pyscala", "createdAt": "2020-10-30T09:56:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk5Njg2NQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514996865", "bodyText": "This works in my environment:\n\t\ttestField(\n\t\t\tTIME(3),\n\t\t\t\"12:12:12.232421\",\n\t\t\tLocalTime.parse(\"12:12:12.232\"),\n\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n\t\t\t\",\");", "author": "wuchong", "createdAt": "2020-10-30T10:20:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTcxNDIxNA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r515714214", "bodyText": "fix it", "author": "pyscala", "createdAt": "2020-11-02T02:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTA3NA=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 954c54ba7d3..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -107,54 +108,22 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tBYTES(),\n \t\t\t\"awML\",\n \t\t\tnew byte[] {107, 3, 11});\n-\t}\n-\n-\t@Test\n-\tpublic void testSerializeDeserializeForTime() throws Exception {\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.232\",\n-\t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\ttestNullableField(\n \t\t\tTIME(3),\n-\t\t\t\"12:12:12.232421\",\n \t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.23\",\n+\t\t\tLocalTime.parse(\"12:12:12.232\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(2),\n \t\t\t\"12:12:12.23\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\t\tLocalTime.parse(\"12:12:12.23\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(1),\n+\t\t\t\"12:12:12.2\",\n+\t\t\tLocalTime.parse(\"12:12:12.2\"));\n+\t\ttestNullableField(\n \t\t\tTIME(0),\n-\t\t\t\"12:12:12.23\",\n \t\t\t\"12:12:12\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\n-\t\tint precision = 2;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 or 3.\", precision);\n-\t\tString actualMessage = null;\n-\t\ttry {\n-\t\t\ttestFieldForTime(\n-\t\t\t\tTIME(precision),\n-\t\t\t\t\"12:12:12.23\",\n-\t\t\t\t\"12:12:12\",\n-\t\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\t\",\");\n-\t\t} catch (Exception e) {\n-\t\t\tactualMessage = e.getCause().getMessage();\n-\t\t}\n-\t\tassertEquals(expectedMessage, actualMessage);\n+\t\t\tLocalTime.parse(\"12:12:12\"));\n \t}\n \n \t@Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTY4OA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514849688", "bodyText": "Add more tests for TIME(1), TIME(2).", "author": "wuchong", "createdAt": "2020-10-30T04:44:43Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -109,6 +109,54 @@ public void testSerializeDeserialize() throws Exception {\n \t\t\tnew byte[] {107, 3, 11});\n \t}\n \n+\t@Test\n+\tpublic void testSerializeDeserializeForTime() throws Exception {\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.232\",\n+\t\t\t\"12:12:12.232\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.232421\",\n+\t\t\t\"12:12:12.232\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.23\",\n+\t\t\t\"12:12:12.23\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(0),", "originalCommit": "3792d96b470ee584cd60265925bf578d65fffa64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg4Njc2Nw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514886767", "bodyText": "ok", "author": "pyscala", "createdAt": "2020-10-30T05:58:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg0OTY4OA=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 954c54ba7d3..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -107,54 +108,22 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tBYTES(),\n \t\t\t\"awML\",\n \t\t\tnew byte[] {107, 3, 11});\n-\t}\n-\n-\t@Test\n-\tpublic void testSerializeDeserializeForTime() throws Exception {\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.232\",\n-\t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\ttestNullableField(\n \t\t\tTIME(3),\n-\t\t\t\"12:12:12.232421\",\n \t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.23\",\n+\t\t\tLocalTime.parse(\"12:12:12.232\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(2),\n \t\t\t\"12:12:12.23\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\t\tLocalTime.parse(\"12:12:12.23\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(1),\n+\t\t\t\"12:12:12.2\",\n+\t\t\tLocalTime.parse(\"12:12:12.2\"));\n+\t\ttestNullableField(\n \t\t\tTIME(0),\n-\t\t\t\"12:12:12.23\",\n \t\t\t\"12:12:12\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\n-\t\tint precision = 2;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 or 3.\", precision);\n-\t\tString actualMessage = null;\n-\t\ttry {\n-\t\t\ttestFieldForTime(\n-\t\t\t\tTIME(precision),\n-\t\t\t\t\"12:12:12.23\",\n-\t\t\t\t\"12:12:12\",\n-\t\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\t\",\");\n-\t\t} catch (Exception e) {\n-\t\t\tactualMessage = e.getCause().getMessage();\n-\t\t}\n-\t\tassertEquals(expectedMessage, actualMessage);\n+\t\t\tLocalTime.parse(\"12:12:12\"));\n \t}\n \n \t@Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDg1MDYwMw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r514850603", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\",\");\n          \n          \n            \n            \t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\tactualMessage = e.getCause().getMessage();\n          \n          \n            \n            \t\t}\n          \n          \n            \n            \t\tassertEquals(expectedMessage, actualMessage);\n          \n          \n            \n            \t\t\t\t\",\");\n          \n          \n            \n            \t\t\t\tfail(\"Exception should be thrown.\");\n          \n          \n            \n            \t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\tassertEquals(expectedMessage, e.getCause().getMessage());\n          \n          \n            \n            \t\t}", "author": "wuchong", "createdAt": "2020-10-30T04:45:45Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -109,6 +109,54 @@ public void testSerializeDeserialize() throws Exception {\n \t\t\tnew byte[] {107, 3, 11});\n \t}\n \n+\t@Test\n+\tpublic void testSerializeDeserializeForTime() throws Exception {\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.232\",\n+\t\t\t\"12:12:12.232\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.232421\",\n+\t\t\t\"12:12:12.232\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(3),\n+\t\t\t\"12:12:12.23\",\n+\t\t\t\"12:12:12.23\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\t\ttestFieldForTime(\n+\t\t\tTIME(0),\n+\t\t\t\"12:12:12.23\",\n+\t\t\t\"12:12:12\",\n+\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\",\");\n+\n+\t\tint precision = 2;\n+\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 or 3.\", precision);\n+\t\tString actualMessage = null;\n+\t\ttry {\n+\t\t\ttestFieldForTime(\n+\t\t\t\tTIME(precision),\n+\t\t\t\t\"12:12:12.23\",\n+\t\t\t\t\"12:12:12\",\n+\t\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n+\t\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n+\t\t\t\t\",\");\n+\t\t} catch (Exception e) {\n+\t\t\tactualMessage = e.getCause().getMessage();\n+\t\t}\n+\t\tassertEquals(expectedMessage, actualMessage);", "originalCommit": "3792d96b470ee584cd60265925bf578d65fffa64", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 954c54ba7d3..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -107,54 +108,22 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tBYTES(),\n \t\t\t\"awML\",\n \t\t\tnew byte[] {107, 3, 11});\n-\t}\n-\n-\t@Test\n-\tpublic void testSerializeDeserializeForTime() throws Exception {\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.232\",\n-\t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\ttestNullableField(\n \t\t\tTIME(3),\n-\t\t\t\"12:12:12.232421\",\n \t\t\t\"12:12:12.232\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n-\t\t\tTIME(3),\n-\t\t\t\"12:12:12.23\",\n+\t\t\tLocalTime.parse(\"12:12:12.232\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(2),\n \t\t\t\"12:12:12.23\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\t\ttestFieldForTime(\n+\t\t\tLocalTime.parse(\"12:12:12.23\"));\n+\t\ttestNullableField(\n+\t\t\tTIME(1),\n+\t\t\t\"12:12:12.2\",\n+\t\t\tLocalTime.parse(\"12:12:12.2\"));\n+\t\ttestNullableField(\n \t\t\tTIME(0),\n-\t\t\t\"12:12:12.23\",\n \t\t\t\"12:12:12\",\n-\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\",\");\n-\n-\t\tint precision = 2;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 or 3.\", precision);\n-\t\tString actualMessage = null;\n-\t\ttry {\n-\t\t\ttestFieldForTime(\n-\t\t\t\tTIME(precision),\n-\t\t\t\t\"12:12:12.23\",\n-\t\t\t\t\"12:12:12\",\n-\t\t\t\t(deserSchema) -> deserSchema.setNullLiteral(\"null\"),\n-\t\t\t\t(serSchema) -> serSchema.setNullLiteral(\"null\"),\n-\t\t\t\t\",\");\n-\t\t} catch (Exception e) {\n-\t\t\tactualMessage = e.getCause().getMessage();\n-\t\t}\n-\t\tassertEquals(expectedMessage, actualMessage);\n+\t\t\tLocalTime.parse(\"12:12:12\"));\n \t}\n \n \t@Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2Mjk1MA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r519662950", "bodyText": "This is never used.", "author": "wuchong", "createdAt": "2020-11-09T09:26:41Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -320,6 +339,34 @@ private void testField(\n \t\tassertEquals(expectedCsv, new String(serializedRow));\n \t}\n \n+\tprivate void testFieldForTime(", "originalCommit": "dc0a2a29d0fba59d7b7769353bd4d91aa1307ecb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5Nzg1OQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521297859", "bodyText": "i will clean up", "author": "pyscala", "createdAt": "2020-11-11T11:37:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2Mjk1MA=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 86701a527a6..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -339,36 +342,8 @@ public class CsvRowDataSerDeSchemaTest {\n \t\tassertEquals(expectedCsv, new String(serializedRow));\n \t}\n \n-\tprivate void testFieldForTime(\n-\t\tDataType fieldType,\n-\t\tString csvValue,\n-\t\tString expectValue,\n-\t\tConsumer<CsvRowDataSerializationSchema.Builder> serializationConfig,\n-\t\tConsumer<CsvRowDataDeserializationSchema.Builder> deserializationConfig,\n-\t\tString fieldDelimiter) throws Exception {\n-\t\tRowType rowType = (RowType) ROW(\n-\t\t\tFIELD(\"f0\", STRING()),\n-\t\t\tFIELD(\"f1\", fieldType),\n-\t\t\tFIELD(\"f2\", STRING())\n-\t\t).getLogicalType();\n-\t\tString inputCsv = \"BEGIN\" + fieldDelimiter + csvValue + fieldDelimiter + \"END\\n\";\n-\t\tString expectedCsv = \"BEGIN\" + fieldDelimiter + expectValue + fieldDelimiter + \"END\\n\";\n-\n-\t\t// deserialization\n-\t\tCsvRowDataDeserializationSchema.Builder deserSchemaBuilder =\n-\t\t\tnew CsvRowDataDeserializationSchema.Builder(rowType, InternalTypeInfo.of(rowType));\n-\t\tdeserializationConfig.accept(deserSchemaBuilder);\n-\t\tRowData deserializedRow = deserialize(deserSchemaBuilder, inputCsv);\n-\n-\t\t// serialization\n-\t\tCsvRowDataSerializationSchema.Builder serSchemaBuilder = new CsvRowDataSerializationSchema.Builder(rowType);\n-\t\tserializationConfig.accept(serSchemaBuilder);\n-\t\tbyte[] serializedRow = serialize(serSchemaBuilder, deserializedRow);\n-\t\tassertEquals(expectedCsv, new String(serializedRow));\n-\t}\n-\n \t@SuppressWarnings(\"unchecked\")\n-\tprivate void testField(\n+\tprivate void testFieldDeserialization(\n \t\t\tDataType fieldType,\n \t\t\tString csvValue,\n \t\t\tObject value,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2MzMzMw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r519663333", "bodyText": "Why not hard code the exception message?", "author": "wuchong", "createdAt": "2020-11-09T09:27:15Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -150,6 +151,24 @@ public void testSerializeDeserializeCustomizedProperties() throws Exception {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n+\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\tint precision = 5;\n+\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 ~ 3.\", precision);", "originalCommit": "dc0a2a29d0fba59d7b7769353bd4d91aa1307ecb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5Nzk0MQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521297941", "bodyText": "fix it", "author": "pyscala", "createdAt": "2020-11-11T11:37:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2MzMzMw=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 86701a527a6..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -151,23 +167,25 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n-\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n \t\tint precision = 5;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 ~ 3.\", precision);\n \t\ttry {\n-\t\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\t\ttestFieldDeserialization(TIME(5), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\t\tfail();\n \t\t} catch (Exception e) {\n-\t\t\tassertEquals(expectedMessage, e.getMessage());\n+\t\t\tassertEquals(\n+\t\t\t\t\"Csv does not support TIME type with precision: 5, it only supports precision 0 ~ 3.\",\n+\t\t\t\te.getMessage());\n \t\t}\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2NjMxMw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r519666313", "bodyText": "Could you add a comment \"this is for rounding off values out of precision\"?", "author": "wuchong", "createdAt": "2020-11-09T09:31:40Z", "path": "flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java", "diffHunk": "@@ -221,12 +221,27 @@ private int convertToDate(JsonNode jsonNode) {\n \t\treturn (int) Date.valueOf(jsonNode.asText()).toLocalDate().toEpochDay();\n \t}\n \n-\tprivate int convertToTime(JsonNode jsonNode) {\n+\tprivate CsvToRowDataConverter convertToTime(TimeType timeType) {\n+\t\tfinal int precision = timeType.getPrecision();\n \t\t// csv currently is using Time.valueOf() to parse time string\n-\t\tLocalTime localTime = Time.valueOf(jsonNode.asText()).toLocalTime();\n \t\t// TODO: FLINK-17525 support millisecond and nanosecond\n \t\t// get number of milliseconds of the day\n-\t\treturn localTime.toSecondOfDay() * 1000;\n+\t\tif (precision > 3) {\n+\t\t\tthrow new IllegalArgumentException(\"Csv does not support TIME type \" +\n+\t\t\t\t\"with precision: \" + precision + \", it only supports precision 0 ~ 3.\");\n+\t\t}\n+\t\treturn jsonNode -> {\n+\t\t\tLocalTime localTime = LocalTime.parse(jsonNode.asText());\n+\t\t\tint mills = (int) (localTime.toNanoOfDay() / 1000_000L);\n+\t\t\tif (precision == 2) {\n+\t\t\t\tmills = mills / 10 * 10;", "originalCommit": "dc0a2a29d0fba59d7b7769353bd4d91aa1307ecb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5NTIxOA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521295218", "bodyText": "ok", "author": "pyscala", "createdAt": "2020-11-11T11:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2NjMxMw=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\nindex b543ae32aa0..8ff2936c6c6 100644\n--- a/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\n+++ b/flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/CsvToRowDataConverters.java\n\n@@ -233,6 +233,7 @@ public class CsvToRowDataConverters implements Serializable {\n \t\treturn jsonNode -> {\n \t\t\tLocalTime localTime = LocalTime.parse(jsonNode.asText());\n \t\t\tint mills = (int) (localTime.toNanoOfDay() / 1000_000L);\n+\t\t\t// this is for rounding off values out of precision\n \t\t\tif (precision == 2) {\n \t\t\t\tmills = mills / 10 * 10;\n \t\t\t} else if (precision == 1) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2NjkzMg==", "url": "https://github.com/apache/flink/pull/13834#discussion_r519666932", "bodyText": "This will not fail. Because it is not TIME(5).\nYou should add fail(); if you want to verify it should fail.", "author": "wuchong", "createdAt": "2020-11-09T09:32:44Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -150,6 +151,24 @@ public void testSerializeDeserializeCustomizedProperties() throws Exception {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n+\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\tint precision = 5;\n+\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 ~ 3.\", precision);\n+\t\ttry {\n+\t\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");", "originalCommit": "dc0a2a29d0fba59d7b7769353bd4d91aa1307ecb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5ODA4MA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521298080", "bodyText": "fix it", "author": "pyscala", "createdAt": "2020-11-11T11:37:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2NjkzMg=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 86701a527a6..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -151,23 +167,25 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n-\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n \t\tint precision = 5;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 ~ 3.\", precision);\n \t\ttry {\n-\t\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\t\ttestFieldDeserialization(TIME(5), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\t\tfail();\n \t\t} catch (Exception e) {\n-\t\t\tassertEquals(expectedMessage, e.getMessage());\n+\t\t\tassertEquals(\n+\t\t\t\t\"Csv does not support TIME type with precision: 5, it only supports precision 0 ~ 3.\",\n+\t\t\t\te.getMessage());\n \t\t}\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r519668695", "bodyText": "All of these only test the deserialization. We should also add tests for serialization. I think we can use testNullableField for this purpose.\nBesides, we can rename method testField(fieldType, csvValue, value, deserializationConfig, fieldDelimiter) to testFieldSerialization to be more specific.", "author": "wuchong", "createdAt": "2020-11-09T09:35:30Z", "path": "flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java", "diffHunk": "@@ -150,6 +151,24 @@ public void testSerializeDeserializeCustomizedProperties() throws Exception {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n+\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n+\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n+\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n+\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");", "originalCommit": "dc0a2a29d0fba59d7b7769353bd4d91aa1307ecb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTMwMjkyNQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521302925", "bodyText": "rename method  testField(fieldType, csvValue, value, deserializationConfig, fieldDelimiter) to testFieldSerialization ?  or testFieldDeserialization ?", "author": "pyscala", "createdAt": "2020-11-11T11:47:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTMxMTk2Mw==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521311963", "bodyText": "The reason for not using testNullableField  can be seen in our previous dialogue.", "author": "pyscala", "createdAt": "2020-11-11T12:05:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0MzM5MA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521343390", "bodyText": "Rename to testFieldDeserialization.", "author": "wuchong", "createdAt": "2020-11-11T13:03:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0MzgxNQ==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521343815", "bodyText": "We only use testNullableField to test conversion without precision loss.", "author": "wuchong", "createdAt": "2020-11-11T13:04:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc2OTgwNA==", "url": "https://github.com/apache/flink/pull/13834#discussion_r521769804", "bodyText": "done", "author": "pyscala", "createdAt": "2020-11-12T02:00:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTY2ODY5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "6dd7a167a257fe6379340600a53ab4262c35f62f", "chunk": "diff --git a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\nindex 86701a527a6..8051b3c4b8c 100644\n--- a/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n+++ b/flink-formats/flink-csv/src/test/java/org/apache/flink/formats/csv/CsvRowDataSerDeSchemaTest.java\n\n@@ -151,23 +167,25 @@ public class CsvRowDataSerDeSchemaTest {\n \t\t\tdeserConfig,\n \t\t\t\";\");\n \t\ttestField(STRING(), \"null\", \"null\", serConfig, deserConfig, \";\"); // string because null literal has not been set\n-\t\ttestField(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\") , deserConfig , \";\");\n-\t\ttestField(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\") , deserConfig , \";\");\n-\t\ttestField(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\") , deserConfig , \";\");\n-\t\ttestField(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n-\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.232342\", LocalTime.parse(\"12:12:12.232\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(3), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.23\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.232312\", LocalTime.parse(\"12:12:12.23\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(2), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12.2235\", LocalTime.parse(\"12:12:12.2\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(1), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\ttestFieldDeserialization(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n \t\tint precision = 5;\n-\t\tString expectedMessage = String.format(\"Csv does not support TIME type with precision: %d, it only supports precision 0 ~ 3.\", precision);\n \t\ttry {\n-\t\t\ttestField(TIME(0), \"12:12:12.45\", LocalTime.parse(\"12:12:12\") , deserConfig , \";\");\n+\t\t\ttestFieldDeserialization(TIME(5), \"12:12:12.45\", LocalTime.parse(\"12:12:12\"), deserConfig, \";\");\n+\t\t\tfail();\n \t\t} catch (Exception e) {\n-\t\t\tassertEquals(expectedMessage, e.getMessage());\n+\t\t\tassertEquals(\n+\t\t\t\t\"Csv does not support TIME type with precision: 5, it only supports precision 0 ~ 3.\",\n+\t\t\t\te.getMessage());\n \t\t}\n \t}\n \n"}}, {"oid": "6dd7a167a257fe6379340600a53ab4262c35f62f", "url": "https://github.com/apache/flink/commit/6dd7a167a257fe6379340600a53ab4262c35f62f", "message": "[FLINK-19872][csv] Fix CSV format is unable to parse millisecond for TIME type\n\nThis closes #13834", "committedDate": "2020-11-12T03:14:20Z", "type": "commit"}, {"oid": "6dd7a167a257fe6379340600a53ab4262c35f62f", "url": "https://github.com/apache/flink/commit/6dd7a167a257fe6379340600a53ab4262c35f62f", "message": "[FLINK-19872][csv] Fix CSV format is unable to parse millisecond for TIME type\n\nThis closes #13834", "committedDate": "2020-11-12T03:14:20Z", "type": "forcePushed"}]}