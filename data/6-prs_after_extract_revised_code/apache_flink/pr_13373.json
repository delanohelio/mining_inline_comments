{"pr_number": 13373, "pr_title": "[FLINK-18802] Upgrade avro to 1.10 ", "pr_createdAt": "2020-09-11T12:52:27Z", "pr_url": "https://github.com/apache/flink/pull/13373", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487027309", "bodyText": "Had to drop the logical types, because the BatchTableEnvironment fails if we have a java.time.Instant in the input DataSet. We extract BasicTypeInfo.INSTANT_TYPE_INFO for it, which is translated to TIMESTAMP_WITH_LOCAL_TIME_ZONE which fails in legacy planner.\nAfter the upgrade to avro 1.10 one of the fields of the User class is of type java.time.Instant, previously it was joda's DateTime.", "author": "dawidwys", "createdAt": "2020-09-11T12:58:31Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -58,7 +55,7 @@\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final User USER_1 = User.newBuilder()\n+\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()", "originalCommit": "df666257b536825e8cb4e3497349079e9a35c51e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NDE5OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487054199", "bodyText": "Thanks for the explanation.", "author": "twalthr", "createdAt": "2020-09-11T13:43:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1NTUzNA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487055534", "bodyText": "But it would still be nice to test all types for Avro but maybe to the new Blink planner. Could we add least have a separate commit for this class? Then we can revert the changes because after FLIP-136 this test should definitely work again, no? Or does it work already today?", "author": "twalthr", "createdAt": "2020-09-11T13:45:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyNzMwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "0999b2c052be034e7de38f03a13840292a4b497f", "chunk": "diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\nindex 0265282e58..dc57515f3c 100644\n--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n\n@@ -55,7 +62,7 @@ import static org.junit.Assert.assertEquals;\n @RunWith(Parameterized.class)\n public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n-\tprivate static final SimpleUser USER_1 = SimpleUser.newBuilder()\n+\tprivate static final User USER_1 = User.newBuilder()\n \t\t\t.setName(\"Charlie\")\n \t\t\t.setFavoriteColor(\"blue\")\n \t\t\t.setFavoriteNumber(null)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyOTE2MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487029161", "bodyText": "wouldn't it be easier (and also more performant) to simply make the field accessible in the constructor of the comparator? Going through all methods for every field access is not very beautiful.", "author": "twalthr", "createdAt": "2020-09-11T13:01:55Z", "path": "flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java", "diffHunk": "@@ -176,14 +181,25 @@ public void getFlatComparator(List<TypeComparator> flatComparators) {\n \t */\n \tpublic final Object accessField(Field field, Object object) {\n \t\ttry {\n-\t\t\tobject = field.get(object);\n+\t\t\tif (field.isAccessible()) {", "originalCommit": "ed7fa522fc930a22eee7e51e87dc778ad6ad3b71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzNTg3Mg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487035872", "bodyText": "It would. I changed it.", "author": "dawidwys", "createdAt": "2020-09-11T13:13:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAyOTE2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "0f6f3bd9e8607ed77350723e5710e1705af3f710", "chunk": "diff --git a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java\nindex 6ff5129a0a..c19bcc691d 100644\n--- a/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java\n+++ b/flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoComparator.java\n\n@@ -175,31 +174,20 @@ public final class PojoComparator<T> extends CompositeTypeComparator<T> implemen\n \t\t\t}\n \t\t}\n \t}\n-\t\n+\n \t/**\n \t * This method is handling the IllegalAccess exceptions of Field.get()\n \t */\n \tpublic final Object accessField(Field field, Object object) {\n \t\ttry {\n-\t\t\tif (field.isAccessible()) {\n-\t\t\t\treturn field.get(object);\n-\t\t\t} else {\n-\t\t\t\t// try using the getter\n-\t\t\t\tOptional<Method> getter = TypeExtractionUtils.getGetter(field);\n-\t\t\t\tif (!getter.isPresent()) {\n-\t\t\t\t\tthrow new IllegalStateException(\"This should not happen. The field should either be accessible or\" +\n-\t\t\t\t\t\t\" we should have a getter. Field: \" + field + \" obj: \" + object);\n-\t\t\t\t}\n-\t\t\t\treturn getter.get().invoke(object);\n-\t\t\t}\n+\t\t\tobject = field.get(object);\n \t\t} catch (NullPointerException npex) {\n \t\t\tthrow new NullKeyFieldException(\"Unable to access field \"+field+\" on object \"+object);\n \t\t} catch (IllegalAccessException iaex) {\n-\t\t\tthrow new RuntimeException(\"This should not happen since we call setAccessible(true) in PojoTypeInfo.\"\n+\t\t\tthrow new RuntimeException(\"This should not happen since we call setAccesssible(true) in the ctor.\"\n \t\t\t+ \" fields: \" + field + \" obj: \" + object);\n-\t\t} catch (InvocationTargetException e) {\n-\t\t\tthrow new WrappingRuntimeException(e);\n \t\t}\n+\t\treturn object;\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMjE4MA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487032180", "bodyText": "we can simply access the member field instead of passing it through the methods, no?", "author": "twalthr", "createdAt": "2020-09-11T13:07:28Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -218,7 +231,7 @@ private Object convertAvroType(Schema schema, TypeInformation<?> info, Object ob\n \t\tswitch (schema.getType()) {\n \t\t\tcase RECORD:\n \t\t\t\tif (object instanceof IndexedRecord) {\n-\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object);\n+\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object, jodaConverter);", "originalCommit": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzODI4Mw==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487038283", "bodyText": "Right in this class we can. I was too fast to follow the same scheme as in the AvroRowDataDeserializationSchema were we have runtime converters instead of member methods.", "author": "dawidwys", "createdAt": "2020-09-11T13:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMjE4MA=="}], "type": "inlineReview", "revised_code": {"commit": "8396f34387c87703171a06563b15e0f0b2a53699", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\nindex 0978f14553..3962285af2 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n\n@@ -231,7 +234,7 @@ public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<\n \t\tswitch (schema.getType()) {\n \t\t\tcase RECORD:\n \t\t\t\tif (object instanceof IndexedRecord) {\n-\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object, jodaConverter);\n+\t\t\t\t\treturn convertAvroRecordToRow(schema, (RowTypeInfo) info, (IndexedRecord) object);\n \t\t\t\t}\n \t\t\t\tthrow new IllegalStateException(\"IndexedRecord expected but was: \" + object.getClass());\n \t\t\tcase ENUM:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzAzMzgzMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487033831", "bodyText": "We can simply access JodaConverter where needed as a singleton? I would not pollute this methods.", "author": "twalthr", "createdAt": "2020-09-11T13:10:10Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java", "diffHunk": "@@ -101,7 +106,7 @@ private static AvroToRowDataConverter createNullableConverter(LogicalType type)\n \t/**\n \t * Creates a runtime converter which assuming input object is not null.\n \t */\n-\tprivate static AvroToRowDataConverter createConverter(LogicalType type) {\n+\tprivate static AvroToRowDataConverter createConverter(LogicalType type, @Nullable JodaConverter jodaConverter) {", "originalCommit": "20cabf7afcac656efb5b959fa8c1a33b76c44fb1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java\nindex d939410309..346ccf6776 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroToRowDataConverters.java\n\n@@ -106,7 +100,7 @@ public class AvroToRowDataConverters {\n \t/**\n \t * Creates a runtime converter which assuming input object is not null.\n \t */\n-\tprivate static AvroToRowDataConverter createConverter(LogicalType type, @Nullable JodaConverter jodaConverter) {\n+\tprivate static AvroToRowDataConverter createConverter(LogicalType type) {\n \t\tswitch (type.getTypeRoot()) {\n \t\tcase NULL:\n \t\t\treturn avroObject -> null;\n"}}, {"oid": "0f6f3bd9e8607ed77350723e5710e1705af3f710", "url": "https://github.com/apache/flink/commit/0f6f3bd9e8607ed77350723e5710e1705af3f710", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:13:13Z", "type": "forcePushed"}, {"oid": "8396f34387c87703171a06563b15e0f0b2a53699", "url": "https://github.com/apache/flink/commit/8396f34387c87703171a06563b15e0f0b2a53699", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:18:05Z", "type": "forcePushed"}, {"oid": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "url": "https://github.com/apache/flink/commit/2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T13:32:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA0NjY5MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487046691", "bodyText": "maybe to much optimization but should we just do the long arithmetic ourselves here and below? We are creating a lot of objects for the hot path.", "author": "twalthr", "createdAt": "2020-09-11T13:31:41Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -340,10 +357,22 @@ private Time convertToTime(Object object, @Nullable JodaConverter jodaConverter)\n \t\treturn new Time(millis - LOCAL_TZ.getOffset(millis));\n \t}\n \n-\tprivate Timestamp convertToTimestamp(Object object) {\n+\tprivate Timestamp convertToTimestamp(Object object, @Nullable JodaConverter jodaConverter, boolean isMicros) {\n \t\tfinal long millis;\n \t\tif (object instanceof Long) {\n-\t\t\tmillis = (Long) object;\n+\t\t\tif (isMicros) {\n+\t\t\t\tlong micros = (Long) object;\n+\t\t\t\tInstant instant = Instant.ofEpochSecond(0)", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2cb9ec4b5e8daf8f4333acb2a8c09a8f2b1cfdb8", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\nindex 17674ce7f9..3962285af2 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n\n@@ -357,7 +353,7 @@ public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<\n \t\treturn new Time(millis - LOCAL_TZ.getOffset(millis));\n \t}\n \n-\tprivate Timestamp convertToTimestamp(Object object, @Nullable JodaConverter jodaConverter, boolean isMicros) {\n+\tprivate Timestamp convertToTimestamp(Object object, boolean isMicros) {\n \t\tfinal long millis;\n \t\tif (object instanceof Long) {\n \t\t\tif (isMicros) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MDkxMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487050911", "bodyText": "Shouldn't this be a SQL type like the others? Is this method actually used?", "author": "twalthr", "createdAt": "2020-09-11T13:38:56Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -272,11 +276,14 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\treturn DataTypes.TIMESTAMP(3)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n-\t\t\t}\n-\t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n \t\t\t\treturn DataTypes.TIMESTAMP(6)\n \t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n \t\t\t\t\t\t.notNull();\n+\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timeMicros()) {\n+\t\t\t\treturn DataTypes.TIME(6)\n+\t\t\t\t\t.bridgedTo(LocalTime.class)", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIwODcxNg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487208716", "bodyText": "Actually, those should be the default conversion classes from java.time. I changed that. It is not used, at least for now. We might need that later e.g. in schema-registry where we will need to convert schema retrieved from schema-registry to a SQL schema.\nIt was added as a  complementary method to org.apache.flink.formats.avro.typeutils.AvroSchemaConverter#convertToSchema(org.apache.flink.table.types.logical.LogicalType)", "author": "dawidwys", "createdAt": "2020-09-11T18:10:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MDkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "0999b2c052be034e7de38f03a13840292a4b497f", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\nindex 42d2541a37..03dc213040 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\n\n@@ -259,31 +258,24 @@ public class AvroSchemaConverter {\n \t\t\t\t\t\tdecimalType.getScale())\n \t\t\t\t\t\t.notNull();\n \t\t\t}\n-\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class))\n-\t\t\t\t\t.notNull();\n+\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT()).notNull();\n \t\tcase INT:\n \t\t\t// logical date and time type\n \t\t\tfinal org.apache.avro.LogicalType logicalType = schema.getLogicalType();\n \t\t\tif (logicalType == LogicalTypes.date()) {\n-\t\t\t\treturn DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull();\n+\t\t\t\treturn DataTypes.DATE().notNull();\n \t\t\t} else if (logicalType == LogicalTypes.timeMillis()) {\n-\t\t\t\treturn DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull();\n+\t\t\t\treturn DataTypes.TIME().notNull();\n \t\t\t}\n \t\t\treturn DataTypes.INT().notNull();\n \t\tcase LONG:\n \t\t\t// logical timestamp type\n \t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMillis()) {\n-\t\t\t\treturn DataTypes.TIMESTAMP(3)\n-\t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n-\t\t\t\t\t\t.notNull();\n+\t\t\t\treturn DataTypes.TIMESTAMP(3).notNull();\n \t\t\t} else if (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n-\t\t\t\treturn DataTypes.TIMESTAMP(6)\n-\t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n-\t\t\t\t\t\t.notNull();\n+\t\t\t\treturn DataTypes.TIMESTAMP(6).notNull();\n \t\t\t} else if (schema.getLogicalType() == LogicalTypes.timeMicros()) {\n-\t\t\t\treturn DataTypes.TIME(6)\n-\t\t\t\t\t.bridgedTo(LocalTime.class)\n-\t\t\t\t\t.notNull();\n+\t\t\t\treturn DataTypes.TIME(6).notNull();\n \t\t\t}\n \t\t\treturn DataTypes.BIGINT().notNull();\n \t\tcase FLOAT:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzA1MjU4MQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487052581", "bodyText": "same question as above why is this not sql.Time?", "author": "twalthr", "createdAt": "2020-09-11T13:41:31Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java", "diffHunk": "@@ -193,7 +193,7 @@ private void validateUserSchema(DataType actual) {\n \t\t\t\tDataTypes.FIELD(\"type_bytes\", DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class)).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_date\", DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_time_millis\", DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull()),\n-\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.INT().notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.TIME(6).notNull()),", "originalCommit": "9038509a993f32233b4406cd6f6ca713258622c5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0999b2c052be034e7de38f03a13840292a4b497f", "chunk": "diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java\nindex e5de3f189b..88c6857f2a 100644\n--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java\n+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverterTest.java\n\n@@ -190,14 +190,14 @@ public class AvroSchemaConverterTest {\n \t\t\t\tDataTypes.FIELD(\"type_fixed\", DataTypes.VARBINARY(16)),\n \t\t\t\tDataTypes.FIELD(\"type_union\", DataTypes.RAW(Types.GENERIC(Object.class)).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_nested\", address),\n-\t\t\t\tDataTypes.FIELD(\"type_bytes\", DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class)).notNull()),\n-\t\t\t\tDataTypes.FIELD(\"type_date\", DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull()),\n-\t\t\t\tDataTypes.FIELD(\"type_time_millis\", DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_bytes\", DataTypes.ARRAY(DataTypes.TINYINT()).notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_date\", DataTypes.DATE().notNull()),\n+\t\t\t\tDataTypes.FIELD(\"type_time_millis\", DataTypes.TIME().notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_time_micros\", DataTypes.TIME(6).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_timestamp_millis\",\n-\t\t\t\t\t\tDataTypes.TIMESTAMP(3).bridgedTo(java.sql.Timestamp.class).notNull()),\n+\t\t\t\t\t\tDataTypes.TIMESTAMP(3).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_timestamp_micros\",\n-\t\t\t\t\t\tDataTypes.TIMESTAMP(6).bridgedTo(java.sql.Timestamp.class).notNull()),\n+\t\t\t\t\t\tDataTypes.TIMESTAMP(6).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_decimal_bytes\", DataTypes.DECIMAL(4, 2).notNull()),\n \t\t\t\tDataTypes.FIELD(\"type_decimal_fixed\", DataTypes.DECIMAL(4, 2).notNull()))\n \t\t\t\t.notNull();\n"}}, {"oid": "0999b2c052be034e7de38f03a13840292a4b497f", "url": "https://github.com/apache/flink/commit/0999b2c052be034e7de38f03a13840292a4b497f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T18:06:58Z", "type": "forcePushed"}, {"oid": "bab621c4f92387eef5bf0101a5b687e45c479f80", "url": "https://github.com/apache/flink/commit/bab621c4f92387eef5bf0101a5b687e45c479f80", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-11T19:56:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487694408", "bodyText": "Actually, this should be DataTypes.BYTES() which would also match to Avro's BYTES type.", "author": "twalthr", "createdAt": "2020-09-14T07:08:11Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java", "diffHunk": "@@ -255,28 +257,24 @@ private static DataType convertToDataType(Schema schema) {\n \t\t\t\t\t\tdecimalType.getScale())\n \t\t\t\t\t\t.notNull();\n \t\t\t}\n-\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class))\n-\t\t\t\t\t.notNull();\n+\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT()).notNull();", "originalCommit": "cac5bf3b0420f10b9480c8e1e8e0b00884612ee7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcyMzI3OA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487723278", "bodyText": "or is Avro using Byte[] instead of byte[]", "author": "twalthr", "createdAt": "2020-09-14T08:01:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzczODc2OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487738769", "bodyText": "Avro uses ByteBuffer, therefore we do a conversion there. I will change it to DataTypes.BYTES().", "author": "dawidwys", "createdAt": "2020-09-14T08:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5NDQwOA=="}], "type": "inlineReview", "revised_code": {"commit": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\nindex cf914793c6..44c5d84f7a 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/typeutils/AvroSchemaConverter.java\n\n@@ -257,24 +255,28 @@ public class AvroSchemaConverter {\n \t\t\t\t\t\tdecimalType.getScale())\n \t\t\t\t\t\t.notNull();\n \t\t\t}\n-\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT()).notNull();\n+\t\t\treturn DataTypes.ARRAY(DataTypes.TINYINT().bridgedTo(Byte.class))\n+\t\t\t\t\t.notNull();\n \t\tcase INT:\n \t\t\t// logical date and time type\n \t\t\tfinal org.apache.avro.LogicalType logicalType = schema.getLogicalType();\n \t\t\tif (logicalType == LogicalTypes.date()) {\n-\t\t\t\treturn DataTypes.DATE().notNull();\n+\t\t\t\treturn DataTypes.DATE().bridgedTo(java.sql.Date.class).notNull();\n \t\t\t} else if (logicalType == LogicalTypes.timeMillis()) {\n-\t\t\t\treturn DataTypes.TIME().notNull();\n+\t\t\t\treturn DataTypes.TIME().bridgedTo(java.sql.Time.class).notNull();\n \t\t\t}\n \t\t\treturn DataTypes.INT().notNull();\n \t\tcase LONG:\n \t\t\t// logical timestamp type\n \t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMillis()) {\n-\t\t\t\treturn DataTypes.TIMESTAMP(3).notNull();\n-\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n-\t\t\t\treturn DataTypes.TIMESTAMP(6).notNull();\n-\t\t\t} else if (schema.getLogicalType() == LogicalTypes.timeMicros()) {\n-\t\t\t\treturn DataTypes.TIME(6).notNull();\n+\t\t\t\treturn DataTypes.TIMESTAMP(3)\n+\t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n+\t\t\t\t\t\t.notNull();\n+\t\t\t}\n+\t\t\tif (schema.getLogicalType() == LogicalTypes.timestampMicros()) {\n+\t\t\t\treturn DataTypes.TIMESTAMP(6)\n+\t\t\t\t\t\t.bridgedTo(java.sql.Timestamp.class)\n+\t\t\t\t\t\t.notNull();\n \t\t\t}\n \t\t\treturn DataTypes.BIGINT().notNull();\n \t\tcase FLOAT:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzY5Njc0Nw==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487696747", "bodyText": "nit: private?", "author": "twalthr", "createdAt": "2020-09-14T07:13:06Z", "path": "flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java", "diffHunk": "@@ -75,12 +75,11 @@\n  */\n @PublicEvolving\n public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<Row> {\n-\n \t/**\n \t * Used for time conversions into SQL types.\n \t */\n \tprivate static final TimeZone LOCAL_TZ = TimeZone.getDefault();\n-\n+\tpublic static final long MICROS_PER_SECOND = 1_000_000L;", "originalCommit": "a639495f2bc3cef6fedf52492e546ebeb6306be5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "chunk": "diff --git a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\nindex 96d2e6b87b..5e3edf77a5 100644\n--- a/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n+++ b/flink-formats/flink-avro/src/main/java/org/apache/flink/formats/avro/AvroRowDeserializationSchema.java\n\n@@ -75,11 +77,12 @@ import java.util.TimeZone;\n  */\n @PublicEvolving\n public class AvroRowDeserializationSchema extends AbstractDeserializationSchema<Row> {\n+\n \t/**\n \t * Used for time conversions into SQL types.\n \t */\n \tprivate static final TimeZone LOCAL_TZ = TimeZone.getDefault();\n-\tpublic static final long MICROS_PER_SECOND = 1_000_000L;\n+\n \t/**\n \t * Avro record class for deserialization. Might be null if record class is not available.\n \t */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzIxMQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703211", "bodyText": "can we add a TODO here, because actually the record should pass the Table API unmodified, but this will come with FLUP-136", "author": "twalthr", "createdAt": "2020-09-14T07:25:49Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport\n+\t\t\t.stream(users.spliterator(), false)\n+\t\t\t.collect(Collectors.toList());\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n \t\t\t\"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],42,{},null,null,null,123456,\" +\n \t\t\t\"12:12:12.000,123456,2014-03-01T12:12:12.321Z,null\\n\" +\n \t\t\t\"blue,null,Charlie,[],[],false,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],2014-03-01,\" +\n \t\t\t\"java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],1.337,RED,null,1337,{},\" +\n-\t\t\t\"{\\\"num\\\": 42, \\\"street\\\": \\\"Bakerstreet\\\", \\\"city\\\": \\\"Berlin\\\", \\\"state\\\": \" +\n-\t\t\t\"\\\"Berlin\\\", \\\"zip\\\": \\\"12049\\\"},null,null,123456,12:12:12.000,123456,\" +\n+\t\t\t\"Berlin,42,Berlin,Bakerstreet,12049,null,null,123456,12:12:12.000,123456,\" +", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "chunk": "diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\nindex e7d68a94dc..7dfe9e38fb 100644\n--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n\n@@ -150,18 +147,15 @@ public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n+\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n \n-\t\tTable t = tEnv.fromDataStream(testData(env));\n+\t\tTable t = tEnv.fromDataSet(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n-\t\tList<Row> results = StreamSupport\n-\t\t\t.stream(users.spliterator(), false)\n-\t\t\t.collect(Collectors.toList());\n+\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487703709", "bodyText": "These should not be necessary in our tests, right?", "author": "twalthr", "createdAt": "2020-09-14T07:26:48Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc0ODkyNg==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487748926", "bodyText": "We do need those in a0122e0 as we still use the joda time in this commit. We can remove them, (and we do in the next commit).\nThe default Kryo serialization does not work well.", "author": "dawidwys", "createdAt": "2020-09-14T08:45:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzc2NjkyMA==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487766920", "bodyText": "BTW, after the comment, I removed the JodaLocalDateSerializer and JodaLocalTimeSerializer classes in 453d02c as they are no longer used.", "author": "dawidwys", "createdAt": "2020-09-14T09:14:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwMzcwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "chunk": "diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\nindex e7d68a94dc..7dfe9e38fb 100644\n--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n\n@@ -150,18 +147,15 @@ public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n+\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n \n-\t\tTable t = tEnv.fromDataStream(testData(env));\n+\t\tTable t = tEnv.fromDataSet(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n-\t\tList<Row> results = StreamSupport\n-\t\t\t.stream(users.spliterator(), false)\n-\t\t\t.collect(Collectors.toList());\n+\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzcwNDU2OQ==", "url": "https://github.com/apache/flink/pull/13373#discussion_r487704569", "bodyText": "nit: We recently added a CollectionUtils.iterableToList maybe this is easier to read than the StreamSupport class.", "author": "twalthr", "createdAt": "2020-09-14T07:28:32Z", "path": "flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java", "diffHunk": "@@ -147,24 +150,26 @@ public AvroTypesITCase(\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n+\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n+\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n \n-\t\tTable t = tEnv.fromDataSet(testData(env));\n+\t\tTable t = tEnv.fromDataStream(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n+\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n+\t\tList<Row> results = StreamSupport", "originalCommit": "a0122e0683100ca2e8e1190b940cdd3a7166a19d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "chunk": "diff --git a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\nindex e7d68a94dc..7dfe9e38fb 100644\n--- a/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n+++ b/flink-formats/flink-avro/src/test/java/org/apache/flink/table/runtime/batch/AvroTypesITCase.java\n\n@@ -150,18 +147,15 @@ public class AvroTypesITCase extends TableProgramsClusterTestBase {\n \n \t@Test\n \tpublic void testAvroToRow() throws Exception {\n-\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+\t\tExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalDate.class, AvroKryoSerializerUtils.JodaLocalDateSerializer.class);\n \t\tenv.getConfig().registerTypeWithKryoSerializer(LocalTime.class, AvroKryoSerializerUtils.JodaLocalTimeSerializer.class);\n-\t\tStreamTableEnvironment tEnv = StreamTableEnvironment.create(env, EnvironmentSettings.newInstance().useBlinkPlanner().build());\n+\t\tBatchTableEnvironment tEnv = BatchTableEnvironment.create(env, config());\n \n-\t\tTable t = tEnv.fromDataStream(testData(env));\n+\t\tTable t = tEnv.fromDataSet(testData(env));\n \t\tTable result = t.select($(\"*\"));\n \n-\t\tIterable<Row> users = () -> DataStreamUtils.collect(tEnv.toAppendStream(result, Row.class));\n-\t\tList<Row> results = StreamSupport\n-\t\t\t.stream(users.spliterator(), false)\n-\t\t\t.collect(Collectors.toList());\n+\t\tList<Row> results = tEnv.toDataSet(result, Row.class).collect();\n \t\tString expected =\n \t\t\t\"black,null,Whatever,[true],[hello],true,java.nio.HeapByteBuffer[pos=0 lim=10 cap=10],\" +\n \t\t\t\"2014-03-01,java.nio.HeapByteBuffer[pos=0 lim=2 cap=2],[7, -48],0.0,GREEN,\" +\n"}}, {"oid": "44161ed79481cd2f7b76527124fbd6186eac5aaf", "url": "https://github.com/apache/flink/commit/44161ed79481cd2f7b76527124fbd6186eac5aaf", "message": "[hotfix] Fix Pojo comparator field access\n\nThe PojoComparator assumes it can access a field of a pojo directly. It assumes the field is either public or setAccessible was called before. This is the case though only if  the record went through serialization. This is not the case e.g. in CollectionExecution mode.\n\nStarting from this commit we make all fields accessible in\nPojoComparator constructor.", "committedDate": "2020-09-14T08:28:44Z", "type": "commit"}, {"oid": "a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "url": "https://github.com/apache/flink/commit/a99c86b50af1d061dcb329d44c88d7419f8ddfb2", "message": "[hotfix] Extract joda conversions to a separate class", "committedDate": "2020-09-14T08:28:44Z", "type": "commit"}, {"oid": "bb7e8094f0675c882471f7ca31732f954275e470", "url": "https://github.com/apache/flink/commit/bb7e8094f0675c882471f7ca31732f954275e470", "message": "[hotfix] Fix schema to DataType/Type conversion", "committedDate": "2020-09-14T08:39:43Z", "type": "commit"}, {"oid": "76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "url": "https://github.com/apache/flink/commit/76e7b1f3424c7348e99ba27d6f533ac01cb0af4d", "message": "[hotfix] Fix time-micros and timestamp-micros handling", "committedDate": "2020-09-14T08:40:47Z", "type": "commit"}, {"oid": "8442f93c6b63aa92c72b890e012151dd8c58d81b", "url": "https://github.com/apache/flink/commit/8442f93c6b63aa92c72b890e012151dd8c58d81b", "message": "[hotfix] Migrate AvroTypesITCase to blink planner", "committedDate": "2020-09-14T09:06:04Z", "type": "commit"}, {"oid": "58d8186564b4f1e810985d59fb8764b1cabb21ff", "url": "https://github.com/apache/flink/commit/58d8186564b4f1e810985d59fb8764b1cabb21ff", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:12:05Z", "type": "forcePushed"}, {"oid": "1979b49a8f98b6edfb860d3e514076407ae2a0d1", "url": "https://github.com/apache/flink/commit/1979b49a8f98b6edfb860d3e514076407ae2a0d1", "message": "[FLINK-18192] Upgrade avro to 1.10\n\nThis commit upgrades the default version of avro that flink-avro will use. It should be possible to downgrade the avro version in a user job as the binary format is compatible and we do not expose any dependencies on avro in the API.\n\nAdditionally this commit fixes handling of logical types: time-micros and timestamp-micros as well as interpretation of timestamp-millis in the AvroRowDataDeserializationSchema.", "committedDate": "2020-09-14T09:15:08Z", "type": "commit"}, {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:15:15Z", "type": "commit"}, {"oid": "166a17e676304c9215f3b5b517cca71fdb2e927f", "url": "https://github.com/apache/flink/commit/166a17e676304c9215f3b5b517cca71fdb2e927f", "message": "[FLINK-18802] Create an uber jar for avro for sql-client", "committedDate": "2020-09-14T09:15:15Z", "type": "forcePushed"}]}