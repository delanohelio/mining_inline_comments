{"pr_number": 11403, "pr_title": "[FLINK-16316][operators] Implement new StreamOperatorBase as a replacement for AbstractStreamOperator", "pr_createdAt": "2020-03-13T12:28:20Z", "pr_url": "https://github.com/apache/flink/pull/11403", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392201502", "bodyText": "@AHeise what do you think about including processingTimeService in StreamOperatorInitializer always, regardless of the ProcessingTimeServiceAware? Generally speaking what do you think about StreamOperatorInitializer?", "author": "pnowojski", "createdAt": "2020-03-13T12:37:42Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java", "diffHunk": "@@ -57,7 +57,13 @@\n \t\t\t((ProcessingTimeServiceAware) operatorFactory).setProcessingTimeService(processingTimeService);\n \t\t}\n \n-\t\tOP op = operatorFactory.createStreamOperator(containingTask, configuration, output);\n+\t\t// TODO: what to do with ProcessingTimeServiceAware?\n+\t\tOP op = operatorFactory.createStreamOperator(\n+\t\t\tnew StreamOperatorInitializer<>(\n+\t\t\t\tcontainingTask,\n+\t\t\t\tconfiguration,\n+\t\t\t\toutput,\n+\t\t\t\tprocessingTimeService));", "originalCommit": "c7595ee5eb7ac60dae52bcd1368878d70d372533", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyMzUwNQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392923505", "bodyText": "In general, as written above \ud83d\udc4d .\nAlways passing timeService comes closer to my understanding of a factory (factory being stateless except for fundamental configurations that would change the type of the returned operator for all invocations of createStreamOperator). The factory then decides if it wants to use the service or not.\nIf the service processingTimeService would only be (costly) created for a specific operator factory (e.g. MailboxExecutor being used only in AsyncWaitOperatorFactory), then I'd wrap the creation in a supplier.\nUltimately, we would get rid of all the different OperatorFactory interfaces except for the main one. Then I'd be perfectly fine to keep factories and not convert them into builders.\nNote for that goal, we would need to get rid of SimpleOperatorFactory: Once an operator has been created, it cannot go back into factory. If we need to functionality, then I only see builder pattern as a clean solution, where going back and forth between operator and operator builder is doable.\nLast remark, if StreamOperatorInitializer ends up with 10+ fields that are all passed on construction, I'd probably switch to a builder style, but that can also be done later.", "author": "AHeise", "createdAt": "2020-03-16T10:38:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyODg0Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394828846", "bodyText": "Note for that goal, we would need to get rid of SimpleOperatorFactory: Once an operator has been created, it cannot go back into factory. If we need to functionality, then I only see builder pattern as a clean solution, where going back and forth between operator and operator builder is doable\n\nSimpleOperatorFactory is not intended to make possible to go back and forth between operators and factories, but just to provide backward compatible class for transporting SetupableStreamOperator classes. Also as it's intended to be removed in the future (we can do it as that's PublicEvolving API), in the design let's assume SimpleOperatorFactory doesn't exist.\nBut @AHeise, what do you think we should do with ProcessingTimeServiceAware? @Deprecate and mark it for removal? Or Should I do it in this PR?", "author": "pnowojski", "createdAt": "2020-03-19T07:16:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExNjcyMQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397116721", "bodyText": "@deprecate and mark it for removal", "author": "AHeise", "createdAt": "2020-03-24T12:32:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMTUwMg=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java\nindex 24b3a62e6e..11090f6d08 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactoryUtil.java\n\n@@ -59,7 +59,7 @@ public class StreamOperatorFactoryUtil {\n \n \t\t// TODO: what to do with ProcessingTimeServiceAware?\n \t\tOP op = operatorFactory.createStreamOperator(\n-\t\t\tnew StreamOperatorInitializer<>(\n+\t\t\tnew StreamOperatorParameters<>(\n \t\t\t\tcontainingTask,\n \t\t\t\tconfiguration,\n \t\t\t\toutput,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392202032", "bodyText": "alternative name could be AbstractStreamOperatorV2?", "author": "pnowojski", "createdAt": "2020-03-13T12:38:57Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,484 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {", "originalCommit": "c7595ee5eb7ac60dae52bcd1368878d70d372533", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMjA5NQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392932095", "bodyText": "I'm fine with both. V2 conveys to me that this is the only Flink left in Flink 2.0. If that roughly corresponds with your deprecation plan, then I like it more.", "author": "AHeise", "createdAt": "2020-03-16T10:49:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTAyMw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393239023", "bodyText": "Or AbstractStreamOperatorNg :)\nI'd like to make it clear for somebody implementing new operator what's the difference and purpose of each - straight from names, without looking at annotations or javadocs.", "author": "rkhachatryan", "createdAt": "2020-03-16T18:44:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzYzOA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394843638", "bodyText": "Renamed to AbstractStreamOperatorV2", "author": "pnowojski", "createdAt": "2020-03-19T07:54:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjIwMjAzMg=="}], "type": "inlineReview", "revised_code": {"commit": "c1facefebee52a1ac84f188f46b114deae0aad89", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\nindex 3f97fdec9c..a8e0d36335 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\n\n@@ -481,4 +481,8 @@ public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n \tpublic void setKeyContextElement2(StreamRecord<?> record) throws Exception {\n \t\tthrow new IllegalStateException(\"This method should never be called. Use Input class instead\");\n \t}\n+\n+\tprotected Optional<InternalTimeServiceManager<?>> getTimeServiceManager() {\n+\t\treturn stateHandler.getTimeServiceManager();\n+\t}\n }\n"}}, {"oid": "c1facefebee52a1ac84f188f46b114deae0aad89", "url": "https://github.com/apache/flink/commit/c1facefebee52a1ac84f188f46b114deae0aad89", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-13T15:07:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5NzE1OA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392897158", "bodyText": "nit: indent", "author": "AHeise", "createdAt": "2020-03-16T09:54:43Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java", "diffHunk": "@@ -133,4 +136,26 @@ static void execute(\n \t\t}\n \t}\n \n+\tprivate static void checkpointStreamOperator(\n+\t\tStreamOperator<?> op,", "originalCommit": "a5f59ce50eca4dbadba277d85f731c7bb52cb66f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\nindex e63211082b..81a6fd8028 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\n\n@@ -136,20 +136,18 @@ final class CheckpointingOperation {\n \t\t}\n \t}\n \n-\tprivate static void checkpointStreamOperator(\n-\t\tStreamOperator<?> op,\n-\t\tCheckpointMetaData checkpointMetaData,\n-\t\tCheckpointOptions checkpointOptions,\n-\t\tCheckpointStreamFactory storageLocation,\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n-\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\t\tStreamOperator<?> op,\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory storageLocation,\n+\t\t\tSupplier<Boolean> isCanceled) throws Exception {\n \t\ttry {\n-\t\t\tOperatorSnapshotFutures snapshotInProgress = op.snapshotState(\n+\t\t\treturn op.snapshotState(\n \t\t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\t\tcheckpointMetaData.getTimestamp(),\n \t\t\t\tcheckpointOptions,\n \t\t\t\tstorageLocation);\n-\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n \t\t}\n \t\tcatch (Exception ex) {\n \t\t\tif (!isCanceled.get()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5NzUzNg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392897536", "bodyText": "Map or better return the OperatorSnapshotFutures and put it on caller side into map.", "author": "AHeise", "createdAt": "2020-03-16T09:55:20Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java", "diffHunk": "@@ -133,4 +136,26 @@ static void execute(\n \t\t}\n \t}\n \n+\tprivate static void checkpointStreamOperator(\n+\t\tStreamOperator<?> op,\n+\t\tCheckpointMetaData checkpointMetaData,\n+\t\tCheckpointOptions checkpointOptions,\n+\t\tCheckpointStreamFactory storageLocation,\n+\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,", "originalCommit": "a5f59ce50eca4dbadba277d85f731c7bb52cb66f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\nindex e63211082b..81a6fd8028 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/CheckpointingOperation.java\n\n@@ -136,20 +136,18 @@ final class CheckpointingOperation {\n \t\t}\n \t}\n \n-\tprivate static void checkpointStreamOperator(\n-\t\tStreamOperator<?> op,\n-\t\tCheckpointMetaData checkpointMetaData,\n-\t\tCheckpointOptions checkpointOptions,\n-\t\tCheckpointStreamFactory storageLocation,\n-\t\tHashMap<OperatorID, OperatorSnapshotFutures> operatorSnapshotsInProgress,\n-\t\tSupplier<Boolean> isCanceled) throws Exception {\n+\tprivate static OperatorSnapshotFutures checkpointStreamOperator(\n+\t\t\tStreamOperator<?> op,\n+\t\t\tCheckpointMetaData checkpointMetaData,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory storageLocation,\n+\t\t\tSupplier<Boolean> isCanceled) throws Exception {\n \t\ttry {\n-\t\t\tOperatorSnapshotFutures snapshotInProgress = op.snapshotState(\n+\t\t\treturn op.snapshotState(\n \t\t\t\tcheckpointMetaData.getCheckpointId(),\n \t\t\t\tcheckpointMetaData.getTimestamp(),\n \t\t\t\tcheckpointOptions,\n \t\t\t\tstorageLocation);\n-\t\t\toperatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress);\n \t\t}\n \t\tcatch (Exception ex) {\n \t\t\tif (!isCanceled.get()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5ODgxMA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392898810", "bodyText": "\ud83d\udc4d for commit. message could reflect that it's actually moved into SetupableOperator.", "author": "AHeise", "createdAt": "2020-03-16T09:57:32Z", "path": "flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java", "diffHunk": "@@ -26,7 +26,6 @@\n import org.apache.flink.runtime.state.CheckpointStorageWorkerView;", "originalCommit": "27cc48bb76227f7e53048ac1cd3dc148cefad738", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java b/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java\nindex de1f146e52..35266ef8c3 100644\n--- a/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java\n+++ b/flink-libraries/flink-state-processing-api/src/test/java/org/apache/flink/state/api/output/SnapshotUtilsTest.java\n\n@@ -28,6 +28,7 @@ import org.apache.flink.runtime.state.CheckpointStreamFactory;\n import org.apache.flink.runtime.state.ttl.mock.MockStateBackend;\n import org.apache.flink.streaming.api.operators.OperatorSnapshotFutures;\n import org.apache.flink.streaming.api.operators.StreamOperator;\n+import org.apache.flink.streaming.api.operators.StreamTaskStateInitializer;\n import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n \n import org.junit.Assert;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwMzYxMA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392903610", "bodyText": "Please check if that needs to be closed at the end of the test.", "author": "AHeise", "createdAt": "2020-03-16T10:06:31Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();", "originalCommit": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3MzE3MQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394373171", "bodyText": "I don't know, but closing doesn't hurt :)", "author": "pnowojski", "createdAt": "2020-03-18T14:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwMzYxMA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\nindex 0198da5ff5..84bb1fc105 100644\n--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n\n@@ -42,8 +42,8 @@ import org.apache.flink.util.ExceptionUtils;\n \n import org.junit.Test;\n \n+import java.util.concurrent.FutureTask;\n import java.util.concurrent.RunnableFuture;\n-import java.util.concurrent.TimeUnit;\n \n import static junit.framework.TestCase.assertTrue;\n import static org.hamcrest.CoreMatchers.equalTo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNTU3OQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392905579", "bodyText": "It's quite confusing that the supplied key is never really used or tested. Also could you make key and value of a different type?", "author": "AHeise", "createdAt": "2020-03-16T10:10:15Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);", "originalCommit": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3NDg4Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394374886", "bodyText": "I need it only to pass some checkState, but sure, I can change it to \"44\" if it makes any difference.", "author": "pnowojski", "createdAt": "2020-03-18T14:11:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNTU3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExNzEyMw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397117123", "bodyText": "It would just make it easier to parse the test (string = key, value = int).", "author": "AHeise", "createdAt": "2020-03-24T12:33:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNTU3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\nindex 0198da5ff5..84bb1fc105 100644\n--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n\n@@ -42,8 +42,8 @@ import org.apache.flink.util.ExceptionUtils;\n \n import org.junit.Test;\n \n+import java.util.concurrent.FutureTask;\n import java.util.concurrent.RunnableFuture;\n-import java.util.concurrent.TimeUnit;\n \n import static junit.framework.TestCase.assertTrue;\n import static org.hamcrest.CoreMatchers.equalTo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNjA4MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392906080", "bodyText": "Looks like two test cases to me: in this test, I'd actually would like to see a successful snapshot. And then have second with failure.", "author": "AHeise", "createdAt": "2020-03-16T10:11:12Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);\n+\t\tstateHandler.initializeOperatorState(stateSnapshotContext -> {\n+\t\t\tstateSnapshotContext.getKeyedStateStore()\n+\t\t\t\t.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.update(42L);\n+\t\t\tstateSnapshotContext.getOperatorStateStore()\n+\t\t\t\t.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.add(42L);\n+\t\t});\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));\n+\n+\t\ttry {\n+\t\t\tstateHandler.snapshotState(", "originalCommit": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3NTY3NA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394375674", "bodyText": "You do realize that you are punishing the messenger here?\nMost of the cases are still tested in AbstractStreamOperatorTest (FYI, I will try to provide equivalent of those tests for the new base class once watermarks and other things are also implemented).", "author": "pnowojski", "createdAt": "2020-03-18T14:12:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNjA4MA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\nindex 0198da5ff5..84bb1fc105 100644\n--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n\n@@ -42,8 +42,8 @@ import org.apache.flink.util.ExceptionUtils;\n \n import org.junit.Test;\n \n+import java.util.concurrent.FutureTask;\n import java.util.concurrent.RunnableFuture;\n-import java.util.concurrent.TimeUnit;\n \n import static junit.framework.TestCase.assertTrue;\n import static org.hamcrest.CoreMatchers.equalTo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkwNzU5NA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392907594", "bodyText": "Could we use FutureTask instead of implementing it ourselves?", "author": "AHeise", "createdAt": "2020-03-16T10:13:55Z", "path": "flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.ListStateDescriptor;\n+import org.apache.flink.api.common.state.ValueStateDescriptor;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.util.InterceptingOperatorMetricGroup;\n+import org.apache.flink.runtime.operators.testutils.ExpectedTestException;\n+import org.apache.flink.runtime.operators.testutils.MockEnvironmentBuilder;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyedStateHandle;\n+import org.apache.flink.runtime.state.OperatorStateHandle;\n+import org.apache.flink.runtime.state.SnapshotResult;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.memory.MemCheckpointStreamFactory;\n+import org.apache.flink.runtime.state.memory.MemoryStateBackend;\n+import org.apache.flink.streaming.runtime.tasks.TestProcessingTimeService;\n+import org.apache.flink.util.ExceptionUtils;\n+\n+import org.junit.Test;\n+\n+import java.util.concurrent.RunnableFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static junit.framework.TestCase.assertTrue;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.empty;\n+import static org.junit.Assert.fail;\n+\n+/**\n+ * Tests for {@link StreamOperatorStateHandlerTest}.\n+ */\n+public class StreamOperatorStateHandlerTest {\n+\t/**\n+\t * Tests that a failing snapshot method call to the keyed state backend will trigger the closing\n+\t * of the StateSnapshotContextSynchronousImpl and the cancellation of the\n+\t * OperatorSnapshotResult. The latter is supposed to also cancel all assigned futures.\n+\t */\n+\t@Test\n+\tpublic void testFailingBackendSnapshotMethod() throws Exception {\n+\t\tfinal long checkpointId = 42L;\n+\t\tfinal long timestamp = 1L;\n+\n+\t\tfinal CloseableRegistry closeableRegistry = new CloseableRegistry();\n+\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture = new CancelableFuture<>();\n+\t\tRunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture = new CancelableFuture<>();\n+\n+\t\tOperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures(\n+\t\t\tkeyedStateManagedFuture,\n+\t\t\tkeyedStateRawFuture,\n+\t\t\toperatorStateManagedFuture,\n+\t\t\toperatorStateRawFuture);\n+\n+\t\tStateSnapshotContextSynchronousImpl context = new TestStateSnapshotContextSynchronousImpl(checkpointId, timestamp, closeableRegistry);\n+\t\tcontext.getRawKeyedOperatorStateOutput();\n+\t\tcontext.getRawOperatorStateOutput();\n+\n+\t\tStreamTaskStateInitializerImpl stateInitializer =\n+\t\t\tnew StreamTaskStateInitializerImpl(new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n+\t\tStreamOperatorStateContext stateContext = stateInitializer.streamOperatorStateContext(\n+\t\t\tnew OperatorID(),\n+\t\t\t\"whatever\",\n+\t\t\tnew TestProcessingTimeService(),\n+\t\t\tnew UnUsedKeyContext(),\n+\t\t\tIntSerializer.INSTANCE,\n+\t\t\tcloseableRegistry,\n+\t\t\tnew InterceptingOperatorMetricGroup());\n+\t\tStreamOperatorStateHandler stateHandler = new StreamOperatorStateHandler(stateContext, new ExecutionConfig(), closeableRegistry);\n+\n+\t\tfinal String keyedStateField = \"keyedStateField\";\n+\t\tfinal String operatorStateField = \"operatorStateField\";\n+\n+\t\tstateHandler.setCurrentKey(44L);\n+\t\tstateHandler.initializeOperatorState(stateSnapshotContext -> {\n+\t\t\tstateSnapshotContext.getKeyedStateStore()\n+\t\t\t\t.getState(new ValueStateDescriptor<>(keyedStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.update(42L);\n+\t\t\tstateSnapshotContext.getOperatorStateStore()\n+\t\t\t\t.getListState(new ListStateDescriptor<>(operatorStateField, LongSerializer.INSTANCE))\n+\t\t\t\t.add(42L);\n+\t\t});\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(not(empty())));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), equalTo(1));\n+\n+\t\ttry {\n+\t\t\tstateHandler.snapshotState(\n+\t\t\t\tstateSnapshotContext -> {\n+\t\t\t\t\tthrow new ExpectedTestException();\n+\t\t\t\t},\n+\t\t\t\t\"42\",\n+\t\t\t\t42,\n+\t\t\t\t42,\n+\t\t\t\tCheckpointOptions.forCheckpointWithDefaultLocation(),\n+\t\t\t\tnew MemCheckpointStreamFactory(1024),\n+\t\t\t\toperatorSnapshotResult,\n+\t\t\t\tcontext);\n+\t\t\tfail(\"Exception expected.\");\n+\t\t} catch (CheckpointException e) {\n+\t\t\t// We can not check for ExpectedTestException class directly,\n+\t\t\t// as CheckpointException is wrapping the cause with SerializedThrowable\n+\t\t\tif (!ExceptionUtils.findThrowableWithMessage(e, ExpectedTestException.MESSAGE).isPresent()) {\n+\t\t\t\tthrow e;\n+\t\t\t}\n+\t\t}\n+\n+\t\tassertTrue(keyedStateManagedFuture.isCancelled());\n+\t\tassertTrue(keyedStateRawFuture.isCancelled());\n+\t\tassertTrue(context.getKeyedStateStreamFuture().isCancelled());\n+\t\tassertTrue(operatorStateManagedFuture.isCancelled());\n+\t\tassertTrue(operatorStateRawFuture.isCancelled());\n+\t\tassertTrue(context.getOperatorStateStreamFuture().isCancelled());\n+\n+\t\tstateHandler.dispose();\n+\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredBroadcastStateNames(), is(empty()));\n+\t\tassertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(empty()));\n+\t\tassertThat(stateContext.keyedStateBackend().numKeyValueStatesByName(), is(0));\n+\t}\n+\n+\tprivate static class TestStateSnapshotContextSynchronousImpl extends StateSnapshotContextSynchronousImpl {\n+\t\tpublic TestStateSnapshotContextSynchronousImpl(\n+\t\t\t\tlong checkpointId,\n+\t\t\t\tlong timestamp,\n+\t\t\t\tCloseableRegistry closeableRegistry) {\n+\t\t\tsuper(checkpointId, timestamp, new MemCheckpointStreamFactory(1024), new KeyGroupRange(0, 2), closeableRegistry);\n+\t\t\tthis.keyedStateCheckpointClosingFuture = new CancelableFuture<>();\n+\t\t\tthis.operatorStateCheckpointClosingFuture = new CancelableFuture<>();\n+\t\t}\n+\t}\n+\n+\tprivate static class CancelableFuture<T> implements RunnableFuture<T> {", "originalCommit": "9cce09936e14e63d8bef95bff57d0e2f2401e1f0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\nindex 0198da5ff5..84bb1fc105 100644\n--- a/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n+++ b/flink-streaming-java/src/test/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandlerTest.java\n\n@@ -42,8 +42,8 @@ import org.apache.flink.util.ExceptionUtils;\n \n import org.junit.Test;\n \n+import java.util.concurrent.FutureTask;\n import java.util.concurrent.RunnableFuture;\n-import java.util.concurrent.TimeUnit;\n \n import static junit.framework.TestCase.assertTrue;\n import static org.hamcrest.CoreMatchers.equalTo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392914268", "bodyText": "\ud83d\udc4d to the idea. Long overdue. However, StreamOperatorInitializer sounds like something active, while it's just a parameter object. How about StreamOperatorSettings or StreamOperatorParameters?", "author": "AHeise", "createdAt": "2020-03-16T10:26:48Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java", "diffHunk": "@@ -58,11 +56,11 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "originalCommit": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1Mjc2Mw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393252763", "bodyText": "+1, other candidates: StreamOperatorCreationContext, StreamOperatorFactoryContext", "author": "rkhachatryan", "createdAt": "2020-03-16T19:07:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDQwNTQ2Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394405466", "bodyText": "I will go with StreamOperatorParameters", "author": "pnowojski", "createdAt": "2020-03-18T14:51:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkxNDI2OA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java\nindex 86a88e950c..97a367321d 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/ContinuousFileReaderOperatorFactory.java\n\n@@ -56,9 +56,9 @@ public class ContinuousFileReaderOperatorFactory<OUT> extends AbstractStreamOper\n \t}\n \n \t@Override\n-\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {\n \t\tContinuousFileReaderOperator<OUT> operator = new ContinuousFileReaderOperator<>(inputFormat, processingTimeService, mailboxExecutor);\n-\t\toperator.setup(initializer.getContainingTask(), initializer.getStreamConfig(), initializer.getOutput());\n+\t\toperator.setup(parameters.getContainingTask(), parameters.getStreamConfig(), parameters.getOutput());\n \t\toperator.setOutputType(type, executionConfig);\n \t\treturn (T) operator;\n \t}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTA5MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392925090", "bodyText": "Candidate for builder pattern as described above.", "author": "AHeise", "createdAt": "2020-03-16T10:39:50Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "originalCommit": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyODk1MQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394828951", "bodyText": "Let's keep it simple for now.", "author": "pnowojski", "createdAt": "2020-03-19T07:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTA5MA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\nsimilarity index 82%\nrename from flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java\nrename to flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\nindex 5e8d8227e0..5aaffcc46a 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\n\n@@ -25,18 +25,20 @@ import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n import org.apache.flink.streaming.runtime.tasks.StreamTask;\n \n /**\n- * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n- * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n- * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ * Helper  class to construct {@link AbstractStreamOperatorV2}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link AbstractStreamOperatorV2} and to\n+ * allow for backward compatible changes in the {@link AbstractStreamOperatorV2}'s constructor.\n+ *\n+ * @param <OUT> The output type of an operator that will be constructed using {@link StreamOperatorParameters}.\n  */\n @Experimental\n-public class StreamOperatorInitializer<OUT> {\n+public class StreamOperatorParameters<OUT> {\n \tprivate final StreamTask<?, ?> containingTask;\n \tprivate final StreamConfig config;\n \tprivate final Output<StreamRecord<OUT>> output;\n \tprivate final ProcessingTimeService processingTimeService;\n \n-\tpublic StreamOperatorInitializer(\n+\tpublic StreamOperatorParameters(\n \t\t\tStreamTask<?, ?> containingTask,\n \t\t\tStreamConfig config,\n \t\t\tOutput<StreamRecord<OUT>> output,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTgxNA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392925814", "bodyText": "OUT needs a java tag: I initially thought OUT is the type of the operator.", "author": "AHeise", "createdAt": "2020-03-16T10:40:38Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+\n+/**\n+ * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n+ * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ */\n+@Experimental\n+public class StreamOperatorInitializer<OUT> {", "originalCommit": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyOTkzNg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394829936", "bodyText": "Do you mean adding java doc? I've added it.", "author": "pnowojski", "createdAt": "2020-03-19T07:19:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNTgxNA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\nsimilarity index 82%\nrename from flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java\nrename to flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\nindex 5e8d8227e0..5aaffcc46a 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorInitializer.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorParameters.java\n\n@@ -25,18 +25,20 @@ import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n import org.apache.flink.streaming.runtime.tasks.StreamTask;\n \n /**\n- * Helper  class to construct {@link StreamOperatorBase}. Wraps couple of internal parameters\n- * to simplify for users construction of classes extending {@link StreamOperatorBase} and to\n- * allow for backward compatible changes in the {@link StreamOperatorBase}'s constructor.\n+ * Helper  class to construct {@link AbstractStreamOperatorV2}. Wraps couple of internal parameters\n+ * to simplify for users construction of classes extending {@link AbstractStreamOperatorV2} and to\n+ * allow for backward compatible changes in the {@link AbstractStreamOperatorV2}'s constructor.\n+ *\n+ * @param <OUT> The output type of an operator that will be constructed using {@link StreamOperatorParameters}.\n  */\n @Experimental\n-public class StreamOperatorInitializer<OUT> {\n+public class StreamOperatorParameters<OUT> {\n \tprivate final StreamTask<?, ?> containingTask;\n \tprivate final StreamConfig config;\n \tprivate final Output<StreamRecord<OUT>> output;\n \tprivate final ProcessingTimeService processingTimeService;\n \n-\tpublic StreamOperatorInitializer(\n+\tpublic StreamOperatorParameters(\n \t\t\tStreamTask<?, ?> containingTask,\n \t\t\tStreamConfig config,\n \t\t\tOutput<StreamRecord<OUT>> output,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNzYxMQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392927611", "bodyText": "@rkhachatryan wanted to get rid of this method's generic afaik. It's really a bit anti pattern. So I'm not sure going into it makes any sense.", "author": "AHeise", "createdAt": "2020-03-16T10:42:31Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java", "diffHunk": "@@ -61,16 +59,16 @@ public void setMailboxExecutor(MailboxExecutor mailboxExecutor) {\n \t}\n \n \t@Override\n-\tpublic StreamOperator createStreamOperator(StreamTask containingTask, StreamConfig config, Output output) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {", "originalCommit": "73b6e6e569d5ccac8bd56c593ba3f8bf5caec9c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzMTg3Mw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394831873", "bodyText": "I know, but I had to do it for now, because of compile errors:\nError:(62, 31) java: name clash: createStreamOperator(org.apache.flink.streaming.api.operators.StreamOperatorParameters<OUT>) in org.apache.flink.streaming.api.operators.async.AsyncWaitOperatorFactory and <T>createStreamOperator(org.apache.flink.streaming.api.operators.StreamOperatorParameters<OUT>) in org.apache.flink.streaming.api.operators.StreamOperatorFactory have the same erasure, yet neither overrides the other", "author": "pnowojski", "createdAt": "2020-03-19T07:25:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkyNzYxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java\nindex d2dcfa803e..c51c68aaca 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/async/AsyncWaitOperatorFactory.java\n\n@@ -59,7 +59,7 @@ public class AsyncWaitOperatorFactory<IN, OUT> extends AbstractStreamOperatorFac\n \t}\n \n \t@Override\n-\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer) {\n+\tpublic <T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters) {\n \t\tAsyncWaitOperator asyncWaitOperator = new AsyncWaitOperator(\n \t\t\t\tasyncFunction,\n \t\t\t\ttimeout,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMDgxMw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392930813", "bodyText": "\ud83d\udc4d to no setup. I'd really wish we could get rid of initializeState as well. Maybe with V3 ;).\n(meta: it's hard for me to see the changes to V1. I have seen no obvious problem with the class itself, but I haven't comapred it)", "author": "AHeise", "createdAt": "2020-03-16T10:47:12Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {", "originalCommit": "4c4ec9eb40a8efc96897d0c0b4c6c27755f2ed7c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzkzOA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394843938", "bodyText": "Yes, initializeState annoyed me as well :/ But one step at a time.", "author": "pnowojski", "createdAt": "2020-03-19T07:55:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMDgxMw=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nsimilarity index 94%\nrename from flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\nrename to flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nindex a8e0d36335..d8287ea543 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n\n@@ -61,7 +61,7 @@ import java.util.Optional;\n \n /**\n  * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n- * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.\n  *\n  * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n  * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r392933478", "bodyText": "This guy should be removed and merged into StreamOperatorInitializer by exposing a Supplier<MailboxExecutor> mailboxExecutorFactory.", "author": "AHeise", "createdAt": "2020-03-16T10:52:00Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java", "diffHunk": "@@ -17,10 +17,13 @@\n \n package org.apache.flink.streaming.api.operators;\n \n+import org.apache.flink.annotation.PublicEvolving;\n+\n /**\n  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created\n  * through a factory implementing this interface.\n  */\n+@PublicEvolving\n public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1MDEwMQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394850101", "bodyText": "That would contradict\n\t\t// yielding operators cannot be chained to legacy sources\n\t\tif (downStreamOperator instanceof YieldingOperatorFactory) {\n\t\t\t// unfortunately the information that vertices have been chained is not preserved at this point\n\t\t\treturn !getHeadOperator(upStreamVertex, streamGraph).isStreamSource();\n\t\t}\n\nWhat do you think about having mixed pattern? Common parameters in StreamOperatorParameters, and \"special\" or rare ones as decorators?", "author": "pnowojski", "createdAt": "2020-03-19T08:10:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2MTg1Mw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396961853", "bodyText": "Haven't thought about this case . Since it's Experimental, I'm also fine with keeping it for now.\nIn general, I don't think we should mix patterns though.\nHere is some solution:  StreamOperatorFactory could have a default boolean needsMailboxExecutor() { return false; }, which triggers a nullable mailboxExecutor to be set in Parameters. The same method can be used to determine chainability.", "author": "AHeise", "createdAt": "2020-03-24T08:02:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzEwMDYyMQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397100621", "bodyText": "Maybe let's keep it for now as it is? As I'm not sure if I like the idea of nullifying parameters based on needsMailboxExecutor(). I think I would prefer mixed pattern to that, but this probably needs some deeper thought through?", "author": "pnowojski", "createdAt": "2020-03-24T12:03:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjkzMzQ3OA=="}], "type": "inlineReview", "revised_code": {"commit": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java\nindex 1e2c5c8e68..c3563c5e79 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/YieldingOperatorFactory.java\n\n@@ -17,13 +17,13 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Experimental;\n \n /**\n  * An operator that needs access to the {@link MailboxExecutor} to yield to downstream operators needs to be created\n  * through a factory implementing this interface.\n  */\n-@PublicEvolving\n+@Experimental\n public interface YieldingOperatorFactory<OUT> extends StreamOperatorFactory<OUT> {\n \tvoid setMailboxExecutor(MailboxExecutor mailboxExecutor);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393239873", "bodyText": "protected?\nI guess it's only for descendants.", "author": "rkhachatryan", "createdAt": "2020-03-16T18:46:05Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class StreamOperatorBase<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorBase.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic StreamOperatorBase(StreamOperatorInitializer<OUT> initializer, int numberOfInputs) {\n+\t\tinputWatermarks = new long[numberOfInputs];\n+\t\tArrays.fill(inputWatermarks, Long.MIN_VALUE);\n+\t\tfinal Environment environment = initializer.getContainingTask().getEnvironment();\n+\t\tconfig = initializer.getStreamConfig();\n+\t\tCountingOutput<OUT> countingOutput;\n+\t\tOperatorMetricGroup operatorMetricGroup;\n+\t\ttry {\n+\t\t\toperatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());\n+\t\t\tcountingOutput = new CountingOutput(initializer.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());\n+\t\t\tif (config.isChainStart()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();\n+\t\t\t}\n+\t\t\tif (config.isChainEnd()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating task metrics.\", e);\n+\t\t\tcountingOutput = null;\n+\t\t\toperatorMetricGroup = null;\n+\t\t}\n+\n+\t\tif (countingOutput == null || operatorMetricGroup == null) {\n+\t\t\tmetrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();\n+\t\t\toutput = initializer.getOutput();\n+\t\t}\n+\t\telse {\n+\t\t\tmetrics = operatorMetricGroup;\n+\t\t\toutput = countingOutput;\n+\t\t}\n+\n+\t\tlatencyStats = createLatencyStats(\n+\t\t\tenvironment.getTaskManagerInfo().getConfiguration(),\n+\t\t\tinitializer.getContainingTask().getIndexInSubtaskGroup());\n+\n+\t\tprocessingTimeService = Preconditions.checkNotNull(initializer.getProcessingTimeService());\n+\t\texecutionConfig = initializer.getContainingTask().getExecutionConfig();\n+\t\tuserCodeClassLoader = initializer.getContainingTask().getUserCodeClassLoader();\n+\t\tcancelables = initializer.getContainingTask().getCancelables();\n+\n+\t\truntimeContext = new StreamingRuntimeContext(\n+\t\t\tenvironment,\n+\t\t\tinitializer.getContainingTask().getAccumulatorMap(),\n+\t\t\toperatorMetricGroup,\n+\t\t\tgetOperatorID(),\n+\t\t\tprocessingTimeService,\n+\t\t\tnull);\n+\t}\n+\n+\tprivate LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {\n+\t\ttry {\n+\t\t\tint historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);\n+\t\t\tif (historySize <= 0) {\n+\t\t\t\tLOG.warn(\"{} has been set to a value equal or below 0: {}. Using default.\", MetricOptions.LATENCY_HISTORY_SIZE, historySize);\n+\t\t\t\thistorySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();\n+\t\t\t}\n+\n+\t\t\tfinal String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);\n+\t\t\tLatencyStats.Granularity granularity;\n+\t\t\ttry {\n+\t\t\t\tgranularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));\n+\t\t\t} catch (IllegalArgumentException iae) {\n+\t\t\t\tgranularity = LatencyStats.Granularity.OPERATOR;\n+\t\t\t\tLOG.warn(\n+\t\t\t\t\t\"Configured value {} option for {} is invalid. Defaulting to {}.\",\n+\t\t\t\t\tconfiguredGranularity,\n+\t\t\t\t\tMetricOptions.LATENCY_SOURCE_GRANULARITY.key(),\n+\t\t\t\t\tgranularity);\n+\t\t\t}\n+\t\t\tTaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();\n+\t\t\treturn new LatencyStats(jobMetricGroup.addGroup(\"latency\"),\n+\t\t\t\thistorySize,\n+\t\t\t\tindexInSubtaskGroup,\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgranularity);\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating latency metrics.\", e);\n+\t\t\treturn new LatencyStats(\n+\t\t\t\tUnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup(\"latency\"),\n+\t\t\t\t1,\n+\t\t\t\t0,\n+\t\t\t\tnew OperatorID(),\n+\t\t\t\tLatencyStats.Granularity.SINGLE);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic MetricGroup getMetricGroup() {\n+\t\treturn metrics;\n+\t}\n+\n+\t@Override\n+\tpublic final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {\n+\t\tfinal TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());\n+\n+\t\tfinal StreamOperatorStateContext context =\n+\t\t\tstreamTaskStateManager.streamOperatorStateContext(\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgetClass().getSimpleName(),\n+\t\t\t\tgetProcessingTimeService(),\n+\t\t\t\tthis,\n+\t\t\t\tkeySerializer,\n+\t\t\t\tcancelables,\n+\t\t\t\tmetrics);\n+\n+\t\tstateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);\n+\t\tstateHandler.initializeOperatorState(this::initializeState);\n+\t}\n+\n+\t/**\n+\t * This method is called immediately before any elements are processed, it should contain the\n+\t * operator's initialization logic, e.g. state initialization.\n+\t *\n+\t * <p>The default implementation does nothing.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void open() throws Exception {}\n+\n+\t/**\n+\t * This method is called after all records have been added to the operators via the methods\n+\t * {@link OneInputStreamOperator#processElement(StreamRecord)}, or\n+\t * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and\n+\t * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.\n+\t *\n+\t * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing\n+\t * of buffered should be propagated, in order to cause the operation to be recognized asa failed,\n+\t * because the last data items are not processed properly.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void close() throws Exception {}\n+\n+\t/**\n+\t * This method is called at the very end of the operator's life, both in the case of a successful\n+\t * completion of the operation, and in the case of a failure and canceling.\n+\t *\n+\t * <p>This method is expected to make a thorough effort to release all resources\n+\t * that the operator has acquired.\n+\t */\n+\t@Override\n+\tpublic void dispose() throws Exception {\n+\t\tif (stateHandler != null) {\n+\t\t\tstateHandler.dispose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n+\t\t// the default implementation does nothing and accepts the checkpoint\n+\t\t// this is purely for subclasses to override\n+\t}\n+\n+\t@Override\n+\tpublic final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws Exception {\n+\t\treturn stateHandler.snapshotState(\n+\t\t\tthis::snapshotState,\n+\t\t\tgetOperatorName(),\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory);\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t}\n+\n+\t/**\n+\t * Stream operators with state which can be restored need to override this hook method.\n+\t *\n+\t * @param context context that allows to register different states.\n+\t */\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tstateHandler.notifyCheckpointComplete(checkpointId);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t//  Properties and Services\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Gets the execution config defined on the execution environment of the job to which this\n+\t * operator belongs.\n+\t *\n+\t * @return The job's execution config.\n+\t */\n+\tpublic ExecutionConfig getExecutionConfig() {\n+\t\treturn executionConfig;\n+\t}\n+\n+\tpublic StreamConfig getOperatorConfig() {\n+\t\treturn config;\n+\t}\n+\n+\tpublic ClassLoader getUserCodeClassloader() {\n+\t\treturn userCodeClassLoader;\n+\t}\n+\n+\t/**\n+\t * Return the operator name. If the runtime context has been set, then the task name with\n+\t * subtask index is returned. Otherwise, the simple class name is returned.\n+\t *\n+\t * @return If runtime context is set, then return task name with subtask index. Otherwise return\n+\t * \t\t\tsimple class name.\n+\t */\n+\tprotected String getOperatorName() {\n+\t\tif (runtimeContext != null) {\n+\t\t\treturn runtimeContext.getTaskNameWithSubtasks();\n+\t\t} else {\n+\t\t\treturn getClass().getSimpleName();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Returns a context that allows the operator to query information about the execution and also\n+\t * to interact with systems such as broadcast variables and managed state. This also allows\n+\t * to register timers.\n+\t */\n+\tpublic StreamingRuntimeContext getRuntimeContext() {\n+\t\treturn runtimeContext;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn stateHandler.getOperatorStateBackend();\n+\t}\n+\n+\t/**\n+\t * Returns the {@link ProcessingTimeService} responsible for getting the current\n+\t * processing time and registering timers.\n+\t */\n+\tpublic ProcessingTimeService getProcessingTimeService() {", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0ODg3Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394848872", "bodyText": "At least for now, not really. This and other methods are being used in different places outside of an operator. Some just in tests, others not only. I would prefer to keep it as is in the first iteration using assumption, that if it was exposed before, there were some reasons behind it. Especially to make transitions from V1 to V2 as smooth as possible.", "author": "pnowojski", "createdAt": "2020-03-19T08:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2OTQ2Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394869466", "bodyText": "I see only 4 usages not in operators - all in tests:\n\nOutputRecordInCloseTestSource\nStreamingRuntimeContextTest.createMapPlainMockOp()\nTestProcessingTimeServiceTest.testCustomTimeServiceProvider()\nThreadInspectingTask\n\nIt's easy to change protected to public, but not the opposite because there could be more usages already.", "author": "rkhachatryan", "createdAt": "2020-03-19T08:48:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNTIwNQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394915205", "bodyText": "plus potential usages from users.\n\nIt's easy to change protected to public, but not the opposite because there could be more usages already.\n\nYes, but you are ignoring migration costs. In this case, imo migration problems overweight drawbacks of exposing something from the abstract operator as convenient testing getter.", "author": "pnowojski", "createdAt": "2020-03-19T10:08:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzOTg3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nsimilarity index 94%\nrename from flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\nrename to flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nindex a8e0d36335..d8287ea543 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorBase.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n\n@@ -61,7 +61,7 @@ import java.util.Optional;\n \n /**\n  * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n- * Currently intended to work with {@link MultipleInputStreamOperator}.\n+ * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.\n  *\n  * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n  * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTM2OA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393241368", "bodyText": "There are 4 similar try-catch blocks here; can we eliminate duplication (by iterating through Runnables for example)?", "author": "rkhachatryan", "createdAt": "2020-03-16T18:49:01Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU2NDE0MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393564140", "bodyText": "I'd recommend guava's Closer.", "author": "AHeise", "createdAt": "2020-03-17T10:01:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTM2OA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MjcyMA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393242720", "bodyText": "It would be more clear to me to see void return type instead of returning passed parameter.\nIf not, it can be returned earlier.", "author": "rkhachatryan", "createdAt": "2020-03-16T18:51:14Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393245072", "bodyText": "protected?\nShould we add type parameter on class level instead of casting?\nIf not, why don't return just KeyedStateBackend<?>?", "author": "rkhachatryan", "createdAt": "2020-03-16T18:55:44Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM2OTY1NQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394369655", "bodyText": "protected I don't think it's needed, as this is looks like valid public api of this class. Note,  StreamOperatorStateHandler is a private field of abstract classes.\n KeyedStateBackend<?> wouldn't work as some PublicEvolving apis need this to be casted. I think global type parameter wouldn't work, as this field/class is being used also in non keyed context.", "author": "pnowojski", "createdAt": "2020-03-18T14:04:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg3Nzk1NQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394877955", "bodyText": "I don't think that abstract class should have any public API. Ideally, only it's descendants should know about it.\nIt sounds very strange that keyedStateBackend is used in not keyed context. Do you mean non-keyed operators? Should we split it then into non-keyed and keyed versions?\nIf not, this class looks keyed and most of its clients know their keys; those who don't can use wildcards/<Object>/casts/....or be fixed:)", "author": "rkhachatryan", "createdAt": "2020-03-19T09:04:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkzMjYzMQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394932631", "bodyText": "this is not an abstract class, and I don't see a problem of exposing public methods in an abstract class.\n\n\n\nDo you mean non-keyed operators\n\nyes. This is one of the reasons why I was struggling with figuring out how the operator API should look like.\n\nShould we split it then into non-keyed and keyed versions?\n\nI don't know how and I don't think this is the right place to do it. As I wrote in my overall comment:\n\nIf you would like to split it even further to things like keyed and not-keyed operators, those two problems (spaghetti/web of connections and multiple inheritance) are going to be more profound.\nI don't know at the moment how to tackle those problems, but for me they are out of scope of this PR/JIRA/FLIP :/", "author": "pnowojski", "createdAt": "2020-03-19T10:39:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM2NTc3MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396365770", "bodyText": "sorry, I messed it up with the base operator class. But nevertheless, we shouldn't expose class internals without a need. Here, all the usages are inside the package, so it could be package-private.\nAt least, we could split StreamOperatorStateHandler (regarding reference to overall comment, please see my reply to it).\nIn either case, why not to parameterize AbstractStreamOperatorV2, StreamOperatorStateHandler and it's keyedStateBackend; in AbstractStreamOperator we can still have a cast; and each time we migrate an operator to V2 we add a proper type parameter (or Object).", "author": "rkhachatryan", "createdAt": "2020-03-23T10:57:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjQzMDQ5Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396430496", "bodyText": "I don't like fanatic approach to restricting visibility, especially if it doesn't make sense. For me those methods are valid public APIs of this class, it's intention is to expose those things. Artificially hiding theirs visibility can cause issues in the future. Like if class is re-used in different package, it will require small changes and/or block people from re-using it.\nParametrising the whole class with key type, even for non-keyed contexts, doesn't make sense. I think that's worse than keeping the cast.", "author": "pnowojski", "createdAt": "2020-03-23T12:58:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU2Mjg2Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396562862", "bodyText": "The approach of narrowing visibility is a practical one: if a method is public then it's part of a class API; and somebody will eventually use it; and it will be difficult to change it later. On the other hand, if and when you actually need it, you can widen the visibility.\nWhy, can you please elaborate?\n\nAs it is now, I see:\n\nAbstractKeyedStateBackend<?> keyedStateBackend; (<?>)\ncasts: in StreamOperatorStateHandler AND in some operators like final K key = this.<K>getKeyedStateBackend().getCurrentKey();\n@SuppressWarnings all the way to actual usages\nconfusing type parameter in method  (can I pass different types in different calls? is it the same as for getInternalTimerService?)\n\nEach of these places is a potential bug.\nWhat I propose is to have\nKeyedOp<K> extends AbstractStreamOperatorV2<K>\nand\nNonKeyedOp extends AbstractStreamOperatorV2<Object>.\n(and  StreamOperatorStateHandler<T> inside)", "author": "rkhachatryan", "createdAt": "2020-03-23T16:00:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyMzUxNA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396623514", "bodyText": "KeyedOp and NonKeyedOp won't work nicely, unless you want to multiply number of abstract classes that are extending from AbstractStreamOperator/AbstractStreamOperatorV2 by factor of two.", "author": "pnowojski", "createdAt": "2020-03-23T17:23:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk1NjM5NQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396956395", "bodyText": "I agree with Roman that the proper way would be to have the Handler parameterized. However, I see that the public API of AbstractStreamOperator already exposes the same method. So I suggest to address the issue holistically in a different PR.", "author": "AHeise", "createdAt": "2020-03-24T07:51:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA1MzU2Nw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397053567", "bodyText": "I think we should parameterize new classes (AbstractStreamOperatorV2 and StreamOperatorStateHandler) and keep the old one (AbstractStreamOperator) as is.\n@pnowojski , I didn't get your point here:\n\nKeyedOp and NonKeyedOp won't work nicely, unless you want to multiply number of abstract classes that are extending from AbstractStreamOperator/AbstractStreamOperatorV2 by factor of two.\n\nCan you please explain if it's still relevant?", "author": "rkhachatryan", "createdAt": "2020-03-24T10:38:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA2Nzk1Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397067956", "bodyText": "As I mentioned before, there are other classes that are building on top of AbstractStreamOperator, like AbstractUdfStreamOperator, AbstractPythonFunctionOperator, TableStreamOperator, .... With splitting AbstractStreamOperator into more classes like keyed, non-keyed, one input, two input, multi input, we multiply the number of classes that need to extend from it.", "author": "pnowojski", "createdAt": "2020-03-24T11:03:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4OTA4MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397089080", "bodyText": "I meant to add type parameter to them, not splitting them. Sorry for the confusion.\n(we don't have to update the whole hierarchy while migrating; e.g. we can start with\nAbstractUdfStreamOperator<OUT> extends AbstractStreamOperatorV2<Object, OUT>.)", "author": "rkhachatryan", "createdAt": "2020-03-24T11:41:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc4ODQzMw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397788433", "bodyText": "Summarizing the offline discussion about type parameters:\n\nFor AbstractStreamOperatorV2, it's unclear whether it's a public API for MultipleInputStreamOperators or not. And if it is, then it's unclear whether it should reproduce AbstractStreamOperator API. But to be on the safe side it's better to have the same API (i.e. type parameters on method level, not on class).\nFor StreamOperatorStateHandler, this is a trade-off between confusion by extends<Object>, by method type parameters, unnecessary casts, duplication of these casts.  Given that this is reversible, it's better to go with type parameters for methods for now as well.", "author": "rkhachatryan", "createdAt": "2020-03-25T11:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NTA3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0NjAxOQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393246019", "bodyText": "Same as getKeyedStateBackend.", "author": "rkhachatryan", "createdAt": "2020-03-16T18:57:02Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393246780", "bodyText": "I couldn't find usages, am I missing something?", "author": "rkhachatryan", "createdAt": "2020-03-16T18:57:58Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\n+\t\tException exception = null;\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\toperatorStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = e;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tkeyedStateBackend.close();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\toperatorStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tkeyedStateBackend.dispose();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\texception = ExceptionUtils.firstOrSuppressed(e, exception);\n+\t\t}\n+\n+\t\tif (exception != null) {\n+\t\t\tthrow exception;\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\treturn snapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\t}\n+\n+\t@VisibleForTesting\n+\tOperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(\n+\t\t\tString name,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tTriggerable<K, N> triggerable) {\n+\n+\t\tcheckTimerServiceInitialization();\n+\n+\t\t// the following casting is to overcome type restrictions.\n+\t\tKeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();\n+\t\tTypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();\n+\t\tInternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;\n+\t\tTimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);\n+\t\treturn keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);\n+\t}\n+\n+\tprivate void checkTimerServiceInitialization() {\n+\t\tif (getKeyedStateBackend() == null) {\n+\t\t\tthrow new UnsupportedOperationException(\"Timers can only be used on keyed operators.\");\n+\t\t} else if (timeServiceManager == null) {\n+\t\t\tthrow new RuntimeException(\"The timer service has not been initialized.\");\n+\t\t}\n+\t}\n+\n+\tpublic void advanceWatermark(Watermark mark) throws Exception {\n+\t\tif (timeServiceManager != null) {\n+\t\t\ttimeServiceManager.advanceWatermark(mark);\n+\t\t}\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numProcessingTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numProcessingTimeTimers();\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic int numEventTimeTimers() {\n+\t\treturn timeServiceManager == null ? 0 :\n+\t\t\ttimeServiceManager.numEventTimeTimers();\n+\t}", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM3MDc3Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394370772", "bodyText": "They are being used in PublicEvolving api, so users might be relaying on this.", "author": "pnowojski", "createdAt": "2020-03-18T14:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg4MTQxNw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394881417", "bodyText": "Isn't it just a base class for the MultipleInputStreamOperator as we agreed below?", "author": "rkhachatryan", "createdAt": "2020-03-19T09:10:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkzMzY4OQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394933689", "bodyText": "No, this is StreamOperatorStateHandler.\nAnd if you are talking about the equivalent methods in AbstractStreamOperatorV2, I would argue the same thing as here.", "author": "pnowojski", "createdAt": "2020-03-19T10:41:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0Njc4MA=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1ODE4MQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393258181", "bodyText": "Why do we allow client to specify return type (T)?\nIMO, it's a factory who knows what it creates, except for strange cases of SimpleOperatorFactory and CodeGenOperatorFactory :)\nI see two options:\n\nparameterize StreamOperatorFactory with the return type (I tried - too many changes)\nreturn StreamOperator<OUT> and move cast to the client; this is less casts and IMO confusion", "author": "rkhachatryan", "createdAt": "2020-03-16T19:18:44Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java", "diffHunk": "@@ -32,14 +30,13 @@\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@Internal\n+@PublicEvolving\n public interface StreamOperatorFactory<OUT> extends Serializable {\n \n \t/**\n \t * Create the operator. Sets access to the context and the output.\n \t */\n-\t<T extends StreamOperator<OUT>> T createStreamOperator(\n-\t\t\tStreamTask<?, ?> containingTask, StreamConfig config, Output<StreamRecord<OUT>> output);\n+\t<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer);", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgyMzkwMA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394823900", "bodyText": "I agree and I don't remember what was the reason behind the template argument here, maybe it was just some error that went under our radar when reviewing/merging. Definitely trying to fix it is on my to do list.\nCurrently I would lean towards option 2. But I don't want to change status quo right know, as the PR is already pretty big and I don't know if that will not explode into some larger change/fix - especially that I'm not sure that there might be some reason behind this construct?", "author": "pnowojski", "createdAt": "2020-03-19T07:01:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1ODE4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\nindex c830dc121b..57efae96f4 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\n\n@@ -36,7 +36,7 @@ public interface StreamOperatorFactory<OUT> extends Serializable {\n \t/**\n \t * Create the operator. Sets access to the context and the output.\n \t */\n-\t<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorInitializer<OUT> initializer);\n+\t<T extends StreamOperator<OUT>> T createStreamOperator(StreamOperatorParameters<OUT> parameters);\n \n \t/**\n \t * Set the chaining strategy for operator factory.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1OTA0Mw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r393259043", "bodyText": "\ud83d\udc4d for extracting and grouping state-related operations", "author": "rkhachatryan", "createdAt": "2020-03-16T19:20:36Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,434 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.ExceptionUtils;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@PublicEvolving\n+public class StreamOperatorStateHandler {", "originalCommit": "c1facefebee52a1ac84f188f46b114deae0aad89", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex d2462ebe10..0f1d89e904 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -18,7 +18,7 @@\n \n package org.apache.flink.streaming.api.operators;\n \n-import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.annotation.Internal;\n import org.apache.flink.annotation.VisibleForTesting;\n import org.apache.flink.api.common.ExecutionConfig;\n import org.apache.flink.api.common.state.KeyedStateStore;\n"}}, {"oid": "af0a9aaf0e21579c2de2715535d166142aa4d2fe", "url": "https://github.com/apache/flink/commit/af0a9aaf0e21579c2de2715535d166142aa4d2fe", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-19T08:13:14Z", "type": "forcePushed"}, {"oid": "6e60715d78ca865c3d687699124338afb1f6d1e2", "url": "https://github.com/apache/flink/commit/6e60715d78ca865c3d687699124338afb1f6d1e2", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-19T08:38:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNjIxNg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r394916216", "bodyText": "This would confuse me if I'd implement a new operator. Should I extend this class or AbstractStreamOperator?\n(annotations don't tell much: this one is \"Experimental\" but the other one - \"PublicEvolving\").\nI think we should direct users to v1 until we remove @Experimental (and deprecate v1).\nMaybe something like this:\nNew base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.\n?", "author": "rkhachatryan", "createdAt": "2020-03-19T10:09:53Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.", "originalCommit": "6e60715d78ca865c3d687699124338afb1f6d1e2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b8fc7b297694ceb7786827ff642c64d84b7e822d", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nindex d8287ea543..5edca4c802 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n\n@@ -60,7 +60,7 @@ import java.util.Locale;\n import java.util.Optional;\n \n /**\n- * New base class for all stream operators, replacing previous {@link AbstractStreamOperator}.\n+ * New base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.\n  * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.\n  *\n  * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n"}}, {"oid": "b8fc7b297694ceb7786827ff642c64d84b7e822d", "url": "https://github.com/apache/flink/commit/b8fc7b297694ceb7786827ff642c64d84b7e822d", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-19T10:45:11Z", "type": "forcePushed"}, {"oid": "46d9e932e6884f229e88d3c69d7a746ed3634124", "url": "https://github.com/apache/flink/commit/46d9e932e6884f229e88d3c69d7a746ed3634124", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-23T10:01:31Z", "type": "forcePushed"}, {"oid": "b77da7156f766d2c480943434732bed63ff1dc0a", "url": "https://github.com/apache/flink/commit/b77da7156f766d2c480943434732bed63ff1dc0a", "message": "[FLINK-16316][operators] Make StreamOperatorFactory PublicEvolving", "committedDate": "2020-03-23T10:06:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM0OTk2Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396349962", "bodyText": "I don't see how this is related to the scope of the PR. Can you please explain the motivation?\nAlso, I don't think this interface is ready to become a part of public API (because of the type parameter issue discussed below; and probably other issues).\nI see fixing this interface and making it public should be separate PR or two.", "author": "rkhachatryan", "createdAt": "2020-03-23T10:30:36Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java", "diffHunk": "@@ -32,14 +30,13 @@\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@Internal\n+@PublicEvolving\n public interface StreamOperatorFactory<OUT> extends Serializable {", "originalCommit": "b77da7156f766d2c480943434732bed63ff1dc0a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjQxMDA0MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396410040", "bodyText": "It should have been @PublicEvolving (or @Experimental) from the beginning, as it's on the same level as StreamOperator. Also you need factories, to actually construct any multiple input stream operator. I could mark it @Experimental if you prefer so.", "author": "pnowojski", "createdAt": "2020-03-23T12:21:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM0OTk2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjUyMTAwNA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396521004", "bodyText": "@Experimental looks good to me \ud83d\udc4d", "author": "rkhachatryan", "createdAt": "2020-03-23T15:06:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM0OTk2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\nindex 57efae96f4..d1ea80c0ce 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorFactory.java\n\n@@ -30,7 +30,7 @@ import java.io.Serializable;\n  *\n  * @param <OUT> The output type of the operator\n  */\n-@PublicEvolving\n+@Experimental\n public interface StreamOperatorFactory<OUT> extends Serializable {\n \n \t/**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM4OTg5OA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396389898", "bodyText": "Reducing visibility would fail migration of only 2 tests.\nWe don't know though when this will happen. And then we could either fix the tests, disable them temporarily, or change visibility back to public.\nSo I think it's better to have it protected until then.\nSimilar argument applies to numEventTimeTimers and numProcessingTimeTimers.", "author": "rkhachatryan", "createdAt": "2020-03-23T11:42:40Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Experimental;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.execution.Environment;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.TaskManagerJobMetricGroup;\n+import org.apache.flink.runtime.metrics.groups.UnregisteredMetricGroups;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.VoidNamespace;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.graph.StreamConfig;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.streaming.runtime.streamrecord.LatencyMarker;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.streaming.runtime.tasks.ProcessingTimeService;\n+import org.apache.flink.streaming.runtime.tasks.StreamTask;\n+import org.apache.flink.streaming.util.LatencyStats;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Arrays;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+/**\n+ * New base class for all stream operators, intended to eventually replace {@link AbstractStreamOperator}.\n+ * Currently intended to work smoothly just with {@link MultipleInputStreamOperator}.\n+ *\n+ * <p>One note-able difference in comparison to {@link AbstractStreamOperator} is lack of\n+ * {@link AbstractStreamOperator#setup(StreamTask, StreamConfig, Output)} in favor of initialisation\n+ * in the constructor, and removed some tight coupling with classes like {@link StreamTask}.\n+ *\n+ * <p>Methods are guaranteed not to be called concurrently.\n+ *\n+ * @param <OUT> The output type of the operator\n+ */\n+@Experimental\n+public abstract class AbstractStreamOperatorV2<OUT> implements StreamOperator<OUT> {\n+\t/** The logger used by the operator class and its subclasses. */\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(AbstractStreamOperatorV2.class);\n+\n+\tprotected final StreamConfig config;\n+\tprotected final Output<StreamRecord<OUT>> output;\n+\tprivate final StreamingRuntimeContext runtimeContext;\n+\tprivate final ExecutionConfig executionConfig;\n+\tprivate final ClassLoader userCodeClassLoader;\n+\tprivate final CloseableRegistry cancelables;\n+\tprivate final long[] inputWatermarks;\n+\n+\t/** Metric group for the operator. */\n+\tprotected final OperatorMetricGroup metrics;\n+\tprotected final LatencyStats latencyStats;\n+\tprotected final ProcessingTimeService processingTimeService;\n+\n+\tprivate StreamOperatorStateHandler stateHandler;\n+\n+\t// We keep track of watermarks from both inputs, the combined input is the minimum\n+\t// Once the minimum advances we emit a new watermark for downstream operators\n+\tprivate long combinedWatermark = Long.MIN_VALUE;\n+\n+\tpublic AbstractStreamOperatorV2(StreamOperatorParameters<OUT> parameters, int numberOfInputs) {\n+\t\tinputWatermarks = new long[numberOfInputs];\n+\t\tArrays.fill(inputWatermarks, Long.MIN_VALUE);\n+\t\tfinal Environment environment = parameters.getContainingTask().getEnvironment();\n+\t\tconfig = parameters.getStreamConfig();\n+\t\tCountingOutput<OUT> countingOutput;\n+\t\tOperatorMetricGroup operatorMetricGroup;\n+\t\ttry {\n+\t\t\toperatorMetricGroup = environment.getMetricGroup().getOrAddOperator(config.getOperatorID(), config.getOperatorName());\n+\t\t\tcountingOutput = new CountingOutput(parameters.getOutput(), operatorMetricGroup.getIOMetricGroup().getNumRecordsOutCounter());\n+\t\t\tif (config.isChainStart()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseInputMetricsForTask();\n+\t\t\t}\n+\t\t\tif (config.isChainEnd()) {\n+\t\t\t\toperatorMetricGroup.getIOMetricGroup().reuseOutputMetricsForTask();\n+\t\t\t}\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating task metrics.\", e);\n+\t\t\tcountingOutput = null;\n+\t\t\toperatorMetricGroup = null;\n+\t\t}\n+\n+\t\tif (countingOutput == null || operatorMetricGroup == null) {\n+\t\t\tmetrics = UnregisteredMetricGroups.createUnregisteredOperatorMetricGroup();\n+\t\t\toutput = parameters.getOutput();\n+\t\t}\n+\t\telse {\n+\t\t\tmetrics = operatorMetricGroup;\n+\t\t\toutput = countingOutput;\n+\t\t}\n+\n+\t\tlatencyStats = createLatencyStats(\n+\t\t\tenvironment.getTaskManagerInfo().getConfiguration(),\n+\t\t\tparameters.getContainingTask().getIndexInSubtaskGroup());\n+\n+\t\tprocessingTimeService = Preconditions.checkNotNull(parameters.getProcessingTimeService());\n+\t\texecutionConfig = parameters.getContainingTask().getExecutionConfig();\n+\t\tuserCodeClassLoader = parameters.getContainingTask().getUserCodeClassLoader();\n+\t\tcancelables = parameters.getContainingTask().getCancelables();\n+\n+\t\truntimeContext = new StreamingRuntimeContext(\n+\t\t\tenvironment,\n+\t\t\tenvironment.getAccumulatorRegistry().getUserMap(),\n+\t\t\toperatorMetricGroup,\n+\t\t\tgetOperatorID(),\n+\t\t\tprocessingTimeService,\n+\t\t\tnull);\n+\t}\n+\n+\tprivate LatencyStats createLatencyStats(Configuration taskManagerConfig, int indexInSubtaskGroup) {\n+\t\ttry {\n+\t\t\tint historySize = taskManagerConfig.getInteger(MetricOptions.LATENCY_HISTORY_SIZE);\n+\t\t\tif (historySize <= 0) {\n+\t\t\t\tLOG.warn(\"{} has been set to a value equal or below 0: {}. Using default.\", MetricOptions.LATENCY_HISTORY_SIZE, historySize);\n+\t\t\t\thistorySize = MetricOptions.LATENCY_HISTORY_SIZE.defaultValue();\n+\t\t\t}\n+\n+\t\t\tfinal String configuredGranularity = taskManagerConfig.getString(MetricOptions.LATENCY_SOURCE_GRANULARITY);\n+\t\t\tLatencyStats.Granularity granularity;\n+\t\t\ttry {\n+\t\t\t\tgranularity = LatencyStats.Granularity.valueOf(configuredGranularity.toUpperCase(Locale.ROOT));\n+\t\t\t} catch (IllegalArgumentException iae) {\n+\t\t\t\tgranularity = LatencyStats.Granularity.OPERATOR;\n+\t\t\t\tLOG.warn(\n+\t\t\t\t\t\"Configured value {} option for {} is invalid. Defaulting to {}.\",\n+\t\t\t\t\tconfiguredGranularity,\n+\t\t\t\t\tMetricOptions.LATENCY_SOURCE_GRANULARITY.key(),\n+\t\t\t\t\tgranularity);\n+\t\t\t}\n+\t\t\tTaskManagerJobMetricGroup jobMetricGroup = this.metrics.parent().parent();\n+\t\t\treturn new LatencyStats(jobMetricGroup.addGroup(\"latency\"),\n+\t\t\t\thistorySize,\n+\t\t\t\tindexInSubtaskGroup,\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgranularity);\n+\t\t} catch (Exception e) {\n+\t\t\tLOG.warn(\"An error occurred while instantiating latency metrics.\", e);\n+\t\t\treturn new LatencyStats(\n+\t\t\t\tUnregisteredMetricGroups.createUnregisteredTaskManagerJobMetricGroup().addGroup(\"latency\"),\n+\t\t\t\t1,\n+\t\t\t\t0,\n+\t\t\t\tnew OperatorID(),\n+\t\t\t\tLatencyStats.Granularity.SINGLE);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic MetricGroup getMetricGroup() {\n+\t\treturn metrics;\n+\t}\n+\n+\t@Override\n+\tpublic final void initializeState(StreamTaskStateInitializer streamTaskStateManager) throws Exception {\n+\t\tfinal TypeSerializer<?> keySerializer = config.getStateKeySerializer(getUserCodeClassloader());\n+\n+\t\tfinal StreamOperatorStateContext context =\n+\t\t\tstreamTaskStateManager.streamOperatorStateContext(\n+\t\t\t\tgetOperatorID(),\n+\t\t\t\tgetClass().getSimpleName(),\n+\t\t\t\tgetProcessingTimeService(),\n+\t\t\t\tthis,\n+\t\t\t\tkeySerializer,\n+\t\t\t\tcancelables,\n+\t\t\t\tmetrics);\n+\n+\t\tstateHandler = new StreamOperatorStateHandler(context, getExecutionConfig(), cancelables);\n+\t\tstateHandler.initializeOperatorState(this::initializeState);\n+\t}\n+\n+\t/**\n+\t * This method is called immediately before any elements are processed, it should contain the\n+\t * operator's initialization logic, e.g. state initialization.\n+\t *\n+\t * <p>The default implementation does nothing.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void open() throws Exception {}\n+\n+\t/**\n+\t * This method is called after all records have been added to the operators via the methods\n+\t * {@link OneInputStreamOperator#processElement(StreamRecord)}, or\n+\t * {@link TwoInputStreamOperator#processElement1(StreamRecord)} and\n+\t * {@link TwoInputStreamOperator#processElement2(StreamRecord)}.\n+\t *\n+\t * <p>The method is expected to flush all remaining buffered data. Exceptions during this flushing\n+\t * of buffered should be propagated, in order to cause the operation to be recognized asa failed,\n+\t * because the last data items are not processed properly.\n+\t *\n+\t * @throws Exception An exception in this method causes the operator to fail.\n+\t */\n+\t@Override\n+\tpublic void close() throws Exception {}\n+\n+\t/**\n+\t * This method is called at the very end of the operator's life, both in the case of a successful\n+\t * completion of the operation, and in the case of a failure and canceling.\n+\t *\n+\t * <p>This method is expected to make a thorough effort to release all resources\n+\t * that the operator has acquired.\n+\t */\n+\t@Override\n+\tpublic void dispose() throws Exception {\n+\t\tif (stateHandler != null) {\n+\t\t\tstateHandler.dispose();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n+\t\t// the default implementation does nothing and accepts the checkpoint\n+\t\t// this is purely for subclasses to override\n+\t}\n+\n+\t@Override\n+\tpublic final OperatorSnapshotFutures snapshotState(long checkpointId, long timestamp, CheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws Exception {\n+\t\treturn stateHandler.snapshotState(\n+\t\t\tthis::snapshotState,\n+\t\t\tgetOperatorName(),\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory);\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context) throws Exception {\n+\t}\n+\n+\t/**\n+\t * Stream operators with state which can be restored need to override this hook method.\n+\t *\n+\t * @param context context that allows to register different states.\n+\t */\n+\tpublic void initializeState(StateInitializationContext context) throws Exception {\n+\n+\t}\n+\n+\t@Override\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tstateHandler.notifyCheckpointComplete(checkpointId);\n+\t}\n+\n+\t// ------------------------------------------------------------------------\n+\t//  Properties and Services\n+\t// ------------------------------------------------------------------------\n+\n+\t/**\n+\t * Gets the execution config defined on the execution environment of the job to which this\n+\t * operator belongs.\n+\t *\n+\t * @return The job's execution config.\n+\t */\n+\tpublic ExecutionConfig getExecutionConfig() {\n+\t\treturn executionConfig;\n+\t}\n+\n+\tpublic StreamConfig getOperatorConfig() {\n+\t\treturn config;\n+\t}\n+\n+\tpublic ClassLoader getUserCodeClassloader() {\n+\t\treturn userCodeClassLoader;\n+\t}\n+\n+\t/**\n+\t * Return the operator name. If the runtime context has been set, then the task name with\n+\t * subtask index is returned. Otherwise, the simple class name is returned.\n+\t *\n+\t * @return If runtime context is set, then return task name with subtask index. Otherwise return\n+\t * \t\t\tsimple class name.\n+\t */\n+\tprotected String getOperatorName() {\n+\t\tif (runtimeContext != null) {\n+\t\t\treturn runtimeContext.getTaskNameWithSubtasks();\n+\t\t} else {\n+\t\t\treturn getClass().getSimpleName();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Returns a context that allows the operator to query information about the execution and also\n+\t * to interact with systems such as broadcast variables and managed state. This also allows\n+\t * to register timers.\n+\t */\n+\tpublic StreamingRuntimeContext getRuntimeContext() {\n+\t\treturn runtimeContext;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) stateHandler.getKeyedStateBackend();\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn stateHandler.getOperatorStateBackend();\n+\t}\n+\n+\t/**\n+\t * Returns the {@link ProcessingTimeService} responsible for getting the current\n+\t * processing time and registering timers.\n+\t */\n+\tpublic ProcessingTimeService getProcessingTimeService() {\n+\t\treturn processingTimeService;\n+\t}", "originalCommit": "b77da7156f766d2c480943434732bed63ff1dc0a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYwODI1OQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396608259", "bodyText": "As I mentioned above, I would prefer to keep it public, but we can mark those methods @VisibleForTesting?", "author": "pnowojski", "createdAt": "2020-03-23T17:01:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM4OTg5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA1OTU4Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397059586", "bodyText": "I'd rather go with protected but I don't think this issue is very important.", "author": "rkhachatryan", "createdAt": "2020-03-24T10:48:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM4OTg5OA=="}], "type": "inlineReview", "revised_code": {"commit": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\nindex b6dd2e1c50..d7683dec04 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/AbstractStreamOperatorV2.java\n\n@@ -90,6 +90,7 @@ public abstract class AbstractStreamOperatorV2<OUT> implements StreamOperator<OU\n \tprotected final ProcessingTimeService processingTimeService;\n \n \tprivate StreamOperatorStateHandler stateHandler;\n+\tprivate InternalTimeServiceManager<?> timeServiceManager;\n \n \t// We keep track of watermarks from both inputs, the combined input is the minimum\n \t// Once the minimum advances we emit a new watermark for downstream operators\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM5NDAwNQ==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396394005", "bodyText": "Regarding having timer-related responsibility in state handler:\n\nWhy not to have getInternalTimerService in the base class (or better outside) and pass stateHandler as a\nparameter? In StreamOperatorStateHandler.snapshotState we can have a parameter similar to\nsnapshotStateAction for timers state.\n\n(sorry for repeating this comment, but I couldn't find an answer)", "author": "rkhachatryan", "createdAt": "2020-03-23T11:50:38Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,411 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyGroupsList;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.KeyedStateCheckpointOutputStream;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.runtime.state.VoidNamespaceSerializer;\n+import org.apache.flink.streaming.api.watermark.Watermark;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final InternalTimeServiceManager<?> timeServiceManager;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\n+\t\ttimeServiceManager = context.internalTimerServiceManager();\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tsnapshotState(snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Stream operators with state, which want to participate in a snapshot need to override this hook method.\n+\t *\n+\t * @param context context that provides information and means required for taking a snapshot\n+\t * @param operatorName\n+\t */\n+\tpublic void snapshotState(StateSnapshotContext context, String operatorName) throws Exception {\n+\t\tfinal KeyedStateBackend<?> keyedStateBackend = getKeyedStateBackend();\n+\t\t//TODO all of this can be removed once heap-based timers are integrated with RocksDB incremental snapshots\n+\t\tif (keyedStateBackend instanceof AbstractKeyedStateBackend &&\n+\t\t\t((AbstractKeyedStateBackend<?>) keyedStateBackend).requiresLegacySynchronousTimerSnapshots()) {\n+\n+\t\t\tKeyedStateCheckpointOutputStream out;\n+\n+\t\t\ttry {\n+\t\t\t\tout = context.getRawKeyedOperatorStateOutput();\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not open raw keyed operator state stream for \" +\n+\t\t\t\t\toperatorName + '.', exception);\n+\t\t\t}\n+\n+\t\t\ttry {\n+\t\t\t\tKeyGroupsList allKeyGroups = out.getKeyGroupList();\n+\t\t\t\tfor (int keyGroupIdx : allKeyGroups) {\n+\t\t\t\t\tout.startNewKeyGroup(keyGroupIdx);\n+\n+\t\t\t\t\ttimeServiceManager.snapshotStateForKeyGroup(\n+\t\t\t\t\t\tnew DataOutputViewStreamWrapper(out), keyGroupIdx);\n+\t\t\t\t}\n+\t\t\t} catch (Exception exception) {\n+\t\t\t\tthrow new Exception(\"Could not write timer service of \" + operatorName +\n+\t\t\t\t\t\" to checkpoint state stream.\", exception);\n+\t\t\t} finally {\n+\t\t\t\ttry {\n+\t\t\t\t\tout.close();\n+\t\t\t\t} catch (Exception closeException) {\n+\t\t\t\t\tLOG.warn(\"Could not close raw keyed operator state stream for {}. This \" +\n+\t\t\t\t\t\t\"might have prevented deleting some state data.\", operatorName, closeException);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Returns a {@link InternalTimerService} that can be used to query current processing time\n+\t * and event time and to set timers. An operator can have several timer services, where\n+\t * each has its own namespace serializer. Timer services are differentiated by the string\n+\t * key that is given when requesting them, if you call this method with the same key\n+\t * multiple times you will get the same timer service instance in subsequent requests.\n+\t *\n+\t * <p>Timers are always scoped to a key, the currently active key of a keyed stream operation.\n+\t * When a timer fires, this key will also be set as the currently active key.\n+\t *\n+\t * <p>Each timer has attached metadata, the namespace. Different timer services\n+\t * can have a different namespace type. If you don't need namespace differentiation you\n+\t * can use {@link VoidNamespaceSerializer} as the namespace serializer.\n+\t *\n+\t * @param name The name of the requested timer service. If no service exists under the given\n+\t *             name a new one will be created and returned.\n+\t * @param namespaceSerializer {@code TypeSerializer} for the timer namespace.\n+\t * @param triggerable The {@link Triggerable} that should be invoked when timers fire\n+\t *\n+\t * @param <N> The type of the timer namespace.\n+\t */\n+\tpublic <K, N> InternalTimerService<N> getInternalTimerService(\n+\t\t\tString name,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tTriggerable<K, N> triggerable) {\n+\n+\t\tcheckTimerServiceInitialization();\n+\n+\t\t// the following casting is to overcome type restrictions.\n+\t\tKeyedStateBackend<K> keyedStateBackend = getKeyedStateBackend();\n+\t\tTypeSerializer<K> keySerializer = keyedStateBackend.getKeySerializer();\n+\t\tInternalTimeServiceManager<K> keyedTimeServiceHandler = (InternalTimeServiceManager<K>) timeServiceManager;\n+\t\tTimerSerializer<K, N> timerSerializer = new TimerSerializer<>(keySerializer, namespaceSerializer);\n+\t\treturn keyedTimeServiceHandler.getInternalTimerService(name, timerSerializer, triggerable);\n+\t}", "originalCommit": "b77da7156f766d2c480943434732bed63ff1dc0a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjQ0NDEzMA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396444130", "bodyText": "What base class do you have in mind? Do you mean to duplicate this code both in AbstractStreamOperator and AbstractStreamOperatorV2? Also what do you mean \"outside\"?", "author": "pnowojski", "createdAt": "2020-03-23T13:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM5NDAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYwNzY5Ng==", "url": "https://github.com/apache/flink/pull/11403#discussion_r396607696", "bodyText": "I have moved the timers snapshotting logic into InternalTimerSerivceManager class", "author": "pnowojski", "createdAt": "2020-03-23T17:00:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjM5NDAwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\nindex 0f1d89e904..ec369d63ad 100644\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n\n@@ -26,7 +26,6 @@ import org.apache.flink.api.common.state.State;\n import org.apache.flink.api.common.state.StateDescriptor;\n import org.apache.flink.api.common.typeutils.TypeSerializer;\n import org.apache.flink.core.fs.CloseableRegistry;\n-import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n import org.apache.flink.runtime.checkpoint.CheckpointException;\n import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n"}}, {"oid": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "url": "https://github.com/apache/flink/commit/b771b91f3a71291eb6926c5521a3e40d55de5a6f", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental", "committedDate": "2020-03-23T17:12:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4MTU1MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397081550", "bodyText": "Operator state snapshot is taken using Consumer snapshotStateAction,\nbut for timeServiceManager we pass it and call directly.\nShould we make it consistent?\nWe could remove opName parameter and then use BiConsumerWithException.\nopName can be turned into a field or exception can be wrapped on a higher level.", "author": "rkhachatryan", "createdAt": "2020-03-24T11:27:39Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+import org.apache.flink.util.function.ThrowingConsumer;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tinitializeOperatorAction.accept(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tsnapshotStateAction,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n+\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\ttimeServiceManager.snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\tsnapshotStateAction.accept(snapshotContext);", "originalCommit": "b771b91f3a71291eb6926c5521a3e40d55de5a6f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzEwNzg0Nw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397107847", "bodyText": "Those kind of interfaces and lambda invocations are hampering the code readability and brake IDE support (find usages/implementations). By using Consumer I was cutting some corners - avoiding defining some extra dedicated interface, so replacing timeServiceManager with BiConsumerWithException would be a step back.\nIf you want I could go the other way, and replace Consumer with some proper interface.", "author": "pnowojski", "createdAt": "2020-03-24T12:16:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4MTU1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzEzODc0NA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397138744", "bodyText": "In terms of readability, it's a tradeoff: I don't know what is going on inside, but I do know how is it used in this method just by looking at its type.\nAnd yes, passing \"functions\" allows to avoid unnecessary interfaces and coupling.\nWith or without them, I think consistency is more important.", "author": "rkhachatryan", "createdAt": "2020-03-24T13:10:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4MTU1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzE3MjI5Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397172292", "bodyText": "I introduced StreamOperatorStateHandler.CheckpointedStreamOperator interface to make it consistent. Can you take a look one more time @rkhachatryan ?", "author": "pnowojski", "createdAt": "2020-03-24T13:58:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzA4MTU1MA=="}], "type": "inlineReview", "revised_code": {"commit": "17a0f2628aad246c23018195a3980e552aca36df", "chunk": "diff --git a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java b/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\ndeleted file mode 100644\nindex ec369d63ad..0000000000\n--- a/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java\n+++ /dev/null\n\n@@ -1,297 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.streaming.api.operators;\n-\n-import org.apache.flink.annotation.Internal;\n-import org.apache.flink.annotation.VisibleForTesting;\n-import org.apache.flink.api.common.ExecutionConfig;\n-import org.apache.flink.api.common.state.KeyedStateStore;\n-import org.apache.flink.api.common.state.State;\n-import org.apache.flink.api.common.state.StateDescriptor;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.core.fs.CloseableRegistry;\n-import org.apache.flink.runtime.checkpoint.CheckpointException;\n-import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n-import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n-import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n-import org.apache.flink.runtime.state.CheckpointStreamFactory;\n-import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n-import org.apache.flink.runtime.state.KeyGroupRange;\n-import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n-import org.apache.flink.runtime.state.KeyedStateBackend;\n-import org.apache.flink.runtime.state.OperatorStateBackend;\n-import org.apache.flink.runtime.state.StateInitializationContext;\n-import org.apache.flink.runtime.state.StateInitializationContextImpl;\n-import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n-import org.apache.flink.runtime.state.StateSnapshotContext;\n-import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n-import org.apache.flink.util.CloseableIterable;\n-import org.apache.flink.util.IOUtils;\n-import org.apache.flink.util.function.ThrowingConsumer;\n-\n-import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.Closeable;\n-import java.io.IOException;\n-import java.util.Optional;\n-\n-/**\n- * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n- */\n-@Internal\n-public class StreamOperatorStateHandler {\n-\n-\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n-\n-\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n-\t@Nullable\n-\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n-\tprivate final CloseableRegistry closeableRegistry;\n-\t@Nullable\n-\tprivate final DefaultKeyedStateStore keyedStateStore;\n-\tprivate final OperatorStateBackend operatorStateBackend;\n-\tprivate final StreamOperatorStateContext context;\n-\n-\tpublic StreamOperatorStateHandler(\n-\t\t\tStreamOperatorStateContext context,\n-\t\t\tExecutionConfig executionConfig,\n-\t\t\tCloseableRegistry closeableRegistry) {\n-\t\tthis.context = context;\n-\t\toperatorStateBackend = context.operatorStateBackend();\n-\t\tkeyedStateBackend = context.keyedStateBackend();\n-\t\tthis.closeableRegistry = closeableRegistry;\n-\n-\t\tif (keyedStateBackend != null) {\n-\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n-\t\t}\n-\t\telse {\n-\t\t\tkeyedStateStore = null;\n-\t\t}\n-\t}\n-\n-\tpublic void initializeOperatorState(ThrowingConsumer<StateInitializationContext, Exception> initializeOperatorAction) throws Exception {\n-\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n-\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n-\n-\t\ttry {\n-\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n-\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n-\t\t\t\toperatorStateBackend, // access to operator state backend\n-\t\t\t\tkeyedStateStore, // access to keyed state backend\n-\t\t\t\tkeyedStateInputs, // access to keyed state stream\n-\t\t\t\toperatorStateInputs); // access to operator state stream\n-\n-\t\t\tinitializeOperatorAction.accept(initializationContext);\n-\t\t} finally {\n-\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n-\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n-\t\t}\n-\t}\n-\n-\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n-\t\tif (registry.unregisterCloseable(closeable)) {\n-\t\t\tIOUtils.closeQuietly(closeable);\n-\t\t}\n-\t}\n-\n-\tpublic void dispose() throws Exception {\n-\t\ttry (Closer closer = Closer.create()) {\n-\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n-\t\t\t\tcloser.register(operatorStateBackend);\n-\t\t\t}\n-\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n-\t\t\t\tcloser.register(keyedStateBackend);\n-\t\t\t}\n-\t\t\tif (operatorStateBackend != null) {\n-\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n-\t\t\t}\n-\t\t\tif (keyedStateBackend != null) {\n-\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\tpublic OperatorSnapshotFutures snapshotState(\n-\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n-\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n-\t\t\tString operatorName,\n-\t\t\tlong checkpointId,\n-\t\t\tlong timestamp,\n-\t\t\tCheckpointOptions checkpointOptions,\n-\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n-\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n-\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n-\n-\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n-\n-\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n-\t\t\tcheckpointId,\n-\t\t\ttimestamp,\n-\t\t\tfactory,\n-\t\t\tkeyGroupRange,\n-\t\t\tcloseableRegistry);\n-\n-\t\tsnapshotState(\n-\t\t\tsnapshotStateAction,\n-\t\t\ttimeServiceManager,\n-\t\t\toperatorName,\n-\t\t\tcheckpointId,\n-\t\t\ttimestamp,\n-\t\t\tcheckpointOptions,\n-\t\t\tfactory,\n-\t\t\tsnapshotInProgress,\n-\t\t\tsnapshotContext);\n-\n-\t\treturn snapshotInProgress;\n-\t}\n-\n-\t@VisibleForTesting\n-\tvoid snapshotState(\n-\t\t\tThrowingConsumer<StateSnapshotContext, Exception> snapshotStateAction,\n-\t\t\tInternalTimeServiceManager<?> timeServiceManager,\n-\t\t\tString operatorName,\n-\t\t\tlong checkpointId,\n-\t\t\tlong timestamp,\n-\t\t\tCheckpointOptions checkpointOptions,\n-\t\t\tCheckpointStreamFactory factory,\n-\t\t\tOperatorSnapshotFutures snapshotInProgress,\n-\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n-\t\ttry {\n-\t\t\ttimeServiceManager.snapshotState(keyedStateBackend, snapshotContext, operatorName);\n-\t\t\tsnapshotStateAction.accept(snapshotContext);\n-\n-\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n-\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n-\n-\t\t\tif (null != operatorStateBackend) {\n-\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n-\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n-\t\t\t}\n-\n-\t\t\tif (null != keyedStateBackend) {\n-\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n-\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n-\t\t\t}\n-\t\t} catch (Exception snapshotException) {\n-\t\t\ttry {\n-\t\t\t\tsnapshotInProgress.cancel();\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tsnapshotException.addSuppressed(e);\n-\t\t\t}\n-\n-\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n-\t\t\t\toperatorName + \".\";\n-\n-\t\t\ttry {\n-\t\t\t\tsnapshotContext.closeExceptionally();\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tsnapshotException.addSuppressed(e);\n-\t\t\t}\n-\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n-\t\t}\n-\t}\n-\n-\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n-\t\tif (keyedStateBackend != null) {\n-\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n-\t\t}\n-\t}\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n-\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n-\t}\n-\n-\tpublic OperatorStateBackend getOperatorStateBackend() {\n-\t\treturn operatorStateBackend;\n-\t}\n-\n-\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n-\t\t\tTypeSerializer<N> namespaceSerializer,\n-\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n-\n-\t\tif (keyedStateStore != null) {\n-\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n-\t\t}\n-\t\telse {\n-\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n-\t\t\t\t\t\"The keyed state backend has not been set.\" +\n-\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n-\t\t}\n-\t}\n-\n-\t/**\n-\t * Creates a partitioned state handle, using the state backend configured for this task.\n-\t *\n-\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n-\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n-\t */\n-\tprotected <S extends State, N> S getPartitionedState(\n-\t\t\tN namespace,\n-\t\t\tTypeSerializer<N> namespaceSerializer,\n-\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n-\n-\t\t/*\n-\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n-\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n-\t    state backend, or being set on the state directly.\n-\t    */\n-\n-\t\tif (keyedStateStore != null) {\n-\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n-\t\t} else {\n-\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n-\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n-\t\t\t\t\"partitioned/keyed.\");\n-\t\t}\n-\t}\n-\n-\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-\tpublic void setCurrentKey(Object key) {\n-\t\tif (keyedStateBackend != null) {\n-\t\t\ttry {\n-\t\t\t\t// need to work around type restrictions\n-\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n-\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n-\n-\t\t\t\trawBackend.setCurrentKey(key);\n-\t\t\t} catch (Exception e) {\n-\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n-\t\t\t}\n-\t\t}\n-\t}\n-\n-\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-\tpublic Object getCurrentKey() {\n-\t\tif (keyedStateBackend != null) {\n-\t\t\treturn keyedStateBackend.getCurrentKey();\n-\t\t} else {\n-\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n-\t\t}\n-\t}\n-\n-\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n-\t\treturn Optional.ofNullable(keyedStateStore);\n-\t}\n-}\n"}}, {"oid": "17a0f2628aad246c23018195a3980e552aca36df", "url": "https://github.com/apache/flink/commit/17a0f2628aad246c23018195a3980e552aca36df", "message": "[FLINK-16316][task] Remove StreamTask dependency from AbstractStreamOperator#snapshotState", "committedDate": "2020-03-24T12:20:06Z", "type": "commit"}, {"oid": "5d5b4fb4bf0ee156f05b465ed3630905114c7358", "url": "https://github.com/apache/flink/commit/5d5b4fb4bf0ee156f05b465ed3630905114c7358", "message": "[FLINK-16316][operators] Remove chaining strategy methods from the StreamOperator interface\n\nThose methods do not have any reason to be on the StreamOperator level since we introduced\nStreamOperatorFactory concept, so they should be moved to SetupableStreamOperator", "committedDate": "2020-03-24T12:20:08Z", "type": "commit"}, {"oid": "d7f53e983fee8f37638fce4b42c86a8f36b8c586", "url": "https://github.com/apache/flink/commit/d7f53e983fee8f37638fce4b42c86a8f36b8c586", "message": "[FLINK-16316][operators] Pass StreamTaskStateInitializer to operators from outside\n\nThis removes another dependency on the StreamTask from AbstractStreamOperator", "committedDate": "2020-03-24T12:20:09Z", "type": "commit"}, {"oid": "80d7744ad7a39cb05fdc1ba6f473f85da9b09ac0", "url": "https://github.com/apache/flink/commit/80d7744ad7a39cb05fdc1ba6f473f85da9b09ac0", "message": "[hotfix][test] Fix formatting in AbstractStreamOperatorTest", "committedDate": "2020-03-24T12:20:10Z", "type": "commit"}, {"oid": "cf3c5304a20da6a7b725f7b8983236ccc5e111f8", "url": "https://github.com/apache/flink/commit/cf3c5304a20da6a7b725f7b8983236ccc5e111f8", "message": "[hotfix][test] Remove no-op tests for AbstractStreamOperator\n\nThose two tests were not performing any assertions since [FLINK-13326] (c75af84d44dfb9b883115bf4fd65b6a5989464e4)", "committedDate": "2020-03-24T12:20:12Z", "type": "commit"}, {"oid": "ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "url": "https://github.com/apache/flink/commit/ab7f6c9a2a2ab86a0fd8fa78a1aab35aa0145533", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental", "committedDate": "2020-03-24T12:20:20Z", "type": "forcePushed"}, {"oid": "af33b0c91276a144e31fe788196f861da3a766f1", "url": "https://github.com/apache/flink/commit/af33b0c91276a144e31fe788196f861da3a766f1", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental", "committedDate": "2020-03-24T13:56:34Z", "type": "forcePushed"}, {"oid": "265474afad0690193c2b195e8293c0f530037335", "url": "https://github.com/apache/flink/commit/265474afad0690193c2b195e8293c0f530037335", "message": "[FLINK-16316][operators] Extract state handling code from AbstractStreamOperator\n\nIntroduce StreamOperatorStateHandler class for that purpose and move more logic into\nIntrenalTimeServiceManager.\n\nThis makes AbstractStreamOperator a simpler class and will allow to deduplicate code with\nnew replacement of AbstractStreamOperator that will come soon.", "committedDate": "2020-03-24T16:05:29Z", "type": "commit"}, {"oid": "b9283b31291a29c829856682b92db1f76b3b59e9", "url": "https://github.com/apache/flink/commit/b9283b31291a29c829856682b92db1f76b3b59e9", "message": "[FLINK-16316][operators] Cut dependency between StreamingRuntimeContext and AbstractStreamOperator\n\nThis simplifies dependencies between those two classes and will allow for StreamingRuntimeContext\nto be re-used in new replacement for AbstractStreamOperator.", "committedDate": "2020-03-24T16:05:30Z", "type": "commit"}, {"oid": "290c2fa43d4bd8ac8e6d21c1bacd7aea010d6332", "url": "https://github.com/apache/flink/commit/290c2fa43d4bd8ac8e6d21c1bacd7aea010d6332", "message": "[FLINK-16316][operators] Move inner CountingClass class out from AbstractStreamOperator", "committedDate": "2020-03-24T16:05:32Z", "type": "commit"}, {"oid": "3d1a3e0164d6ab44c10bc16df582c725ceadc8e5", "url": "https://github.com/apache/flink/commit/3d1a3e0164d6ab44c10bc16df582c725ceadc8e5", "message": "[FLINK-16316][operators] Introduce StreamOperatorParameters class\n\nNew POJO class will make Public and PublicEvolving interfaces more stable\nand easier to use. User will not have to pass n parameters, but just this\none POJO.", "committedDate": "2020-03-24T16:05:33Z", "type": "commit"}, {"oid": "464da82dd19bcbcfda733a1efb185aeff7bb18a8", "url": "https://github.com/apache/flink/commit/464da82dd19bcbcfda733a1efb185aeff7bb18a8", "message": "[FLINK-16316][operators] Implement new AbstractStreamOperatorV2 as a replacement for AbstractStreamOperator\n\nThe new base class for operators tries to address couple of limitations in the AbstractStreamOperator like:\n- lack of support for multiple inputs\n- setup(...) method", "committedDate": "2020-03-24T16:05:34Z", "type": "commit"}, {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580", "url": "https://github.com/apache/flink/commit/ef4235ea44fb27303cc8355de9111fe545e8d580", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental", "committedDate": "2020-03-24T16:05:36Z", "type": "commit"}, {"oid": "ef4235ea44fb27303cc8355de9111fe545e8d580", "url": "https://github.com/apache/flink/commit/ef4235ea44fb27303cc8355de9111fe545e8d580", "message": "[FLINK-16316][operators] Make StreamOperatorFactory Experimental", "committedDate": "2020-03-24T16:05:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5MzM4Mg==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397793382", "bodyText": "This interface is implemented by @PublicEvolving AbstractStreamOperator (which is de-facto API).\nShould it be a top-level @PublicEvolving class then?\nWith Javadoc moved from AbstractStreamOperator into it.", "author": "rkhachatryan", "createdAt": "2020-03-25T11:46:11Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(CheckpointedStreamOperator streamOperator) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tstreamOperator.initializeState(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tstreamOperator,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tif (timeServiceManager.isPresent()) {\n+\t\t\t\tcheckState(keyedStateBackend != null, \"keyedStateBackend should be available with timeServiceManager\");\n+\t\t\t\ttimeServiceManager.get().snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\t}\n+\t\t\tstreamOperator.snapshotState(snapshotContext);\n+\n+\t\t\tsnapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());\n+\t\t\tsnapshotInProgress.setOperatorStateRawFuture(snapshotContext.getOperatorStateStreamFuture());\n+\n+\t\t\tif (null != operatorStateBackend) {\n+\t\t\t\tsnapshotInProgress.setOperatorStateManagedFuture(\n+\t\t\t\t\toperatorStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\n+\t\t\tif (null != keyedStateBackend) {\n+\t\t\t\tsnapshotInProgress.setKeyedStateManagedFuture(\n+\t\t\t\t\tkeyedStateBackend.snapshot(checkpointId, timestamp, factory, checkpointOptions));\n+\t\t\t}\n+\t\t} catch (Exception snapshotException) {\n+\t\t\ttry {\n+\t\t\t\tsnapshotInProgress.cancel();\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\n+\t\t\tString snapshotFailMessage = \"Could not complete snapshot \" + checkpointId + \" for operator \" +\n+\t\t\t\toperatorName + \".\";\n+\n+\t\t\ttry {\n+\t\t\t\tsnapshotContext.closeExceptionally();\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tsnapshotException.addSuppressed(e);\n+\t\t\t}\n+\t\t\tthrow new CheckpointException(snapshotFailMessage, CheckpointFailureReason.CHECKPOINT_DECLINED, snapshotException);\n+\t\t}\n+\t}\n+\n+\tpublic void notifyCheckpointComplete(long checkpointId) throws Exception {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateBackend.notifyCheckpointComplete(checkpointId);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic <K> KeyedStateBackend<K> getKeyedStateBackend() {\n+\t\treturn (KeyedStateBackend<K>) keyedStateBackend;\n+\t}\n+\n+\tpublic OperatorStateBackend getOperatorStateBackend() {\n+\t\treturn operatorStateBackend;\n+\t}\n+\n+\tpublic <N, S extends State, T> S getOrCreateKeyedState(\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, T> stateDescriptor) throws Exception {\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n+\t\t}\n+\t\telse {\n+\t\t\tthrow new IllegalStateException(\"Cannot create partitioned state. \" +\n+\t\t\t\t\t\"The keyed state backend has not been set.\" +\n+\t\t\t\t\t\"This indicates that the operator is not partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a partitioned state handle, using the state backend configured for this task.\n+\t *\n+\t * @throws IllegalStateException Thrown, if the key/value state was already initialized.\n+\t * @throws Exception Thrown, if the state backend cannot create the key/value state.\n+\t */\n+\tprotected <S extends State, N> S getPartitionedState(\n+\t\t\tN namespace,\n+\t\t\tTypeSerializer<N> namespaceSerializer,\n+\t\t\tStateDescriptor<S, ?> stateDescriptor) throws Exception {\n+\n+\t\t/*\n+\t    TODO: NOTE: This method does a lot of work caching / retrieving states just to update the namespace.\n+\t    This method should be removed for the sake of namespaces being lazily fetched from the keyed\n+\t    state backend, or being set on the state directly.\n+\t    */\n+\n+\t\tif (keyedStateStore != null) {\n+\t\t\treturn keyedStateBackend.getPartitionedState(namespace, namespaceSerializer, stateDescriptor);\n+\t\t} else {\n+\t\t\tthrow new RuntimeException(\"Cannot create partitioned state. The keyed state \" +\n+\t\t\t\t\"backend has not been set. This indicates that the operator is not \" +\n+\t\t\t\t\"partitioned/keyed.\");\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic void setCurrentKey(Object key) {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\ttry {\n+\t\t\t\t// need to work around type restrictions\n+\t\t\t\t@SuppressWarnings(\"unchecked,rawtypes\")\n+\t\t\t\tAbstractKeyedStateBackend rawBackend = (AbstractKeyedStateBackend) keyedStateBackend;\n+\n+\t\t\t\trawBackend.setCurrentKey(key);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Exception occurred while setting the current key context.\", e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\tpublic Object getCurrentKey() {\n+\t\tif (keyedStateBackend != null) {\n+\t\t\treturn keyedStateBackend.getCurrentKey();\n+\t\t} else {\n+\t\t\tthrow new UnsupportedOperationException(\"Key can only be retrieved on KeyedStream.\");\n+\t\t}\n+\t}\n+\n+\tpublic Optional<KeyedStateStore> getKeyedStateStore() {\n+\t\treturn Optional.ofNullable(keyedStateStore);\n+\t}\n+\n+\t/**\n+\t * Custom state handling hooks to be invoked by {@link StreamOperatorStateHandler}.\n+\t */\n+\tpublic interface CheckpointedStreamOperator {\n+\t\tvoid initializeState(StateInitializationContext context) throws Exception;\n+\n+\t\tvoid snapshotState(StateSnapshotContext context) throws Exception;\n+\t}", "originalCommit": "ef4235ea44fb27303cc8355de9111fe545e8d580", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzgwNzgxNw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397807817", "bodyText": "My intention was to make this interface @Internal, and making (keeping as they are) those methods @PublicEvolving only on the AbstractStreamOperator level. Maybe it should be turned into @PublicEvolving interface at some point, but I didn't want to commit us to it right now.", "author": "pnowojski", "createdAt": "2020-03-25T12:14:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5MzM4Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NDg3MA==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397794870", "bodyText": "nit: ifPresent could be used instead to get rid of get().\n(exception thrown by snapshotState could/should be runtime)", "author": "rkhachatryan", "createdAt": "2020-03-25T11:49:07Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/StreamOperatorStateHandler.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.state.KeyedStateStore;\n+import org.apache.flink.api.common.state.State;\n+import org.apache.flink.api.common.state.StateDescriptor;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.core.fs.CloseableRegistry;\n+import org.apache.flink.runtime.checkpoint.CheckpointException;\n+import org.apache.flink.runtime.checkpoint.CheckpointFailureReason;\n+import org.apache.flink.runtime.checkpoint.CheckpointOptions;\n+import org.apache.flink.runtime.state.AbstractKeyedStateBackend;\n+import org.apache.flink.runtime.state.CheckpointStreamFactory;\n+import org.apache.flink.runtime.state.DefaultKeyedStateStore;\n+import org.apache.flink.runtime.state.KeyGroupRange;\n+import org.apache.flink.runtime.state.KeyGroupStatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.KeyedStateBackend;\n+import org.apache.flink.runtime.state.OperatorStateBackend;\n+import org.apache.flink.runtime.state.StateInitializationContext;\n+import org.apache.flink.runtime.state.StateInitializationContextImpl;\n+import org.apache.flink.runtime.state.StatePartitionStreamProvider;\n+import org.apache.flink.runtime.state.StateSnapshotContext;\n+import org.apache.flink.runtime.state.StateSnapshotContextSynchronousImpl;\n+import org.apache.flink.util.CloseableIterable;\n+import org.apache.flink.util.IOUtils;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.io.Closer;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * Class encapsulating various state backend handling logic for {@link StreamOperator} implementations.\n+ */\n+@Internal\n+public class StreamOperatorStateHandler {\n+\n+\tprotected static final Logger LOG = LoggerFactory.getLogger(StreamOperatorStateHandler.class);\n+\n+\t/** Backend for keyed state. This might be empty if we're not on a keyed stream. */\n+\t@Nullable\n+\tprivate final AbstractKeyedStateBackend<?> keyedStateBackend;\n+\tprivate final CloseableRegistry closeableRegistry;\n+\t@Nullable\n+\tprivate final DefaultKeyedStateStore keyedStateStore;\n+\tprivate final OperatorStateBackend operatorStateBackend;\n+\tprivate final StreamOperatorStateContext context;\n+\n+\tpublic StreamOperatorStateHandler(\n+\t\t\tStreamOperatorStateContext context,\n+\t\t\tExecutionConfig executionConfig,\n+\t\t\tCloseableRegistry closeableRegistry) {\n+\t\tthis.context = context;\n+\t\toperatorStateBackend = context.operatorStateBackend();\n+\t\tkeyedStateBackend = context.keyedStateBackend();\n+\t\tthis.closeableRegistry = closeableRegistry;\n+\n+\t\tif (keyedStateBackend != null) {\n+\t\t\tkeyedStateStore = new DefaultKeyedStateStore(keyedStateBackend, executionConfig);\n+\t\t}\n+\t\telse {\n+\t\t\tkeyedStateStore = null;\n+\t\t}\n+\t}\n+\n+\tpublic void initializeOperatorState(CheckpointedStreamOperator streamOperator) throws Exception {\n+\t\tCloseableIterable<KeyGroupStatePartitionStreamProvider> keyedStateInputs = context.rawKeyedStateInputs();\n+\t\tCloseableIterable<StatePartitionStreamProvider> operatorStateInputs = context.rawOperatorStateInputs();\n+\n+\t\ttry {\n+\t\t\tStateInitializationContext initializationContext = new StateInitializationContextImpl(\n+\t\t\t\tcontext.isRestored(), // information whether we restore or start for the first time\n+\t\t\t\toperatorStateBackend, // access to operator state backend\n+\t\t\t\tkeyedStateStore, // access to keyed state backend\n+\t\t\t\tkeyedStateInputs, // access to keyed state stream\n+\t\t\t\toperatorStateInputs); // access to operator state stream\n+\n+\t\t\tstreamOperator.initializeState(initializationContext);\n+\t\t} finally {\n+\t\t\tcloseFromRegistry(operatorStateInputs, closeableRegistry);\n+\t\t\tcloseFromRegistry(keyedStateInputs, closeableRegistry);\n+\t\t}\n+\t}\n+\n+\tprivate static void closeFromRegistry(Closeable closeable, CloseableRegistry registry) {\n+\t\tif (registry.unregisterCloseable(closeable)) {\n+\t\t\tIOUtils.closeQuietly(closeable);\n+\t\t}\n+\t}\n+\n+\tpublic void dispose() throws Exception {\n+\t\ttry (Closer closer = Closer.create()) {\n+\t\t\tif (closeableRegistry.unregisterCloseable(operatorStateBackend)) {\n+\t\t\t\tcloser.register(operatorStateBackend);\n+\t\t\t}\n+\t\t\tif (closeableRegistry.unregisterCloseable(keyedStateBackend)) {\n+\t\t\t\tcloser.register(keyedStateBackend);\n+\t\t\t}\n+\t\t\tif (operatorStateBackend != null) {\n+\t\t\t\tcloser.register(() -> operatorStateBackend.dispose());\n+\t\t\t}\n+\t\t\tif (keyedStateBackend != null) {\n+\t\t\t\tcloser.register(() -> keyedStateBackend.dispose());\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic OperatorSnapshotFutures snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory) throws CheckpointException {\n+\t\tKeyGroupRange keyGroupRange = null != keyedStateBackend ?\n+\t\t\tkeyedStateBackend.getKeyGroupRange() : KeyGroupRange.EMPTY_KEY_GROUP_RANGE;\n+\n+\t\tOperatorSnapshotFutures snapshotInProgress = new OperatorSnapshotFutures();\n+\n+\t\tStateSnapshotContextSynchronousImpl snapshotContext = new StateSnapshotContextSynchronousImpl(\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tfactory,\n+\t\t\tkeyGroupRange,\n+\t\t\tcloseableRegistry);\n+\n+\t\tsnapshotState(\n+\t\t\tstreamOperator,\n+\t\t\ttimeServiceManager,\n+\t\t\toperatorName,\n+\t\t\tcheckpointId,\n+\t\t\ttimestamp,\n+\t\t\tcheckpointOptions,\n+\t\t\tfactory,\n+\t\t\tsnapshotInProgress,\n+\t\t\tsnapshotContext);\n+\n+\t\treturn snapshotInProgress;\n+\t}\n+\n+\t@VisibleForTesting\n+\tvoid snapshotState(\n+\t\t\tCheckpointedStreamOperator streamOperator,\n+\t\t\tOptional<InternalTimeServiceManager<?>> timeServiceManager,\n+\t\t\tString operatorName,\n+\t\t\tlong checkpointId,\n+\t\t\tlong timestamp,\n+\t\t\tCheckpointOptions checkpointOptions,\n+\t\t\tCheckpointStreamFactory factory,\n+\t\t\tOperatorSnapshotFutures snapshotInProgress,\n+\t\t\tStateSnapshotContextSynchronousImpl snapshotContext) throws CheckpointException {\n+\t\ttry {\n+\t\t\tif (timeServiceManager.isPresent()) {\n+\t\t\t\tcheckState(keyedStateBackend != null, \"keyedStateBackend should be available with timeServiceManager\");\n+\t\t\t\ttimeServiceManager.get().snapshotState(keyedStateBackend, snapshotContext, operatorName);\n+\t\t\t}", "originalCommit": "ef4235ea44fb27303cc8355de9111fe545e8d580", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzgwNjIzNw==", "url": "https://github.com/apache/flink/pull/11403#discussion_r397806237", "bodyText": "I know :/ I was thinking about it, but it's not worth it because of wrapping and unwrapping the exception. (exception thrown by snapshotState shouldn't be runtime)", "author": "pnowojski", "createdAt": "2020-03-25T12:11:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc5NDg3MA=="}], "type": "inlineReview", "revised_code": null}]}