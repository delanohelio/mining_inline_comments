{"pr_number": 13449, "pr_title": "[FLINK-19282][table sql/planner]Supports watermark push down with Wat\u2026", "pr_createdAt": "2020-09-22T04:41:20Z", "pr_url": "https://github.com/apache/flink/pull/13449", "timeline": [{"oid": "cf69333ccf949c116ede01138e2b01e78c624f2f", "url": "https://github.com/apache/flink/commit/cf69333ccf949c116ede01138e2b01e78c624f2f", "message": "add rule to push WatermarkStrategy into table source scan", "committedDate": "2020-09-24T09:41:21Z", "type": "forcePushed"}, {"oid": "28d25983818d7805f6708b36125a65a493d03aa9", "url": "https://github.com/apache/flink/commit/28d25983818d7805f6708b36125a65a493d03aa9", "message": "add rule and refactor TestValuesTableSource", "committedDate": "2020-09-25T02:53:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzNzM1Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497237353", "bodyText": "it's better to add some comments about \"@deprecated\" action", "author": "godfreyhe", "createdAt": "2020-09-30T04:33:26Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/source/abilities/PeriodicWatermarkAssignerProvider.java", "diffHunk": "@@ -28,6 +28,7 @@\n  * generating watermarks in {@link ScanTableSource}.\n  */\n @PublicEvolving\n+@Deprecated", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/source/abilities/PeriodicWatermarkAssignerProvider.java b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/source/SourceProvider.java\nsimilarity index 54%\nrename from flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/source/abilities/PeriodicWatermarkAssignerProvider.java\nrename to flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/source/SourceProvider.java\nindex 407887d242c..256cd1413ba 100644\n--- a/flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/source/abilities/PeriodicWatermarkAssignerProvider.java\n+++ b/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/source/SourceProvider.java\n\n@@ -16,20 +16,38 @@\n  * limitations under the License.\n  */\n \n-package org.apache.flink.table.connector.source.abilities;\n+package org.apache.flink.table.connector.source;\n \n import org.apache.flink.annotation.PublicEvolving;\n-import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks;\n-import org.apache.flink.table.connector.source.ScanTableSource;\n+import org.apache.flink.api.connector.source.Boundedness;\n+import org.apache.flink.api.connector.source.Source;\n import org.apache.flink.table.data.RowData;\n \n /**\n- * Provider of an {@link AssignerWithPeriodicWatermarks} instance as a runtime implementation for\n- * generating watermarks in {@link ScanTableSource}.\n+ * Provider of a {@link Source} instance as a runtime implementation for {@link ScanTableSource}.\n  */\n @PublicEvolving\n-@Deprecated\n-public interface PeriodicWatermarkAssignerProvider extends SupportsWatermarkPushDown.WatermarkProvider {\n+public interface SourceProvider extends ScanTableSource.ScanRuntimeProvider {\n \n-\tAssignerWithPeriodicWatermarks<RowData> getPeriodicWatermarkAssigner();\n+\t/**\n+\t * Helper method for creating a static provider.\n+\t */\n+\tstatic SourceProvider of(Source<RowData, ?, ?> source) {\n+\t\treturn new SourceProvider() {\n+\t\t\t@Override\n+\t\t\tpublic Source<RowData, ?, ?> createSource() {\n+\t\t\t\treturn source;\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic boolean isBounded() {\n+\t\t\t\treturn Boundedness.BOUNDED.equals(source.getBoundedness());\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Creates a {@link Source} instance.\n+\t */\n+\tSource<RowData, ?, ?> createSource();\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzODAzMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497238032", "bodyText": "please add some comments to explain the purpose of this rule", "author": "godfreyhe", "createdAt": "2020-09-30T04:36:31Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 58%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex 70849cb5c02..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -24,7 +24,6 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzOTQzNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497239434", "bodyText": "add static identifier and add serialVersionUID field", "author": "godfreyhe", "createdAt": "2020-09-30T04:42:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(\n+\t\t\t\tscan.getCluster(), scan.getTraitSet(), scan.getHints(), newTableSourceTable);\n+\n+\t\tcall.transformTo(newScan);\n+\t}\n+\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {\n+\t\tprivate final Configuration configuration;\n+\t\tprivate final GeneratedWatermarkGenerator generatedWatermarkGenerator;\n+\n+\t\tpublic DefaultWatermarkGeneratorSupplier(Configuration configuration, GeneratedWatermarkGenerator generatedWatermarkGenerator) {\n+\t\t\tthis.configuration = configuration;\n+\t\t\tthis.generatedWatermarkGenerator = generatedWatermarkGenerator;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic WatermarkGenerator<RowData> createWatermarkGenerator(Context context) {\n+\n+\t\t\tList<Object> references = new ArrayList<>(Arrays.asList(generatedWatermarkGenerator.getReferences()));\n+\t\t\treferences.add(context);\n+\n+\t\t\torg.apache.flink.table.runtime.generated.WatermarkGenerator innerWatermarkGenerator =\n+\t\t\t\t\tnew GeneratedWatermarkGenerator(\n+\t\t\t\t\t\tgeneratedWatermarkGenerator.getClassName(),\n+\t\t\t\t\t\tgeneratedWatermarkGenerator.getCode(),\n+\t\t\t\t\t\treferences.toArray())\n+\t\t\t\t\t\t\t.newInstance(Thread.currentThread().getContextClassLoader());\n+\n+\t\t\ttry {\n+\t\t\t\tinnerWatermarkGenerator.open(configuration);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Fail to instantiate generated watermark generator.\", e);\n+\t\t\t}\n+\t\t\treturn new DefaultWatermarkGenerator(innerWatermarkGenerator);\n+\t\t}\n+\n+\t\tprivate class DefaultWatermarkGenerator implements WatermarkGenerator<RowData> {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 58%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex 70849cb5c02..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -24,7 +24,6 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzOTgzMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497239831", "bodyText": "add serialVersionUID field", "author": "godfreyhe", "createdAt": "2020-09-30T04:43:58Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(\n+\t\t\t\tscan.getCluster(), scan.getTraitSet(), scan.getHints(), newTableSourceTable);\n+\n+\t\tcall.transformTo(newScan);\n+\t}\n+\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 58%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex 70849cb5c02..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -24,7 +24,6 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMDI3Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500800277", "bodyText": "nit: use LogicalTableScan.create instead", "author": "godfreyhe", "createdAt": "2020-10-07T07:39:18Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 58%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex 70849cb5c02..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -24,7 +24,6 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMjUwNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500802505", "bodyText": "please add some comments to explain the purpose of this rule", "author": "godfreyhe", "createdAt": "2020-10-07T07:43:04Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\ndeleted file mode 100644\nindex ca8fdb6c53a..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-/**\n- * WatermarkAssignerProjectTransposeRule.\n- * */\n-public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n-\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n-\n-\tpublic WatermarkAssignerProjectTransposeRule() {\n-\t\tsuper(operand(LogicalWatermarkAssigner.class,\n-\t\t\t\toperand(LogicalProject.class,\n-\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n-\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n-\t}\n-\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalTableScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n-\t\tLogicalProject project = call.rel(1);\n-\n-\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n-\n-\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\treturn computedColumn;\n-\t\t\t}\n-\t\t});\n-\n-\t\t// use -1 to indicate rowtime column is not in scan and watermark generator has to calculate it.\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner =\n-\t\t\t\t(LogicalWatermarkAssigner) watermarkAssigner.copy(watermarkAssigner.getTraitSet(),\n-\t\t\t\tproject.getInput(),\n-\t\t\t\t-1,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\tList<RexNode> newProjections = new ArrayList<>(project.getProjects());\n-\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\n-\t\t// cast timestamp type to rowtime type.\n-\t\tRexNode newRexNode = builder.makeReinterpretCast(\n-\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n-\t\t\t\tnewProjections.get(watermarkAssigner.rowtimeFieldIndex()),\n-\t\t\t\tnull);\n-\t\tnewProjections.set(watermarkAssigner.rowtimeFieldIndex(), newRexNode);\n-\t\tLogicalProject newProject = project.copy(\n-\t\t\t\tproject.getTraitSet(),\n-\t\t\t\tnewWatermarkAssigner,\n-\t\t\t\tnewProjections,\n-\t\t\t\twatermarkAssigner.getRowType());\n-\n-\t\tcall.transformTo(newProject);\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMzM1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500803358", "bodyText": "do all input refs in watermark expression are from rowtime field ?", "author": "godfreyhe", "createdAt": "2020-10-07T07:44:37Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n+\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+\n+\tpublic WatermarkAssignerProjectTransposeRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalProject.class,\n+\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n+\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalProject project = call.rel(1);\n+\n+\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn computedColumn;", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE4MTUzNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r502181535", "bodyText": "Yes. Currelty, flink doesn't support define computed column on computed column.", "author": "fsk119", "createdAt": "2020-10-09T04:21:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMzM1OA=="}], "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\ndeleted file mode 100644\nindex ca8fdb6c53a..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-/**\n- * WatermarkAssignerProjectTransposeRule.\n- * */\n-public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n-\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n-\n-\tpublic WatermarkAssignerProjectTransposeRule() {\n-\t\tsuper(operand(LogicalWatermarkAssigner.class,\n-\t\t\t\toperand(LogicalProject.class,\n-\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n-\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n-\t}\n-\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalTableScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n-\t\tLogicalProject project = call.rel(1);\n-\n-\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n-\n-\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\treturn computedColumn;\n-\t\t\t}\n-\t\t});\n-\n-\t\t// use -1 to indicate rowtime column is not in scan and watermark generator has to calculate it.\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner =\n-\t\t\t\t(LogicalWatermarkAssigner) watermarkAssigner.copy(watermarkAssigner.getTraitSet(),\n-\t\t\t\tproject.getInput(),\n-\t\t\t\t-1,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\tList<RexNode> newProjections = new ArrayList<>(project.getProjects());\n-\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\n-\t\t// cast timestamp type to rowtime type.\n-\t\tRexNode newRexNode = builder.makeReinterpretCast(\n-\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n-\t\t\t\tnewProjections.get(watermarkAssigner.rowtimeFieldIndex()),\n-\t\t\t\tnull);\n-\t\tnewProjections.set(watermarkAssigner.rowtimeFieldIndex(), newRexNode);\n-\t\tLogicalProject newProject = project.copy(\n-\t\t\t\tproject.getTraitSet(),\n-\t\t\t\tnewWatermarkAssigner,\n-\t\t\t\tnewProjections,\n-\t\t\t\twatermarkAssigner.getRowType());\n-\n-\t\tcall.transformTo(newProject);\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxMzkyNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500813924", "bodyText": "could this rule push watermark into scan directly? then we need not to change the semantic of  LogicalWatermarkAssigner#rowtimeFieldIndex. It's a little strange rowtimeFieldIndex is -1. ( we can extract a base class for PushWatermarkIntoTableSourceScanRule and WatermarkAssignerProjectTransposeRule)", "author": "godfreyhe", "createdAt": "2020-10-07T08:01:58Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n+\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+\n+\tpublic WatermarkAssignerProjectTransposeRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalProject.class,\n+\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n+\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalProject project = call.rel(1);\n+\n+\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn computedColumn;\n+\t\t\t}\n+\t\t});\n+\n+\t\t// use -1 to indicate rowtime column is not in scan and watermark generator has to calculate it.\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner =\n+\t\t\t\t(LogicalWatermarkAssigner) watermarkAssigner.copy(watermarkAssigner.getTraitSet(),\n+\t\t\t\tproject.getInput(),\n+\t\t\t\t-1,", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\ndeleted file mode 100644\nindex ca8fdb6c53a..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-/**\n- * WatermarkAssignerProjectTransposeRule.\n- * */\n-public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n-\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n-\n-\tpublic WatermarkAssignerProjectTransposeRule() {\n-\t\tsuper(operand(LogicalWatermarkAssigner.class,\n-\t\t\t\toperand(LogicalProject.class,\n-\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n-\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n-\t}\n-\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalTableScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n-\t\tLogicalProject project = call.rel(1);\n-\n-\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n-\n-\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\treturn computedColumn;\n-\t\t\t}\n-\t\t});\n-\n-\t\t// use -1 to indicate rowtime column is not in scan and watermark generator has to calculate it.\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner =\n-\t\t\t\t(LogicalWatermarkAssigner) watermarkAssigner.copy(watermarkAssigner.getTraitSet(),\n-\t\t\t\tproject.getInput(),\n-\t\t\t\t-1,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\tList<RexNode> newProjections = new ArrayList<>(project.getProjects());\n-\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\n-\t\t// cast timestamp type to rowtime type.\n-\t\tRexNode newRexNode = builder.makeReinterpretCast(\n-\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n-\t\t\t\tnewProjections.get(watermarkAssigner.rowtimeFieldIndex()),\n-\t\t\t\tnull);\n-\t\tnewProjections.set(watermarkAssigner.rowtimeFieldIndex(), newRexNode);\n-\t\tLogicalProject newProject = project.copy(\n-\t\t\t\tproject.getTraitSet(),\n-\t\t\t\tnewWatermarkAssigner,\n-\t\t\t\tnewProjections,\n-\t\t\t\twatermarkAssigner.getRowType());\n-\n-\t\tcall.transformTo(newProject);\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxNjE4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500816180", "bodyText": "give some more meaningful comments", "author": "godfreyhe", "createdAt": "2020-10-07T08:05:48Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.factories;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.io.CollectionInputFormat;\n+import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.RuntimeConverter;\n+import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n+import org.apache.flink.table.connector.source.InputFormatProvider;\n+import org.apache.flink.table.connector.source.LookupTableSource;\n+import org.apache.flink.table.connector.source.ScanTableSource;\n+import org.apache.flink.table.connector.source.SourceFunctionProvider;\n+import org.apache.flink.table.connector.source.TableFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.functions.AsyncTableFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.InstantiationUtil;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Base class.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java\ndeleted file mode 100644\nindex c7facbafab3..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java\n+++ /dev/null\n\n@@ -1,174 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.factories;\n-\n-import org.apache.flink.api.common.ExecutionConfig;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.api.java.io.CollectionInputFormat;\n-import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n-import org.apache.flink.table.api.TableException;\n-import org.apache.flink.table.api.TableSchema;\n-import org.apache.flink.table.connector.ChangelogMode;\n-import org.apache.flink.table.connector.RuntimeConverter;\n-import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n-import org.apache.flink.table.connector.source.InputFormatProvider;\n-import org.apache.flink.table.connector.source.LookupTableSource;\n-import org.apache.flink.table.connector.source.ScanTableSource;\n-import org.apache.flink.table.connector.source.SourceFunctionProvider;\n-import org.apache.flink.table.connector.source.TableFunctionProvider;\n-import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.functions.AsyncTableFunction;\n-import org.apache.flink.table.functions.TableFunction;\n-import org.apache.flink.types.Row;\n-import org.apache.flink.util.InstantiationUtil;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-/**\n- * Base class.\n- * */\n-public abstract class TestValuesTableSourceBase implements ScanTableSource, LookupTableSource {\n-\n-\tprotected TableSchema physicalSchema;\n-\tprotected final ChangelogMode changelogMode;\n-\tprotected final boolean bounded;\n-\tprotected final String runtimeSource;\n-\t/* If source table is not partitionable, we will put all data into a emptyMap. */\n-\tprotected Map<Map<String, String>, Collection<Row>> data;\n-\tprotected final boolean isAsync;\n-\tprotected final @Nullable String lookupFunctionClass;\n-\n-\tprotected TestValuesTableSourceBase(\n-\t\t\tTableSchema physicalSchema,\n-\t\t\tChangelogMode changelogMode,\n-\t\t\tboolean bounded,\n-\t\t\tString runtimeSource,\n-\t\t\tMap<Map<String, String>, Collection<Row>> data,\n-\t\t\tboolean isAsync,\n-\t\t\t@Nullable String lookupFunctionClass) {\n-\t\tthis.physicalSchema = physicalSchema;\n-\t\tthis.changelogMode = changelogMode;\n-\t\tthis.bounded = bounded;\n-\t\tthis.runtimeSource = runtimeSource;\n-\t\tthis.data = data;\n-\t\tthis.isAsync = isAsync;\n-\t\tthis.lookupFunctionClass = lookupFunctionClass;\n-\t}\n-\n-\t@Override\n-\tpublic ChangelogMode getChangelogMode() {\n-\t\treturn changelogMode;\n-\t}\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\t@Override\n-\tpublic ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderContext) {\n-\t\tTypeSerializer<RowData> serializer = (TypeSerializer<RowData>) runtimeProviderContext\n-\t\t\t\t.createTypeInformation(physicalSchema.toRowDataType())\n-\t\t\t\t.createSerializer(new ExecutionConfig());\n-\t\tDataStructureConverter converter = runtimeProviderContext.createDataStructureConverter(physicalSchema.toRowDataType());\n-\t\tconverter.open(RuntimeConverter.Context.create(TestValuesTableFactory.class.getClassLoader()));\n-\t\tCollection<RowData> values = convertToRowData(converter);\n-\n-\t\tif (runtimeSource.equals(\"SourceFunction\")) {\n-\t\t\ttry {\n-\t\t\t\treturn SourceFunctionProvider.of(\n-\t\t\t\t\t\tnew FromElementsFunction<>(serializer, values),\n-\t\t\t\t\t\tbounded);\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tthrow new TableException(\"Fail to init source function\", e);\n-\t\t\t}\n-\t\t} else if (runtimeSource.equals(\"InputFormat\")) {\n-\t\t\treturn InputFormatProvider.of(new CollectionInputFormat<>(values, serializer));\n-\t\t} else {\n-\t\t\tthrow new IllegalArgumentException(\"Unsupported runtime source class: \" + runtimeSource);\n-\t\t}\n-\t}\n-\n-\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-\t@Override\n-\tpublic LookupRuntimeProvider getLookupRuntimeProvider(LookupContext context) {\n-\t\tif (lookupFunctionClass != null) {\n-\t\t\t// use the specified lookup function\n-\t\t\ttry {\n-\t\t\t\tClass<?> clazz = Class.forName(lookupFunctionClass);\n-\t\t\t\tObject udtf = InstantiationUtil.instantiate(clazz);\n-\t\t\t\tif (udtf instanceof TableFunction) {\n-\t\t\t\t\treturn TableFunctionProvider.of((TableFunction) udtf);\n-\t\t\t\t} else {\n-\t\t\t\t\treturn AsyncTableFunctionProvider.of((AsyncTableFunction) udtf);\n-\t\t\t\t}\n-\t\t\t} catch (ClassNotFoundException e) {\n-\t\t\t\tthrow new IllegalArgumentException(\"Could not instantiate class: \" + lookupFunctionClass);\n-\t\t\t}\n-\t\t}\n-\n-\t\tint[] lookupIndices = Arrays.stream(context.getKeys())\n-\t\t\t\t.mapToInt(k -> k[0])\n-\t\t\t\t.toArray();\n-\t\tMap<Row, List<Row>> mapping = new HashMap<>();\n-\n-\t\tdata.get(Collections.emptyMap()).forEach(record -> {\n-\t\t\tRow key = Row.of(Arrays.stream(lookupIndices)\n-\t\t\t\t\t.mapToObj(record::getField)\n-\t\t\t\t\t.toArray());\n-\t\t\tList<Row> list = mapping.get(key);\n-\t\t\tif (list != null) {\n-\t\t\t\tlist.add(record);\n-\t\t\t} else {\n-\t\t\t\tlist = new ArrayList<>();\n-\t\t\t\tlist.add(record);\n-\t\t\t\tmapping.put(key, list);\n-\t\t\t}\n-\t\t});\n-\t\tif (isAsync) {\n-\t\t\treturn AsyncTableFunctionProvider.of(new TestValuesRuntimeFunctions.AsyncTestValueLookupFunction(mapping));\n-\t\t} else {\n-\t\t\treturn TableFunctionProvider.of(new TestValuesRuntimeFunctions.TestValuesLookupFunction(mapping));\n-\t\t}\n-\t}\n-\n-\tprotected Collection<RowData> convertToRowData(DataStructureConverter converter) {\n-\t\tList<RowData> result = new ArrayList<>();\n-\t\tfor (Row value : handle()) {\n-\t\t\tRowData rowData = (RowData) converter.toInternal(value);\n-\t\t\tif (rowData != null) {\n-\t\t\t\trowData.setRowKind(value.getKind());\n-\t\t\t\tresult.add(rowData);\n-\t\t\t}\n-\t\t}\n-\t\treturn result;\n-\t}\n-\n-\t/*\n-\t* Used by apply method to deal with.\n-\t* */\n-\tpublic Collection<Row> handle() {\n-\t\treturn data.get(Collections.emptyMap());\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxODg0Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500818843", "bodyText": "/**\n * \n */", "author": "godfreyhe", "createdAt": "2020-10-07T08:10:10Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.factories;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.io.CollectionInputFormat;\n+import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.RuntimeConverter;\n+import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n+import org.apache.flink.table.connector.source.InputFormatProvider;\n+import org.apache.flink.table.connector.source.LookupTableSource;\n+import org.apache.flink.table.connector.source.ScanTableSource;\n+import org.apache.flink.table.connector.source.SourceFunctionProvider;\n+import org.apache.flink.table.connector.source.TableFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.functions.AsyncTableFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.InstantiationUtil;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Base class.\n+ * */\n+public abstract class TestValuesTableSourceBase implements ScanTableSource, LookupTableSource {\n+\n+\tprotected TableSchema physicalSchema;\n+\tprotected final ChangelogMode changelogMode;\n+\tprotected final boolean bounded;\n+\tprotected final String runtimeSource;\n+\t/* If source table is not partitionable, we will put all data into a emptyMap. */\n+\tprotected Map<Map<String, String>, Collection<Row>> data;\n+\tprotected final boolean isAsync;\n+\tprotected final @Nullable String lookupFunctionClass;\n+\n+\tprotected TestValuesTableSourceBase(\n+\t\t\tTableSchema physicalSchema,\n+\t\t\tChangelogMode changelogMode,\n+\t\t\tboolean bounded,\n+\t\t\tString runtimeSource,\n+\t\t\tMap<Map<String, String>, Collection<Row>> data,\n+\t\t\tboolean isAsync,\n+\t\t\t@Nullable String lookupFunctionClass) {\n+\t\tthis.physicalSchema = physicalSchema;\n+\t\tthis.changelogMode = changelogMode;\n+\t\tthis.bounded = bounded;\n+\t\tthis.runtimeSource = runtimeSource;\n+\t\tthis.data = data;\n+\t\tthis.isAsync = isAsync;\n+\t\tthis.lookupFunctionClass = lookupFunctionClass;\n+\t}\n+\n+\t@Override\n+\tpublic ChangelogMode getChangelogMode() {\n+\t\treturn changelogMode;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\t@Override\n+\tpublic ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderContext) {\n+\t\tTypeSerializer<RowData> serializer = (TypeSerializer<RowData>) runtimeProviderContext\n+\t\t\t\t.createTypeInformation(physicalSchema.toRowDataType())\n+\t\t\t\t.createSerializer(new ExecutionConfig());\n+\t\tDataStructureConverter converter = runtimeProviderContext.createDataStructureConverter(physicalSchema.toRowDataType());\n+\t\tconverter.open(RuntimeConverter.Context.create(TestValuesTableFactory.class.getClassLoader()));\n+\t\tCollection<RowData> values = convertToRowData(converter);\n+\n+\t\tif (runtimeSource.equals(\"SourceFunction\")) {\n+\t\t\ttry {\n+\t\t\t\treturn SourceFunctionProvider.of(\n+\t\t\t\t\t\tnew FromElementsFunction<>(serializer, values),\n+\t\t\t\t\t\tbounded);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new TableException(\"Fail to init source function\", e);\n+\t\t\t}\n+\t\t} else if (runtimeSource.equals(\"InputFormat\")) {\n+\t\t\treturn InputFormatProvider.of(new CollectionInputFormat<>(values, serializer));\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"Unsupported runtime source class: \" + runtimeSource);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\t@Override\n+\tpublic LookupRuntimeProvider getLookupRuntimeProvider(LookupContext context) {\n+\t\tif (lookupFunctionClass != null) {\n+\t\t\t// use the specified lookup function\n+\t\t\ttry {\n+\t\t\t\tClass<?> clazz = Class.forName(lookupFunctionClass);\n+\t\t\t\tObject udtf = InstantiationUtil.instantiate(clazz);\n+\t\t\t\tif (udtf instanceof TableFunction) {\n+\t\t\t\t\treturn TableFunctionProvider.of((TableFunction) udtf);\n+\t\t\t\t} else {\n+\t\t\t\t\treturn AsyncTableFunctionProvider.of((AsyncTableFunction) udtf);\n+\t\t\t\t}\n+\t\t\t} catch (ClassNotFoundException e) {\n+\t\t\t\tthrow new IllegalArgumentException(\"Could not instantiate class: \" + lookupFunctionClass);\n+\t\t\t}\n+\t\t}\n+\n+\t\tint[] lookupIndices = Arrays.stream(context.getKeys())\n+\t\t\t\t.mapToInt(k -> k[0])\n+\t\t\t\t.toArray();\n+\t\tMap<Row, List<Row>> mapping = new HashMap<>();\n+\n+\t\tdata.get(Collections.emptyMap()).forEach(record -> {\n+\t\t\tRow key = Row.of(Arrays.stream(lookupIndices)\n+\t\t\t\t\t.mapToObj(record::getField)\n+\t\t\t\t\t.toArray());\n+\t\t\tList<Row> list = mapping.get(key);\n+\t\t\tif (list != null) {\n+\t\t\t\tlist.add(record);\n+\t\t\t} else {\n+\t\t\t\tlist = new ArrayList<>();\n+\t\t\t\tlist.add(record);\n+\t\t\t\tmapping.put(key, list);\n+\t\t\t}\n+\t\t});\n+\t\tif (isAsync) {\n+\t\t\treturn AsyncTableFunctionProvider.of(new TestValuesRuntimeFunctions.AsyncTestValueLookupFunction(mapping));\n+\t\t} else {\n+\t\t\treturn TableFunctionProvider.of(new TestValuesRuntimeFunctions.TestValuesLookupFunction(mapping));\n+\t\t}\n+\t}\n+\n+\tprotected Collection<RowData> convertToRowData(DataStructureConverter converter) {\n+\t\tList<RowData> result = new ArrayList<>();\n+\t\tfor (Row value : handle()) {\n+\t\t\tRowData rowData = (RowData) converter.toInternal(value);\n+\t\t\tif (rowData != null) {\n+\t\t\t\trowData.setRowKind(value.getKind());\n+\t\t\t\tresult.add(rowData);\n+\t\t\t}\n+\t\t}\n+\t\treturn result;\n+\t}\n+\n+\t/*\n+\t* Used by apply method to deal with.\n+\t* */", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java\ndeleted file mode 100644\nindex c7facbafab3..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java\n+++ /dev/null\n\n@@ -1,174 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.factories;\n-\n-import org.apache.flink.api.common.ExecutionConfig;\n-import org.apache.flink.api.common.typeutils.TypeSerializer;\n-import org.apache.flink.api.java.io.CollectionInputFormat;\n-import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n-import org.apache.flink.table.api.TableException;\n-import org.apache.flink.table.api.TableSchema;\n-import org.apache.flink.table.connector.ChangelogMode;\n-import org.apache.flink.table.connector.RuntimeConverter;\n-import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n-import org.apache.flink.table.connector.source.InputFormatProvider;\n-import org.apache.flink.table.connector.source.LookupTableSource;\n-import org.apache.flink.table.connector.source.ScanTableSource;\n-import org.apache.flink.table.connector.source.SourceFunctionProvider;\n-import org.apache.flink.table.connector.source.TableFunctionProvider;\n-import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.functions.AsyncTableFunction;\n-import org.apache.flink.table.functions.TableFunction;\n-import org.apache.flink.types.Row;\n-import org.apache.flink.util.InstantiationUtil;\n-\n-import javax.annotation.Nullable;\n-\n-import java.io.IOException;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-/**\n- * Base class.\n- * */\n-public abstract class TestValuesTableSourceBase implements ScanTableSource, LookupTableSource {\n-\n-\tprotected TableSchema physicalSchema;\n-\tprotected final ChangelogMode changelogMode;\n-\tprotected final boolean bounded;\n-\tprotected final String runtimeSource;\n-\t/* If source table is not partitionable, we will put all data into a emptyMap. */\n-\tprotected Map<Map<String, String>, Collection<Row>> data;\n-\tprotected final boolean isAsync;\n-\tprotected final @Nullable String lookupFunctionClass;\n-\n-\tprotected TestValuesTableSourceBase(\n-\t\t\tTableSchema physicalSchema,\n-\t\t\tChangelogMode changelogMode,\n-\t\t\tboolean bounded,\n-\t\t\tString runtimeSource,\n-\t\t\tMap<Map<String, String>, Collection<Row>> data,\n-\t\t\tboolean isAsync,\n-\t\t\t@Nullable String lookupFunctionClass) {\n-\t\tthis.physicalSchema = physicalSchema;\n-\t\tthis.changelogMode = changelogMode;\n-\t\tthis.bounded = bounded;\n-\t\tthis.runtimeSource = runtimeSource;\n-\t\tthis.data = data;\n-\t\tthis.isAsync = isAsync;\n-\t\tthis.lookupFunctionClass = lookupFunctionClass;\n-\t}\n-\n-\t@Override\n-\tpublic ChangelogMode getChangelogMode() {\n-\t\treturn changelogMode;\n-\t}\n-\n-\t@SuppressWarnings(\"unchecked\")\n-\t@Override\n-\tpublic ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderContext) {\n-\t\tTypeSerializer<RowData> serializer = (TypeSerializer<RowData>) runtimeProviderContext\n-\t\t\t\t.createTypeInformation(physicalSchema.toRowDataType())\n-\t\t\t\t.createSerializer(new ExecutionConfig());\n-\t\tDataStructureConverter converter = runtimeProviderContext.createDataStructureConverter(physicalSchema.toRowDataType());\n-\t\tconverter.open(RuntimeConverter.Context.create(TestValuesTableFactory.class.getClassLoader()));\n-\t\tCollection<RowData> values = convertToRowData(converter);\n-\n-\t\tif (runtimeSource.equals(\"SourceFunction\")) {\n-\t\t\ttry {\n-\t\t\t\treturn SourceFunctionProvider.of(\n-\t\t\t\t\t\tnew FromElementsFunction<>(serializer, values),\n-\t\t\t\t\t\tbounded);\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tthrow new TableException(\"Fail to init source function\", e);\n-\t\t\t}\n-\t\t} else if (runtimeSource.equals(\"InputFormat\")) {\n-\t\t\treturn InputFormatProvider.of(new CollectionInputFormat<>(values, serializer));\n-\t\t} else {\n-\t\t\tthrow new IllegalArgumentException(\"Unsupported runtime source class: \" + runtimeSource);\n-\t\t}\n-\t}\n-\n-\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n-\t@Override\n-\tpublic LookupRuntimeProvider getLookupRuntimeProvider(LookupContext context) {\n-\t\tif (lookupFunctionClass != null) {\n-\t\t\t// use the specified lookup function\n-\t\t\ttry {\n-\t\t\t\tClass<?> clazz = Class.forName(lookupFunctionClass);\n-\t\t\t\tObject udtf = InstantiationUtil.instantiate(clazz);\n-\t\t\t\tif (udtf instanceof TableFunction) {\n-\t\t\t\t\treturn TableFunctionProvider.of((TableFunction) udtf);\n-\t\t\t\t} else {\n-\t\t\t\t\treturn AsyncTableFunctionProvider.of((AsyncTableFunction) udtf);\n-\t\t\t\t}\n-\t\t\t} catch (ClassNotFoundException e) {\n-\t\t\t\tthrow new IllegalArgumentException(\"Could not instantiate class: \" + lookupFunctionClass);\n-\t\t\t}\n-\t\t}\n-\n-\t\tint[] lookupIndices = Arrays.stream(context.getKeys())\n-\t\t\t\t.mapToInt(k -> k[0])\n-\t\t\t\t.toArray();\n-\t\tMap<Row, List<Row>> mapping = new HashMap<>();\n-\n-\t\tdata.get(Collections.emptyMap()).forEach(record -> {\n-\t\t\tRow key = Row.of(Arrays.stream(lookupIndices)\n-\t\t\t\t\t.mapToObj(record::getField)\n-\t\t\t\t\t.toArray());\n-\t\t\tList<Row> list = mapping.get(key);\n-\t\t\tif (list != null) {\n-\t\t\t\tlist.add(record);\n-\t\t\t} else {\n-\t\t\t\tlist = new ArrayList<>();\n-\t\t\t\tlist.add(record);\n-\t\t\t\tmapping.put(key, list);\n-\t\t\t}\n-\t\t});\n-\t\tif (isAsync) {\n-\t\t\treturn AsyncTableFunctionProvider.of(new TestValuesRuntimeFunctions.AsyncTestValueLookupFunction(mapping));\n-\t\t} else {\n-\t\t\treturn TableFunctionProvider.of(new TestValuesRuntimeFunctions.TestValuesLookupFunction(mapping));\n-\t\t}\n-\t}\n-\n-\tprotected Collection<RowData> convertToRowData(DataStructureConverter converter) {\n-\t\tList<RowData> result = new ArrayList<>();\n-\t\tfor (Row value : handle()) {\n-\t\t\tRowData rowData = (RowData) converter.toInternal(value);\n-\t\t\tif (rowData != null) {\n-\t\t\t\trowData.setRowKind(value.getKind());\n-\t\t\t\tresult.add(rowData);\n-\t\t\t}\n-\t\t}\n-\t\treturn result;\n-\t}\n-\n-\t/*\n-\t* Used by apply method to deal with.\n-\t* */\n-\tpublic Collection<Row> handle() {\n-\t\treturn data.get(Collections.emptyMap());\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyNjM0Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500826342", "bodyText": "it's better to build a specific program that only contains the rules needed for the current test, this could avoid  interference with other rules.", "author": "godfreyhe", "createdAt": "2020-10-07T08:22:05Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\ndeleted file mode 100644\nindex 26bd573cec7..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\n+++ /dev/null\n\n@@ -1,188 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-/**\n- * Test rule PushWatermarkIntoTableSourceScanRule.\n- * */\n-public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(\n-\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n-\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleWatermark() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTranspose() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTransposeNotNull() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testComputedColumnWithMultipleInputs() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a string,\\n\" +\n-\t\t\t\t\"  b string,\\n\" +\n-\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n-\t\t\t\t\"  e as c.d,\" +\n-\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithNestedRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n-\t\t\t\t\"  g as c.d.f,\" +\n-\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithUdf() {\n-\t\tutil.addFunction(\"func1\", new InnerUdf());\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\" +\n-\t\t\t\t\"  d as func1(c),\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t/**\n-\t * Udf for test.\n-\t * */\n-\tpublic static class InnerUdf extends ScalarFunction {\n-\t\tpublic LocalDateTime eval(LocalDateTime input) {\n-\t\t\treturn LocalDateTime.ofInstant(input.toInstant(ZoneOffset.UTC).plusMillis(5000), ZoneOffset.UTC);\n-\t\t}\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyODQwMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500828401", "bodyText": "add some tests about\n\nprojection/filter in select,\nwatermark expression contains two field references", "author": "godfreyhe", "createdAt": "2020-10-07T08:25:13Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleTranspose() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleTransposeNotNull() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n+\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testComputedColumnWithMultipleInputs() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a string,\\n\" +\n+\t\t\t\t\"  b string,\\n\" +\n+\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n+\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithRow() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n+\t\t\t\t\"  e as c.d,\" +\n+\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithNestedRow() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n+\t\t\t\t\"  g as c.d.f,\" +\n+\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithUdf() {\n+\t\tutil.addFunction(\"func1\", new InnerUdf());\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\" +\n+\t\t\t\t\"  d as func1(c),\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE3NzcxNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r502177717", "bodyText": "Please refer to testWatermarkOnComputedColumnWithQuery\nand testWatermarkOnComputedColumnWithMultipleInputs.", "author": "fsk119", "createdAt": "2020-10-09T04:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyODQwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\ndeleted file mode 100644\nindex 26bd573cec7..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\n+++ /dev/null\n\n@@ -1,188 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-/**\n- * Test rule PushWatermarkIntoTableSourceScanRule.\n- * */\n-public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(\n-\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n-\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleWatermark() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTranspose() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTransposeNotNull() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testComputedColumnWithMultipleInputs() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a string,\\n\" +\n-\t\t\t\t\"  b string,\\n\" +\n-\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n-\t\t\t\t\"  e as c.d,\" +\n-\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithNestedRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n-\t\t\t\t\"  g as c.d.f,\" +\n-\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithUdf() {\n-\t\tutil.addFunction(\"func1\", new InnerUdf());\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\" +\n-\t\t\t\t\"  d as func1(c),\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t/**\n-\t * Udf for test.\n-\t * */\n-\tpublic static class InnerUdf extends ScalarFunction {\n-\t\tpublic LocalDateTime eval(LocalDateTime input) {\n-\t\t\treturn LocalDateTime.ofInstant(input.toInstant(ZoneOffset.UTC).plusMillis(5000), ZoneOffset.UTC);\n-\t\t}\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgzMDY4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500830680", "bodyText": "Test for [[PushWatermarkIntoTableSourceScanRule]] and [[WatermarkAssignerProjectTransposeRule]]", "author": "godfreyhe", "createdAt": "2020-10-07T08:28:50Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\ndeleted file mode 100644\nindex 26bd573cec7..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\n+++ /dev/null\n\n@@ -1,188 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-/**\n- * Test rule PushWatermarkIntoTableSourceScanRule.\n- * */\n-public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(\n-\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n-\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleWatermark() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTranspose() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleTransposeNotNull() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n-\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testComputedColumnWithMultipleInputs() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a string,\\n\" +\n-\t\t\t\t\"  b string,\\n\" +\n-\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n-\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n-\t\t\t\t\"  e as c.d,\" +\n-\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithNestedRow() {\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n-\t\t\t\t\"  g as c.d.f,\" +\n-\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testTransposeWithUdf() {\n-\t\tutil.addFunction(\"func1\", new InnerUdf());\n-\t\tString ddl = \"create table MyTable(\" +\n-\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\"  c timestamp(3),\" +\n-\t\t\t\t\"  d as func1(c),\" +\n-\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n-\t\t\t\t\" 'bounded' = 'false'\\n\" +\n-\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t/**\n-\t * Udf for test.\n-\t * */\n-\tpublic static class InnerUdf extends ScalarFunction {\n-\t\tpublic LocalDateTime eval(LocalDateTime input) {\n-\t\t\treturn LocalDateTime.ofInstant(input.toInstant(ZoneOffset.UTC).plusMillis(5000), ZoneOffset.UTC);\n-\t\t}\n-\t}\n-}\n"}}, {"oid": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "url": "https://github.com/apache/flink/commit/614d1934dd815569b08e7ed0546c0fee1ebcfd18", "message": "[FLINK-19282][planner] Add watermark push down rule for planner", "committedDate": "2020-11-05T10:01:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwMTQ3Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503001477", "bodyText": "please update the rule description", "author": "godfreyhe", "createdAt": "2020-10-12T01:55:12Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossProjectRule.java", "diffHunk": "@@ -36,12 +36,13 @@\n import java.util.List;\n \n /**\n- * WatermarkAssignerProjectTransposeRule.\n+ * Planner rule that push {@link LogicalWatermarkAssigner} into a {@link LogicalTableScan}\n+ * which wraps a {@link SupportsWatermarkPushDown} dynamic table source across {@link LogicalProject}.\n  * */\n-public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n-\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+public class PushWatermarkIntoTableSourceScanAcrossProjectRule extends PushWatermarkIntoTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossProjectRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossProjectRule();\n \n-\tpublic WatermarkAssignerProjectTransposeRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossProjectRule() {", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossProjectRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossProjectRule.java\ndeleted file mode 100644\nindex ef6375c3883..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossProjectRule.java\n+++ /dev/null\n\n@@ -1,93 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n-\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-/**\n- * Planner rule that push {@link LogicalWatermarkAssigner} into a {@link LogicalTableScan}\n- * which wraps a {@link SupportsWatermarkPushDown} dynamic table source across {@link LogicalProject}.\n- * */\n-public class PushWatermarkIntoTableSourceScanAcrossProjectRule extends PushWatermarkIntoTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoTableSourceScanAcrossProjectRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossProjectRule();\n-\n-\tpublic PushWatermarkIntoTableSourceScanAcrossProjectRule() {\n-\t\tsuper(operand(LogicalWatermarkAssigner.class,\n-\t\t\t\toperand(LogicalProject.class,\n-\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n-\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n-\t}\n-\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalTableScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n-\t\tLogicalProject project = call.rel(1);\n-\n-\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n-\n-\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\treturn computedColumn;\n-\t\t\t}\n-\t\t});\n-\n-\t\tLogicalTableScan newScan = getNewScan(watermarkAssigner, newWatermarkExpr, call.rel(2), (FlinkContext) call.getPlanner().getContext());\n-\n-\t\tList<RexNode> newProjections = new ArrayList<>(project.getProjects());\n-\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\n-\t\t// cast timestamp type to rowtime type.\n-\t\tRexNode newRexNode = builder.makeReinterpretCast(\n-\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n-\t\t\t\tnewProjections.get(watermarkAssigner.rowtimeFieldIndex()),\n-\t\t\t\tnull);\n-\t\tnewProjections.set(watermarkAssigner.rowtimeFieldIndex(), newRexNode);\n-\t\tLogicalProject newProject = project.copy(\n-\t\t\t\tproject.getTraitSet(),\n-\t\t\t\tnewScan,\n-\t\t\t\tnewProjections,\n-\t\t\t\twatermarkAssigner.getRowType());\n-\n-\t\tcall.transformTo(newProject);\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwNDIzMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503004231", "bodyText": "update the comments", "author": "godfreyhe", "createdAt": "2020-10-12T02:09:31Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 65%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex daf3e28e608..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -31,13 +31,13 @@ import org.apache.flink.table.data.RowData;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n \n import org.apache.calcite.plan.RelOptRule;\n import org.apache.calcite.plan.RelOptRuleOperand;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n import org.apache.calcite.rex.RexNode;\n \n import java.time.Duration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwNTE1NA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503005154", "bodyText": "if only TableConfig is used in this method, I suggest to pass TableConfig instead FlinkContext .", "author": "godfreyhe", "createdAt": "2020-10-12T02:14:26Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.\n+ */\n+public abstract class PushWatermarkIntoTableSourceScanBaseRule extends RelOptRule {\n+\tpublic PushWatermarkIntoTableSourceScanBaseRule(RelOptRuleOperand operand, String description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\tprotected LogicalTableScan getNewScan(LogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, LogicalTableScan scan, FlinkContext context) {", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 65%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex daf3e28e608..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -31,13 +31,13 @@ import org.apache.flink.table.data.RowData;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n \n import org.apache.calcite.plan.RelOptRule;\n import org.apache.calcite.plan.RelOptRuleOperand;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n import org.apache.calcite.rex.RexNode;\n \n import java.time.Duration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwODIyOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503008228", "bodyText": "%s, idletimeout=[%s]", "author": "godfreyhe", "createdAt": "2020-10-12T02:29:28Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.\n+ */\n+public abstract class PushWatermarkIntoTableSourceScanBaseRule extends RelOptRule {\n+\tpublic PushWatermarkIntoTableSourceScanBaseRule(RelOptRuleOperand operand, String description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\tprotected LogicalTableScan getNewScan(LogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, LogicalTableScan scan, FlinkContext context) {\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nsimilarity index 65%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nindex daf3e28e608..b17de0b96d6 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n\n@@ -31,13 +31,13 @@ import org.apache.flink.table.data.RowData;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n \n import org.apache.calcite.plan.RelOptRule;\n import org.apache.calcite.plan.RelOptRuleOperand;\n-import org.apache.calcite.rel.logical.LogicalTableScan;\n import org.apache.calcite.rex.RexNode;\n \n import java.time.Duration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk4NzcwOQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r517987709", "bodyText": "Are there any tests that cover these changes?", "author": "godfreyhe", "createdAt": "2020-11-05T11:41:22Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java", "diffHunk": "@@ -463,7 +466,19 @@ private void collectPhysicalFieldsTypes(List<SqlNode> derivedColumns) {\n \t\t\t\t\tboolean nullable = type.getNullable() == null ? true : type.getNullable();\n \t\t\t\t\tRelDataType relType = type.deriveType(sqlValidator, nullable);\n \t\t\t\t\t// add field name and field type to physical field list\n-\t\t\t\t\tphysicalFieldNamesToTypes.put(name, relType);\n+\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);\n+\t\t\t\t} else if (derivedColumn instanceof SqlMetadataColumn) {\n+\t\t\t\t\tSqlMetadataColumn metadataColumn = (SqlMetadataColumn) derivedColumn;\n+\t\t\t\t\tString name = metadataColumn.getName().getSimple();\n+\t\t\t\t\tif (columns.containsKey(name)) {\n+\t\t\t\t\t\tthrow new ValidationException(String.format(\n+\t\t\t\t\t\t\t\"A column named '%s' already exists in the base table.\",\n+\t\t\t\t\t\t\tname));\n+\t\t\t\t\t}\n+\t\t\t\t\tRelDataType relType = metadataColumn.getType()\n+\t\t\t\t\t\t\t\t\t\t\t.deriveType(sqlValidator, metadataColumn.getType().getNullable());\n+\t\t\t\t\t// add field name and field type to physical field list\n+\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzM3MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518463371", "bodyText": "Added now", "author": "fsk119", "createdAt": "2020-11-06T01:05:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk4NzcwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java\nindex 6344fd1b127..e69ea64e95e 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java\n\n@@ -466,19 +463,7 @@ class MergeTableLikeUtil {\n \t\t\t\t\tboolean nullable = type.getNullable() == null ? true : type.getNullable();\n \t\t\t\t\tRelDataType relType = type.deriveType(sqlValidator, nullable);\n \t\t\t\t\t// add field name and field type to physical field list\n-\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);\n-\t\t\t\t} else if (derivedColumn instanceof SqlMetadataColumn) {\n-\t\t\t\t\tSqlMetadataColumn metadataColumn = (SqlMetadataColumn) derivedColumn;\n-\t\t\t\t\tString name = metadataColumn.getName().getSimple();\n-\t\t\t\t\tif (columns.containsKey(name)) {\n-\t\t\t\t\t\tthrow new ValidationException(String.format(\n-\t\t\t\t\t\t\t\"A column named '%s' already exists in the base table.\",\n-\t\t\t\t\t\t\tname));\n-\t\t\t\t\t}\n-\t\t\t\t\tRelDataType relType = metadataColumn.getType()\n-\t\t\t\t\t\t\t\t\t\t\t.deriveType(sqlValidator, metadataColumn.getType().getNullable());\n-\t\t\t\t\t// add field name and field type to physical field list\n-\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);\n+\t\t\t\t\tphysicalFieldNamesToTypes.put(name, relType);\n \t\t\t\t}\n \t\t\t}\n \t\t}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwMzAwOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518003008", "bodyText": "remove the prefix Flink, it can be simplified as ProjectWatermarkAssignerTransposeRule", "author": "godfreyhe", "createdAt": "2020-11-05T12:08:33Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\ndeleted file mode 100644\nindex c70f8961c5f..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\n+++ /dev/null\n\n@@ -1,178 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.utils.NestedColumn;\n-import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n-import org.apache.flink.table.planner.plan.utils.NestedSchema;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.RelNode;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.rules.ProjectRemoveRule;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n- * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n- * {@link LogicalProject} as a pruner.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n-\n-\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n-\n-\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n-\t\tsuper(operand(LogicalProject.class,\n-\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n-\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n-\t}\n-\n-\t/**\n-\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n-\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n-\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n-\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n-\t * count as the input of the {@link LogicalWatermarkAssigner}.\n-\t * */\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\t\t// check RexNode type\n-\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n-\t\tif (!allRef) {\n-\t\t\treturn true;\n-\t\t}\n-\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\t\tif (rowTimeIndexInProject != -1) {\n-\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n-\t\t} else {\n-\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n-\t\t}\n-\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\n-\t\t// whether rowtime field is in the top level projection\n-\t\tRelNode originInput = watermarkAssigner.getInput();\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n-\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\n-\t\t// get projects and data type of the transposed LogicalProject\n-\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n-\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n-\t\tList<String> transposedProjectFieldNames =\n-\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n-\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n-\t\tint rowTimeIndexInTranposedProject;\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n-\n-\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n-\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n-\t\t} else {\n-\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n-\t\t}\n-\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n-\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n-\t\t\t\ttransposedProjectFieldNames);\n-\n-\t\t// build the transposed LogicalProjection\n-\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n-\n-\t\t// prepare for rewrite\n-\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n-\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n-\t\t}\n-\t\t// label by hand\n-\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n-\n-\t\t// build the LogicalWatermarkAssigner\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\t\tRexNode newWatermarkExpr =\n-\t\t\t\tNestedProjectionUtil.rewrite(\n-\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n-\t\t\t\t\t\tnestedSchema,\n-\t\t\t\t\t\tbuilder).get(0);\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n-\t\t\t\twatermarkAssigner.getCluster(),\n-\t\t\t\ttransposedProject,\n-\t\t\t\trowTimeIndexInTranposedProject,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\t// build the origin top level LogicalProjection\n-\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n-\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n-\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n-\t\t}\n-\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n-\n-\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n-\t\t\t// drop project if the transformed program merely returns its input\n-\t\t\tcall.transformTo(newWatermarkAssigner);\n-\t\t} else {\n-\t\t\tcall.transformTo(newProject);\n-\t\t}\n-\t}\n-\n-\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n-\t\tfor (int i = 0; i < projects.size(); i++) {\n-\t\t\tRexNode project = projects.get(i);\n-\t\t\tif (project instanceof RexInputRef) {\n-\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn i;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn -1;\n-\t}\n-\n-\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n-\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\tif (inputRef.getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn new RexInputRef(rowTimeIndex, originType);\n-\t\t\t\t}\n-\t\t\t\treturn inputRef;\n-\t\t\t}\n-\t\t})).collect(Collectors.toList());\n-\t\treturn projectsWithRowtime;\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwNzIxNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518007217", "bodyText": "maybe the projection outputs the deduplicate fields, such as: a, a, a, b, b\nyou should push down the used fields in the projection.", "author": "godfreyhe", "createdAt": "2020-11-05T12:16:16Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\ndeleted file mode 100644\nindex c70f8961c5f..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\n+++ /dev/null\n\n@@ -1,178 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.utils.NestedColumn;\n-import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n-import org.apache.flink.table.planner.plan.utils.NestedSchema;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.RelNode;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.rules.ProjectRemoveRule;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n- * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n- * {@link LogicalProject} as a pruner.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n-\n-\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n-\n-\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n-\t\tsuper(operand(LogicalProject.class,\n-\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n-\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n-\t}\n-\n-\t/**\n-\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n-\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n-\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n-\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n-\t * count as the input of the {@link LogicalWatermarkAssigner}.\n-\t * */\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\t\t// check RexNode type\n-\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n-\t\tif (!allRef) {\n-\t\t\treturn true;\n-\t\t}\n-\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\t\tif (rowTimeIndexInProject != -1) {\n-\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n-\t\t} else {\n-\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n-\t\t}\n-\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\n-\t\t// whether rowtime field is in the top level projection\n-\t\tRelNode originInput = watermarkAssigner.getInput();\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n-\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\n-\t\t// get projects and data type of the transposed LogicalProject\n-\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n-\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n-\t\tList<String> transposedProjectFieldNames =\n-\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n-\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n-\t\tint rowTimeIndexInTranposedProject;\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n-\n-\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n-\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n-\t\t} else {\n-\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n-\t\t}\n-\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n-\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n-\t\t\t\ttransposedProjectFieldNames);\n-\n-\t\t// build the transposed LogicalProjection\n-\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n-\n-\t\t// prepare for rewrite\n-\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n-\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n-\t\t}\n-\t\t// label by hand\n-\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n-\n-\t\t// build the LogicalWatermarkAssigner\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\t\tRexNode newWatermarkExpr =\n-\t\t\t\tNestedProjectionUtil.rewrite(\n-\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n-\t\t\t\t\t\tnestedSchema,\n-\t\t\t\t\t\tbuilder).get(0);\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n-\t\t\t\twatermarkAssigner.getCluster(),\n-\t\t\t\ttransposedProject,\n-\t\t\t\trowTimeIndexInTranposedProject,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\t// build the origin top level LogicalProjection\n-\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n-\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n-\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n-\t\t}\n-\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n-\n-\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n-\t\t\t// drop project if the transformed program merely returns its input\n-\t\t\tcall.transformTo(newWatermarkAssigner);\n-\t\t} else {\n-\t\t\tcall.transformTo(newProject);\n-\t\t}\n-\t}\n-\n-\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n-\t\tfor (int i = 0; i < projects.size(); i++) {\n-\t\t\tRexNode project = projects.get(i);\n-\t\t\tif (project instanceof RexInputRef) {\n-\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn i;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn -1;\n-\t}\n-\n-\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n-\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\tif (inputRef.getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn new RexInputRef(rowTimeIndex, originType);\n-\t\t\t\t}\n-\t\t\t\treturn inputRef;\n-\t\t\t}\n-\t\t})).collect(Collectors.toList());\n-\t\treturn projectsWithRowtime;\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxMjU4Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518012587", "bodyText": "use project.getCluster().getTypeFactory(), and move it close to the place where it is used", "author": "godfreyhe", "createdAt": "2020-11-05T12:26:21Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\ndeleted file mode 100644\nindex c70f8961c5f..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\n+++ /dev/null\n\n@@ -1,178 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.utils.NestedColumn;\n-import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n-import org.apache.flink.table.planner.plan.utils.NestedSchema;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.RelNode;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.rules.ProjectRemoveRule;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n- * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n- * {@link LogicalProject} as a pruner.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n-\n-\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n-\n-\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n-\t\tsuper(operand(LogicalProject.class,\n-\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n-\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n-\t}\n-\n-\t/**\n-\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n-\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n-\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n-\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n-\t * count as the input of the {@link LogicalWatermarkAssigner}.\n-\t * */\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\t\t// check RexNode type\n-\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n-\t\tif (!allRef) {\n-\t\t\treturn true;\n-\t\t}\n-\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\t\tif (rowTimeIndexInProject != -1) {\n-\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n-\t\t} else {\n-\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n-\t\t}\n-\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\n-\t\t// whether rowtime field is in the top level projection\n-\t\tRelNode originInput = watermarkAssigner.getInput();\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n-\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\n-\t\t// get projects and data type of the transposed LogicalProject\n-\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n-\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n-\t\tList<String> transposedProjectFieldNames =\n-\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n-\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n-\t\tint rowTimeIndexInTranposedProject;\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n-\n-\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n-\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n-\t\t} else {\n-\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n-\t\t}\n-\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n-\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n-\t\t\t\ttransposedProjectFieldNames);\n-\n-\t\t// build the transposed LogicalProjection\n-\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n-\n-\t\t// prepare for rewrite\n-\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n-\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n-\t\t}\n-\t\t// label by hand\n-\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n-\n-\t\t// build the LogicalWatermarkAssigner\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\t\tRexNode newWatermarkExpr =\n-\t\t\t\tNestedProjectionUtil.rewrite(\n-\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n-\t\t\t\t\t\tnestedSchema,\n-\t\t\t\t\t\tbuilder).get(0);\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n-\t\t\t\twatermarkAssigner.getCluster(),\n-\t\t\t\ttransposedProject,\n-\t\t\t\trowTimeIndexInTranposedProject,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\t// build the origin top level LogicalProjection\n-\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n-\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n-\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n-\t\t}\n-\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n-\n-\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n-\t\t\t// drop project if the transformed program merely returns its input\n-\t\t\tcall.transformTo(newWatermarkAssigner);\n-\t\t} else {\n-\t\t\tcall.transformTo(newProject);\n-\t\t}\n-\t}\n-\n-\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n-\t\tfor (int i = 0; i < projects.size(); i++) {\n-\t\t\tRexNode project = projects.get(i);\n-\t\t\tif (project instanceof RexInputRef) {\n-\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn i;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn -1;\n-\t}\n-\n-\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n-\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\tif (inputRef.getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn new RexInputRef(rowTimeIndex, originType);\n-\t\t\t\t}\n-\t\t\t\treturn inputRef;\n-\t\t\t}\n-\t\t})).collect(Collectors.toList());\n-\t\treturn projectsWithRowtime;\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDA1MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518014051", "bodyText": "originType => rowtimeType", "author": "godfreyhe", "createdAt": "2020-11-05T12:29:03Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n+\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n+\t\tList<String> transposedProjectFieldNames =\n+\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n+\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tint rowTimeIndexInTranposedProject;\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n+\n+\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n+\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n+\t\t}\n+\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n+\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n+\t\t\t\ttransposedProjectFieldNames);\n+\n+\t\t// build the transposed LogicalProjection\n+\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n+\n+\t\t// prepare for rewrite\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n+\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n+\t\t}\n+\t\t// label by hand\n+\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n+\n+\t\t// build the LogicalWatermarkAssigner\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\tRexNode newWatermarkExpr =\n+\t\t\t\tNestedProjectionUtil.rewrite(\n+\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n+\t\t\t\t\t\tnestedSchema,\n+\t\t\t\t\t\tbuilder).get(0);\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\trowTimeIndexInTranposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\t// build the origin top level LogicalProjection\n+\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n+\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n+\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n+\t\t}\n+\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n+\n+\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n+\t\t\t// drop project if the transformed program merely returns its input\n+\t\t\tcall.transformTo(newWatermarkAssigner);\n+\t\t} else {\n+\t\t\tcall.transformTo(newProject);\n+\t\t}\n+\t}\n+\n+\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n+\t\tfor (int i = 0; i < projects.size(); i++) {\n+\t\t\tRexNode project = projects.get(i);\n+\t\t\tif (project instanceof RexInputRef) {\n+\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n+\t\t\t\t\treturn i;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn -1;\n+\t}\n+\n+\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\ndeleted file mode 100644\nindex c70f8961c5f..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\n+++ /dev/null\n\n@@ -1,178 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.utils.NestedColumn;\n-import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n-import org.apache.flink.table.planner.plan.utils.NestedSchema;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.RelNode;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.rules.ProjectRemoveRule;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n- * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n- * {@link LogicalProject} as a pruner.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n-\n-\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n-\n-\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n-\t\tsuper(operand(LogicalProject.class,\n-\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n-\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n-\t}\n-\n-\t/**\n-\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n-\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n-\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n-\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n-\t * count as the input of the {@link LogicalWatermarkAssigner}.\n-\t * */\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\t\t// check RexNode type\n-\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n-\t\tif (!allRef) {\n-\t\t\treturn true;\n-\t\t}\n-\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\t\tif (rowTimeIndexInProject != -1) {\n-\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n-\t\t} else {\n-\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n-\t\t}\n-\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\n-\t\t// whether rowtime field is in the top level projection\n-\t\tRelNode originInput = watermarkAssigner.getInput();\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n-\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\n-\t\t// get projects and data type of the transposed LogicalProject\n-\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n-\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n-\t\tList<String> transposedProjectFieldNames =\n-\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n-\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n-\t\tint rowTimeIndexInTranposedProject;\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n-\n-\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n-\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n-\t\t} else {\n-\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n-\t\t}\n-\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n-\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n-\t\t\t\ttransposedProjectFieldNames);\n-\n-\t\t// build the transposed LogicalProjection\n-\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n-\n-\t\t// prepare for rewrite\n-\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n-\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n-\t\t}\n-\t\t// label by hand\n-\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n-\n-\t\t// build the LogicalWatermarkAssigner\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\t\tRexNode newWatermarkExpr =\n-\t\t\t\tNestedProjectionUtil.rewrite(\n-\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n-\t\t\t\t\t\tnestedSchema,\n-\t\t\t\t\t\tbuilder).get(0);\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n-\t\t\t\twatermarkAssigner.getCluster(),\n-\t\t\t\ttransposedProject,\n-\t\t\t\trowTimeIndexInTranposedProject,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\t// build the origin top level LogicalProjection\n-\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n-\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n-\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n-\t\t}\n-\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n-\n-\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n-\t\t\t// drop project if the transformed program merely returns its input\n-\t\t\tcall.transformTo(newWatermarkAssigner);\n-\t\t} else {\n-\t\t\tcall.transformTo(newProject);\n-\t\t}\n-\t}\n-\n-\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n-\t\tfor (int i = 0; i < projects.size(); i++) {\n-\t\t\tRexNode project = projects.get(i);\n-\t\t\tif (project instanceof RexInputRef) {\n-\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn i;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn -1;\n-\t}\n-\n-\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n-\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\tif (inputRef.getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn new RexInputRef(rowTimeIndex, originType);\n-\t\t\t\t}\n-\t\t\t\treturn inputRef;\n-\t\t\t}\n-\t\t})).collect(Collectors.toList());\n-\t\treturn projectsWithRowtime;\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDQxMA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518014410", "bodyText": "return the result directly", "author": "godfreyhe", "createdAt": "2020-11-05T12:29:38Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n+\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n+\t\tList<String> transposedProjectFieldNames =\n+\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n+\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tint rowTimeIndexInTranposedProject;\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n+\n+\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n+\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n+\t\t}\n+\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n+\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n+\t\t\t\ttransposedProjectFieldNames);\n+\n+\t\t// build the transposed LogicalProjection\n+\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n+\n+\t\t// prepare for rewrite\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n+\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n+\t\t}\n+\t\t// label by hand\n+\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n+\n+\t\t// build the LogicalWatermarkAssigner\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\tRexNode newWatermarkExpr =\n+\t\t\t\tNestedProjectionUtil.rewrite(\n+\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n+\t\t\t\t\t\tnestedSchema,\n+\t\t\t\t\t\tbuilder).get(0);\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\trowTimeIndexInTranposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\t// build the origin top level LogicalProjection\n+\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n+\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n+\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n+\t\t}\n+\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n+\n+\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n+\t\t\t// drop project if the transformed program merely returns its input\n+\t\t\tcall.transformTo(newWatermarkAssigner);\n+\t\t} else {\n+\t\t\tcall.transformTo(newProject);\n+\t\t}\n+\t}\n+\n+\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n+\t\tfor (int i = 0; i < projects.size(); i++) {\n+\t\t\tRexNode project = projects.get(i);\n+\t\t\tif (project instanceof RexInputRef) {\n+\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n+\t\t\t\t\treturn i;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn -1;\n+\t}\n+\n+\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n+\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\ndeleted file mode 100644\nindex c70f8961c5f..00000000000\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java\n+++ /dev/null\n\n@@ -1,178 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to you under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n-import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.utils.NestedColumn;\n-import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n-import org.apache.flink.table.planner.plan.utils.NestedSchema;\n-\n-import org.apache.calcite.plan.RelOptRule;\n-import org.apache.calcite.plan.RelOptRuleCall;\n-import org.apache.calcite.rel.RelNode;\n-import org.apache.calcite.rel.logical.LogicalProject;\n-import org.apache.calcite.rel.rules.ProjectRemoveRule;\n-import org.apache.calcite.rel.type.RelDataType;\n-import org.apache.calcite.rex.RexBuilder;\n-import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexNode;\n-import org.apache.calcite.rex.RexShuttle;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n- * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n- * {@link LogicalProject} as a pruner.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n-\n-\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n-\n-\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n-\t\tsuper(operand(LogicalProject.class,\n-\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n-\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n-\t}\n-\n-\t/**\n-\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n-\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n-\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n-\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n-\t * count as the input of the {@link LogicalWatermarkAssigner}.\n-\t * */\n-\t@Override\n-\tpublic boolean matches(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\t\t// check RexNode type\n-\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n-\t\tif (!allRef) {\n-\t\t\treturn true;\n-\t\t}\n-\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\t\tif (rowTimeIndexInProject != -1) {\n-\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n-\t\t} else {\n-\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n-\t\t}\n-\n-\t}\n-\n-\t@Override\n-\tpublic void onMatch(RelOptRuleCall call) {\n-\t\tLogicalProject project = call.rel(0);\n-\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n-\n-\t\t// whether rowtime field is in the top level projection\n-\t\tRelNode originInput = watermarkAssigner.getInput();\n-\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n-\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n-\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n-\n-\t\t// get projects and data type of the transposed LogicalProject\n-\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n-\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n-\t\tList<String> transposedProjectFieldNames =\n-\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n-\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n-\t\tint rowTimeIndexInTranposedProject;\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n-\n-\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n-\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n-\t\t} else {\n-\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n-\t\t}\n-\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n-\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n-\t\t\t\ttransposedProjectFieldNames);\n-\n-\t\t// build the transposed LogicalProjection\n-\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n-\n-\t\t// prepare for rewrite\n-\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n-\t\tif (rowTimeIndexInTopLevelProject == -1) {\n-\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n-\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n-\t\t}\n-\t\t// label by hand\n-\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n-\n-\t\t// build the LogicalWatermarkAssigner\n-\t\tRexBuilder builder = call.builder().getRexBuilder();\n-\t\tRexNode newWatermarkExpr =\n-\t\t\t\tNestedProjectionUtil.rewrite(\n-\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n-\t\t\t\t\t\tnestedSchema,\n-\t\t\t\t\t\tbuilder).get(0);\n-\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n-\t\t\t\twatermarkAssigner.getCluster(),\n-\t\t\t\ttransposedProject,\n-\t\t\t\trowTimeIndexInTranposedProject,\n-\t\t\t\tnewWatermarkExpr);\n-\n-\t\t// build the origin top level LogicalProjection\n-\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n-\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n-\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n-\t\t}\n-\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n-\n-\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n-\t\t\t// drop project if the transformed program merely returns its input\n-\t\t\tcall.transformTo(newWatermarkAssigner);\n-\t\t} else {\n-\t\t\tcall.transformTo(newProject);\n-\t\t}\n-\t}\n-\n-\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n-\t\tfor (int i = 0; i < projects.size(); i++) {\n-\t\t\tRexNode project = projects.get(i);\n-\t\t\tif (project instanceof RexInputRef) {\n-\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn i;\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n-\t\treturn -1;\n-\t}\n-\n-\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n-\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){\n-\t\t\t@Override\n-\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n-\t\t\t\tif (inputRef.getIndex() == rowTimeIndex) {\n-\t\t\t\t\treturn new RexInputRef(rowTimeIndex, originType);\n-\t\t\t\t}\n-\t\t\t\treturn inputRef;\n-\t\t\t}\n-\t\t})).collect(Collectors.toList());\n-\t\treturn projectsWithRowtime;\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNDI2Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518024263", "bodyText": "the test should only involves the required rules", "author": "godfreyhe", "createdAt": "2020-11-05T12:47:04Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java\ndeleted file mode 100644\nindex 245794b9a3a..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java\n+++ /dev/null\n\n@@ -1,143 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-/**\n- * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"ProjectWatermarkAssignerTranspose\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(FlinkProjectWatermarkAssignerTransposeRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void simpleTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT a, c FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void cannotTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void transposeWithReorder() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void transposeWithNestedField() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a ROW<a1 INT, a2 INT, a3 INT>,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a.a1, a.a2 FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void complicatedTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a ROW<a1 INT, a2 INT, a3 INT>,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT a.a1, a.a2 + b FROM Source\");\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNTA0MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518025041", "bodyText": "should also consider ddl with computed column and watermark with expression", "author": "godfreyhe", "createdAt": "2020-11-05T12:48:28Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"ProjectWatermarkAssignerTranspose\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(FlinkProjectWatermarkAssignerTransposeRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void simpleTranspose() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE Source(\\n\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n+\t\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\";\n+\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT a, c FROM Source\");\n+\t}\n+\n+\t@Test\n+\tpublic void cannotTranspose() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE Source(\\n\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n+\t\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\";\n+\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n+\t}\n+\n+\t@Test\n+\tpublic void transposeWithReorder() {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java\ndeleted file mode 100644\nindex 245794b9a3a..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java\n+++ /dev/null\n\n@@ -1,143 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-/**\n- * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n- */\n-public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"ProjectWatermarkAssignerTranspose\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(FlinkProjectWatermarkAssignerTransposeRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void simpleTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT a, c FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void cannotTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void transposeWithReorder() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void transposeWithNestedField() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a ROW<a1 INT, a2 INT, a3 INT>,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT b, a.a1, a.a2 FROM Source\");\n-\t}\n-\n-\t@Test\n-\tpublic void complicatedTranspose() {\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE Source(\\n\" +\n-\t\t\t\t\t\t\"  a ROW<a1 INT, a2 INT, a3 INT>,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n-\t\t\t\t\t\t\"  d STRING,\\n\" +\n-\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n-\t\t\t\t\t\t\") WITH (\" +\n-\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n-\t\t\t\t\t\t\")\";\n-\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"SELECT a.a1, a.a2 + b FROM Source\");\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNTk1Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518025957", "bodyText": "the class name can be simplified as PushWatermarkIntoTableSourceScanRuleBase", "author": "godfreyhe", "createdAt": "2020-11-05T12:50:00Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nsimilarity index 80%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nindex b17de0b96d6..ef3bf7e1dad 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\n\n@@ -24,11 +24,11 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzMjg4MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518032881", "bodyText": "wrap to multiple lines?", "author": "godfreyhe", "createdAt": "2020-11-05T13:01:36Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nsimilarity index 80%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nindex b17de0b96d6..ef3bf7e1dad 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\n\n@@ -24,11 +24,11 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0MTE4OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518041188", "bodyText": "return the result directly", "author": "godfreyhe", "createdAt": "2020-11-05T13:15:26Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {\n+\t\t\t// without projection or project doesn't project or project doesn't add new computed columns\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t} else {\n+\t\t\t// project exists. make the project's rowtype is consistent with the origin plan.\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\tscan.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t}\n+\n+\t\tFlinkLogicalTableSourceScan newScan = FlinkLogicalTableSourceScan.create(scan.getCluster(),\n+\t\t\t\tnewTableSourceTable);\n+\t\treturn newScan;", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nsimilarity index 80%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nindex b17de0b96d6..ef3bf7e1dad 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\n\n@@ -24,11 +24,11 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NDQ5OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518044498", "bodyText": "add static", "author": "godfreyhe", "createdAt": "2020-11-05T13:20:40Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {\n+\t\t\t// without projection or project doesn't project or project doesn't add new computed columns\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t} else {\n+\t\t\t// project exists. make the project's rowtype is consistent with the origin plan.\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\tscan.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t}\n+\n+\t\tFlinkLogicalTableSourceScan newScan = FlinkLogicalTableSourceScan.create(scan.getCluster(),\n+\t\t\t\tnewTableSourceTable);\n+\t\treturn newScan;\n+\t}\n+\n+\t/**\n+\t * Wrapper of the {@link GeneratedWatermarkGenerator} that is used to create {@link WatermarkGenerator}.\n+\t * The {@link DefaultWatermarkGeneratorSupplier} uses the {@link WatermarkGeneratorSupplier.Context} to init\n+\t * the generated watermark generator.\n+\t */\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {\n+\n+\t\tprivate static final long serialVersionUID = 1L;\n+\n+\t\tprivate final Configuration configuration;\n+\t\tprivate final GeneratedWatermarkGenerator generatedWatermarkGenerator;\n+\n+\t\tpublic DefaultWatermarkGeneratorSupplier(Configuration configuration,\n+\t\t\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator) {\n+\t\t\tthis.configuration = configuration;\n+\t\t\tthis.generatedWatermarkGenerator = generatedWatermarkGenerator;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic WatermarkGenerator<RowData> createWatermarkGenerator(Context context) {\n+\n+\t\t\tList<Object> references = new ArrayList<>(Arrays.asList(generatedWatermarkGenerator.getReferences()));\n+\t\t\treferences.add(context);\n+\n+\t\t\torg.apache.flink.table.runtime.generated.WatermarkGenerator innerWatermarkGenerator =\n+\t\t\t\t\tnew GeneratedWatermarkGenerator(\n+\t\t\t\t\t\t\tgeneratedWatermarkGenerator.getClassName(),\n+\t\t\t\t\t\t\tgeneratedWatermarkGenerator.getCode(),\n+\t\t\t\t\t\t\treferences.toArray())\n+\t\t\t\t\t\t\t.newInstance(Thread.currentThread().getContextClassLoader());\n+\n+\t\t\ttry {\n+\t\t\t\tinnerWatermarkGenerator.open(configuration);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Fail to instantiate generated watermark generator.\", e);\n+\t\t\t}\n+\t\t\treturn new DefaultWatermarkGeneratorSupplier.DefaultWatermarkGenerator(innerWatermarkGenerator);\n+\t\t}\n+\n+\t\t/**\n+\t\t * Wrapper of the code-generated {@link org.apache.flink.table.runtime.generated.WatermarkGenerator}.\n+\t\t */\n+\t\tprivate class DefaultWatermarkGenerator implements WatermarkGenerator<RowData> {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nsimilarity index 80%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nindex b17de0b96d6..ef3bf7e1dad 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\n\n@@ -24,11 +24,11 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTA2Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045062", "bodyText": "PushWatermarkIntoTableSourceScanRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:21:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nindex 64a338ac564..848aebbe140 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n\n@@ -18,11 +18,9 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTIzNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045235", "bodyText": "\"PushWatermarkIntoFlinkTableSourceScan\" -> \"PushWatermarkIntoTableSourceScanRule\"", "author": "godfreyhe", "createdAt": "2020-11-05T13:21:48Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScan\");", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\nindex 64a338ac564..848aebbe140 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java\n\n@@ -18,11 +18,9 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTkyMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045922", "bodyText": "PushWatermarkIntoTableSourceScanAcrossCalcRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:22:57Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex f781ba42f25..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -19,46 +19,42 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n+import java.util.stream.Collectors;\n \n /**\n  * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n  * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n  * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n  */\n-public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n \n-\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n \t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n \t\t\t\toperand(FlinkLogicalCalc.class,\n \t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n-\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule\");\n \t}\n \n \t@Override\n \tpublic boolean matches(RelOptRuleCall call) {\n \t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t\treturn supportsWatermarkPushDown(scan);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0Njc4Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518046787", "bodyText": "we can extract a common method into PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:24:20Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex f781ba42f25..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -19,46 +19,42 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n+import java.util.stream.Collectors;\n \n /**\n  * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n  * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n  * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n  */\n-public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n \n-\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n \t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n \t\t\t\toperand(FlinkLogicalCalc.class,\n \t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n-\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule\");\n \t}\n \n \t@Override\n \tpublic boolean matches(RelOptRuleCall call) {\n \t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t\treturn supportsWatermarkPushDown(scan);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0OTM4Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518049383", "bodyText": "we can expand the local ref first", "author": "godfreyhe", "createdAt": "2020-11-05T13:28:15Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex f781ba42f25..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -19,46 +19,42 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n+import java.util.stream.Collectors;\n \n /**\n  * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n  * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n  * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n  */\n-public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n \n-\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n \t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n \t\t\t\toperand(FlinkLogicalCalc.class,\n \t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n-\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule\");\n \t}\n \n \t@Override\n \tpublic boolean matches(RelOptRuleCall call) {\n \t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t\treturn supportsWatermarkPushDown(scan);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1MjkyMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518052922", "bodyText": "we should only replace the rowtime field ref and other refs should be re-indexed based on TableScan's rowtype.", "author": "godfreyhe", "createdAt": "2020-11-05T13:33:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = originProgram.expandLocalRef(projectList.get(watermarkAssigner.rowtimeFieldIndex()));\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3MDY4MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518470681", "bodyText": "The watermark expression only has one input ref. But it's a good idea to make it more robust.", "author": "fsk119", "createdAt": "2020-11-06T01:29:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1MjkyMg=="}], "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex f781ba42f25..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -19,46 +19,42 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n+import java.util.stream.Collectors;\n \n /**\n  * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n  * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n  * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n  */\n-public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n \n-\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n \t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n \t\t\t\toperand(FlinkLogicalCalc.class,\n \t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n-\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule\");\n \t}\n \n \t@Override\n \tpublic boolean matches(RelOptRuleCall call) {\n \t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t\treturn supportsWatermarkPushDown(scan);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1NDMwNg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518054306", "bodyText": "newComputedColumn", "author": "godfreyhe", "createdAt": "2020-11-05T13:35:32Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = originProgram.expandLocalRef(projectList.get(watermarkAssigner.rowtimeFieldIndex()));\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\t// replace the input ref with the computed column\n+\t\t\t\treturn computedColumn;\n+\t\t\t}\n+\t\t});\n+\n+\t\t// push watermark assigner into the scan\n+\t\tFlinkLogicalTableSourceScan newScan =\n+\t\t\t\tgetNewScan(watermarkAssigner, newWatermarkExpr, call.rel(2), (FlinkContext) call.getPlanner().getContext());\n+\n+\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\t// cast timestamp type to rowtime type.\n+\t\tRexNode newRexNode = builder.makeReinterpretCast(", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nsimilarity index 68%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex f781ba42f25..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -19,46 +19,42 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n-import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n-import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n \n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n+import java.util.stream.Collectors;\n \n /**\n  * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n  * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n  * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n  */\n-public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n-\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n \n-\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n \t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n \t\t\t\toperand(FlinkLogicalCalc.class,\n \t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n-\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule\");\n \t}\n \n \t@Override\n \tpublic boolean matches(RelOptRuleCall call) {\n \t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n-\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n-\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t\treturn supportsWatermarkPushDown(scan);\n \t}\n \n \t@Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MDEwNg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518060106", "bodyText": "add a method parameter determine the condition", "author": "godfreyhe", "createdAt": "2020-11-05T13:44:16Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nsimilarity index 80%\nrename from flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\nrename to flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\nindex b17de0b96d6..ef3bf7e1dad 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleBase.java\n\n@@ -24,11 +24,11 @@ import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n import org.apache.flink.api.common.eventtime.WatermarkOutput;\n import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n import org.apache.flink.table.api.config.ExecutionConfigOptions;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n import org.apache.flink.table.data.RowData;\n-import org.apache.flink.table.planner.calcite.FlinkContext;\n import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTMxMA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518061310", "bodyText": "UNSUPPORTED_ABILITIES should also be removed", "author": "godfreyhe", "createdAt": "2020-11-05T13:46:03Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/sources/DynamicSourceUtils.java", "diffHunk": "@@ -331,19 +329,6 @@ private static void validateWatermarks(\n \t\t}\n \t}\n \n-\tprivate static void validateAbilities(DynamicTableSource source) {\n-\t\tUNSUPPORTED_ABILITIES.forEach(ability -> {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTkwNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518061907", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-11-05T13:46:53Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java\ndeleted file mode 100644\nindex 9198afaf27e..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java\n+++ /dev/null\n\n@@ -1,202 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-/**\n- * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n- * */\n-public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(\n-\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanRule.INSTANCE,\n-\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleWatermark() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select a, c from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumn() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumnWithQuery() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n-\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select a, b from MyTable where d > TO_TIMESTAMP('2020-10-09 12:12:12')\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumnWithMultipleInputs() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a string,\\n\" +\n-\t\t\t\t\t\t\"  b string,\\n\" +\n-\t\t\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n-\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnRow() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n-\t\t\t\t\t\t\"  e as c.d,\" +\n-\t\t\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnNestedRow() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n-\t\t\t\t\t\t\"  g as c.d.f,\" +\n-\t\t\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkWithUdf() {\n-\t\tutil.addFunction(\"func1\", new InnerUdf());\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE MyTable(\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\" +\n-\t\t\t\t\t\t\"  d AS func1(c),\" +\n-\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t/**\n-\t * Udf for test.\n-\t * */\n-\tpublic static class InnerUdf extends ScalarFunction {\n-\t\tpublic LocalDateTime eval(LocalDateTime input) {\n-\t\t\treturn LocalDateTime.ofInstant(input.toInstant(ZoneOffset.UTC).plusMillis(5000), ZoneOffset.UTC);\n-\t\t}\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2OTQ1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518069458", "bodyText": "add a test about watermark for d as d - interval '5' second + other timestamp field", "author": "godfreyhe", "createdAt": "2020-11-05T13:57:37Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select a, c from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumn() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithQuery() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n+\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE4NzQ5Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518187497", "bodyText": "The watermark expression only allows one input reference. The expression mentioned is illegal", "author": "fsk119", "createdAt": "2020-11-05T16:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2OTQ1OA=="}], "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java\ndeleted file mode 100644\nindex 9198afaf27e..00000000000\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java\n+++ /dev/null\n\n@@ -1,202 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.flink.table.planner.plan.rules.logical;\n-\n-import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n-import org.apache.flink.table.planner.calcite.CalciteConfig;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n-import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n-import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n-import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n-import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n-import org.apache.flink.table.planner.utils.TableConfigUtils;\n-import org.apache.flink.table.planner.utils.TableTestBase;\n-\n-import org.apache.calcite.plan.hep.HepMatchOrder;\n-import org.apache.calcite.tools.RuleSets;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.time.LocalDateTime;\n-import java.time.ZoneOffset;\n-\n-/**\n- * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n- * */\n-public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n-\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n-\n-\t@Before\n-\tpublic void setup() {\n-\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());\n-\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n-\t\tcalciteConfig.getStreamProgram().get().addLast(\n-\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n-\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n-\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n-\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n-\t\t\t\t\t\t.add(RuleSets.ofList(\n-\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanRule.INSTANCE,\n-\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.INSTANCE))\n-\t\t\t\t\t\t.build()\n-\t\t);\n-\t}\n-\n-\t@Test\n-\tpublic void testSimpleWatermark() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select a, c from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumn() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n-\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumnWithQuery() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n-\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n-\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select a, b from MyTable where d > TO_TIMESTAMP('2020-10-09 12:12:12')\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnComputedColumnWithMultipleInputs() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a string,\\n\" +\n-\t\t\t\t\t\t\"  b string,\\n\" +\n-\t\t\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n-\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnRow() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n-\t\t\t\t\t\t\"  e as c.d,\" +\n-\t\t\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkOnNestedRow() {\n-\t\tString ddl =\n-\t\t\t\t\"create table MyTable(\" +\n-\t\t\t\t\t\t\"  a int,\\n\" +\n-\t\t\t\t\t\t\"  b bigint,\\n\" +\n-\t\t\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n-\t\t\t\t\t\t\"  g as c.d.f,\" +\n-\t\t\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t@Test\n-\tpublic void testWatermarkWithUdf() {\n-\t\tutil.addFunction(\"func1\", new InnerUdf());\n-\t\tString ddl =\n-\t\t\t\t\"CREATE TABLE MyTable(\" +\n-\t\t\t\t\t\t\"  a INT,\\n\" +\n-\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n-\t\t\t\t\t\t\"  c TIMESTAMP(3),\" +\n-\t\t\t\t\t\t\"  d AS func1(c),\" +\n-\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n-\t\t\t\t\t\t\") WITH (\\n\" +\n-\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n-\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n-\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n-\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n-\t\t\t\t\t\t\")\";\n-\t\tutil.tableEnv().executeSql(ddl);\n-\t\tutil.verifyPlan(\"select * from MyTable\");\n-\t}\n-\n-\t/**\n-\t * Udf for test.\n-\t * */\n-\tpublic static class InnerUdf extends ScalarFunction {\n-\t\tpublic LocalDateTime eval(LocalDateTime input) {\n-\t\t\treturn LocalDateTime.ofInstant(input.toInstant(ZoneOffset.UTC).plusMillis(5000), ZoneOffset.UTC);\n-\t\t}\n-\t}\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2MzM1NQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518563355", "bodyText": "It better rename setIndex to setIndexOfLeafInNewSchema", "author": "godfreyhe", "createdAt": "2020-11-06T07:19:41Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\nindex c6eac3a7d56..25ec695e833 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n\n@@ -17,6 +17,8 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n+import org.apache.flink.table.planner.calcite.FlinkRelBuilder;\n+import org.apache.flink.table.planner.calcite.FlinkRelFactories;\n import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.utils.NestedColumn;\n import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2OTk4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518569980", "bodyText": "builder.project(transposedProjects, usedNames);", "author": "godfreyhe", "createdAt": "2020-11-06T07:37:06Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\nindex c6eac3a7d56..25ec695e833 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n\n@@ -17,6 +17,8 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n+import org.apache.flink.table.planner.calcite.FlinkRelBuilder;\n+import org.apache.flink.table.planner.calcite.FlinkRelFactories;\n import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.utils.NestedColumn;\n import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MDA5Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518570092", "bodyText": "builder.watermark(xx)", "author": "godfreyhe", "createdAt": "2020-11-06T07:37:21Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}\n+\t\t});\n+\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\nindex c6eac3a7d56..25ec695e833 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n\n@@ -17,6 +17,8 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n+import org.apache.flink.table.planner.calcite.FlinkRelBuilder;\n+import org.apache.flink.table.planner.calcite.FlinkRelFactories;\n import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.utils.NestedColumn;\n import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MDcxMw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518570713", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-11-06T07:39:07Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}\n+\t\t});\n+\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\tindexOfRowTimeInTransposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\tList<RexNode> newProjects = NestedProjectionUtil.rewrite(project.getProjects(), nestedSchema, call.builder().getRexBuilder());\n+\t\tLogicalProject newProject = LogicalProject.create(newWatermarkAssigner, project.getHints(), newProjects, project.getRowType());", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\nindex c6eac3a7d56..25ec695e833 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n\n@@ -17,6 +17,8 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n+import org.apache.flink.table.planner.calcite.FlinkRelBuilder;\n+import org.apache.flink.table.planner.calcite.FlinkRelFactories;\n import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.utils.NestedColumn;\n import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MjU5NA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518572594", "bodyText": "overwrite the ref only its index equals to the index of rowtime", "author": "godfreyhe", "createdAt": "2020-11-06T07:43:52Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\nindex c6eac3a7d56..25ec695e833 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java\n\n@@ -17,6 +17,8 @@\n \n package org.apache.flink.table.planner.plan.rules.logical;\n \n+import org.apache.flink.table.planner.calcite.FlinkRelBuilder;\n+import org.apache.flink.table.planner.calcite.FlinkRelFactories;\n import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n import org.apache.flink.table.planner.plan.utils.NestedColumn;\n import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU4MDM3OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518580378", "bodyText": "\"PushWatermarkIntoTableSourceScanAcrossCalcRule\"", "author": "godfreyhe", "createdAt": "2020-11-06T08:01:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex 1a1b3b07503..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -28,12 +28,10 @@ import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAs\n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n import java.util.stream.Collectors;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU4MTA1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518581058", "bodyText": "use the element in projectList", "author": "godfreyhe", "createdAt": "2020-11-06T08:03:01Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\treturn supportsWatermarkPushDown(scan);\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexNode> projectList = originProgram.getProjectList().stream()\n+\t\t\t\t.map(originProgram::expandLocalRef)\n+\t\t\t\t.collect(Collectors.toList());\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = projectList.get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\t// replace the input ref of the rowtime with the computed column\n+\t\t\t\tif (inputRef.getIndex() == watermarkAssigner.rowtimeFieldIndex()) {\n+\t\t\t\t\treturn computedColumn;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn inputRef;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\n+\t\t// push watermark assigner into the scan\n+\t\tFlinkLogicalTableSourceScan newScan =\n+\t\t\t\tgetNewScan(watermarkAssigner, newWatermarkExpr, call.rel(2), ((FlinkContext) call.getPlanner().getContext()).getTableConfig());\n+\n+\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\t// cast timestamp type to rowtime type.\n+\t\tRexNode newComputedColumn = builder.makeReinterpretCast(\n+\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n+\t\t\t\tcomputedColumn,\n+\t\t\t\tnull);\n+\n+\t\t// build new calc program\n+\t\tRexProgramBuilder programBuilder = new RexProgramBuilder(newScan.getRowType(), builder);\n+\n+\t\tfor (int i = 0; i < projectList.size(); i++) {\n+\t\t\tPair<RexLocalRef, String> rexLocalRefStringPair = originProgram.getNamedProjects().get(i);", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\nindex 1a1b3b07503..912d0ce07ef 100644\n--- a/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n+++ b/flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java\n\n@@ -28,12 +28,10 @@ import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAs\n import org.apache.calcite.plan.RelOptRuleCall;\n import org.apache.calcite.rex.RexBuilder;\n import org.apache.calcite.rex.RexInputRef;\n-import org.apache.calcite.rex.RexLocalRef;\n import org.apache.calcite.rex.RexNode;\n import org.apache.calcite.rex.RexProgram;\n import org.apache.calcite.rex.RexProgramBuilder;\n import org.apache.calcite.rex.RexShuttle;\n-import org.apache.calcite.util.Pair;\n \n import java.util.List;\n import java.util.stream.Collectors;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU5Nzg0Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518597843", "bodyText": "define this class in JavaUserDefinedScalarFunctions", "author": "godfreyhe", "createdAt": "2020-11-06T08:37:50Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkVolcanoProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.Convention;\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.rel.rules.CoreRules;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tFlinkChainedProgram<StreamOptimizeContext> program = new FlinkChainedProgram<>();\n+\t\tprogram.addLast(\n+\t\t\t\t\"Converter\",\n+\t\t\t\tFlinkVolcanoProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tCoreRules.PROJECT_TO_CALC,\n+\t\t\t\t\t\t\t\tCoreRules.FILTER_TO_CALC,\n+\t\t\t\t\t\t\t\tFlinkLogicalCalc.CONVERTER(),\n+\t\t\t\t\t\t\t\tFlinkLogicalTableSourceScan.CONVERTER(),\n+\t\t\t\t\t\t\t\tFlinkLogicalWatermarkAssigner.CONVERTER()\n+\t\t\t\t\t\t\t\t))\n+\t\t\t\t\t\t.setRequiredOutputTraits(new Convention[] {FlinkConventions.LOGICAL()})\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t\tprogram.addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanAcrossCalcRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t\tutil.replaceStreamProgram(program);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR c AS c - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select a, c from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumn() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"  d AS c + INTERVAL '5' SECOND,\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithQuery() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3) NOT NULL,\\n\" +\n+\t\t\t\t\t\t\"  d AS c + INTERVAL '5' SECOND,\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT a, b FROM MyTable WHERE d > TO_TIMESTAMP('2020-10-09 12:12:12')\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithMultipleInputs() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a STRING,\\n\" +\n+\t\t\t\t\t\t\"  b STRING,\\n\" +\n+\t\t\t\t\t\t\"  c as TO_TIMESTAMP(a, b),\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR c AS c - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnRow() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c ROW<name STRING, d TIMESTAMP(3)>,\" +\n+\t\t\t\t\t\t\"  e AS c.d,\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR e AS e - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnNestedRow() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c ROW<name STRING, d row<e STRING, f TIMESTAMP(3)>>,\" +\n+\t\t\t\t\t\t\"  g as c.d.f,\" +\n+\t\t\t\t\t\t\"  WATERMARK for g as g - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkWithUdf() {\n+\t\tutil.addFunction(\"func1\", new InnerUdf());\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\" +\n+\t\t\t\t\t\t\"  d AS func1(c),\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t/**\n+\t * Udf for test.\n+\t * */\n+\tpublic static class InnerUdf extends ScalarFunction {", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6c252f9aeea7ec390706195833a6f5433f71b28c", "chunk": "diff --git a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\nindex 389bf65812d..dcdee828f23 100644\n--- a/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\n+++ b/flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java\n\n@@ -19,7 +19,6 @@\n package org.apache.flink.table.planner.plan.rules.logical;\n \n import org.apache.flink.table.api.TableConfig;\n-import org.apache.flink.table.functions.ScalarFunction;\n import org.apache.flink.table.planner.plan.nodes.FlinkConventions;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n"}}, {"oid": "6c252f9aeea7ec390706195833a6f5433f71b28c", "url": "https://github.com/apache/flink/commit/6c252f9aeea7ec390706195833a6f5433f71b28c", "message": "[FLINK-19282][planner] Support watermark push down in planner", "committedDate": "2020-11-06T13:24:54Z", "type": "commit"}, {"oid": "6c252f9aeea7ec390706195833a6f5433f71b28c", "url": "https://github.com/apache/flink/commit/6c252f9aeea7ec390706195833a6f5433f71b28c", "message": "[FLINK-19282][planner] Support watermark push down in planner", "committedDate": "2020-11-06T13:24:54Z", "type": "forcePushed"}]}