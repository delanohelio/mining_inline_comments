{"pr_number": 12560, "pr_title": "[FLINK-18097][history-server] Cleaning job files in history server", "pr_createdAt": "2020-06-09T15:28:12Z", "pr_url": "https://github.com/apache/flink/pull/12560", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437893569", "bodyText": "nit: can we reuse the variable defined in HistoryServerArchiveFetcher.java?", "author": "dmvk", "createdAt": "2020-06-10T06:44:17Z", "path": "flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java", "diffHunk": "@@ -78,6 +78,7 @@\n \t\t.disable(JsonGenerator.Feature.AUTO_CLOSE_JSON_CONTENT);\n \tprivate static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n \t\t.enable(DeserializationFeature.FAIL_ON_MISSING_CREATOR_PROPERTIES);\n+\tprivate static final String JSON_FILE_ENDING = \".json\";", "originalCommit": "3e40dddf2d2559baabc544e1254b942c853dd595", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyMTcwOQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437921709", "bodyText": "I guess that wouldn't be problem. There could be even more constants shared between HistoryServerArchiveFetcher and HistoryServerTest to make the code a bit cleaner.", "author": "Draczech", "createdAt": "2020-06-10T07:40:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNjA4Nw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437936087", "bodyText": "I made the JSON_FILE_ENDING package private to be used in test as well.", "author": "Draczech", "createdAt": "2020-06-10T08:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "chunk": "diff --git a/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java b/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\nindex eedc4bbe64..8c8ebb7ac7 100644\n--- a/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\n+++ b/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\n\n@@ -78,7 +90,6 @@ public class HistoryServerTest extends TestLogger {\n \t\t.disable(JsonGenerator.Feature.AUTO_CLOSE_JSON_CONTENT);\n \tprivate static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n \t\t.enable(DeserializationFeature.FAIL_ON_MISSING_CREATOR_PROPERTIES);\n-\tprivate static final String JSON_FILE_ENDING = \".json\";\n \n \t@Rule\n \tpublic final TemporaryFolder tmpFolder = new TemporaryFolder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5NDUwMQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437894501", "bodyText": "\ud83d\udc4d", "author": "dmvk", "createdAt": "2020-06-10T06:46:12Z", "path": "flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java", "diffHunk": "@@ -302,18 +289,37 @@ public void run() {\n \n \t\t\tcachedArchives.removeAll(jobsToRemove);\n \t\t\tjobsToRemove.forEach(removedJobID -> {\n-\t\t\t\ttry {\n-\t\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, removedJobID + JSON_FILE_ENDING).toPath());\n-\t\t\t\t\tFileUtils.deleteDirectory(new File(webJobDir, removedJobID));\n-\t\t\t\t} catch (IOException e) {\n-\t\t\t\t\tLOG.error(\"Failure while removing job overview for job {}.\", removedJobID, e);\n-\t\t\t\t}\n+\t\t\t\tdeleteJobFiles(removedJobID);\n \t\t\t\tdeleteLog.add(new ArchiveEvent(removedJobID, ArchiveEventType.DELETED));\n \t\t\t});\n \n \t\t\treturn deleteLog;\n \t\t}\n \n+\t\tprivate void deleteJobFiles(String jobID) {\n+\t\t\t// Make sure we do not include this job in the overview\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not delete file from overview directory.\", ioe);\n+\t\t\t}\n+\n+\t\t\t// Clean up job files we may have created\n+\t\t\tFile jobDirectory = new File(webJobDir, jobID);\n+\t\t\ttry {\n+\t\t\t\tFileUtils.deleteDirectory(jobDirectory);\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not clean up job directory.\", ioe);\n+\t\t\t}\n+\n+\t\t\t// Also clean up job json file in webJobDir\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webJobDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {", "originalCommit": "3e40dddf2d2559baabc544e1254b942c853dd595", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "chunk": "diff --git a/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java b/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\nindex d6d6d07c7e..24beb70ba9 100644\n--- a/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\n+++ b/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\n\n@@ -282,6 +307,19 @@ class HistoryServerArchiveFetcher {\n \t\t\t}\n \t\t}\n \n+\t\tprivate List<ArchiveEvent> cleanupJobsBeyondSizeLimit(Set<Path> jobArchivesToRemove) {\n+\t\t\tSet<String> jobIdsToRemoveFromOverview = new HashSet<>();\n+\t\t\tfor (Path archive : jobArchivesToRemove) {\n+\t\t\t\tjobIdsToRemoveFromOverview.add(archive.getName());\n+\t\t\t\ttry {\n+\t\t\t\t\tarchive.getFileSystem().delete(archive, false);\n+\t\t\t\t} catch (IOException ioe) {\n+\t\t\t\t\tLOG.warn(\"Could not delete old archive \" + archive, ioe);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn cleanupExpiredJobs(jobIdsToRemoveFromOverview);\n+\t\t}\n+\n \t\tprivate List<ArchiveEvent> cleanupExpiredJobs(Set<String> jobsToRemove) {\n \n \t\t\tList<ArchiveEvent> deleteLog = new ArrayList<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MDQ4Mw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438070483", "bodyText": "This test is written more from a user perspective, and as such I'd prefer if we instead check that /job/<jobId>/overview does (not) return a 404, instead of diving into the nitty-gritty details of how the files are stored on disk.", "author": "zentol", "createdAt": "2020-06-10T12:06:28Z", "path": "flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java", "diffHunk": "@@ -217,11 +219,19 @@ private void runArchiveExpirationTest(boolean cleanupExpiredJobs) throws Excepti\n \t\t\t\t.map(JobID::toString)\n \t\t\t\t.filter(jobId -> jobId.equals(jobIdToDelete))\n \t\t\t\t.count());\n+\t\t\tassertHSFilesExistence(jobIdToDelete, !cleanupExpiredJobs);", "originalCommit": "02f47cea448880d6d2f6185c3086158875818adb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA4NjM2Nw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438086367", "bodyText": "Well, the purpose of the fix was deleting files. As there haven't been any test for that so far I added them to show that now all files are deleted properly with HS cleaning feature enabled.", "author": "Draczech", "createdAt": "2020-06-10T12:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MDQ4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "chunk": "diff --git a/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java b/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\nindex 9b0f170506..8c8ebb7ac7 100644\n--- a/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\n+++ b/flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java\n\n@@ -205,13 +299,12 @@ public class HistoryServerTest extends TestLogger {\n \t\t\t\t.map(JobID::toString)\n \t\t\t\t.orElseThrow(() -> new IllegalStateException(\"Expected at least one existing job\"));\n \n-\t\t\tassertHSFilesExistence(jobIdToDelete, true);\n \t\t\t// delete one archive from jm\n \t\t\tFiles.deleteIfExists(jmDirectory.toPath().resolve(jobIdToDelete));\n \n-\t\t\tassertTrue(numExpectedExpiredJobs.await(10L, TimeUnit.SECONDS));\n+\t\t\tassertTrue(firstArchiveExpiredLatch.await(10L, TimeUnit.SECONDS));\n \n-\t\t\t// check that archive is present in hs\n+\t\t\t// check that archive is still/no longer present in hs\n \t\t\tCollection<JobDetails> jobsAfterDeletion = getJobsOverview(baseUrl).getJobs();\n \t\t\tAssert.assertEquals(numJobs - numExpiredJobs, jobsAfterDeletion.size());\n \t\t\tAssert.assertEquals(1 - numExpiredJobs, jobsAfterDeletion.stream()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MjUyNQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438072525", "bodyText": "This changes the log level, which is a bit annoying for the cleanup if a download fails. In that case it is quite likely that we will try to delete something that was never created; for which we shouldn't be logging a warning.", "author": "zentol", "createdAt": "2020-06-10T12:10:25Z", "path": "flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java", "diffHunk": "@@ -302,18 +289,37 @@ public void run() {\n \n \t\t\tcachedArchives.removeAll(jobsToRemove);\n \t\t\tjobsToRemove.forEach(removedJobID -> {\n-\t\t\t\ttry {\n-\t\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, removedJobID + JSON_FILE_ENDING).toPath());\n-\t\t\t\t\tFileUtils.deleteDirectory(new File(webJobDir, removedJobID));\n-\t\t\t\t} catch (IOException e) {\n-\t\t\t\t\tLOG.error(\"Failure while removing job overview for job {}.\", removedJobID, e);\n-\t\t\t\t}\n+\t\t\t\tdeleteJobFiles(removedJobID);\n \t\t\t\tdeleteLog.add(new ArchiveEvent(removedJobID, ArchiveEventType.DELETED));\n \t\t\t});\n \n \t\t\treturn deleteLog;\n \t\t}\n \n+\t\tprivate void deleteJobFiles(String jobID) {\n+\t\t\t// Make sure we do not include this job in the overview\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not delete file from overview directory.\", ioe);", "originalCommit": "02f47cea448880d6d2f6185c3086158875818adb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA5MzY5NA==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438093694", "bodyText": "For this reason I also changed deleting method to Files.deleteIfExists. So there should be logs only for cases when deleting of actually existing file fails. Also FileUtils.deleteDirectory doesn't do anything in case the directory doesn't exist.\nSo warning is used only if there is an actual problem with deleting existing files. Let me know if it is desired level for such cases.", "author": "Draczech", "createdAt": "2020-06-10T12:47:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MjUyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "chunk": "diff --git a/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java b/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\nindex 26b5a4bc8a..24beb70ba9 100644\n--- a/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\n+++ b/flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java\n\n@@ -282,6 +307,19 @@ class HistoryServerArchiveFetcher {\n \t\t\t}\n \t\t}\n \n+\t\tprivate List<ArchiveEvent> cleanupJobsBeyondSizeLimit(Set<Path> jobArchivesToRemove) {\n+\t\t\tSet<String> jobIdsToRemoveFromOverview = new HashSet<>();\n+\t\t\tfor (Path archive : jobArchivesToRemove) {\n+\t\t\t\tjobIdsToRemoveFromOverview.add(archive.getName());\n+\t\t\t\ttry {\n+\t\t\t\t\tarchive.getFileSystem().delete(archive, false);\n+\t\t\t\t} catch (IOException ioe) {\n+\t\t\t\t\tLOG.warn(\"Could not delete old archive \" + archive, ioe);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn cleanupExpiredJobs(jobIdsToRemoveFromOverview);\n+\t\t}\n+\n \t\tprivate List<ArchiveEvent> cleanupExpiredJobs(Set<String> jobsToRemove) {\n \n \t\t\tList<ArchiveEvent> deleteLog = new ArrayList<>();\n"}}, {"oid": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "url": "https://github.com/apache/flink/commit/8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "message": "[FLINK-18097][history] Delete all job-related files on expiration", "committedDate": "2020-07-07T19:50:12Z", "type": "commit"}, {"oid": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "url": "https://github.com/apache/flink/commit/8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "message": "[FLINK-18097][history] Delete all job-related files on expiration", "committedDate": "2020-07-07T19:50:12Z", "type": "forcePushed"}]}