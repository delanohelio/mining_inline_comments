{"pr_number": 13902, "pr_title": "[FLINK-19941][Connectors / Kafka]Support sink parallelism configuration to Kafka connector", "pr_createdAt": "2020-11-03T08:45:05Z", "pr_url": "https://github.com/apache/flink/pull/13902", "timeline": [{"oid": "a256a28f6cebf586309a7cfb8d15c5ddb1890e9f", "url": "https://github.com/apache/flink/commit/a256a28f6cebf586309a7cfb8d15c5ddb1890e9f", "message": "[FLINK-19941][Connectors / Kafka]Support sink parallelism configuration to Kafka connector", "committedDate": "2020-11-03T08:39:57Z", "type": "commit"}, {"oid": "a3c798b00f7596f539c9bd9e206611f2c981bd98", "url": "https://github.com/apache/flink/commit/a3c798b00f7596f539c9bd9e206611f2c981bd98", "message": "[FLINK-19941][Connectors / Kafka]Support sink parallelism configuration to Kafka connector", "committedDate": "2020-11-03T09:46:26Z", "type": "commit"}, {"oid": "46ec64b96f816e080f4e8d25024c0ffea4884a1a", "url": "https://github.com/apache/flink/commit/46ec64b96f816e080f4e8d25024c0ffea4884a1a", "message": "add docs", "committedDate": "2020-11-03T11:29:11Z", "type": "commit"}, {"oid": "0b19dd363604fb00239da34f02762c9bc194a300", "url": "https://github.com/apache/flink/commit/0b19dd363604fb00239da34f02762c9bc194a300", "message": "fix checkstyle", "committedDate": "2020-11-03T16:36:54Z", "type": "commit"}, {"oid": "bb8469feac8cd4d4ba5032e5306a57aa3e41d6dc", "url": "https://github.com/apache/flink/commit/bb8469feac8cd4d4ba5032e5306a57aa3e41d6dc", "message": "fix doc", "committedDate": "2020-11-03T16:46:00Z", "type": "commit"}, {"oid": "1c50df79274b61c21aefbae266cdabef63ff4e07", "url": "https://github.com/apache/flink/commit/1c50df79274b61c21aefbae266cdabef63ff4e07", "message": "update", "committedDate": "2020-11-04T02:51:30Z", "type": "commit"}, {"oid": "dc78068f8b87f8a82df7574095d2f5695c690112", "url": "https://github.com/apache/flink/commit/dc78068f8b87f8a82df7574095d2f5695c690112", "message": "update", "committedDate": "2020-11-04T02:54:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA2OTQ2Mg==", "url": "https://github.com/apache/flink/pull/13902#discussion_r517069462", "bodyText": "Can simplify to Optional.ofNullable(parallelism).", "author": "wuchong", "createdAt": "2020-11-04T02:52:02Z", "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java", "diffHunk": "@@ -282,6 +288,20 @@ public int hashCode() {\n \t\treturn format.createRuntimeEncoder(context, physicalFormatDataType);\n \t}\n \n+\t/**\n+\t * Returns the parallelism for this instance.\n+\t *\n+\t * <p>The parallelism denotes how many parallel instances of a source or sink will be spawned\n+\t * during the execution.\n+\t *\n+\t * @return empty if the connector does not provide a custom parallelism, then the planner will\n+\t * decide the number of parallel instances by itself.\n+\t */\n+\t@Override\n+\tpublic Optional<Integer> getParallelism() {\n+\t\treturn parallelism != null ? Optional.of(parallelism) : Optional.empty();", "originalCommit": "bb8469feac8cd4d4ba5032e5306a57aa3e41d6dc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dc78068f8b87f8a82df7574095d2f5695c690112", "chunk": "diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\nindex a73f6591970..a43b903736c 100644\n--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\n+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\n\n@@ -288,20 +298,6 @@ public class KafkaDynamicSink implements DynamicTableSink, SupportsWritingMetada\n \t\treturn format.createRuntimeEncoder(context, physicalFormatDataType);\n \t}\n \n-\t/**\n-\t * Returns the parallelism for this instance.\n-\t *\n-\t * <p>The parallelism denotes how many parallel instances of a source or sink will be spawned\n-\t * during the execution.\n-\t *\n-\t * @return empty if the connector does not provide a custom parallelism, then the planner will\n-\t * decide the number of parallel instances by itself.\n-\t */\n-\t@Override\n-\tpublic Optional<Integer> getParallelism() {\n-\t\treturn parallelism != null ? Optional.of(parallelism) : Optional.empty();\n-\t}\n-\n \t// --------------------------------------------------------------------------------------------\n \t// Metadata handling\n \t// --------------------------------------------------------------------------------------------\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3MjgxMQ==", "url": "https://github.com/apache/flink/pull/13902#discussion_r517072811", "bodyText": "Could you add a new util method in SinkFunctionProvider? I think most of the connector can use this new method.\n\t/**\n\t * Helper method for creating a SinkFunction provider with a provided sink parallelism.\n\t */\n\tstatic SinkFunctionProvider of(SinkFunction<RowData> sinkFunction, Integer sinkParallelism) {\n\t\treturn new SinkFunctionProvider() {\n\n\t\t\t@Override\n\t\t\tpublic SinkFunction<RowData> createSinkFunction() {\n\t\t\t\treturn sinkFunction;\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic Optional<Integer> getParallelism() {\n\t\t\t\treturn Optional.ofNullable(sinkParallelism);\n\t\t\t}\n\t\t};\n\t}", "author": "wuchong", "createdAt": "2020-11-04T03:04:58Z", "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java", "diffHunk": "@@ -145,7 +150,17 @@ public SinkRuntimeProvider getSinkRuntimeProvider(Context context) {\n \t\tfinal FlinkKafkaProducer<RowData> kafkaProducer =\n \t\t\t\tcreateKafkaProducer(keySerialization, valueSerialization);\n \n-\t\treturn SinkFunctionProvider.of(kafkaProducer);\n+\t\treturn new SinkFunctionProvider() {", "originalCommit": "dc78068f8b87f8a82df7574095d2f5695c690112", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3Mzk1NA==", "url": "https://github.com/apache/flink/pull/13902#discussion_r517073954", "bodyText": "yes,it's better to have common function", "author": "zhuxiaoshang", "createdAt": "2020-11-04T03:09:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3MjgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "f7d8e95015408dc337e9ccc71f51a23b067f3e23", "chunk": "diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\nindex a43b903736c..55d01945f4b 100644\n--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\n+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSink.java\n\n@@ -150,17 +150,7 @@ public class KafkaDynamicSink implements DynamicTableSink, SupportsWritingMetada\n \t\tfinal FlinkKafkaProducer<RowData> kafkaProducer =\n \t\t\t\tcreateKafkaProducer(keySerialization, valueSerialization);\n \n-\t\treturn new SinkFunctionProvider() {\n-\t\t\t@Override\n-\t\t\tpublic SinkFunction<RowData> createSinkFunction() {\n-\t\t\t\treturn kafkaProducer;\n-\t\t\t}\n-\n-\t\t\t@Override\n-\t\t\tpublic Optional<Integer> getParallelism() {\n-\t\t\t\treturn parallelism == null ? Optional.empty() : Optional.of(parallelism);\n-\t\t\t}\n-\t\t};\n+\t\treturn SinkFunctionProvider.of(kafkaProducer, parallelism);\n \t}\n \n \t@Override\n"}}, {"oid": "f7d8e95015408dc337e9ccc71f51a23b067f3e23", "url": "https://github.com/apache/flink/commit/f7d8e95015408dc337e9ccc71f51a23b067f3e23", "message": "update", "committedDate": "2020-11-04T03:16:50Z", "type": "commit"}, {"oid": "2b88714d0fc1ffc0f35e3086b5fc52f9b778ea09", "url": "https://github.com/apache/flink/commit/2b88714d0fc1ffc0f35e3086b5fc52f9b778ea09", "message": "fix checkstyle", "committedDate": "2020-11-04T06:33:08Z", "type": "commit"}]}