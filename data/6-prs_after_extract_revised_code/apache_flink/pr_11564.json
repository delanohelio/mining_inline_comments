{"pr_number": 11564, "pr_title": "[FLINK-16864][metrics] Add IdleTime metric for task.", "pr_createdAt": "2020-03-30T12:03:31Z", "pr_url": "https://github.com/apache/flink/pull/11564", "timeline": [{"oid": "0542c5dc966c56853433d487858711cbba1d9eb3", "url": "https://github.com/apache/flink/commit/0542c5dc966c56853433d487858711cbba1d9eb3", "message": "add doc for idle metric", "committedDate": "2020-03-31T02:09:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5MTY1MQ==", "url": "https://github.com/apache/flink/pull/11564#discussion_r400791651", "bodyText": "typo idleTimePerSecond", "author": "pnowojski", "createdAt": "2020-03-31T10:03:57Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/groups/TaskIOMetricGroup.java", "diffHunk": "@@ -45,6 +45,7 @@\n \tprivate final Meter numRecordsInRate;\n \tprivate final Meter numRecordsOutRate;\n \tprivate final Meter numBuffersOutRate;\n+\tprivate final Meter idlTimePerSecond;", "originalCommit": "0542c5dc966c56853433d487858711cbba1d9eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "dfc6f9642a2fe6fca383707a11d53ef6ed2ea381", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/groups/TaskIOMetricGroup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/groups/TaskIOMetricGroup.java\nindex 232e208962..e2b984a5c4 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/groups/TaskIOMetricGroup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/groups/TaskIOMetricGroup.java\n\n@@ -45,7 +45,7 @@ public class TaskIOMetricGroup extends ProxyMetricGroup<TaskMetricGroup> {\n \tprivate final Meter numRecordsInRate;\n \tprivate final Meter numRecordsOutRate;\n \tprivate final Meter numBuffersOutRate;\n-\tprivate final Meter idlTimePerSecond;\n+\tprivate final Meter idleTimePerSecond;\n \n \tpublic TaskIOMetricGroup(TaskMetricGroup parent) {\n \t\tsuper(parent);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMTM2NA==", "url": "https://github.com/apache/flink/pull/11564#discussion_r400801364", "bodyText": "I think this is most of the times correct, however there might be a race condition with NetworkBufferPool#redistributeBuffers and isApproximatelyAvailable() check. Check might return available, while the method would still block.\nThe proper way of doing it would be to add non blocking version of the method getBufferBuilder() (or rather rename the existing one to getBufferBuilderBlocking() and implement new getBufferBuilder() which would be non blocking)   to the ResultPartition (and BufferPool + LocalBufferPool). It should be easy, as there are already non blocking methods for requesting memory segments.", "author": "pnowojski", "createdAt": "2020-03-31T10:20:19Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java", "diffHunk": "@@ -276,6 +281,21 @@ protected void checkErroneous() throws IOException {\n \t\t}\n \t}\n \n+\tprotected void addBufferConsumer(BufferConsumer consumer, int targetChannel) throws IOException {\n+\t\ttargetPartition.addBufferConsumer(consumer, targetChannel);\n+\t}\n+\n+\tprotected BufferBuilder getBufferBuilder() throws IOException, InterruptedException {\n+\t\tBufferBuilder builder;\n+\t\tif (!targetPartition.isApproximatelyAvailable()) {\n+\t\t\tlong start = System.currentTimeMillis();\n+\t\t\tbuilder = targetPartition.getBufferBuilder();\n+\t\t\tidleTimeMsPerSecond.markEvent(System.currentTimeMillis() - start);\n+\t\t} else {\n+\t\t\tbuilder = targetPartition.getBufferBuilder();\n+\t\t}\n+\t\treturn builder;\n+\t}", "originalCommit": "0542c5dc966c56853433d487858711cbba1d9eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNzU0Mg==", "url": "https://github.com/apache/flink/pull/11564#discussion_r401327542", "bodyText": "NetworkBufferPool#redistributeBuffers reduce the buffer available only when new task deployed right? I think it can be ignored, because we use meter to measure average idle time which use a time window by default 60s and redistributeBuffers happens in very low frequence.", "author": "wenlong88", "createdAt": "2020-04-01T02:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMTM2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA0MzE2MQ==", "url": "https://github.com/apache/flink/pull/11564#discussion_r403043161", "bodyText": "The thing is that the code might change/evolve over time making this check even more wrong. Yes now this bug is pretty harmless, but if we can make it easily completely correct, why not doing it? Proper fix is just ~5 lines of code in LocalBufferPool to provide LocalBufferPool#requestBufferBuilder, maybe 5 more lines TestPooledBufferProvider, add the method to the BufferPool interface and proxy/expose it in the ResultPartition.", "author": "pnowojski", "createdAt": "2020-04-03T14:25:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMTM2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc4NTEwNQ==", "url": "https://github.com/apache/flink/pull/11564#discussion_r404785105", "bodyText": "Thanks for the update!", "author": "pnowojski", "createdAt": "2020-04-07T12:54:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMTM2NA=="}], "type": "inlineReview", "revised_code": {"commit": "dfc6f9642a2fe6fca383707a11d53ef6ed2ea381", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java\nindex ada5c905ac..4352e6688e 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/writer/RecordWriter.java\n\n@@ -285,7 +285,8 @@ public abstract class RecordWriter<T extends IOReadableWritable> implements Avai\n \t\ttargetPartition.addBufferConsumer(consumer, targetChannel);\n \t}\n \n-\tprotected BufferBuilder getBufferBuilder() throws IOException, InterruptedException {\n+\t@VisibleForTesting\n+\tpublic BufferBuilder getBufferBuilder() throws IOException, InterruptedException {\n \t\tBufferBuilder builder;\n \t\tif (!targetPartition.isApproximatelyAvailable()) {\n \t\t\tlong start = System.currentTimeMillis();\n"}}, {"oid": "dfc6f9642a2fe6fca383707a11d53ef6ed2ea381", "url": "https://github.com/apache/flink/commit/dfc6f9642a2fe6fca383707a11d53ef6ed2ea381", "message": "add idle time metrics for task.", "committedDate": "2020-04-03T03:51:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzA0NTExNw==", "url": "https://github.com/apache/flink/pull/11564#discussion_r403045117", "bodyText": "Test is failing on azure:\n[ERROR] Failures: \n[ERROR]   BroadcastRecordWriterTest>RecordWriterTest.testIdleTime:505 \nExpected: a value equal to or greater than <10L>\n     but: <0L> was less than <10L>\n[ERROR]   RecordWriterTest.testIdleTime:505 \nExpected: a value equal to or greater than <10L>\n     but: <0L> was less than <10L>", "author": "pnowojski", "createdAt": "2020-04-03T14:28:09Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/api/writer/RecordWriterTest.java", "diffHunk": "@@ -464,6 +466,46 @@ public void testIsAvailableOrNot() throws Exception {\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testIdleTime() throws IOException, InterruptedException {", "originalCommit": "dfc6f9642a2fe6fca383707a11d53ef6ed2ea381", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e41026b4385126ab1405cba5ec96298f490be248", "chunk": "diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/api/writer/RecordWriterTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/api/writer/RecordWriterTest.java\nindex 3ae01a3d50..98ff3b2e87 100644\n--- a/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/api/writer/RecordWriterTest.java\n+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/api/writer/RecordWriterTest.java\n\n@@ -460,12 +484,66 @@ public class RecordWriterTest {\n \t\t\tbuffer.recycleBuffer();\n \t\t\tassertTrue(recordWriter.getAvailableFuture().isDone());\n \t\t\tassertEquals(recordWriter.AVAILABLE, recordWriter.getAvailableFuture());\n+\n \t\t} finally {\n \t\t\tlocalPool.lazyDestroy();\n \t\t\tglobalPool.destroy();\n \t\t}\n \t}\n \n+\t@Test\n+\tpublic void testEmitRecordWithPartitionStateRecovery() throws Exception {\n+\t\tfinal int totalBuffers = 10; // enough for both states and normal records\n+\t\tfinal int totalStates = 2;\n+\t\tfinal int[] states = {1, 2, 3, 4};\n+\t\tfinal int[] records = {5, 6, 7, 8};\n+\t\tfinal int bufferSize = states.length * Integer.BYTES;\n+\n+\t\tfinal NetworkBufferPool globalPool = new NetworkBufferPool(totalBuffers, bufferSize, 1);\n+\t\tfinal ChannelStateReader stateReader = new ResultPartitionTest.FiniteChannelStateReader(totalStates, states);\n+\t\tfinal ResultPartition partition = new ResultPartitionBuilder()\n+\t\t\t.setNetworkBufferPool(globalPool)\n+\t\t\t.build();\n+\t\tfinal RecordWriter<IntValue> recordWriter = new RecordWriterBuilder<IntValue>().build(partition);\n+\n+\t\ttry {\n+\t\t\tpartition.setup();\n+\t\t\tpartition.initializeState(stateReader);\n+\n+\t\t\tfor (int record: records) {\n+\t\t\t\t// the record length 4 is also written into buffer for every emit\n+\t\t\t\trecordWriter.broadcastEmit(new IntValue(record));\n+\t\t\t}\n+\n+\t\t\t// every buffer can contain 2 int records with 2 int length(4)\n+\t\t\tfinal int[][] expectedRecordsInBuffer = {{4, 5, 4, 6}, {4, 7, 4, 8}};\n+\n+\t\t\tfor (ResultSubpartition subpartition : partition.getAllPartitions()) {\n+\t\t\t\t// create the view to consume all the buffers with states and records\n+\t\t\t\tfinal ResultSubpartitionView view = new PipelinedSubpartitionView(\n+\t\t\t\t\t(PipelinedSubpartition) subpartition,\n+\t\t\t\t\tnew NoOpBufferAvailablityListener());\n+\n+\t\t\t\tint numConsumedBuffers = 0;\n+\t\t\t\tResultSubpartition.BufferAndBacklog bufferAndBacklog;\n+\t\t\t\twhile ((bufferAndBacklog = view.getNextBuffer()) != null) {\n+\t\t\t\t\tBuffer buffer = bufferAndBacklog.buffer();\n+\t\t\t\t\tint[] expected = numConsumedBuffers < totalStates ? states : expectedRecordsInBuffer[numConsumedBuffers - totalStates];\n+\t\t\t\t\tBufferBuilderAndConsumerTest.assertContent(buffer, partition.getBufferPool(), expected);\n+\n+\t\t\t\t\tbuffer.recycleBuffer();\n+\t\t\t\t\tnumConsumedBuffers++;\n+\t\t\t\t}\n+\n+\t\t\t\tassertEquals(totalStates + expectedRecordsInBuffer.length, numConsumedBuffers);\n+\t\t\t}\n+\t\t} finally {\n+\t\t\t// cleanup\n+\t\t\tglobalPool.destroyAllBufferPools();\n+\t\t\tglobalPool.destroy();\n+\t\t}\n+\t}\n+\n \t@Test\n \tpublic void testIdleTime() throws IOException, InterruptedException {\n \t\t// setup\n"}}, {"oid": "e41026b4385126ab1405cba5ec96298f490be248", "url": "https://github.com/apache/flink/commit/e41026b4385126ab1405cba5ec96298f490be248", "message": "add non blocking request buffer builder.", "committedDate": "2020-04-07T15:44:14Z", "type": "forcePushed"}, {"oid": "3aa5c9ddf82d9ac50f5a0e0ce8f3161f19545dde", "url": "https://github.com/apache/flink/commit/3aa5c9ddf82d9ac50f5a0e0ce8f3161f19545dde", "message": "[FLINK-16864][metrics] Add IdleTime metric for task\n\nThis pr adds an IdleTime metric which measures idle time of a task including the time cost for mail processor to wait for new mail and the time cost in record writer to waiting a new buffer.\n\n1. when a job can not catch up with the speed of data generating, the vertex which idle time is near to zero is the bottle neck of the job.\n2. when a job is not busy, idle time can be used to guide user how much he can scale down the job.", "committedDate": "2020-04-08T07:44:58Z", "type": "commit"}, {"oid": "3aa5c9ddf82d9ac50f5a0e0ce8f3161f19545dde", "url": "https://github.com/apache/flink/commit/3aa5c9ddf82d9ac50f5a0e0ce8f3161f19545dde", "message": "[FLINK-16864][metrics] Add IdleTime metric for task\n\nThis pr adds an IdleTime metric which measures idle time of a task including the time cost for mail processor to wait for new mail and the time cost in record writer to waiting a new buffer.\n\n1. when a job can not catch up with the speed of data generating, the vertex which idle time is near to zero is the bottle neck of the job.\n2. when a job is not busy, idle time can be used to guide user how much he can scale down the job.", "committedDate": "2020-04-08T07:44:58Z", "type": "forcePushed"}]}