{"pr_number": 10820, "pr_title": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)", "pr_createdAt": "2020-01-09T18:44:22Z", "pr_url": "https://github.com/apache/flink/pull/10820", "timeline": [{"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "url": "https://github.com/apache/flink/commit/bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "message": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)\n\nDue to the implemenation of write buffer manager of RocksDB and the issue cannot create stric capacity limit cache, we need to refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s).", "committedDate": "2020-01-09T18:13:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzU2OQ==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127569", "bodyText": "Suggest to add a TODO comment here, mentioning that we will change the strictCapacityLimit flag to true after rocksdb#6247 is resolved.", "author": "carp84", "createdAt": "2020-01-10T08:53:15Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).\n+\t * We introduce this method because:\n+\t * a) We cannot create a strict capacity limit cache util FLINK-15532 resolved.\n+\t * b) Regardless of the memory usage of blocks pinned by RocksDB iterators,\n+\t * which is difficult to calculate and only happened when we iterator entries in RocksDBMapState, the overuse of memory is mainly occupied by at most half of the write buffer usage.\n+\t * (see <a href=\"https://github.com/dataArtisans/frocksdb/blob/958f191d3f7276ae59b270f9db8390034d549ee0/include/rocksdb/write_buffer_manager.h#L51\">the flush implementation of write buffer manager</a>).\n+\t * Thus, we have four equations below:\n+\t *   write_buffer_manager_memory = 1.5 * write_buffer_manager_capacity\n+\t *   write_buffer_manager_memory = total_memory_size * write_buffer_ratio\n+\t *   write_buffer_manager_memory + other_part = total_memory_size\n+\t *   write_buffer_manager_capacity + other_part = cache_size\n+\t * And we would deduce the formula: cache_size = 3 * total_memory_size / (3 + write_buffer_ratio)\n+\t *\n+\t * @param totalMemorySize  Total off-heap memory size reserved for RocksDB instance(s).\n+\t * @param writeBufferRatio The ratio of memory size which could be reserved for write buffer manager to control the memory usage.\n+\t * @return The actual calculated memory size.\n+\t */\n+\t@VisibleForTesting\n+\tstatic long calculateActualCacheSize(long totalMemorySize, double writeBufferRatio) {\n+\t\treturn (long) (3 * totalMemorySize / (3 + writeBufferRatio));\n+\t}\n+\n+\t@VisibleForTesting\n+\tstatic Cache createCache(long cacheSize, double highPriorityPoolRatio) {\n+\t\treturn new LRUCache(cacheSize, -1, false, highPriorityPoolRatio);", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\nindex 4b0cd9cfae7..3f3f90532a6 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n\n@@ -213,10 +213,11 @@ public class RocksDBOperationUtils {\n \t}\n \n \t@VisibleForTesting\n-\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n-\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n-\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n-\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n+\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n \t\treturn new RocksDBSharedResources(cache, wbm);\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzkyNA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127924", "bodyText": "Ditto, please revert this change if no rational reason.", "author": "carp84", "createdAt": "2020-01-10T08:54:07Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java", "diffHunk": "@@ -121,7 +121,7 @@\n \t\t.doubleType()\n \t\t.defaultValue(0.1)\n \t\t.withDescription(String.format(\n-\t\t\t\t\"The fraction of cache memory that is reserved for high-priority data like index, filter, and \" +\n+\t\t\t\t\"The fraction of total shared memory that is reserved for high-priority data like index, filter, and \" +", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java\nindex df389f88707..c94aa19420e 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java\n\n@@ -121,7 +121,7 @@ public class RocksDBOptions {\n \t\t.doubleType()\n \t\t.defaultValue(0.1)\n \t\t.withDescription(String.format(\n-\t\t\t\t\"The fraction of total shared memory that is reserved for high-priority data like index, filter, and \" +\n+\t\t\t\t\"The fraction of cache memory that is reserved for high-priority data like index, filter, and \" +\n \t\t\t\t\"compression dictionary blocks. This option only has an effect when '%s' or '%s' are configured.\",\n \t\t\t\tUSE_MANAGED_MEMORY.key(),\n \t\t\t\tFIX_PER_SLOT_MEMORY_SIZE.key()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNjkxMA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365226910", "bodyText": "The WriteBufferManager size should also be calculated with the deduced formula: 2 * total_memory_size * write_buffer_ratio / 3", "author": "carp84", "createdAt": "2020-01-10T13:12:41Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\nindex 4b0cd9cfae7..3f3f90532a6 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n\n@@ -213,10 +213,11 @@ public class RocksDBOperationUtils {\n \t}\n \n \t@VisibleForTesting\n-\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n-\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n-\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n-\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n+\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n \t\treturn new RocksDBSharedResources(cache, wbm);\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNzkzMQ==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365227931", "bodyText": "The design of this test seems to be tightly coupled with the implementation, while it's true that we cannot get the actual cache size through RocksDB's JNI (not exposed so reflection couldn't get it, either)", "author": "carp84", "createdAt": "2020-01-10T13:15:42Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\nindex d263ec1b2bd..8672befb577 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\n\n@@ -163,12 +163,12 @@ public class RocksDBResourceContainerTest {\n \t@Test\n \tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {\n \t\tPowerMockito.spy(RocksDBOperationUtils.class);\n-\t\tfinal AtomicLong actualCacheSize = new AtomicLong(0L);\n+\t\tfinal AtomicLong actualCacheCapacity = new AtomicLong(0L);\n \t\t// the `createCache` wrapper is introduced due to PowerMockito cannot mock on native static method easily.\n \t\tPowerMockito.when(RocksDBOperationUtils.createCache(anyLong(), anyDouble()))\n \t\t\t.thenAnswer((Answer<LRUCache>) invocation -> {\n \t\t\t\tObject[] arguments = invocation.getArguments();\n-\t\t\t\tactualCacheSize.set((long) arguments[0]);\n+\t\t\t\tactualCacheCapacity.set((long) arguments[0]);\n \t\t\t\treturn (LRUCache) invocation.callRealMethod();\n \t\t\t});\n \n"}}, {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "url": "https://github.com/apache/flink/commit/64d8a9a6821c95f904ca567afd7a056be7f04f3a", "message": "address comments", "committedDate": "2020-01-10T17:25:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NDk2OA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365564968", "bodyText": "I suggest to either remove this test, or also add a verification of write buffer manager size.", "author": "carp84", "createdAt": "2020-01-12T08:11:49Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {\n+\t\tPowerMockito.spy(RocksDBOperationUtils.class);\n+\t\tfinal AtomicLong actualCacheCapacity = new AtomicLong(0L);\n+\t\t// the `createCache` wrapper is introduced due to PowerMockito cannot mock on native static method easily.\n+\t\tPowerMockito.when(RocksDBOperationUtils.createCache(anyLong(), anyDouble()))\n+\t\t\t.thenAnswer((Answer<LRUCache>) invocation -> {\n+\t\t\t\tObject[] arguments = invocation.getArguments();\n+\t\t\t\tactualCacheCapacity.set((long) arguments[0]);\n+\t\t\t\treturn (LRUCache) invocation.callRealMethod();\n+\t\t\t});\n+\n+\t\tlong totalMemorySize = 2048L;\n+\t\tdouble writeBufferRatio = 0.5;\n+\t\tdouble highPriPoolRatio = 0.1;\n+\t\tcreateSharedResources(totalMemorySize, writeBufferRatio, highPriPoolRatio);\n+\t\tlong expectedCacheCapacity = RocksDBOperationUtils.calculateActualCacheCapacity(totalMemorySize, writeBufferRatio);\n+\t\tassertThat(actualCacheCapacity.get(), is(expectedCacheCapacity));", "originalCommit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d9edb24152bed26f717b6f87725efaa796d64e9", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\nindex 8672befb577..73d4babb72e 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java\n\n@@ -160,34 +145,12 @@ public class RocksDBResourceContainerTest {\n \t\tcontainer.close();\n \t}\n \n-\t@Test\n-\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {\n-\t\tPowerMockito.spy(RocksDBOperationUtils.class);\n-\t\tfinal AtomicLong actualCacheCapacity = new AtomicLong(0L);\n-\t\t// the `createCache` wrapper is introduced due to PowerMockito cannot mock on native static method easily.\n-\t\tPowerMockito.when(RocksDBOperationUtils.createCache(anyLong(), anyDouble()))\n-\t\t\t.thenAnswer((Answer<LRUCache>) invocation -> {\n-\t\t\t\tObject[] arguments = invocation.getArguments();\n-\t\t\t\tactualCacheCapacity.set((long) arguments[0]);\n-\t\t\t\treturn (LRUCache) invocation.callRealMethod();\n-\t\t\t});\n-\n-\t\tlong totalMemorySize = 2048L;\n-\t\tdouble writeBufferRatio = 0.5;\n-\t\tdouble highPriPoolRatio = 0.1;\n-\t\tcreateSharedResources(totalMemorySize, writeBufferRatio, highPriPoolRatio);\n-\t\tlong expectedCacheCapacity = RocksDBOperationUtils.calculateActualCacheCapacity(totalMemorySize, writeBufferRatio);\n-\t\tassertThat(actualCacheCapacity.get(), is(expectedCacheCapacity));\n-\t}\n-\n \tprivate OpaqueMemoryResource<RocksDBSharedResources> getSharedResources() {\n-\t\treturn createSharedResources(1024L, 0.5, 0.1);\n-\t}\n-\n-\tprivate OpaqueMemoryResource<RocksDBSharedResources> createSharedResources(long totalMemorySize, double writeBufferRatio, double highPriPoolRatio) {\n-\t\tRocksDBSharedResources rocksDBSharedResources = RocksDBOperationUtils\n-\t\t\t.allocateRocksDBSharedResources(totalMemorySize, writeBufferRatio, highPriPoolRatio);\n-\t\treturn new OpaqueMemoryResource<>(rocksDBSharedResources, totalMemorySize, rocksDBSharedResources::close);\n+\t\tfinal long cacheSize = 1024L, writeBufferSize = 512L;\n+\t\tfinal LRUCache cache = new LRUCache(cacheSize, -1, false, 0.1);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferSize, cache);\n+\t\tRocksDBSharedResources rocksDBSharedResources = new RocksDBSharedResources(cache, wbm);\n+\t\treturn new OpaqueMemoryResource<>(rocksDBSharedResources, cacheSize, rocksDBSharedResources::close);\n \t}\n \n \tprivate Cache getBlockCache(ColumnFamilyOptions columnOptions) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NTAxMA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365565010", "bodyText": "Minor: the actual calculated memory size -> the actual memory size", "author": "carp84", "createdAt": "2020-01-12T08:12:39Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,49 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n+\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).", "originalCommit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d9edb24152bed26f717b6f87725efaa796d64e9", "chunk": "diff --git a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\nindex 3f3f90532a6..45df7283ade 100644\n--- a/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n+++ b/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java\n\n@@ -211,49 +207,4 @@ public class RocksDBOperationUtils {\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n-\n-\t@VisibleForTesting\n-\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n-\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n-\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n-\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n-\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n-\t\treturn new RocksDBSharedResources(cache, wbm);\n-\t}\n-\n-\t/**\n-\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).\n-\t * We introduce this method because:\n-\t * a) We cannot create a strict capacity limit cache util FLINK-15532 resolved.\n-\t * b) Regardless of the memory usage of blocks pinned by RocksDB iterators,\n-\t * which is difficult to calculate and only happened when we iterator entries in RocksDBMapState, the overuse of memory is mainly occupied by at most half of the write buffer usage.\n-\t * (see <a href=\"https://github.com/dataArtisans/frocksdb/blob/958f191d3f7276ae59b270f9db8390034d549ee0/include/rocksdb/write_buffer_manager.h#L51\">the flush implementation of write buffer manager</a>).\n-\t * Thus, we have four equations below:\n-\t *   write_buffer_manager_memory = 1.5 * write_buffer_manager_capacity\n-\t *   write_buffer_manager_memory = total_memory_size * write_buffer_ratio\n-\t *   write_buffer_manager_memory + other_part = total_memory_size\n-\t *   write_buffer_manager_capacity + other_part = cache_capacity\n-\t * And we would deduce the formula:\n-\t *   cache_capacity =  (3 - write_buffer_ratio) * total_memory_size / 3\n-\t *   write_buffer_manager_capacity = 2 * total_memory_size * write_buffer_ratio / 3\n-\t *\n-\t * @param totalMemorySize  Total off-heap memory size reserved for RocksDB instance(s).\n-\t * @param writeBufferRatio The ratio of memory size which could be reserved for write buffer manager to control the memory usage.\n-\t * @return The actual calculated memory size.\n-\t */\n-\t@VisibleForTesting\n-\tstatic long calculateActualCacheCapacity(long totalMemorySize, double writeBufferRatio) {\n-\t\treturn (long) ((3 - writeBufferRatio) * totalMemorySize / 3);\n-\t}\n-\n-\t@VisibleForTesting\n-\tstatic long calculateWriteBufferManagerCapacity(long totalMemorySize, double writeBufferRatio) {\n-\t\treturn (long) (2 * totalMemorySize * writeBufferRatio / 3);\n-\t}\n-\n-\t@VisibleForTesting\n-\tstatic Cache createCache(long cacheCapacity, double highPriorityPoolRatio) {\n-\t\t// TODO use strict capacity limit until FLINK-15532 resolved\n-\t\treturn new LRUCache(cacheCapacity, -1, false, highPriorityPoolRatio);\n-\t}\n }\n"}}, {"oid": "2d9edb24152bed26f717b6f87725efaa796d64e9", "url": "https://github.com/apache/flink/commit/2d9edb24152bed26f717b6f87725efaa796d64e9", "message": "address comments\n\n1. Add tests for wirte buffer manager\n2. Refactor RocksDBMemoryControllerUtils and its tests", "committedDate": "2020-01-12T12:44:26Z", "type": "commit"}, {"oid": "584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "url": "https://github.com/apache/flink/commit/584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "message": "minor fix on docs", "committedDate": "2020-01-12T12:46:03Z", "type": "commit"}]}