{"pr_number": 13144, "pr_title": "[FLINK-15853][hive][table-planner-blink] Use the new type inference f\u2026", "pr_createdAt": "2020-08-14T06:57:17Z", "pr_url": "https://github.com/apache/flink/pull/13144", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ1ODQzNA==", "url": "https://github.com/apache/flink/pull/13144#discussion_r470458434", "bodyText": "I guess we will also need a matching input type strategy such that the validation can work properly.", "author": "twalthr", "createdAt": "2020-08-14T07:32:16Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -82,6 +84,13 @@ public void open(FunctionContext context) {\n \t\tisArgsSingleArray = HiveFunctionUtil.isSingleBoxedArray(argTypes);\n \t}\n \n+\t@Override\n+\tpublic TypeInference getTypeInference(DataTypeFactory typeFactory) {\n+\t\tTypeInference.Builder builder = TypeInference.newBuilder();\n+\t\tbuilder.outputTypeStrategy(new ResultTypeStrategy(this));", "originalCommit": "409db9efb76541dd932a9b878ba45fa6a78d7c46", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "059c4960d2201b0c18cba4f984df35c8af5585b6", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\nindex 1ece2a9ce6..ffd73b4e4d 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n\n@@ -87,7 +115,8 @@ public abstract class HiveScalarFunction<UDFType> extends ScalarFunction impleme\n \t@Override\n \tpublic TypeInference getTypeInference(DataTypeFactory typeFactory) {\n \t\tTypeInference.Builder builder = TypeInference.newBuilder();\n-\t\tbuilder.outputTypeStrategy(new ResultTypeStrategy(this));\n+\t\tbuilder.inputTypeStrategy(new HiveUDFInputStrategy());\n+\t\tbuilder.outputTypeStrategy(new HiveUDFOutputStrategy());\n \t\treturn builder.build();\n \t}\n \n"}}, {"oid": "059c4960d2201b0c18cba4f984df35c8af5585b6", "url": "https://github.com/apache/flink/commit/059c4960d2201b0c18cba4f984df35c8af5585b6", "message": "implement input type strategy", "committedDate": "2020-08-17T10:12:42Z", "type": "forcePushed"}, {"oid": "3c30fef231493dd6cd8f3dec8838b6a7d663bc32", "url": "https://github.com/apache/flink/commit/3c30fef231493dd6cd8f3dec8838b6a7d663bc32", "message": "implement input type strategy", "committedDate": "2020-08-18T07:18:35Z", "type": "forcePushed"}, {"oid": "9b69c04b6a987bf81e21fd8a7c062fb72fe7ccb5", "url": "https://github.com/apache/flink/commit/9b69c04b6a987bf81e21fd8a7c062fb72fe7ccb5", "message": "implement input type strategy", "committedDate": "2020-08-21T09:07:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2NzE3OQ==", "url": "https://github.com/apache/flink/pull/13144#discussion_r475367179", "bodyText": "Looks like it is inferOutputType", "author": "JingsongLi", "createdAt": "2020-08-24T06:24:36Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +142,62 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate Tuple2<Object[], DataType[]> getConstantArgAndTypes(CallContext callContext) {\n+\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n+\t\tObject[] constantArgs = new Object[inputTypes.length];\n+\t\tfor (int i = 0; i < constantArgs.length; i++) {\n+\t\t\tif (callContext.isArgumentLiteral(i)) {\n+\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n+\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n+\t\t\t\t\t\t.orElse(null);\n+\t\t\t}\n+\t\t}\n+\t\treturn Tuple2.of(constantArgs, inputTypes);\n+\t}\n+\n+\t/**\n+\t * Validate input argument types and decide result type.\n+\t */\n+\tprotected abstract DataType validateInputTypes(DataType[] argTypes) throws UDFArgumentException;", "originalCommit": "9b69c04b6a987bf81e21fd8a7c062fb72fe7ccb5", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "289be5bacc5a37979ba81da7044b8d2f9a2aa96c", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\nindex ffd73b4e4d..1ece2a9ce6 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n\n@@ -142,62 +113,4 @@ public abstract class HiveScalarFunction<UDFType> extends ScalarFunction impleme\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n-\n-\tprivate Tuple2<Object[], DataType[]> getConstantArgAndTypes(CallContext callContext) {\n-\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n-\t\tObject[] constantArgs = new Object[inputTypes.length];\n-\t\tfor (int i = 0; i < constantArgs.length; i++) {\n-\t\t\tif (callContext.isArgumentLiteral(i)) {\n-\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n-\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n-\t\t\t\t\t\t.orElse(null);\n-\t\t\t}\n-\t\t}\n-\t\treturn Tuple2.of(constantArgs, inputTypes);\n-\t}\n-\n-\t/**\n-\t * Validate input argument types and decide result type.\n-\t */\n-\tprotected abstract DataType validateInputTypes(DataType[] argTypes) throws UDFArgumentException;\n-\n-\tprivate class HiveUDFOutputStrategy implements TypeStrategy {\n-\n-\t\t@Override\n-\t\tpublic Optional<DataType> inferType(CallContext callContext) {\n-\t\t\tTuple2<Object[], DataType[]> constantArgAndTypes = getConstantArgAndTypes(callContext);\n-\t\t\treturn Optional.ofNullable(getHiveResultType(constantArgAndTypes.f0, constantArgAndTypes.f1));\n-\t\t}\n-\t}\n-\n-\tprivate class HiveUDFInputStrategy implements InputTypeStrategy {\n-\n-\t\t@Override\n-\t\tpublic ArgumentCount getArgumentCount() {\n-\t\t\treturn ConstantArgumentCount.any();\n-\t\t}\n-\n-\t\t@Override\n-\t\tpublic Optional<List<DataType>> inferInputTypes(CallContext callContext, boolean throwOnFailure) {\n-\t\t\tTuple2<Object[], DataType[]> constantArgAndTypes = getConstantArgAndTypes(callContext);\n-\t\t\tsetArgumentTypesAndConstants(constantArgAndTypes.f0, constantArgAndTypes.f1);\n-\t\t\ttry {\n-\t\t\t\tresultType = validateInputTypes(argTypes);\n-\t\t\t} catch (UDFArgumentException e) {\n-\t\t\t\tif (throwOnFailure) {\n-\t\t\t\t\tthrow new ValidationException(\n-\t\t\t\t\t\t\tString.format(\"Cannot find a suitable Hive function from %s for the input arguments\",\n-\t\t\t\t\t\t\t\t\thiveFunctionWrapper.getClassName()), e);\n-\t\t\t\t} else {\n-\t\t\t\t\treturn Optional.empty();\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\treturn Optional.of(callContext.getArgumentDataTypes());\n-\t\t}\n-\n-\t\t@Override\n-\t\tpublic List<Signature> getExpectedSignatures(FunctionDefinition definition) {\n-\t\t\treturn Collections.singletonList(Signature.of(Signature.Argument.of(\"*\")));\n-\t\t}\n-\t}\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2NzgyNQ==", "url": "https://github.com/apache/flink/pull/13144#discussion_r475367825", "bodyText": "I can not get it what this is for.", "author": "JingsongLi", "createdAt": "2020-08-24T06:26:19Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +142,62 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate Tuple2<Object[], DataType[]> getConstantArgAndTypes(CallContext callContext) {\n+\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n+\t\tObject[] constantArgs = new Object[inputTypes.length];\n+\t\tfor (int i = 0; i < constantArgs.length; i++) {\n+\t\t\tif (callContext.isArgumentLiteral(i)) {\n+\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n+\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n+\t\t\t\t\t\t.orElse(null);\n+\t\t\t}\n+\t\t}\n+\t\treturn Tuple2.of(constantArgs, inputTypes);\n+\t}\n+\n+\t/**\n+\t * Validate input argument types and decide result type.\n+\t */\n+\tprotected abstract DataType validateInputTypes(DataType[] argTypes) throws UDFArgumentException;\n+\n+\tprivate class HiveUDFOutputStrategy implements TypeStrategy {\n+\n+\t\t@Override\n+\t\tpublic Optional<DataType> inferType(CallContext callContext) {\n+\t\t\tTuple2<Object[], DataType[]> constantArgAndTypes = getConstantArgAndTypes(callContext);\n+\t\t\treturn Optional.ofNullable(getHiveResultType(constantArgAndTypes.f0, constantArgAndTypes.f1));\n+\t\t}\n+\t}\n+\n+\tprivate class HiveUDFInputStrategy implements InputTypeStrategy {", "originalCommit": "9b69c04b6a987bf81e21fd8a7c062fb72fe7ccb5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQyNTg0NQ==", "url": "https://github.com/apache/flink/pull/13144#discussion_r475425845", "bodyText": "I think this is needed for input type validation. For example, according to the API contract, a ValidationException can be thrown if the input is invalid, but this should only happen during input inference rather than output inference.", "author": "lirui-apache", "createdAt": "2020-08-24T08:29:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2NzgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MDk2Nw==", "url": "https://github.com/apache/flink/pull/13144#discussion_r475480967", "bodyText": "Got it.", "author": "JingsongLi", "createdAt": "2020-08-24T09:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2NzgyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "289be5bacc5a37979ba81da7044b8d2f9a2aa96c", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\nindex ffd73b4e4d..1ece2a9ce6 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java\n\n@@ -142,62 +113,4 @@ public abstract class HiveScalarFunction<UDFType> extends ScalarFunction impleme\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n-\n-\tprivate Tuple2<Object[], DataType[]> getConstantArgAndTypes(CallContext callContext) {\n-\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n-\t\tObject[] constantArgs = new Object[inputTypes.length];\n-\t\tfor (int i = 0; i < constantArgs.length; i++) {\n-\t\t\tif (callContext.isArgumentLiteral(i)) {\n-\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n-\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n-\t\t\t\t\t\t.orElse(null);\n-\t\t\t}\n-\t\t}\n-\t\treturn Tuple2.of(constantArgs, inputTypes);\n-\t}\n-\n-\t/**\n-\t * Validate input argument types and decide result type.\n-\t */\n-\tprotected abstract DataType validateInputTypes(DataType[] argTypes) throws UDFArgumentException;\n-\n-\tprivate class HiveUDFOutputStrategy implements TypeStrategy {\n-\n-\t\t@Override\n-\t\tpublic Optional<DataType> inferType(CallContext callContext) {\n-\t\t\tTuple2<Object[], DataType[]> constantArgAndTypes = getConstantArgAndTypes(callContext);\n-\t\t\treturn Optional.ofNullable(getHiveResultType(constantArgAndTypes.f0, constantArgAndTypes.f1));\n-\t\t}\n-\t}\n-\n-\tprivate class HiveUDFInputStrategy implements InputTypeStrategy {\n-\n-\t\t@Override\n-\t\tpublic ArgumentCount getArgumentCount() {\n-\t\t\treturn ConstantArgumentCount.any();\n-\t\t}\n-\n-\t\t@Override\n-\t\tpublic Optional<List<DataType>> inferInputTypes(CallContext callContext, boolean throwOnFailure) {\n-\t\t\tTuple2<Object[], DataType[]> constantArgAndTypes = getConstantArgAndTypes(callContext);\n-\t\t\tsetArgumentTypesAndConstants(constantArgAndTypes.f0, constantArgAndTypes.f1);\n-\t\t\ttry {\n-\t\t\t\tresultType = validateInputTypes(argTypes);\n-\t\t\t} catch (UDFArgumentException e) {\n-\t\t\t\tif (throwOnFailure) {\n-\t\t\t\t\tthrow new ValidationException(\n-\t\t\t\t\t\t\tString.format(\"Cannot find a suitable Hive function from %s for the input arguments\",\n-\t\t\t\t\t\t\t\t\thiveFunctionWrapper.getClassName()), e);\n-\t\t\t\t} else {\n-\t\t\t\t\treturn Optional.empty();\n-\t\t\t\t}\n-\t\t\t}\n-\t\t\treturn Optional.of(callContext.getArgumentDataTypes());\n-\t\t}\n-\n-\t\t@Override\n-\t\tpublic List<Signature> getExpectedSignatures(FunctionDefinition definition) {\n-\t\t\treturn Collections.singletonList(Signature.of(Signature.Argument.of(\"*\")));\n-\t\t}\n-\t}\n }\n"}}, {"oid": "289be5bacc5a37979ba81da7044b8d2f9a2aa96c", "url": "https://github.com/apache/flink/commit/289be5bacc5a37979ba81da7044b8d2f9a2aa96c", "message": "[FLINK-15853][hive][table-planner-blink] Use the new type inference for hive udf", "committedDate": "2020-08-24T06:49:11Z", "type": "commit"}, {"oid": "99dbe8bfead5fa8ef998c4b9933e61de0c5c9c01", "url": "https://github.com/apache/flink/commit/99dbe8bfead5fa8ef998c4b9933e61de0c5c9c01", "message": "implement input type strategy", "committedDate": "2020-08-24T06:49:11Z", "type": "commit"}, {"oid": "5e59034c2ae2d7a9fdef6a2bdaaeda311d9464c7", "url": "https://github.com/apache/flink/commit/5e59034c2ae2d7a9fdef6a2bdaaeda311d9464c7", "message": "refactor", "committedDate": "2020-08-24T08:19:46Z", "type": "commit"}, {"oid": "5e59034c2ae2d7a9fdef6a2bdaaeda311d9464c7", "url": "https://github.com/apache/flink/commit/5e59034c2ae2d7a9fdef6a2bdaaeda311d9464c7", "message": "refactor", "committedDate": "2020-08-24T08:19:46Z", "type": "forcePushed"}, {"oid": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "url": "https://github.com/apache/flink/commit/d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "message": "fix call context", "committedDate": "2020-08-25T07:46:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2MzI4NA==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479963284", "bodyText": "Move this to a dedicated class because it will be shared for other functions as well?", "author": "twalthr", "createdAt": "2020-08-31T08:01:42Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +114,66 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate void setArguments(CallContext callContext) {", "originalCommit": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk4MjgzMg==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479982832", "bodyText": "We can rename HiveFunction to HiveLegacyFunction, and create a new abstract base class HiveFunction.", "author": "JingsongLi", "createdAt": "2020-08-31T08:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2MzI4NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2MzUzMg==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479963532", "bodyText": "We should also check for isNullLiteral?", "author": "twalthr", "createdAt": "2020-08-31T08:02:09Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +114,66 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate void setArguments(CallContext callContext) {\n+\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n+\t\tObject[] constantArgs = new Object[inputTypes.length];\n+\t\tfor (int i = 0; i < constantArgs.length; i++) {\n+\t\t\tif (callContext.isArgumentLiteral(i)) {", "originalCommit": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk4NjM5OA==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479986398", "bodyText": "Looks like getArgumentValue will return empty for null literal. But we should add test for null literal.", "author": "JingsongLi", "createdAt": "2020-08-31T08:47:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2MzUzMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2NDA3OQ==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479964079", "bodyText": "the CallContext provides a method for throwing validation errors.", "author": "twalthr", "createdAt": "2020-08-31T08:03:21Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +114,66 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate void setArguments(CallContext callContext) {\n+\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n+\t\tObject[] constantArgs = new Object[inputTypes.length];\n+\t\tfor (int i = 0; i < constantArgs.length; i++) {\n+\t\t\tif (callContext.isArgumentLiteral(i)) {\n+\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n+\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n+\t\t\t\t\t\t.orElse(null);\n+\t\t\t}\n+\t\t}\n+\t\tthis.constantArguments = constantArgs;\n+\t\tthis.argTypes = inputTypes;\n+\t}\n+\n+\t/**\n+\t * Infer return type of this function call.\n+\t */\n+\tprotected abstract DataType inferReturnType() throws UDFArgumentException;\n+\n+\tprivate class HiveUDFOutputStrategy implements TypeStrategy {\n+\n+\t\t@Override\n+\t\tpublic Optional<DataType> inferType(CallContext callContext) {\n+\t\t\tsetArguments(callContext);\n+\t\t\ttry {\n+\t\t\t\treturn Optional.of(inferReturnType());\n+\t\t\t} catch (UDFArgumentException e) {\n+\t\t\t\tthrow new FlinkHiveUDFException(e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate class HiveUDFInputStrategy implements InputTypeStrategy {\n+\n+\t\t@Override\n+\t\tpublic ArgumentCount getArgumentCount() {\n+\t\t\treturn ConstantArgumentCount.any();\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Optional<List<DataType>> inferInputTypes(CallContext callContext, boolean throwOnFailure) {\n+\t\t\tsetArguments(callContext);\n+\t\t\ttry {\n+\t\t\t\tinferReturnType();\n+\t\t\t} catch (UDFArgumentException e) {\n+\t\t\t\tif (throwOnFailure) {\n+\t\t\t\t\tthrow new ValidationException(", "originalCommit": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2NTQxMQ==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479965411", "bodyText": "I think it would be helpful to print the expected signature in case the user passes wrong arguments?", "author": "twalthr", "createdAt": "2020-08-31T08:06:05Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/functions/hive/HiveScalarFunction.java", "diffHunk": "@@ -104,4 +114,66 @@ public Object eval(Object... args) {\n \t * Evaluation logical, args will be wrapped when is a single array.\n \t */\n \tprotected abstract Object evalInternal(Object[] args);\n+\n+\tprivate void setArguments(CallContext callContext) {\n+\t\tDataType[] inputTypes = callContext.getArgumentDataTypes().toArray(new DataType[0]);\n+\t\tObject[] constantArgs = new Object[inputTypes.length];\n+\t\tfor (int i = 0; i < constantArgs.length; i++) {\n+\t\t\tif (callContext.isArgumentLiteral(i)) {\n+\t\t\t\tconstantArgs[i] = callContext.getArgumentValue(\n+\t\t\t\t\t\ti, ClassLogicalTypeConverter.getDefaultExternalClassForType(inputTypes[i].getLogicalType()))\n+\t\t\t\t\t\t.orElse(null);\n+\t\t\t}\n+\t\t}\n+\t\tthis.constantArguments = constantArgs;\n+\t\tthis.argTypes = inputTypes;\n+\t}\n+\n+\t/**\n+\t * Infer return type of this function call.\n+\t */\n+\tprotected abstract DataType inferReturnType() throws UDFArgumentException;\n+\n+\tprivate class HiveUDFOutputStrategy implements TypeStrategy {\n+\n+\t\t@Override\n+\t\tpublic Optional<DataType> inferType(CallContext callContext) {\n+\t\t\tsetArguments(callContext);\n+\t\t\ttry {\n+\t\t\t\treturn Optional.of(inferReturnType());\n+\t\t\t} catch (UDFArgumentException e) {\n+\t\t\t\tthrow new FlinkHiveUDFException(e);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate class HiveUDFInputStrategy implements InputTypeStrategy {\n+\n+\t\t@Override\n+\t\tpublic ArgumentCount getArgumentCount() {\n+\t\t\treturn ConstantArgumentCount.any();\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic Optional<List<DataType>> inferInputTypes(CallContext callContext, boolean throwOnFailure) {\n+\t\t\tsetArguments(callContext);\n+\t\t\ttry {\n+\t\t\t\tinferReturnType();\n+\t\t\t} catch (UDFArgumentException e) {\n+\t\t\t\tif (throwOnFailure) {\n+\t\t\t\t\tthrow new ValidationException(\n+\t\t\t\t\t\t\tString.format(\"Cannot find a suitable Hive function from %s for the input arguments\",\n+\t\t\t\t\t\t\t\t\thiveFunctionWrapper.getClassName()), e);\n+\t\t\t\t} else {\n+\t\t\t\t\treturn Optional.empty();\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn Optional.of(callContext.getArgumentDataTypes());\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic List<Signature> getExpectedSignatures(FunctionDefinition definition) {\n+\t\t\treturn Collections.singletonList(Signature.of(Signature.Argument.of(\"*\")));", "originalCommit": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzODU1Mw==", "url": "https://github.com/apache/flink/pull/13144#discussion_r480038553", "bodyText": "I'm not sure whether it's possible to get all the valid signatures for a hive function. Some hive function supports implicit type conversion, e.g. a function that operates on string values may take numeric input as well. I'll double check.", "author": "lirui-apache", "createdAt": "2020-08-31T10:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2NTQxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDE0MDM4OA==", "url": "https://github.com/apache/flink/pull/13144#discussion_r480140388", "bodyText": "Actually, this is why this method is very generic and allows you to pass arbitrary strings like NUMERIC or ANY. I don't know how Hive implements UDFs but as a user I would find it useful to get exceptions like\nInvalid input arguments. Expected signatures are:\\n\nf(STRING NOT NULL)\\nf(INT NOT NULL)\\nf(BIGINT NOT NULL)\n\nBtw you can also use InputTypeStrategiesTestBase for testing. See InputTypeStrategiesTest for an example.", "author": "twalthr", "createdAt": "2020-08-31T13:44:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2NTQxMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk2NTYxMw==", "url": "https://github.com/apache/flink/pull/13144#discussion_r479965613", "bodyText": "Use org.apache.flink.table.types.inference.utils.CallContextMock", "author": "twalthr", "createdAt": "2020-08-31T08:06:32Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/functions/hive/HiveSimpleUDFTest.java", "diffHunk": "@@ -291,4 +297,58 @@ public String evaluate(String content) {\n \t\t\treturn content;\n \t\t}\n \t}\n+\n+\t/**\n+\t * A CallContext implementation for Hive UDF tests.\n+\t */\n+\tpublic static class HiveUDFCallContext implements CallContext {", "originalCommit": "d18c88b2c9387076875d7e9f33b05d8f171ba8d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}