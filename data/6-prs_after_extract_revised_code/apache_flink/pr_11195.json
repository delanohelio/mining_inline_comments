{"pr_number": 11195, "pr_title": "[FLINK-16222][runtime] Use plugins mechanism for initializing MetricReporters", "pr_createdAt": "2020-02-23T12:17:34Z", "pr_url": "https://github.com/apache/flink/pull/11195", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NTQzMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386465432", "bodyText": "we don't allow star imports", "author": "zentol", "createdAt": "2020-03-02T15:34:23Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -38,11 +38,7 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.BufferedReader;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n+import java.io.*;", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYyODM4Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386628387", "bodyText": "fixed", "author": "afedulov", "createdAt": "2020-03-02T20:21:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NTQzMg=="}], "type": "inlineReview", "revised_code": {"commit": "1613baf0244adc63bf029415e97227a6770591c9", "chunk": "diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\nindex 8280cabce4d..4396cb663d8 100644\n--- a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\n+++ b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\n\n@@ -38,7 +38,11 @@ import org.junit.rules.TemporaryFolder;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.*;\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n import java.nio.charset.StandardCharsets;\n import java.nio.file.Files;\n import java.nio.file.Path;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NzkwMQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386467901", "bodyText": "why is this passing null and not following the same approach as JobManagerHAProcessFailureRecoveryITCase?", "author": "zentol", "createdAt": "2020-03-02T15:38:29Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java", "diffHunk": "@@ -92,7 +92,7 @@ private static Configuration createConfiguration() {\n \t}\n \n \tprivate static TaskManagerRunner createTaskManagerRunner(final Configuration configuration) throws Exception {\n-\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate());\n+\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate(), null);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYyMDc2NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386620764", "bodyText": "adjusted", "author": "afedulov", "createdAt": "2020-03-02T20:05:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2NzkwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "738a6fd162d5ba99432438d224f3b4890961af56", "chunk": "diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java\nindex 4d91176a80a..2af131912fb 100644\n--- a/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java\n+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunnerTest.java\n\n@@ -92,7 +94,8 @@ public class TaskManagerRunnerTest extends TestLogger {\n \t}\n \n \tprivate static TaskManagerRunner createTaskManagerRunner(final Configuration configuration) throws Exception {\n-\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate(), null);\n+\t\tfinal PluginManager pluginManager = PluginUtils.createPluginManagerFromRootFolder(configuration);\n+\t\tTaskManagerRunner taskManagerRunner = new TaskManagerRunner(configuration, ResourceID.generate(), pluginManager);\n \t\ttaskManagerRunner.start();\n \t\treturn taskManagerRunner;\n \t}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386468691", "bodyText": "In the PRs current state pluginManager should be annotated with Nullable", "author": "zentol", "createdAt": "2020-03-02T15:39:35Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java", "diffHunk": "@@ -119,7 +120,7 @@\n \n \tprivate boolean shutdown;\n \n-\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId) throws Exception {\n+\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId, PluginManager pluginManager) throws Exception {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0NDUwMQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386644501", "bodyText": "I am  not sure what should be the expected contract here. ReporterSetup will currently only work with the null pluginManager if no reporters are configured (namedReporters.isEmpty()). We could maybe add a checkNonNull in  the ReporterSetup after that first return due to empty namedReporters.\n(TaskManagerRunnerTest is now fixed to initialize the PluginManager properly)", "author": "afedulov", "createdAt": "2020-03-02T20:55:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMjQ5OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388312499", "bodyText": "FileSystem can also take a null for plugin manager. We should probably extract an interface and have a no-op implementation instead. That's out of scope for this PR though.", "author": "AHeise", "createdAt": "2020-03-05T14:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2ODY5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java\nindex 7e30c9fe851..0478953e8ed 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerRunner.java\n\n@@ -120,7 +118,7 @@ public class TaskManagerRunner implements FatalErrorHandler, AutoCloseableAsync\n \n \tprivate boolean shutdown;\n \n-\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId, PluginManager pluginManager) throws Exception {\n+\tpublic TaskManagerRunner(Configuration configuration, ResourceID resourceId) throws Exception {\n \t\tthis.configuration = checkNotNull(configuration);\n \t\tthis.resourceId = checkNotNull(resourceId);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTAwMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469003", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:40:04Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -273,3 +319,4 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn Optional.of((MetricReporter) reporterClass.newInstance());\n \t}\n }\n+", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MjM3Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386662377", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:31:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTAwMw=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -319,4 +320,3 @@ public final class ReporterSetup {\n \t\treturn Optional.of((MetricReporter) reporterClass.newInstance());\n \t}\n }\n-\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469696", "bodyText": "remove TODOs", "author": "zentol", "createdAt": "2020-03-02T15:41:07Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYzMDkyOQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386630929", "bodyText": "ping @pnowojski @AHeise  (depends if we want to proceed with the classloading modifications)", "author": "afedulov", "createdAt": "2020-03-02T20:26:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0ODM0OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388348348", "bodyText": "Takes a while until we get proper SPI, so I'd add the commented code to increase usability.", "author": "AHeise", "createdAt": "2020-03-05T15:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU3MDg0Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393570847", "bodyText": "@AHeise the jar path for existing metrics reporters will currently point to the same file due to parent-first loading of org.apache.flink packages (even if one of the jars is in /plugin directory). It might be misleading, so I wanted to keep the note for improvement for later, for when the loading is done differently.", "author": "afedulov", "createdAt": "2020-03-17T10:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzI2NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147265", "bodyText": "So this would then only work for two plugins. I don't see a way around that without proper SPI.\nI'd probably remove the commented code completely; it shouldn't be hard to bring back and would avoid some confusion.", "author": "AHeise", "createdAt": "2020-03-18T07:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NjUyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394246528", "bodyText": "We usually don't allow commented code, and I agree with arvid that it would be easy to bring back.", "author": "zentol", "createdAt": "2020-03-18T10:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2ODA3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395368073", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-19T23:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTY5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTc0MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386469740", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:41:11Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n+\t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n \t\t\t\tLOG.warn(\"Error while loading reporter factory.\", e);\n \t\t\t}\n \t\t}\n-", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0OTA3OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386649079", "bodyText": "Is this a preferred style in Flink or just according to a principle of touching as few lines as possible?", "author": "afedulov", "createdAt": "2020-03-02T21:04:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ2OTc0MA=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386471891", "bodyText": "Is it guaranteed that they are in opt and lib? What if 2 plugins specified the same factory class?", "author": "zentol", "createdAt": "2020-03-02T15:44:25Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+\t\t\t\t\t\t.toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY0NjY5Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386646692", "bodyText": "But this would technically be \"multiple implementations of the same reporter\"? The message does not tell explicitly that one of them is in lib and another in plugins - just that while searching those two directories, multiple implementations were found.", "author": "afedulov", "createdAt": "2020-03-02T20:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NzgxMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388347812", "bodyText": "Should be 'or'", "author": "AHeise", "createdAt": "2020-03-05T14:59:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU4MDQ1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393580453", "bodyText": "Strictly speaking it then should be 'and/or', because 'or' could mean that there are two jars, both of which are either in 'lib' or in 'plugins'. I think and was more fitting, but I am also ok with and/or", "author": "afedulov", "createdAt": "2020-03-17T10:30:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MTg5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjQ5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472491", "bodyText": "Given that we are iterating over all factories anyway we should be able to move this into the while loop.", "author": "zentol", "createdAt": "2020-03-02T15:45:14Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2Mjk2Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386662966", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:32:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjQ5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjcwMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386472702", "bodyText": "Should likely be removed or replaced with a meaningful INFO message that a factory was found.", "author": "zentol", "createdAt": "2020-03-02T15:45:33Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n \n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {\n+\t\t\t\t\tString reporterName = matcher.group(1);\n+\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n+\t\t\t\t\t\tif (namedOrderedReporters.contains(reporterName)) {\n+\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tnamedOrderedReporters.add(reporterName);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn namedOrderedReporters;\n+\t}\n+\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n+\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.warn(new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2Mzc0NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386663744", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T21:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3MjcwMg=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDE4OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474188", "bodyText": "why is this necessary?", "author": "zentol", "createdAt": "2020-03-02T15:47:39Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving\n-public class PrometheusReporter extends AbstractPrometheusReporter {\n+public class PrometheusReporter extends AbstractPrometheusReporter implements MetricReporter {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3NTUzMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386675530", "bodyText": "missed that AbstractPrometheusReporter already implements it. Fixed.", "author": "afedulov", "createdAt": "2020-03-02T21:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDE4OA=="}], "type": "inlineReview", "revised_code": {"commit": "77f24b292a04fde34f4c645151484cf86a13832c", "chunk": "diff --git a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\nindex 356292da06c..4697685b8c0 100644\n--- a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\n+++ b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\n\n@@ -35,7 +35,7 @@ import java.util.Iterator;\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving\n-public class PrometheusReporter extends AbstractPrometheusReporter implements MetricReporter {\n+public class PrometheusReporter extends AbstractPrometheusReporter {\n \n \tstatic final String ARG_PORT = \"port\";\n \tprivate static final String DEFAULT_PORT = \"9249\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDU5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474591", "bodyText": "Add @InstantiateViaFactory annotation so that all instantiations go through the factory.", "author": "zentol", "createdAt": "2020-03-02T15:48:10Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java", "diffHunk": "@@ -35,7 +35,7 @@\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "77f24b292a04fde34f4c645151484cf86a13832c", "chunk": "diff --git a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\nindex 356292da06c..4697685b8c0 100644\n--- a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\n+++ b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporter.java\n\n@@ -35,7 +35,7 @@ import java.util.Iterator;\n  * {@link MetricReporter} that exports {@link Metric Metrics} via Prometheus.\n  */\n @PublicEvolving\n-public class PrometheusReporter extends AbstractPrometheusReporter implements MetricReporter {\n+public class PrometheusReporter extends AbstractPrometheusReporter {\n \n \tstatic final String ARG_PORT = \"port\";\n \tprivate static final String DEFAULT_PORT = \"9249\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDcyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386474722", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:48:21Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -185,6 +214,7 @@ public void testReporter() throws Exception {\n \n \t\t\tcheckMetricAvailability(client, \"flink_jobmanager_numRegisteredTaskManagers\");\n \t\t\tcheckMetricAvailability(client, \"flink_taskmanager_Status_Network_TotalMemorySegments\");\n+", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY4MjgwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386682800", "bodyText": "done", "author": "afedulov", "createdAt": "2020-03-02T22:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NDcyMg=="}], "type": "inlineReview", "revised_code": {"commit": "5dfb306ba6ff07f700b1afc21847641321705d4d", "chunk": "diff --git a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\nindex 5622d18a3c6..ba72046d971 100644\n--- a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n+++ b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n\n@@ -214,7 +214,6 @@ public class PrometheusReporterEndToEndITCase extends TestLogger {\n \n \t\t\tcheckMetricAvailability(client, \"flink_jobmanager_numRegisteredTaskManagers\");\n \t\t\tcheckMetricAvailability(client, \"flink_taskmanager_Status_Network_TotalMemorySegments\");\n-\n \t\t}\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386476291", "bodyText": "ping @pnowojski / @AHeise", "author": "zentol", "createdAt": "2020-03-02T15:50:33Z", "path": "flink-core/src/main/java/org/apache/flink/core/plugin/PluginLoader.java", "diffHunk": "@@ -69,7 +68,7 @@ public static PluginLoader create(PluginDescriptor pluginDescriptor, ClassLoader\n \t * @param <P> Type of the requested plugin service.\n \t * @return An iterator of all implementations of the given service interface that could be loaded from the plugin.\n \t */\n-\tpublic <P extends Plugin> Iterator<P> load(Class<P> service) {\n+\tpublic <P> Iterator<P> load(Class<P> service) {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0MDAyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388340028", "bodyText": "That was actually my proposal, since there is no benefit from implementing Plugin and its #configure method does not work well with existing metric factories.", "author": "AHeise", "createdAt": "2020-03-05T14:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI1Njc3MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393256771", "bodyText": "Marking as resolved.", "author": "afedulov", "createdAt": "2020-03-16T19:15:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NjI5MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477670", "bodyText": "we should actually remove this line (or exclude the metricConfig) as we may be leaking sensitive information.", "author": "zentol", "createdAt": "2020-03-02T15:52:29Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYwNDA3OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386604078", "bodyText": "Good point. I am not 100% sure about it - do we have a Flink-wide way to handle such cases? I guess the cleanest approach would be to have a special set of keys that are considered sensitive, which have to be obfuscated prior to logging. Seeing which other config values are used during the initialization could be generally pretty useful for debugging.", "author": "afedulov", "createdAt": "2020-03-02T19:32:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgzOTc1NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393839754", "bodyText": "Ping @AHeise @zentol - could we agree on something here?\nI am always \"pro extensive logging\", but this could be professional deformation. Being able to \"on-demand\" see what is going on is very valuable for production systems. We could declare somewhere for Flink in general that if you choose to run with debug log level, some potentially sensitive information could leak into logs. My arguments are:\n\nIf someone has uncontrolled access to the log files on your machine in production, content of this file is probably not the biggest of your problems.\nRunning with debug level is not a \"normal\" scenario - this is intended for hands on investigation of issues. Log level for potentially compromisable external systems could be explicitly set to trace in such cases.\nWe have been \"leaking\" this data in the current versions with info (!) level without much concern", "author": "afedulov", "createdAt": "2020-03-17T17:14:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzkwMzUwNQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393903505", "bodyText": "do we have a Flink-wide way to handle such cases\n\nThe GlobalConfiguration contains a set of keys that are considered sensitive, which we use for the WebUI and various INFO logging.\n\nWe have been \"leaking\" this data in the current versions with info (!) level without much concern\n\nFew reporters actually use credentials (afaik only datadog does), so the sample size is fairly low.\n\nIf someone has uncontrolled access to the log files on your machine in production, content of this file is probably not the biggest of your problems.\n\nDoesn't need access to the machine; access to the UI is sufficient, which was grave enough that we introduced the whole secret-key concept in the first place.\n\nRunning with debug level is not a \"normal\" scenario - this is intended for hands on investigation of issues. Log level for potentially compromisable external systems could be explicitly set to trace in such cases.\n\nThere's precedence with FLINK-10363 that credentials should not be logged even on debug.\nFLINK-16478 also which proposes a REST API for modifying the log level potentially voiding any argument for it being opt-in insecurity.\nI would approach this cautiously and never log anything sensitive.", "author": "zentol", "createdAt": "2020-03-17T18:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDY4Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950683", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3NzY3MA=="}], "type": "inlineReview", "revised_code": {"commit": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..3d04532862b 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -134,18 +134,18 @@ public final class ReporterSetup {\n \t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n \n-\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n-\t\t\tincludedReportersString);\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration, includedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n-\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n \t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n \t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n+\n \t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n \t\tLOG.debug(\"All initialized Reporters:\");\n \t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzc0NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477745", "bodyText": "same as above", "author": "zentol", "createdAt": "2020-03-02T15:52:36Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDgxMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950810", "bodyText": "Removed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzc0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..3d04532862b 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -134,18 +134,18 @@ public final class ReporterSetup {\n \t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n \n-\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n-\t\t\tincludedReportersString);\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration, includedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n-\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n \t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n \t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n+\n \t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n \t\tLOG.debug(\"All initialized Reporters:\");\n \t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386477973", "bodyText": "revert", "author": "zentol", "createdAt": "2020-03-02T15:52:55Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -178,36 +164,96 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjYxMzk4MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386613981", "bodyText": "Is this an accepted style in Flink? I mostly see \"classic\" variant with } catch ... , including the same class in loadReporterFactories() method.", "author": "afedulov", "createdAt": "2020-03-02T19:52:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDI1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344253", "bodyText": "In general, the best option is to leave old code as is to not blow up the PR. You could make a separate hotfix to address code style fixes though.", "author": "AHeise", "createdAt": "2020-03-05T14:54:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzgzMjUwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393832500", "bodyText": "This whole code block was already \"touched\" anyhow, because of refactoring, so I think it should be OK to do such things, unless you have a strong opinion.", "author": "afedulov", "createdAt": "2020-03-17T17:02:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0MTMyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394241322", "bodyText": "our code style unfortunately does not cover the placement of such braces; hence we reject any changes such as this to existing code.", "author": "zentol", "createdAt": "2020-03-18T10:22:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5ODMyNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395298324", "bodyText": "@zentol Ok, I find it a bit strange, but I am not setting the rules here.", "author": "afedulov", "createdAt": "2020-03-19T20:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyMzAzMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395323032", "bodyText": "Done.", "author": "afedulov", "createdAt": "2020-03-19T21:13:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3Nzk3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..131a28599ff 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -218,8 +218,7 @@ public final class ReporterSetup {\n \tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n \t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n-\t\tLOG.debug(\"All available factories (from both SPIs and Plugins):\");\n-\t\tgetAllReporterFactories(pluginManager).forEachRemaining(i -> LOG.debug(i.toString()));\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386478652", "bodyText": "reviews are a lot easier if we either a) refrain from non-critical refactorings b) move such refactorings into a separate commit.", "author": "zentol", "createdAt": "2020-03-02T15:53:50Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NDcyNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388344724", "bodyText": "\ud83d\udc4d to split up refactoring from actual commit. But in general also \ud83d\udc4d to refactorings.", "author": "AHeise", "createdAt": "2020-03-05T14:54:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0MDk1Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393840952", "bodyText": "Done.", "author": "afedulov", "createdAt": "2020-03-17T17:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTM5Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395299396", "bodyText": "As this did not come up in the second round I consider the new split of commits as appropriate. Resolving.", "author": "afedulov", "createdAt": "2020-03-19T20:25:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3ODY1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..3d04532862b 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -134,18 +134,18 @@ public final class ReporterSetup {\n \t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n \n-\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n-\t\t\tincludedReportersString);\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration, includedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n-\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n \t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n \t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n+\n \t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n \t\tLOG.debug(\"All initialized Reporters:\");\n \t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479500", "bodyText": "same as above about leaking sensitive information", "author": "zentol", "createdAt": "2020-03-02T15:55:01Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDU3OQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950579", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T20:30:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUwMA=="}], "type": "inlineReview", "revised_code": {"commit": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..3d04532862b 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -134,18 +134,18 @@ public final class ReporterSetup {\n \t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n \n-\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n-\t\t\tincludedReportersString);\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration, includedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n-\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n \t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n \t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n+\n \t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n \t\tLOG.debug(\"All initialized Reporters:\");\n \t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUzNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r386479537", "bodyText": "same as above about leaking sensitive information", "author": "zentol", "createdAt": "2020-03-02T15:55:04Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -120,55 +124,37 @@ public static ReporterSetup forReporter(String reporterName, MetricConfig metric\n \t}\n \n \tprivate static ReporterSetup createReporterSetup(String reporterName, MetricConfig metricConfig, MetricReporter reporter) {\n-\t\tLOG.info(\"Configuring {} with {}.\", reporterName, metricConfig);\n+\t\tLOG.debug(\"Configuring {} with {}.\", reporterName, metricConfig);\n \t\treporter.open(metricConfig);\n \n \t\treturn new ReporterSetup(reporterName, metricConfig, reporter);\n \t}\n \n-\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration) {\n+\tpublic static List<ReporterSetup> fromConfiguration(final Configuration configuration, final PluginManager pluginManager) {\n+\t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n-\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n-\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n-\t\t\t.collect(Collectors.toSet());\n \n-\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n-\t\tSet<String> namedReporters = new TreeSet<>(String::compareTo);\n-\t\t// scan entire configuration for \"metric.reporter\" keys and parse individual reporter configurations\n-\t\tfor (String key : configuration.keySet()) {\n-\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n-\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n-\t\t\t\tif (matcher.matches()) {\n-\t\t\t\t\tString reporterName = matcher.group(1);\n-\t\t\t\t\tif (includedReporters.isEmpty() || includedReporters.contains(reporterName)) {\n-\t\t\t\t\t\tif (namedReporters.contains(reporterName)) {\n-\t\t\t\t\t\t\tLOG.warn(\"Duplicate class configuration detected for reporter {}.\", reporterName);\n-\t\t\t\t\t\t} else {\n-\t\t\t\t\t\t\tnamedReporters.add(reporterName);\n-\t\t\t\t\t\t}\n-\t\t\t\t\t} else {\n-\t\t\t\t\t\tLOG.info(\"Excluding reporter {}, not configured in reporter list ({}).\", reporterName, includedReportersString);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t}\n-\t\t}\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n+\t\t\tincludedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tList<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n-\t\tfor (String namedReporter: namedReporters) {\n-\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n-\t\t\t\tconfiguration,\n-\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n+\t\tLOG.debug(\"All initialized Reporters:\");\n+\t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));", "originalCommit": "d693668c44effeffafc944835df873e3978f88b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1MDUwOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393950508", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T20:29:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjQ3OTUzNw=="}], "type": "inlineReview", "revised_code": {"commit": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex e33fe96eff8..3d04532862b 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -134,18 +134,18 @@ public final class ReporterSetup {\n \t\tLOG.debug(\"Initializing Reporters from Configuration: {}\", configuration);\n \t\tString includedReportersString = configuration.getString(MetricOptions.REPORTERS_LIST, \"\");\n \n-\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration,\n-\t\t\tincludedReportersString);\n+\t\tSet<String> namedReporters = findEnabledReportersInConfiguration(configuration, includedReportersString);\n \n \t\tif (namedReporters.isEmpty()) {\n \t\t\treturn Collections.emptyList();\n \t\t}\n \n-\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n-\t\tLOG.debug(\"Loaded Reporter Factories: {}\", reporterFactories);\n \t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = loadReporterConfigurations(configuration, namedReporters);\n \t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n \n+\t\tfinal Map<String, MetricReporterFactory> reporterFactories = loadAvailableReporterFactories(pluginManager);\n+\t\tLOG.debug(\"Loaded Reporter Configurations: {}\", reporterConfigurations);\n+\n \t\tList<ReporterSetup> reporterSetups = setupReporters(reporterFactories, reporterConfigurations);\n \t\tLOG.debug(\"All initialized Reporters:\");\n \t\treporterSetups.forEach(i -> LOG.debug(\"{} - {}\", i.getName(), i.getConfiguration()));\n"}}, {"oid": "738a6fd162d5ba99432438d224f3b4890961af56", "url": "https://github.com/apache/flink/commit/738a6fd162d5ba99432438d224f3b4890961af56", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T20:03:21Z", "type": "forcePushed"}, {"oid": "1613baf0244adc63bf029415e97227a6770591c9", "url": "https://github.com/apache/flink/commit/1613baf0244adc63bf029415e97227a6770591c9", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T20:18:06Z", "type": "forcePushed"}, {"oid": "21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "url": "https://github.com/apache/flink/commit/21c0efa3b9bae9e5bb23338c23483f41f0d1e738", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T21:23:39Z", "type": "forcePushed"}, {"oid": "77f24b292a04fde34f4c645151484cf86a13832c", "url": "https://github.com/apache/flink/commit/77f24b292a04fde34f4c645151484cf86a13832c", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T21:57:12Z", "type": "forcePushed"}, {"oid": "666e058b3924dd6593106ccffa84ebdfb68ea1fa", "url": "https://github.com/apache/flink/commit/666e058b3924dd6593106ccffa84ebdfb68ea1fa", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T22:08:35Z", "type": "forcePushed"}, {"oid": "5dfb306ba6ff07f700b1afc21847641321705d4d", "url": "https://github.com/apache/flink/commit/5dfb306ba6ff07f700b1afc21847641321705d4d", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-02T22:12:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310058", "bodyText": "Just tagging TODO.", "author": "AHeise", "createdAt": "2020-03-05T14:00:05Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -160,13 +161,14 @@ public void startCluster() throws ClusterEntrypointException {\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\n-\t\t\tconfigureFileSystems(configuration);\n+\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)", "originalCommit": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU2MzI1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393563258", "bodyText": "@AHeise I wanted to ask if what is written in TODO is a good idea in your opinion. I am not sure about the implications of initializing FileSystems within runSecured. I do not quite like that initialization of services (initializeServices) and  file systems happen in different places.", "author": "afedulov", "createdAt": "2020-03-17T09:59:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NDA0Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394144042", "bodyText": "That's something that @zentol knows much better. It sounds plausible to me.", "author": "AHeise", "createdAt": "2020-03-18T07:17:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzNjMyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394236320", "bodyText": "I've got no clue. Maybe @tillrohrmann remembers why this was added outside runSecured in bbac4a6#diff-5334e24ac6a0d7e69599ceca71fd2e99.", "author": "zentol", "createdAt": "2020-03-18T10:14:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NjM1Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395366353", "bodyText": "If it is something non-trivial and hard to make a call about, I would propose to skip this refactoring for now.", "author": "afedulov", "createdAt": "2020-03-19T23:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDA1OA=="}], "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\nindex 7cd5714720e..59d1eb61411 100755\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\n\n@@ -161,14 +159,13 @@ public abstract class ClusterEntrypoint implements AutoCloseableAsync, FatalErro\n \t\tLOG.info(\"Starting {}.\", getClass().getSimpleName());\n \n \t\ttry {\n-\t\t\t//TODO: push down filesystem initialization into runCluster - initializeServices (?)\n-\t\t\tPluginManager pluginManager = PluginUtils.createPluginManagerFromRootFolder(configuration);\n-\t\t\tconfigureFileSystems(configuration, pluginManager);\n+\n+\t\t\tconfigureFileSystems(configuration);\n \n \t\t\tSecurityContext securityContext = installSecurityContext(configuration);\n \n \t\t\tsecurityContext.runSecured((Callable<Void>) () -> {\n-\t\t\t\trunCluster(configuration, pluginManager);\n+\t\t\t\trunCluster(configuration);\n \n \t\t\t\treturn null;\n \t\t\t});\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDQwNg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388310406", "bodyText": "Just tagging TODO.", "author": "AHeise", "createdAt": "2020-03-05T14:00:38Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java", "diffHunk": "@@ -202,9 +204,11 @@ private SecurityContext installSecurityContext(Configuration configuration) thro\n \t\treturn SecurityUtils.getInstalledContext();\n \t}\n \n-\tprivate void runCluster(Configuration configuration) throws Exception {\n+\tprivate void runCluster(Configuration configuration, PluginManager pluginManager) throws Exception {\n \t\tsynchronized (lock) {\n-\t\t\tinitializeServices(configuration);\n+\n+\t\t\t//TODO: Ask why FileSystem is not initialized here too.", "originalCommit": "bc188f48bff0c164ad2e36ef0eda3a5557e5adba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0Mzc0Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393843746", "bodyText": "See above.", "author": "afedulov", "createdAt": "2020-03-17T17:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMDQwNg=="}], "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\nindex 7cd5714720e..59d1eb61411 100755\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/entrypoint/ClusterEntrypoint.java\n\n@@ -204,11 +201,9 @@ public abstract class ClusterEntrypoint implements AutoCloseableAsync, FatalErro\n \t\treturn SecurityUtils.getInstalledContext();\n \t}\n \n-\tprivate void runCluster(Configuration configuration, PluginManager pluginManager) throws Exception {\n+\tprivate void runCluster(Configuration configuration) throws Exception {\n \t\tsynchronized (lock) {\n-\n-\t\t\t//TODO: Ask why FileSystem is not initialized here too.\n-\t\t\tinitializeServices(configuration, pluginManager);\n+\t\t\tinitializeServices(configuration);\n \n \t\t\t// write host information into configuration\n \t\t\tconfiguration.setString(JobManagerOptions.ADDRESS, commonRpcService.getAddress());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMzEwMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388313102", "bodyText": "Commit message should explain what's actually happening.", "author": "AHeise", "createdAt": "2020-03-05T14:05:20Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -77,6 +77,7 @@\n \tprivate Path conf;", "originalCommit": "c2c2b9d6b545c77ed473156d7bbf54c5aecd632b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzU3ODMyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393578320", "bodyText": "Addressed.", "author": "afedulov", "createdAt": "2020-03-17T10:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODMxMzEwMg=="}], "type": "inlineReview", "revised_code": {"commit": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "chunk": "diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\nsimilarity index 64%\nrename from flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\nrename to flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\nindex 4396cb663d8..4306d7c40e8 100644\n--- a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\n+++ b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\n\n@@ -61,82 +60,32 @@ import java.util.stream.Stream;\n /**\n  * A wrapper around a Flink distribution.\n  */\n-public final class FlinkDistribution implements ExternalResource {\n+final class FlinkDistribution {\n \n \tprivate static final Logger LOG = LoggerFactory.getLogger(FlinkDistribution.class);\n \n \tprivate static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();\n \n-\tprivate final Path logBackupDir;\n+\tprivate final Path opt;\n+\tprivate final Path lib;\n+\tprivate final Path conf;\n+\tprivate final Path log;\n+\tprivate final Path bin;\n+\tprivate final Path plugins;\n \n-\tprivate final TemporaryFolder temporaryFolder = new TemporaryFolder();\n+\tprivate final Configuration defaultConfig;\n \n-\tprivate final Path originalFlinkDir;\n-\tprivate Path opt;\n-\tprivate Path lib;\n-\tprivate Path conf;\n-\tprivate Path log;\n-\tprivate Path bin;\n-\tprivate Path plugins;\n-\n-\tprivate Configuration defaultConfig;\n-\n-\tpublic FlinkDistribution() {\n-\t\tfinal String distDirProperty = System.getProperty(\"distDir\");\n-\t\tif (distDirProperty == null) {\n-\t\t\tAssert.fail(\"The distDir property was not set. You can set it when running maven via -DdistDir=<path> .\");\n-\t\t}\n-\t\tfinal String backupDirProperty = System.getProperty(\"logBackupDir\");\n-\t\tlogBackupDir = backupDirProperty == null ? null : Paths.get(backupDirProperty);\n-\t\toriginalFlinkDir = Paths.get(distDirProperty);\n-\t}\n-\n-\t@Override\n-\tpublic void before() throws IOException {\n-\t\ttemporaryFolder.create();\n-\n-\t\tfinal Path flinkDir = temporaryFolder.newFolder().toPath();\n-\n-\t\tLOG.info(\"Copying distribution to {}.\", flinkDir);\n-\t\tTestUtils.copyDirectory(originalFlinkDir, flinkDir);\n-\n-\t\tbin = flinkDir.resolve(\"bin\");\n-\t\topt = flinkDir.resolve(\"opt\");\n-\t\tlib = flinkDir.resolve(\"lib\");\n-\t\tconf = flinkDir.resolve(\"conf\");\n-\t\tlog = flinkDir.resolve(\"log\");\n-\t\tplugins = flinkDir.resolve(\"plugins\");\n+\tFlinkDistribution(Path distributionDir) {\n+\t\tbin = distributionDir.resolve(\"bin\");\n+\t\topt = distributionDir.resolve(\"opt\");\n+\t\tlib = distributionDir.resolve(\"lib\");\n+\t\tconf = distributionDir.resolve(\"conf\");\n+\t\tlog = distributionDir.resolve(\"log\");\n+\t\tplugins = distributionDir.resolve(\"plugins\");\n \n \t\tdefaultConfig = new UnmodifiableConfiguration(GlobalConfiguration.loadConfiguration(conf.toAbsolutePath().toString()));\n \t}\n \n-\t@Override\n-\tpublic void afterTestSuccess() {\n-\t\ttry {\n-\t\t\tstopFlinkCluster();\n-\t\t} catch (IOException e) {\n-\t\t\tLOG.error(\"Failure while shutting down Flink cluster.\", e);\n-\t\t}\n-\n-\t\ttemporaryFolder.delete();\n-\t}\n-\n-\t@Override\n-\tpublic void afterTestFailure() {\n-\t\tif (logBackupDir != null) {\n-\t\t\tfinal UUID id = UUID.randomUUID();\n-\t\t\tLOG.info(\"Backing up logs to {}/{}.\", logBackupDir, id);\n-\t\t\ttry {\n-\t\t\t\tFiles.createDirectories(logBackupDir);\n-\t\t\t\tTestUtils.copyDirectory(log, logBackupDir.resolve(id.toString()));\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tLOG.warn(\"An error occurred while backing up logs.\", e);\n-\t\t\t}\n-\t\t}\n-\n-\t\tafterTestSuccess();\n-\t}\n-\n \tpublic void startJobManager() throws IOException {\n \t\tLOG.info(\"Starting Flink JobManager.\");\n \t\tAutoClosableProcess.runBlocking(bin.resolve(\"jobmanager.sh\").toAbsolutePath().toString(), \"start\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346247", "bodyText": "Collectors.toCollection(TreeSet::new) to get rid of the next few lines.", "author": "AHeise", "createdAt": "2020-03-05T14:56:56Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());", "originalCommit": "5dfb306ba6ff07f700b1afc21847641321705d4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0ODM4Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393848386", "bodyText": "Thanks, changed as proposed.", "author": "afedulov", "createdAt": "2020-03-17T17:27:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM0ODA1NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395348055", "bodyText": "@AHeise I have applied this refactoring but then understood that I probably really did not get what you actually propose. Could you please clarify?", "author": "afedulov", "createdAt": "2020-03-19T22:11:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODI1Nw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r396968257", "bodyText": "Set<String> namedOrderedReporters = reporterListPattern.splitAsStream(includedReportersString)\n\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n\t\t\t.collect(Collectors.toCollection(TreeSet::new));", "author": "AHeise", "createdAt": "2020-03-24T08:15:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzAzMDI2OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397030268", "bodyText": "You've mentioned \"to get rid of the next few lines\", but this Tree data structure is further used as a container that is filled using some conditional logic and returned from the method, it is not just about having the input entries sorted. Do you propose to rewrite it?", "author": "afedulov", "createdAt": "2020-03-24T09:59:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzAzNjYyMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397036620", "bodyText": "Ah you are right. Ignore my comment.", "author": "AHeise", "createdAt": "2020-03-24T10:09:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0NjI0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex 131a28599ff..cc0ab2a1370 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -238,7 +238,7 @@ public final class ReporterSetup {\n //\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n //\t\t\t\t\t\t.toURI()).getCanonicalPath();\n //\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n-\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n \t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n \t\t\t\tLOG.warn(\"Error while loading reporter factory.\", e);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r388346850", "bodyText": "warn if it doesn't match?", "author": "AHeise", "createdAt": "2020-03-05T14:57:51Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -179,28 +164,82 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\t\t\tmetricReporterOptional.ifPresent(reporter -> {\n \t\t\t\t\tMetricConfig metricConfig = new MetricConfig();\n \t\t\t\t\treporterConfig.addAllToProperties(metricConfig);\n-\n-\t\t\t\t\treporterArguments.add(createReporterSetup(reporterName, metricConfig, reporter));\n+\t\t\t\t\treporterSetups.add(createReporterSetup(reporterName, metricConfig, reporter));\n \t\t\t\t});\n-\t\t\t}\n-\t\t\tcatch (Throwable t) {\n+\t\t\t} catch (Throwable t) {\n \t\t\t\tLOG.error(\"Could not instantiate metrics reporter {}. Metrics might not be exposed/reported.\", reporterName, t);\n \t\t\t}\n \t\t}\n-\t\treturn reporterArguments;\n+\t\treturn reporterSetups;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n+\tprivate static List<Tuple2<String, Configuration>> loadReporterConfigurations(Configuration configuration, Set<String> namedReporters) {\n+\t\tfinal List<Tuple2<String, Configuration>> reporterConfigurations = new ArrayList<>(namedReporters.size());\n \n+\t\tfor (String namedReporter: namedReporters) {\n+\t\t\tDelegatingConfiguration delegatingConfiguration = new DelegatingConfiguration(\n+\t\t\t\tconfiguration,\n+\t\t\t\tConfigConstants.METRICS_REPORTER_PREFIX + namedReporter + '.');\n+\n+\t\t\treporterConfigurations.add(Tuple2.of(namedReporter, delegatingConfiguration));\n+\t\t}\n+\t\treturn reporterConfigurations;\n+\t}\n+\n+\tprivate static Set<String> findEnabledReportersInConfiguration(Configuration configuration, String includedReportersString) {\n+\t\tSet<String> includedReporters = reporterListPattern.splitAsStream(includedReportersString)\n+\t\t\t.filter(r -> !r.isEmpty()) // splitting an empty string results in an empty string on jdk9+\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\t// use a TreeSet to make the reporter order deterministic, which is useful for testing\n+\t\tSet<String> namedOrderedReporters = new TreeSet<>(String::compareTo);\n+\n+\t\t// scan entire configuration for keys starting with METRICS_REPORTER_PREFIX and determine the set of enabled reporters\n+\t\tfor (String key : configuration.keySet()) {\n+\t\t\tif (key.startsWith(ConfigConstants.METRICS_REPORTER_PREFIX)) {\n+\t\t\t\tMatcher matcher = reporterClassPattern.matcher(key);\n+\t\t\t\tif (matcher.matches()) {", "originalCommit": "5dfb306ba6ff07f700b1afc21847641321705d4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg0Mjg3Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393842876", "bodyText": "Seems like a silent skip . This is old code, maybe @zentol could comment.", "author": "afedulov", "createdAt": "2020-03-17T17:19:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzkwNDczMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r393904732", "bodyText": "This would flood the logs with warnings for every single configured parameter, as they all have the metrics.reporter. prefix but don't end with class.", "author": "zentol", "createdAt": "2020-03-17T19:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODM0Njg1MA=="}], "type": "inlineReview", "revised_code": {"commit": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex 131a28599ff..cc0ab2a1370 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -238,7 +238,7 @@ public final class ReporterSetup {\n //\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n //\t\t\t\t\t\t.toURI()).getCanonicalPath();\n //\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n-\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n \t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n \t\t\t\tLOG.warn(\"Error while loading reporter factory.\", e);\n"}}, {"oid": "3aded2be8a0019e7b025d811d204e92d36dd24e7", "url": "https://github.com/apache/flink/commit/3aded2be8a0019e7b025d811d204e92d36dd24e7", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T10:25:49Z", "type": "forcePushed"}, {"oid": "57db59bd20c14d5a0872f6d35b2b3220624ec96b", "url": "https://github.com/apache/flink/commit/57db59bd20c14d5a0872f6d35b2b3220624ec96b", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T13:51:44Z", "type": "forcePushed"}, {"oid": "5b0f219689e81fe11c3511c13c7f4943a997a4ef", "url": "https://github.com/apache/flink/commit/5b0f219689e81fe11c3511c13c7f4943a997a4ef", "message": "[FLINK-16222][runtime] Use plugins load mechanism to initialize MetricsReporters", "committedDate": "2020-03-17T16:58:33Z", "type": "forcePushed"}, {"oid": "a244cee274bab74683c25f90bfd515698bc04c95", "url": "https://github.com/apache/flink/commit/a244cee274bab74683c25f90bfd515698bc04c95", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-17T20:29:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394147676", "bodyText": "/ means or. and/or is and or or, which can be simplified to or. (or is not xor in English)", "author": "AHeise", "createdAt": "2020-03-18T07:26:11Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java", "diffHunk": "@@ -210,17 +213,31 @@ private static ReporterSetup createReporterSetup(String reporterName, MetricConf\n \t\treturn namedOrderedReporters;\n \t}\n \n-\tprivate static Map<String, MetricReporterFactory> loadReporterFactories() {\n-\t\tfinal ServiceLoader<MetricReporterFactory> serviceLoader = ServiceLoader.load(MetricReporterFactory.class);\n-\n+\tprivate static Map<String, MetricReporterFactory> loadAvailableReporterFactories(PluginManager pluginManager) {\n \t\tfinal Map<String, MetricReporterFactory> reporterFactories = new HashMap<>(2);\n-\t\tfinal Iterator<MetricReporterFactory> factoryIterator = serviceLoader.iterator();\n+\t\tfinal Iterator<MetricReporterFactory> factoryIterator = getAllReporterFactories(pluginManager);\n+\t\tLOG.info(\"Prepare reporter factories (from both SPIs and Plugins):\");\n \t\t// do not use streams or for-each loops here because they do not allow catching individual ServiceConfigurationErrors\n \t\t// such an error might be caused if the META-INF/services contains an entry to a non-existing factory class\n \t\twhile (factoryIterator.hasNext()) {\n \t\t\ttry {\n \t\t\t\tMetricReporterFactory factory = factoryIterator.next();\n-\t\t\t\treporterFactories.put(factory.getClass().getName(), factory);\n+\t\t\t\tString factoryClassName = factory.getClass().getName();\n+\t\t\t\tMetricReporterFactory existingFactory = reporterFactories.get(factoryClassName);\n+\t\t\t\tif (existingFactory == null){\n+\t\t\t\t\treporterFactories.put(factoryClassName, factory);\n+\t\t\t\t\tLOG.info(\"Found reporter factory {} at {} \",\n+\t\t\t\t\t\tfactoryClassName,\n+\t\t\t\t\t\tnew File(factory.getClass().getProtectionDomain().getCodeSource().getLocation().toURI()).getCanonicalPath());\n+\t\t\t\t} else {\n+\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n+//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n+//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n+//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n+\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);", "originalCommit": "63001ed57dcdebbf5f0642285f6e82565caf7b4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDI0NTc0NQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394245745", "bodyText": "It's frequently used in our code and documentation; I don't think we gain anything by watching out for things like this.\nPersonally I find it less ambiguous than just or.", "author": "zentol", "createdAt": "2020-03-18T10:30:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMTg4MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394321880", "bodyText": "I wouldn't care if it's just in a comment or internal exception. But if it's user facing, I'd strongly recommend to proof-read everything and fix it.", "author": "AHeise", "createdAt": "2020-03-18T12:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMyNjAzNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395326037", "bodyText": "https://en.wikipedia.org/wiki/And/or\nIt is used as an inclusive \"or\" (as in logic and mathematics), while an \"or\" in spoken language might be inclusive or exclusive.\nSeems to me like something that reduces ambiguity, as @zentol said.", "author": "afedulov", "createdAt": "2020-03-19T21:20:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzMDEyMg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395330122", "bodyText": "No hard feelings. You can safely ignore that comment. Just wanted to point it out and closing with a cite of your link\n\nIt has been strongly criticized as both ugly in style, and ambiguous in legal documents .\n\nSame in academic writing.", "author": "AHeise", "createdAt": "2020-03-19T21:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NTExNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395365114", "bodyText": "I thing the problem is that we have too many variants to describe with a single coordinating conjunction like \"or\" (plus \"or\" can unfortunately be both inclusive and exclusive). Cases:\n(xx) _ ()\n() _ (xx)\n(x) _ (x)\n(xx) _ (xx)\nAlternatives like \"a or b or both\" also do not work, because in this particular case they can be easily be interpreted as if the \"(x) _ (x)\" case is not an issue (because of \"Multiple\" in the beginning). Seems to me like the best case to indicate this ambiguity is is to use \"and/or\" so that people will be aware of multiple ways this can happen.", "author": "afedulov", "createdAt": "2020-03-19T22:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxODgyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395618828", "bodyText": "I think we should stop discussing this here; this is relevant for the entirety of the documentation, and we could get much more experienced people involved if we target that instead.", "author": "zentol", "createdAt": "2020-03-20T12:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2MTI1OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395661258", "bodyText": "I leave it as \"and/or\" here, and then we comb through the docs and sources to address it separately.", "author": "afedulov", "createdAt": "2020-03-20T14:10:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE0NzY3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "a1b15671c97e8809c0301fb4c225fdc1a7f78545", "chunk": "diff --git a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\nindex 97ccd640cd6..15cfd23e9e7 100644\n--- a/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n+++ b/flink-runtime/src/main/java/org/apache/flink/runtime/metrics/ReporterSetup.java\n\n@@ -230,12 +230,6 @@ public final class ReporterSetup {\n \t\t\t\t\t\tfactoryClassName,\n \t\t\t\t\t\tnew File(factory.getClass().getProtectionDomain().getCodeSource().getLocation().toURI()).getCanonicalPath());\n \t\t\t\t} else {\n-\t\t\t\t\t//TODO: use path information below, when Plugin Classloader stops always prioritizing factories from /lib\n-//\t\t\t\t\tString jarPath1 = new File(existingFactory.getClass().getProtectionDomain().getCodeSource().getLocation()\n-//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n-//\t\t\t\t\tString jarPath2 = new File(factory.getClass().getProtectionDomain().getCodeSource().getLocation()\n-//\t\t\t\t\t\t.toURI()).getCanonicalPath();\n-//\t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found: \\n {} and \\n{}\", jarPath1, jarPath2);\n \t\t\t\t\tLOG.warn(\"Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for {}. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.\", factoryClassName);\n \t\t\t\t}\n \t\t\t} catch (Exception | ServiceConfigurationError e) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394180142", "bodyText": "This will require a rebase; we added a more generic version for copying jars so we don't have to keep adding new ones. You will have to add a JarLocation for the plugins directory, and modify FlinkDistribution#moveJar to handle this location appropriately.", "author": "zentol", "createdAt": "2020-03-18T08:38:16Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java", "diffHunk": "@@ -260,16 +262,26 @@ public void submitSQLJob(SQLJobSubmission job) throws IOException {\n \t}\n \n \tpublic void copyOptJarsToLib(String jarNamePrefix) throws FileNotFoundException, IOException {\n-\t\tfinal Optional<Path> reporterJarOptional;\n-\t\ttry (Stream<Path> logFiles = Files.walk(opt)) {\n-\t\t\treporterJarOptional = logFiles\n+\t\tcopyOptJars(jarNamePrefix, lib);\n+\t}\n+\n+\tpublic void copyOptJarsToPlugins(String jarNamePrefix) throws FileNotFoundException, IOException {", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NTQyMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395375423", "bodyText": "But this is not really \"copying jars\", right? It will actually move the file from opt to lib or plugins. The problem is that one of the cases I would like to test required the jar to be actually copied to both.", "author": "afedulov", "createdAt": "2020-03-19T23:30:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NjMzNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395376334", "bodyText": "I assume you mean to modify FlinkDistribution#mapJarLocationToPath ?", "author": "afedulov", "createdAt": "2020-03-19T23:34:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNzg3Mw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395617873", "bodyText": "hmmm that's a bit frustrating; now we have to open up the API to allow things that people shouldn't be doing; though admittedly we should be able to test everything a user might do.\nA dumb intermediate workaround would be to have 2 variants; one for copying/moving each.\nYou will also have to modify #moveJar to pass in the file(name at least) to #mapJarLocationPath so that you can introduce the directory for the individual plugin.", "author": "zentol", "createdAt": "2020-03-20T12:57:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MDE0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "chunk": "diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\nsimilarity index 64%\nrename from flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\nrename to flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\nindex 4396cb663d8..4306d7c40e8 100644\n--- a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/FlinkDistribution.java\n+++ b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java\n\n@@ -261,29 +208,45 @@ public final class FlinkDistribution implements ExternalResource {\n \t\tAutoClosableProcess.runBlocking(commands.toArray(new String[0]));\n \t}\n \n-\tpublic void copyOptJarsToLib(String jarNamePrefix) throws FileNotFoundException, IOException {\n-\t\tcopyOptJars(jarNamePrefix, lib);\n-\t}\n-\n-\tpublic void copyOptJarsToPlugins(String jarNamePrefix) throws FileNotFoundException, IOException {\n-\t\tPath pluginPath =  Paths.get(plugins.toString(), jarNamePrefix);\n-\t\tFiles.createDirectories(pluginPath);\n-\t\tcopyOptJars(jarNamePrefix, pluginPath);\n-\t}\n+\tpublic void performJarOperation(JarOperation operation) throws IOException {\n+\t\tfinal Path source = mapJarLocationToPath(operation.getSource());\n+\t\tfinal Path target = mapJarLocationToPath(operation.getTarget());\n \n-\tprivate void copyOptJars(String jarNamePrefix, Path to) throws FileNotFoundException, IOException {\n \t\tfinal Optional<Path> jarOptional;\n-\t\ttry (Stream<Path> optFiles = Files.walk(opt)){\n-\t\t\tjarOptional = optFiles\n-\t\t\t\t.filter(path -> path.getFileName().toString().startsWith(jarNamePrefix))\n+\t\ttry (Stream<Path> files = Files.walk(source)) {\n+\t\t\tjarOptional = files\n+\t\t\t\t.filter(path -> path.getFileName().toString().startsWith(operation.getJarNamePrefix()))\n \t\t\t\t.findFirst();\n \t\t}\n-\t\tif (jarOptional.isPresent()){\n-\t\t\tfinal Path jar = jarOptional.get();\n-\t\t\tfinal Path targetFilePath = to.resolve(jar.getFileName());\n-\t\t\tFiles.copy(jar, targetFilePath);\n+\t\tif (jarOptional.isPresent()) {\n+\t\t\tfinal Path sourceJar = jarOptional.get();\n+\t\t\tfinal Path targetJar = target.resolve(sourceJar.getFileName());\n+\t\t\tswitch (operation.getOperationType()){\n+\t\t\t\tcase COPY:\n+\t\t\t\t\tFiles.copy(sourceJar, targetJar);\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase MOVE:\n+\t\t\t\t\tFiles.move(sourceJar, targetJar);\n+\t\t\t\t\tbreak;\n+\t\t\t\tdefault:\n+\t\t\t\t\tthrow new IllegalStateException();\n+\t\t\t}\n+\n \t\t} else {\n-\t\t\tthrow new FileNotFoundException(\"No jar could be found matching the pattern \" + jarNamePrefix + \".\");\n+\t\t\tthrow new FileNotFoundException(\"No jar could be found matching the pattern \" + operation.getJarNamePrefix() + \".\");\n+\t\t}\n+\t}\n+\n+\tprivate Path mapJarLocationToPath(JarLocation location) {\n+\t\tswitch (location) {\n+\t\t\tcase LIB:\n+\t\t\t\treturn lib;\n+\t\t\tcase OPT:\n+\t\t\t\treturn opt;\n+\t\t\tcase PLUGINS:\n+\t\t\t\treturn plugins;\n+\t\t\tdefault:\n+\t\t\t\tthrow new IllegalStateException();\n \t\t}\n \t}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394181288", "bodyText": "this will also need adjustments after a rebase, as this test now works against the FlinkResource interface, where jar copies and configuration settings are done as part of the FlinkResource setup.", "author": "zentol", "createdAt": "2020-03-18T08:40:35Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgwOTg5NA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r396809894", "bodyText": "@zentol It seems that this updated approach that got merged into master does not support the kinds of tests that we would need to do for the supported scenarios (see reporterWorksWhenFoundInLibsViaReflection, reporterWorksWhenFoundInPluginsViaReflection, reporterWorksWhenFoundBothInPluginsAndLibsViaFactories in this PR). How should we proceed? I can either bend the FlinkResource implementation back to the state where it supports modifications of the underlying resources after creation and keep the initialization in @Rule (a hack), or reinitialize FlinkResource in every test. What do you think?", "author": "afedulov", "createdAt": "2020-03-23T23:05:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY3NjIxOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r397676218", "bodyText": "I'd opt for creating a separate FlinkResource in every test.", "author": "zentol", "createdAt": "2020-03-25T08:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MTI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "chunk": "diff --git a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\nindex ba72046d971..43cb152485a 100644\n--- a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n+++ b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n\n@@ -112,53 +124,76 @@ public class PrometheusReporterEndToEndITCase extends TestLogger {\n \t\tAssume.assumeFalse(\"This test does not run on Windows.\", OperatingSystem.isWindows());\n \t}\n \n-\t@Rule\n-\tpublic final FlinkDistribution dist = new FlinkDistribution();\n+\t@Parameterized.Parameters(name = \"{index}: {0}\")\n+\tpublic static Collection<TestParams> testParameters() {\n+\t\tList<TestParams> testParams = new ArrayList<>();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'libs' and initialized via reflection\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.LIB, COPY)),\n+\t\t\t\tfalse)\n+\t\t);\n \n-\t@Rule\n-\tpublic final TemporaryFolder tmp = new TemporaryFolder();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'plugins' and initialized via reflection\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)),\n+\t\t\t\tfalse)\n+\t\t);\n \n-\t@Rule\n-\tpublic final DownloadCache downloadCache = DownloadCache.get();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'plugins' and initialized via factories\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)),\n+\t\t\t\ttrue)\n+\t\t);\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n-\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(false);\n-\t}\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in both 'libs' and 'plugins' and initialized via factories\",\n+\t\t\t\tcollectionOf(\n+\t\t\t\t\t\t\tJarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.LIB, COPY),\n+\t\t\t\t\t\t\tJarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)\n+\t\t\t\t),\n+\t\t\t\ttrue)\n+\t\t);\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInPluginsViaReflection() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(false);\n+\t\treturn testParams;\n \t}\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInPluginsViaFactories() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(true);\n-\t}\n+\t@Rule\n+\tpublic final FlinkResource dist;\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundBothInPluginsAndLibsViaFactories() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(true);\n+\tpublic PrometheusReporterEndToEndITCase(TestParams params) {\n+\t\tfinal FlinkResourceSetup.FlinkResourceSetupBuilder builder = FlinkResourceSetup.builder();\n+\t\tfor (JarOperation jarOperation : params.getOperations()) {\n+\t\t\tbuilder.addJarOperation(jarOperation);\n+\t\t}\n+\t\tbuilder.addConfiguration(getFlinkConfig(params.getUseFactory()));\n+\t\tdist = new LocalStandaloneFlinkResourceFactory().create(builder.build()).get();\n \t}\n \n-\tprivate void testReporter(boolean useFactory) throws Exception {\n+\t@Rule\n+\tpublic final TemporaryFolder tmp = new TemporaryFolder();\n+\n+\t@Rule\n+\tpublic final DownloadCache downloadCache = DownloadCache.get();\n+\n+\tprivate static Configuration getFlinkConfig(boolean useReporterFactory) {\n \t\tfinal Configuration config = new Configuration();\n \n-\t\tif (useFactory) {\n+\t\tif (useReporterFactory) {\n \t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX, PrometheusReporterFactory.class.getName());\n \t\t} else {\n \t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n \t\t}\n \n \t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.port\", \"9000-9100\");\n+\t\treturn config;\n+\t}\n \n-\t\tdist.appendConfiguration(config);\n+\tprivate static Collection<JarOperation> collectionOf(JarOperation ... copies){\n+\t\treturn Arrays.asList(copies);\n+\t}\n \n+\t@Test\n+\tpublic void testReporter() throws Exception {\n \t\tfinal Path tmpPrometheusDir = tmp.newFolder().toPath().resolve(\"prometheus\");\n \t\tfinal Path prometheusBinDir = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME);\n \t\tfinal Path prometheusConfig = prometheusBinDir.resolve(\"prometheus.yml\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183150", "bodyText": "Ideally we move the logic from PrometheusReporter#open into this method and change the constructor accordingly.", "author": "zentol", "createdAt": "2020-03-18T08:43:55Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {\n+\n+\t@Override\n+\tpublic PrometheusReporter createMetricReporter(Properties properties) {\n+\t\treturn new PrometheusReporter();", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzNTMzMw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395335333", "bodyText": "It seems that this will pull a rather large refactoring with it, because of the call to super.open(config) in the open methods and because of having to reconcile different configuration containers - Properties vs MetricsConfig. I would prefer to address it in a separate refactoring PR, if possible.", "author": "afedulov", "createdAt": "2020-03-19T21:40:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxOTM4Mg==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395619382", "bodyText": "hmm that is true, I suppose the dual nature of the Prometheus reporters make things a bit funky. Let's leave it like this for now.", "author": "zentol", "createdAt": "2020-03-20T13:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzE1MA=="}], "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\nindex d6c8ea52d77..a1ad3657b18 100644\n--- a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\n+++ b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\n\n@@ -17,7 +17,6 @@\n \n package org.apache.flink.metrics.prometheus;\n \n-import org.apache.flink.core.plugin.Plugin;\n import org.apache.flink.metrics.reporter.MetricReporterFactory;\n \n import java.util.Properties;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzMwMA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394183300", "bodyText": "We need a second factory for the PrometheusPushGatewayReporter", "author": "zentol", "createdAt": "2020-03-18T08:44:10Z", "path": "flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.metrics.prometheus;\n+\n+import org.apache.flink.core.plugin.Plugin;\n+import org.apache.flink.metrics.reporter.MetricReporterFactory;\n+\n+import java.util.Properties;\n+\n+/**\n+ * {@link MetricReporterFactory} for {@link PrometheusReporter}.\n+ */\n+public class PrometheusReporterFactory implements MetricReporterFactory, Plugin {", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzNzI0MQ==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395337241", "bodyText": "Added.", "author": "afedulov", "createdAt": "2020-03-19T21:44:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDE4MzMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\nindex d6c8ea52d77..a1ad3657b18 100644\n--- a/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\n+++ b/flink-metrics/flink-metrics-prometheus/src/main/java/org/apache/flink/metrics/prometheus/PrometheusReporterFactory.java\n\n@@ -17,7 +17,6 @@\n \n package org.apache.flink.metrics.prometheus;\n \n-import org.apache.flink.core.plugin.Plugin;\n import org.apache.flink.metrics.reporter.MetricReporterFactory;\n \n import java.util.Properties;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzODA1MA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394238050", "bodyText": "unused?", "author": "zentol", "createdAt": "2020-03-18T10:17:12Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.flink.configuration.ConfigConstants;\n import org.apache.flink.configuration.Configuration;\n import org.apache.flink.configuration.MetricOptions;\n+import org.apache.flink.core.plugin.PluginManager;", "originalCommit": "a244cee274bab74683c25f90bfd515698bc04c95", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7f6ad172474e37bbf346a7762868c9114510c4c9", "chunk": "diff --git a/flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java b/flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java\nindex a901bb05c3f..f687c66034c 100644\n--- a/flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java\n+++ b/flink-runtime/src/test/java/org/apache/flink/runtime/metrics/ReporterSetupTest.java\n\n@@ -21,7 +21,6 @@ package org.apache.flink.runtime.metrics;\n import org.apache.flink.configuration.ConfigConstants;\n import org.apache.flink.configuration.Configuration;\n import org.apache.flink.configuration.MetricOptions;\n-import org.apache.flink.core.plugin.PluginManager;\n import org.apache.flink.metrics.MetricConfig;\n import org.apache.flink.metrics.reporter.InstantiateViaFactory;\n import org.apache.flink.metrics.reporter.MetricReporter;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzOTExNA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r394239114", "bodyText": "this belongs into a separate commit since it is fixing a bug in the test that can occur independently from this PR.", "author": "zentol", "createdAt": "2020-03-18T10:18:59Z", "path": "flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java", "diffHunk": "@@ -120,24 +122,51 @@ public static void checkOS() {\n \tpublic final DownloadCache downloadCache = DownloadCache.get();\n \n \t@Test\n-\tpublic void testReporter() throws Exception {\n-\t\tdist.copyOptJarsToLib(\"flink-metrics-prometheus\");\n+\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaReflection() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(false);\n+\t}\n+\n+\t@Test\n+\tpublic void reporterWorksWhenFoundInPluginsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n \n+\t@Test\n+\tpublic void reporterWorksWhenFoundBothInPluginsAndLibsViaFactories() throws Exception {\n+\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n+\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n+\t\ttestReporter(true);\n+\t}\n+\n+\tprivate void testReporter(boolean useFactory) throws Exception {\n \t\tfinal Configuration config = new Configuration();\n-\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\n+\t\tif (useFactory) {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX, PrometheusReporterFactory.class.getName());\n+\t\t} else {\n+\t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n+\t\t}\n+\n \t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.port\", \"9000-9100\");\n \n \t\tdist.appendConfiguration(config);\n \n \t\tfinal Path tmpPrometheusDir = tmp.newFolder().toPath().resolve(\"prometheus\");\n-\t\tfinal Path prometheusArchive = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME + \".tar.gz\");\n \t\tfinal Path prometheusBinDir = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME);\n \t\tfinal Path prometheusConfig = prometheusBinDir.resolve(\"prometheus.yml\");\n \t\tfinal Path prometheusBinary = prometheusBinDir.resolve(\"prometheus\");\n \t\tFiles.createDirectory(tmpPrometheusDir);\n \n-\t\tdownloadCache.getOrDownload(\n-\t\t\t\"https://github.com/prometheus/prometheus/releases/download/v\" + PROMETHEUS_VERSION + '/' + prometheusArchive.getFileName(),\n+\t\tfinal Path prometheusArchive = downloadCache.getOrDownload(", "originalCommit": "37984c5d08a46b06bee75779aed813a5e1f04863", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MDQyNw==", "url": "https://github.com/apache/flink/pull/11195#discussion_r395360427", "bodyText": "Split as requested.", "author": "afedulov", "createdAt": "2020-03-19T22:44:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzOTExNA=="}], "type": "inlineReview", "revised_code": {"commit": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "chunk": "diff --git a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\nindex ba72046d971..43cb152485a 100644\n--- a/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n+++ b/flink-end-to-end-tests/flink-metrics-reporter-prometheus-test/src/test/java/org/apache/flink/metrics/prometheus/tests/PrometheusReporterEndToEndITCase.java\n\n@@ -112,53 +124,76 @@ public class PrometheusReporterEndToEndITCase extends TestLogger {\n \t\tAssume.assumeFalse(\"This test does not run on Windows.\", OperatingSystem.isWindows());\n \t}\n \n-\t@Rule\n-\tpublic final FlinkDistribution dist = new FlinkDistribution();\n+\t@Parameterized.Parameters(name = \"{index}: {0}\")\n+\tpublic static Collection<TestParams> testParameters() {\n+\t\tList<TestParams> testParams = new ArrayList<>();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'libs' and initialized via reflection\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.LIB, COPY)),\n+\t\t\t\tfalse)\n+\t\t);\n \n-\t@Rule\n-\tpublic final TemporaryFolder tmp = new TemporaryFolder();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'plugins' and initialized via reflection\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)),\n+\t\t\t\tfalse)\n+\t\t);\n \n-\t@Rule\n-\tpublic final DownloadCache downloadCache = DownloadCache.get();\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in 'plugins' and initialized via factories\",\n+\t\t\t\tcollectionOf(JarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)),\n+\t\t\t\ttrue)\n+\t\t);\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInLibsViaReflection() throws Exception {\n-\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(false);\n-\t}\n+\t\ttestParams.add(\n+\t\t\tTestParams.from(\"Reporter works when found in both 'libs' and 'plugins' and initialized via factories\",\n+\t\t\t\tcollectionOf(\n+\t\t\t\t\t\t\tJarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.LIB, COPY),\n+\t\t\t\t\t\t\tJarOperation.of(PROMETHEUS_JAR_PREFIX, JarLocation.OPT, JarLocation.PLUGINS, COPY)\n+\t\t\t\t),\n+\t\t\t\ttrue)\n+\t\t);\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInPluginsViaReflection() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(false);\n+\t\treturn testParams;\n \t}\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundInPluginsViaFactories() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(true);\n-\t}\n+\t@Rule\n+\tpublic final FlinkResource dist;\n \n-\t@Test\n-\tpublic void reporterWorksWhenFoundBothInPluginsAndLibsViaFactories() throws Exception {\n-\t\tdist.copyOptJarsToPlugins(PROMETHEUS_JAR_PREFIX);\n-\t\tdist.copyOptJarsToLib(PROMETHEUS_JAR_PREFIX);\n-\t\ttestReporter(true);\n+\tpublic PrometheusReporterEndToEndITCase(TestParams params) {\n+\t\tfinal FlinkResourceSetup.FlinkResourceSetupBuilder builder = FlinkResourceSetup.builder();\n+\t\tfor (JarOperation jarOperation : params.getOperations()) {\n+\t\t\tbuilder.addJarOperation(jarOperation);\n+\t\t}\n+\t\tbuilder.addConfiguration(getFlinkConfig(params.getUseFactory()));\n+\t\tdist = new LocalStandaloneFlinkResourceFactory().create(builder.build()).get();\n \t}\n \n-\tprivate void testReporter(boolean useFactory) throws Exception {\n+\t@Rule\n+\tpublic final TemporaryFolder tmp = new TemporaryFolder();\n+\n+\t@Rule\n+\tpublic final DownloadCache downloadCache = DownloadCache.get();\n+\n+\tprivate static Configuration getFlinkConfig(boolean useReporterFactory) {\n \t\tfinal Configuration config = new Configuration();\n \n-\t\tif (useFactory) {\n+\t\tif (useReporterFactory) {\n \t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX, PrometheusReporterFactory.class.getName());\n \t\t} else {\n \t\t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.\" + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX, PrometheusReporter.class.getCanonicalName());\n \t\t}\n \n \t\tconfig.setString(ConfigConstants.METRICS_REPORTER_PREFIX + \"prom.port\", \"9000-9100\");\n+\t\treturn config;\n+\t}\n \n-\t\tdist.appendConfiguration(config);\n+\tprivate static Collection<JarOperation> collectionOf(JarOperation ... copies){\n+\t\treturn Arrays.asList(copies);\n+\t}\n \n+\t@Test\n+\tpublic void testReporter() throws Exception {\n \t\tfinal Path tmpPrometheusDir = tmp.newFolder().toPath().resolve(\"prometheus\");\n \t\tfinal Path prometheusBinDir = tmpPrometheusDir.resolve(PROMETHEUS_FILE_NAME);\n \t\tfinal Path prometheusConfig = prometheusBinDir.resolve(\"prometheus.yml\");\n"}}, {"oid": "7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "url": "https://github.com/apache/flink/commit/7ce9ad87a780aab19b9c97680d7af5f648c13f3b", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:12:49Z", "type": "forcePushed"}, {"oid": "245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "url": "https://github.com/apache/flink/commit/245fcd1ee6e8a5515ccb44621e86361fd9f3cd78", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:42:39Z", "type": "forcePushed"}, {"oid": "7f6ad172474e37bbf346a7762868c9114510c4c9", "url": "https://github.com/apache/flink/commit/7f6ad172474e37bbf346a7762868c9114510c4c9", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T21:47:24Z", "type": "forcePushed"}, {"oid": "2590a69417bdd2b6bf2f4765b276a051040a97cf", "url": "https://github.com/apache/flink/commit/2590a69417bdd2b6bf2f4765b276a051040a97cf", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T22:15:42Z", "type": "forcePushed"}, {"oid": "d07ec693eb90e33071e710be0b774fc995f05867", "url": "https://github.com/apache/flink/commit/d07ec693eb90e33071e710be0b774fc995f05867", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T22:43:07Z", "type": "forcePushed"}, {"oid": "a1b15671c97e8809c0301fb4c225fdc1a7f78545", "url": "https://github.com/apache/flink/commit/a1b15671c97e8809c0301fb4c225fdc1a7f78545", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-19T23:05:05Z", "type": "forcePushed"}, {"oid": "eccc41d96524bd8ff6bfa6bfa36f366689255893", "url": "https://github.com/apache/flink/commit/eccc41d96524bd8ff6bfa6bfa36f366689255893", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-26T17:29:07Z", "type": "forcePushed"}, {"oid": "19b07382fedcab4e7c4866eb260a12cde4780538", "url": "https://github.com/apache/flink/commit/19b07382fedcab4e7c4866eb260a12cde4780538", "message": "[FLINK-16222][runtime] Refactor: remove potential reporter credentials leak via logging", "committedDate": "2020-03-26T21:38:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NDkyOA==", "url": "https://github.com/apache/flink/pull/11195#discussion_r399084928", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));\n          \n          \n            \n            \t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarOperations));", "author": "zentol", "createdAt": "2020-03-27T07:48:14Z", "path": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java", "diffHunk": "@@ -69,13 +69,13 @@ public FlinkResourceSetupBuilder addConfiguration(Configuration config) {\n \t\t\treturn this;\n \t\t}\n \n-\t\tpublic FlinkResourceSetupBuilder moveJar(String jarNamePrefix, JarLocation source, JarLocation target) {\n-\t\t\tthis.jarMoveOperations.add(new JarMove(jarNamePrefix, source, target));\n+\t\tpublic FlinkResourceSetupBuilder addJarOperation(JarOperation jarOperation) {\n+\t\t\tthis.jarOperations.add(jarOperation);\n \t\t\treturn this;\n \t\t}\n \n \t\tpublic FlinkResourceSetup build() {\n-\t\t\treturn new FlinkResourceSetup(config, Collections.unmodifiableCollection(jarMoveOperations));\n+\t\t\treturn new FlinkResourceSetup(config,  Collections.unmodifiableCollection(jarOperations));", "originalCommit": "19b07382fedcab4e7c4866eb260a12cde4780538", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "590a281040da44deee5137b037bbabcaedd0b487", "chunk": "diff --git a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java\nindex 5be45a846b1..2e4c3ab642e 100644\n--- a/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java\n+++ b/flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkResourceSetup.java\n\n@@ -69,8 +69,13 @@ public class FlinkResourceSetup {\n \t\t\treturn this;\n \t\t}\n \n-\t\tpublic FlinkResourceSetupBuilder addJarOperation(JarOperation jarOperation) {\n-\t\t\tthis.jarOperations.add(jarOperation);\n+\t\tpublic FlinkResourceSetupBuilder moveJar(String jarNamePrefix, JarLocation source, JarLocation target) {\n+\t\t\tthis.jarOperations.add(new JarOperation(jarNamePrefix, source, target, JarOperation.OperationType.MOVE));\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic FlinkResourceSetupBuilder copyJar(String jarNamePrefix, JarLocation source, JarLocation target) {\n+\t\t\tthis.jarOperations.add(new JarOperation(jarNamePrefix, source, target, JarOperation.OperationType.COPY));\n \t\t\treturn this;\n \t\t}\n \n"}}, {"oid": "590a281040da44deee5137b037bbabcaedd0b487", "url": "https://github.com/apache/flink/commit/590a281040da44deee5137b037bbabcaedd0b487", "message": "[FLINK-16222][core] Relax Plugin bounded type parameter constraint", "committedDate": "2020-03-27T15:24:35Z", "type": "commit"}, {"oid": "ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "url": "https://github.com/apache/flink/commit/ad42c142ec109c5fb4cf1bcccb61183c3e8b4a68", "message": "[FLINK-16222][runtime] Introduce PluginManager to ReporterSetup", "committedDate": "2020-03-27T18:11:23Z", "type": "commit"}, {"oid": "3630f07793d9eba899a746df43549b971ea6b2b7", "url": "https://github.com/apache/flink/commit/3630f07793d9eba899a746df43549b971ea6b2b7", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:11:49Z", "type": "forcePushed"}, {"oid": "672c515dda8d5d659c009099b98dd6a5835bbd40", "url": "https://github.com/apache/flink/commit/672c515dda8d5d659c009099b98dd6a5835bbd40", "message": "[FLINK-16222][metrics] Support loading reporters as plugins", "committedDate": "2020-03-27T18:19:01Z", "type": "commit"}, {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:19:01Z", "type": "commit"}, {"oid": "6a088a5f122ccce53e5baa97603eb8b0a9599247", "url": "https://github.com/apache/flink/commit/6a088a5f122ccce53e5baa97603eb8b0a9599247", "message": "[FLINK-16222][metrics][prometheus] Add plugin e2e test", "committedDate": "2020-03-27T18:19:01Z", "type": "forcePushed"}]}