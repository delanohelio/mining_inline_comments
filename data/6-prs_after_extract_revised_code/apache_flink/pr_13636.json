{"pr_number": 13636, "pr_title": "[FLINK-19641][hive] Optimize parallelism calculating of HiveTableSource by checking file number", "pr_createdAt": "2020-10-14T12:20:38Z", "pr_url": "https://github.com/apache/flink/pull/13636", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDU1ODY3NA==", "url": "https://github.com/apache/flink/pull/13636#discussion_r510558674", "bodyText": "Revert", "author": "JingsongLi", "createdAt": "2020-10-23T02:24:36Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveStatsUtil.java", "diffHunk": "@@ -69,7 +69,7 @@\n public class HiveStatsUtil {\n \tprivate static final Logger LOG = LoggerFactory.getLogger(HiveStatsUtil.class);\n \n-\tprivate static final int DEFAULT_UNKNOWN_STATS_VALUE = -1;\n+\tpublic static final int DEFAULT_UNKNOWN_STATS_VALUE = -1;", "originalCommit": "ccf58fbc6e8b269f07cc0ba4ad332ca06631b493", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c890e0cd38e99cc0f7decdb5d0835c5c0396f90", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveStatsUtil.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveStatsUtil.java\nindex 31b5ac29dae..d4ae6d2a10d 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveStatsUtil.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveStatsUtil.java\n\n@@ -69,7 +69,7 @@ import static org.apache.flink.util.Preconditions.checkNotNull;\n public class HiveStatsUtil {\n \tprivate static final Logger LOG = LoggerFactory.getLogger(HiveStatsUtil.class);\n \n-\tpublic static final int DEFAULT_UNKNOWN_STATS_VALUE = -1;\n+\tprivate static final int DEFAULT_UNKNOWN_STATS_VALUE = -1;\n \n \tprivate HiveStatsUtil() {}\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDU1OTM1NA==", "url": "https://github.com/apache/flink/pull/13636#discussion_r510559354", "bodyText": "Can you extract these parallelism inference logic to a dedicated class like HiveParallelismInference (Including limit logic)?", "author": "JingsongLi", "createdAt": "2020-10-23T02:27:24Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -210,19 +212,35 @@ private boolean isStreamingSource() {\n \t\t\t\t\t\t\t\t\" cannot be less than 1\");\n \t\t\t}\n \n-\t\t\tint splitNum;\n \t\t\ttry {\n-\t\t\t\tlong nano1 = System.nanoTime();\n-\t\t\t\tsplitNum = inputFormat.createInputSplits(0).length;\n-\t\t\t\tlong nano2 = System.nanoTime();\n+\t\t\t\t// `createInputSplits` is costly,", "originalCommit": "ccf58fbc6e8b269f07cc0ba4ad332ca06631b493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2MDY2OA==", "url": "https://github.com/apache/flink/pull/13636#discussion_r510860668", "bodyText": "I don't think this is needed, at least in this PR. This PR is only an optimization and code cleanups should be done in separate PRs.", "author": "tsreaper", "createdAt": "2020-10-23T12:50:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDU1OTM1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkzMDQ1Ng==", "url": "https://github.com/apache/flink/pull/13636#discussion_r510930456", "bodyText": "Yes, it can be a separate PR.\nYou are making the logic more complex, so I think you should cleanup code first.", "author": "JingsongLi", "createdAt": "2020-10-23T14:38:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDU1OTM1NA=="}], "type": "inlineReview", "revised_code": {"commit": "d2f035bb2422d0b409164c9953efaa857f4393db", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java\nindex ba6c4c61bd1..16f4fe4aeae 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java\n\n@@ -203,47 +198,11 @@ public class HiveTableSource implements\n \t\t\tTypeInformation<RowData> typeInfo, HiveTableInputFormat inputFormat) {\n \t\tDataStreamSource<RowData> source = execEnv.createInput(inputFormat, typeInfo);\n \n-\t\tint parallelism = flinkConf.get(ExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM);\n-\t\tif (flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM)) {\n-\t\t\tint max = flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX);\n-\t\t\tif (max < 1) {\n-\t\t\t\tthrow new IllegalConfigurationException(\n-\t\t\t\t\t\tHiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX.key() +\n-\t\t\t\t\t\t\t\t\" cannot be less than 1\");\n-\t\t\t}\n-\n-\t\t\ttry {\n-\t\t\t\t// `createInputSplits` is costly,\n-\t\t\t\t// so we try to avoid calling it by first checking the number of files\n-\t\t\t\t// which is the lower bound of the number of splits\n-\t\t\t\tlong startTimeMillis = System.currentTimeMillis();\n-\t\t\t\tint lowerBound = inputFormat.getNumFiles();\n-\t\t\t\tLOG.info(\n-\t\t\t\t\t\"Hive source({}}) getNumFiles use time: {} ms, number of files: {}\",\n-\t\t\t\t\ttablePath,\n-\t\t\t\t\tSystem.currentTimeMillis() - startTimeMillis,\n-\t\t\t\t\tlowerBound);\n+\t\tint parallelism = new HiveParallelismInference(tablePath, flinkConf)\n+\t\t\t.limit(limit)\n+\t\t\t.inputFormat(inputFormat)\n+\t\t\t.infer();\n \n-\t\t\t\tif (lowerBound >= max) {\n-\t\t\t\t\tparallelism = max;\n-\t\t\t\t} else {\n-\t\t\t\t\tint splitNum;\n-\t\t\t\t\tstartTimeMillis = System.currentTimeMillis();\n-\t\t\t\t\tsplitNum = inputFormat.createInputSplits(0).length;\n-\t\t\t\t\tLOG.info(\n-\t\t\t\t\t\t\"Hive source({}}) createInputSplits use time: {} ms, number of split: {}\",\n-\t\t\t\t\t\ttablePath,\n-\t\t\t\t\t\t\tSystem.currentTimeMillis() - startTimeMillis,\n-\t\t\t\t\t\tsplitNum);\n-\n-\t\t\t\t\tparallelism = Math.min(splitNum, max);\n-\t\t\t\t}\n-\t\t\t} catch (IOException e) {\n-\t\t\t\tthrow new FlinkHiveException(e);\n-\t\t\t}\n-\t\t}\n-\t\tparallelism = limit > 0 ? Math.min(parallelism, (int) limit / 1000) : parallelism;\n-\t\tparallelism = Math.max(1, parallelism);\n \t\tsource.setParallelism(parallelism);\n \t\treturn source.name(explainSource());\n \t}\n"}}, {"oid": "7c890e0cd38e99cc0f7decdb5d0835c5c0396f90", "url": "https://github.com/apache/flink/commit/7c890e0cd38e99cc0f7decdb5d0835c5c0396f90", "message": "[FLINK-19641][hive] Optimize parallelism calculating of HiveTableSource by checking file number", "committedDate": "2020-10-23T09:15:30Z", "type": "commit"}, {"oid": "d2f035bb2422d0b409164c9953efaa857f4393db", "url": "https://github.com/apache/flink/commit/d2f035bb2422d0b409164c9953efaa857f4393db", "message": "[fix] Fix comments", "committedDate": "2020-10-27T05:20:16Z", "type": "commit"}, {"oid": "c5da742f0e0ec1d9c79832051472749466a847c1", "url": "https://github.com/apache/flink/commit/c5da742f0e0ec1d9c79832051472749466a847c1", "message": "Comments from Jingsong", "committedDate": "2020-10-27T07:52:28Z", "type": "commit"}, {"oid": "dfa2662f2b4b5a2c40d4751edb6ab92e0fc8f7ec", "url": "https://github.com/apache/flink/commit/dfa2662f2b4b5a2c40d4751edb6ab92e0fc8f7ec", "message": "[fix] Fix comments", "committedDate": "2020-10-27T13:02:39Z", "type": "commit"}]}