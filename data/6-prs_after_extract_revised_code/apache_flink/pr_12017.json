{"pr_number": 12017, "pr_title": "[FLINK-17452][hive] Support creating Hive tables with constraints", "pr_createdAt": "2020-05-07T09:09:51Z", "pr_url": "https://github.com/apache/flink/pull/12017", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjIwNQ==", "url": "https://github.com/apache/flink/pull/12017#discussion_r422466205", "bodyText": "Can client do more things to include upper couple of lines?", "author": "JingsongLi", "createdAt": "2020-05-09T07:54:35Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java", "diffHunk": "@@ -374,8 +375,30 @@ public void createTable(ObjectPath tablePath, CatalogBaseTable table, boolean ig\n \n \t\tTable hiveTable = instantiateHiveTable(tablePath, table);\n \n+\t\tUniqueConstraint pkConstraint = null;\n+\t\tList<String> notNullCols = new ArrayList<>();\n+\t\tboolean isGeneric = isGenericForCreate(table.getOptions());\n+\t\tif (!isGeneric) {\n+\t\t\tpkConstraint = table.getSchema().getPrimaryKey().orElse(null);\n+\t\t\tfor (int i = 0; i < table.getSchema().getFieldDataTypes().length; i++) {\n+\t\t\t\tif (!table.getSchema().getFieldDataTypes()[i].getLogicalType().isNullable()) {\n+\t\t\t\t\tnotNullCols.add(table.getSchema().getFieldNames()[i]);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\ttry {\n-\t\t\tclient.createTable(hiveTable);\n+\t\t\tif (pkConstraint != null || !notNullCols.isEmpty()) {\n+\t\t\t\t// for now we just create constraints that are DISABLE, NOVALIDATE, RELY\n+\t\t\t\tByte[] pkTraits = new Byte[pkConstraint == null ? 0 : pkConstraint.getColumns().size()];\n+\t\t\t\tArrays.fill(pkTraits, HiveTableUtil.relyConstraint((byte) 0));\n+\t\t\t\tByte[] nnTraits = new Byte[notNullCols.size()];\n+\t\t\t\tArrays.fill(nnTraits, HiveTableUtil.relyConstraint((byte) 0));\n+\t\t\t\tclient.createTableWithConstraints(hiveTable, hiveConf,", "originalCommit": "e31740d8c7693906aae2ace9336e943a7ad2e186", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NzQ3Mg==", "url": "https://github.com/apache/flink/pull/12017#discussion_r422467472", "bodyText": "The client is meant to be just a wrapper of IMetaStoreClient. So I think it's more natural to keep such logic in HiveCatalog. We can add util method if that logic has to be repeated somewhere else.", "author": "lirui-apache", "createdAt": "2020-05-09T08:08:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjIwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "185f1aa3a6f4cc739d0120828b739b05b582b7e7", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java\nindex 11b1c7def27..6d9dc57022b 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java\n\n@@ -394,8 +394,13 @@ public class HiveCatalog extends AbstractCatalog {\n \t\t\t\tArrays.fill(pkTraits, HiveTableUtil.relyConstraint((byte) 0));\n \t\t\t\tByte[] nnTraits = new Byte[notNullCols.size()];\n \t\t\t\tArrays.fill(nnTraits, HiveTableUtil.relyConstraint((byte) 0));\n-\t\t\t\tclient.createTableWithConstraints(hiveTable, hiveConf,\n-\t\t\t\t\t\tpkConstraint, Arrays.asList(pkTraits), notNullCols, Arrays.asList(nnTraits));\n+\t\t\t\tclient.createTableWithConstraints(\n+\t\t\t\t\t\thiveTable,\n+\t\t\t\t\t\thiveConf,\n+\t\t\t\t\t\tpkConstraint,\n+\t\t\t\t\t\tArrays.asList(pkTraits),\n+\t\t\t\t\t\tnotNullCols,\n+\t\t\t\t\t\tArrays.asList(nnTraits));\n \t\t\t} else {\n \t\t\t\tclient.createTable(hiveTable);\n \t\t\t}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQ2NjQ5NQ==", "url": "https://github.com/apache/flink/pull/12017#discussion_r422466495", "bodyText": "Too many parameters should be one parameter one line, both call and declaration are like this.", "author": "JingsongLi", "createdAt": "2020-05-09T07:57:38Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV310.java", "diffHunk": "@@ -239,4 +241,54 @@ public Writable hivePrimitiveToWritable(Object value) {\n \t\t}\n \t\tthrow new FlinkHiveException(\"Unsupported primitive java value of class \" + value.getClass().getName());\n \t}\n+\n+\t@Override\n+\tpublic void createTableWithConstraints(IMetaStoreClient client, Table table, Configuration conf,", "originalCommit": "e31740d8c7693906aae2ace9336e943a7ad2e186", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "185f1aa3a6f4cc739d0120828b739b05b582b7e7", "chunk": "diff --git a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV310.java b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV310.java\nindex 83b7178dd3f..fde469cc4ea 100644\n--- a/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV310.java\n+++ b/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV310.java\n\n@@ -243,13 +243,22 @@ public class HiveShimV310 extends HiveShimV235 {\n \t}\n \n \t@Override\n-\tpublic void createTableWithConstraints(IMetaStoreClient client, Table table, Configuration conf,\n-\t\t\tUniqueConstraint pk, List<Byte> pkTraits, List<String> notNullCols, List<Byte> nnTraits) {\n+\tpublic void createTableWithConstraints(\n+\t\t\tIMetaStoreClient client,\n+\t\t\tTable table,\n+\t\t\tConfiguration conf,\n+\t\t\tUniqueConstraint pk,\n+\t\t\tList<Byte> pkTraits,\n+\t\t\tList<String> notNullCols,\n+\t\t\tList<Byte> nnTraits) {\n \t\ttry {\n \t\t\tList<Object> hivePKs = createHivePKs(table, pk, pkTraits);\n \t\t\tList<Object> hiveNNs = createHiveNNs(table, conf, notNullCols, nnTraits);\n \t\t\t// createTableWithConstraints takes PK, FK, UNIQUE, NN, DEFAULT, CHECK lists\n-\t\t\tHiveReflectionUtils.invokeMethod(client.getClass(), client, \"createTableWithConstraints\",\n+\t\t\tHiveReflectionUtils.invokeMethod(\n+\t\t\t\t\tclient.getClass(),\n+\t\t\t\t\tclient,\n+\t\t\t\t\t\"createTableWithConstraints\",\n \t\t\t\t\tnew Class[]{Table.class, List.class, List.class, List.class, List.class, List.class, List.class},\n \t\t\t\t\tnew Object[]{table, hivePKs, Collections.emptyList(), Collections.emptyList(), hiveNNs,\n \t\t\t\t\t\t\tCollections.emptyList(), Collections.emptyList()});\n"}}, {"oid": "25639f2435dc6aacfea1493f84a16880a69be6d3", "url": "https://github.com/apache/flink/commit/25639f2435dc6aacfea1493f84a16880a69be6d3", "message": "[FLINK-17452][hive] Support creating Hive tables with constraints", "committedDate": "2020-05-09T08:02:59Z", "type": "commit"}, {"oid": "185f1aa3a6f4cc739d0120828b739b05b582b7e7", "url": "https://github.com/apache/flink/commit/185f1aa3a6f4cc739d0120828b739b05b582b7e7", "message": "fix code style", "committedDate": "2020-05-09T08:16:46Z", "type": "commit"}, {"oid": "185f1aa3a6f4cc739d0120828b739b05b582b7e7", "url": "https://github.com/apache/flink/commit/185f1aa3a6f4cc739d0120828b739b05b582b7e7", "message": "fix code style", "committedDate": "2020-05-09T08:16:46Z", "type": "forcePushed"}]}