{"pr_number": 1326, "pr_title": "Task Framework IdealState Removal", "pr_createdAt": "2020-08-27T22:09:17Z", "pr_url": "https://github.com/apache/helix/pull/1326", "timeline": [{"oid": "17cfc79c203e321790170aaabdfb4393b83748ed", "url": "https://github.com/apache/helix/commit/17cfc79c203e321790170aaabdfb4393b83748ed", "message": "IS removal", "committedDate": "2020-08-27T18:52:19Z", "type": "commit"}, {"oid": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "url": "https://github.com/apache/helix/commit/6bb6c0f755800fabbe0ca33730febc386259f0e1", "message": "Remove unused code", "committedDate": "2020-08-27T22:11:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478724234", "bodyText": "Fixes #1325", "author": "NealSun96", "createdAt": "2020-08-27T22:11:41Z", "path": "helix-core/src/main/java/org/apache/helix/controller/rebalancer/util/RebalanceScheduler.java", "diffHunk": "@@ -80,6 +80,7 @@ public void scheduleRebalance(HelixManager manager, String resource, long startT\n     long delay = startTime - System.currentTimeMillis();\n     if (delay < 0) {\n       LOG.debug(String.format(\"Delay time is %s, will not be scheduled\", delay));\n+      return;", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDI5NDUzMQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480294531", "bodyText": "Good catch.", "author": "alirezazamani", "createdAt": "2020-08-31T17:59:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyMTgwNw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483221807", "bodyText": "I'm not convinced this should not be scheduled. I believe the expected behavior is triggering the rebalance immediately. In this case, we shall fix the log not the logic.\nOverall, if the caller wants to schedule a rebalance, then it should be done. It is the caller responsibility to decide whether it is necessary. The scheduler should ensure it happens. Otherwise, we may miss the event by not doing anything. That will be a real bug.", "author": "jiajunwang", "createdAt": "2020-09-03T20:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNjIzOA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483226238", "bodyText": "In my opinion, if delay is less than 0, we should not schedule rebalance. I will let Neal to convince you though. But anyways it is not the concern of this PR.", "author": "alirezazamani", "createdAt": "2020-09-03T20:09:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI1MzM0OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483253349", "bodyText": "The fix was done based on the expectation of this function, as seen in the comment: add a future rebalance task. In my opinion this function's duty is for future rebalance scheduling, therefore a start time in the past should be rejected as shown in the log.\nIf a user wants to schedule an immediate rebalance, we have scheduleOnDemandRebalance. If a user is calling this function incorrectly (passing in a past time), then the problem should show up during tests (by not triggering rebalance) instead of hiding it and let it slip to production; if a user is using this function correctly and wants to schedule a rebalance in the future at time=x, but somehow this function is delayed and is processed at time=x+1, then should that rebalance still happen? I don't think we should assume it's okay, therefore it should be rejected.\n@jiajunwang Functionally I understand your point; code-quality-wise I think this function should do what it advertises. If there's a problem it should be caught by tests and the negative delay should be handled during development.", "author": "NealSun96", "createdAt": "2020-09-03T21:04:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM0NTY5Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483345696", "bodyText": "If this change is not absolutely necessary for this PR, let's split.\n\n\nDoes it really cause any trouble for us? We should do the right thing, not what has been written down as a comment.\nThe potential problem I see here is that, as you mentioned, the possible gap between the timestamp generated and the time when this method starts processing. The delayed rebalancer has this potential issue if you return prematurely. So if you want to change it, then you need to \"fix\" the delayed rebalance. But back to the first point, I don't think it is a problem and the comment is the only thing we shall fix.\n\n\nAnyway, please convince me with a scenario that without return, our logic will fail. Otherwise, #1325 does not look like an issue to me.", "author": "jiajunwang", "createdAt": "2020-09-04T02:07:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDAyNTAzMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r484025032", "bodyText": "The initial motivation was that 1 test case is failing. After digging around, it turns out that 1 negative delay was passed into the function, which removes a scheduled rebalance at a later time. A part of the fix was that the negative delay shouldn't be passed (it was unintentional), and the other part of the fix was #1325.\nI'm unable to produce any errors now that negative delays are not passed, so I can no longer provide such a scenario.\n#1325 should either be resolved by rejecting negative delay or fixing the description and expectation of this function. For now I'll remove it from this PR.", "author": "NealSun96", "createdAt": "2020-09-06T05:42:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNDIzNA=="}], "type": "inlineReview", "revised_code": {"commit": "80b687f5f76dd6576ea7260a1eaf0b97a2051e17", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/rebalancer/util/RebalanceScheduler.java b/helix-core/src/main/java/org/apache/helix/controller/rebalancer/util/RebalanceScheduler.java\nindex 7e9f2536a..c074ebcd3 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/rebalancer/util/RebalanceScheduler.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/rebalancer/util/RebalanceScheduler.java\n\n@@ -80,7 +80,6 @@ public class RebalanceScheduler {\n     long delay = startTime - System.currentTimeMillis();\n     if (delay < 0) {\n       LOG.debug(String.format(\"Delay time is %s, will not be scheduled\", delay));\n-      return;\n     }\n     LOG.info(\"Schedule rebalance for resource : {} at time: {} delay: {}\", resource, startTime,\n         delay);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNTM2Mg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478725362", "bodyText": "Should have been in #1231", "author": "NealSun96", "createdAt": "2020-08-27T22:14:51Z", "path": "helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java", "diffHunk": "@@ -298,6 +299,7 @@ private ResourceAssignment computeResourceMapping(String jobResource,\n       handleJobTimeout(jobCtx, workflowCtx, jobResource, jobCfg);\n       finishJobInRuntimeJobDag(cache.getTaskDataCache(), workflowConfig.getWorkflowId(),\n           jobResource);\n+      scheduleJobCleanUp(jobCfg.getTerminalStateExpiry(), workflowConfig, currentTime);", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNjU3OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478726579", "bodyText": "All updateInflightJobs are making up for a case that wasn't covered before: any time a workflow exits this function before inflight jobs are handled, the inflight jobs will not be processed and will fallback to the legacy pipeline logic. This isn't correct as inflight jobs need to respond to workflow states such as TimedOut. Therefore, the new logic is to handle inflight jobs before exiting this function.", "author": "NealSun96", "createdAt": "2020-08-27T22:18:03Z", "path": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java", "diffHunk": "@@ -84,6 +84,7 @@ public void updateWorkflowStatus(String workflow, WorkflowConfig workflowCfg,\n     TargetState targetState = workflowCfg.getTargetState();\n     if (targetState == TargetState.DELETE) {\n       LOG.info(\"Workflow is marked as deleted \" + workflow + \" cleaning up the workflow context.\");\n+      updateInflightJobs(workflow, workflowCtx, currentStateOutput, bestPossibleOutput);", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNjg1Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478726856", "bodyText": "This line is already done in processJob() when the job is first started, making this logic redundant. Therefore it's removed.", "author": "NealSun96", "createdAt": "2020-08-27T22:18:56Z", "path": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java", "diffHunk": "@@ -322,64 +328,6 @@ private void processJob(String job, CurrentStateOutput currentStateOutput,\n     }\n   }\n \n-  /**\n-   * Posts new job to cluster\n-   */\n-  private void scheduleSingleJob(String jobResource, JobConfig jobConfig) {\n-    HelixAdmin admin = _manager.getClusterManagmentTool();\n-\n-    IdealState jobIS = admin.getResourceIdealState(_manager.getClusterName(), jobResource);\n-    if (jobIS != null) {\n-      LOG.info(\"Job \" + jobResource + \" idealstate already exists!\");\n-      return;\n-    }\n-\n-    // Set up job resource based on partitions from target resource\n-\n-    // Create the UserContentStore for the job first\n-    TaskUtil.createUserContent(_manager.getHelixPropertyStore(), jobResource,", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNzQ2Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483237466", "bodyText": "Agreed - we've been meaning to do this. We have an issue created for this work item I believe?", "author": "narendly", "createdAt": "2020-09-03T20:30:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNjg1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\nindex b358adb25..68a5be52b 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\n\n@@ -328,6 +328,20 @@ public class WorkflowDispatcher extends AbstractTaskDispatcher {\n     }\n   }\n \n+  /**\n+   * Jobs that are missing corresponding JobConfigs or WorkflowConfigs or WorkflowContexts need to\n+   * be dropped\n+   */\n+  public void processJobForDrop(String resourceName, CurrentStateOutput currentStateOutput,\n+      BestPossibleStateOutput bestPossibleStateOutput) {\n+    JobConfig jobConfig = _clusterDataCache.getJobConfig(resourceName);\n+    if (jobConfig == null || _clusterDataCache.getWorkflowConfig(jobConfig.getWorkflow()) == null\n+        || _clusterDataCache.getWorkflowContext(jobConfig.getWorkflow()) == null) {\n+      ResourceAssignment emptyAssignment = buildEmptyAssignment(resourceName, currentStateOutput);\n+      updateBestPossibleStateOutput(resourceName, emptyAssignment, bestPossibleStateOutput);\n+    }\n+  }\n+\n   /**\n    * Check if a workflow is ready to schedule, and schedule a rebalance if it is not\n    * @param workflow the Helix resource associated with the workflow\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNzEzNw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478727137", "bodyText": "Fix #1324", "author": "NealSun96", "createdAt": "2020-08-27T22:19:36Z", "path": "helix-core/src/main/java/org/apache/helix/task/assigner/ThreadCountBasedTaskAssigner.java", "diffHunk": "@@ -112,36 +111,18 @@\n         continue;\n       }\n \n-      // TODO: Review this logic", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyNzQ5NA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478727494", "bodyText": "Test bug fix: the old logic causes each job to accumulate the tasks assigned to the previous job.", "author": "NealSun96", "createdAt": "2020-08-27T22:20:30Z", "path": "helix-core/src/test/java/org/apache/helix/controller/stages/TestQuotaConstraintSkipWorkflowAssignment.java", "diffHunk": "@@ -51,12 +51,11 @@ public void beforeClass() throws Exception {\n   public void testQuotaConstraintSkipWorkflowAssignment() throws Exception {\n     ClusterEvent event = new ClusterEvent(ClusterEventType.Unknown);\n     WorkflowControllerDataProvider cache = new WorkflowControllerDataProvider(CLUSTER_NAME);\n-    JobConfig.Builder job = new JobConfig.Builder();\n-\n-    job.setJobCommandConfigMap(Collections.singletonMap(MockTask.JOB_DELAY, \"100000\"));\n     TaskDriver driver = new TaskDriver(_manager);\n     for (int i = 0; i < 10; i++) {\n       Workflow.Builder workflow = new Workflow.Builder(\"Workflow\" + i);\n+      JobConfig.Builder job = new JobConfig.Builder();", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODcyODUzNw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r478728537", "bodyText": "Test bug fix: if the job queue is deleted right after stopping, it is possible that current states are not dropped on the instances. This is because the RUNNING to STOPPED message may still be pending when STOPPED to DROPPED message is generated, meaning the latter message is not sent; however, during the next pipeline cycle the job queue may have been deleted already, so the STOPPED to DROPPED message is never generated again. Adding this check to make the test non-flaky.", "author": "NealSun96", "createdAt": "2020-08-27T22:23:24Z", "path": "helix-core/src/test/java/org/apache/helix/task/TestGetLastScheduledTaskExecInfo.java", "diffHunk": "@@ -75,6 +75,10 @@ public void testGetLastScheduledTaskExecInfo() throws Exception {\n \n     // Stop and delete the queue\n     _driver.stop(queueName);\n+    TestHelper.verify(() -> {", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NTM2Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480375367", "bodyText": "I think previously, when currentState exist and configs are missing, we were relying on this legacy code to remove the currentState (DROP the task). However, since you removed this part, how can we ensure that functionality?", "author": "alirezazamani", "createdAt": "2020-08-31T20:17:35Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java", "diffHunk": "@@ -110,117 +103,9 @@ private BestPossibleStateOutput compute(ClusterEvent event, Map<String, Resource\n       restOfResources.remove(jobName);\n     }\n \n-    // Current rest of resources including: only current state left over ones\n-    // Original resource map contains workflows + jobs + other invalid resources\n-    // After removing workflows + jobs, only leftover ones will go over old rebalance pipeline.\n-    for (Resource resource : restOfResources.values()) {", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM2MTU1Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r481361556", "bodyText": "Added new logic to drop task resources without configs.", "author": "NealSun96", "createdAt": "2020-09-01T18:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NTM2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "971e99b6375518b0541392b392d6d1cc74ffef0b", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\nindex 0d36ad1dc..05289749b 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\n\n@@ -103,6 +104,14 @@ public class TaskSchedulingStage extends AbstractBaseStage {\n       restOfResources.remove(jobName);\n     }\n \n+    Map<String, Resource> taskResourcesToDrop =\n+        event.getAttribute(AttributeName.TASK_RESOURCES_TO_DROP.name());\n+    for (String resourceName : taskResourcesToDrop.keySet()) {\n+      ResourceAssignment emptyAssignment =\n+          _workflowDispatcher.buildEmptyAssignment(resourceName, currentStateOutput);\n+      _workflowDispatcher.updateBestPossibleStateOutput(resourceName, emptyAssignment, output);\n+    }\n+\n     return output;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NjA4OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480376089", "bodyText": "Maybe you can add comment for onDemand rebalances and point out why you add this line? Something like making sure next pipeline runs and context get updated maybe?", "author": "alirezazamani", "createdAt": "2020-08-31T20:19:05Z", "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "diffHunk": "@@ -518,7 +519,7 @@ protected void handleJobTimeout(JobContext jobCtx, WorkflowContext workflowCtx,\n     }\n     _clusterStatusMonitor.updateJobCounters(jobCfg, TaskState.TIMED_OUT);\n     _rebalanceScheduler.removeScheduledRebalance(jobResource);\n-    TaskUtil.cleanupJobIdealStateExtView(_manager.getHelixDataAccessor(), jobResource);\n+    RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\nindex 089fd2589..add9f27e7 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\n\n@@ -519,6 +519,7 @@ public abstract class AbstractTaskDispatcher {\n     }\n     _clusterStatusMonitor.updateJobCounters(jobCfg, TaskState.TIMED_OUT);\n     _rebalanceScheduler.removeScheduledRebalance(jobResource);\n+    // New pipeline trigger for workflow status update\n     RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NjgxMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480376812", "bodyText": "I am assuming this is not related to this PR? Anyways it is fine to have this comment, I just want to make sure I understand it correctly.", "author": "alirezazamani", "createdAt": "2020-08-31T20:20:27Z", "path": "helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java", "diffHunk": "@@ -85,15 +86,15 @@ public ResourceAssignment processJobStatusUpdateAndAssignment(String jobName,\n     // completed)\n     TaskState workflowState = workflowCtx.getWorkflowState();\n     TaskState jobState = workflowCtx.getJobState(jobName);\n-    // The job is already in a final state (completed/failed).\n+    // Do not include workflowState == TIMED_OUT here, as later logic needs to handle this case", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM4NzA2MQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480387061", "bodyText": "No it's not related to this PR. I added it as I realized why we shouldn't have TIMED_OUT here, and other devs should know too.", "author": "NealSun96", "createdAt": "2020-08-31T20:41:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NjgxMg=="}], "type": "inlineReview", "revised_code": {"commit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\nindex d92a440f1..b9c8f8224 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\n\n@@ -94,6 +94,7 @@ public class JobDispatcher extends AbstractTaskDispatcher {\n           \"Workflow %s or job %s is already in final state, workflow state (%s), job state (%s), clean up job IS.\",\n           workflowResource, jobName, workflowState, jobState));\n       finishJobInRuntimeJobDag(_dataProvider.getTaskDataCache(), workflowResource, jobName);\n+      // New pipeline trigger for workflow status update\n       RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);\n       _rebalanceScheduler.removeScheduledRebalance(jobName);\n       return buildEmptyAssignment(jobName, currStateOutput);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3ODg2OA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480378868", "bodyText": "Can we keep TaskDriver to clean up IS for a while? What would happen to the workflows/jobs that are running if we switch to new controller? Are these IS are getting deleted anyways? What do you think?", "author": "alirezazamani", "createdAt": "2020-08-31T20:24:30Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java", "diffHunk": "@@ -746,13 +705,11 @@ public void deleteAndWaitForCompletion(String workflow, long timeout)\n     BaseDataAccessor baseDataAccessor = _accessor.getBaseDataAccessor();\n     PropertyKey.Builder keyBuilder = _accessor.keyBuilder();\n \n-    String idealStatePath = keyBuilder.idealStates(workflow).getPath();\n     String workflowConfigPath = keyBuilder.resourceConfig(workflow).getPath();\n     String workflowContextPath = keyBuilder.workflowContext(workflow).getPath();\n \n     while (System.currentTimeMillis() <= endTime) {\n-      if (baseDataAccessor.exists(idealStatePath, AccessOption.PERSISTENT)\n-          || baseDataAccessor.exists(workflowConfigPath, AccessOption.PERSISTENT)\n+      if (baseDataAccessor.exists(workflowConfigPath, AccessOption.PERSISTENT)", "originalCommit": "6bb6c0f755800fabbe0ca33730febc386259f0e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM5MzY2Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r480393666", "bodyText": "So this section you commented on is only used for testing purpose, as far as I know.\nHowever, you raised a good point here:\n\nWorkflows relying on the current pipeline logic should be fine during the switch, because they are guaranteed to have workflow configs.\nWorkflows relying on the old pipeline logic (no config) wouldn't be managed by the controller after this change. Is that a concern?\n\nIn general, keeping the IS clean up has only one advantage, which is to clean up the leftover IS from pre-existing workflows. However I don't think that is an huge issue.", "author": "NealSun96", "createdAt": "2020-08-31T20:55:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3ODg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5OTY2NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r482599665", "bodyText": "@alirezazamani Could you take another look at this?", "author": "NealSun96", "createdAt": "2020-09-02T23:33:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3ODg2OA=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\nindex 1f45803cb..d463cecdd 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\n\n@@ -705,11 +707,13 @@ public class TaskDriver {\n     BaseDataAccessor baseDataAccessor = _accessor.getBaseDataAccessor();\n     PropertyKey.Builder keyBuilder = _accessor.keyBuilder();\n \n+    String idealStatePath = keyBuilder.idealStates(workflow).getPath();\n     String workflowConfigPath = keyBuilder.resourceConfig(workflow).getPath();\n     String workflowContextPath = keyBuilder.workflowContext(workflow).getPath();\n \n     while (System.currentTimeMillis() <= endTime) {\n-      if (baseDataAccessor.exists(workflowConfigPath, AccessOption.PERSISTENT)\n+      if (baseDataAccessor.exists(idealStatePath, AccessOption.PERSISTENT)\n+          || baseDataAccessor.exists(workflowConfigPath, AccessOption.PERSISTENT)\n           || baseDataAccessor.exists(workflowContextPath, AccessOption.PERSISTENT)) {\n         Thread.sleep(1000);\n       } else {\n"}}, {"oid": "971e99b6375518b0541392b392d6d1cc74ffef0b", "url": "https://github.com/apache/helix/commit/971e99b6375518b0541392b392d6d1cc74ffef0b", "message": "Stale CurrentState removal", "committedDate": "2020-09-01T05:45:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM1ODc5MA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r481358790", "bodyText": "Do we need this? We already based on all Workflows to do the assignment. Originally have this is for backward compatible change.", "author": "junkaixue", "createdAt": "2020-09-01T18:51:29Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {", "originalCommit": "971e99b6375518b0541392b392d6d1cc74ffef0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM2NzQ1Mg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r481367452", "bodyText": "This logic is how we read WorkflowConfig and JobConfig to create resources in the pipeline. After removing IdealStates this is the only source for workflow resources.", "author": "NealSun96", "createdAt": "2020-09-01T19:02:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM1ODc5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExMTM5Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r485111397", "bodyText": "No. We should not change it here but in TaskSchedulingStage. We do not need this specific process to select workflows. All we need is to get WorkflowConfig list in Cache at TaskSchedulingStage and loop it. These operations are unnecessary.", "author": "junkaixue", "createdAt": "2020-09-08T18:20:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM1ODc5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExNDQ0OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r485114449", "bodyText": "I think we need it here because of currentState computation stage. If we skip the resources here, we will miss the pending messages and currentStates. This can cause issue for TaskScheduling Stage.\n@NealSun96 could you please confirm it. Thanks.", "author": "alirezazamani", "createdAt": "2020-09-08T18:25:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM1ODc5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE0MjA1Mg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r485142052", "bodyText": "@dasahcc I believe this has been resolved in our offline meeting - we still need to rely on resourcesMap at this moment as @alirezazamani said.", "author": "NealSun96", "createdAt": "2020-09-08T19:18:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM1ODc5MA=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex e6e2ae28a..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjIxMjAwMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r482212002", "bodyText": "Can remind me why scheduleSignleJob is removed? We already schedule the job in other places?", "author": "alirezazamani", "createdAt": "2020-09-02T16:42:09Z", "path": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java", "diffHunk": "@@ -290,7 +297,6 @@ private void scheduleJobs(String workflow, WorkflowConfig workflowCfg,\n         // Time is not ready. Set a trigger and update the start time.\n         // Check if the job is ready to be executed.\n         if (System.currentTimeMillis() >= workflowCtx.getJobStartTime(job)) {\n-          scheduleSingleJob(job, jobConfig);", "originalCommit": "971e99b6375518b0541392b392d6d1cc74ffef0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI0OTkyNQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r482249925", "bodyText": "The only line that was kept in scheduleSingleJob() was the line about creating job context, however, that is already done in processJob. You could check my comment in scheduleSingleJob.", "author": "NealSun96", "createdAt": "2020-09-02T17:38:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjIxMjAwMg=="}], "type": "inlineReview", "revised_code": null}, {"oid": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "url": "https://github.com/apache/helix/commit/809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "message": "Added current state removal test and removed old test", "committedDate": "2020-09-02T22:51:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNTI2Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483225266", "bodyText": "Does this need to be a LinkedHashMap?", "author": "narendly", "createdAt": "2020-09-03T20:08:00Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -59,6 +62,7 @@ public void process(ClusterEvent event) throws Exception {\n \n     Map<String, Resource> resourceMap = new LinkedHashMap<>();\n     Map<String, Resource> resourceToRebalance = new LinkedHashMap<>();\n+    Map<String, Resource> taskResourcesToDrop = new LinkedHashMap<>();", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI1MzYzNg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483253636", "bodyText": "Good catch, probably not.", "author": "NealSun96", "createdAt": "2020-09-03T21:05:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNTI2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -62,7 +63,7 @@ public class ResourceComputationStage extends AbstractBaseStage {\n \n     Map<String, Resource> resourceMap = new LinkedHashMap<>();\n     Map<String, Resource> resourceToRebalance = new LinkedHashMap<>();\n-    Map<String, Resource> taskResourcesToDrop = new LinkedHashMap<>();\n+    Map<String, Resource> taskResourcesToDrop = new HashMap<>();\n \n     boolean isTaskCache = cache instanceof WorkflowControllerDataProvider;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNjk5Mg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483226992", "bodyText": "What does this do? addPartition(resourceName, resourceName, resourceMap);\n\nWhy are we doing an addPartition for a workflow?\nWhy are we putting resourceName twice?", "author": "narendly", "createdAt": "2020-09-03T20:11:26Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = workflowConfigEntry.getKey();\n+        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        addPartition(resourceName, resourceName, resourceMap);", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDAyODQ0Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r484028447", "bodyText": "This is mimicking the behavior of IdealState-based resource computation: when Workflow configs are created, their MapFields contains their own workflow names (1 field), which will be added as a partition.", "author": "NealSun96", "createdAt": "2020-09-06T06:28:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNjk5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNzI4MA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483227280", "bodyText": "Could this whole block be further refactored into a private method for readability? It would be helpful to add a JavaDoc as well.", "author": "narendly", "createdAt": "2020-09-03T20:12:02Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = workflowConfigEntry.getKey();\n+        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        addPartition(resourceName, resourceName, resourceMap);\n+      }\n+\n+      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+          .entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = jobConfigEntry.getKey();\n+        JobConfig jobConfig = jobConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        int numPartitions = jobConfig.getTaskConfigMap().size();\n+        if (numPartitions == 0 && idealStates != null) {\n+          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n+          if (targetIs == null) {\n+            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n+          } else {\n+            numPartitions = targetIs.getPartitionSet().size();\n+          }\n+        }\n+        for (int i = 0; i < numPartitions; i++) {\n+          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n+        }\n+      }\n+    }", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMTg5OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483231899", "bodyText": "So it seems that all WorkflowConfigs and JobConfigs are being added to both resourceMap and resourceToRebalance.\nIf my understanding of the pipeline is up-to-date, the reason we have two different maps is for the resource pipeline to filter out TASK resources and save them into resourceToRebalance.\nSo\n\nresourceMap: all resources\nresourceToRebalance: all resources - TASK resources\n\nNow, for the task pipeline, do we need to keep both maps? It seems that you're doing the filtering by populating things from ResourceConfigs only + currentStates to resourceToRebalance. With that said, what's the point of populating/keeping resourceMap? Does resourceMap still contain ALL resources for the task pipeline as well?", "author": "narendly", "createdAt": "2020-09-03T20:20:20Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -185,4 +232,21 @@ private void addPartition(String partition, String resourceName, Map<String, Res\n     resource.addPartition(partition);\n \n   }\n+\n+  private void addResourceConfigToResourceMap(String resourceName, ResourceConfig resourceConfig,", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3MzUwMA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483273500", "bodyText": "This PR doesn't change any of the map populating behavior: if a workflow/job was added to both maps in the past (based on IS), now they are added to both maps based on configs. With that said, your assessment on resourceToRebalance isn't entirely accurate: when the pipeline is for tasks, resourceToRebalance contains all the task resources as well. Edit: the original comment is referring to the resource pipeline and is correct.\nThe reason why we have both maps is because of the usages in other stages. For example, in CurrentStateComputationStage, task resources need to be present in both maps. There's definitely room for improvement in this aspect, but that would perhaps be in another PR.", "author": "NealSun96", "createdAt": "2020-09-03T21:52:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMTg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NTMzNQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483275335", "bodyText": "With that said, your assessment on resourceToRebalance isn't entirely accurate: when the pipeline is for tasks, resourceToRebalance contains all the task resources as well.\n\nCould you pinpoint what's amiss here? Do you mean to say that for the resource pipeline, resourceToRebalance also contains task resources? For the task pipeline, should resourceMap contain all resources and resourceToRebalance contain only task resources?", "author": "narendly", "createdAt": "2020-09-03T21:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMTg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzOTQ0MA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483839440", "bodyText": "I see that I had a bit misunderstanding on your original message: you're right that in the resource pipeline, resourceToRebalance doesn't contain task resources; in the task pipeline, resourceToRebalance only contains task resources. This behavior remains the same after IS removal (resourceMap contains all resources).", "author": "NealSun96", "createdAt": "2020-09-04T20:52:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMTg5OQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMjU0NA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483232544", "bodyText": "Nit: the resource could \"have been created\" based on IS", "author": "narendly", "createdAt": "2020-09-03T20:21:08Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = workflowConfigEntry.getKey();\n+        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        addPartition(resourceName, resourceName, resourceMap);\n+      }\n+\n+      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+          .entrySet()) {\n+        // always overwrite, because the resource could be created by IS", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzMjkxNw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483232917", "bodyText": "Nit: the resource could \"have been created\" based on IS? Since we aren't doing IS-based task resource creation anymore.", "author": "narendly", "createdAt": "2020-09-03T20:21:34Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNDQwMQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483234401", "bodyText": "Nit: could we add some comments here to make it clear that we're doing this for targeted jobs?", "author": "narendly", "createdAt": "2020-09-03T20:24:21Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = workflowConfigEntry.getKey();\n+        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        addPartition(resourceName, resourceName, resourceMap);\n+      }\n+\n+      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+          .entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = jobConfigEntry.getKey();\n+        JobConfig jobConfig = jobConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        int numPartitions = jobConfig.getTaskConfigMap().size();\n+        if (numPartitions == 0 && idealStates != null) {\n+          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n+          if (targetIs == null) {\n+            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n+          } else {\n+            numPartitions = targetIs.getPartitionSet().size();\n+          }\n+        }", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNDU1Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483234556", "bodyText": "Probably more helpful if you included the name of the target resource.", "author": "narendly", "createdAt": "2020-09-03T20:24:42Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +101,43 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+          .getWorkflowConfigMap().entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = workflowConfigEntry.getKey();\n+        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        addPartition(resourceName, resourceName, resourceMap);\n+      }\n+\n+      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+          .entrySet()) {\n+        // always overwrite, because the resource could be created by IS\n+        String resourceName = jobConfigEntry.getKey();\n+        JobConfig jobConfig = jobConfigEntry.getValue();\n+        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n+            resourceMap, resourceToRebalance);\n+        int numPartitions = jobConfig.getTaskConfigMap().size();\n+        if (numPartitions == 0 && idealStates != null) {\n+          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n+          if (targetIs == null) {\n+            LOG.warn(\"Target resource does not exist for job \" + resourceName);", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..d43657a39 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -106,36 +107,8 @@ public class ResourceComputationStage extends AbstractBaseStage {\n     if (isTaskCache) {\n       WorkflowControllerDataProvider taskDataCache =\n           event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n-          .getWorkflowConfigMap().entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = workflowConfigEntry.getKey();\n-        WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, workflowConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        addPartition(resourceName, resourceName, resourceMap);\n-      }\n-\n-      for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n-          .entrySet()) {\n-        // always overwrite, because the resource could be created by IS\n-        String resourceName = jobConfigEntry.getKey();\n-        JobConfig jobConfig = jobConfigEntry.getValue();\n-        addResourceConfigToResourceMap(resourceName, jobConfig, cache.getClusterConfig(),\n-            resourceMap, resourceToRebalance);\n-        int numPartitions = jobConfig.getTaskConfigMap().size();\n-        if (numPartitions == 0 && idealStates != null) {\n-          IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n-          if (targetIs == null) {\n-            LOG.warn(\"Target resource does not exist for job \" + resourceName);\n-          } else {\n-            numPartitions = targetIs.getPartitionSet().size();\n-          }\n-        }\n-        for (int i = 0; i < numPartitions; i++) {\n-          addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n-        }\n-      }\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n     }\n \n     // It's important to get partitions from CurrentState as well since the\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNTE2MQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483235161", "bodyText": "What if the task's state is IN_PROGRESS or in a non-terminal state?", "author": "narendly", "createdAt": "2020-09-03T20:25:52Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -130,11 +170,15 @@ public void process(ClusterEvent event) throws Exception {\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (resource.getStateModelDefRef() == null && !isTaskCache\n-                || resource.getStateModelDefRef() != null && (\n-                resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME) && isTaskCache\n-                    || !resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)\n-                    && !isTaskCache)) {\n+            if (!isTaskCache && (resource.getStateModelDefRef() == null\n+                || !TaskConstants.STATE_MODEL_NAME.equals(resource.getStateModelDefRef()))) {\n+              resourceToRebalance.put(resourceName, resource);\n+            }\n+\n+            if (isTaskCache && TaskConstants.STATE_MODEL_NAME\n+                .equals(resource.getStateModelDefRef())) {\n+              // If a task current state exists without configs, it needs to be cleaned up\n+              taskResourcesToDrop.put(resourceName, resource);", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3MTMzMA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483271330", "bodyText": "It will get dropped. This is not a newly introduced logic: in the old way before this PR, any job that doesn't have corresponding configs will be assigned DROPPED.", "author": "NealSun96", "createdAt": "2020-09-03T21:46:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNTE2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 2118fe395..89da58b51 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -164,21 +205,15 @@ public class ResourceComputationStage extends AbstractBaseStage {\n \n           // don't overwrite ideal state settings\n           if (!resourceMap.containsKey(resourceName)) {\n-            addResource(resourceName, resourceMap);\n-            Resource resource = resourceMap.get(resourceName);\n+            Resource resource = new Resource(resourceName);\n             resource.setStateModelDefRef(currentState.getStateModelDefRef());\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (!isTaskCache && (resource.getStateModelDefRef() == null\n-                || !TaskConstants.STATE_MODEL_NAME.equals(resource.getStateModelDefRef()))) {\n-              resourceToRebalance.put(resourceName, resource);\n-            }\n-\n-            if (isTaskCache && TaskConstants.STATE_MODEL_NAME\n+            if (!isTaskCache && !TaskConstants.STATE_MODEL_NAME\n+                .equals(resource.getStateModelDefRef())\n+                || isTaskCache && TaskConstants.STATE_MODEL_NAME\n                 .equals(resource.getStateModelDefRef())) {\n-              // If a task current state exists without configs, it needs to be cleaned up\n-              taskResourcesToDrop.put(resourceName, resource);\n               resourceToRebalance.put(resourceName, resource);\n             }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNjI2OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483236269", "bodyText": "Should we keep this for backward-compatibility? For legacy or existing workflows/jobs, how will their IdealStates be removed? Who will remove them?", "author": "narendly", "createdAt": "2020-09-03T20:28:02Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskDriver.java", "diffHunk": "@@ -762,9 +719,6 @@ public void deleteAndWaitForCompletion(String workflow, long timeout)\n \n     // Deletion failed: check which step of deletion failed to complete and create an error message\n     StringBuilder failed = new StringBuilder();\n-    if (baseDataAccessor.exists(idealStatePath, AccessOption.PERSISTENT)) {\n-      failed.append(\"IdealState \");\n-    }", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NTI2MQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483275261", "bodyText": "As @alirezazamani has also mentioned, I suppose we should keep this behavior for now. I will add a comment noting that this should be removed later.", "author": "NealSun96", "createdAt": "2020-09-03T21:56:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNjI2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\nindex 1f45803cb..d463cecdd 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/TaskDriver.java\n\n@@ -719,6 +723,9 @@ public class TaskDriver {\n \n     // Deletion failed: check which step of deletion failed to complete and create an error message\n     StringBuilder failed = new StringBuilder();\n+    if (baseDataAccessor.exists(idealStatePath, AccessOption.PERSISTENT)) {\n+      failed.append(\"IdealState \");\n+    }\n     if (baseDataAccessor.exists(workflowConfigPath, AccessOption.PERSISTENT)) {\n       failed.append(\"WorkflowConfig \");\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNjY2Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483236666", "bodyText": "I wonder for backward-compatibility, if we should leave this in for the time being and just mark them as deprecated. For the existing workload?", "author": "narendly", "createdAt": "2020-09-03T20:28:55Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -594,58 +594,6 @@ public static PropertyKey getWorkflowConfigKey(final HelixDataAccessor accessor,\n     return accessor.keyBuilder().resourceConfig(workflow);\n   }\n \n-  /**\n-   * Cleans up IdealState and external view associated with a job.\n-   * @param accessor\n-   * @param job\n-   * @return True if remove success, otherwise false\n-   */\n-  protected static boolean cleanupJobIdealStateExtView(final HelixDataAccessor accessor,\n-      String job) {\n-    return cleanupIdealStateExtView(accessor, job);\n-  }", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NzA0NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483277045", "bodyText": "Ditto above, I'll leave them in.", "author": "NealSun96", "createdAt": "2020-09-03T22:01:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNjY2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java b/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java\nindex 58c775a9d..52b81ce8a 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/TaskUtil.java\n\n@@ -594,6 +594,64 @@ public class TaskUtil {\n     return accessor.keyBuilder().resourceConfig(workflow);\n   }\n \n+  /**\n+   * TODO: Task Framework no longer uses IdealState; this is left in for backward compability\n+   * Cleans up IdealState and external view associated with a job.\n+   * @param accessor\n+   * @param job\n+   * @return True if remove success, otherwise false\n+   */\n+  @Deprecated\n+  protected static boolean cleanupJobIdealStateExtView(final HelixDataAccessor accessor,\n+      String job) {\n+    return cleanupIdealStateExtView(accessor, job);\n+  }\n+\n+  /**\n+   * TODO: Task Framework no longer uses IdealState; this is left in for backward compability\n+   * Cleans up IdealState and external view associated with a workflow.\n+   * @param accessor\n+   * @param workflow\n+   * @return True if remove success, otherwise false\n+   */\n+  @Deprecated\n+  protected static boolean cleanupWorkflowIdealStateExtView(final HelixDataAccessor accessor,\n+      String workflow) {\n+    return cleanupIdealStateExtView(accessor, workflow);\n+  }\n+\n+  /**\n+   * TODO: Task Framework no longer uses IdealState; this is left in for backward compability\n+   * Cleans up IdealState and external view associated with a job/workflow resource.\n+   */\n+  @Deprecated\n+  private static boolean cleanupIdealStateExtView(final HelixDataAccessor accessor,\n+      String workflowJobResource) {\n+    boolean success = true;\n+    PropertyKey isKey = accessor.keyBuilder().idealStates(workflowJobResource);\n+    if (accessor.getPropertyStat(isKey) != null) {\n+      if (!accessor.removeProperty(isKey)) {\n+        LOG.warn(String.format(\n+            \"Error occurred while trying to remove IdealState for %s. Failed to remove node %s.\",\n+            workflowJobResource, isKey));\n+        success = false;\n+      }\n+    }\n+\n+    // Delete external view\n+    PropertyKey evKey = accessor.keyBuilder().externalView(workflowJobResource);\n+    if (accessor.getPropertyStat(evKey) != null) {\n+      if (!accessor.removeProperty(evKey)) {\n+        LOG.warn(String.format(\n+            \"Error occurred while trying to remove ExternalView of resource %s. Failed to remove node %s.\",\n+            workflowJobResource, evKey));\n+        success = false;\n+      }\n+    }\n+\n+    return success;\n+  }\n+\n   /**\n    * Remove a workflow and all jobs for the workflow. This removes the workflow config, idealstate,\n    * externalview and workflow contexts associated with this workflow, and all jobs information,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNzUxMQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483237511", "bodyText": "Yay! :)", "author": "narendly", "createdAt": "2020-09-03T20:30:38Z", "path": "helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java", "diffHunk": "@@ -322,64 +328,6 @@ private void processJob(String job, CurrentStateOutput currentStateOutput,\n     }\n   }\n \n-  /**\n-   * Posts new job to cluster\n-   */\n-  private void scheduleSingleJob(String jobResource, JobConfig jobConfig) {", "originalCommit": "809ea07955c1dfaba7c3f12cd56a8a090b5d33e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3ODEzMA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483278130", "bodyText": ":)", "author": "NealSun96", "createdAt": "2020-09-03T22:04:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNzUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\nindex b358adb25..68a5be52b 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/WorkflowDispatcher.java\n\n@@ -328,6 +328,20 @@ public class WorkflowDispatcher extends AbstractTaskDispatcher {\n     }\n   }\n \n+  /**\n+   * Jobs that are missing corresponding JobConfigs or WorkflowConfigs or WorkflowContexts need to\n+   * be dropped\n+   */\n+  public void processJobForDrop(String resourceName, CurrentStateOutput currentStateOutput,\n+      BestPossibleStateOutput bestPossibleStateOutput) {\n+    JobConfig jobConfig = _clusterDataCache.getJobConfig(resourceName);\n+    if (jobConfig == null || _clusterDataCache.getWorkflowConfig(jobConfig.getWorkflow()) == null\n+        || _clusterDataCache.getWorkflowContext(jobConfig.getWorkflow()) == null) {\n+      ResourceAssignment emptyAssignment = buildEmptyAssignment(resourceName, currentStateOutput);\n+      updateBestPossibleStateOutput(resourceName, emptyAssignment, bestPossibleStateOutput);\n+    }\n+  }\n+\n   /**\n    * Check if a workflow is ready to schedule, and schedule a rebalance if it is not\n    * @param workflow the Helix resource associated with the workflow\n"}}, {"oid": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "url": "https://github.com/apache/helix/commit/191b8e6a44a6fd8885bb13c982d73d9a72618013", "message": "Address comments", "committedDate": "2020-09-04T00:11:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM0NzM4OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483347389", "bodyText": "Humm... this condition was not readable, even the new one is confusing. Could you please add a comment here for future readers?", "author": "jiajunwang", "createdAt": "2020-09-04T02:14:20Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -74,9 +79,8 @@ public void process(ClusterEvent event) throws Exception {\n               cache.getResourceConfig(resourceName));\n           resourceMap.put(resourceName, resource);\n \n-          if (!idealState.isValid() && !isTaskCache\n-              || idealState.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME) && isTaskCache\n-              || !idealState.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME) && !isTaskCache) {\n+          if (!isTaskCache && (!idealState.isValid() || !idealState.getStateModelDefRef()", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM0NzQ5Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483347497", "bodyText": "I'm very curious why we need to rebalance an invalid IS node?", "author": "jiajunwang", "createdAt": "2020-09-04T02:14:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM0NzM4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MDc0Ng==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483840746", "bodyText": "I'll add a comment. I don't have an answer to that question unfortunately; for the scope of this PR I'll leave it untouched.", "author": "NealSun96", "createdAt": "2020-09-04T20:56:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM0NzM4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex d43657a39..89da58b51 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -59,19 +60,43 @@ public class ResourceComputationStage extends AbstractBaseStage {\n       throw new StageException(\"Missing attributes in event:\" + event + \". Requires DataCache\");\n     }\n \n-    Map<String, IdealState> idealStates = cache.getIdealStates();\n-\n     Map<String, Resource> resourceMap = new LinkedHashMap<>();\n     Map<String, Resource> resourceToRebalance = new LinkedHashMap<>();\n-    Map<String, Resource> taskResourcesToDrop = new HashMap<>();\n \n+    Map<String, IdealState> idealStates = cache.getIdealStates();\n     boolean isTaskCache = cache instanceof WorkflowControllerDataProvider;\n \n+    processIdealStates(cache, resourceMap, resourceToRebalance, idealStates, isTaskCache);\n+\n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n+    }\n+\n+    // It's important to get partitions from CurrentState as well since the\n+    // idealState might be removed.\n+    processCurrentStates(cache, resourceMap, resourceToRebalance, idealStates, isTaskCache);\n+\n+    event.addAttribute(AttributeName.RESOURCES.name(), resourceMap);\n+    event.addAttribute(AttributeName.RESOURCES_TO_REBALANCE.name(), resourceToRebalance);\n+  }\n+\n+  /*\n+   * Construct Resources based on IdealStates and add them to resource maps\n+   */\n+  private void processIdealStates(BaseControllerDataProvider cache,\n+      Map<String, Resource> resourceMap, Map<String, Resource> resourceToRebalance,\n+      Map<String, IdealState> idealStates, boolean isTaskCache) {\n     if (idealStates != null && idealStates.size() > 0) {\n       for (IdealState idealState : idealStates.values()) {\n         if (idealState == null) {\n           continue;\n         }\n+\n         Set<String> partitionSet = idealState.getPartitionSet();\n         String resourceName = idealState.getResourceName();\n         if (!resourceMap.containsKey(resourceName)) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM1ODUyNQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483358525", "bodyText": "Is it possible that we just check in the task dispatch stage to remove all the resources in the RESOURCES_TO_REBALANCE but with no ideal state?\nSo we don't need this attribute.", "author": "jiajunwang", "createdAt": "2020-09-04T03:00:46Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/AttributeName.java", "diffHunk": "@@ -22,6 +22,7 @@\n public enum AttributeName {\n   RESOURCES,\n   RESOURCES_TO_REBALANCE,\n+  TASK_RESOURCES_TO_DROP,", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MTE0NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483841145", "bodyText": "It's not about ideal state but rather configs. However with that said, I think you raised a good point; I can just check the cache. Let me explore in that direction. Thanks!", "author": "NealSun96", "createdAt": "2020-09-04T20:58:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM1ODUyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/AttributeName.java b/helix-core/src/main/java/org/apache/helix/controller/stages/AttributeName.java\nindex 41ccbfb19..9a0bbb668 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/AttributeName.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/AttributeName.java\n\n@@ -22,7 +22,6 @@ package org.apache.helix.controller.stages;\n public enum AttributeName {\n   RESOURCES,\n   RESOURCES_TO_REBALANCE,\n-  TASK_RESOURCES_TO_DROP,\n   BEST_POSSIBLE_STATE,\n   CURRENT_STATE,\n   CUSTOMIZED_STATE,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDMyOA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483360328", "bodyText": "It's hard to comment with github review, but with your change, I think the whole logic is cleaner. It would either read IdealState for regular resources or read Task config for task resources.\nIn this case, could you please consider the following changes,\n\nCreate a TaskResourceComputationStage, because we the reuse logic has been reduced quite a lot. It is no longer reasonable to put all logic in one class.\nIf another class is too much, we should at least make the workflow clean to fit the following structure:\nif (taskCache) {\n// process TF Resource Objects...\n} else {\n// process Regular Resource Objects...\n}\n// Read the current state to backfill any resources that need to be removed.", "author": "jiajunwang", "createdAt": "2020-09-04T03:08:54Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +102,15 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MzM4NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483843385", "bodyText": "One problem is that the task pipeline still needs the regular resource objects due to targeted jobs. Therefore the task pipeline resource-computation needs everything from resource pipeline resource-computation; it makes sense for task pipeline to be \"resource pipeline resource computation + reading configs\", which is the current logic.", "author": "NealSun96", "createdAt": "2020-09-04T21:04:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDMyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjU0NTIyOA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486545228", "bodyText": "Then let's re-org the logic a little bit. So they are not interleaved.", "author": "jiajunwang", "createdAt": "2020-09-10T18:21:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDMyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjU2MTYwMw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486561603", "bodyText": "I wouldn't say it's interleaved, it's just how the logic should look. With what you proposed, it looks like:\nif (taskCache) {\n  processIdealStates();\n  processWorkflowConfigs();\n  processJobConfigs();\n} else {\n  processIdealStates();\n}\nbackfillCurrentStates();\n\nIf we take out the common factor, we have:\nprocessIdealStates();\nif (taskCache) {\n  processWorkflowConfigs();\n  processJobConfigs();\n}\nbackfillCurrentStates();\n\nwhich is exactly what it is now. I think it's clear enough (especially given that we may remove the if block altogether later).", "author": "NealSun96", "createdAt": "2020-09-10T18:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDMyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc4Mzk0OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486783949", "bodyText": "Yeah, that's not too bad.\nI was thinking if the RESOURCES attribute is still necessary. But might be. For example, for the targeted jobs. So let's keep it for now.", "author": "jiajunwang", "createdAt": "2020-09-11T05:36:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDMyOA=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex d43657a39..89da58b51 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -101,18 +128,59 @@ public class ResourceComputationStage extends AbstractBaseStage {\n         }\n       }\n     }\n+  }\n \n-    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n-    // use IdealState\n-    if (isTaskCache) {\n-      WorkflowControllerDataProvider taskDataCache =\n-          event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n-      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n+  /*\n+   * Construct Resources based on WorkflowConfigs and add them to the two resource maps\n+   */\n+  private void processWorkflowConfigs(WorkflowControllerDataProvider taskDataCache, Map<String, Resource> resourceMap,\n+      Map<String, Resource> resourceToRebalance) {\n+    for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+        .getWorkflowConfigMap().entrySet()) {\n+      // The resource could have been created by IS - always overwrite with config values\n+      String resourceName = workflowConfigEntry.getKey();\n+      WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+      addResourceConfigToResourceMap(resourceName, workflowConfig, taskDataCache.getClusterConfig(),\n+          resourceMap, resourceToRebalance);\n+      addPartition(resourceName, resourceName, resourceMap);\n     }\n+  }\n \n-    // It's important to get partitions from CurrentState as well since the\n-    // idealState might be removed.\n+  /*\n+   * Construct Resources based on JobConfigs and add them to the two resource maps\n+   */\n+  private void processJobConfigs(WorkflowControllerDataProvider taskDataCache, Map<String, Resource> resourceMap,\n+      Map<String, Resource> resourceToRebalance, Map<String, IdealState> idealStates) {\n+    for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+        .entrySet()) {\n+      // always overwrite, because the resource could be created by IS\n+      String resourceName = jobConfigEntry.getKey();\n+      JobConfig jobConfig = jobConfigEntry.getValue();\n+      addResourceConfigToResourceMap(resourceName, jobConfig, taskDataCache.getClusterConfig(),\n+          resourceMap, resourceToRebalance);\n+      int numPartitions = jobConfig.getTaskConfigMap().size();\n+      // If there is no task config, this is a targeted job. We get task counts based on target\n+      // resource IdealState\n+      if (numPartitions == 0 && idealStates != null) {\n+        IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n+        if (targetIs == null) {\n+          LOG.warn(\"Target resource \" + jobConfig.getTargetResource() + \" does not exist for job \" + resourceName);\n+        } else {\n+          numPartitions = targetIs.getPartitionSet().size();\n+        }\n+      }\n+      for (int i = 0; i < numPartitions; i++) {\n+        addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n+      }\n+    }\n+  }\n+\n+  /*\n+   * Construct Resources based on CurrentStates and add them to resource maps\n+   */\n+  private void processCurrentStates(BaseControllerDataProvider cache,\n+      Map<String, Resource> resourceMap, Map<String, Resource> resourceToRebalance,\n+      Map<String, IdealState> idealStates, boolean isTaskCache) throws StageException {\n     Map<String, LiveInstance> availableInstances = cache.getLiveInstances();\n \n     if (availableInstances != null && availableInstances.size() > 0) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDUwNA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483360504", "bodyText": "Suggest moving the following logic of processing CS to a separate method.", "author": "jiajunwang", "createdAt": "2020-09-04T03:09:43Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -98,6 +102,15 @@ public void process(ClusterEvent event) throws Exception {\n       }\n     }\n \n+    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n+    // use IdealState\n+    if (isTaskCache) {\n+      WorkflowControllerDataProvider taskDataCache =\n+          event.getAttribute(AttributeName.ControllerDataProvider.name());\n+      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n+      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n+    }\n+\n     // It's important to get partitions from CurrentState as well since the\n     // idealState might be removed.\n     Map<String, LiveInstance> availableInstances = cache.getLiveInstances();", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex d43657a39..89da58b51 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -101,18 +128,59 @@ public class ResourceComputationStage extends AbstractBaseStage {\n         }\n       }\n     }\n+  }\n \n-    // Add TaskFramework resources from workflow and job configs as Task Framework will no longer\n-    // use IdealState\n-    if (isTaskCache) {\n-      WorkflowControllerDataProvider taskDataCache =\n-          event.getAttribute(AttributeName.ControllerDataProvider.name());\n-      processWorkflowConfigs(taskDataCache, resourceMap, resourceToRebalance);\n-      processJobConfigs(taskDataCache, resourceMap, resourceToRebalance, idealStates);\n+  /*\n+   * Construct Resources based on WorkflowConfigs and add them to the two resource maps\n+   */\n+  private void processWorkflowConfigs(WorkflowControllerDataProvider taskDataCache, Map<String, Resource> resourceMap,\n+      Map<String, Resource> resourceToRebalance) {\n+    for (Map.Entry<String, WorkflowConfig> workflowConfigEntry : taskDataCache\n+        .getWorkflowConfigMap().entrySet()) {\n+      // The resource could have been created by IS - always overwrite with config values\n+      String resourceName = workflowConfigEntry.getKey();\n+      WorkflowConfig workflowConfig = workflowConfigEntry.getValue();\n+      addResourceConfigToResourceMap(resourceName, workflowConfig, taskDataCache.getClusterConfig(),\n+          resourceMap, resourceToRebalance);\n+      addPartition(resourceName, resourceName, resourceMap);\n     }\n+  }\n \n-    // It's important to get partitions from CurrentState as well since the\n-    // idealState might be removed.\n+  /*\n+   * Construct Resources based on JobConfigs and add them to the two resource maps\n+   */\n+  private void processJobConfigs(WorkflowControllerDataProvider taskDataCache, Map<String, Resource> resourceMap,\n+      Map<String, Resource> resourceToRebalance, Map<String, IdealState> idealStates) {\n+    for (Map.Entry<String, JobConfig> jobConfigEntry : taskDataCache.getJobConfigMap()\n+        .entrySet()) {\n+      // always overwrite, because the resource could be created by IS\n+      String resourceName = jobConfigEntry.getKey();\n+      JobConfig jobConfig = jobConfigEntry.getValue();\n+      addResourceConfigToResourceMap(resourceName, jobConfig, taskDataCache.getClusterConfig(),\n+          resourceMap, resourceToRebalance);\n+      int numPartitions = jobConfig.getTaskConfigMap().size();\n+      // If there is no task config, this is a targeted job. We get task counts based on target\n+      // resource IdealState\n+      if (numPartitions == 0 && idealStates != null) {\n+        IdealState targetIs = idealStates.get(jobConfig.getTargetResource());\n+        if (targetIs == null) {\n+          LOG.warn(\"Target resource \" + jobConfig.getTargetResource() + \" does not exist for job \" + resourceName);\n+        } else {\n+          numPartitions = targetIs.getPartitionSet().size();\n+        }\n+      }\n+      for (int i = 0; i < numPartitions; i++) {\n+        addPartition(resourceName + \"_\" + i, resourceName, resourceMap);\n+      }\n+    }\n+  }\n+\n+  /*\n+   * Construct Resources based on CurrentStates and add them to resource maps\n+   */\n+  private void processCurrentStates(BaseControllerDataProvider cache,\n+      Map<String, Resource> resourceMap, Map<String, Resource> resourceToRebalance,\n+      Map<String, IdealState> idealStates, boolean isTaskCache) throws StageException {\n     Map<String, LiveInstance> availableInstances = cache.getLiveInstances();\n \n     if (availableInstances != null && availableInstances.size() > 0) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDgzMQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483360831", "bodyText": "I think taskResourcesToDrop is not necessary since we should be able to tell in the dispatch stage.\nIt seems resourceToRebalance will be put anyway. So it seems to be (maybe) some redundant code.", "author": "jiajunwang", "createdAt": "2020-09-04T03:11:22Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -130,11 +143,15 @@ public void process(ClusterEvent event) throws Exception {\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (resource.getStateModelDefRef() == null && !isTaskCache\n-                || resource.getStateModelDefRef() != null && (\n-                resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME) && isTaskCache\n-                    || !resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)\n-                    && !isTaskCache)) {\n+            if (!isTaskCache && (resource.getStateModelDefRef() == null\n+                || !TaskConstants.STATE_MODEL_NAME.equals(resource.getStateModelDefRef()))) {\n+              resourceToRebalance.put(resourceName, resource);", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDAyNTg4OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r484025889", "bodyText": "It has been removed, thanks for the suggestion.\nWe still need an if statement: if not task pipeline and state model name is not TASK, or, if is task pipeline and state model name is TASK.", "author": "NealSun96", "createdAt": "2020-09-06T05:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MDgzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex d43657a39..89da58b51 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -137,21 +205,15 @@ public class ResourceComputationStage extends AbstractBaseStage {\n \n           // don't overwrite ideal state settings\n           if (!resourceMap.containsKey(resourceName)) {\n-            addResource(resourceName, resourceMap);\n-            Resource resource = resourceMap.get(resourceName);\n+            Resource resource = new Resource(resourceName);\n             resource.setStateModelDefRef(currentState.getStateModelDefRef());\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (!isTaskCache && (resource.getStateModelDefRef() == null\n-                || !TaskConstants.STATE_MODEL_NAME.equals(resource.getStateModelDefRef()))) {\n-              resourceToRebalance.put(resourceName, resource);\n-            }\n-\n-            if (isTaskCache && TaskConstants.STATE_MODEL_NAME\n+            if (!isTaskCache && !TaskConstants.STATE_MODEL_NAME\n+                .equals(resource.getStateModelDefRef())\n+                || isTaskCache && TaskConstants.STATE_MODEL_NAME\n                 .equals(resource.getStateModelDefRef())) {\n-              // If a task current state exists without configs, it needs to be cleaned up\n-              taskResourcesToDrop.put(resourceName, resource);\n               resourceToRebalance.put(resourceName, resource);\n             }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTQxNg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483361416", "bodyText": "I see much duplicate code here. Could you please check if we can use the same code for the regular resource addition?", "author": "jiajunwang", "createdAt": "2020-09-04T03:14:07Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -185,4 +250,21 @@ private void addPartition(String partition, String resourceName, Map<String, Res\n     resource.addPartition(partition);\n \n   }\n+\n+  private void addResourceConfigToResourceMap(String resourceName, ResourceConfig resourceConfig,\n+      ClusterConfig clusterConfig, Map<String, Resource> resourceMap,\n+      Map<String, Resource> resourceToRebalance) {\n+    Resource resource = new Resource(resourceName, clusterConfig, resourceConfig);\n+    resourceMap.put(resourceName, resource);", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0OTQ4OQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483849489", "bodyText": "Unfortunately, with the way IdealState and CurrentState are implemented, although they share similar methods and the same parent class, they cannot be generalized as the similar methods are implemented in the sub classes individually. The best I can do based on my knowledge is to refactor.", "author": "NealSun96", "createdAt": "2020-09-04T21:24:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc4Nzc1Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486787757", "bodyText": "Not a must, but we did add a IS to ResourceConfig conversion method. It is ResourceConfig.mergeIdealStateWithResourceConfig(). So in theory, you can keep only this method by converting the IS into ResourceConfig, then use this method to add to the resource map.\n\nThis helps to reduce duplicate code.\nResourceConfig is the one we are going to use in the near future. IS will be transformed for controller output only. So that logic will be replaced anyway.\n\nUp to you if you want to do it now or in the future. If in the future, please add a TODO here.", "author": "jiajunwang", "createdAt": "2020-09-11T05:49:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzE5NzcxMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r487197712", "bodyText": "That is interesting. However, the next step of Task Framework will lead to the removal of this section of ResourceComputationStage - it no longer needs to create Resources from WorkflowConfigs/JobConfigs. (Check here https://github.com/apache/helix/wiki/Task-Framework-IdealState-Dependency-Removal-Progression)\nI will put a TODO here in case the next step doesn't happen.", "author": "NealSun96", "createdAt": "2020-09-11T17:48:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIzNjg5NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r487236895", "bodyText": "Sure, that also makes sense.", "author": "jiajunwang", "createdAt": "2020-09-11T19:09:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTQxNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2Mzc1NQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483363755", "bodyText": "Can this logic be handled inside the workflow dispatcher just like the job dispatcher? The current code breaks workflow dispatcher OO design and lets the Stage class takes the responsibility of the dispatcher.", "author": "jiajunwang", "createdAt": "2020-09-04T03:23:58Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java", "diffHunk": "@@ -110,117 +104,17 @@ private BestPossibleStateOutput compute(ClusterEvent event, Map<String, Resource\n       restOfResources.remove(jobName);\n     }\n \n-    // Current rest of resources including: only current state left over ones\n-    // Original resource map contains workflows + jobs + other invalid resources\n-    // After removing workflows + jobs, only leftover ones will go over old rebalance pipeline.\n-    for (Resource resource : restOfResources.values()) {\n-      if (!computeResourceBestPossibleState(event, cache, currentStateOutput, resource, output)) {\n-        failureResources.add(resource.getResourceName());\n-        LogUtil.logWarn(logger, _eventId,\n-            \"Failed to calculate best possible states for \" + resource.getResourceName());\n-      }\n+    Map<String, Resource> taskResourcesToDrop =\n+        event.getAttribute(AttributeName.TASK_RESOURCES_TO_DROP.name());\n+    for (String resourceName : taskResourcesToDrop.keySet()) {\n+      ResourceAssignment emptyAssignment =\n+          _workflowDispatcher.buildEmptyAssignment(resourceName, currentStateOutput);\n+      _workflowDispatcher.updateBestPossibleStateOutput(resourceName, emptyAssignment, output);", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e611db7b2a201766572ce20c02490432a3f3f22d", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\nindex 05289749b..9746bf9ef 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/task/TaskSchedulingStage.java\n\n@@ -104,12 +104,12 @@ public class TaskSchedulingStage extends AbstractBaseStage {\n       restOfResources.remove(jobName);\n     }\n \n-    Map<String, Resource> taskResourcesToDrop =\n-        event.getAttribute(AttributeName.TASK_RESOURCES_TO_DROP.name());\n-    for (String resourceName : taskResourcesToDrop.keySet()) {\n-      ResourceAssignment emptyAssignment =\n-          _workflowDispatcher.buildEmptyAssignment(resourceName, currentStateOutput);\n-      _workflowDispatcher.updateBestPossibleStateOutput(resourceName, emptyAssignment, output);\n+    // Jobs that exist in current states but are missing corresponding JobConfigs or WorkflowConfigs\n+    // or WorkflowContexts need to be cleaned up. Note that restOfResources can only be jobs,\n+    // because workflow resources are created based on Configs only - workflows don't have\n+    // CurrentStates\n+    for (String resourceName : restOfResources.keySet()) {\n+      _workflowDispatcher.processJobForDrop(resourceName, currentStateOutput, output);\n     }\n \n     return output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NDUwNQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483364505", "bodyText": "nit, \"job status update\"?", "author": "jiajunwang", "createdAt": "2020-09-04T03:27:21Z", "path": "helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java", "diffHunk": "@@ -94,6 +95,8 @@ public ResourceAssignment processJobStatusUpdateAndAssignment(String jobName,\n           workflowResource, jobName, workflowState, jobState));\n       finishJobInRuntimeJobDag(_dataProvider.getTaskDataCache(), workflowResource, jobName);\n       TaskUtil.cleanupJobIdealStateExtView(_manager.getHelixDataAccessor(), jobName);\n+      // New pipeline trigger for workflow status update", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDAyNTc3MQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r484025771", "bodyText": "It's about how workflow needs another run to handle \"all jobs completed\", for example.", "author": "NealSun96", "createdAt": "2020-09-06T05:52:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NDUwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "24de07766e18a06d90639ac2a2f4c66527171725", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\nindex d043427d1..9a48339b3 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/JobDispatcher.java\n\n@@ -96,6 +96,7 @@ public class JobDispatcher extends AbstractTaskDispatcher {\n       finishJobInRuntimeJobDag(_dataProvider.getTaskDataCache(), workflowResource, jobName);\n       TaskUtil.cleanupJobIdealStateExtView(_manager.getHelixDataAccessor(), jobName);\n       // New pipeline trigger for workflow status update\n+      // TODO: Enhance the pipeline and remove this because this operation is expansive\n       RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);\n       _rebalanceScheduler.removeScheduledRebalance(jobName);\n       return buildEmptyAssignment(jobName, currStateOutput);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r483365939", "bodyText": "2 questions.\n\nI assume the IS change will trigger the pipeline. But obviously, if the TF logic says goodbye to IS, then this won't trigger the right pipeline anymore.\nIn this case, shall we just listen to the context change? Depends on onDemond pipeline is not a scalable solution in general.\n\nPlease correct me if I misunderstood the first point.", "author": "jiajunwang", "createdAt": "2020-09-04T03:33:32Z", "path": "helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java", "diffHunk": "@@ -519,6 +520,8 @@ protected void handleJobTimeout(JobContext jobCtx, WorkflowContext workflowCtx,\n     _clusterStatusMonitor.updateJobCounters(jobCfg, TaskState.TIMED_OUT);\n     _rebalanceScheduler.removeScheduledRebalance(jobResource);\n     TaskUtil.cleanupJobIdealStateExtView(_manager.getHelixDataAccessor(), jobResource);\n+    // New pipeline trigger for workflow status update\n+    RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);", "originalCommit": "191b8e6a44a6fd8885bb13c982d73d9a72618013", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDAyNzQ3Nw==", "url": "https://github.com/apache/helix/pull/1326#discussion_r484027477", "bodyText": "Your understanding is correct: that's why we need the on-demand trigger now without IS removal event.\nAbout the second point: these are the only places IS removal events are necessary to trigger rebalance. It doesn't need to scale up.\n@alirezazamani Could you chime in here on @jiajunwang 's proposal? I think context-based rebalance might be an overkill and introduce problems we are not ready to face. (Either way I don't think something like that should be tackled in this PR)", "author": "NealSun96", "createdAt": "2020-09-06T06:15:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3MzgwNA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r485073804", "bodyText": "I think this will be overkill as well and not necessary. Basically, I am looking the context as controller's output and reacting on output is not ideal from my prospective. Also, unlike regular resources, context/output changes are much more frequent in TF resources. So there will be many redundant pipeline runs and can cause other issue. In my opinion, we can stick to ondemand rebalancer for these corner cases.", "author": "alirezazamani", "createdAt": "2020-09-08T17:10:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc4ODkzMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486788932", "bodyText": "Then, can we add scheduleOnDemandPipeline into cleanupJobIdealStateExtView() ? Otherwise, cleanupJobIdealStateExtView is not a complete call that triggers the expected rebalance, right?\nIt also helps to simplify code, IMO.", "author": "jiajunwang", "createdAt": "2020-09-11T05:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIwMDQ0Mg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r487200442", "bodyText": "cleanupJobIdealStateExtView() is kept for backward-compatibility purpose and is marked as deprecated now; it will be removed on a later phase (it could trigger rebalance if the participant side is not updated, and it wouldn't trigger rebalance if the participant side is updated). I suppose we can put the on-demand rebalance in cleanupJobIdealStateExtView() now, and move it out when we delete cleanupJobIdealStateExtView(). Do you think that's necessary @jiajunwang ? Seems not to be too much difference.", "author": "NealSun96", "createdAt": "2020-09-11T17:54:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI1NTYwMQ==", "url": "https://github.com/apache/helix/pull/1326#discussion_r487255601", "bodyText": "As we discussed, please add a TODO there for the future change. For now, it is OK to be left here.", "author": "jiajunwang", "createdAt": "2020-09-11T19:46:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2NTkzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "24de07766e18a06d90639ac2a2f4c66527171725", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java b/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\nindex a654c1ca6..cd240b551 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/AbstractTaskDispatcher.java\n\n@@ -521,6 +521,7 @@ public abstract class AbstractTaskDispatcher {\n     _rebalanceScheduler.removeScheduledRebalance(jobResource);\n     TaskUtil.cleanupJobIdealStateExtView(_manager.getHelixDataAccessor(), jobResource);\n     // New pipeline trigger for workflow status update\n+    // TODO: Enhance the pipeline and remove this because this operation is expansive\n     RebalanceUtil.scheduleOnDemandPipeline(_manager.getClusterName(),0L,false);\n   }\n \n"}}, {"oid": "e611db7b2a201766572ce20c02490432a3f3f22d", "url": "https://github.com/apache/helix/commit/e611db7b2a201766572ce20c02490432a3f3f22d", "message": "Address more comments", "committedDate": "2020-09-04T22:36:09Z", "type": "commit"}, {"oid": "80b687f5f76dd6576ea7260a1eaf0b97a2051e17", "url": "https://github.com/apache/helix/commit/80b687f5f76dd6576ea7260a1eaf0b97a2051e17", "message": "Drop the negative delay rebalance fix", "committedDate": "2020-09-09T01:37:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc4NjM1NA==", "url": "https://github.com/apache/helix/pull/1326#discussion_r486786354", "bodyText": "How about \"isTaskCache == TaskConstants.STATE_MODEL_NAME.equals(resource.getStateModelDefRef())\"\nYou can comment that we are trying to match for 2 conditions:\n\nIf resource state model def is null, then we only proceed if it is a regular resource pipeline.\nIf resource state model def is not null, then we only proceed if the pipeline type matches the resource state model type.", "author": "jiajunwang", "createdAt": "2020-09-11T05:44:42Z", "path": "helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java", "diffHunk": "@@ -124,17 +205,15 @@ public void process(ClusterEvent event) throws Exception {\n \n           // don't overwrite ideal state settings\n           if (!resourceMap.containsKey(resourceName)) {\n-            addResource(resourceName, resourceMap);\n-            Resource resource = resourceMap.get(resourceName);\n+            Resource resource = new Resource(resourceName);\n             resource.setStateModelDefRef(currentState.getStateModelDefRef());\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (resource.getStateModelDefRef() == null && !isTaskCache\n-                || resource.getStateModelDefRef() != null && (\n-                resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME) && isTaskCache\n-                    || !resource.getStateModelDefRef().equals(TaskConstants.STATE_MODEL_NAME)\n-                    && !isTaskCache)) {\n+            if (!isTaskCache && !TaskConstants.STATE_MODEL_NAME", "originalCommit": "80b687f5f76dd6576ea7260a1eaf0b97a2051e17", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIwMjMzMg==", "url": "https://github.com/apache/helix/pull/1326#discussion_r487202332", "bodyText": "That's very smart - updating.", "author": "NealSun96", "createdAt": "2020-09-11T17:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc4NjM1NA=="}], "type": "inlineReview", "revised_code": {"commit": "24de07766e18a06d90639ac2a2f4c66527171725", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\nindex 89da58b51..284479ce7 100644\n--- a/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n+++ b/helix-core/src/main/java/org/apache/helix/controller/stages/ResourceComputationStage.java\n\n@@ -210,9 +210,9 @@ public class ResourceComputationStage extends AbstractBaseStage {\n             resource.setStateModelFactoryName(currentState.getStateModelFactoryName());\n             resource.setBucketSize(currentState.getBucketSize());\n             resource.setBatchMessageMode(currentState.getBatchMessageMode());\n-            if (!isTaskCache && !TaskConstants.STATE_MODEL_NAME\n-                .equals(resource.getStateModelDefRef())\n-                || isTaskCache && TaskConstants.STATE_MODEL_NAME\n+            // if state model def is null, it's added during resource pipeline; if it's not null,\n+            // it's added when it matches the pipeline type\n+            if (isTaskCache == TaskConstants.STATE_MODEL_NAME\n                 .equals(resource.getStateModelDefRef())) {\n               resourceToRebalance.put(resourceName, resource);\n             }\n"}}, {"oid": "24de07766e18a06d90639ac2a2f4c66527171725", "url": "https://github.com/apache/helix/commit/24de07766e18a06d90639ac2a2f4c66527171725", "message": "Add TODO, change if, remove txt", "committedDate": "2020-09-11T22:16:43Z", "type": "commit"}]}