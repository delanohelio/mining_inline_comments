{"pr_number": 1061, "pr_title": "Remove previousAssignment from FixedTargetTaskAssignmentCalculator", "pr_createdAt": "2020-06-04T20:38:59Z", "pr_url": "https://github.com/apache/helix/pull/1061", "timeline": [{"oid": "0726f33fd1c6d289b1cb6d7e5abc5b0e52bf6d98", "url": "https://github.com/apache/helix/commit/0726f33fd1c6d289b1cb6d7e5abc5b0e52bf6d98", "message": "Remove previousAssignment from FixedTargetTaskAssignmentCalculator\n\nThe FixedTargetTaskAssignmentCalculator class is relying on the previousAssignment.\nIn this commit, this method has been modified and previousAssignment has been\nreplaced with the context information.", "committedDate": "2020-06-04T18:29:09Z", "type": "commit"}, {"oid": "9745afe38eb76ab01bfb551660a918ca14939bc1", "url": "https://github.com/apache/helix/commit/9745afe38eb76ab01bfb551660a918ca14939bc1", "message": "minor fix", "committedDate": "2020-06-06T17:32:28Z", "type": "commit"}, {"oid": "9745afe38eb76ab01bfb551660a918ca14939bc1", "url": "https://github.com/apache/helix/commit/9745afe38eb76ab01bfb551660a918ca14939bc1", "message": "minor fix", "committedDate": "2020-06-06T17:32:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyMTA1Mw==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437621053", "bodyText": "I dont think any one is using this class. Shall we remove it? Or at least, let's deprecate the class instead of changing the public API for backward incompatible change.", "author": "junkaixue", "createdAt": "2020-06-09T18:06:08Z", "path": "helix-core/src/main/java/org/apache/helix/task/DeprecatedTaskRebalancer.java", "diffHunk": "@@ -110,10 +109,9 @@\n    * @return map of instances to set of partition numbers\n    */", "originalCommit": "9745afe38eb76ab01bfb551660a918ca14939bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3MTk4Ng==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437671986", "bodyText": "Removed.", "author": "alirezazamani", "createdAt": "2020-06-09T19:38:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyMTA1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7d2d65092e5719578cb1845b30ad17c45b163035", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/DeprecatedTaskRebalancer.java b/helix-core/src/main/java/org/apache/helix/task/DeprecatedTaskRebalancer.java\ndeleted file mode 100644\nindex 316b637d5..000000000\n--- a/helix-core/src/main/java/org/apache/helix/task/DeprecatedTaskRebalancer.java\n+++ /dev/null\n\n@@ -1,1147 +0,0 @@\n-package org.apache.helix.task;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-import java.text.DateFormat;\n-import java.text.SimpleDateFormat;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.Date;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.SortedSet;\n-import java.util.TreeMap;\n-import java.util.TreeSet;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.TimeUnit;\n-\n-import com.google.common.base.Joiner;\n-import com.google.common.collect.BiMap;\n-import com.google.common.collect.HashBiMap;\n-import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.Lists;\n-import com.google.common.collect.Maps;\n-import com.google.common.collect.Sets;\n-import org.apache.helix.AccessOption;\n-import org.apache.helix.HelixDataAccessor;\n-import org.apache.helix.HelixDefinedState;\n-import org.apache.helix.HelixManager;\n-import org.apache.helix.HelixProperty;\n-import org.apache.helix.PropertyKey;\n-import org.apache.helix.zookeeper.datamodel.ZNRecord;\n-import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n-import org.apache.helix.controller.rebalancer.Rebalancer;\n-import org.apache.helix.controller.rebalancer.internal.MappingCalculator;\n-import org.apache.helix.controller.rebalancer.util.RebalanceScheduler;\n-import org.apache.helix.controller.stages.CurrentStateOutput;\n-import org.apache.helix.model.IdealState;\n-import org.apache.helix.model.Message;\n-import org.apache.helix.model.Partition;\n-import org.apache.helix.model.Resource;\n-import org.apache.helix.model.ResourceAssignment;\n-import org.apache.helix.zookeeper.zkclient.DataUpdater;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * Custom rebalancer implementation for the {@code Task} state model.\n- */\n-/** This rebalancer is deprecated, left here only for back-compatible. **/\n-@Deprecated\n-public abstract class DeprecatedTaskRebalancer\n-    implements Rebalancer<WorkflowControllerDataProvider>,\n-    MappingCalculator<WorkflowControllerDataProvider> {\n-  private static final Logger LOG = LoggerFactory.getLogger(TaskRebalancer.class);\n-\n-  // Management of already-scheduled rebalances across jobs\n-  private static final BiMap<String, Date> SCHEDULED_TIMES = HashBiMap.create();\n-  private static final ScheduledExecutorService SCHEDULED_EXECUTOR = Executors\n-      .newSingleThreadScheduledExecutor();\n-  public static final String PREV_RA_NODE = \"PreviousResourceAssignment\";\n-\n-  // For connection management\n-  private HelixManager _manager;\n-\n-  /**\n-   * Get all the partitions that should be created by this task\n-   * @param jobCfg the task configuration\n-   * @param jobCtx the task context\n-   * @param workflowCfg the workflow configuration\n-   * @param workflowCtx the workflow context\n-   * @param cache cluster snapshot\n-   * @return set of partition numbers\n-   */\n-  public abstract Set<Integer> getAllTaskPartitions(JobConfig jobCfg, JobContext jobCtx,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx, WorkflowControllerDataProvider cache);\n-\n-  /**\n-   * Compute an assignment of tasks to instances\n-   * @param currStateOutput the current state of the instances\n-   * @param instances the instances\n-   * @param jobCfg the task configuration\n-   * @param jobContext the task context\n-   * @param workflowCfg the workflow configuration\n-   * @param workflowCtx the workflow context\n-   * @param partitionSet the partitions to assign\n-   * @param cache cluster snapshot\n-   * @return map of instances to set of partition numbers\n-   */\n-  public abstract Map<String, SortedSet<Integer>> getTaskAssignment(\n-      CurrentStateOutput currStateOutput, Collection<String> instances, JobConfig jobCfg,\n-      JobContext jobContext, WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n-      Set<Integer> partitionSet, WorkflowControllerDataProvider cache);\n-\n-  @Override\n-  public void init(HelixManager manager) {\n-    _manager = manager;\n-  }\n-\n-  @Override\n-  public ResourceAssignment computeBestPossiblePartitionState(WorkflowControllerDataProvider clusterData,\n-      IdealState taskIs, Resource resource, CurrentStateOutput currStateOutput) {\n-    final String resourceName = resource.getResourceName();\n-    LOG.debug(\"Computer Best Partition for resource: \" + resourceName);\n-\n-    // Fetch job configuration\n-    JobConfig jobCfg = (JobConfig) clusterData.getResourceConfig(resourceName);\n-    if (jobCfg == null) {\n-      LOG.debug(\"Job configuration is NULL for \" + resourceName);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-    String workflowResource = jobCfg.getWorkflow();\n-\n-    // Fetch workflow configuration and context\n-    WorkflowConfig workflowCfg = clusterData.getWorkflowConfig(workflowResource);\n-    if (workflowCfg == null) {\n-      LOG.debug(\"Workflow configuration is NULL for \" + resourceName);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-    WorkflowContext workflowCtx = clusterData.getWorkflowContext(workflowResource);\n-\n-    // Initialize workflow context if needed\n-    if (workflowCtx == null) {\n-      workflowCtx = new WorkflowContext(new ZNRecord(TaskUtil.WORKFLOW_CONTEXT_KW));\n-      workflowCtx.setStartTime(System.currentTimeMillis());\n-      workflowCtx.setName(workflowResource);\n-      LOG.info(\"Workflow context for \" + resourceName + \" created!\");\n-    }\n-\n-    // check ancestor job status\n-    int notStartedCount = 0;\n-    int inCompleteCount = 0;\n-    for (String ancestor : workflowCfg.getJobDag().getAncestors(resourceName)) {\n-      TaskState jobState = workflowCtx.getJobState(ancestor);\n-      if (jobState == null || jobState == TaskState.NOT_STARTED) {\n-        ++notStartedCount;\n-      } else if (jobState == TaskState.IN_PROGRESS || jobState == TaskState.STOPPED) {\n-        ++inCompleteCount;\n-      }\n-    }\n-\n-    if (notStartedCount > 0 || (workflowCfg.isJobQueue() && inCompleteCount >= workflowCfg\n-        .getParallelJobs())) {\n-      LOG.debug(\"Job is not ready to be scheduled due to pending dependent jobs \" + resourceName);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // Clean up if workflow marked for deletion\n-    TargetState targetState = workflowCfg.getTargetState();\n-    if (targetState == TargetState.DELETE) {\n-      LOG.info(\n-          \"Workflow is marked as deleted \" + workflowResource\n-              + \" cleaning up the workflow context.\");\n-      cleanup(_manager, resourceName, workflowCfg, workflowResource);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // Check if this workflow has been finished past its expiry.\n-    if (workflowCtx.getFinishTime() != WorkflowContext.UNFINISHED\n-        && workflowCtx.getFinishTime() + workflowCfg.getExpiry() <= System.currentTimeMillis()) {\n-      LOG.info(\"Workflow \" + workflowResource\n-          + \" is completed and passed expiry time, cleaning up the workflow context.\");\n-      markForDeletion(_manager, workflowResource);\n-      cleanup(_manager, resourceName, workflowCfg, workflowResource);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // Fetch any existing context information from the property store.\n-\n-    JobContext jobCtx = clusterData.getJobContext(resourceName);\n-    if (jobCtx == null) {\n-      jobCtx = new JobContext(new ZNRecord(TaskUtil.TASK_CONTEXT_KW));\n-      jobCtx.setStartTime(System.currentTimeMillis());\n-      jobCtx.setName(resourceName);\n-    }\n-\n-    // Check for expired jobs for non-terminable workflows\n-    long jobFinishTime = jobCtx.getFinishTime();\n-    if (!workflowCfg.isTerminable() && jobFinishTime != WorkflowContext.UNFINISHED\n-        && jobFinishTime + workflowCfg.getExpiry() <= System.currentTimeMillis()) {\n-      LOG.info(\"Job \" + resourceName\n-          + \" is completed and passed expiry time, cleaning up the job context.\");\n-      cleanup(_manager, resourceName, workflowCfg, workflowResource);\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // The job is already in a final state (completed/failed).\n-    if (workflowCtx.getJobState(resourceName) == TaskState.FAILED\n-        || workflowCtx.getJobState(resourceName) == TaskState.COMPLETED) {\n-      LOG.debug(\"Job \" + resourceName + \" is failed or already completed.\");\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // Check for readiness, and stop processing if it's not ready\n-    boolean isReady =\n-        scheduleIfNotReady(workflowCfg, workflowCtx, workflowResource, resourceName, clusterData);\n-    if (!isReady) {\n-      LOG.debug(\"Job \" + resourceName + \" is not ready to be scheduled.\");\n-      return emptyAssignment(resourceName, currStateOutput);\n-    }\n-\n-    // Grab the old assignment, or an empty one if it doesn't exist\n-    ResourceAssignment prevAssignment = getPrevResourceAssignment(_manager, resourceName);\n-    if (prevAssignment == null) {\n-      prevAssignment = new ResourceAssignment(resourceName);\n-    }\n-\n-    // Will contain the list of partitions that must be explicitly dropped from the ideal state that\n-    // is stored in zk.\n-    // Fetch the previous resource assignment from the property store. This is required because of\n-    // HELIX-230.\n-    Set<Integer> partitionsToDrop = new TreeSet<Integer>();\n-\n-    ResourceAssignment newAssignment =\n-        computeResourceMapping(resourceName, workflowCfg, jobCfg, prevAssignment, clusterData\n-            .getLiveInstances().keySet(), currStateOutput, workflowCtx, jobCtx, partitionsToDrop,\n-            clusterData);\n-\n-    if (!partitionsToDrop.isEmpty()) {\n-      for (Integer pId : partitionsToDrop) {\n-        taskIs.getRecord().getMapFields().remove(pName(resourceName, pId));\n-      }\n-      HelixDataAccessor accessor = _manager.getHelixDataAccessor();\n-      PropertyKey propertyKey = accessor.keyBuilder().idealStates(resourceName);\n-      accessor.setProperty(propertyKey, taskIs);\n-    }\n-\n-    // Update Workflow and Job context in data cache and ZK.\n-    clusterData.updateJobContext(resourceName, jobCtx);\n-    clusterData\n-        .updateWorkflowContext(workflowResource, workflowCtx);\n-\n-    setPrevResourceAssignment(_manager, resourceName, newAssignment);\n-\n-    LOG.debug(\"Job \" + resourceName + \" new assignment \" + Arrays\n-        .toString(newAssignment.getMappedPartitions().toArray()));\n-\n-    return newAssignment;\n-  }\n-\n-  /**\n-   * Get the last task assignment for a given job\n-   * @param manager a connection to Helix\n-   * @param resourceName the name of the job\n-   * @return {@link ResourceAssignment} instance, or null if no assignment is available\n-   */\n-  private ResourceAssignment getPrevResourceAssignment(HelixManager manager,\n-      String resourceName) {\n-    ZNRecord r =\n-        manager.getHelixPropertyStore().get(\n-            Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, resourceName, PREV_RA_NODE),\n-            null, AccessOption.PERSISTENT);\n-    return r != null ? new ResourceAssignment(r) : null;\n-  }\n-\n-  /**\n-   * Set the last task assignment for a given job\n-   * @param manager a connection to Helix\n-   * @param resourceName the name of the job\n-   * @param ra {@link ResourceAssignment} containing the task assignment\n-   */\n-  public void setPrevResourceAssignment(HelixManager manager, String resourceName,\n-      ResourceAssignment ra) {\n-    manager.getHelixPropertyStore().set(\n-        Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, resourceName, PREV_RA_NODE),\n-        ra.getRecord(), AccessOption.PERSISTENT);\n-  }\n-\n-  private Set<String> getInstancesAssignedToOtherJobs(String currentJobName,\n-      WorkflowConfig workflowCfg, WorkflowControllerDataProvider cache) {\n-\n-    Set<String> ret = new HashSet<String>();\n-\n-    for (String jobName : workflowCfg.getJobDag().getAllNodes()) {\n-      if (jobName.equals(currentJobName)) {\n-        continue;\n-      }\n-\n-      JobContext jobContext = cache.getJobContext(jobName);\n-      if (jobContext == null) {\n-        continue;\n-      }\n-      for (int partition : jobContext.getPartitionSet()) {\n-        TaskPartitionState partitionState = jobContext.getPartitionState(partition);\n-        if (partitionState == TaskPartitionState.INIT ||\n-            partitionState == TaskPartitionState.RUNNING) {\n-          ret.add(jobContext.getAssignedParticipant(partition));\n-        }\n-      }\n-    }\n-\n-    return ret;\n-  }\n-\n-  private ResourceAssignment computeResourceMapping(String jobResource,\n-      WorkflowConfig workflowConfig, JobConfig jobCfg, ResourceAssignment prevAssignment,\n-      Collection<String> liveInstances, CurrentStateOutput currStateOutput,\n-      WorkflowContext workflowCtx, JobContext jobCtx, Set<Integer> partitionsToDropFromIs,\n-      WorkflowControllerDataProvider cache) {\n-    TargetState jobTgtState = workflowConfig.getTargetState();\n-\n-    // Update running status in workflow context\n-    if (jobTgtState == TargetState.STOP) {\n-      workflowCtx.setJobState(jobResource, TaskState.STOPPED);\n-      // Workflow has been stopped if all jobs are stopped\n-      if (isWorkflowStopped(workflowCtx, workflowConfig)) {\n-        workflowCtx.setWorkflowState(TaskState.STOPPED);\n-      }\n-    } else {\n-      workflowCtx.setJobState(jobResource, TaskState.IN_PROGRESS);\n-      // Workflow is in progress if any task is in progress\n-      workflowCtx.setWorkflowState(TaskState.IN_PROGRESS);\n-    }\n-\n-    // Used to keep track of tasks that have already been assigned to instances.\n-    Set<Integer> assignedPartitions = new HashSet<Integer>();\n-\n-    // Used to keep track of tasks that have failed, but whose failure is acceptable\n-    Set<Integer> skippedPartitions = new HashSet<Integer>();\n-\n-    // Keeps a mapping of (partition) -> (instance, state)\n-    Map<Integer, PartitionAssignment> paMap = new TreeMap<Integer, PartitionAssignment>();\n-\n-    Set<String> excludedInstances =\n-        getInstancesAssignedToOtherJobs(jobResource, workflowConfig, cache);\n-\n-    // Process all the current assignments of tasks.\n-    Set<Integer> allPartitions =\n-        getAllTaskPartitions(jobCfg, jobCtx, workflowConfig, workflowCtx, cache);\n-    Map<String, SortedSet<Integer>> taskAssignments =\n-        getTaskPartitionAssignments(liveInstances, prevAssignment, allPartitions);\n-    long currentTime = System.currentTimeMillis();\n-    for (String instance : taskAssignments.keySet()) {\n-      if (excludedInstances.contains(instance)) {\n-        continue;\n-      }\n-\n-      Set<Integer> pSet = taskAssignments.get(instance);\n-      // Used to keep track of partitions that are in one of the final states: COMPLETED, TIMED_OUT,\n-      // TASK_ERROR, ERROR.\n-      Set<Integer> donePartitions = new TreeSet<Integer>();\n-      for (int pId : pSet) {\n-        final String pName = pName(jobResource, pId);\n-\n-        // Check for pending state transitions on this (partition, instance).\n-        Message pendingMessage =\n-            currStateOutput.getPendingMessage(jobResource, new Partition(pName), instance);\n-        if (pendingMessage != null) {\n-          // There is a pending state transition for this (partition, instance). Just copy forward\n-          // the state assignment from the previous ideal state.\n-          Map<String, String> stateMap = prevAssignment.getReplicaMap(new Partition(pName));\n-          if (stateMap != null) {\n-            String prevState = stateMap.get(instance);\n-            paMap.put(pId, new PartitionAssignment(instance, prevState));\n-            assignedPartitions.add(pId);\n-            if (LOG.isDebugEnabled()) {\n-              LOG.debug(String\n-                  .format(\n-                      \"Task partition %s has a pending state transition on instance %s. Using the previous ideal state which was %s.\",\n-                      pName, instance, prevState));\n-            }\n-          }\n-\n-          continue;\n-        }\n-\n-        TaskPartitionState currState =\n-            TaskPartitionState.valueOf(currStateOutput.getCurrentState(jobResource, new Partition(\n-                pName), instance));\n-        jobCtx.setPartitionState(pId, currState);\n-\n-        // Process any requested state transitions.\n-        String requestedStateStr =\n-            currStateOutput.getRequestedState(jobResource, new Partition(pName), instance);\n-        if (requestedStateStr != null && !requestedStateStr.isEmpty()) {\n-          TaskPartitionState requestedState = TaskPartitionState.valueOf(requestedStateStr);\n-          if (requestedState.equals(currState)) {\n-            LOG.warn(String.format(\n-                \"Requested state %s is the same as the current state for instance %s.\",\n-                requestedState, instance));\n-          }\n-\n-          paMap.put(pId, new PartitionAssignment(instance, requestedState.name()));\n-          assignedPartitions.add(pId);\n-          LOG.debug(String.format(\n-              \"Instance %s requested a state transition to %s for partition %s.\", instance,\n-              requestedState, pName));\n-          continue;\n-        }\n-\n-        switch (currState) {\n-        case RUNNING:\n-        case STOPPED: {\n-          TaskPartitionState nextState;\n-          if (jobTgtState == TargetState.START) {\n-            nextState = TaskPartitionState.RUNNING;\n-          } else {\n-            nextState = TaskPartitionState.STOPPED;\n-          }\n-\n-          paMap.put(pId, new PartitionAssignment(instance, nextState.name()));\n-          assignedPartitions.add(pId);\n-          LOG.debug(String.format(\"Setting task partition %s state to %s on instance %s.\", pName,\n-              nextState, instance));\n-        }\n-          break;\n-        case COMPLETED: {\n-          // The task has completed on this partition. Mark as such in the context object.\n-          donePartitions.add(pId);\n-          LOG.debug(String\n-              .format(\n-                  \"Task partition %s has completed with state %s. Marking as such in rebalancer context.\",\n-                  pName, currState));\n-          partitionsToDropFromIs.add(pId);\n-          markPartitionCompleted(jobCtx, pId);\n-        }\n-          break;\n-        case TIMED_OUT:\n-        case TASK_ERROR:\n-        case ERROR: {\n-          donePartitions.add(pId); // The task may be rescheduled on a different instance.\n-          LOG.debug(String.format(\n-              \"Task partition %s has error state %s. Marking as such in rebalancer context.\",\n-              pName, currState));\n-          markPartitionError(jobCtx, pId, currState, true);\n-          // The error policy is to fail the task as soon a single partition fails for a specified\n-          // maximum number of attempts.\n-          if (jobCtx.getPartitionNumAttempts(pId) >= jobCfg.getMaxAttemptsPerTask()) {\n-            // If the user does not require this task to succeed in order for the job to succeed,\n-            // then we don't have to fail the job right now\n-            boolean successOptional = false;\n-            String taskId = jobCtx.getTaskIdForPartition(pId);\n-            if (taskId != null) {\n-              TaskConfig taskConfig = jobCfg.getTaskConfig(taskId);\n-              if (taskConfig != null) {\n-                successOptional = taskConfig.isSuccessOptional();\n-              }\n-            }\n-\n-            // Similarly, if we have some leeway for how many tasks we can fail, then we don't have\n-            // to fail the job immediately\n-            if (skippedPartitions.size() < jobCfg.getFailureThreshold()) {\n-              successOptional = true;\n-            }\n-\n-            if (!successOptional) {\n-              long finishTime = currentTime;\n-              workflowCtx.setJobState(jobResource, TaskState.FAILED);\n-              if (workflowConfig.isTerminable()) {\n-                workflowCtx.setWorkflowState(TaskState.FAILED);\n-                workflowCtx.setFinishTime(finishTime);\n-              }\n-              jobCtx.setFinishTime(finishTime);\n-              markAllPartitionsError(jobCtx, currState, false);\n-              addAllPartitions(allPartitions, partitionsToDropFromIs);\n-              return emptyAssignment(jobResource, currStateOutput);\n-            } else {\n-              skippedPartitions.add(pId);\n-              partitionsToDropFromIs.add(pId);\n-            }\n-          } else {\n-            // Mark the task to be started at some later time (if enabled)\n-            markPartitionDelayed(jobCfg, jobCtx, pId);\n-          }\n-        }\n-          break;\n-        case INIT:\n-        case DROPPED: {\n-          // currState in [INIT, DROPPED]. Do nothing, the partition is eligible to be reassigned.\n-          donePartitions.add(pId);\n-          LOG.debug(String.format(\n-              \"Task partition %s has state %s. It will be dropped from the current ideal state.\",\n-              pName, currState));\n-        }\n-          break;\n-        default:\n-          throw new AssertionError(\"Unknown enum symbol: \" + currState);\n-        }\n-      }\n-\n-      // Remove the set of task partitions that are completed or in one of the error states.\n-      pSet.removeAll(donePartitions);\n-    }\n-\n-    // For delayed tasks, trigger a rebalance event for the closest upcoming ready time\n-    scheduleForNextTask(jobResource, jobCtx, currentTime);\n-\n-    if (isJobComplete(jobCtx, allPartitions, skippedPartitions, jobCfg)) {\n-      workflowCtx.setJobState(jobResource, TaskState.COMPLETED);\n-      jobCtx.setFinishTime(currentTime);\n-      if (isWorkflowComplete(workflowCtx, workflowConfig)) {\n-        workflowCtx.setWorkflowState(TaskState.COMPLETED);\n-        workflowCtx.setFinishTime(currentTime);\n-      }\n-    }\n-\n-    // Make additional task assignments if needed.\n-    if (jobTgtState == TargetState.START) {\n-      // Contains the set of task partitions that must be excluded from consideration when making\n-      // any new assignments.\n-      // This includes all completed, failed, delayed, and already assigned partitions.\n-      Set<Integer> excludeSet = Sets.newTreeSet(assignedPartitions);\n-      addCompletedPartitions(excludeSet, jobCtx, allPartitions);\n-      addGiveupPartitions(excludeSet, jobCtx, allPartitions, jobCfg);\n-      excludeSet.addAll(skippedPartitions);\n-      excludeSet.addAll(getNonReadyPartitions(jobCtx, currentTime));\n-      // Get instance->[partition, ...] mappings for the target resource.\n-      Map<String, SortedSet<Integer>> tgtPartitionAssignments =\n-          getTaskAssignment(currStateOutput, liveInstances, jobCfg, jobCtx,\n-              workflowConfig, workflowCtx, allPartitions, cache);\n-      for (Map.Entry<String, SortedSet<Integer>> entry : taskAssignments.entrySet()) {\n-        String instance = entry.getKey();\n-        if (!tgtPartitionAssignments.containsKey(instance) || excludedInstances.contains(instance)) {\n-          continue;\n-        }\n-        // Contains the set of task partitions currently assigned to the instance.\n-        Set<Integer> pSet = entry.getValue();\n-        int numToAssign = jobCfg.getNumConcurrentTasksPerInstance() - pSet.size();\n-        if (numToAssign > 0) {\n-          List<Integer> nextPartitions =\n-              getNextPartitions(tgtPartitionAssignments.get(instance), excludeSet, numToAssign);\n-          for (Integer pId : nextPartitions) {\n-            String pName = pName(jobResource, pId);\n-            paMap.put(pId, new PartitionAssignment(instance, TaskPartitionState.RUNNING.name()));\n-            excludeSet.add(pId);\n-            jobCtx.setAssignedParticipant(pId, instance);\n-            jobCtx.setPartitionState(pId, TaskPartitionState.INIT);\n-            LOG.debug(String.format(\"Setting task partition %s state to %s on instance %s.\", pName,\n-                TaskPartitionState.RUNNING, instance));\n-          }\n-        }\n-      }\n-    }\n-\n-    // Construct a ResourceAssignment object from the map of partition assignments.\n-    ResourceAssignment ra = new ResourceAssignment(jobResource);\n-    for (Map.Entry<Integer, PartitionAssignment> e : paMap.entrySet()) {\n-      PartitionAssignment pa = e.getValue();\n-      ra.addReplicaMap(new Partition(pName(jobResource, e.getKey())),\n-          ImmutableMap.of(pa._instance, pa._state));\n-    }\n-\n-    return ra;\n-  }\n-\n-  /**\n-   * Check if a workflow is ready to schedule, and schedule a rebalance if it is not\n-   * @param workflowCfg the workflow to check\n-   * @param workflowCtx the current workflow context\n-   * @param workflowResource the Helix resource associated with the workflow\n-   * @param jobResource a job from the workflow\n-   * @param cache the current snapshot of the cluster\n-   * @return true if ready, false if not ready\n-   */\n-  private boolean scheduleIfNotReady(WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n-      String workflowResource, String jobResource, WorkflowControllerDataProvider cache) {\n-    // Ignore non-scheduled workflows\n-    if (workflowCfg == null || workflowCfg.getScheduleConfig() == null) {\n-      return true;\n-    }\n-\n-    // Figure out when this should be run, and if it's ready, then just run it\n-    ScheduleConfig scheduleConfig = workflowCfg.getScheduleConfig();\n-    Date startTime = scheduleConfig.getStartTime();\n-    long currentTime = new Date().getTime();\n-    long delayFromStart = startTime.getTime() - currentTime;\n-\n-    if (delayFromStart <= 0) {\n-      // Remove any timers that are past-time for this workflow\n-      Date scheduledTime = SCHEDULED_TIMES.get(workflowResource);\n-      if (scheduledTime != null && currentTime > scheduledTime.getTime()) {\n-        LOG.debug(\"Remove schedule timer for \" + jobResource + \" time: \" + SCHEDULED_TIMES.get(jobResource));\n-        SCHEDULED_TIMES.remove(workflowResource);\n-      }\n-\n-      // Recurring workflows are just templates that spawn new workflows\n-      if (scheduleConfig.isRecurring()) {\n-        // Skip scheduling this workflow if it's not in a start state\n-        if (!workflowCfg.getTargetState().equals(TargetState.START)) {\n-          LOG.debug(\n-              \"Skip scheduling since the workflow has not been started \" + workflowResource);\n-          return false;\n-        }\n-\n-        // Skip scheduling this workflow again if the previous run (if any) is still active\n-        String lastScheduled = workflowCtx.getLastScheduledSingleWorkflow();\n-        if (lastScheduled != null) {\n-          WorkflowContext lastWorkflowCtx = cache.getWorkflowContext(lastScheduled);\n-          if (lastWorkflowCtx != null\n-              && lastWorkflowCtx.getFinishTime() == WorkflowContext.UNFINISHED) {\n-            LOG.info(\"Skip scheduling since last schedule has not completed yet \" + lastScheduled);\n-            return false;\n-          }\n-        }\n-\n-        // Figure out how many jumps are needed, thus the time to schedule the next workflow\n-        // The negative of the delay is the amount of time past the start time\n-        long period =\n-            scheduleConfig.getRecurrenceUnit().toMillis(scheduleConfig.getRecurrenceInterval());\n-        long offsetMultiplier = (-delayFromStart) / period;\n-        long timeToSchedule = period * offsetMultiplier + startTime.getTime();\n-\n-        // Now clone the workflow if this clone has not yet been created\n-        DateFormat df = new SimpleDateFormat(\"yyyyMMdd'T'HHmmssZ\");\n-        // Now clone the workflow if this clone has not yet been created\n-        String newWorkflowName = workflowResource + \"_\" + df.format(new java.util.Date(timeToSchedule));\n-        LOG.debug(\"Ready to start workflow \" + newWorkflowName);\n-        if (!newWorkflowName.equals(lastScheduled)) {\n-          Workflow clonedWf =\n-              cloneWorkflow(_manager, workflowResource, newWorkflowName, new Date(timeToSchedule));\n-          TaskDriver driver = new TaskDriver(_manager);\n-          try {\n-            // Start the cloned workflow\n-            driver.start(clonedWf);\n-          } catch (Exception e) {\n-            LOG.error(\"Failed to schedule cloned workflow \" + newWorkflowName, e);\n-          }\n-          // Persist workflow start regardless of success to avoid retrying and failing\n-          workflowCtx.setLastScheduledSingleWorkflow(newWorkflowName);\n-          cache.updateWorkflowContext(workflowResource, workflowCtx);\n-        }\n-\n-        // Change the time to trigger the pipeline to that of the next run\n-        startTime = new Date(timeToSchedule + period);\n-        delayFromStart = startTime.getTime() - System.currentTimeMillis();\n-      } else {\n-        // This is a one-time workflow and is ready\n-        return true;\n-      }\n-    }\n-\n-    scheduleRebalance(workflowResource, jobResource, startTime, delayFromStart);\n-    return false;\n-  }\n-\n-  /**\n-   * Create a new workflow based on an existing one\n-   * @param manager connection to Helix\n-   * @param origWorkflowName the name of the existing workflow\n-   * @param newWorkflowName the name of the new workflow\n-   * @param newStartTime a provided start time that deviates from the desired start time\n-   * @return the cloned workflow, or null if there was a problem cloning the existing one\n-   */\n-  private Workflow cloneWorkflow(HelixManager manager, String origWorkflowName,\n-      String newWorkflowName, Date newStartTime) {\n-    // Read all resources, including the workflow and jobs of interest\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    PropertyKey.Builder keyBuilder = accessor.keyBuilder();\n-    Map<String, HelixProperty> resourceConfigMap =\n-        accessor.getChildValuesMap(keyBuilder.resourceConfigs());\n-    if (!resourceConfigMap.containsKey(origWorkflowName)) {\n-      LOG.error(\"No such workflow named \" + origWorkflowName);\n-      return null;\n-    }\n-    if (resourceConfigMap.containsKey(newWorkflowName)) {\n-      LOG.error(\"Workflow with name \" + newWorkflowName + \" already exists!\");\n-      return null;\n-    }\n-\n-    // Create a new workflow with a new name\n-    HelixProperty workflowConfig = resourceConfigMap.get(origWorkflowName);\n-    Map<String, String> wfSimpleFields = workflowConfig.getRecord().getSimpleFields();\n-    JobDag jobDag =\n-        JobDag.fromJson(wfSimpleFields.get(WorkflowConfig.WorkflowConfigProperty.Dag.name()));\n-    Map<String, Set<String>> parentsToChildren = jobDag.getParentsToChildren();\n-    Workflow.Builder builder = new Workflow.Builder(newWorkflowName);\n-\n-    // Set the workflow expiry\n-    builder.setExpiry(\n-        Long.parseLong(wfSimpleFields.get(WorkflowConfig.WorkflowConfigProperty.Expiry.name())));\n-\n-    // Set the schedule, if applicable\n-    ScheduleConfig scheduleConfig;\n-    if (newStartTime != null) {\n-      scheduleConfig = ScheduleConfig.oneTimeDelayedStart(newStartTime);\n-    } else {\n-      scheduleConfig = WorkflowConfig.parseScheduleFromConfigMap(wfSimpleFields);\n-    }\n-    if (scheduleConfig != null) {\n-      builder.setScheduleConfig(scheduleConfig);\n-    }\n-\n-    // Add each job back as long as the original exists\n-    Set<String> namespacedJobs = jobDag.getAllNodes();\n-    for (String namespacedJob : namespacedJobs) {\n-      if (resourceConfigMap.containsKey(namespacedJob)) {\n-        // Copy over job-level and task-level configs\n-        String job = TaskUtil.getDenamespacedJobName(origWorkflowName, namespacedJob);\n-        HelixProperty jobConfig = resourceConfigMap.get(namespacedJob);\n-        Map<String, String> jobSimpleFields = jobConfig.getRecord().getSimpleFields();\n-        jobSimpleFields.put(JobConfig.JobConfigProperty.WorkflowID.name(), newWorkflowName); // overwrite workflow name\n-        for (Map.Entry<String, String> e : jobSimpleFields.entrySet()) {\n-          builder.addConfig(job, e.getKey(), e.getValue());\n-        }\n-        Map<String, Map<String, String>> rawTaskConfigMap = jobConfig.getRecord().getMapFields();\n-        List<TaskConfig> taskConfigs = Lists.newLinkedList();\n-        for (Map<String, String> rawTaskConfig : rawTaskConfigMap.values()) {\n-          TaskConfig taskConfig = TaskConfig.Builder.from(rawTaskConfig);\n-          taskConfigs.add(taskConfig);\n-        }\n-        builder.addTaskConfigs(job, taskConfigs);\n-\n-        // Add dag dependencies\n-        Set<String> children = parentsToChildren.get(namespacedJob);\n-        if (children != null) {\n-          for (String namespacedChild : children) {\n-            String child = TaskUtil.getDenamespacedJobName(origWorkflowName, namespacedChild);\n-            builder.addParentChildDependency(job, child);\n-          }\n-        }\n-      }\n-    }\n-    return builder.build();\n-  }\n-\n-  private void scheduleRebalance(String id, String jobResource, Date startTime, long delayFromStart) {\n-    // Do nothing if there is already a timer set for the this workflow with the same start time.\n-    if ((SCHEDULED_TIMES.containsKey(id) && SCHEDULED_TIMES.get(id).equals(startTime))\n-        || SCHEDULED_TIMES.inverse().containsKey(startTime)) {\n-      LOG.debug(\"Schedule timer for\" + id + \"and job: \" + jobResource + \" is up to date.\");\n-      return;\n-    }\n-    LOG.info(\n-        \"Schedule rebalance with id: \" + id + \"and job: \" + jobResource + \" at time: \" + startTime\n-            + \" delay from start: \" + delayFromStart);\n-\n-    // For workflows not yet scheduled, schedule them and record it\n-    RebalanceInvoker rebalanceInvoker = new RebalanceInvoker(_manager, jobResource);\n-    SCHEDULED_TIMES.put(id, startTime);\n-    SCHEDULED_EXECUTOR.schedule(rebalanceInvoker, delayFromStart, TimeUnit.MILLISECONDS);\n-  }\n-\n-  private void scheduleForNextTask(String jobResource, JobContext ctx, long now) {\n-    // Clear current entries if they exist and are expired\n-    long currentTime = now;\n-    Date scheduledTime = SCHEDULED_TIMES.get(jobResource);\n-    if (scheduledTime != null && currentTime > scheduledTime.getTime()) {\n-      LOG.debug(\n-          \"Remove schedule timer for\" + jobResource + \" time: \" + SCHEDULED_TIMES.get(jobResource));\n-      SCHEDULED_TIMES.remove(jobResource);\n-    }\n-\n-    // Figure out the earliest schedulable time in the future of a non-complete job\n-    boolean shouldSchedule = false;\n-    long earliestTime = Long.MAX_VALUE;\n-    for (int p : ctx.getPartitionSet()) {\n-      long retryTime = ctx.getNextRetryTime(p);\n-      TaskPartitionState state = ctx.getPartitionState(p);\n-      state = (state != null) ? state : TaskPartitionState.INIT;\n-      Set<TaskPartitionState> errorStates =\n-          Sets.newHashSet(TaskPartitionState.ERROR, TaskPartitionState.TASK_ERROR,\n-              TaskPartitionState.TIMED_OUT);\n-      if (errorStates.contains(state) && retryTime > currentTime && retryTime < earliestTime) {\n-        earliestTime = retryTime;\n-        shouldSchedule = true;\n-      }\n-    }\n-\n-    // If any was found, then schedule it\n-    if (shouldSchedule) {\n-      long delay = earliestTime - currentTime;\n-      Date startTime = new Date(earliestTime);\n-      scheduleRebalance(jobResource, jobResource, startTime, delay);\n-    }\n-  }\n-\n-  /**\n-   * Checks if the job has completed.\n-   * @param ctx The rebalancer context.\n-   * @param allPartitions The set of partitions to check.\n-   * @param skippedPartitions partitions that failed, but whose failure is acceptable\n-   * @return true if all task partitions have been marked with status\n-   *         {@link TaskPartitionState#COMPLETED} in the rebalancer\n-   *         context, false otherwise.\n-   */\n-  private static boolean isJobComplete(JobContext ctx, Set<Integer> allPartitions,\n-      Set<Integer> skippedPartitions, JobConfig cfg) {\n-    for (Integer pId : allPartitions) {\n-      TaskPartitionState state = ctx.getPartitionState(pId);\n-      if (!skippedPartitions.contains(pId) && state != TaskPartitionState.COMPLETED\n-          && !isTaskGivenup(ctx, cfg, pId)) {\n-        return false;\n-      }\n-    }\n-    return true;\n-  }\n-\n-  /**\n-   * Checks if the workflow has completed.\n-   * @param ctx Workflow context containing job states\n-   * @param cfg Workflow config containing set of jobs\n-   * @return returns true if all tasks are {@link TaskState#COMPLETED}, false otherwise.\n-   */\n-  private static boolean isWorkflowComplete(WorkflowContext ctx, WorkflowConfig cfg) {\n-    if (!cfg.isTerminable()) {\n-      return false;\n-    }\n-    for (String job : cfg.getJobDag().getAllNodes()) {\n-      if (ctx.getJobState(job) != TaskState.COMPLETED) {\n-        return false;\n-      }\n-    }\n-    return true;\n-  }\n-\n-  /**\n-   * Checks if the workflow has been stopped.\n-   * @param ctx Workflow context containing task states\n-   * @param cfg Workflow config containing set of tasks\n-   * @return returns true if all tasks are {@link TaskState#STOPPED}, false otherwise.\n-   */\n-  private static boolean isWorkflowStopped(WorkflowContext ctx, WorkflowConfig cfg) {\n-    for (String job : cfg.getJobDag().getAllNodes()) {\n-      if (ctx.getJobState(job) != TaskState.STOPPED && ctx.getJobState(job) != null) {\n-        return false;\n-      }\n-    }\n-    return true;\n-  }\n-\n-  private static void markForDeletion(HelixManager mgr, String resourceName) {\n-    mgr.getConfigAccessor().set(\n-        TaskUtil.getResourceConfigScope(mgr.getClusterName(), resourceName),\n-        WorkflowConfig.WorkflowConfigProperty.TargetState.name(), TargetState.DELETE.name());\n-  }\n-\n-  /**\n-   * Cleans up all Helix state associated with this job, wiping workflow-level information if this\n-   * is the last remaining job in its workflow, and the workflow is terminable.\n-   */\n-  private static void cleanup(HelixManager mgr, final String resourceName, WorkflowConfig cfg,\n-      String workflowResource) {\n-    LOG.info(\"Cleaning up job: \" + resourceName + \" in workflow: \" + workflowResource);\n-    HelixDataAccessor accessor = mgr.getHelixDataAccessor();\n-\n-    // Remove any DAG references in workflow\n-    PropertyKey workflowKey = getConfigPropertyKey(accessor, workflowResource);\n-    DataUpdater<ZNRecord> dagRemover = new DataUpdater<ZNRecord>() {\n-      @Override\n-      public ZNRecord update(ZNRecord currentData) {\n-        JobDag jobDag = JobDag\n-            .fromJson(currentData.getSimpleField(WorkflowConfig.WorkflowConfigProperty.Dag.name()));\n-        for (String child : jobDag.getDirectChildren(resourceName)) {\n-          jobDag.getChildrenToParents().get(child).remove(resourceName);\n-        }\n-        for (String parent : jobDag.getDirectParents(resourceName)) {\n-          jobDag.getParentsToChildren().get(parent).remove(resourceName);\n-        }\n-        jobDag.getChildrenToParents().remove(resourceName);\n-        jobDag.getParentsToChildren().remove(resourceName);\n-        jobDag.getAllNodes().remove(resourceName);\n-        try {\n-          currentData\n-              .setSimpleField(WorkflowConfig.WorkflowConfigProperty.Dag.name(), jobDag.toJson());\n-        } catch (Exception e) {\n-          LOG.equals(\"Could not update DAG for job: \" + resourceName);\n-        }\n-        return currentData;\n-      }\n-    };\n-    accessor.getBaseDataAccessor().update(workflowKey.getPath(), dagRemover,\n-        AccessOption.PERSISTENT);\n-\n-    // Delete resource configs.\n-    PropertyKey cfgKey = getConfigPropertyKey(accessor, resourceName);\n-    if (!accessor.removeProperty(cfgKey)) {\n-      throw new RuntimeException(String.format(\n-          \"Error occurred while trying to clean up job %s. Failed to remove node %s from Helix. Aborting further clean up steps.\",\n-          resourceName,\n-          cfgKey));\n-    }\n-\n-    // Delete property store information for this resource.\n-    // For recurring workflow, it's OK if the node doesn't exist.\n-    String propStoreKey = getRebalancerPropStoreKey(resourceName);\n-    mgr.getHelixPropertyStore().remove(propStoreKey, AccessOption.PERSISTENT);\n-\n-    // Delete the ideal state itself.\n-    PropertyKey isKey = getISPropertyKey(accessor, resourceName);\n-    if (!accessor.removeProperty(isKey)) {\n-      throw new RuntimeException(String.format(\n-          \"Error occurred while trying to clean up task %s. Failed to remove node %s from Helix.\",\n-          resourceName, isKey));\n-    }\n-\n-    // Delete dead external view\n-    // because job is already completed, there is no more current state change\n-    // thus dead external views removal will not be triggered\n-    PropertyKey evKey = accessor.keyBuilder().externalView(resourceName);\n-    accessor.removeProperty(evKey);\n-\n-    LOG.info(String.format(\"Successfully cleaned up job resource %s.\", resourceName));\n-\n-    boolean lastInWorkflow = true;\n-    for (String job : cfg.getJobDag().getAllNodes()) {\n-      // check if property store information or resource configs exist for this job\n-      if (mgr.getHelixPropertyStore().exists(getRebalancerPropStoreKey(job),\n-          AccessOption.PERSISTENT)\n-          || accessor.getProperty(getConfigPropertyKey(accessor, job)) != null\n-          || accessor.getProperty(getISPropertyKey(accessor, job)) != null) {\n-        lastInWorkflow = false;\n-        break;\n-      }\n-    }\n-\n-    // clean up workflow-level info if this was the last in workflow\n-    if (lastInWorkflow && (cfg.isTerminable() || cfg.getTargetState() == TargetState.DELETE)) {\n-      // delete workflow config\n-      PropertyKey workflowCfgKey = getConfigPropertyKey(accessor, workflowResource);\n-      if (!accessor.removeProperty(workflowCfgKey)) {\n-        throw new RuntimeException(\n-            String\n-                .format(\n-                    \"Error occurred while trying to clean up workflow %s. Failed to remove node %s from Helix. Aborting further clean up steps.\",\n-                    workflowResource, workflowCfgKey));\n-      }\n-      // Delete property store information for this workflow\n-      String workflowPropStoreKey = getRebalancerPropStoreKey(workflowResource);\n-      if (!mgr.getHelixPropertyStore().remove(workflowPropStoreKey, AccessOption.PERSISTENT)) {\n-        throw new RuntimeException(\n-            String\n-                .format(\n-                    \"Error occurred while trying to clean up workflow %s. Failed to remove node %s from Helix. Aborting further clean up steps.\",\n-                    workflowResource, workflowPropStoreKey));\n-      }\n-      // Remove pending timer for this workflow if exists\n-      if (SCHEDULED_TIMES.containsKey(workflowResource)) {\n-        SCHEDULED_TIMES.remove(workflowResource);\n-      }\n-    }\n-\n-  }\n-\n-  private static String getRebalancerPropStoreKey(String resource) {\n-    return Joiner.on(\"/\").join(TaskConstants.REBALANCER_CONTEXT_ROOT, resource);\n-  }\n-\n-  private static PropertyKey getISPropertyKey(HelixDataAccessor accessor, String resource) {\n-    return accessor.keyBuilder().idealStates(resource);\n-  }\n-\n-  private static PropertyKey getConfigPropertyKey(HelixDataAccessor accessor, String resource) {\n-    return accessor.keyBuilder().resourceConfig(resource);\n-  }\n-\n-  private static void addAllPartitions(Set<Integer> toAdd, Set<Integer> destination) {\n-    for (Integer pId : toAdd) {\n-      destination.add(pId);\n-    }\n-  }\n-\n-  private static ResourceAssignment emptyAssignment(String name, CurrentStateOutput currStateOutput) {\n-    ResourceAssignment assignment = new ResourceAssignment(name);\n-    Set<Partition> partitions = currStateOutput.getCurrentStateMappedPartitions(name);\n-    for (Partition partition : partitions) {\n-      Map<String, String> currentStateMap = currStateOutput.getCurrentStateMap(name, partition);\n-      Map<String, String> replicaMap = Maps.newHashMap();\n-      for (String instanceName : currentStateMap.keySet()) {\n-        replicaMap.put(instanceName, HelixDefinedState.DROPPED.toString());\n-      }\n-      assignment.addReplicaMap(partition, replicaMap);\n-    }\n-    return assignment;\n-  }\n-\n-  private static void addCompletedPartitions(Set<Integer> set, JobContext ctx,\n-      Iterable<Integer> pIds) {\n-    for (Integer pId : pIds) {\n-      TaskPartitionState state = ctx.getPartitionState(pId);\n-      if (state == TaskPartitionState.COMPLETED) {\n-        set.add(pId);\n-      }\n-    }\n-  }\n-\n-  private static boolean isTaskGivenup(JobContext ctx, JobConfig cfg, int pId) {\n-    return ctx.getPartitionNumAttempts(pId) >= cfg.getMaxAttemptsPerTask();\n-  }\n-\n-  // add all partitions that have been tried maxNumberAttempts\n-  private static void addGiveupPartitions(Set<Integer> set, JobContext ctx, Iterable<Integer> pIds,\n-      JobConfig cfg) {\n-    for (Integer pId : pIds) {\n-      if (isTaskGivenup(ctx, cfg, pId)) {\n-        set.add(pId);\n-      }\n-    }\n-  }\n-\n-  private static List<Integer> getNextPartitions(SortedSet<Integer> candidatePartitions,\n-      Set<Integer> excluded, int n) {\n-    List<Integer> result = new ArrayList<Integer>();\n-    for (Integer pId : candidatePartitions) {\n-      if (result.size() >= n) {\n-        break;\n-      }\n-\n-      if (!excluded.contains(pId)) {\n-        result.add(pId);\n-      }\n-    }\n-\n-    return result;\n-  }\n-\n-  private static void markPartitionDelayed(JobConfig cfg, JobContext ctx, int p) {\n-    long delayInterval = cfg.getTaskRetryDelay();\n-    if (delayInterval <= 0) {\n-      return;\n-    }\n-    long nextStartTime = ctx.getPartitionFinishTime(p) + delayInterval;\n-    ctx.setNextRetryTime(p, nextStartTime);\n-  }\n-\n-  private static void markPartitionCompleted(JobContext ctx, int pId) {\n-    ctx.setPartitionState(pId, TaskPartitionState.COMPLETED);\n-    ctx.setPartitionFinishTime(pId, System.currentTimeMillis());\n-    ctx.incrementNumAttempts(pId);\n-  }\n-\n-  private static void markPartitionError(JobContext ctx, int pId, TaskPartitionState state,\n-      boolean incrementAttempts) {\n-    ctx.setPartitionState(pId, state);\n-    ctx.setPartitionFinishTime(pId, System.currentTimeMillis());\n-    if (incrementAttempts) {\n-      ctx.incrementNumAttempts(pId);\n-    }\n-  }\n-\n-  private static void markAllPartitionsError(JobContext ctx, TaskPartitionState state,\n-      boolean incrementAttempts) {\n-    for (int pId : ctx.getPartitionSet()) {\n-      markPartitionError(ctx, pId, state, incrementAttempts);\n-    }\n-  }\n-\n-  /**\n-   * Return the assignment of task partitions per instance.\n-   */\n-  private static Map<String, SortedSet<Integer>> getTaskPartitionAssignments(\n-      Iterable<String> instanceList, ResourceAssignment assignment, Set<Integer> includeSet) {\n-    Map<String, SortedSet<Integer>> result = new HashMap<String, SortedSet<Integer>>();\n-    for (String instance : instanceList) {\n-      result.put(instance, new TreeSet<Integer>());\n-    }\n-\n-    for (Partition partition : assignment.getMappedPartitions()) {\n-      int pId = pId(partition.getPartitionName());\n-      if (includeSet.contains(pId)) {\n-        Map<String, String> replicaMap = assignment.getReplicaMap(partition);\n-        for (String instance : replicaMap.keySet()) {\n-          SortedSet<Integer> pList = result.get(instance);\n-          if (pList != null) {\n-            pList.add(pId);\n-          }\n-        }\n-      }\n-    }\n-    return result;\n-  }\n-\n-  private static Set<Integer> getNonReadyPartitions(JobContext ctx, long now) {\n-    Set<Integer> nonReadyPartitions = Sets.newHashSet();\n-    for (int p : ctx.getPartitionSet()) {\n-      long toStart = ctx.getNextRetryTime(p);\n-      if (now < toStart) {\n-        nonReadyPartitions.add(p);\n-      }\n-    }\n-    return nonReadyPartitions;\n-  }\n-\n-  /**\n-   * Computes the partition name given the resource name and partition id.\n-   */\n-  protected static String pName(String resource, int pId) {\n-    return resource + \"_\" + pId;\n-  }\n-\n-  /**\n-   * Extracts the partition id from the given partition name.\n-   */\n-  protected static int pId(String pName) {\n-    String[] tokens = pName.split(\"_\");\n-    return Integer.valueOf(tokens[tokens.length - 1]);\n-  }\n-\n-  /**\n-   * An (instance, state) pair.\n-   */\n-  private static class PartitionAssignment {\n-    private final String _instance;\n-    private final String _state;\n-\n-    private PartitionAssignment(String instance, String state) {\n-      _instance = instance;\n-      _state = state;\n-    }\n-  }\n-\n-  @Override\n-  public IdealState computeNewIdealState(String resourceName, IdealState currentIdealState,\n-      CurrentStateOutput currentStateOutput, WorkflowControllerDataProvider clusterData) {\n-    // All of the heavy lifting is in the ResourceAssignment computation,\n-    // so this part can just be a no-op.\n-    return currentIdealState;\n-  }\n-\n-  /**\n-   * The simplest possible runnable that will trigger a run of the controller pipeline\n-   */\n-  private static class RebalanceInvoker implements Runnable {\n-    private final HelixManager _manager;\n-    private final String _resource;\n-\n-    public RebalanceInvoker(HelixManager manager, String resource) {\n-      _manager = manager;\n-      _resource = resource;\n-    }\n-\n-    @Override\n-    public void run() {\n-      RebalanceScheduler.invokeRebalance(_manager.getHelixDataAccessor(), _resource);\n-    }\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyMTQ1Ng==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437621456", "bodyText": "So it may not be safe to change public API directly. My suggestion is to deprecate the method and create a new one if necessary.\nThis deprecated function can call the new function.", "author": "junkaixue", "createdAt": "2020-06-09T18:06:52Z", "path": "helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskAssignmentCalculator.java", "diffHunk": "@@ -78,11 +78,11 @@ public FixedTargetTaskAssignmentCalculator(AssignableInstanceManager assignableI\n \n   @Override\n   public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,", "originalCommit": "9745afe38eb76ab01bfb551660a918ca14939bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4Mzk1Ng==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437683956", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-06-09T20:00:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyMTQ1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7d2d65092e5719578cb1845b30ad17c45b163035", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskAssignmentCalculator.java b/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskAssignmentCalculator.java\nindex decb3fbb0..d031d8967 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskAssignmentCalculator.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskAssignmentCalculator.java\n\n@@ -76,6 +76,16 @@ public class FixedTargetTaskAssignmentCalculator extends TaskAssignmentCalculato\n     return getAllTaskPartitions(tgtIs, jobCfg, jobCtx);\n   }\n \n+  @Override\n+  @Deprecated\n+  public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n+      ResourceAssignment prevAssignment, Collection<String> instances, JobConfig jobCfg,\n+      JobContext jobContext, WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n+      Set<Integer> partitionSet, Map<String, IdealState> idealStateMap) {\n+    return getTaskAssignment(currStateOutput, instances, jobCfg, jobContext, workflowCfg,\n+        workflowCtx, partitionSet, idealStateMap);\n+  }\n+\n   @Override\n   public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n       Collection<String> instances, JobConfig jobCfg, JobContext jobContext,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDI0Ng==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437624246", "bodyText": "Same here. Shall we remove this class?", "author": "junkaixue", "createdAt": "2020-06-09T18:11:42Z", "path": "helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskRebalancer.java", "diffHunk": "@@ -48,13 +48,11 @@\n   }", "originalCommit": "9745afe38eb76ab01bfb551660a918ca14939bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NDU4MQ==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437674581", "bodyText": "Removed.", "author": "alirezazamani", "createdAt": "2020-06-09T19:42:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDI0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7d2d65092e5719578cb1845b30ad17c45b163035", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskRebalancer.java b/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskRebalancer.java\ndeleted file mode 100644\nindex e246b42b7..000000000\n--- a/helix-core/src/main/java/org/apache/helix/task/FixedTargetTaskRebalancer.java\n+++ /dev/null\n\n@@ -1,58 +0,0 @@\n-package org.apache.helix.task;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.SortedSet;\n-\n-import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n-import org.apache.helix.controller.stages.CurrentStateOutput;\n-import org.apache.helix.model.ResourceAssignment;\n-/**\n- * A rebalancer for when a task group must be assigned according to partitions/states on a target\n- * resource. Here, tasks are colocated according to where a resource's partitions are, as well as\n- * (if desired) only where those partitions are in a given state.\n- */\n-\n-/**\n- * This rebalancer is deprecated, left here only for back-compatible. *\n- */\n-@Deprecated\n-public class FixedTargetTaskRebalancer extends DeprecatedTaskRebalancer {\n-  private FixedTargetTaskAssignmentCalculator taskAssignmentCalculator =\n-      new FixedTargetTaskAssignmentCalculator();\n-\n-  @Override public Set<Integer> getAllTaskPartitions(JobConfig jobCfg, JobContext jobCtx,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx, WorkflowControllerDataProvider cache) {\n-    return taskAssignmentCalculator\n-        .getAllTaskPartitions(jobCfg, jobCtx, workflowCfg, workflowCtx, cache.getIdealStates());\n-  }\n-\n-  @Override\n-  public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n-      Collection<String> instances, JobConfig jobCfg, JobContext jobContext,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx, Set<Integer> partitionSet,\n-      WorkflowControllerDataProvider cache) {\n-    return taskAssignmentCalculator.getTaskAssignment(currStateOutput, instances, jobCfg,\n-        jobContext, workflowCfg, workflowCtx, partitionSet, cache.getIdealStates());\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDYxNg==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437624616", "bodyText": "Better not change public API, we can deprecate it and add a new one.", "author": "junkaixue", "createdAt": "2020-06-09T18:12:23Z", "path": "helix-core/src/main/java/org/apache/helix/task/GenericTaskAssignmentCalculator.java", "diffHunk": "@@ -65,9 +65,9 @@\n \n   @Override\n   public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n-      ResourceAssignment prevAssignment, Collection<String> instances, JobConfig jobCfg,\n-      final JobContext jobContext, WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n-      Set<Integer> partitionSet, Map<String, IdealState> idealStateMap) {\n+      Collection<String> instances, JobConfig jobCfg, final JobContext jobContext,", "originalCommit": "9745afe38eb76ab01bfb551660a918ca14939bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDA1MA==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437684050", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-06-09T20:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDYxNg=="}], "type": "inlineReview", "revised_code": {"commit": "7d2d65092e5719578cb1845b30ad17c45b163035", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/GenericTaskAssignmentCalculator.java b/helix-core/src/main/java/org/apache/helix/task/GenericTaskAssignmentCalculator.java\nindex 6411f5310..93e81f96e 100644\n--- a/helix-core/src/main/java/org/apache/helix/task/GenericTaskAssignmentCalculator.java\n+++ b/helix-core/src/main/java/org/apache/helix/task/GenericTaskAssignmentCalculator.java\n\n@@ -63,6 +63,16 @@ public class GenericTaskAssignmentCalculator extends TaskAssignmentCalculator {\n     return jobCtx.getPartitionSet();\n   }\n \n+  @Override\n+  @Deprecated\n+  public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n+      ResourceAssignment prevAssignment, Collection<String> instances, JobConfig jobCfg,\n+      JobContext jobContext, WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n+      Set<Integer> partitionSet, Map<String, IdealState> idealStateMap) {\n+    return getTaskAssignment(currStateOutput, instances, jobCfg, jobContext, workflowCfg,\n+        workflowCtx, partitionSet, idealStateMap);\n+  }\n+\n   @Override\n   public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n       Collection<String> instances, JobConfig jobCfg, final JobContext jobContext,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDg4OQ==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437624889", "bodyText": "Same here. Shall we remove the rebalancer related class. Or, at least, deprecate it.", "author": "junkaixue", "createdAt": "2020-06-09T18:12:50Z", "path": "helix-core/src/main/java/org/apache/helix/task/GenericTaskRebalancer.java", "diffHunk": "@@ -40,18 +40,18 @@\n \n   @Override\n   public Set<Integer> getAllTaskPartitions(JobConfig jobCfg, JobContext jobCtx,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx, WorkflowControllerDataProvider cache) {\n-    return taskAssignmentCalculator\n-        .getAllTaskPartitions(jobCfg, jobCtx, workflowCfg, workflowCtx, cache.getIdealStates());\n+      WorkflowConfig workflowCfg, WorkflowContext workflowCtx,", "originalCommit": "9745afe38eb76ab01bfb551660a918ca14939bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3NDc4MA==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437674780", "bodyText": "Removed.", "author": "alirezazamani", "createdAt": "2020-06-09T19:43:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYyNDg4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7d2d65092e5719578cb1845b30ad17c45b163035", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/task/GenericTaskRebalancer.java b/helix-core/src/main/java/org/apache/helix/task/GenericTaskRebalancer.java\ndeleted file mode 100644\nindex eb9c2f1c1..000000000\n--- a/helix-core/src/main/java/org/apache/helix/task/GenericTaskRebalancer.java\n+++ /dev/null\n\n@@ -1,57 +0,0 @@\n-package org.apache.helix.task;\n-\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-import java.util.Collection;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.SortedSet;\n-\n-import org.apache.helix.controller.dataproviders.WorkflowControllerDataProvider;\n-import org.apache.helix.controller.stages.CurrentStateOutput;\n-import org.apache.helix.model.ResourceAssignment;\n-\n-\n-/**\n- * This class does an assignment based on an automatic rebalancing strategy, rather than requiring\n- * assignment to target partitions and states of another resource\n- */\n-/** This rebalancer is deprecated, left here only for back-compatible. **/\n-@Deprecated\n-public class GenericTaskRebalancer extends DeprecatedTaskRebalancer {\n-  private GenericTaskAssignmentCalculator taskAssignmentCalculator =\n-      new GenericTaskAssignmentCalculator();\n-\n-  @Override\n-  public Set<Integer> getAllTaskPartitions(JobConfig jobCfg, JobContext jobCtx,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx,\n-      WorkflowControllerDataProvider cache) {\n-    return taskAssignmentCalculator.getAllTaskPartitions(jobCfg, jobCtx, workflowCfg, workflowCtx,\n-        cache.getIdealStates());\n-  }\n-\n-  @Override\n-  public Map<String, SortedSet<Integer>> getTaskAssignment(CurrentStateOutput currStateOutput,\n-      Collection<String> instances, JobConfig jobCfg, final JobContext jobContext,\n-      WorkflowConfig workflowCfg, WorkflowContext workflowCtx, Set<Integer> partitionSet,\n-      WorkflowControllerDataProvider cache) {\n-    return taskAssignmentCalculator.getTaskAssignment(currStateOutput, instances, jobCfg,\n-        jobContext, workflowCfg, workflowCtx, partitionSet, cache.getIdealStates());\n-  }\n-}\n"}}, {"oid": "7d2d65092e5719578cb1845b30ad17c45b163035", "url": "https://github.com/apache/helix/commit/7d2d65092e5719578cb1845b30ad17c45b163035", "message": "Address comments", "committedDate": "2020-06-09T20:04:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MTA3OA==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437691078", "bodyText": "Would this break backward compatibility for existing long-running TF resources?", "author": "narendly", "createdAt": "2020-06-09T20:14:24Z", "path": "helix-core/src/main/java/org/apache/helix/model/IdealState.java", "diffHunk": "@@ -721,9 +719,7 @@ private RebalanceMode normalizeRebalanceMode(IdealStateModeProperty mode) {\n       String rebalancerName = getRebalancerClassName();\n       if (rebalancerName != null) {\n         if (rebalancerName.equals(JobRebalancer.class.getName())\n-            || rebalancerName.equals(WorkflowRebalancer.class.getName())\n-            || rebalancerName.equals(GenericTaskRebalancer.class.getName())\n-            || rebalancerName.equals(FixedTargetTaskRebalancer.class.getName())) {\n+            || rebalancerName.equals(WorkflowRebalancer.class.getName())) {", "originalCommit": "7d2d65092e5719578cb1845b30ad17c45b163035", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NTM2Mg==", "url": "https://github.com/apache/helix/pull/1061#discussion_r437695362", "bodyText": "I think we are safe because the remove ones have been deprecated around 4 years ago. Perhaps it is time to do some cleaning for TF code base.", "author": "alirezazamani", "createdAt": "2020-06-09T20:22:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MTA3OA=="}], "type": "inlineReview", "revised_code": {"commit": "9d5b0201489247516a09b2cf8958e0036ff6676b", "chunk": "diff --git a/helix-core/src/main/java/org/apache/helix/model/IdealState.java b/helix-core/src/main/java/org/apache/helix/model/IdealState.java\nindex 20dd905f1..ff9a99b08 100644\n--- a/helix-core/src/main/java/org/apache/helix/model/IdealState.java\n+++ b/helix-core/src/main/java/org/apache/helix/model/IdealState.java\n\n@@ -721,6 +726,14 @@ public class IdealState extends HelixProperty {\n         if (rebalancerName.equals(JobRebalancer.class.getName())\n             || rebalancerName.equals(WorkflowRebalancer.class.getName())) {\n           property = RebalanceMode.TASK;\n+        } else if (LEGACY_TASK_REBALANCERS.contains(rebalancerName)) {\n+          // Print a warning message if legacy TASK rebalancer is used\n+          // Since legacy rebalancers have been removed, it is not safe just running legacy jobs and jobs/workflows\n+          //with current task assignment strategy.\n+          logger.warn(\n+              \"The rebalancer {} is not supported anymore. Setting rebalance mode to USER_DEFINED.\",\n+              rebalancerName);\n+          property = RebalanceMode.USER_DEFINED;\n         } else {\n           property = RebalanceMode.USER_DEFINED;\n         }\n"}}, {"oid": "9d5b0201489247516a09b2cf8958e0036ff6676b", "url": "https://github.com/apache/helix/commit/9d5b0201489247516a09b2cf8958e0036ff6676b", "message": "log added for legacy rebalancers", "committedDate": "2020-06-10T18:13:11Z", "type": "commit"}, {"oid": "9d5b0201489247516a09b2cf8958e0036ff6676b", "url": "https://github.com/apache/helix/commit/9d5b0201489247516a09b2cf8958e0036ff6676b", "message": "log added for legacy rebalancers", "committedDate": "2020-06-10T18:13:11Z", "type": "forcePushed"}, {"oid": "ae1e40e76a83421ae8b3ffe08d15a9a4537dee51", "url": "https://github.com/apache/helix/commit/ae1e40e76a83421ae8b3ffe08d15a9a4537dee51", "message": "minor change", "committedDate": "2020-06-10T18:23:00Z", "type": "commit"}]}