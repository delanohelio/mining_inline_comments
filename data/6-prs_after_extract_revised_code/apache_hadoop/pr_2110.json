{"pr_number": 2110, "pr_title": "HDFS-15447 RBF: Add top real owners metrics for delegation tokens", "pr_createdAt": "2020-06-30T08:02:02Z", "pr_url": "https://github.com/apache/hadoop/pull/2110", "timeline": [{"oid": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "url": "https://github.com/apache/hadoop/commit/1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "message": "Add top real owners metrics for token", "committedDate": "2020-06-30T07:59:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447745987", "bodyText": "is it necessary to import static?", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:51:47Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -34,6 +38,8 @@\n import org.apache.hadoop.classification.InterfaceAudience;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.io.Text;\n+import static org.apache.hadoop.metrics2.util.Metrics2Util.NameValuePair;", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4NjI0MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447986241", "bodyText": "Inigo told me once about it and I think it can have the usage of member variables easier and cleaner.", "author": "fengnanli", "createdAt": "2020-06-30T21:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAwNDc0Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448004743", "bodyText": "If the method/class is very obvious like assertTrue(), it usually makes sense to do a static import.\nIn this case, I guess is fine either way.", "author": "goiri", "createdAt": "2020-06-30T22:02:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA2OTExNQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448069115", "bodyText": "Not always the case but I'd say this is fine.", "author": "goiri", "createdAt": "2020-07-01T01:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NTk4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 3274a3c5223..4acc224b235 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -38,8 +37,8 @@\n import org.apache.hadoop.classification.InterfaceAudience;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.io.Text;\n-import static org.apache.hadoop.metrics2.util.Metrics2Util.NameValuePair;\n-import static org.apache.hadoop.metrics2.util.Metrics2Util.TopN;\n+import org.apache.hadoop.metrics2.util.Metrics2Util.NameValuePair;\n+import org.apache.hadoop.metrics2.util.Metrics2Util.TopN;\n import org.apache.hadoop.security.AccessControlException;\n import org.apache.hadoop.security.HadoopKerberosName;\n import org.apache.hadoop.security.token.SecretManager;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447747693", "bodyText": "we need to define this new configure item at hdfs-rbf-default.xml.", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:53:50Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RBFConfigKeys.java", "diffHunk": "@@ -79,6 +79,10 @@\n   public static final Class<? extends RouterRpcMonitor>\n       DFS_ROUTER_METRICS_CLASS_DEFAULT =\n       FederationRPCPerformanceMonitor.class;\n+  public static final String DFS_ROUTER_METRICS_TOP_NUM_TOKEN_OWNERS_KEY =", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTc5NA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965794", "bodyText": "not sure if there is a metrics.md page for RBF - if so we should add there too.", "author": "sunchao", "createdAt": "2020-06-30T20:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4ODQ4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447988483", "bodyText": "Sure. I will add it here: https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/resources/hdfs-rbf-default.xml", "author": "fengnanli", "createdAt": "2020-06-30T21:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzY5Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0ODk1Mg==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447748952", "bodyText": "just suggest to replace with single class imports.", "author": "Hexiaoqiao", "createdAt": "2020-06-30T14:55:20Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java", "diffHunk": "@@ -39,6 +39,7 @@\n import org.junit.Rule;\n import org.junit.Test;\n \n+import static org.apache.hadoop.metrics2.util.Metrics2Util.*;", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk4ODU2Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447988563", "bodyText": "Sure", "author": "fengnanli", "createdAt": "2020-06-30T21:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0ODk1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\nindex de2076edcbc..f0b86e31a6b 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\n\n@@ -39,7 +40,6 @@\n import org.junit.Rule;\n import org.junit.Test;\n \n-import static org.apache.hadoop.metrics2.util.Metrics2Util.*;\n import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n import static org.junit.Assert.assertTrue;\n import static org.junit.Assert.assertFalse;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965061", "bodyText": "will this get pretty expensive if there are lots of tokens stored? as every metrics pull needs to iterate through all tokens.", "author": "sunchao", "createdAt": "2020-06-30T20:40:02Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +732,41 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5MzMzMQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447993331", "bodyText": "I had similar thoughts as well but didn't come up with a better way. In namenode TopN metrics, it is doing so as well just at a lower frequency like every 5/15/25 minutes. We can potentially do that by reducing the metric reporting frequency.\nI also checked modern CPU for looping over 1M, which takes about 1ms-10ms.\nAnother one would be to maintain a data structure to dynamically maintain the ordering of users and edit ordering per getdelegationtoken and per canceldelegationtoken like stream processing. I am not sure about the cost overall since in reality we generally have < 1 Million tokens.", "author": "fengnanli", "createdAt": "2020-06-30T21:36:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAyMDc3MA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448020770", "bodyText": "Can we update the TopN queue when creating/deleting tokens? we are just paying an extra constant cost for updating that which I think is fine. Even though it is using concurrent hashmap, I'm not sure how much performance impact will be if one thread is iterating over the key set while others want to updating the map.", "author": "sunchao", "createdAt": "2020-06-30T22:46:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNjQ0OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448036448", "bodyText": "I am fine with it. We also need to add an initialization step to make sure this structure has the initial information from currentTokens.", "author": "fengnanli", "createdAt": "2020-06-30T23:36:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTA2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 3274a3c5223..4acc224b235 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -739,34 +748,79 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @return map of owners to counts\n    */\n   public List<NameValuePair> getTopTokenRealOwners(int n) {\n-    Map<String, Integer> tokenOwnerMap = new HashMap<>();\n-    for (TokenIdent id : currentTokens.keySet()) {\n-      String realUser;\n-      if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n-        realUser = id.getRealUser().toString();\n-      } else {\n-        // if there is no real user -> this is a non proxy user\n-        // the user itself is the real owner\n-        realUser = id.getUser().getUserName();\n-      }\n-      tokenOwnerMap.put(realUser, tokenOwnerMap.getOrDefault(realUser, 0)+1);\n-    }\n-    n = Math.min(n, tokenOwnerMap.size());\n+    n = Math.min(n, tokenOwnerStats.size());\n     if (n == 0) {\n-      return new LinkedList<>();\n+      return new ArrayList<>();\n     }\n \n     TopN topN = new TopN(n);\n-    for (Map.Entry<String, Integer> entry : tokenOwnerMap.entrySet()) {\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n       topN.offer(new NameValuePair(\n           entry.getKey(), entry.getValue()));\n     }\n \n-    List<NameValuePair> list = new LinkedList<>();\n+    List<NameValuePair> list = new ArrayList<>();\n     while (!topN.isEmpty()) {\n       list.add(topN.poll());\n     }\n     Collections.reverse(list);\n     return list;\n   }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    if (tokenOwnerStats.containsKey(realOwner)) {\n+      // unlikely to be less than 1 but in case\n+      if (tokenOwnerStats.get(realOwner) <= 1) {\n+        tokenOwnerStats.remove(realOwner);\n+      } else {\n+        tokenOwnerStats.put(realOwner, tokenOwnerStats.get(realOwner)-1);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method syncs token information from currentTokens to tokenOwnerStats.\n+   * It is used when the currentTokens is initialized or refreshed.\n+   */\n+  public void syncTokenOwnerStats() {\n+    for (TokenIdent id : currentTokens.keySet()) {\n+      addTokenForOwnerStats(id);\n+    }\n+  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965275", "bodyText": "any reason to use LinkedList instead of ArrayList? the latter is usually more performant.", "author": "sunchao", "createdAt": "2020-06-30T20:40:27Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +732,41 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    Map<String, Integer> tokenOwnerMap = new HashMap<>();\n+    for (TokenIdent id : currentTokens.keySet()) {\n+      String realUser;\n+      if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+        realUser = id.getRealUser().toString();\n+      } else {\n+        // if there is no real user -> this is a non proxy user\n+        // the user itself is the real owner\n+        realUser = id.getUser().getUserName();\n+      }\n+      tokenOwnerMap.put(realUser, tokenOwnerMap.getOrDefault(realUser, 0)+1);\n+    }\n+    n = Math.min(n, tokenOwnerMap.size());\n+    if (n == 0) {\n+      return new LinkedList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Integer> entry : tokenOwnerMap.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new LinkedList<>();", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5MzgyNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447993824", "bodyText": "There is a reverse op and I think reverse linked list is faster without additional space.\nNot sure how java implement the reverse array list, but I think it will introduce copy and reassign.", "author": "fengnanli", "createdAt": "2020-06-30T21:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAyMjUxOA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448022518", "bodyText": "Reverse shouldn't need extra space - it uses two indexes from begin and end of the array and swaps elements. I don't see real difference between the two for the reverse.", "author": "sunchao", "createdAt": "2020-06-30T22:51:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTI3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 3274a3c5223..4acc224b235 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -739,34 +748,79 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @return map of owners to counts\n    */\n   public List<NameValuePair> getTopTokenRealOwners(int n) {\n-    Map<String, Integer> tokenOwnerMap = new HashMap<>();\n-    for (TokenIdent id : currentTokens.keySet()) {\n-      String realUser;\n-      if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n-        realUser = id.getRealUser().toString();\n-      } else {\n-        // if there is no real user -> this is a non proxy user\n-        // the user itself is the real owner\n-        realUser = id.getUser().getUserName();\n-      }\n-      tokenOwnerMap.put(realUser, tokenOwnerMap.getOrDefault(realUser, 0)+1);\n-    }\n-    n = Math.min(n, tokenOwnerMap.size());\n+    n = Math.min(n, tokenOwnerStats.size());\n     if (n == 0) {\n-      return new LinkedList<>();\n+      return new ArrayList<>();\n     }\n \n     TopN topN = new TopN(n);\n-    for (Map.Entry<String, Integer> entry : tokenOwnerMap.entrySet()) {\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n       topN.offer(new NameValuePair(\n           entry.getKey(), entry.getValue()));\n     }\n \n-    List<NameValuePair> list = new LinkedList<>();\n+    List<NameValuePair> list = new ArrayList<>();\n     while (!topN.isEmpty()) {\n       list.add(topN.poll());\n     }\n     Collections.reverse(list);\n     return list;\n   }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    if (tokenOwnerStats.containsKey(realOwner)) {\n+      // unlikely to be less than 1 but in case\n+      if (tokenOwnerStats.get(realOwner) <= 1) {\n+        tokenOwnerStats.remove(realOwner);\n+      } else {\n+        tokenOwnerStats.put(realOwner, tokenOwnerStats.get(realOwner)-1);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method syncs token information from currentTokens to tokenOwnerStats.\n+   * It is used when the currentTokens is initialized or refreshed.\n+   */\n+  public void syncTokenOwnerStats() {\n+    for (TokenIdent id : currentTokens.keySet()) {\n+      addTokenForOwnerStats(id);\n+    }\n+  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTkzNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447965934", "bodyText": "nit: extra blank line", "author": "sunchao", "createdAt": "2020-06-30T20:41:33Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java", "diffHunk": "@@ -124,6 +126,71 @@ public void testDelegationTokens() throws IOException {\n     securityManager.renewDelegationToken(token);\n   }\n \n+  @Test\n+  public void testDelgationTokenTopOwners() throws Exception {\n+    List<NameValuePair> topOwners;\n+\n+    UserGroupInformation user = UserGroupInformation\n+        .createUserForTesting(\"abc\", new String[]{\"router_group\"});\n+    UserGroupInformation.setLoginUser(user);\n+    Token dt = securityManager.getDelegationToken(new Text(\"abc\"));\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"abc\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.renewDelegationToken(dt);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"abc\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.cancelDelegationToken(dt);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(0, topOwners.size());\n+\n+\n+    // Use proxy user - the code should use the proxy user as the real owner\n+    UserGroupInformation routerUser =\n+        UserGroupInformation.createRemoteUser(\"router\");\n+    UserGroupInformation proxyUser = UserGroupInformation\n+        .createProxyUserForTesting(\"abc\",\n+            routerUser,\n+            new String[]{\"router_group\"});\n+    UserGroupInformation.setLoginUser(proxyUser);\n+\n+    Token proxyDT = securityManager.getDelegationToken(new Text(\"router\"));\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"router\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    // router to renew tokens\n+    UserGroupInformation.setLoginUser(routerUser);\n+    securityManager.renewDelegationToken(proxyDT);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(1, topOwners.size());\n+    assertEquals(\"router\", topOwners.get(0).getName());\n+    assertEquals(1, topOwners.get(0).getValue());\n+\n+    securityManager.cancelDelegationToken(proxyDT);\n+    topOwners = securityManager.getSecretManager().getTopTokenRealOwners(2);\n+    assertEquals(0, topOwners.size());\n+", "originalCommit": "1696b5fbfe79b13a68c1a14b7c7fac2a5ffb00be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk5NDA4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r447994083", "bodyText": "will remove", "author": "fengnanli", "createdAt": "2020-06-30T21:37:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2NTkzNA=="}], "type": "inlineReview", "revised_code": {"commit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\nindex de2076edcbc..d62837ccb13 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/security/TestRouterSecurityManager.java\n\n@@ -128,6 +128,7 @@ public void testDelegationTokens() throws IOException {\n \n   @Test\n   public void testDelgationTokenTopOwners() throws Exception {\n+    UserGroupInformation.reset();\n     List<NameValuePair> topOwners;\n \n     UserGroupInformation user = UserGroupInformation\n"}}, {"oid": "6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "url": "https://github.com/apache/hadoop/commit/6f46d5ce915f9fa3227be12f94f7dd4a4f5200db", "message": "Address comments; using streaming fashion to deal with structure updates", "committedDate": "2020-07-01T00:08:03Z", "type": "commit"}, {"oid": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "url": "https://github.com/apache/hadoop/commit/64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "message": "Fix checkstyle and unit tests", "committedDate": "2020-07-01T00:56:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwMTI4OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448701288", "bodyText": "top users -> top user metrics?", "author": "sunchao", "createdAt": "2020-07-02T01:39:02Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -64,7 +69,13 @@ private String formatTokenId(TokenIdent id) {\n    */\n   protected final Map<TokenIdent, DelegationTokenInformation> currentTokens \n       = new ConcurrentHashMap<>();\n-  \n+\n+  /**\n+   * Map of token real owners to its token count. This is used to generate\n+   * top users by owned tokens.", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -72,7 +72,7 @@ private String formatTokenId(TokenIdent id) {\n \n   /**\n    * Map of token real owners to its token count. This is used to generate\n-   * top users by owned tokens.\n+   * metrics of top users by owned tokens.\n    */\n   protected final Map<String, Long> tokenOwnerStats = new ConcurrentHashMap<>();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Njc2OA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448756768", "bodyText": "nit: use capital 0L to make IDE happy", "author": "sunchao", "createdAt": "2020-07-02T05:28:54Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -774,7 +774,7 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @param id\n    * @return real owner\n    */\n-  public String getTokenRealOwner(TokenIdent id) {\n+  private String getTokenRealOwner(TokenIdent id) {\n     String realUser;\n     if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n       realUser = id.getRealUser().toString();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1NzU4OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448757589", "bodyText": "Even though tokenOwnerStats is a concurrent map, you may run into race conditions if multiple threads operate on this method at the same time. We can potentially make the method synchronized to avoid that. Not sure we should care much though since this is only for metrics.", "author": "sunchao", "createdAt": "2020-07-02T05:31:56Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    if (tokenOwnerStats.containsKey(realOwner)) {\n+      // unlikely to be less than 1 but in case\n+      if (tokenOwnerStats.get(realOwner) <= 1) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzU1OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227559", "bodyText": "The function is called from createPassword and cancelToken which are all synchronized so it is safe here. Similarly currentTokens is used in the pattern.", "author": "fengnanli", "createdAt": "2020-07-08T01:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1NzU4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -774,7 +774,7 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @param id\n    * @return real owner\n    */\n-  public String getTokenRealOwner(TokenIdent id) {\n+  private String getTokenRealOwner(TokenIdent id) {\n     String realUser;\n     if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n       realUser = id.getRealUser().toString();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Nzg3Nw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448757877", "bodyText": "It's slightly unfortunate that we need to expose NameValuePair in a public method here as it is scope = private, but I don't know an easy way to avoid this.", "author": "sunchao", "createdAt": "2020-07-02T05:33:15Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNjA0MA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451226040", "bodyText": "I will keep it as it is.", "author": "fengnanli", "createdAt": "2020-07-08T01:08:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1Nzg3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -774,7 +774,7 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @param id\n    * @return real owner\n    */\n-  public String getTokenRealOwner(TokenIdent id) {\n+  private String getTokenRealOwner(TokenIdent id) {\n     String realUser;\n     if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n       realUser = id.getRealUser().toString();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODUxMg==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448758512", "bodyText": "can we swap the order and update the stats as last step?", "author": "sunchao", "createdAt": "2020-07-02T05:35:50Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -292,6 +303,7 @@ protected DelegationTokenInformation getTokenInfo(TokenIdent ident) {\n   protected void storeToken(TokenIdent ident,\n       DelegationTokenInformation tokenInfo) throws IOException {\n     currentTokens.put(ident, tokenInfo);\n+    addTokenForOwnerStats(ident);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODYyNA==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448758624", "bodyText": "same here - swap order and update stats as the last step?", "author": "sunchao", "createdAt": "2020-07-02T05:36:08Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -578,6 +591,7 @@ public synchronized TokenIdent cancelToken(Token<TokenIdent> token,\n     if (info == null) {\n       throw new InvalidToken(\"Token not found \" + formatTokenId(id));\n     }\n+    removeTokenForOwnerStats(id);", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzI5MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227291", "bodyText": "The reason i left the order as this is that the metric is a in-memory reflection currentTokens so it can be calculated once the memory data structure is changed.\nThe procedure after is for persistent storage.", "author": "fengnanli", "createdAt": "2020-07-08T01:13:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1ODYyNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1OTU4Mw==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448759583", "bodyText": "This and a few others do not need to be public?", "author": "sunchao", "createdAt": "2020-07-02T05:39:42Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -726,4 +741,86 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n     return token.decodeIdentifier();\n   }\n \n+  /**\n+   * Return top token real owners list as well as the tokens count.\n+   *\n+   * @param n top number of users\n+   * @return map of owners to counts\n+   */\n+  public List<NameValuePair> getTopTokenRealOwners(int n) {\n+    n = Math.min(n, tokenOwnerStats.size());\n+    if (n == 0) {\n+      return new ArrayList<>();\n+    }\n+\n+    TopN topN = new TopN(n);\n+    for (Map.Entry<String, Long> entry : tokenOwnerStats.entrySet()) {\n+      topN.offer(new NameValuePair(\n+          entry.getKey(), entry.getValue()));\n+    }\n+\n+    List<NameValuePair> list = new ArrayList<>();\n+    while (!topN.isEmpty()) {\n+      list.add(topN.poll());\n+    }\n+    Collections.reverse(list);\n+    return list;\n+  }\n+\n+  /**\n+   * Return the real owner for a token. If this is a token from a proxy user,\n+   * the real/effective user will be returned.\n+   *\n+   * @param id\n+   * @return real owner\n+   */\n+  public String getTokenRealOwner(TokenIdent id) {\n+    String realUser;\n+    if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n+      realUser = id.getRealUser().toString();\n+    } else {\n+      // if there is no real user -> this is a non proxy user\n+      // the user itself is the real owner\n+      realUser = id.getUser().getUserName();\n+    }\n+    return realUser;\n+  }\n+\n+  /**\n+   * Add token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void addTokenForOwnerStats(TokenIdent id) {\n+    String realOwner = getTokenRealOwner(id);\n+    tokenOwnerStats.put(realOwner,\n+        tokenOwnerStats.getOrDefault(realOwner, 0l)+1);\n+  }\n+\n+  /**\n+   * Remove token stats to the owner to token count mapping.\n+   *\n+   * @param id\n+   */\n+  public void removeTokenForOwnerStats(TokenIdent id) {", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzA2OQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227069", "bodyText": "this was fixed.", "author": "fengnanli", "createdAt": "2020-07-08T01:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc1OTU4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -774,7 +774,7 @@ public TokenIdent decodeTokenIdentifier(Token<TokenIdent> token) throws IOExcept\n    * @param id\n    * @return real owner\n    */\n-  public String getTokenRealOwner(TokenIdent id) {\n+  private String getTokenRealOwner(TokenIdent id) {\n     String realUser;\n     if (id.getRealUser() != null && !id.getRealUser().toString().isEmpty()) {\n       realUser = id.getRealUser().toString();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r448762409", "bodyText": "Seems this won't be updated if a standby NN updates its own token info by pulling from edit log?", "author": "sunchao", "createdAt": "2020-07-02T05:50:11Z", "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java", "diffHunk": "@@ -64,7 +69,13 @@ private String formatTokenId(TokenIdent id) {\n    */\n   protected final Map<TokenIdent, DelegationTokenInformation> currentTokens \n       = new ConcurrentHashMap<>();\n-  \n+\n+  /**\n+   * Map of token real owners to its token count. This is used to generate\n+   * top users by owned tokens.\n+   */\n+  protected final Map<String, Long> tokenOwnerStats = new ConcurrentHashMap<>();", "originalCommit": "64fcba5ccb29bee2a6b9159c758d9b5d3ceadd5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzAyNQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451227025", "bodyText": "It depends on individual secret manager to initialize the currentTokens. In namenode, it is loading from edit log. In router, it is loading from ZK.\nI would have a separate ticket for namenode.", "author": "fengnanli", "createdAt": "2020-07-08T01:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTcyOTA3MQ==", "url": "https://github.com/apache/hadoop/pull/2110#discussion_r451729071", "bodyText": "OK. Can you add a comment for this though indicating that this only support RBF for now?", "author": "sunchao", "createdAt": "2020-07-08T18:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2MjQwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "eee3bf835215916aaf1632920523d612bee5429f", "chunk": "diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\nindex 4acc224b235..263cce9d887 100644\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java\n\n@@ -72,7 +72,7 @@ private String formatTokenId(TokenIdent id) {\n \n   /**\n    * Map of token real owners to its token count. This is used to generate\n-   * top users by owned tokens.\n+   * metrics of top users by owned tokens.\n    */\n   protected final Map<String, Long> tokenOwnerStats = new ConcurrentHashMap<>();\n \n"}}, {"oid": "eee3bf835215916aaf1632920523d612bee5429f", "url": "https://github.com/apache/hadoop/commit/eee3bf835215916aaf1632920523d612bee5429f", "message": "Address more comments", "committedDate": "2020-07-05T22:19:49Z", "type": "commit"}, {"oid": "93caedbb9cd7bd3cf6f13a8e267e59ac23dd6442", "url": "https://github.com/apache/hadoop/commit/93caedbb9cd7bd3cf6f13a8e267e59ac23dd6442", "message": "Remove unrelated change", "committedDate": "2020-07-07T06:10:39Z", "type": "commit"}]}